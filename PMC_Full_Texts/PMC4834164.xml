<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-archivearticle1.dtd?><?SourceDTD.Version 1.1?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">Comput Math Methods Med</journal-id><journal-id journal-id-type="iso-abbrev">Comput Math Methods Med</journal-id><journal-id journal-id-type="publisher-id">CMMM</journal-id><journal-title-group><journal-title>Computational and Mathematical Methods in Medicine</journal-title></journal-title-group><issn pub-type="ppub">1748-670X</issn><issn pub-type="epub">1748-6718</issn><publisher><publisher-name>Hindawi Publishing Corporation</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">4834164</article-id><article-id pub-id-type="doi">10.1155/2016/4809831</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>The Virtual Screening of the Drug Protein with a Few Crystal Structures Based on the Adaboost-SVM</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Meng-yu</given-names></name><xref ref-type="aff" rid="I1">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Li</surname><given-names>Peng</given-names></name><xref ref-type="aff" rid="I1">
<sup>1</sup>
</xref><xref ref-type="aff" rid="I2">
<sup>2</sup>
</xref><xref ref-type="corresp" rid="cor1">
<sup>*</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Qiao</surname><given-names>Pei-li</given-names></name><xref ref-type="aff" rid="I1">
<sup>1</sup>
</xref></contrib></contrib-group><aff id="I1"><sup>1</sup>School of Computer Science and Technology, Harbin University of Science and Technology, Harbin 150080, China</aff><aff id="I2"><sup>2</sup>School of Software, Harbin University of Science and Technology, Harbin 150080, China</aff><author-notes><corresp id="cor1">*Peng Li: <email>pli@hrbust.edu.cn</email></corresp><fn fn-type="other"><p>Academic Editor: Ezequiel L&#x000f3;pez-Rubio</p></fn></author-notes><pub-date pub-type="ppub"><year>2016</year></pub-date><pub-date pub-type="epub"><day>3</day><month>4</month><year>2016</year></pub-date><volume>2016</volume><elocation-id>4809831</elocation-id><history><date date-type="received"><day>27</day><month>12</month><year>2015</year></date><date date-type="rev-recd"><day>6</day><month>3</month><year>2016</year></date><date date-type="accepted"><day>7</day><month>3</month><year>2016</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2016 Meng-yu Wang et al.</copyright-statement><copyright-year>2016</copyright-year><license xlink:href="https://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><abstract><p>Using the theory of machine learning to assist the virtual screening (VS) has been an effective plan. However, the quality of the training set may reduce because of mixing with the wrong docking poses and it will affect the screening efficiencies. To solve this problem, we present a method using the ensemble learning to improve the support vector machine to process the generated protein-ligand interaction fingerprint (IFP). By combining multiple classifiers, ensemble learning is able to avoid the limitations of the single classifier's performance and obtain better generalization. According to the research of virtual screening experiment with SRC and Cathepsin K as the target, the results show that the ensemble learning method can effectively reduce the error because the sample quality is not high and improve the effect of the whole virtual screening process.</p></abstract></article-meta></front><body><sec id="sec1"><title>1. Introduction</title><p>Since the 21st century, the focus of life science has been developed from the experimental analysis and data accumulation to experiments under the guidance of data analysis. Life science is undergoing a transition from analysis of reduction of method to the system integration method [<xref rid="B1" ref-type="bibr">1</xref>]. With the completion of human genome project (HGP), more and more three-dimensional structures of important function of biological macromolecules (proteins, nucleic acids, enzymes, etc.) have been parsed [<xref rid="B2" ref-type="bibr">2</xref>]. As the amount of data has increased exponentially in recent years, the combination of traditional pharmaceutical field and modern computer technology has become the inevitable result of the development of life science, and virtual screening is the product of this combination. At present, millions of molecules can be screened out by the virtual screening method every day. For each specific target structure, we can get the active compounds in short time. The research object is focused on hundreds of compounds from millions compounds, which can greatly improve the speed and efficiency of the compounds screening and shorten the cycle of new drug research. However, the increasing amount of data makes ordinary computer algorithm unable to maintain a high level, so the machine learning method has gradually entered the view of the scientists due to its reliable and fast performance.</p><p>The combination of machine learning and virtual screening has become a hotspot in the field of chemical information and embodies its value in the process of drug discovery, such as searching inhibitors [<xref rid="B3" ref-type="bibr">3</xref>], finding novel search chemotypes [<xref rid="B4" ref-type="bibr">4</xref>], and predicting protein structures [<xref rid="B5" ref-type="bibr">5</xref>]. The number of crystal structures of complex for training is crucial in the method of the combination of virtual screening and machine learning. Relative to the small number of training sets, a larger and more diverse training set can train a more powerful learning mode. However, the crystal structures which can be used for virtual screening always come from X-ray crystal diffraction or the means of NMR [<xref rid="B6" ref-type="bibr">6</xref>]. Although the structure is accurate, the high funding and the period limit the speed of resolution, which cannot meet the needs of the virtual screening experiment. So in order to expand the size of the training set, some docking poses of the known active compounds will be added to the training set. Because the docking poses are supposed to include incorrect binding modes, large amounts of negative samples are introduced. The accumulation of the negative samples is possible for producing the imbalanced data set, which is a common phenomenon and of great value in the studies on bioinformatics.</p><p>On the prediction of DNA-binding proteins, Song et al. propose an ensemble learning algorithm imDC according to the analysis on unbalanced DNA-binding protein data, which has outperformed classic classification models like SVM under the same situation [<xref rid="B7" ref-type="bibr">7</xref>]. Based on the ensemble learning framework, Zou et al. give a new predictor to improve the performance of tRNAscan-SE Annotation, and the experimental results show their algorithm can distinguish functional tRNAs from pseudo-tRNAs [<xref rid="B8" ref-type="bibr">8</xref>]. Lin et al. propose merging <italic>K</italic>-means, static selective strategy, and ensemble forward sequential selection on the ensemble learning architecture for hierarchical classification of protein folds with the accuracy reaching 74.21%, which is the state-of-the-art strategy at present [<xref rid="B9" ref-type="bibr">9</xref>]. Zou et al. combine the synthetic minority oversampling and <italic>K</italic>-means clustering undersampling to tackle the negative influence brought by imbalanced data sets [<xref rid="B10" ref-type="bibr">10</xref>].</p><p>Obviously, it is common for bioinformatics studies to face the imbalance data sets. The widely utilized strategies include preprocessing training samples and improving classifiers at present. In this paper, we start from the perspective of improving machine learning algorithm, introducing the ensemble learning method on the basis of simple SVM classifier, using layered combination and iterative weight to enhance the performance of the classifier, so as to reduce the impact of the quality of the sample set. Meanwhile, this paper introduces Random Forest as the experimental baseline to examine the effect of ensemble learning on virtual screening.</p></sec><sec id="sec2"><title>2. The Quantitative Method</title><p>With the rapid development of combinatorial chemistry, bioinformatics, molecular biology, and computer science, the computer aided drug design (CADD) is widely used. Virtual screening as one of the most widely used methods in the CADD, because of its quick and low cost, has been gradually replaced by the high-throughput screening as the main mean of drug screening [<xref rid="B11" ref-type="bibr">11</xref>]. In this paper, we will use the virtual screening method to screen the drug protein.</p><sec id="sec2.1"><title>2.1. General Process of Virtual Screening</title><p>Virtual screening is also known as a computer screen, which is a prescreening of compound molecules on the computer to reduce the number of actual screening compounds and to improve the efficiency of the discovery of lead compounds. The workflow of virtual screening process is shown in <xref ref-type="fig" rid="fig1">Figure 1</xref>.</p><p>Virtual screening includes four steps: the establishment of the receptor model; the generation of small molecule libraries; the computer screening; the postprocessing of hit compounds.</p><p>
<statement id="step1"><title>Step 1 (the establishment of the receptor model). </title><p>(1) Obtaining macromolecular structure: preparation of protein structure is an important step in the virtual screening. The crystal structures which will be used in the virtual screening can be directly obtained from the PDB or modeling the sequence and structure information of the homologous protein.</p><p>(2) Binding site description: the choice of the appropriate ligand binding pocket is very important in molecular docking. There are two ways to choose: (1) we take from the ligand-receptor complex structure directly. (2) If there is no complex structure, we need to manually choose the binding sites according to the experiment information of biological functions such as mutation and combination.</p></statement>
</p><p>
<statement id="step2"><title>Step 2 (the generation of small molecule libraries). </title><p>We can use conversion program to translate the two-dimensional structure to three-dimensional structure. The obtained 3D structures can be used for docking process after adding the hydrogen atoms and charges.</p></statement>
</p><p>
<statement id="step3"><title>Step 3 (docking and scoring). </title><p>Docking operation is putting every small molecule on ligand binding sites of receptor protein, optimizing the conformation and location of ligand, and making sure of the best combination. To score the best conformation and to rank all compounds according to the scoring, then pick out the small molecules with the highest score from compound library. Docking algorithm aims to predict complex conformation generated by the receptor and the ligand. The purpose of the scoring function is choosing the conformation from candidate set of conformations according to the score. The scoring function will get a lower score if the docking result is more close to the natural compound. However, there is no completely correct scoring function. So far, all kinds of scoring functions used in the existing various docking algorithms are only an approximation to the correct scoring function.</p></statement>
</p><p>
<statement id="step4"><title>Step 4 (postprocessing of hit compounds). </title><p>If only use of the sample-scoring model will lead to a huge difference in the final results and sometimes lead to wrong judgment, final results must be analyzed from multiple perspectives and postprocessing. The purpose of this analysis and postprocessing is as accurate as possible to assess protein-ligand binding free energies. The generated complex candidate set is classified, and the error results are distinguished.</p></statement>
</p><p>As the accuracy of the scoring function in virtual screening has not been properly resolved, in this paper, we use the protein-ligand interaction fingerprint (IFP) to deal with the interactions between target proteins and ligands. The IFP encode the observed interactions between ligand and protein into a binary string of fixed length [<xref rid="B12" ref-type="bibr">12</xref>]. The IFP method was originally designed for analyzing ligand docking poses to protein kinases. Based on this method, the atom-based IFP concept was put forward and extended. Each kind of IFP has its own characteristics, whether it is residue-based IFP or atom-based IFP. One-dimensional interaction fingerprint is more likely to be generated and compared with the 3D structure of protein ligand, and it is more suitable for computer aided drug design [<xref rid="B13" ref-type="bibr">13</xref>].</p></sec><sec id="sec2.2"><title>2.2. The Concept and Calculation Process of Pharm-IF</title><p>In this paper, we use a kind of atomic-based fingerprint&#x02014;Pharm-IF as an aid to verify the theory in this paper. The concept of Pharm-IF is put forward by Sato et al. [<xref rid="B14" ref-type="bibr">14</xref>]. The Pharm-IF is calculated from the distances of pairs of ligand pharmacophore features that interact with protein atoms and it can detect important geometrical patterns of ligand pharmacophore.</p><p>The calculation of Pharm-IF can be divided into the following three steps as <xref ref-type="fig" rid="fig2">Figure 2</xref> shows.</p><p>
<statement id="step10"><title>Step 1 . </title><p>To detect the protein-ligand interactions from complex structures, interactions can be classified into six types: (1) hydrogen bond with ligand acceptor; (2) hydrogen bond with ligand donor; (3) hydrogen bond in which the roles of ligand and protein atoms could not be determined; (4) ionic interaction with ligand cation; (5) ionic interaction with ligand anion; (6) hydrophobic interaction.</p></statement>
</p><p>
<statement id="step20"><title>Step 2 . </title><p>To create all possible interaction pairs, each interaction pair is characterized by the pharmacophore features of the ligand atoms and their distance. To calculate the resulting matrix, each interaction pair is assigned to the corresponding bin. In an interaction pair of two hydrogen bonds, ligand atoms will be assigned to the vector corresponding to this hydrogen bond pair if ligand atoms are a donor and an acceptor that are 4.3&#x02009;&#x000c5; apart from each other. For example, in order to describe the distance of 4.3&#x02009;&#x000c5; in the interaction, 0.7 is assigned to the bin of 4&#x02009;&#x000c5; and 0.3 is assigned to the bin of 5&#x02009;&#x000c5;.</p></statement>
</p><p>
<statement id="step30"><title>Step 3 . </title><p>The result matrix is calculated by the summation of the values of all of the interaction pairs. The formula of Pharm-IF calculation is as follows:<disp-formula id="EEq1"><label>(1)</label><mml:math id="M1"><mml:mtable style="T17"><mml:mtr><mml:mtd><mml:maligngroup/><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:malignmark/><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mstyle displaystyle="true"><mml:mo stretchy="false">&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:mspace height="6.57999pt" depth="0.12pt"/><mml:mi>i</mml:mi><mml:mspace height="6.57999pt" depth="0.12pt"/></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:maligngroup/><mml:malignmark/></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
<disp-formula id="EEq2"><label>(2)</label><mml:math id="EEq2EAAAAAABBDCA"><mml:mtable><mml:mtr><mml:mtd><mml:maligngroup/><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:mspace height="6.57999pt" depth="0.12pt"/><mml:mi>i</mml:mi><mml:mspace height="6.57999pt" depth="0.12pt"/></mml:mrow></mml:mfenced><mml:malignmark/><mml:mo>=</mml:mo><mml:mfenced open="{" close="" separators="|"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mn mathvariant="normal">0</mml:mn><mml:mo>,</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mtext>if&#x02009;&#x02009;</mml:mtext><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>&#x02265;</mml:mo><mml:mn mathvariant="normal">1</mml:mn><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mn mathvariant="normal">1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mtext>otherwise</mml:mtext><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:maligngroup/><mml:malignmark/></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p></statement>
</p><p>In formula (<xref ref-type="disp-formula" rid="EEq1">1</xref>), <italic>H</italic> stands for the interaction fingerprint of a protein-ligand complex by Pharm-IF. <italic>t</italic> is the pair of six types of pharmacophore features. <italic>k</italic> = 1,2, 3,&#x02026; stands for the corresponding bins of the distances (&#x000c5;) between ligand atoms. <italic>I</italic>
<sub><italic>t</italic></sub> represents the fact that the whole set of the interactions are classified as type <italic>t</italic>, and <italic>i</italic> represents an element in <italic>I</italic>
<sub><italic>t</italic></sub>. In formula (<xref ref-type="disp-formula" rid="EEq2">2</xref>), <italic>d</italic>
<sub><italic>i</italic></sub> represents the distances between ligand atoms of <italic>i</italic> (&#x000c5;).</p></sec><sec id="sec2.3"><title>2.3. Cathepsin K and SRC</title><p>This paper selects Cathepsin K and SRC as the target for screening. These two kinds of proteins are the hotspot in the field of pharmaceutical drug targets and both of them do not have enough experimentally determined protein-ligand complex structures for virtual screening. Therefore, it is necessary to add some docking poses in the training set and these docking poses will influence the virtual screening efficiency.</p><p>Protooncogene tyrosine-protein kinase SRC, also known as protooncogene c-Src or simply c-Src, is a nonreceptor tyrosine kinase protein that in humans is encoded by the SRC gene. The SRC family kinase is made up of 9 members: LYN, FYN, LCK, HCK, FGR, BLK, YRK, YES, and c-SRC. The SRC widely exists in tissue cells and it plays an important role in the process of cell metabolism, regulation of cell growth, development, and differentiation process by interacting with the important molecules in the signal transduction pathways. The c-Src is made up of 6 functional regions: SRC homology 4 (SH4) domain (SH4 domain), unique region, SH3 domain, SH2 domain, catalytic domain, and short regulatory tail. When SRC is inactive, that will cause intermolecular interactions between the phosphorylation TYR527 (tyrosine group 527) and SH2 domain. At the same time, the SH3 domain will combine with the proline-rich SH2 kinase link domain. When Tyr527 is dephosphorylated and Tyr416 is phosphorated, links between these molecules will break, and the SRC protein is activated. The SRC causes a series of biological effects by participating in many signal transduction pathways through a variety of receptors and this kind of protein is closely associated with a variety of cancers. The activation of the c-Src pathway has been observed in about 50% of tumors from colon, liver, lung, breast, and the pancreas. As a drug target, a number of tyrosine kinase inhibitors treating c-Src tyrosine kinase (as well as related tyrosine kinases) as target have been developed and put into use [<xref rid="B15" ref-type="bibr">15</xref>].</p><p>Cathepsin K is a lysosomal cysteine protease belonging to the papain superfamily and it has been cloned in 1999. The gene location is lq21.2, the length of the transcript is 1.7&#x02009;kb, and it consisted of 8 extrons and 7 introns. The protein expression is in the osteoclasts and included in the bone resorption. In the process of bone resorption, the acid will dissolve the hydroxyapatite and the organic ingredients in the bone matrix will be separated and degraded by Cathepsin K. Cathepsin K has strong activity of collagenase in acid environment and it has been found that it plays a role in a variety of pathological phenomena at present such as rheumatoid arthritis, tumor invasion and metastasis, inflammation, and osteoporosis. The function of Cathepsin K in osteoclast has been recognized; therefore, many labs treat their inhibitors as a drug target for the treatment of osteoporosis. At present, the first choice of antiabsorption treatment is bisphosphonates, which can reduce the risk of nonvertebral and vertebral fractures. However, the long-term using of bisphosphonates may produce adverse reactions: esophageal stimulus symptoms, hypocalcaemia, kidney irritation, and so on. In addition, bisphosphonates not only prevent bone loss but also inhibit bone formation at the same time, so the new replacement therapy drugs are more meaningful [<xref rid="B16" ref-type="bibr">16</xref>].</p></sec></sec><sec id="sec3"><title>3. Classification Algorithm Based on the Adaboost-SVM</title><p>Currently, SVM can deal with many problems, such as small size of samples, nonlinearity, or high dimensions. Based on the statistical learning theory, it has a simple mathematical form, fast training method, and good generalization performance. It has been widely used in data mining problems such as pattern recognition, function estimation, and time series prediction. Under the condition that the quality of sample set is not very low, even if we do not make any improvements, we can get a good result. The learning mechanism of SVM provides a lot of space to improve the classification model. In addition, one major advantage of SVM is using of convex quadratic programming, which provides only global minima and hence avoids being trapped in local minima, so in this paper we use SVM as the base classifier. There have been a large number of literatures about the SVM; this paper only gives a simple introduction. The basic process of SVM classification problems is as follows.</p><p>For a given sample set <italic>L</italic> = {(<italic>x</italic>
<sub>1</sub>, <italic>y</italic>
<sub>1</sub>), (<italic>x</italic>
<sub>2</sub>, <italic>y</italic>
<sub>2</sub>),&#x02026;, (<italic>x</italic>
<sub><italic>n</italic></sub>, <italic>y</italic>
<sub><italic>n</italic></sub>)} and <italic>x</italic>
<sub><italic>i</italic></sub> &#x02208; <italic>R</italic>
<sup><italic>d</italic></sup>&#x02009;&#x02009;
<italic>y</italic>
<sub><italic>i</italic></sub> &#x02208; {1, &#x02212;1}, <italic>i</italic> = 1,2,&#x02026;, <italic>n</italic>, <italic>y</italic>
<sub><italic>i</italic></sub> stands for the categories of sample <italic>x</italic>
<sub><italic>i</italic></sub>, <italic>d</italic> is the sample number, and <italic>n</italic> is the training sample number. If the input vector set is linearly separable, then the input vector set can be separated by a hyperplane. The hyperplane can be expressed as<disp-formula id="EEq3"><label>(3)</label><mml:math id="M2"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:mi>w</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>x</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">0</mml:mn><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p><p>
<italic>w</italic> is the normal vector of the hyperplane and <italic>b</italic> is offset. The SVM learning problem is minimizing the objective function:<disp-formula id="EEq4"><label>(4)</label><mml:math id="M3"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:mrow><mml:mrow><mml:mi mathvariant="normal">min</mml:mi></mml:mrow><mml:mo>&#x02061;</mml:mo><mml:mrow><mml:mi>&#x003d5;</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:mspace height="4.53pt" depth="0.12pt"/><mml:mi>w</mml:mi><mml:mspace height="4.53pt" depth="0.12pt"/></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mn mathvariant="normal">2</mml:mn></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mfenced open="&#x02016;" close="&#x02016;" separators="|"><mml:mrow><mml:mspace height="4.53pt" depth="0.12pt"/><mml:mi>w</mml:mi><mml:mspace height="4.53pt" depth="0.12pt"/></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn mathvariant="normal">2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mspace height="15.60695pt" depth="11.644pt"/><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo stretchy="false">&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003be;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mspace height="15.60695pt" depth="11.644pt"/></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p><p>This meets the condition<disp-formula id="EEq5"><label>(5)</label><mml:math id="M4"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mspace height="7.08pt" depth="2.484pt"/><mml:mi>w</mml:mi><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mspace height="7.08pt" depth="2.484pt"/></mml:mrow></mml:mfenced><mml:mo>&#x02265;</mml:mo><mml:mn mathvariant="normal">1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003be;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="10pt"/><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1,2</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p><p>Here, (1/2)&#x02016;<italic>w</italic>&#x02016;<sup>2</sup> is structure complexity, <italic>C</italic>(&#x02211;<sub><italic>i</italic>=1</sub>
<sup><italic>n</italic></sup>
<italic>&#x003be;</italic>
<sub><italic>i</italic></sub>) stands for empirical risk, and <italic>&#x003be;</italic>
<sub><italic>i</italic></sub> presents the slack variable. <italic>H</italic> is a constant which is punishment factor of samples wrongly classified. For the situation of linear inseparable the main idea of SVM is used to map the feature vector to the high dimensional feature space and constructs an optimal hyperplane in the feature space.</p><p>To get the change of <italic>&#x003d5;</italic>, <italic>x</italic> in space of <italic>R</italic>
<sup><italic>n</italic></sup> mapped into <italic>H</italic>:<disp-formula id="EEq6"><label>(6)</label><mml:math id="M5"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:mi>x</mml:mi><mml:mo>&#x027f6;</mml:mo><mml:mi>&#x003d5;</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:mspace height="4.53pt" depth="0.12pt"/><mml:mi>x</mml:mi><mml:mspace height="4.53pt" depth="0.12pt"/></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mspace height="6.93999pt" depth="2.59pt"/><mml:msub><mml:mrow><mml:mi>&#x003d5;</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="normal">1</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mspace height="4.53pt" depth="0.12pt"/><mml:mi>x</mml:mi><mml:mspace height="4.53pt" depth="0.12pt"/></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003d5;</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="normal">2</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mspace height="4.53pt" depth="0.12pt"/><mml:mi>x</mml:mi><mml:mspace height="4.53pt" depth="0.12pt"/></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003d5;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mspace height="4.53pt" depth="0.12pt"/><mml:mi>x</mml:mi><mml:mspace height="4.53pt" depth="0.12pt"/></mml:mrow></mml:mfenced><mml:mspace height="6.93999pt" depth="2.59pt"/></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>&#x003a4;</mml:mi></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p><p>Eventually we can decide optimization classification function:<disp-formula id="EEq7"><label>(7)</label><mml:math id="M6"><mml:mtable style="T6"><mml:mtr><mml:mtd><mml:maligngroup/><mml:mi>f</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mspace height="4.53pt" depth="0.12pt"/><mml:mi>x</mml:mi><mml:mspace height="4.53pt" depth="0.12pt"/></mml:mrow></mml:mfenced><mml:malignmark/><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sgn</mml:mi></mml:mrow><mml:mo>&#x02061;</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mspace height="7.08pt" depth="2.59pt"/><mml:mi>w</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>&#x003d5;</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mspace height="4.53pt" depth="0.12pt"/><mml:mi>x</mml:mi><mml:mspace height="4.53pt" depth="0.12pt"/></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mspace height="7.08pt" depth="2.59pt"/></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:maligngroup/><mml:malignmark/><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sgn</mml:mi></mml:mrow><mml:mo>&#x02061;</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mspace height="15.60695pt" depth="11.644pt"/><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo stretchy="false">&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>&#x003d5;</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mspace height="4.53pt" depth="2.484pt"/><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace height="4.53pt" depth="2.484pt"/></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>&#x000b7;</mml:mo><mml:mi>&#x003d5;</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mspace height="4.53pt" depth="0.12pt"/><mml:mi>x</mml:mi><mml:mspace height="4.53pt" depth="0.12pt"/></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mspace height="15.60695pt" depth="11.644pt"/></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p><p>In our work, Radial Basis Function (RBF) is taken as the kernel function of SVM, and the mathematical description of this kernel is given below:<disp-formula id="EEq8"><label>(8)</label><mml:math id="M7"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:mi>K</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:mspace height="4.53pt" depth="4.19899pt"/><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace height="4.53pt" depth="4.19899pt"/></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mrow><mml:mfenced open="&#x02016;" close="&#x02016;" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn mathvariant="normal">2</mml:mn></mml:mrow></mml:msup><mml:mo>/</mml:mo><mml:mn mathvariant="normal">2</mml:mn><mml:msup><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="normal">2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p><p>Relative to other classifiers, the SVM is more stable and less affected by the quality of sample set. However, the sample categories imbalance of data set and the high complexity of the data set will destabilize the classifier and the instability of the classifier will directly affect the final classification result. In this paper, we introduce the Adaboost mechanism in ensemble learning to divide one classification process into several layers of weak classifier based on SVM.</p><p>The key of the combination of Adaboost and SVM is to find a suitable Gauss width <italic>&#x003c3;</italic> value for each component. If the <italic>&#x003c3;</italic> value is relatively large, the component classifier is too weak, and the final classification performance is decreased. On the other hand, if the <italic>&#x003c3;</italic> value is relatively small, which makes the component classifier robust, and the error of component classifier is highly correlated, the difference is small, so that the ensemble learning is invalid. Even more importantly, <italic>&#x003c3;</italic> value is too small which will lead to overfitting and resulting in a greatly reduced generalization. Therefore, in this paper, the standard deviation of the sample set of each component classifier is used as the <italic>&#x003c3;</italic> value of the component classifier to control the classification accuracy of the component classifier; thus SVM based Adaboost classifier is obtained. The program used in this paper is not an open source, so we need to explain some key parameters. We list the values of <italic>&#x003c3;</italic>, <italic>C</italic> and other parameters in <xref ref-type="table" rid="tab1">Table 1</xref>.</p><p>The specific process of the algorithm is as follows.<list list-type="simple"><list-item><label>(1)</label><p>RBFSVM presents the SVM with the RBF kernel; <italic>T</italic> presents the number of iterations required in the Adaboost process.</p></list-item><list-item><label>(2)</label><p>Initialization: initialize the weights of each sample: <italic>w</italic>
<sub>1</sub>(<italic>i</italic>) = 1/<italic>n</italic>, <italic>i</italic> = 1,2,&#x02026;, <italic>n</italic>.</p></list-item><list-item><label>(3)</label><p>For <italic>t</italic> = 1,2,&#x02026;, <italic>T</italic>:</p></list-item><list-item><label>&#x02009;</label><p>for each <italic>h</italic>(<italic>x</italic>
<sub><italic>i</italic></sub>), calculate the weighted error:<disp-formula id="EEq9"><label>(9)</label><mml:math id="M8"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b5;</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo stretchy="false">&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:mspace height="9.52998pt" depth="4.43001pt"/><mml:mi>h</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mspace height="6.57999pt" depth="4.19899pt"/><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace height="6.57999pt" depth="4.19899pt"/></mml:mrow></mml:mfenced><mml:mo>&#x02212;</mml:mo><mml:mi>y</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mspace height="6.57999pt" depth="2.59pt"/><mml:mi>j</mml:mi><mml:mspace height="6.57999pt" depth="2.59pt"/></mml:mrow></mml:mfenced><mml:mspace height="9.52998pt" depth="4.43001pt"/></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p></list-item><list-item><label>&#x02009;</label><p>Choose a feature with the lowest weighted error rate <italic>&#x003b5;</italic>
<sub><italic>j</italic></sub> and save its corresponding SVM model. Calculate the selected weak classifier's weight:<disp-formula id="EEq10"><label>(10)</label><mml:math id="M9"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mn mathvariant="normal">2</mml:mn></mml:mrow></mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">ln</mml:mi></mml:mrow><mml:mo>&#x02061;</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mspace height="13.14397pt" depth="9.55399pt"/><mml:mfrac><mml:mrow><mml:mn mathvariant="normal">1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b5;</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b5;</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mspace height="13.14397pt" depth="9.55399pt"/></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p></list-item><list-item><label>&#x02009;</label><p>Update sample weights according to <italic>a</italic>
<sub><italic>t</italic></sub>: <disp-formula id="EEq11"><label>(11)</label><mml:math id="M10"><mml:mtable style="T6"><mml:mtr><mml:mtd><mml:maligngroup/><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:mspace height="6.57999pt" depth="0.12pt"/><mml:mi>i</mml:mi><mml:mspace height="6.57999pt" depth="0.12pt"/></mml:mrow></mml:mfenced><mml:malignmark/><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>F</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:mspace height="6.57999pt" depth="2.484pt"/><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mspace height="6.57999pt" depth="2.484pt"/></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:maligngroup/><mml:malignmark/><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mfenced open="{" close="" separators="|"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mtd><mml:mtd columnalign="left"><mml:mtext>if&#x02009;&#x02009;</mml:mtext><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mtd><mml:mtd columnalign="left"><mml:mtext>if&#x02009;&#x02009;</mml:mtext><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>&#x02260;</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p></list-item><list-item><label>&#x02009;</label><p>And the normalized parameters are<disp-formula id="EEq12"><label>(12)</label><mml:math id="M11"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo stretchy="false">&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:mspace height="6.57999pt" depth="0.12pt"/><mml:mi>i</mml:mi><mml:mspace height="6.57999pt" depth="0.12pt"/></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p></list-item><list-item><label>(4)</label><p>Use strong classifier <italic>H</italic> integrated by SVM weak classifier to training set:<disp-formula id="EEq13"><label>(13)</label><mml:math id="M12"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:mi>H</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:mspace height="4.53pt" depth="0.12pt"/><mml:mi>x</mml:mi><mml:mspace height="4.53pt" depth="0.12pt"/></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sign</mml:mi></mml:mrow><mml:mo>&#x02061;</mml:mo><mml:mrow><mml:mfenced separators="" open="[" close="]"><mml:mrow><mml:mspace height="15.60695pt" depth="11.644pt"/><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo stretchy="false">&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:mspace height="4.53pt" depth="0.12pt"/><mml:mi>x</mml:mi><mml:mspace height="4.53pt" depth="0.12pt"/></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mspace height="15.60695pt" depth="11.644pt"/></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p></list-item></list>
</p><p>For the Adaboost-SVM, we set the parameters in <xref ref-type="table" rid="tab2">Table 2</xref>, and the basic SVM parameters are the same as <xref ref-type="table" rid="tab1">Table 1</xref>.</p><p>Thus compared to the single machine learning algorithm, ensemble learning method requires that each base classifier should be independent from the others. The probability of sample misclassification should be less than 0.5. In the ensemble learning method, all classifiers will work together to solve one problem and this can also reduce the impact of the quality of sample set to the virtual screening effect.</p></sec><sec id="sec4"><title>4. Experiment and Analysis</title><p>In order to verify the validity of the proposed method in this paper, besides the crystal structure of PDB, we also combine the data from the PubChem database and the StARLITe database and the enrichment factor (EF) and the ROC curve are used to evaluate the effect of virtual screening and the machine learning to ensure the effectiveness of the method. PubChem is a database of chemical molecules and their activities against biological assays. StARLITe is a database containing biological activity and/or binding affinity data between various compounds and proteins and it is one of the databases that can be directly used in data mining.</p><p>All the crystal structures used in this experiment are from PDB database; the material is available free of charge via the Internet at <ext-link ext-link-type="uri" xlink:href="http://www.rcsb.org/">http://www.rcsb.org/</ext-link>. All the training set decoys are from PubChem data set; the material is available free of charge via the Internet at <ext-link ext-link-type="uri" xlink:href="http://pubchem.ncbi.nlm.nih.gov/">http://pubchem.ncbi.nlm.nih.gov/</ext-link>. We thank laboratory colleagues for providing the StARLITe data.</p><sec id="sec4.1"><title>4.1. Data Set</title><p>In order to cooperate with machine learning, in this paper, we construct a set of training sets and test sets of these two target proteins for machine learning, which include the decoys and known active compounds. In the training set, we selected the experimentally determined complex structures of these two kinds of proteins from the PDB as the positive samples. The Protein Data Bank (PDB) is a crystallographic database for the three-dimensional structural data of large biological molecules. The data in the PDB is submitted by biologists and biochemists around the world by the experimental means such as X-ray crystallography, NMR spectroscopy, or, increasingly, cryoelectron microscopy. To expand the training set, we randomly and respectively selected 1, 3, 5, 10, 20, 40, 60, and 80 active compounds from the known active compounds for which crystal structures with their targets were not determined and this process is repeated 10 times. For each of the selected compounds, we used the GLIDE to generate five docking poses and mixed them into the training set. Among them, the crystal structures of these two proteins used in docking experiments are selected from the PDB with protein-inhibitor compounds with high inhibitor activity and high resolution crystal structure. The entry 2h8h, SRC kinase in complex with a quinazoline inhibitor, the resolution 2.30&#x02009;&#x000c5;, was selected for SRC. The entry 1u9w, crystal structure of the cysteine protease human Cathepsin K in complex with the covalent inhibitor NVP-ABI491, the resolution 2.20&#x02009;&#x000c5;, was selected for Cathepsin K. We used the SP mode of GLIDE to generate the docking poses of the decoys and the active compounds for which crystal structures were not experimentally determined. For the preparation of the docking, we use the Protein Preparation Wizard to add the hydrogen atoms of the protein and optimize their positions. Using Pipeline Pilot of SciTegic to enumerate the tautomer, stereoisomers and protonation/deprotonation form at pH 7.4 of the active and decoy compounds. Then, the additional ring conformations of the compounds were generated by LigPrep. Then the GLIDE score was used to select five poses for each compound in the docking results. In this paper, five docking poses of each active compound as the positive examples were chosen by the GLIDE score because this procedure would generate higher enrichment factors in a preliminary test than using one pose of each active compound. Other settings of GLIDE were set to the default values. In this paper, we use the averages of the 10% EF and the ROC score of the 10 trials to evaluate the screening efficiencies of the learning models using each number of docking poses. Then, select the docking poses of 2000 decoy compounds from them as the negative samples, randomly. Each decoy compound was docked to the target proteins by the same way as mentioned above.</p><p>After the completion of the training set, we set out to build the test set. First, choose the active compounds of the target proteins (IC<sub>50</sub> &#x02264; 10&#x02009;<italic>&#x003bc;</italic>m) from StARLITe and divide them into 100 clusters. Dividing strategy is that hierarchical clustering with Ward method based on the Euclidean distance between their 2D structure fingerprints. The compound with the highest inhibitory activity was selected from each cluster. Dock the 100 active compounds obtained for each target to their target protein and five docking poses for each active compound were used as positive samples of the test set. The docking way and target protein crystal structures are same as those mentioned above. Then, use selection strategy of negative sample of the training set to choose the decoys for the test set.</p><p>After the completion of the date preparation, we will use the Pharm-IF to quantify the training set. Then, treat the data as the input of machine learning algorithms to get the corresponding learning model. The learning model obtained will be used to test set, respectively.</p><p>From <xref ref-type="table" rid="tab3">Table 3</xref>, it can be seen that the proportion of negative samples and positive samples is up to 20&#x02009;:&#x02009;1, which leads to significant imbalanced-data problem, and the motivation of our work is to address this issue.</p></sec><sec id="sec4.2"><title>4.2. The Evaluation Index of the Machine Learning Combined with Virtual Screening</title><p>At present, the virtual screening and machine learning have their own evaluation index [<xref rid="B17" ref-type="bibr">17</xref>]. The enrichment factor (EF) is one of the most famous measures for evaluating the screening efficiency. EF is usually used to evaluate the early recognition properties of screening method and it can indicate the ratio of the number of obtained active compounds by in silico screening against that generated by random selection at the predefined sampling percentage. The calculation method of EF is as follows:<disp-formula id="EEq14"><label>(14)</label><mml:math id="M13"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:mtext>EF</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mtext>Hits</mml:mtext></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mtext>Hit</mml:mtext></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p><p>Here, Hits<sub><italic>s</italic></sub> represents the number of active compounds in the sample, Hit<sub><italic>t</italic></sub> is the number of active compounds tested, <italic>N</italic>
<sub><italic>s</italic></sub> is the number of compounds sampled, and <italic>N</italic>
<sub><italic>t</italic></sub> is the number of all compounds. In the actual drug discovery, only a small part of the compound is filtered by computer. In general, 0.01&#x02013;1% of the compounds will be selected from a huge compound database (10000&#x02013;1000000 compounds) in the actual virtual screening process. Since the number of test sets in this experiment is far from reaching this order of magnitude, we use 10% EF to carry out this test in order to reduce the deviation of the early evaluation. EF has only specific sampling proportion screening efficiency; therefore this paper also introduced the ROC curve and AUC value to assess the entire range of sampling (0&#x02013;100%). The ROC curve (receiver operating characteristic curve) is a graphical method to show the tradeoff between false positive rate and true positive rate of classifier. As shown in <xref ref-type="fig" rid="fig3">Figure 3</xref>, in ROC curve, the true positive rate (TPR) is plotted along the <italic>y</italic>-axis, while the false positive rate (FPR) is displayed on the <italic>x</italic>-axis. Although the ROC curve can directly reflect the effect of the machine learning model, we also need a kind of numerical method, the AUC (area under ROC curve) value, to evaluate the effect of the model in the practical application. The AUC value indicates the area under the ROC curve and it is more intuitive and accurate. The calculation method of AUC value is as follows:<disp-formula id="EEq15"><label>(15)</label><mml:math id="M14"><mml:mtable style="T1"><mml:mtr><mml:mtd><mml:mtext>AUC</mml:mtext><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo stretchy="false">&#x0222b;</mml:mo></mml:mstyle><mml:mrow><mml:mn mathvariant="normal">0</mml:mn></mml:mrow><mml:mrow><mml:mn mathvariant="normal">1</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:mfrac><mml:mrow><mml:mtext>TP</mml:mtext></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:mfrac><mml:mi>d</mml:mi><mml:mfrac><mml:mrow><mml:mtext>FP</mml:mtext></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn mathvariant="normal">1</mml:mn></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo stretchy="false">&#x0222b;</mml:mo></mml:mstyle><mml:mrow><mml:mn mathvariant="normal">0</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mtext>TP</mml:mtext><mml:mi>&#x02009;</mml:mi><mml:mi>d</mml:mi><mml:mi>&#x02009;</mml:mi><mml:mtext>FP</mml:mtext></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p><p>Among all the variables of formula (<xref ref-type="disp-formula" rid="EEq15">15</xref>), <italic>P</italic> stands for the positive samples, <italic>N</italic> represents the negative samples, TP (true positive) stands for the active compounds that are classified correctly, and FP (false positive) stands for the misclassification of active compounds.</p><p>AUC values are between 0.5 and 1.0; if the model is perfect, the AUC value is 1; if the model is only a random guess, the AUC value is 0.5. If a model is better than another, AUC value of the better one is higher. ROC curves and AUC are not affected by imbalance distribution of data class and normal distribution of the data. In addition, the AUC value allows a middle state and experimental results can be divided into multiple ordered classification.</p></sec><sec id="sec4.3"><title>4.3. The Analysis of Experimental Results</title><p>According to the experiment, we used three different classification methods (SVM, Adaboost-SVM, and RF) to compare the two kinds of target proteins for virtual screening experiment. As the baseline algorithm, RF is also developed based on the machine learning libs of the authors' lab, and the parameters of RF are set in <xref ref-type="table" rid="tab4">Table 4</xref>.</p><p>The ROC curves from the comparative experiments on these two kinds of data sets using ensemble learning (compared with SVM) are as those in Figures <xref ref-type="fig" rid="fig4">4</xref> and <xref ref-type="fig" rid="fig5">5</xref>.</p><p>
<xref ref-type="table" rid="tab5">Table 5</xref> shows the 10% EF of the two methods and calculates the AUC value.</p><p>Aiming at the problem of sample set quality, the Adaboost method gives the same weight value to each training data; the sample weight represents the probability of the data treated as the training set by a weak classifier. At each iteration, the Adaboost algorithm will modify the weight value of the sample; if the training sample is correctly classified in this iteration, the weight value of the sample will be reduced; that is, the probability of being treated as the training sample is reduced in the next iteration. On the contrary, if the training sample is misclassified in the current base classifier, the weight value of the sample will be increased, and the probability of being treated as the training sample will be increased in the next iteration. In this way, the weak classifier will pay more attention to the serious misclassification of training set. The experimental results above show that Adaboost-SVM has notably outperformed RF. This observation indicates that on both 10% EF and AUC ensemble learning based virtual screening has shown its ability of noise resistance, under the situation that the amount of structure samples is limited; thus the better screening results are obtained.</p></sec></sec><sec id="sec5"><title>5. Conclusion</title><p>In this paper, we use ensemble learning method to solve the problem caused by the quality of the training set. This method mainly uses Pharm-IF to encode protein-ligand interactions as a binary form and then uses the improved SVM algorithm, Adaboost-SVM, and Random Forest to classify the data. The idea of ensemble learning in dealing with data classification problem is to get a number of weak classifiers which are independent of each other and then use an effective method to combine these independent weak classifiers. By comparing the experimental results, after the Adaboost-SVM is used as the classifier, 10% EF for the SRC model increased from 4.7 to 5.5, and the AUC value increased from 0.734 to 0.821, 10% EF of Cathepsin K model increased from 3.9 to 4.8, and the AUC value increased from 0.683 to 0.802. It can be observed from the results that, comparing with the na&#x000ef;ve SVM, Random Forest has obtained better performance on both 10% EF and AUC: 10% EF is improved to 5.3 and 4.5 on SRC and Cathepsin K, respectively, and AUC is improved to 0.805 and 0.783, respectively. As a classic ensemble learning algorithm, Random Forest has shown that ensemble learning is able to get better results on the imbalanced data set with satisfying robustness. Nevertheless, the performance of Random Forest is lower than Adaboost-SVM, and we will continue investigating the reasons in our future work. Compared with the traditional method, the proposed method is more significant for the improvement of the accuracy of the virtual screening model. In the future work, the problem of improving the accuracy of virtual screening should be further studied from two aspects: virtual screening theory and computer theory. Although the status of virtual screening is gradually increasing, the problem of virtual screening false positive rate is still to be solved. The speed of laboratory determination of protein structure has been unable to catch up with the needs of drug development, therefore, in the virtual screening it will often encounter problems similar to this paper, so there are still many improvements in the algorithm. For example, the selection of kernel function will directly affect the performance of the classifier. In view of the problem of this kind of data set, we should set up a special kernel function to adapt to the characteristics of the data set.</p></sec></body><back><ack><title>Acknowledgments</title><p>This paper is partially supported by Natural Science Foundation of Heilongjiang Province (QC2013C060), Science Funds for the Young Innovative Talents of HUST (no. 201304), China Postdoctoral Science Foundation (2011M500682), and Postdoctoral Science Foundation of Heilongjiang Province (LBH-Z11106).</p></ack><sec><title>Competing Interests</title><p>The authors declare that they have no competing interests.</p></sec><ref-list><ref id="B1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanaka</surname><given-names>K.</given-names></name><name><surname>Aoki-Kinoshita</surname><given-names>K. F.</given-names></name><name><surname>Kotera</surname><given-names>M.</given-names></name><etal/></person-group><article-title>WURCS: the Web3 unique representation of carbohydrate structures</article-title><source><italic>Journal of Chemical Information and Modeling</italic></source><year>2014</year><volume>54</volume><issue>6</issue><fpage>1558</fpage><lpage>1566</lpage><pub-id pub-id-type="doi">10.1021/ci400571e</pub-id><pub-id pub-id-type="other">2-s2.0-84903289596</pub-id><pub-id pub-id-type="pmid">24897372</pub-id></element-citation></ref><ref id="B2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seuss</surname><given-names>S.</given-names></name><name><surname>Boccaccini</surname><given-names>A. R.</given-names></name></person-group><article-title>Electrophoretic deposition of biological macromolecules, drugs, and cells</article-title><source><italic>Biomacromolecules</italic></source><year>2013</year><volume>14</volume><issue>10</issue><fpage>3355</fpage><lpage>3369</lpage><pub-id pub-id-type="doi">10.1021/bm401021b</pub-id><pub-id pub-id-type="other">2-s2.0-84885670414</pub-id><pub-id pub-id-type="pmid">24001091</pub-id></element-citation></ref><ref id="B3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liew</surname><given-names>C. Y.</given-names></name><name><surname>Ma</surname><given-names>X. H.</given-names></name><name><surname>Liu</surname><given-names>X.</given-names></name><name><surname>Yap</surname><given-names>C. W.</given-names></name></person-group><article-title>SVM model for virtual screening of Lck inhibitors</article-title><source><italic>Journal of Chemical Information and Modeling</italic></source><year>2009</year><volume>49</volume><issue>4</issue><fpage>877</fpage><lpage>885</lpage><pub-id pub-id-type="doi">10.1021/ci800387z</pub-id><pub-id pub-id-type="other">2-s2.0-66149099982</pub-id><pub-id pub-id-type="pmid">19267483</pub-id></element-citation></ref><ref id="B4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kurczyk</surname><given-names>A.</given-names></name><name><surname>Warszycki</surname><given-names>D.</given-names></name><name><surname>Musiol</surname><given-names>R.</given-names></name><name><surname>Kafel</surname><given-names>R.</given-names></name><name><surname>Bojarski</surname><given-names>A. J.</given-names></name><name><surname>Polanski</surname><given-names>J.</given-names></name></person-group><article-title>Ligand-based virtual screening in a search for novel anti-HIV-1 chemotypes</article-title><source><italic>Journal of Chemical Information and Modeling</italic></source><year>2015</year><volume>55</volume><issue>10</issue><fpage>2168</fpage><lpage>2177</lpage><pub-id pub-id-type="doi">10.1021/acs.jcim.5b00295</pub-id><pub-id pub-id-type="other">2-s2.0-84945535619</pub-id><pub-id pub-id-type="pmid">26431196</pub-id></element-citation></ref><ref id="B5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bilsland</surname><given-names>A. E.</given-names></name><name><surname>Pugliese</surname><given-names>A.</given-names></name><name><surname>Liu</surname><given-names>Y.</given-names></name><etal/></person-group><article-title>Identification of a selective G1-phase benzimidazolone inhibitor by a senescence-targeted virtual screen using artificial neural networks</article-title><source><italic>Neoplasia</italic></source><year>2015</year><volume>17</volume><issue>9</issue><fpage>704</fpage><lpage>715</lpage><pub-id pub-id-type="doi">10.1016/j.neo.2015.08.009</pub-id><pub-id pub-id-type="pmid">26476078</pub-id></element-citation></ref><ref id="B6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wallentin</surname><given-names>J.</given-names></name><name><surname>Osterhoff</surname><given-names>M.</given-names></name><name><surname>Wilke</surname><given-names>R. N.</given-names></name><etal/></person-group><article-title>Hard X-ray detection using a single 100&#x02009;nm diameter nanowire</article-title><source><italic>Nano Letters</italic></source><year>2014</year><volume>14</volume><issue>12</issue><fpage>7071</fpage><lpage>7076</lpage><pub-id pub-id-type="doi">10.1021/nl5040545</pub-id><pub-id pub-id-type="other">2-s2.0-84916624101</pub-id><pub-id pub-id-type="pmid">25419623</pub-id></element-citation></ref><ref id="B7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>L.</given-names></name><name><surname>Li</surname><given-names>D.</given-names></name><name><surname>Zeng</surname><given-names>X.</given-names></name><name><surname>Wu</surname><given-names>Y.</given-names></name><name><surname>Guo</surname><given-names>L.</given-names></name><name><surname>Zou</surname><given-names>Q.</given-names></name></person-group><article-title>nDNA-prot: identification of DNA-binding proteins based on unbalanced classification</article-title><source><italic>BMC Bioinformatics</italic></source><year>2014</year><volume>15</volume><issue>1, article 298</issue><fpage>10</fpage><pub-id pub-id-type="doi">10.1186/1471-2105-15-298</pub-id><pub-id pub-id-type="other">2-s2.0-84907013321</pub-id><pub-id pub-id-type="pmid">24423111</pub-id></element-citation></ref><ref id="B8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zou</surname><given-names>Q.</given-names></name><name><surname>Guo</surname><given-names>J. S.</given-names></name><name><surname>Ju</surname><given-names>Y.</given-names></name><name><surname>Wu</surname><given-names>M. H.</given-names></name><name><surname>Zeng</surname><given-names>X. X.</given-names></name><name><surname>Hong</surname><given-names>Z. L.</given-names></name></person-group><article-title>Improving tRNAscan-SE annotation results via ensemble classifiers</article-title><source><italic>Molecular Informatics</italic></source><year>2015</year><volume>34</volume><fpage>761</fpage><lpage>770</lpage><pub-id pub-id-type="doi">10.1002/minf.201500031</pub-id><pub-id pub-id-type="other">2-s2.0-84941584548</pub-id><pub-id pub-id-type="pmid">27491037</pub-id></element-citation></ref><ref id="B9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>C.</given-names></name><name><surname>Zou</surname><given-names>Y.</given-names></name><name><surname>Qin</surname><given-names>J.</given-names></name><etal/></person-group><article-title>Hierarchical classification of protein folds using a novel ensemble classifier</article-title><source><italic>PLoS ONE</italic></source><year>2013</year><volume>8</volume><issue>2</issue><pub-id pub-id-type="publisher-id">e56499</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0056499</pub-id><pub-id pub-id-type="other">2-s2.0-84874240374</pub-id></element-citation></ref><ref id="B10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zou</surname><given-names>Q.</given-names></name><name><surname>Wang</surname><given-names>Z.</given-names></name><name><surname>Guan</surname><given-names>X.</given-names></name><etal/></person-group><article-title>An approach for identifying cytokines based on a novel ensemble classifier</article-title><source><italic>BioMed Research International</italic></source><year>2013</year><volume>8</volume><issue>8</issue><fpage>616</fpage><lpage>617</lpage></element-citation></ref><ref id="B11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takaya</surname><given-names>D.</given-names></name><name><surname>Sato</surname><given-names>T.</given-names></name><name><surname>Yuki</surname><given-names>H.</given-names></name><etal/></person-group><article-title>Prediction of ligand-induced structural polymorphism of receptor interaction sites using machine learning</article-title><source><italic>Journal of Chemical Information and Modeling</italic></source><year>2013</year><volume>53</volume><issue>3</issue><fpage>704</fpage><lpage>716</lpage><pub-id pub-id-type="doi">10.1021/ci300458g</pub-id><pub-id pub-id-type="other">2-s2.0-84875470356</pub-id><pub-id pub-id-type="pmid">23351076</pub-id></element-citation></ref><ref id="B12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramatenki</surname><given-names>V.</given-names></name><name><surname>Potlapally</surname><given-names>S. R.</given-names></name><name><surname>Dumpati</surname><given-names>R. K.</given-names></name><name><surname>Vadija</surname><given-names>R.</given-names></name><name><surname>Vuruputuri</surname><given-names>U.</given-names></name><name><surname>Ramatenki</surname><given-names>V.</given-names></name></person-group><article-title>Homology modeling and virtual screening of ubiquitin conjugation enzyme E2A for designing a novel selective antagonist against cancer</article-title><source><italic>Journal of Receptor and Signal Transduction Research</italic></source><year>2015</year><volume>35</volume><issue>6</issue><fpage>536</fpage><lpage>549</lpage><pub-id pub-id-type="doi">10.3109/10799893.2014.969375</pub-id><pub-id pub-id-type="pmid">25316404</pub-id></element-citation></ref><ref id="B13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sawada</surname><given-names>R.</given-names></name><name><surname>Kotera</surname><given-names>M.</given-names></name><name><surname>Yamanishi</surname><given-names>Y.</given-names></name></person-group><article-title>Benchmarking a wide range of chemical descriptors for drug-target interaction prediction using a chemogenomic approach</article-title><source><italic>Molecular Informatics</italic></source><year>2014</year><volume>33</volume><issue>11-12</issue><fpage>719</fpage><lpage>731</lpage><pub-id pub-id-type="doi">10.1002/minf.201400066</pub-id><pub-id pub-id-type="other">2-s2.0-84915753460</pub-id><pub-id pub-id-type="pmid">27485418</pub-id></element-citation></ref><ref id="B14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sato</surname><given-names>T.</given-names></name><name><surname>Honma</surname><given-names>T.</given-names></name><name><surname>Yokoyama</surname><given-names>S.</given-names></name></person-group><article-title>Combining machine learning and pharmacophore-based interaction fingerprint for in silico screening</article-title><source><italic>Journal of Chemical Information and Modeling</italic></source><year>2010</year><volume>50</volume><issue>1</issue><fpage>170</fpage><lpage>185</lpage><pub-id pub-id-type="doi">10.1021/ci900382e</pub-id><pub-id pub-id-type="other">2-s2.0-75749126524</pub-id><pub-id pub-id-type="pmid">20038188</pub-id></element-citation></ref><ref id="B15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>M.-Y.</given-names></name><name><surname>Hong</surname><given-names>C.</given-names></name><name><surname>Bae</surname><given-names>S. H.</given-names></name><name><surname>So</surname><given-names>I.</given-names></name><name><surname>Park</surname><given-names>K.-S.</given-names></name></person-group><article-title>Dynamic modulation of the Kv2.1 channel by Src-dependent tyrosine phosphorylation</article-title><source><italic>Journal of Proteome Research</italic></source><year>2012</year><volume>11</volume><issue>2</issue><fpage>1018</fpage><lpage>1026</lpage><pub-id pub-id-type="doi">10.1021/pr200770v</pub-id><pub-id pub-id-type="other">2-s2.0-84856670333</pub-id><pub-id pub-id-type="pmid">22106938</pub-id></element-citation></ref><ref id="B16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nallaseth</surname><given-names>F. S.</given-names></name><name><surname>Lecaille</surname><given-names>F.</given-names></name><name><surname>Li</surname><given-names>Z.</given-names></name><name><surname>Br&#x000f6;mme</surname><given-names>D.</given-names></name></person-group><article-title>The role of basic amino acid surface clusters on the collagenase activity of cathepsin K</article-title><source><italic>Biochemistry</italic></source><year>2013</year><volume>52</volume><issue>44</issue><fpage>7742</fpage><lpage>7752</lpage><pub-id pub-id-type="doi">10.1021/bi401051j</pub-id><pub-id pub-id-type="other">2-s2.0-84887673573</pub-id><pub-id pub-id-type="pmid">24088021</pub-id></element-citation></ref><ref id="B17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anighoro</surname><given-names>A.</given-names></name><name><surname>Rastelli</surname><given-names>G.</given-names></name></person-group><article-title>Enrichment factor analyses on G-Protein coupled receptors with known crystal structure</article-title><source><italic>Journal of Chemical Information and Modeling</italic></source><year>2013</year><volume>53</volume><issue>4</issue><fpage>739</fpage><lpage>743</lpage><pub-id pub-id-type="doi">10.1021/ci4000745</pub-id><pub-id pub-id-type="other">2-s2.0-84876551012</pub-id><pub-id pub-id-type="pmid">23484900</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="fig1" orientation="portrait" position="float"><label>Figure 1</label><caption><p>Virtual screening process.</p></caption><graphic xlink:href="CMMM2016-4809831.001"/></fig><fig id="fig2" orientation="portrait" position="float"><label>Figure 2</label><caption><p>The calculation process of Pharm-IF [<xref rid="B14" ref-type="bibr">14</xref>].</p></caption><graphic xlink:href="CMMM2016-4809831.002"/></fig><fig id="fig3" orientation="portrait" position="float"><label>Figure 3</label><caption><p>Two ROC curves <italic>X</italic> and <italic>Y</italic>.</p></caption><graphic xlink:href="CMMM2016-4809831.003"/></fig><fig id="fig4" orientation="portrait" position="float"><label>Figure 4</label><caption><p>Comparative experiment of SRC.</p></caption><graphic xlink:href="CMMM2016-4809831.004"/></fig><fig id="fig5" orientation="portrait" position="float"><label>Figure 5</label><caption><p>Comparative experiment of Cathepsin K.</p></caption><graphic xlink:href="CMMM2016-4809831.005"/></fig><table-wrap id="tab1" orientation="portrait" position="float"><label>Table 1</label><caption><p>SVM parameter setting.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="1" colspan="1">Parameter name</th><th align="center" rowspan="1" colspan="1">Parameter values</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">SVM type</td><td align="center" rowspan="1" colspan="1">C-SVM</td></tr><tr><td align="left" rowspan="1" colspan="1">Class number</td><td align="center" rowspan="1" colspan="1">2</td></tr><tr><td align="left" rowspan="1" colspan="1">Kernel function</td><td align="center" rowspan="1" colspan="1">RBF</td></tr><tr><td align="left" rowspan="1" colspan="1">The degree in kernel function</td><td align="center" rowspan="1" colspan="1">3</td></tr><tr><td align="left" rowspan="1" colspan="1">
<italic>&#x003c3;</italic> in kernel function</td><td align="center" rowspan="1" colspan="1">0.001</td></tr><tr><td align="left" rowspan="1" colspan="1">Coast factor</td><td align="center" rowspan="1" colspan="1">5</td></tr><tr><td align="left" rowspan="1" colspan="1">Cache size</td><td align="center" rowspan="1" colspan="1">500&#x02009;MB</td></tr><tr><td align="left" rowspan="1" colspan="1">Tolerance in the termination criteria</td><td align="center" rowspan="1" colspan="1">0.001</td></tr><tr><td align="left" rowspan="1" colspan="1">The weight value of penalty factor for all kinds of samples</td><td align="center" rowspan="1" colspan="1">1</td></tr><tr><td align="left" rowspan="1" colspan="1">Cross validation</td><td align="center" rowspan="1" colspan="1">5</td></tr></tbody></table></table-wrap><table-wrap id="tab2" orientation="portrait" position="float"><label>Table 2</label><caption><p>Adaboost-SVM parameter setting.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="1" colspan="1">Parameter name</th><th align="center" rowspan="1" colspan="1">Parameter values</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Ensemble learning type</td><td align="center" rowspan="1" colspan="1">Adaboost</td></tr><tr><td align="left" rowspan="1" colspan="1">Class number</td><td align="center" rowspan="1" colspan="1">2</td></tr><tr><td align="left" rowspan="1" colspan="1">The basic classifier type</td><td align="center" rowspan="1" colspan="1">C-SVM</td></tr><tr><td align="left" rowspan="1" colspan="1">Number of classifiers per layer</td><td align="center" rowspan="1" colspan="1">100</td></tr><tr><td align="left" rowspan="1" colspan="1">The max false alarm rate</td><td align="center" rowspan="1" colspan="1">0.5</td></tr><tr><td align="left" rowspan="1" colspan="1">The min hit rate</td><td align="center" rowspan="1" colspan="1">0.9</td></tr><tr><td align="left" rowspan="1" colspan="1">Number of iterations</td><td align="center" rowspan="1" colspan="1">5</td></tr><tr><td align="left" rowspan="1" colspan="1">Weight trim rate</td><td align="center" rowspan="1" colspan="1">0.9</td></tr><tr><td align="left" rowspan="1" colspan="1">Cache size</td><td align="center" rowspan="1" colspan="1">500&#x02009;MB</td></tr></tbody></table></table-wrap><table-wrap id="tab3" orientation="portrait" position="float"><label>Table 3</label><caption><p>Experimental data structure.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="1" colspan="1">Date set</th><th align="center" rowspan="1" colspan="1">Positive sample</th><th align="center" rowspan="1" colspan="1">Negative sample</th><th align="center" rowspan="1" colspan="1">Total</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Training set</td><td align="center" rowspan="1" colspan="1">100</td><td align="center" rowspan="1" colspan="1">2000</td><td align="center" rowspan="1" colspan="1">2100</td></tr><tr><td align="left" rowspan="1" colspan="1">Test set</td><td align="center" rowspan="1" colspan="1">100<italic>&#x02217;</italic>5 = 500</td><td align="center" rowspan="1" colspan="1">2000<italic>&#x02217;</italic>5 = 10000</td><td align="center" rowspan="1" colspan="1">10500</td></tr></tbody></table></table-wrap><table-wrap id="tab4" orientation="portrait" position="float"><label>Table 4</label><caption><p>Random Forest parameter setting.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="1" colspan="1">Parameter name</th><th align="center" rowspan="1" colspan="1">Parameter values</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Tree number</td><td align="center" rowspan="1" colspan="1">1000</td></tr><tr><td align="left" rowspan="1" colspan="1">Node size</td><td align="center" rowspan="1" colspan="1">5</td></tr><tr><td align="left" rowspan="1" colspan="1">The number of different descriptors tried at each split</td><td align="center" rowspan="1" colspan="1">50</td></tr></tbody></table></table-wrap><table-wrap id="tab5" orientation="portrait" position="float"><label>Table 5</label><caption><p>Experimental comparison of SVM, Adaboost-SVM, and Random Forest.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="1" colspan="1">Algorithm</th><th align="center" rowspan="1" colspan="1">Target protein</th><th align="center" rowspan="1" colspan="1">10% EF</th><th align="center" rowspan="1" colspan="1">AUC</th></tr></thead><tbody><tr><td align="left" rowspan="2" colspan="1">SVM</td><td align="center" rowspan="1" colspan="1">SRC</td><td align="center" rowspan="1" colspan="1">4.7</td><td align="center" rowspan="1" colspan="1">0.734</td></tr><tr><td align="center" rowspan="1" colspan="1">Cathepsin K</td><td align="center" rowspan="1" colspan="1">3.9</td><td align="center" rowspan="1" colspan="1">0.683</td></tr><tr><td align="center" colspan="4" rowspan="1">
<hr/>
</td></tr><tr><td align="left" rowspan="2" colspan="1">Adaboost-SVM</td><td align="center" rowspan="1" colspan="1">SRC</td><td align="center" rowspan="1" colspan="1">5.5</td><td align="center" rowspan="1" colspan="1">0.821</td></tr><tr><td align="center" rowspan="1" colspan="1">Cathepsin K</td><td align="center" rowspan="1" colspan="1">4.8</td><td align="center" rowspan="1" colspan="1">0.802</td></tr><tr><td align="center" colspan="4" rowspan="1">
<hr/>
</td></tr><tr><td align="left" rowspan="2" colspan="1">Random Forest</td><td align="center" rowspan="1" colspan="1">SRC</td><td align="center" rowspan="1" colspan="1">5.3</td><td align="center" rowspan="1" colspan="1">0.805</td></tr><tr><td align="center" rowspan="1" colspan="1">Cathepsin K</td><td align="center" rowspan="1" colspan="1">4.5</td><td align="center" rowspan="1" colspan="1">0.783</td></tr></tbody></table></table-wrap></floats-group></article>