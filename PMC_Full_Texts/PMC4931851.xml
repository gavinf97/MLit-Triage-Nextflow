<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v3.0 20080202//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName journalpublishing3.dtd?><?SourceDTD.Version 3.0?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 2?><front><journal-meta><journal-id journal-id-type="nlm-ta">Aging (Albany NY)</journal-id><journal-id journal-id-type="iso-abbrev">Aging (Albany NY)</journal-id><journal-id journal-id-type="publisher-id">Aging</journal-id><journal-id journal-id-type="publisher-id">ImpactJ</journal-id><journal-title-group><journal-title>Aging (Albany NY)</journal-title></journal-title-group><issn pub-type="epub">1945-4589</issn><publisher><publisher-name>Impact Journals LLC</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">4931851</article-id><article-id pub-id-type="pmid">27191382</article-id><article-id pub-id-type="publisher-id">100968</article-id><article-id pub-id-type="doi">10.18632/aging.100968</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Paper</subject></subj-group></article-categories><title-group><article-title>Deep biomarkers of human aging: Application of deep neural networks to biomarker development</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Putin</surname><given-names>Evgeny</given-names></name><xref ref-type="aff" rid="A1"><sup>1</sup></xref><xref ref-type="aff" rid="A2"><sup>2</sup></xref></contrib><contrib contrib-type="author"><name><surname>Mamoshina</surname><given-names>Polina</given-names></name><xref ref-type="aff" rid="A1"><sup>1</sup></xref><xref ref-type="aff" rid="A3"><sup>3</sup></xref></contrib><contrib contrib-type="author"><name><surname>Aliper</surname><given-names>Alexander</given-names></name><xref ref-type="aff" rid="A1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Korzinkin</surname><given-names>Mikhail</given-names></name><xref ref-type="aff" rid="A1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Moskalev</surname><given-names>Alexey</given-names></name><xref ref-type="aff" rid="A1"><sup>1</sup></xref><xref ref-type="aff" rid="A4"><sup>4</sup></xref></contrib><contrib contrib-type="author"><name><surname>Kolosov</surname><given-names>Alexey</given-names></name><xref ref-type="aff" rid="A5"><sup>5</sup></xref></contrib><contrib contrib-type="author"><name><surname>Ostrovskiy</surname><given-names>Alexander</given-names></name><xref ref-type="aff" rid="A5"><sup>5</sup></xref></contrib><contrib contrib-type="author"><name><surname>Cantor</surname><given-names>Charles</given-names></name><xref ref-type="aff" rid="A6"><sup>6</sup></xref></contrib><contrib contrib-type="author"><name><surname>Vijg</surname><given-names>Jan</given-names></name><xref ref-type="aff" rid="A7"><sup>7</sup></xref></contrib><contrib contrib-type="author"><name><surname>Zhavoronkov</surname><given-names>Alex</given-names></name><xref ref-type="aff" rid="A1"><sup>1</sup></xref><xref ref-type="aff" rid="A3"><sup>3</sup></xref></contrib></contrib-group><aff id="A1"><sup>1</sup> Pharma.AI Department, Insilico Medicine, Inc, Baltimore, MD 21218, USA</aff><aff id="A2"><sup>2</sup> Computer Technologies Lab, ITMO University, St. Petersburg 197101, Russia</aff><aff id="A3"><sup>3</sup> The Biogerontology Research Foundation, Oxford, UK</aff><aff id="A4"><sup>4</sup> School of Systems Biology, George Mason University (GMU), Fairfax, VA 22030, USA</aff><aff id="A5"><sup>5</sup> Invitro Laboratory, Ltd, Moscow 125047, Russia</aff><aff id="A6"><sup>6</sup> Department of Biomedical Engineering, Boston University, Boston, MA 02215, USA</aff><aff id="A7"><sup>7</sup> Department of Genetics, Albert Einstein College of Medicine, Bronx, NY 10461, USA</aff><author-notes><corresp id="cor1"><bold><italic>Correspondence to:</italic></bold><italic>Alex Zhavoronkov, PhD;</italic><email>alex@biogerontology.org</email></corresp></author-notes><pub-date pub-type="collection"><month>5</month><year>2016</year></pub-date><pub-date pub-type="epub"><day>18</day><month>5</month><year>2016</year></pub-date><volume>8</volume><issue>5</issue><fpage>1021</fpage><lpage>1030</lpage><history><date date-type="received"><day>26</day><month>9</month><year>2015</year></date><date date-type="accepted"><day>9</day><month>5</month><year>2016</year></date></history><permissions><copyright-statement>Copyright: &#x000a9; 2016 Putin et al.</copyright-statement><copyright-year>2016</copyright-year><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.5/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract><p>One of the major impediments in human aging research is the absence of a comprehensive and actionable set of biomarkers that may be targeted and measured to track the effectiveness of therapeutic interventions. In this study, we designed a modular ensemble of 21 deep neural networks (DNNs) of varying depth, structure and optimization to predict human chronological age using a basic blood test. To train the DNNs, we used over 60,000 samples from common blood biochemistry and cell count tests from routine health exams performed by a single laboratory and linked to chronological age and sex. The best performing DNN in the ensemble demonstrated 81.5 % epsilon-accuracy <italic>r</italic> = 0.90 with <italic>R<sup>2</sup></italic> = 0.80 and MAE = 6.07 years in predicting chronological age within a 10 year frame, while the entire ensemble achieved 83.5% epsilon-accuracy <italic>r</italic> = 0.91 with <italic>R</italic><sup>2</sup> = 0.82 and MAE = 5.55 years. The ensemble also identified the 5 most important markers for predicting human chronological age: albumin, glucose, alkaline phosphatase, urea and erythrocytes. To allow for public testing and evaluate real-life performance of the predictor, we developed an online system available at <ext-link ext-link-type="uri" xlink:href="http://www.aging.ai">http://www.aging.ai</ext-link>. The ensemble approach may facilitate integration of multi-modal data linked to chronological age and sex that may lead to simple, minimally invasive, and affordable methods of tracking integrated biomarkers of aging in humans and performing cross-species feature importance analysis.</p></abstract><kwd-group><kwd>deep learning</kwd><kwd>deep neural networks</kwd><kwd>biomarker development</kwd><kwd>aging biomarkers</kwd><kwd>human aging</kwd><kwd>machine learning</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>INTRODUCTION</title><p>Aging is a complex process affecting all biological systems at every level of organization [<xref rid="R1" ref-type="bibr">1</xref>, <xref rid="R2" ref-type="bibr">2</xref>]. While many anti-aging interventions have demonstrated life-extending or other geroprotective effects in model organisms, practical limitations continue to hamper translation to the clinic [<xref rid="R3" ref-type="bibr">3</xref>]. One problem is that the evaluation of aging changes and possible anti-aging remedies requires a comprehensive set of robust biomarkers [<xref rid="R4" ref-type="bibr">4</xref>]. Large-scale longitudinal programs like MARK-AGE [<xref rid="R5" ref-type="bibr">5</xref>] have been launched to analyze changes in multiple biomarkers during aging and correlation between biological and chronological age. Several &#x0201c;aging clocks&#x0201d; able to predict human chronological age using various biomarkers have already been proposed. Methylation-based markers such as epigenetic aging clocks (Horvath [<xref rid="R6" ref-type="bibr">6</xref>] and Hannum [<xref rid="R7" ref-type="bibr">7</xref>]) are currently the most accurate, while transcriptomics [<xref rid="R8" ref-type="bibr">8</xref>,<xref rid="R9" ref-type="bibr">9</xref>] and metabolomics [<xref rid="R10" ref-type="bibr">10</xref>] have shown to be less so. Telomere length is commonly used to measure senescence but has lower predictive ability of human chronological age than IgG N-glycans, immunoglobulin G glycosylated at conservative N-glycation sites [<xref rid="R11" ref-type="bibr">11</xref>]. Recent studies show that biomarkers of age-related pathologies could be used to evaluate senescence modifications based on the connection between age-related pathologies at the signaling pathway level [<xref rid="R12" ref-type="bibr">12</xref>].</p><p>However, most of these biomarkers are not representative of the health state of the entire organism or individual systems and are not easily measured or targeted with known interventions. The common blood biochemistry test is one of the simplest tests used by physicians to examine the health state of patients. While being highly variable in nature, some markers from blood biochemistry are sensitive indicators of various conditions, such as inflammation and even alcoholism, and are approved for clinical use [<xref rid="R13" ref-type="bibr">13</xref>, <xref rid="R14" ref-type="bibr">14</xref>].</p><p>Machine learning (ML) techniques, such as support vector machines (SVM), are routinely used in biomarker development [<xref rid="R15" ref-type="bibr">15</xref>] and rapid increases in labeled data are enabling deep neural networks (DNNs). Methods based on deep architectures have outperformed classical approaches not only in image analysis, but also in solving a wide range of genomics, transcriptomics and proteomics problems [<xref rid="R16" ref-type="bibr">16</xref>].</p><p>In this study, we apply a deep learning technique for predicting human chronological age that utilizes multiple DNNs stacked into an ensemble and trained on tens of thousands of blood biochemistry samples from patients undergoing routine physical examinations. We then use a custom implementation of the permutation feature importance (PFI) technique [<xref rid="R17" ref-type="bibr">17</xref>] to evaluate the relative importance of each blood biochemistry marker to ensemble accuracy. We also analyzed the performance and accuracy of 40 DNN architectures optimized using a variety of optimizers, identified the best DNN, and selected 21 DNNs that cumulatively provided higher accuracy and <italic>R</italic><sup>2</sup> as an ensemble than the best DNN in the ensemble.</p></sec><sec id="s2"><title>RESULTS</title><p>To perform this study, we obtained a dataset of 62,419 anonymized blood biochemistry records, where each record consists of a person's age, sex, and 46 standardized blood markers through a collaboration with one of the largest laboratory networks in Russia, Invitro Laboratory, Ltd. We aimed to draw data from a reasonably healthy population. While we did not have access to patient records, we selected only blood tests from routine health checks, avoiding obvious sources of unhealthy patients, such as hospitals, and through statistical analysis omitted blood tests with outliers.</p><p>The generalized project pipeline is depicted in Figure <xref ref-type="fig" rid="F1">1</xref>. First, we preprocessed the blood test data set, excluding highly biased markers from reference ranges, normalizing them for training the DNNs, and removing outliers (see Methods for details). The resulting data set was split into training and test sets comprised of 56,177 and 6242 samples, respectively. Then 40 different DNNs were trained on 56,177 blood test samples.</p><fig id="F1" orientation="portrait" position="float"><label>Figure 1</label><caption><title>Project pipeline</title><p>Laboratory blood biochemistry data sets were normalized and cleaned of outliers and some abnormal markers. For biological age prediction, 21 different DNNs with different parameters were combined in ensemble based on ElasticNet model. For biological sex prediction, single DNN were trained.</p></caption><graphic xlink:href="aging-08-1021-g001"/></fig><p>Since we treated human age prediction as a regression problem, we used two metrics to estimate the performance of the method: standard coefficient of determination (R<sup>2</sup>) and &#x003b5;-prediction (epsilon-prediction) accuracy (see Methods for details). When using epsilon-prediction accuracy, the sample is considered correctly recognized if the predicted age is in the range of [true age -&#x003b5;; true age +&#x003b5;], where &#x003b5; controls the level of certainty in the prediction. So if &#x003b5; = 0, then it is a simple classification accuracy. In this study, we considered &#x003b5; = 10. The key advantage of using epsilon-prediction accuracy is that it allows cohort analysis without fixed age ranges (e.g. 10-20, 20-30).</p><p>The best single DNN performed with 0.80 of R<sup>2</sup> and 82% within the 10 year frame of epsilon-prediction accuracy (Figure <xref ref-type="fig" rid="F2">2A &#x00026; B</xref>). Single DNN outperformed other ML models such as k-Nearest Neighbors, Support Vector Machine, Random Forests, Gradient Boosting Machine, etc (Figure <xref ref-type="fig" rid="F3">3 &#x00026; B</xref>).</p><fig id="F2" orientation="portrait" position="float"><label>Figure 2</label><caption><title>Analysis of best DNN model in the ensemble and the whole ensemble</title><p>(<bold>A</bold>) Correlation between actual and predicted age values by the best DNN in the ensemble. (<bold>B</bold>) Biological age epsilon-prediction accuracy plot for the best DNN. (<bold>C</bold>) Biological age marker Importance, performed using FPI method. (<bold>D</bold>) Correlation between actual and predicted age values by whole ensemble based on ElasticNet model. (<bold>E</bold>) Biological age epsilon-prediction accuracy plot for the ensemble. (<bold>F</bold>) Heat map for Pearson's correlation coefficients between 40 DNNs. Scale bar colors indicate the sign and magnitude of Pearson's correlation coefficient between predictions of DNNs.</p></caption><graphic xlink:href="aging-08-1021-g002"/></fig><fig id="F3" orientation="portrait" position="float"><label>Figure 3</label><caption><title>DNNs outperform baseline ML approaches in terms of R<sup>2</sup> statistics</title><p>DNN were compared with 7 ML techniques: GBM (Gradient Boosting Machine), RF (Random Forests), DT (Decision Trees), LR (Linear Regression), kNN (k-Nearest Neighbors), ElasticNet, SVM (Support Vector Machines). (<bold>A</bold>) GBM shows the higher 0,72 R<sup>2</sup> among ML models for biological age prediction. (<bold>B</bold>) All ML models have comparable high R<sup>2</sup> for biological sex prediction.</p></caption><graphic xlink:href="aging-08-1021-g003"/></fig><p>To further increase the coefficient of determination and accuracy of predictions, we combined these single DNNs into an ensemble based on the stacked generalization (Stacking) technique [<xref rid="R18" ref-type="bibr">18</xref>]. Stacking is a method that fits some ML models on the predictions of other models, in our case on the predictions of DNNs. Model selection was performed with 10 fold cross-validation and with the random search strategy for finding the best hyperparameters for considered models. The experiments with Stacking models showed (Figure <xref ref-type="fig" rid="F4">4A &#x00026; B</xref>) that the best ML model was ElasticNet.</p><fig id="F4" orientation="portrait" position="float"><label>Figure 4</label><caption><title>Comparison of sub-models for stacking ensemble and evaluation of filling strategies</title><p>(<bold>A</bold>) ElasticNet model has the higher epsilon-prediction accuracy among the stacking models. (<bold>B</bold>) ElasticNet is the best model for stacking from the point of R<sup>2</sup> statistics. (<bold>C</bold>) Median filling strategy has higher epsilon-prediction accuracy than other strategies. Median filling strategy shows 64,5 % epsilon accuracy within 10 years frame. (<bold>D</bold>) Median filling strategy is better from the point of R<sup>2</sup> statistics.</p></caption><graphic xlink:href="aging-08-1021-g004"/></fig><p>To successfully combine the predictions of DNNs into the Stacking ensemble model, the predictions of DNNs should closely approximate the target variable and differ from one another, or be less correlated. To achieve this, DNNs should be trained with different hyperparameters, varying in the number of layers, counts of neurons in each layer, activation functions, regularization techniques, etc. We investigated 40 DNNs, each unique in terms of hyperparameters. Pearson correlations of these DNNs are presented in a heat map on Figure <xref ref-type="fig" rid="F2">2F</xref>, showing a high degree of similarity among many of the networks regarding predictions (r approaching 1) but also some major distinctions.</p><p>To determine how many of these trained DNNs were necessary for constructing the Stacking ensemble model, we performed an iterative process of adding each DNN's predictions vector into the ensemble. Two iterative strategies were employed: adding predictions by decreasing R<sup>2</sup> of each network, i.e. adding better networks considering R<sup>2</sup> earliest in the ensemble, and increasing the correlation between DNNs, i.e. adding less correlated networks first. The results of this assay are presented in <xref ref-type="supplementary-material" rid="SD1">Figure S2</xref>. Both strategies showed that no more than 21 DNNs were needed in the ensemble. The ensemble resulting from distinguishing the correlations of DNNs and ordering the addition of DNNs into the ensemble demonstrated R<sup>2</sup>=0.82 and 83,5% within a 10 year frame of epsilon-prediction accuracy (Figure <xref ref-type="fig" rid="F2">2D &#x00026; E</xref>).</p><p>We compared our deep-learned predictor with several published epigenetics and transcriptomics markers of human age. Surprisingly, despite the fact that we used only blood biochemistry data with 41 values for each patient, our biomarker outperformed blood transcriptomics biomarkers presented by Peters et al with R<sup>2</sup>=0,6 for the best model [<xref rid="R8" ref-type="bibr">8</xref>]. Due to the nature of the data, epigenetics markers show a stronger correlation with chronological age, with R<sup>2</sup>=0,93 for Horvath's methylation clock and R<sup>2</sup>=0,89 for the Hannum et methylation clock [<xref rid="R6" ref-type="bibr">6</xref>, <xref rid="R7" ref-type="bibr">7</xref>].</p><sec id="s2_1"><title>Marker importance</title><p>In order to analyze the importance of blood test markers via neural networks, some wrapper feature (selection) importances approaches are required. We used a modification of the Permutation Feature Importance (PFI) method (see Methods for details). By applying this method, one receives a list sorted by the importance of markers via DNN. This technique has two benefits: 1) it is native and simple to interpret and 2) as other wrapper methods it relies on DNN performance, which in this case is better than other ML models, thus produces more robust and meaningful features. Marker importance analysis by PFI method, the results of which are presented in Figure <xref ref-type="fig" rid="F2">2C</xref>, reveals the five important markers: albumin, glucose, alkaline phosphatase, urea, and erythrocytes.</p></sec><sec id="s2_2"><title>Top features</title><p>We also performed so-called top features analysis, which answers how the performance of a single DNN will decrease as the number of markers used in the model decreases. To select the smaller number of markers for training the DNN, the sorted list of all PFI scores is used. The results of this analysis for both R<sup>2</sup> and epsilon-prediction accuracy are presented on Figure <xref ref-type="fig" rid="F5">5A &#x00026; B</xref>. For the top 10 features by PFI, the DNN got R<sup>2</sup>=0.63 and 70% of 10 year frame epsilon-accuracy prediction. In practical terms, the fact that this drop in performance was so small supports the top 10 markers received by PFI as robust and reliable features for predicting age.</p><fig id="F5" orientation="portrait" position="float"><label>Figure 5</label><caption><title>Top features analysis</title><p>(<bold>A</bold>) Dependence of the epsilon-prediction accuracy from the number of features. (<bold>B</bold>) Dependence of R<sup>2</sup> statistics from the number of features.</p></caption><graphic xlink:href="aging-08-1021-g005"/></fig></sec><sec id="s2_3"><title>Use case</title><p>To make this deep network ensemble available to the public, we placed our system online (<ext-link ext-link-type="uri" xlink:href="http://www.Aging.AI">www.Aging.AI</ext-link>), allowing any patient with blood test data to predict their age and sex. In order to validate our approach, we collected the blood biochemistry reports that were uploaded on the site from 25 January to 15 March 2016. The total number of collected reports with indicated real age was 1,563 samples. Many users expressed no desire to specify all 41 parameters of the blood test, so we added an option to enter only the 10 most important markers. The average number of missing values provided by the volunteer testers was 18.5 markers per person. There are several strategies for filling skipped values, including zero, mean, mode and median over all values of each marker. Evaluation of these 4 strategies on the aging.ai data showed that median filling strategy has the best performance in terms of both R<sup>2</sup> and epsilon-prediction accuracy (Figure <xref ref-type="fig" rid="F4">4C &#x00026; D</xref>).</p><p>Aging.AI provides a proof of concept for a simple and inexpensive blood-based predictor of chronological age, which may be used for speculate on the biological age of the patient. However, it has many limitations. When it comes to developing predictors using deep neural networks, one of the major difficulties is building large data sets. In this study we were constrained by the limited number of features available to us in large numbers of blood test results. Some of the features, for example globulin fractures, are no longer frequently used in diagnostic medicine and are excluded from the newer standard tests. However, these features were present in historical tests available in large numbers and were used for training.</p></sec></sec><sec id="s3"><title>DISCUSSION</title><p>Aging is a complex process and occurs at different rates and to different extents in the various organ systems, including respiratory, renal, hepatic, and metabolic [<xref rid="R19" ref-type="bibr">19</xref>, <xref rid="R20" ref-type="bibr">20</xref>]. The analysis of relative feature importance within the DNNs helped deduce the most important features that may shed light on the contribution of these systems to the aging process, ranked in the following order: metabolic, liver, renal system and respiratory function. The five markers related to these functions were previously associated with aging and used to predict human biological age [<xref rid="R21" ref-type="bibr">21</xref>, <xref rid="R22" ref-type="bibr">22</xref>]. Another interesting finding was the extraordinarily high importance of albumin, which primarily controls the oncotic pressure of blood. Albumin declines during aging and is associated with sarcopenia [<xref rid="R23" ref-type="bibr">23</xref>]. The second marker by relative importance is glucose, which is directly linked to metabolic health. Cardiovascular diseases associated with diabetes mellitus are major causes of death within the general population [<xref rid="R24" ref-type="bibr">24</xref>].</p><p>Our approach of using an ensemble of DNNs outperformed other ML models in terms of R<sup>2</sup> and epsilon-prediction accuracy (Figure <xref ref-type="fig" rid="F3">3A &#x00026; B</xref>). Application of DNNs uncovered complex nonlinear interactions between markers resulting in robust ensemble performance. This ensemble may also be expanded with DNNs trained on different sources and types of biological data allowing for complex multi-modal markers to be created and relative contributions of each input analyzed.</p><p>Current and future directions of this work include adding other sources of features including transcriptomic and metabolomics markers from blood, urine, individual organ biopsies and even imaging data as well as testing the system using data from patients with accelerated aging syndromes, multiple diseases and performing gender-specific analysis. Similar tests may be performed by research teams working on rare diseases or working with athletic groups by using <ext-link ext-link-type="uri" xlink:href="http://www.Aging.AI">http://www.Aging.AI</ext-link> system or contacting the authors to perform a high-throughput analysis. Developing similar systems for model organisms and performing PFI analysis may help perform cross-species analysis and of the relative importance of individual markers and organ systems in predicting chronological and biological age.</p></sec><sec sec-type="methods" id="s4"><title>MATERIALS AND METHODS</title><sec id="s4_1"><title>Data</title><p>Anonymized statistical data of human blood tests was kindly provided by an independent laboratory, Invitro (<ext-link ext-link-type="uri" xlink:href="http://www.www.Invitro.ru">http://www.Invitro.ru</ext-link>). No patient records were used in the study. In total, the data contains 62419 records where each record consists of person's age and 46 standardized blood markers, such as Glucose, Cholesterol, Alpha-1-globulins, etc. (<xref ref-type="supplementary-material" rid="SD1">Table S1</xref>) Histograms of human age for training sets and descriptive statistics of top 10 blood markers used in the research are depicted in the <xref ref-type="supplementary-material" rid="SD1">Figure S1A</xref>.</p><p>One can see from the <xref ref-type="supplementary-material" rid="SD1">Figure S1B</xref> that minimum and maximum values of each marker are far distributed from their normal range values. This distribution reflects patients' tendencies to self-report symptoms and test their health with professional health-care services only in complex cases, which affects their health condition and thus test results [<xref rid="R25" ref-type="bibr">25</xref>]. Moreover, we found that there were no patients that could be considered as healthy and who have blood test values within a reference range. The most frequently abnormal markers in the distribution were white blood cell count markers: basophils, abs., eosinophils, abs., lymphocytes abs. monocytes, abs, neutrophils, abs. These types of test provide the total number (absolute number, abs.) of white blood cells in blood microliter. Here, this routine analysis was conducted using a hematology automated analyzer, which counts cells precisely with low error rate [<xref rid="R26" ref-type="bibr">26</xref>]. In this case, these aberrant values of markers are more likely linked to the major function of white blood cells; immune function, infections, allergies, smoking [<xref rid="R27" ref-type="bibr">27</xref>] or even sleep duration [<xref rid="R28" ref-type="bibr">28</xref>] could affect the rate of white blood cells. Additionally, recent studies show a connection between metabolic diseases such as diabetes and range of white blood cells [<xref rid="R29" ref-type="bibr">29</xref>, <xref rid="R30" ref-type="bibr">30</xref>]. For this reason, levels of basophils, eosinophils, lymphocytes, monocytes and neutrophils are extremely variable in the general population. To prevent DNN predictions from being highly biased with respect to abnormal ranges of blood markers, we excluded these 5 markers. Processed data was presented in a tabular format of 62419 rows and 42 columns (age and sex + 41 markers).</p><p>Then, specifically for training deep neural network, we normalized all blood markers to 0-1 range by using the formula:
<disp-formula id="eq-001"><mml:math id="M1"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>X</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mtext mathvariant="italic">min</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mtext mathvariant="italic">max</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mtext mathvariant="italic">min</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
where <italic>X</italic> is the origin values of each blood marker, <italic>X<sub>min</sub></italic> and <italic>X<sub>max</sub></italic> are its minimum and maximum, respectively and <italic>X<sub>0&#x02013;</sub></italic> is the marker within 0-1 range.</p><p>We split the data to the training and test sets with 90/10 ratio. Thus, the size of training and test sets were 56177 and 6242 samples, respectively. The DNN was built by adjusting its hyperparameters (such as a number of layers, activation function, etc.) on the training set and measuring the performance of the trained neural network on the test set. The comparison of performances of 6 best DNNs with different values of hyperparameters is depicted on <xref ref-type="supplementary-material" rid="SD1">Table S1</xref>. All experiments were conducted on Nvidia Tesla K80 graphics processing unit.</p><p>There are two reasons why in the study we treated the prediction of human age as a regression problem: 1) age has natural order, so it is an order variable and 2) one may be interested in the difference in values of the markers with difference in ages, which is the natural way to perform the analysis of marker influence. In this case, it was better to use regression instead of classification methods.</p><p>So, in all evaluations 4 metrics were measured:
<list list-type="simple"><list-item><p><italic>r</italic>, which is a Pearson's correlation coefficient defined as: <inline-formula><mml:math id="M2"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:msubsup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt><mml:msqrt><mml:mrow><mml:msubsup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>; where <italic>x<sub>i</sub></italic> is real value and <inline-formula><mml:math id="M3"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover></mml:math></inline-formula> is the mean of <italic>x</italic>, <italic>y<sub>i</sub></italic> is predicted value and <inline-formula><mml:math id="M4"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover></mml:math></inline-formula> is the mean of <italic>y</italic>, and <italic>N</italic> is number of samples.</p></list-item><list-item><p><italic>R<sup>2</sup></italic>, which is a standard coefficient of determination defined as: <inline-formula><mml:math id="M5"><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>; where <italic>y<sub>i</sub></italic> is the real value, <italic>f<sub>i</sub></italic> is the predicted value and <inline-formula><mml:math id="M6"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover></mml:math></inline-formula> is the mean of <italic>y</italic>.</p></list-item><list-item><p>Mean absolute error (MAE), which is defined as <inline-formula><mml:math id="M7"><mml:mrow><mml:mtext mathvariant="italic">MAE</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>; where <italic>f<sub>i</sub></italic> is a prediction of the model, <italic>y<sub>i</sub></italic> is a true value and N is a number of samples.</p></list-item><list-item><p><italic>&#x003b5;</italic>-prediction accuracy defined as: <inline-formula><mml:math id="M8"><mml:mrow><mml:mi>&#x003b5;</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mtext mathvariant="italic">prediction</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:msub><mml:mn>1</mml:mn><mml:mi>A</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>N</mml:mi></mml:mfrac></mml:mrow></mml:math></inline-formula>; where A is [<italic>y<sub>i</sub></italic> &#x02212; <italic>&#x003b5;</italic>; <italic>y<sub>i</sub></italic> + <italic>&#x003b5;</italic>]; <italic>y<sub>i</sub></italic> is the real value, <italic>f<sub>i</sub></italic> is the predicted value and <italic>&#x003b5;</italic> is a parameter that controls the range of correctness of predictions. So for example if <italic>&#x003b5;</italic> is 10 and the true value of age is 45 the deep neural network correctly recognized sample if it is in the [<xref rid="R35" ref-type="bibr">35</xref>, 55] range.</p></list-item></list></p></sec><sec id="s4_2"><title>Feature importance method</title><p>The idea behind the algorithm stemmed from the feature randomization technique used in Random Forest (RF) [<xref rid="R31" ref-type="bibr">31</xref>]. PFI computes significance scores for all features by determining the accuracy of a model to random permutations of the values of those feature variables. The main underlying assumption is that permuting the values of important features results in a more significant reduction in a model's performance compared to the effect of less important ones. But when cross-validation is not performed, one should improve the robustness of the method.</p><p>To do this, we shuffled each feature <italic>k</italic> times and then computed the average PFI score for the feature, concretely the PFI score for one feature is defined as follows:</p><p><inline-formula><mml:math id="M9"><mml:mrow><mml:mi>P</mml:mi><mml:mi>F</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mtext mathvariant="italic">feature</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mtext mathvariant="italic">total</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mtext mathvariant="italic">shuffle</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>; where <inline-formula><mml:math id="M10"><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mtext mathvariant="italic">total</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> is a total <italic>R<sup>2</sup></italic> for the model without any permutations and <inline-formula><mml:math id="M11"><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mtext mathvariant="italic">shuffle</mml:mtext></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&#x000a0;</mml:mo></mml:mrow></mml:math></inline-formula> is a <italic>R<sup>2</sup></italic> for the model with permutated feature permutated feature and <italic>K</italic> is a parameter that controls how many times the feature is permutated.</p><p>Note that PFI is a wrapper method, so it would significantly depend on applying ML model, but because DNNs show better performance than other ML models, it was suitable for the problem.</p></sec><sec id="s4_3"><title>Architecture of DNN</title><p>We used simple feed-forward neural networks trained with the standard backpropagation algorithm as our deep (more than 3 layers) learning models. For each DNN in the resulting ensemble, multiple hyperparameters were adjusted, including the number of hidden layers, the number of neurons in each layer, choice of activation function, choice of optimization method, and regularization techniques. The table with experiments of different hyperparameters for the DNNs are presented in <xref ref-type="supplementary-material" rid="SD1">Table S1</xref>.</p><p>The best DNN in the ensemble had 5 hidden layers with 2000, 1500, 1000, 500, and 1 neurons in each, respectively. The last layer, with one neuron, corresponds to regression output. The optimization loss function was simple mean squared error (MSE) with regularization terms. The DNN used PReLU activation function [<xref rid="R32" ref-type="bibr">32</xref>] in each layer, AdaGrad [<xref rid="R33" ref-type="bibr">33</xref>] as optimizer of the loss function, Dropout [<xref rid="R34" ref-type="bibr">34</xref>] with probability of 0.2 after each layer, and l2 weight decay [<xref rid="R35" ref-type="bibr">35</xref>]. To further cope with over fitting and make more stable convergence of models, we used Batch normalization technique [<xref rid="R36" ref-type="bibr">36</xref>] after the first 2 layers.</p></sec></sec><sec sec-type="supplementary-material" id="s5"><title>SUPPLEMENTARY DATA FIGURES AND TABLES</title><supplementary-material content-type="local-data" id="SD1"><media mimetype="application" mime-subtype="pdf" xlink:href="aging-08-1021-s001.pdf" orientation="portrait" xlink:type="simple" id="d36e1246" position="anchor"/></supplementary-material></sec></body><back><ack><p>We thank Vladimir Parfenov for assistance and helpful comments, Mark Berger from NVIDIA for assistance with the GPU eqiupment and Dr. Elena Kondrasheva, who made major contribution to data selection and processing and interpretation, but decided that this major contribution did not justify authorship. We would like to thank Dr. Leslie C. Jellen for editing this manuscript. The Aging.AI system was inspired by <ext-link ext-link-type="uri" xlink:href="http://How-Old.net">http://How-Old.net</ext-link> by Microsoft, Inc and we would like to thank Dr. Joseph Sirosh for presentations of this system. Finally, we are grateful to all users of the Aging.AI system for helping test and improve the system.</p></ack><fn-group><fn fn-type="supported-by"><p><bold>Funding</bold></p><p>This work was financially supported by the Government of Russian Federation, Grant 074-U01 and by a research grant from the Life Extension Foundation 2016&#x02013;LEF&#x02013; AA&#x02013;INSIL. Insilico Medicine is grateful to Nvidia Corporation for providing Tesla K80 GPUs and early access to the NVIDIA DevBox used in this study.</p></fn><fn fn-type="conflict"><p><bold>Conflict of interest statement</bold></p><p>The authors are affiliated with Insilico Medicine, Inc, a commercial company developing differential pathway activation scoring-based and deep learned biomarkers of multiple diseases and aging and engaging in drug discovery and drug repurposing. The company has developed a range of drug candidates addressing specific diseases and geroprotector interventions addressing human aging processes that need to be validated in human patients. The company intends to use blood biochemistry and multi-parametric markers, including the one published in this paper to test the efficacy of these compounds. Despite company's commitment to best academic practices and in silico veritas, the authors may have a conflict of interest.</p></fn></fn-group><glossary><title>Abbreviations</title><def-list><def-item><term>ML</term><def><p>Machine Learning</p></def></def-item><def-item><term>SVM</term><def><p>Support Vector Machine</p></def></def-item><def-item><term>DNN</term><def><p>Deep Neural Network</p></def></def-item><def-item><term>PFI</term><def><p>Permutation Feature Importance</p></def></def-item><def-item><term>RF</term><def><p>Random Forests</p></def></def-item><def-item><term>GBM</term><def><p>Gradient Boosting Machine</p></def></def-item><def-item><term>kNN</term><def><p>k-Nearest Neighbors</p></def></def-item><def-item><term>DT</term><def><p>Decision Trees</p></def></def-item><def-item><term>LR</term><def><p>Linear Regression</p></def></def-item></def-list></glossary><ref-list><title>REFERENCES</title><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhavoronkov</surname><given-names>A</given-names></name><name><surname>Cantor</surname><given-names>CR</given-names></name></person-group><article-title>Methods for structuring scientific knowledge from many areas related to aging research</article-title><source>PLoS One</source><year>2011</year><volume>6</volume><fpage>e22597</fpage><pub-id pub-id-type="pmid">21799912</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moskalev</surname><given-names>A</given-names></name><name><surname>Zhikrivetskaya</surname><given-names>S</given-names></name><name><surname>Shaposhnikov</surname><given-names>M</given-names></name><name><surname>Dobrovolskaya</surname><given-names>E</given-names></name><name><surname>Gurinovich</surname><given-names>R</given-names></name><name><surname>Kuryan</surname><given-names>O</given-names></name><etal/></person-group><article-title>Aging Chart: a community resource for rapid exploratory pathway analysis of age-related processes</article-title><source>Nucleic Acids Res</source><year>2016</year><volume>44</volume><fpage>D894</fpage><lpage>899</lpage><pub-id pub-id-type="pmid">26602690</pub-id></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moskalev</surname><given-names>A</given-names></name><name><surname>Chernyagina</surname><given-names>E</given-names></name><name><surname>de Magalh&#x000e3;es</surname><given-names>JP</given-names></name><name><surname>Barardo</surname><given-names>D</given-names></name><name><surname>Thoppil</surname><given-names>H</given-names></name><name><surname>Shaposhnikov</surname><given-names>M</given-names></name><etal/></person-group><article-title>Geroprotectors.org: a new, structured and curated database of current therapeutic interventions in aging and age-related disease</article-title><source>Aging (Albany NY)</source><year>2015</year><volume>7</volume><fpage>616</fpage><lpage>728</lpage><pub-id pub-id-type="pmid">26342919</pub-id></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhavoronkov</surname><given-names>A</given-names></name><name><surname>Alex</surname><given-names>Z</given-names></name><name><surname>Bhupinder</surname><given-names>B</given-names></name></person-group><article-title>Classifying Aging as a Disease in the context of ICD-1</article-title><source>Frontiers in Genetics</source><year>2015</year><volume>6</volume><fpage>1</fpage><lpage>16</lpage><pub-id pub-id-type="pmid">25674101</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>B&#x000fc;rkle</surname><given-names>A</given-names></name><name><surname>Moreno-Villanueva</surname><given-names>M</given-names></name><name><surname>Bernhard</surname><given-names>J</given-names></name><name><surname>Blasco</surname><given-names>M</given-names></name><name><surname>Zondag</surname><given-names>G</given-names></name><name><surname>Hoeijmakers</surname><given-names>JHJ</given-names></name><etal/></person-group><article-title>MARK-AGE biomarkers of ageing</article-title><source>Mech. Ageing Dev</source><year>2015</year><volume>151</volume><fpage>2</fpage><lpage>12</lpage><pub-id pub-id-type="pmid">25818235</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horvath</surname><given-names>S</given-names></name></person-group><article-title>DNA methylation age of human tissues and cell types</article-title><source>Genome Biol</source><year>2013</year><volume>14</volume><fpage>R115</fpage><pub-id pub-id-type="pmid">24138928</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hannum</surname><given-names>G</given-names></name><name><surname>Gregory</surname><given-names>H</given-names></name><name><surname>Justin</surname><given-names>G</given-names></name><name><surname>Ling</surname><given-names>Z</given-names></name><name><surname>Li</surname><given-names>Z</given-names></name><name><surname>Guy</surname><given-names>H</given-names></name><etal/></person-group><article-title>Genome-wide Methylation Profiles Reveal Quantitative Views of Human Aging Rates</article-title><source>Mol. Cell</source><year>2013</year><volume>49</volume><fpage>359</fpage><lpage>367</lpage><pub-id pub-id-type="pmid">23177740</pub-id></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peters</surname><given-names>MJ</given-names></name><name><surname>Joehanes</surname><given-names>R</given-names></name><name><surname>Pilling</surname><given-names>LC</given-names></name><name><surname>Schurmann</surname><given-names>C</given-names></name><name><surname>Conneely</surname><given-names>KN</given-names></name><name><surname>Powell</surname><given-names>J</given-names></name><etal/></person-group><article-title>The transcriptional landscape of age in human peripheral blood</article-title><source>Nat. Commun</source><year>2015</year><volume>6</volume><fpage>8570</fpage><pub-id pub-id-type="pmid">26490707</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nakamura</surname><given-names>S</given-names></name><name><surname>Kawai</surname><given-names>K</given-names></name><name><surname>Takeshita</surname><given-names>Y</given-names></name><name><surname>Honda</surname><given-names>M</given-names></name><name><surname>Takamura</surname><given-names>T</given-names></name><name><surname>Kaneko</surname><given-names>S</given-names></name><etal/></person-group><article-title>Identification of blood biomarkers of aging by transcript profiling of whole blood</article-title><source>Biochem. Biophys. Res. Commun</source><year>2012</year><volume>418</volume><fpage>313</fpage><lpage>318</lpage><pub-id pub-id-type="pmid">22266314</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Menni</surname><given-names>C</given-names></name><name><surname>Kastenm&#x000fc;ller</surname><given-names>G</given-names></name><name><surname>Petersen</surname><given-names>AK</given-names></name><name><surname>Bell</surname><given-names>JT</given-names></name><name><surname>Psatha</surname><given-names>M</given-names></name><name><surname>Tsai</surname><given-names>P-C</given-names></name><etal/></person-group><article-title>Metabolomic markers reveal novel pathways of ageing and early development in human populations</article-title><source>Int. J. Epidemiol</source><year>2013</year><volume>42</volume><fpage>1111</fpage><lpage>1119</lpage><pub-id pub-id-type="pmid">23838602</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kri&#x00161;ti&#x00107;</surname><given-names>J</given-names></name><name><surname>Kri ti</surname><given-names>J</given-names></name><name><surname>Vu kovi</surname><given-names>F</given-names></name><name><surname>Menni</surname><given-names>C</given-names></name><name><surname>Klari</surname><given-names>L</given-names></name><name><surname>Keser</surname><given-names>T</given-names></name><etal/></person-group><article-title>Glycans Are a Novel Biomarker of Chronological and Biological Ages</article-title><source>J. Gerontol. A Biol. Sci. Med. Sci</source><year>2013</year><volume>69</volume><fpage>779</fpage><lpage>789</lpage><pub-id pub-id-type="pmid">24325898</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aliper</surname><given-names>AM</given-names></name><name><surname>Csoka</surname><given-names>AB</given-names></name><name><surname>Buzdin</surname><given-names>A</given-names></name><name><surname>Jetka</surname><given-names>T</given-names></name><name><surname>Roumiantsev</surname><given-names>S</given-names></name><name><surname>Moskalev</surname><given-names>A</given-names></name><etal/></person-group><article-title>Signaling pathway activation drift during aging: Hutchinson-Gilford Progeria Syndrome fibroblasts are comparable to normal middle-age and old-age cells</article-title><source>Aging (Albany NY)</source><year>2015</year><volume>7</volume><fpage>26</fpage><lpage>37</lpage><pub-id pub-id-type="pmid">25587796</pub-id></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaysen</surname><given-names>GA</given-names></name></person-group><article-title>Biochemistry and biomarkers of inflamed patients: why look, what to assess</article-title><source>Clin. J. Am. Soc. Nephrol</source><volume>4</volume><issue>Suppl 1</issue><year>2009</year><fpage>S56</fpage><lpage>63</lpage><pub-id pub-id-type="pmid">19996007</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peterson</surname><given-names>K</given-names></name></person-group><article-title>Biomarkers for alcohol use and abuse--a summary</article-title><source>Alcohol Res. Health</source><year>2004</year><volume>28</volume><fpage>30</fpage><lpage>37</lpage><pub-id pub-id-type="pmid">19006989</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Libbrecht</surname><given-names>MW</given-names></name><name><surname>Noble</surname><given-names>WS</given-names></name></person-group><article-title>Machine learning applications in genetics and genomics</article-title><source>Nat. Rev. Genet</source><year>2015</year><volume>16</volume><fpage>321</fpage><lpage>332</lpage><pub-id pub-id-type="pmid">25948244</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mamoshina</surname><given-names>P</given-names></name><name><surname>Polina</surname><given-names>M</given-names></name><name><surname>Armando</surname><given-names>V</given-names></name><name><surname>Evgeny</surname><given-names>P</given-names></name><name><surname>Alex</surname><given-names>Z</given-names></name></person-group><article-title>Applications of Deep Learning in Biomedicine</article-title><source>Mol. Pharm. Internet</source><year>2016</year><comment><ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1021/acs.molpharmaceut.5b00982">http://dx.doi.org/10.1021/acs.molpharmaceut.5b00982</ext-link></comment></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Altmann</surname><given-names>A</given-names></name><name><surname>Tolo&#x0015f;i</surname><given-names>L</given-names></name><name><surname>Sander</surname><given-names>O</given-names></name><name><surname>Lengauer</surname><given-names>T</given-names></name></person-group><article-title>Permutation importance: a corrected feature importance measure</article-title><source>Bioinformatics</source><year>2010</year><volume>26</volume><fpage>1340</fpage><lpage>1347</lpage><pub-id pub-id-type="pmid">20385727</pub-id></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolpert</surname><given-names>DH</given-names></name></person-group><article-title>Stacked generalization</article-title><source>Neural Netw</source><year>1992</year><volume>5</volume><fpage>241</fpage><lpage>259</lpage></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levine</surname><given-names>ME</given-names></name></person-group><article-title>Modeling the rate of senescence: can estimated biological age predict mortality more accurately than chronological age?</article-title><source>J. Gerontol. A Biol. Sci. Med. Sci</source><year>2013</year><volume>68</volume><fpage>667</fpage><lpage>674</lpage><pub-id pub-id-type="pmid">23213031</pub-id></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheng</surname><given-names>S</given-names></name><name><surname>Larson</surname><given-names>MG</given-names></name><name><surname>McCabe</surname><given-names>EL</given-names></name><name><surname>Murabito</surname><given-names>JM</given-names></name><name><surname>Rhee</surname><given-names>EP</given-names></name><name><surname>Ho</surname><given-names>JE</given-names></name><etal/></person-group><article-title>Distinct metabolomic signatures are associated with longevity in humans</article-title><source>Nat. Commun</source><year>2015</year><volume>6</volume><fpage>6791</fpage><pub-id pub-id-type="pmid">25864806</pub-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>AA</given-names></name><name><surname>Milot</surname><given-names>E</given-names></name><name><surname>Li</surname><given-names>Q</given-names></name><name><surname>Bergeron</surname><given-names>P</given-names></name><name><surname>Poirier</surname><given-names>R</given-names></name><name><surname>Dusseault-B&#x000e9;langer</surname><given-names>F</given-names></name><etal/></person-group><article-title>Detection of a novel, integrative aging process suggests complex physiological integration</article-title><source>PLoS One</source><year>2015</year><volume>10</volume><fpage>e0116489</fpage><pub-id pub-id-type="pmid">25761112</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>J</given-names></name><name><surname>Cho</surname><given-names>B</given-names></name><name><surname>Kwon</surname><given-names>H</given-names></name><name><surname>Lee</surname><given-names>C</given-names></name></person-group><article-title>Developing a biological age assessment equation using principal component analysis and clinical biomarkers of aging in Korean men</article-title><source>Arch. Gerontol. Geriatr</source><year>2009</year><volume>49</volume><fpage>7</fpage><lpage>12</lpage><pub-id pub-id-type="pmid">18597867</pub-id></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Visser</surname><given-names>M</given-names></name><name><surname>Kritchevsky</surname><given-names>SB</given-names></name><name><surname>Newman</surname><given-names>AB</given-names></name><name><surname>Goodpaster</surname><given-names>BH</given-names></name><name><surname>Tylavsky</surname><given-names>FA</given-names></name><name><surname>Nevitt</surname><given-names>MC</given-names></name><etal/></person-group><article-title>Lower serum albumin concentration and change in muscle mass: the Health, Aging and Body Composition Study</article-title><source>Am. J. Clin. Nutr</source><year>2005</year><volume>82</volume><fpage>531</fpage><lpage>537</lpage><pub-id pub-id-type="pmid">16155264</pub-id></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="book"><person-group person-group-type="author"><collab>World Health Organization</collab></person-group><source>Health in 2015: from MDGs, Millennium Development Goals to SDGs, Sustainable Development Goals</source><publisher-name>WHO (World Health Organization)</publisher-name><year>2015</year></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Elnegaard</surname><given-names>S</given-names></name><name><surname>Andersen</surname><given-names>RS</given-names></name><name><surname>Pedersen</surname><given-names>AF</given-names></name><name><surname>Larsen</surname><given-names>PV</given-names></name><name><surname>S&#x000f8;ndergaard</surname><given-names>J</given-names></name><name><surname>Rasmussen</surname><given-names>S</given-names></name><etal/></person-group><source>Self-reported symptoms and healthcare seeking in the general population--exploring &#x0201c;The Symptom Iceberg.&#x0201d;</source><publisher-name>BMC Public Health</publisher-name><year>2015</year><volume>15</volume><fpage>685</fpage></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Devreese</surname><given-names>K</given-names></name><name><surname>De Logi</surname><given-names>E</given-names></name><name><surname>Francart</surname><given-names>C</given-names></name><name><surname>Heyndrickx</surname><given-names>B</given-names></name><name><surname>Philipp&#x000e9;</surname><given-names>J</given-names></name><name><surname>Leroux-Roels</surname><given-names>G</given-names></name></person-group><article-title>Evaluation of the automated haematology analyser Sysmex NE-8000</article-title><source>Eur. J. Clin. Chem. Clin. Biochem</source><year>1991</year><volume>29</volume><fpage>339</fpage><lpage>345</lpage><pub-id pub-id-type="pmid">1892955</pub-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hansen</surname><given-names>LK</given-names></name><name><surname>Grimm</surname><given-names>RH</given-names></name><name><surname>Neaton</surname><given-names>JD</given-names></name></person-group><article-title>The Relationship of White Blood Cell Count to Other Cardiovascular Risk Factors</article-title><source>Int. J. Epidemiol</source><year>1990</year><volume>19</volume><fpage>881</fpage><lpage>888</lpage><pub-id pub-id-type="pmid">2084016</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boudjeltia</surname><given-names>KZ</given-names></name><name><surname>Faraut</surname><given-names>B</given-names></name><name><surname>Stenuit</surname><given-names>P</given-names></name><name><surname>Esposito</surname><given-names>MJ</given-names></name><name><surname>Dyzma</surname><given-names>M</given-names></name><name><surname>Broh&#x000e9;e</surname><given-names>D</given-names></name><etal/></person-group><article-title>Sleep restriction increases white blood cells, mainly neutrophil count, in young healthy men: a pilot study</article-title><source>Vasc. Health Risk Manag</source><year>2008</year><volume>4</volume><fpage>1467</fpage><lpage>1470</lpage><pub-id pub-id-type="pmid">19337560</pub-id></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Babio</surname><given-names>N</given-names></name><name><surname>Ibarrola-Jurado</surname><given-names>N</given-names></name><name><surname>Bull&#x000f3;</surname><given-names>M</given-names></name><name><surname>Mart&#x000ed;nez-Gonz&#x000e1;lez</surname><given-names>M&#x000c1;</given-names></name><name><surname>W&#x000e4;rnberg</surname><given-names>J</given-names></name><name><surname>Salaverr&#x000ed;a</surname><given-names>I</given-names></name><etal/></person-group><article-title>White blood cell counts as risk markers of developing metabolic syndrome and its components in the PREDIMED study</article-title><source>PLoS One</source><year>2013</year><volume>8</volume><fpage>e58354</fpage><pub-id pub-id-type="pmid">23526980</pub-id></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Twig</surname><given-names>G</given-names></name><name><surname>Afek</surname><given-names>A</given-names></name><name><surname>Shamiss</surname><given-names>A</given-names></name><name><surname>Derazne</surname><given-names>E</given-names></name><name><surname>Tzur</surname><given-names>D</given-names></name><name><surname>Gordon</surname><given-names>B</given-names></name><etal/></person-group><article-title>White blood cells count and incidence of type 2 diabetes in young men</article-title><source>Diabetes Care</source><year>2013</year><volume>36</volume><fpage>276</fpage><lpage>282</lpage><pub-id pub-id-type="pmid">22961572</pub-id></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Breiman</surname><given-names>L</given-names></name><name><surname>Leo</surname><given-names>B</given-names></name><name><surname>Michael</surname><given-names>L</given-names></name><name><surname>John</surname><given-names>R</given-names></name></person-group><article-title>Random Forests: Finding Quasars</article-title><source>Statistical Challenges in Astronomy</source><year>2001</year><fpage>243</fpage><lpage>254</lpage></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>K</given-names></name><name><surname>Kaiming</surname><given-names>H</given-names></name><name><surname>Xiangyu</surname><given-names>Z</given-names></name><name><surname>Shaoqing</surname><given-names>R</given-names></name><name><surname>Jian</surname><given-names>S</given-names></name></person-group><article-title>Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</article-title><source>IEEE International Conference on Computer Vision (ICCV) Internet</source><year>2015</year><fpage>2015</fpage></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duchi</surname><given-names>J</given-names></name><name><surname>Hazan</surname><given-names>E</given-names></name><name><surname>Singer</surname><given-names>Y</given-names></name></person-group><article-title>Adaptive subgradient methods for online learning and stochastic optimization</article-title><source>J. Mach. Learn. Res</source><year>2011</year><volume>12</volume><fpage>2121</fpage><lpage>2159</lpage></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Srivastava</surname><given-names>N</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name><name><surname>Krizhevsky</surname><given-names>A</given-names></name><name><surname>Sutskever</surname><given-names>I</given-names></name><name><surname>Salakhutdinov</surname><given-names>R</given-names></name></person-group><article-title>Dropout: A simple way to prevent neural networks from overfitting</article-title><source>J. Mach. Learn. Res</source><year>2014</year><volume>15</volume><fpage>1929</fpage><lpage>1958</lpage></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moody</surname><given-names>J</given-names></name><name><surname>Hanson</surname><given-names>S</given-names></name><name><surname>Krogh</surname><given-names>A</given-names></name><name><surname>Hertz</surname><given-names>JA</given-names></name></person-group><article-title>A simple weight decay can improve generalization</article-title><source>Adv. Neural Inf. Process. Syst</source><year>1995</year><volume>4</volume><fpage>950</fpage><lpage>957</lpage></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Ioffe</surname><given-names>S</given-names></name><name><surname>Szegedy</surname><given-names>C</given-names></name></person-group><article-title>Batch normalization: Accelerating deep network training by reducing internal covariate shift</article-title><comment>arXiv preprint</comment><year>2015</year><comment>arXiv:1502.03167</comment></element-citation></ref></ref-list></back></article>