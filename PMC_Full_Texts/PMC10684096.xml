<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd"> 
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-journalpublishing1.dtd?><?SourceDTD.Version 39.96?><?ConverterInfo.XSLTName jats2jats3.xsl?><?ConverterInfo.Version 1?><?subarticle pone.0294812.r001?><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS One</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-title-group><journal-title>PLOS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">10684096</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0294812</article-id><article-id pub-id-type="publisher-id">PONE-D-23-16263</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Data Management</subject><subj-group><subject>Metadata</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Artificial Intelligence</subject><subj-group><subject>Machine Learning</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Information Technology</subject><subj-group><subject>Natural Language Processing</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Information Technology</subject><subj-group><subject>Text Mining</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Information Technology</subject><subj-group><subject>Natural Language Processing</subject><subj-group><subject>Named Entity Recognition</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Research Facilities</subject><subj-group><subject>Information Centers</subject><subj-group><subject>Archives</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Science Policy</subject><subj-group><subject>Open Science</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Research Assessment</subject><subj-group><subject>Reproducibility</subject></subj-group></subj-group></subj-group></article-categories><title-group><article-title>A machine learning-enabled open biodata resource inventory from the scientific literature</article-title><alt-title alt-title-type="running-head">A machine learning-enabled open biodata resource inventory from the scientific literature</alt-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4748-7453</contrib-id><name><surname>Imker</surname><given-names>Heidi J.</given-names></name><role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role><role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff001" ref-type="aff">
<sup>1</sup>
</xref><xref rid="aff002" ref-type="aff">
<sup>2</sup>
</xref><xref rid="cor001" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1658-3699</contrib-id><name><surname>Schackart</surname><given-names>Kenneth E.</given-names><suffix>III</suffix></name><role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/software/">Software</role><role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role><role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff001" ref-type="aff">
<sup>1</sup>
</xref><xref rid="aff003" ref-type="aff">
<sup>3</sup>
</xref></contrib><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7953-5168</contrib-id><name><surname>Istrate</surname><given-names>Ana-Maria</given-names></name><role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/software/">Software</role><role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role><role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff004" ref-type="aff">
<sup>4</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Cook</surname><given-names>Charles E.</given-names></name><role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role><role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff001" ref-type="aff">
<sup>1</sup>
</xref></contrib></contrib-group><aff id="aff001"><label>1</label>
<addr-line>Global Biodata Coalition, Strasbourg, France</addr-line></aff><aff id="aff002"><label>2</label>
<addr-line>University Library, University of Illinois at Urbana-Champaign, Urbana, Illinois, United States of America</addr-line></aff><aff id="aff003"><label>3</label>
<addr-line>Department of Biosystems Engineering, The University of Arizona, Tucson, Arizona, United States of America</addr-line></aff><aff id="aff004"><label>4</label>
<addr-line>Chan Zuckerberg Initiative, Redwood City, California, United States of America</addr-line></aff><contrib-group><contrib contrib-type="editor"><name><surname>Bernasconi</surname><given-names>Anna</given-names></name><role>Editor</role><xref rid="edit1" ref-type="aff"/></contrib></contrib-group><aff id="edit1">
<addr-line>Politecnico di Milano, ITALY</addr-line>
</aff><author-notes><fn fn-type="COI-statement" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><corresp id="cor001">* E-mail: <email>imker@illinois.edu</email></corresp></author-notes><pub-date pub-type="epub"><day>28</day><month>11</month><year>2023</year></pub-date><pub-date pub-type="collection"><year>2023</year></pub-date><volume>18</volume><issue>11</issue><elocation-id>e0294812</elocation-id><history><date date-type="received"><day>26</day><month>5</month><year>2023</year></date><date date-type="accepted"><day>7</day><month>11</month><year>2023</year></date></history><permissions><copyright-statement>&#x000a9; 2023 Imker et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Imker et al</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="pone.0294812.pdf"/><abstract><p>Modern biological research depends on data resources. These resources archive difficult-to-reproduce data and provide added-value aggregation, curation, and analyses. Collectively, they constitute a global infrastructure of biodata resources. While the organic proliferation of biodata resources has enabled incredible research, sustained support for the individual resources that make up this distributed infrastructure is a challenge. The Global Biodata Coalition (GBC) was established by research funders in part to aid in developing sustainable funding strategies for biodata resources. An important component of this work is understanding the scope of the resource infrastructure; how many biodata resources there are, where they are, and how they are supported. Existing registries require self-registration and/or extensive curation, and we sought to develop a method for assembling a global inventory of biodata resources that could be periodically updated with minimal human intervention. The approach we developed identifies biodata resources using open data from the scientific literature. Specifically, we used a machine learning-enabled natural language processing approach to identify biodata resources from titles and abstracts of life sciences publications contained in Europe PMC. Pretrained BERT (Bidirectional Encoder Representations from Transformers) models were fine-tuned to classify publications as describing a biodata resource or not and to predict the resource name using named entity recognition. To improve the quality of the resulting inventory, low-confidence predictions and potential duplicates were manually reviewed. Further information about the resources were then obtained using article metadata, such as funder and geolocation information. These efforts yielded an inventory of 3112 unique biodata resources based on articles published from 2011&#x02013;2021. The code was developed to facilitate reuse and includes automated pipelines. All products of this effort are released under permissive licensing, including the biodata resource inventory itself (CC0) and all associated code (BSD/MIT).</p></abstract><funding-group><award-group id="award001"><funding-source>
<institution>Global Biodata Coalition</institution>
</funding-source><principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4748-7453</contrib-id>
<name><surname>Imker</surname><given-names>Heidi J.</given-names></name>
</principal-award-recipient></award-group><award-group id="award002"><funding-source>
<institution-wrap><institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100014989</institution-id><institution>Chan Zuckerberg Initiative</institution></institution-wrap>
</funding-source><principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7953-5168</contrib-id>
<name><surname>Istrate</surname><given-names>Ana-Maria</given-names></name>
</principal-award-recipient></award-group><funding-statement>This project was initiated by the Global Biodata Coalition as part of its programme of work, and which supported the work of CEC, KES, and HJI in planning and implementing the project. The Chan Zuckerberg Initiative supported the work of AMI in the development of machine learning methods.</funding-statement></funding-group><counts><fig-count count="8"/><table-count count="3"/><page-count count="28"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>All code and data are archived in Zenodo along with associated documentation at <ext-link xlink:href="https://zenodo.org/doi/10.5281/zenodo.10105161" ext-link-type="uri">https://zenodo.org/doi/10.5281/zenodo.10105161</ext-link>. The final inventory and its associated data dictionary are available as a separate Zenodo deposit at <ext-link xlink:href="https://zenodo.org/doi/10.5281/zenodo.10105947" ext-link-type="uri">https://zenodo.org/doi/10.5281/zenodo.10105947</ext-link>. Additionally, all materials are also available on GitHub at <ext-link xlink:href="https://github.com/globalbiodata/inventory_2022/" ext-link-type="uri">https://github.com/globalbiodata/inventory_2022/</ext-link>, which may be updated from the time of this publication. To facilitate exploration, an Open Science Products Table (<xref rid="pone.0294812.s011" ref-type="supplementary-material">S7 Table</xref>) provides the location of specific items.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>All code and data are archived in Zenodo along with associated documentation at <ext-link xlink:href="https://zenodo.org/doi/10.5281/zenodo.10105161" ext-link-type="uri">https://zenodo.org/doi/10.5281/zenodo.10105161</ext-link>. The final inventory and its associated data dictionary are available as a separate Zenodo deposit at <ext-link xlink:href="https://zenodo.org/doi/10.5281/zenodo.10105947" ext-link-type="uri">https://zenodo.org/doi/10.5281/zenodo.10105947</ext-link>. Additionally, all materials are also available on GitHub at <ext-link xlink:href="https://github.com/globalbiodata/inventory_2022/" ext-link-type="uri">https://github.com/globalbiodata/inventory_2022/</ext-link>, which may be updated from the time of this publication. To facilitate exploration, an Open Science Products Table (<xref rid="pone.0294812.s011" ref-type="supplementary-material">S7 Table</xref>) provides the location of specific items.</p></notes></front><body><sec sec-type="intro" id="sec001"><title>1. Introduction</title><p>Scientists have long undertaken major infrastructure projects that examine large-scale scientific questions. Such initiatives often require sustained long-term support, frequently from a defined set of funders, for decades. The physical sciences have been especially adept at establishing infrastructures to produce data that are critically important for furthering scientific understanding. Typically, these projects, for example the large hadron collider at CERN and the James Webb Space telescope, are tangible structures or instruments that have well-defined physical locations (whether on earth or in space). Because they are tangible objects, the funders and the taxpayers who ultimately support the infrastructure can readily understand both how funds are spent and the necessity of long-term support in order to ensure that returns on the high initial investments are maximized.</p><p>In contrast, the life sciences&#x02019; data infrastructure is highly distributed and largely virtual. There are thousands of distinct systems that provide access to structured biological data, collectively referred to as biodata resources. These resources archive difficult-to-reproduce data and also provide added-value aggregation, curation, and analysis to those archived data. Biodata resources are found throughout the world, vary in scale, and are supported by hundreds of funding bodies, institutions, and charitable foundations. This distributed infrastructure has grown dramatically over the past three or four decades as technological advances, such as in nucleotide sequencing, enabled exponential increases in the amount and types of data generated. However, and again unlike physical sciences, growth has been organic and driven locally. In the life sciences, individual researchers and institutions sought or provided funding to create each data resource, with new resources joining the infrastructure individually when they begin exchanging data with other resources.</p><p>The impact of biodata resources on life science research has been immense, and a number of efforts have been launched in recent years to improve their coordination and long-term sustainability. In Europe, ELIXIR was established in 2013 as an intergovernmental organization to coordinate life science data infrastructure. As part of ELIXIR&#x02019;s mission, they identified a set of European Core Biodata Resources that are of &#x0201c;fundamental importance&#x0201d; to research and show &#x0201c;wide applicability and usage&#x0201d; based on a set of quantitative and qualitative indicators. Initially, 19 resources were identified (now 22 after additional selection rounds), and literature mentions and citations show incredible reach. In an analysis of Europe PMC&#x02019;s full text articles, 17% were found to refer to a core resource [<xref rid="pone.0294812.ref001" ref-type="bibr">1</xref>].</p><p>Despite their critical importance for the life sciences research endeavor, biodata resources are usually funded precariously through short-term grants (generally 3&#x02013;5 years) [<xref rid="pone.0294812.ref001" ref-type="bibr">1</xref>&#x02013;<xref rid="pone.0294812.ref003" ref-type="bibr">3</xref>]. Research funders provide support for many of the biodata resources that comprise the biodata infrastructure, and they recognize both the need for long-term support of data resources and the challenges associated with creating long-term funding streams for such support [<xref rid="pone.0294812.ref004" ref-type="bibr">4</xref>]. While not all resources should live on in perpetuity, there is collective interest in establishing alternate funding mechanisms to stabilize the resources that make up the infrastructure [<xref rid="pone.0294812.ref005" ref-type="bibr">5</xref>]. In recognition of this challenge, research funders supported creation of the Global Biodata Coalition (GBC; globalbiodata.org) to aid them in coordinating funding for biodata resources and to develop mechanisms to more efficiently fund the biodata infrastructure. A basic requirement for coordinating support for this infrastructure is to understand its scope: how many biodata resources are there and where are they located? However, because biodata resources have been developed and managed independently of each other, this global overview is missing.</p><p>There have been many efforts to catalog biodata resources over the years. An early example is DBCat, launched in 1999 by the EMBnet branch Infobiogen, which used a combination of general web searches, journal review, and contributions from resource providers to assemble a list of 511 resources [<xref rid="pone.0294812.ref006" ref-type="bibr">6</xref>]. Another effort in the biodiversity community found over 600 biodiversity information projects between 2005&#x02013;2006 based on 100 hours of consulting effort [<xref rid="pone.0294812.ref007" ref-type="bibr">7</xref>]. There are also partial lists created by research funders [<xref rid="pone.0294812.ref008" ref-type="bibr">8</xref>], academic libraries [<xref rid="pone.0294812.ref009" ref-type="bibr">9</xref>], scholarly publishers [<xref rid="pone.0294812.ref010" ref-type="bibr">10</xref>], and Wikipedia [<xref rid="pone.0294812.ref011" ref-type="bibr">11</xref>]. The journal <italic toggle="yes">Nucleic Acids Research</italic> also maintains a catalogue of primarily molecular biology-related databases, the vast majority of which are described in one of the annual database issues of that journal [<xref rid="pone.0294812.ref012" ref-type="bibr">12</xref>].</p><p>Blair et al. [<xref rid="pone.0294812.ref007" ref-type="bibr">7</xref>] noted that catalogs quickly become outdated if static and are subject to funding and staffing challenges themselves. Indeed, the largest collection of molecular biology databases is Database Commons, hosted by National Genomics Data Center in Beijing China, which has developed its 5000+ record collection with contributions from over 50 curators. An alternative is encouraging resource owners to register their own resources. Currently, there are several options for such registration, including re3data.org [<xref rid="pone.0294812.ref013" ref-type="bibr">13</xref>], FAIRsharing [<xref rid="pone.0294812.ref014" ref-type="bibr">14</xref>], and the SciCrunch Registry [<xref rid="pone.0294812.ref015" ref-type="bibr">15</xref>]. All three actively encourage registration and include between ~ 1500 to ~ 3000 biodata resources, depending on interpretation of categories. Registration preliminarily happens in one of two ways; either a resource owner registers their resource themselves or another person, such as a curator at the registry, submits a record for the resource. The former path requires awareness of the registry and the latter path requires awareness of the resource, a loop that is a perennial challenge to close.</p><p>Given the interest from many different perspectives and the challenge of documenting the ever-growing life sciences infrastructure, we sought a method of assembling a global inventory of biodata resources and creating a process that would allow periodic updates. Here we describe the results of a reproducible, machine learning-enabled method to create this inventory by identifying biodata resources described in scientific articles between 2011&#x02013;2021. The inventory developed, which contains 3112 resources, represents a use case-focused practical application of machine learning to address a question of interest to research funders and other stakeholders who support and use biodata resources across the globe. BERT (Bidirectional Encoder Representations from Transformers) models and the resulting metrics (i.e., F1, precision, and recall) were used in an exploratory manner to guide article classification and extraction of biodata resource names. To facilitate reuse, we released the inventory under CC0 licensing along with code available under BSD/MIT licensing; the code includes the machine learning steps in an automated pipeline plus scripts that extract value-add information about the identified resources from the metadata of associated articles. Along with a presentation of the methodology, we also provide a preliminary analysis of the inventory to demonstrate the potential for its reuse and augmentation.</p></sec><sec sec-type="materials|methods" id="sec002"><title>2. Methods</title><sec id="sec003"><title>2.1. Design overview</title><p>In order to create an open, reproducible inventory we needed a large source of open data that contains information about biodata resources and is structured enough to enable programmatic access. Text mining the scientific literature has been used to locate resources in previous studies, and Wren et al. combined this strategy with crowdsourcing to classify over 20,000 URLs extracted from MEDLINE abstracts, including 4757 that were designated as databases [<xref rid="pone.0294812.ref016" ref-type="bibr">16</xref>]. While Wren et al. did not identify resource names or locations, the high number of results suggested that scientific abstracts are a viable data source for identifying a large cache of resources. Furthermore, articles in centralized literature services are associated with high-quality metadata available via robust APIs. This means associated metadata, such as title, abstract, authors, author affiliations, funders, and citations, can be used to extract or infer information about the biodata resource itself, even when full text articles are paywalled. Additional metadata associated with the resource URL extracted from the abstract (e.g., HTTP status and IP location) also allows collection of a set of useful characteristics for each inventoried resource. While there are limitations to this strategy since not all resource owners publish articles describing their biodata resources, many do. We hypothesized that we could not only create a large inventory that could be of use in and of itself, but freely releasing the inventory and the associated code would allow for reproducibility and extension by others. Given broad interest in the topic, we were particularly motivated by the idea that others may wish to subset or augment the inventory for other purposes.</p><p>Europe PMC is a large data resource of life sciences literature with an API allowing full access to the entire resource [<xref rid="pone.0294812.ref017" ref-type="bibr">17</xref>]. Using the strategy described above, we developed a targeted query to retrieve from Europe PMC a corpus of articles and then tested and used a machine-learning based approach to identify biodata resources named in this corpus (<xref rid="pone.0294812.g001" ref-type="fig">Fig 1</xref>). Openly available pretrained language models are currently state-of-the-art in natural language processing (NLP), achieving high performance on a variety of tasks such as Named Entity Recognition (NER), Question Answering, summarization, and machine translation. These models have also been adapted to the biomedical field by pretraining on domain-specific corpora (e.g., BioBERT, SciBERT, PubmedBERT). We defined two tasks: article classification, which aimed to classify a research article (based on the title and abstract) as being about a biodata resource or not, and NER, which extracted the exact mentions of biodata resources from text. We experimented with several of these pretrained language models relevant to the biomedical field by fine tuning them on these two tasks. We used a regular expression algorithm to extract URLs corresponding to the biodata resources and checked their HTTP response statuses and locations. With articles and their biodata resources defined, we then accessed additional metadata to further characterize individual resources, as mentioned above. This entire workflow was automated and made reproducible by implementing it in a Snakemake pipeline [<xref rid="pone.0294812.ref018" ref-type="bibr">18</xref>]. To maximize utility across a wide variety of potential users, the results have been made available as shown in the Open Science Products Table (<xref rid="pone.0294812.s011" ref-type="supplementary-material">S7 Table</xref>).</p><fig position="float" id="pone.0294812.g001"><object-id pub-id-type="doi">10.1371/journal.pone.0294812.g001</object-id><label>Fig 1</label><caption><title>Flowchart of overall study design to identify biodata resources from the scientific literature.</title><p>Study design for creating an inventory of biodata resources starting with a targeted query of articles found in Europe PMC, predicting biodata resources from article titles and abstracts using NLP, then reviewing and augmenting with additional metadata from Europe PMC to create the final inventory.</p></caption><graphic xlink:href="pone.0294812.g001" position="float"/></fig></sec><sec id="sec004"><title>2.2. Open science implementation plan</title><p>At the start of the project, an Open Science Implementation Plan was created in order to clearly articulate our Open Science goals. The plan guided decision-making, allocation of time and resources, and the ultimate products of the project. The plan has four components: Reproducibility Standards, Code Standards, Data Standards, and External Review/Validation [<xref rid="pone.0294812.ref019" ref-type="bibr">19</xref>]. An account of our efforts to adhere to this plan, including a detailed description of steps taken to follow reproducibility standards outlined by Heil et al., are described in a companion article [<xref rid="pone.0294812.ref020" ref-type="bibr">20</xref>, <xref rid="pone.0294812.ref021" ref-type="bibr">21</xref>].</p></sec><sec id="sec005"><title>2.3. Working definitions</title><p>Creating the inventory required definitions of &#x0201c;biodata&#x0201d; and &#x0201c;biodata resource&#x0201d; explicit enough to allow human curators to evaluate articles and create a training dataset for the machine learning models. For this inventory, which is intended to be of use to funders of basic research worldwide, we specifically excluded clinical and patient data resources that appeared to be aimed at clinical or diagnostic use rather than for use in research. We reviewed both formal ontologies and generic definitions related to the life sciences and the basic sciences (<xref rid="pone.0294812.s005" ref-type="supplementary-material">S1 Table</xref>) to assemble a working definition that reflected the objective of the inventory. The <italic toggle="yes">life science biodata</italic> definition used was &#x0201c;Biodata created through studies of living organisms and their associated life processes through research conducted for the specific purpose of acquiring fundamental knowledge; this knowledge forms the basis of testable theories that aim to increase our ability to understand, interpret, and predict the phenomena that impact these organisms and processes.&#x0201d;</p><p>To define &#x0201c;biodata resource&#x0201d; we likewise reviewed existing formal and general definitions (see <xref rid="pone.0294812.s006" ref-type="supplementary-material">S2 Table</xref>), including those from re3data.org, ELIXIR, the US National Institutes of Health, and the US Department of Energy as well as standards such as the <ext-link xlink:href="https://bioportal.bioontology.org/ontologies/BRO" ext-link-type="uri">Biomedical Resource Ontology</ext-link> and W3C&#x02019;s Data Catalog Vocabulary (DCAT). The <italic toggle="yes">data resource</italic> definition used was &#x0201c;An online source of structured data. The data cannot be a copy readily obtained from another resource (e.g., must be primary data or data annotated, curated, or otherwise augmented with value-added elements that are unique to the resource). The resource must have a distinct name and interface for browsing, searching, querying, viewing, and/or downloading the data within. Mechanisms such as an API may be the main access method, but there still must be a distinct online presence that provides information about the data available. Analysis tools may be provided, but information about and access to the underlying, unique data must be clearly available to users visiting the resource.&#x0201d;</p><p>A particular challenge for this project was distinguishing biodata resources, which explicitly provide access to data, from tools that provide analysis or visualization of data, either through an inaccessible background database or via input by a user. In cases where the resource appeared to be both a source of biodata and a tool, it was included in the inventory.</p></sec><sec id="sec006"><title>2.4. Data sources and query development</title><p>To ensure that all project data are freely distributable and that the inventory may be updated programmatically in future, only open public data accessible via an API was used. The Europe PMC API was accessed using the Python requests library (v2.27.1) [<xref rid="pone.0294812.ref022" ref-type="bibr">22</xref>] to gather English-language articles that potentially describe a biodata data resource. The query for Europe PMC was iteratively developed to enrich the corpus with articles that potentially describe a biodata resource. Strings with various biodata resource-related terms and degrees of complexity were tested and the number and quality of results were manually inspected. On investigation, some initially promising terms were ruled out. For example, &#x0201c;repository&#x0201d; was often found in reference to code repositories. This resulted in a large number of false positives and created curation and classification challenges when associated with data analysis servers. We also looked at the impact of limiting the results to Open Access (OA) articles, which would enable more analysis later via the full text. However, restricting the query to OA returned less than half as many articles and was judged overly restrictive for the first step of the pipeline. In the converse, excluding terms to identify URLs returned millions of articles, only a very small fraction of which would describe a resource. Operators were also experimented with, and known true positives were used throughout as a check. After mid-project evaluation (see section 2.6 below), small adjustments to the query were made to exclude additional common false positives identified. The final query string was developed to locate abstracts that contained a URL and a small set of focused keywords that suggested the articles described a data resource while excluding retracted articles and those that include general URLs (e.g., for clinical trial registrations). The final query string used is shown in <xref rid="pone.0294812.s001" ref-type="supplementary-material">S1 Fig</xref> and provided in the project&#x02019;s data deposits and git repositories. To accommodate other queries, which may be better optimized or tailored to reflect a different use case (e.g., different year range, etc.), the pipeline developed calls for a user-provided query file, and tests in the code verify that the query passes successfully to Europe PMC.</p><p>Data retrieved from the re3data.org and FAIRsharing APIs are licensed for reuse and were used to benchmark the resulting inventory. Finally, Wayback Machine URLs and geo coordinates were retrieved via the Internet Archive Wayback Availability, ipinfo, and ip-api APIs as indicated in <xref rid="pone.0294812.s007" ref-type="supplementary-material">S3 Table</xref>.</p></sec><sec id="sec007"><title>2.5. Natural language processing (NLP) tasks</title><p>To generate the inventory from open data several natural language processing (NLP) methods were employed. ML models were trained to perform article classification and named entity recognition (NER) to identify articles describing biodata resources and extract their names. A regular expression was used to extract the URLs from the abstracts of predicted biodata resources. This workflow for the NLP tasks is shown in <xref rid="pone.0294812.g002" ref-type="fig">Fig 2</xref>, and details about the ML methods are covered in the section below.</p><fig position="float" id="pone.0294812.g002"><object-id pub-id-type="doi">10.1371/journal.pone.0294812.g002</object-id><label>Fig 2</label><caption><title>Flowchart of the process used to extract mentions and URLs of biodata resources.</title><p>The article title and abstract are first fed into an article classification model, which determines if the article is about a biodata resource or not. Articles that are classified as being about a biodata resource are then fed into an additional Named Entity Recognition (NER) model which extracts the name(s) of the biodata resource and reports the average probability score of the tokens constituting the predicted name. A regular-expression based URL extraction algorithm separately extracts URLs from the abstract. In this example, the NER model extracted both a &#x0201c;full name&#x0201d; (Protein Data Bank) and a &#x0201c;common name&#x0201d; (PDB) for the resource, both of which are valid in this case.</p></caption><graphic xlink:href="pone.0294812.g002" position="float"/></fig><sec id="sec008"><title>2.5.1 Training data</title><p>To create the training dataset needed to develop a classifier via machine learning, a random sample of records returned from the query above was selected for manual review. The training set was created in two phases, with the first containing 638 records and second containing an additional 996 records for a total of 1634 records in the training dataset. Article titles and abstracts were independently reviewed by two curators in each phase and classified as either describing a biodata resource or not describing a biodata resource based on the developed definitions (see above). We kept the entries where both curators agreed on the article classification label (either positive or negative, n = 1587) and used this as a training dataset for the article classification task. For articles manually classified as describing a biodata resource, mentions of biodata resources in the title and abstract were identified, including &#x0201c;common names&#x0201d; (e.g., PDB) and &#x0201c;full names&#x0201d; (e.g., Protein Data Bank). This curated set of mentions was used for the NER task. Both training datasets were split into 70% training, 15% validation, 15% test (hold-out) for article classification (<xref rid="pone.0294812.t001" ref-type="table">Table 1</xref>) and NER tasks (<xref rid="pone.0294812.t002" ref-type="table">Table 2</xref>). Following common practice, the training sets were used to fine-tune the models on their respective tasks, the validation sets were used to compare the fine-tuned models for selection, and the test sets were used to evaluate how the models perform on unseen data [<xref rid="pone.0294812.ref023" ref-type="bibr">23</xref>].</p><table-wrap position="float" id="pone.0294812.t001"><object-id pub-id-type="doi">10.1371/journal.pone.0294812.t001</object-id><label>Table 1</label><caption><title>Training dataset splits for the article classification task.</title></caption><alternatives><graphic xlink:href="pone.0294812.t001" id="pone.0294812.t001g" position="float"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1">Train</th><th align="center" rowspan="1" colspan="1">Validation</th><th align="center" rowspan="1" colspan="1">Test</th><th align="center" rowspan="1" colspan="1">Total</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Positive labels</td><td align="center" rowspan="1" colspan="1">337 (30.4%)</td><td align="center" rowspan="1" colspan="1">61 (25.6%)</td><td align="center" rowspan="1" colspan="1">80 (33.5%)</td><td align="center" rowspan="1" colspan="1">478</td></tr><tr><td align="left" rowspan="1" colspan="1">Negative labels</td><td align="center" rowspan="1" colspan="1">773 (69.6%)</td><td align="center" rowspan="1" colspan="1">177 (74.4%)</td><td align="center" rowspan="1" colspan="1">159 (66.5%)</td><td align="center" rowspan="1" colspan="1">1109</td></tr><tr><td align="left" rowspan="1" colspan="1">Articles</td><td align="center" rowspan="1" colspan="1">1110</td><td align="center" rowspan="1" colspan="1">238</td><td align="center" rowspan="1" colspan="1">239</td><td align="center" rowspan="1" colspan="1">1587</td></tr></tbody></table></alternatives></table-wrap><table-wrap position="float" id="pone.0294812.t002"><object-id pub-id-type="doi">10.1371/journal.pone.0294812.t002</object-id><label>Table 2</label><caption><title>Training dataset splits for the Named Entity Recognition (NER) task.</title></caption><alternatives><graphic xlink:href="pone.0294812.t002" id="pone.0294812.t002g" position="float"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1">Train</th><th align="center" rowspan="1" colspan="1">Validation</th><th align="center" rowspan="1" colspan="1">Test</th><th align="center" rowspan="1" colspan="1">Total</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Articles</td><td align="center" rowspan="1" colspan="1">306</td><td align="center" rowspan="1" colspan="1">66</td><td align="center" rowspan="1" colspan="1">66</td><td align="center" rowspan="1" colspan="1">438</td></tr><tr><td align="left" rowspan="1" colspan="1">Biodata resource mentions</td><td align="center" rowspan="1" colspan="1">1192</td><td align="center" rowspan="1" colspan="1">269</td><td align="center" rowspan="1" colspan="1">293</td><td align="center" rowspan="1" colspan="1">1754</td></tr></tbody></table></alternatives></table-wrap></sec><sec sec-type="materials|methods" id="sec009"><title>2.5.2. Models</title><p>Two machine learning models were fine-tuned to automate the process of 1) classifying research articles and 2) extracting mentions of biodata resources from those predicted to describe a biodata resource. Given a paper&#x02019;s title and abstract, the article classification model classifies the paper as being about a biodata resource or not. If an article receives a positive score, it is then passed through the NER model, which extracts the common name and full name of the biodata resource from the text, if they are present. A confidence score, computed as the average probability among the tokens constituting the mention, is also output (<xref rid="pone.0294812.s002" ref-type="supplementary-material">S2 Fig</xref>). BERT performs well on a variety of NLP tasks and several BERT derivatives have been pre-trained on biomedical corpora, making them excellent candidates for this project. For both the article classification and NER task, BERT itself and 14 other BERT model variations available on Hugging Face Hub (<ext-link xlink:href="https://huggingface.co/" ext-link-type="uri">https://huggingface.co/</ext-link>) were fine-tuned and evaluated to select the highest performing model (<xref rid="pone.0294812.t003" ref-type="table">Table 3</xref> and citations therein).</p><table-wrap position="float" id="pone.0294812.t003"><object-id pub-id-type="doi">10.1371/journal.pone.0294812.t003</object-id><label>Table 3</label><caption><title>Pre-trained models that were fine-tuned for the article classification and NER tasks.</title></caption><alternatives><graphic xlink:href="pone.0294812.t003" id="pone.0294812.t003g" position="float"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Model</th><th align="left" rowspan="1" colspan="1">Hugging Face Model Name</th><th align="left" rowspan="1" colspan="1">Citation</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">BERT</td><td align="left" rowspan="1" colspan="1">&#x0201c;bert-base-uncased&#x0201d;</td><td align="left" rowspan="1" colspan="1">[<xref rid="pone.0294812.ref024" ref-type="bibr">24</xref>]</td></tr><tr><td align="left" rowspan="1" colspan="1">BioBERT</td><td align="left" rowspan="1" colspan="1">&#x0201c;dmis-lab/biobert-v1.1&#x0201d;</td><td align="left" rowspan="1" colspan="1">[<xref rid="pone.0294812.ref025" ref-type="bibr">25</xref>]</td></tr><tr><td align="left" rowspan="1" colspan="1">BioELECTRA</td><td align="left" rowspan="1" colspan="1">&#x0201c;kamalkraj/bioelectra-base-discriminator-pubmed&#x0201d;</td><td align="left" rowspan="1" colspan="1">[<xref rid="pone.0294812.ref026" ref-type="bibr">26</xref>]</td></tr><tr><td align="left" rowspan="1" colspan="1">BioELECTRA-PMC</td><td align="left" rowspan="1" colspan="1">&#x0201c;kamalkraj/bioelectra-base-discriminator-pubmed-pmc&#x0201d;</td><td align="left" rowspan="1" colspan="1">[<xref rid="pone.0294812.ref026" ref-type="bibr">26</xref>]</td></tr><tr><td align="left" rowspan="1" colspan="1">BioMed-RoBERTa</td><td align="left" rowspan="1" colspan="1">&#x0201c;allenai/biomed_roberta_base&#x0201d;</td><td align="left" rowspan="1" colspan="1">[<xref rid="pone.0294812.ref027" ref-type="bibr">27</xref>]</td></tr><tr><td align="left" rowspan="1" colspan="1">BioMed-RoBERTa-CP</td><td align="left" rowspan="1" colspan="1">&#x0201c;allenai/dsp_roberta_base_dapt_biomed_tapt_chemprot_4169&#x0201d;</td><td align="left" rowspan="1" colspan="1">[<xref rid="pone.0294812.ref027" ref-type="bibr">27</xref>]</td></tr><tr><td align="left" rowspan="1" colspan="1">BioMed-RoBERTa-RCT</td><td align="left" rowspan="1" colspan="1">&#x0201c;allenai/dsp_roberta_base_dapt_biomed_tapt_rct_500&#x0201d;</td><td align="left" rowspan="1" colspan="1">[<xref rid="pone.0294812.ref027" ref-type="bibr">27</xref>]</td></tr><tr><td align="left" rowspan="1" colspan="1">BlueBERT</td><td align="left" rowspan="1" colspan="1">&#x0201c;bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12&#x0201d;</td><td align="left" rowspan="1" colspan="1">[<xref rid="pone.0294812.ref028" ref-type="bibr">28</xref>]</td></tr><tr><td align="left" rowspan="1" colspan="1">BlueBERT-MIMIC-III</td><td align="left" rowspan="1" colspan="1">&#x0201c;bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12&#x0201d;</td><td align="left" rowspan="1" colspan="1">[<xref rid="pone.0294812.ref028" ref-type="bibr">28</xref>]</td></tr><tr><td align="left" rowspan="1" colspan="1">ELECTRAMed</td><td align="left" rowspan="1" colspan="1">&#x0201c;giacomomiolo/electramed_base_scivocab_1M&#x0201d;</td><td align="left" rowspan="1" colspan="1">[<xref rid="pone.0294812.ref029" ref-type="bibr">29</xref>]</td></tr><tr><td align="left" rowspan="1" colspan="1">PubMedBERT</td><td align="left" rowspan="1" colspan="1">&#x0201c;microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract&#x0201d;</td><td align="left" rowspan="1" colspan="1">[<xref rid="pone.0294812.ref030" ref-type="bibr">30</xref>]</td></tr><tr><td align="left" rowspan="1" colspan="1">PubMedBERT-Full</td><td align="left" rowspan="1" colspan="1">&#x0201c;microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext&#x0201d;</td><td align="left" rowspan="1" colspan="1">[<xref rid="pone.0294812.ref030" ref-type="bibr">30</xref>]</td></tr><tr><td align="left" rowspan="1" colspan="1">SapBERT</td><td align="left" rowspan="1" colspan="1">&#x0201c;cambridgeltl/SapBERT-from-PubMedBERT-fulltext&#x0201d;</td><td align="left" rowspan="1" colspan="1">[<xref rid="pone.0294812.ref031" ref-type="bibr">31</xref>]</td></tr><tr><td align="left" rowspan="1" colspan="1">SapBERT-Mean</td><td align="left" rowspan="1" colspan="1">&#x0201c;cambridgeltl/SapBERT-from-PubMedBERT-fulltext-mean-token&#x0201d;</td><td align="left" rowspan="1" colspan="1">[<xref rid="pone.0294812.ref031" ref-type="bibr">31</xref>]</td></tr><tr><td align="left" rowspan="1" colspan="1">SciBERT</td><td align="left" rowspan="1" colspan="1">&#x0201c;allenai/scibert_scivocab_uncased&#x0201d;</td><td align="left" rowspan="1" colspan="1">[<xref rid="pone.0294812.ref032" ref-type="bibr">32</xref>]</td></tr></tbody></table></alternatives></table-wrap></sec><sec id="sec010"><title>2.5.3. Article classification task</title><p>The pre-trained models were fine-tuned on the article classification task. The model with the highest performance on the validation set was selected and used to generate the inventory. In order to consider both title and abstract for classification the title and abstract were concatenated with a space character between fields to create a contiguous string. XML tags were removed using regular expressions, while adding white space after punctuation if not present after tag removal. The resulting input string was tokenized using a pre-trained tokenizer associated with the specific pre-trained model to be used for classification. Tokenized input was then passed through the pretrained model module to obtain context embeddings, which were subsequently fed into a linear classification layer that performs binary classification. This process classifies an article, based on title and abstract, as describing a biodata resource or not (<xref rid="pone.0294812.g003" ref-type="fig">Fig 3A</xref>).</p><fig position="float" id="pone.0294812.g003"><object-id pub-id-type="doi">10.1371/journal.pone.0294812.g003</object-id><label>Fig 3</label><caption><title>Machine learning model architectures for article classification and named entity recognition.</title><p>Model architecture for (A) sequence classification used to classify articles based on title and abstract and (B) token classification used to perform NER to obtain the resource names. Each architecture shows the possible classification labels resulting from model prediction. Additional details for token classification are shown in <xref rid="pone.0294812.s002" ref-type="supplementary-material">S2 Fig</xref>.</p></caption><graphic xlink:href="pone.0294812.g003" position="float"/></fig><p>Classification performance was evaluated on the validation set using precision (<xref rid="pone.0294812.e001" ref-type="disp-formula">Eq 1</xref>), recall (<xref rid="pone.0294812.e002" ref-type="disp-formula">Eq 2</xref>), and <italic toggle="yes">F</italic>1 score (<xref rid="pone.0294812.e003" ref-type="disp-formula">Eq 3</xref>). For calculating performance metrics, an article that describes a biodata resource that is correctly classified is a true positive (TP), and if incorrectly classified is a false negative (FN). An article that does not describe a biodata resource that is correctly classified is a true negative (TN), and if incorrectly classified is a false positive (FP). Precision is the proportion of those articles predicted to describe a biodata resource that are indeed describing a biodata resource. Recall is the proportion of articles that describe a biodata resource that are correctly classified. <italic toggle="yes">F</italic>1 score is the harmonic mean of precision and recall.</p><disp-formula id="pone.0294812.e001">
<alternatives><graphic xlink:href="pone.0294812.e001.jpg" id="pone.0294812.e001g" position="anchor"/><mml:math id="M1" display="block" overflow="scroll"><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives>
<label>(1)</label>
</disp-formula><disp-formula id="pone.0294812.e002">
<alternatives><graphic xlink:href="pone.0294812.e002.jpg" id="pone.0294812.e002g" position="anchor"/><mml:math id="M2" display="block" overflow="scroll"><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives>
<label>(2)</label>
</disp-formula><disp-formula id="pone.0294812.e003">
<alternatives><graphic xlink:href="pone.0294812.e003.jpg" id="pone.0294812.e003g" position="anchor"/><mml:math id="M3" display="block" overflow="scroll"><mml:mi>F</mml:mi><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>*</mml:mo><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>*</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives>
<label>(3)</label>
</disp-formula><p>All models were trained for a maximum of 10 epochs following general convention as a starting point. For each model the model checkpoint with the highest precision (regardless of epoch number) was saved. After evaluating the inventory in a mid-project evaluation (see section 2.6 below), precision was chosen over <italic toggle="yes">F</italic>1 and recall for the classification task to reduce the number of false positives. From this evaluation, we found that preferencing precision would improve overall quality of the inventory such that we would be able to finalize the inventory without manually validating every resource included. The precision scores of all the fine-tuned models on the validation set were compared to select the most performant model, which was then used for classification of unlabeled data.</p></sec><sec id="sec011"><title>2.5.4. Named entity recognition (NER) task</title><p>The same pre-trained models evaluated for the article classification task were fine-tuned for the NER task (<xref rid="pone.0294812.t003" ref-type="table">Table 3</xref>). To accomplish this, the linear sequence classification layer was replaced by a token classification layer (<xref rid="pone.0294812.g003" ref-type="fig">Fig 3B</xref> and <xref rid="pone.0294812.s002" ref-type="supplementary-material">S2 Fig</xref>). Input (training and validation) data was tagged using the following BIO scheme [<xref rid="pone.0294812.ref033" ref-type="bibr">33</xref>]:</p><list list-type="bullet"><list-item><p>B-COM: token is the start of a sequence corresponding to a common name</p></list-item><list-item><p>I-COM: token is a non-start part of a sequence corresponding to a common name</p></list-item><list-item><p>B-FUL: token is the start of a sequence corresponding to a full name</p></list-item><list-item><p>I-FUL: token is a non-start part of a sequence corresponding to a full name</p></list-item><list-item><p>O: outside</p></list-item></list><p>NER performance was evaluated using partial-match entity level metrics (precision, recall, <italic toggle="yes">F</italic>1 score) on the validation set. As with the classification task, models were trained for a maximum of 10 epochs. For each model architecture the trained model checkpoint with the highest <italic toggle="yes">F</italic>1 score was saved. The model with the highest <italic toggle="yes">F</italic>1 score on the validation set was then used for downstream tasks.</p></sec><sec id="sec012"><title>2.5.5. Model implementation details</title><p>The Huggingface framework was utilized to load the BERT model architectures [<xref rid="pone.0294812.ref034" ref-type="bibr">34</xref>]. The Huggingface&#x02019;s AutoModelForSequenceClassification module was used to fine-tune the BERT models on the article classification task, and the AutoModelForTokenClassification module to fine-tune the models on the NER task. The hyper-parameters used during fine-tuning of the models can be found in <xref rid="pone.0294812.s008" ref-type="supplementary-material">S4 Table</xref>. We used the Adam optimizer for training and the seqeval module for computing partial match entity-level metrics. Models were trained for a maximum of 10 epochs. All machine learning code was implemented in Python v3.8.12 and used the following third-party packages: Datasets v1.18.3, Natural Language Toolkit (NLTK) v3.6.1, NumPy v1.19.2, Pandas v1.2.4, pytest v6.2.4, scikit-learn v0.24.1, PyTorch v1.9.0, tqdm v4.63.0, and transformers v4.16.2 [<xref rid="pone.0294812.ref034" ref-type="bibr">34</xref>&#x02013;<xref rid="pone.0294812.ref042" ref-type="bibr">42</xref>].</p></sec></sec><sec id="sec013"><title>2.6. Mid-project evaluation and iteration</title><p>We conducted a manual evaluation midway through the project to assess how well the predictions were performing in practice and if any improvements could be made before we continued. At that point, SapBERT resulted in the highest best <italic toggle="yes">F</italic>1 score of the 15 models tested for the classification task (<xref rid="pone.0294812.s009" ref-type="supplementary-material">S5 Table</xref>). Using the results of that model, a curator assessed precision on a 10% random sample (n = 468) of the predictions to assess the correctness of the article classifications and NER extracted terms. Classification was determined to be either correct or incorrect. For the NER outputs, the evaluation determined if the extracted common and full names were correct, partially correct, or incorrect. This step helped us confirm that machine learning was indeed viable for this project and also helped us determine that a selective manual evaluation of low-scoring predictions would still enhance the overall quality of the inventory. To determine which predictions qualify as &#x0201c;low-scoring&#x0201d; for this first inventory and updates in the future, we used the results of the midway evaluation to determine a threshold probability of &#x0003c; 0.978 as &#x0201c;low-scoring,&#x0201d; where 0.978 was the average probability for names determined by a curator to have been correctly predicted in the 10% random sample of the 468 articles that were manually reviewed (see additional details in Results section 3.3.1 Mid-Project Manual Evaluation). Therefore, any resource whose highest scoring predicted name (&#x0201c;best name,&#x0201d; regardless if common or full) has a probability below this threshold is annotated to be manually reviewed by a curator before the inventory is finalized. In addition to the threshold, this step also helped us determine what iterative improvements could be made to refine the overall strategy, such as revising the input query (e.g., excluding &#x0201c;onlinelibrary.wiley.com&#x0201d; URLs) and adding conditionals to the models (e.g., predicted name length &#x0003e; 1 and number of URLs &#x02264; 2; see Section 2.7.6.).</p><p>During preparation of this manuscript, we realized that a portion of the ML test sets may have been present in the set of articles that were manually reviewed during the mid-project evaluation. While we did not pass labeled data through the pipeline, we did process all of the articles returned from Europe PMC. The potential impact of such data leakage was assessed and is reported in Results.</p></sec><sec id="sec014"><title>2.7. Post processing</title><sec id="sec015"><title>2.7.1. Best name determination</title><p>As detailed above, for each article the NER model attempts to predict both full and common names and may output multiple predictions, each of which is associated with a probability score, where the higher the score the greater the confidence in the predicted name. To determine the highest quality names, the probability scores for named entities of each type were compared to determine the &#x0201c;best common name&#x0201d; and &#x0201c;best full name&#x0201d;. These probability scores of these two named entities were compared to choose the best overall name &#x0201c;best name&#x0201d; (that with the highest probability score).</p></sec><sec id="sec016"><title>2.7.2. Automated deduplication</title><p>Many resources publish repeatedly, for instance, to provide updates about the resource. Consequently, the raw inventory contained duplicate records from several articles describing the same resource. A first step toward deduplicating the inventory was performed by identifying records that had the same predicted best name and same extracted URL (ignoring differences due to trailing slashes or &#x0201c;http:&#x0201d; vs &#x0201c;https:&#x0201d;). These duplicate resources were merged with the PMIDs of each original article and retained along with the title-abstract text and publication date of the most recently published article.</p></sec><sec id="sec017"><title>2.7.3. Annotation for selective manual evaluation</title><p>Up to this point all steps were automated. However, based on the results of the mid-project evaluation described above, we realized that it would be advantageous to conduct a selective manual evaluation of some predicted resources to improve the overall quality of the inventory. In preparation for this step, a script within the pipeline added a new column with the variable &#x0201c;low_prob&#x0201d; for any resource whose best name probability &#x0003c; 0.978, the value determined in the mid-project evaluation as the average of correctly predicted names in the 10% random sample. This served as a flag to aid the curator conducting the manual evaluation. Additionally, while the automated deduplication was able to merge any articles with exact names and exact URLs matches, we were aware of suspected duplicates (e.g. variable names such &#x02019;&#x02019;FANTOM&#x02019;&#x02019; and &#x02019;&#x02019;FANTOM5&#x02019;&#x02019; sharing the same extracted URL while variable URLs such as <ext-link xlink:href="http://appris-tools.org/" ext-link-type="uri">http://appris-tools.org</ext-link> and <ext-link xlink:href="http://appris.bioinfo.cnio.es/" ext-link-type="uri">http://appris.bioinfo.cnio.es</ext-link> share the same predicted name &#x02019;&#x02019;APPRIS&#x02019;&#x02019;). Deduplication on either name or URL (as opposed to both) would have led to erroneous mergers. For example, &#x02019;&#x02019;Seed&#x02019;&#x02019; and &#x02019;&#x02019;SEED&#x02019;&#x02019; are two different resources, while there are at least three distinct &#x02019;&#x02019;PED&#x02019;&#x02019; resources and two distinct resources for &#x02019;&#x02019;SMART.&#x02019;&#x02019; Instead, to account for potential duplicates, columns were also generated for matching best names (flagged with &#x0201c;duplicate_names&#x0201d;) or matching extracted URLs (flagged with &#x0201c;duplicate_urls&#x0201d;) for evaluation by the curator. While more complex, automated procedures may be warranted in the future as the inventory grows over time, these cases were relatively few and we judged this strategy to be sufficient for the time being.</p></sec><sec id="sec018"><title>2.7.4. Selective manual evaluation procedure</title><p>With steps implemented above, a preliminary inventory with records flagged for manual review was generated as a CSV file. A curator then reviewed each flag to determine if low probability records should be removed from the inventory and if potential duplicate records should be merged within the inventory. This review was done in Microsoft Excel, with data validation applied to a set of predetermined outcomes (e.g. &#x02019;&#x02019;remove&#x02019;&#x02019;, &#x02019;&#x02019;merge&#x02019;&#x02019;, etc.). Importantly, no corrections to the predicted names or URLs were made; thus all values within the inventory are the output of the machine learning pipeline, which reduces the confusion that could result if the inventory were a mixture of ML-generated and human-generated names/URLs (especially in future updates). Review guidelines were developed to help standardize handling of edge cases (see <xref rid="pone.0294812.s011" ref-type="supplementary-material">S7 Table</xref>). The resulting manually reviewed file was added into the directory for subsequent processing. The pipeline first ensures all flagged records contain only valid review values and then removes or merges the appropriate records before moving on to metadata augmentation.</p></sec><sec id="sec019"><title>2.7.5. Metadata augmentation</title><p>Once we had the final prediction script and the results of the manual review processed, the Europe PMC API was once again queried using PMIDs to retrieve author affiliations, author names, grant IDs, grant agency name, and citation counts (i.e. via metadata elements &#x02019;affiliation&#x02019;, &#x02019;fullName&#x02019;, &#x02019;grantID&#x02019;, &#x02019;agency&#x02019;, &#x02019;citedByCount&#x02019;, respectively) for each article associated with the biodata resources.</p></sec><sec id="sec020"><title>2.7.6. URL processing</title><p>Biodata resources may be impermanent for reasons that include loss of funding, loss of key personnel, and technological change leading to deprecation, and we were interested in establishing if the URL provided in the abstract was still viable. Accordingly, the extracted URLs were checked for viability through standard HTTP status calls using the Python requests and urllib3 (v1.26.8) [<xref rid="pone.0294812.ref043" ref-type="bibr">43</xref>] libraries, and the returns (e.g. 200 OK, 404 Not Found, etc.) were recorded in the inventory on 11 November 2022. Extracted URLs were tested three times, with each attempt allowing 5 seconds for a response. The second attempt is submitted immediately after the first, while the third attempt is submitted after a one second delay.</p><p>Web archives offer a chance to locate snapshots of previously available websites [<xref rid="pone.0294812.ref044" ref-type="bibr">44</xref>]. To mitigate current and anticipate future availability issues, we used the Internet Archive&#x02019;s Wayback Machine API to check URLs for the presence of archived sites. While the Wayback crawler is often unable to access the data itself, these snapshots provide views of HTML pages such as the home page, search interface, etc. which provide important context in the absence of the live site. For the biodata resources in this inventory the most recent Wayback Machine URL was recorded for successful returns; for live URLs not represented in the Wayback Machine the URLs were submitted for archiving and the associated Wayback URL recorded. While the Wayback Machine is able to crawl and archive the majority of sites represented here, sites behind firewalls or those that prohibit crawlers cannot be archived.</p></sec><sec id="sec021"><title>2.7.7. Resource geolocation</title><p>We use two methods to identify the location of the biodata resource. The first is the location as determined from the IP address, which suggests a physical location for the infrastructure. For those URLs that return a status less than 400, the IP address is obtained from the host name. In an attempt to geolocate the IP addresses, ipinfo [<xref rid="pone.0294812.ref045" ref-type="bibr">45</xref>] and ip-api [<xref rid="pone.0294812.ref046" ref-type="bibr">46</xref>] are queried to request the IP address country and coordinates. Two APIs are used since neither is complete, and querying multiple APIs increases the chance of successful geolocation. When a location is successfully obtained from either API, the country and coordinates are recorded.</p><p>Because of the global nature of the life sciences research enterprise, physical location alone may not reflect collaboratively developed resources. Therefore, we also extracted country names following ISO 3166 from the author affiliations available from the Europe PMC metadata. When geolocating IP addresses both coordinates and country name were returned. ISO-3166-1 Alpha-3 codes and country names of all countries were searched against both the IP address geolocations and author affiliations [<xref rid="pone.0294812.ref047" ref-type="bibr">47</xref>] and recorded in the inventory.</p></sec></sec><sec id="sec022"><title>2.8. Workflow management</title><p>The Snakemake workflow manager is used to automate the process described above in two pipelines. The first pipeline performs data splitting, model training (including model selection and evaluation), prediction, and downstream processing prior to selective manual review. After the selective manual review this pipeline resumes for final processing. This process, excluding model training and selection, is shown in <xref rid="pone.0294812.g001" ref-type="fig">Fig 1</xref>. A second pipeline was also developed to facilitate updating the inventory in future using new queries to Europe PMC and the previously fine-tuned models.</p></sec><sec id="sec023"><title>2.9. Analysis of the final inventory</title><p>With the final inventory established and additional metadata elements added, we carried out analyses on location, funders, and text-mining related metadata to provide a preliminary analysis of the resources identified and identify future opportunities to further explore and reuse the inventory. Using the geolocation information (see Section 2.7.7. above), location information was mapped without additional cleaning or filtering. All analyses were performed in R using the packages argparse, dplyr, europepmc, forcats, ggplot2, glue, gt, httr, jsonlite, magrittr, purrr, RColorBrewer, readr, scales, stringr, tibble, tidyr, and xml2 [<xref rid="pone.0294812.ref048" ref-type="bibr">48</xref>&#x02013;<xref rid="pone.0294812.ref067" ref-type="bibr">67</xref>]. The data resulting from these analyses, as well as the scripts to perform them, are available in GitHub and archived in Zenodo along with the code and data for developing the inventory.</p><sec id="sec024"><title>2.9.1. Analysis of funders</title><p>To evaluate the funding agency names found in article metadata, agency names which appeared three or more times were extracted and the countries of origin for the funding body were manually identified through Google searches. Recorded country names were verified by a second curator and then standardized to a three-letter coding following ISO 3166&#x02013;1 alpha-3. For funders international in nature, which are common for funding provided through the European Union, a unique 3-letter code of &#x0201c;INT&#x0201d; was used in the absence of an ISO standard.</p></sec><sec id="sec025"><title>2.9.2. Comparison with existing registries</title><p>To get a sense of how well this machine-learning enabled method of identifying biodata resources may complement other methods, we compared the biodata resources in this inventory with life science data resources collected elsewhere. There are several collections, such as the catalogue maintained by the journal <italic toggle="yes">Nucleic Acids Research</italic> and Database Commons; however, neither offer bulk download or programmatic access to their data. As such, we focused on two registries, <ext-link xlink:href="http://re3data.org" ext-link-type="uri">re3data.org</ext-link> [<xref rid="pone.0294812.ref013" ref-type="bibr">13</xref>] and FAIRsharing [<xref rid="pone.0294812.ref014" ref-type="bibr">14</xref>]. Both carefully curate their registered resources and provide robust API access. These registries, which were created for different purposes and via different teams, do not themselves contain all known data resources but inclusion criteria are similar to the inventory (see below). Therefore, we anticipated some overlap but not a complete union with either.</p><p>Library and information science professionals in Germany established <ext-link xlink:href="http://re3data.org" ext-link-type="uri">re3data.org</ext-link> in 2013, specifically as a registry of research data repositories, and the resource has maintained a domain agnostic collection policy. The criteria for inclusion in re3data requires that a resource 1) be run by a legal entity, 2) has access conditions and terms of use, and 3) focuses on research data. We accessed all resource records from re3data&#x02019;s API and then filtered to align with the inclusion criteria for the inventory. To do this, we subsetted to only resources categorized as &#x0201c;life sciences&#x0201d; which had URLs and removed the generalist categories (specifically &#x0201c;institutional&#x0201d; or &#x0201c;other&#x0201d;) to focus on resources specifically dedicated to the life sciences. FAIRsharing emerged from its more focused predecessor, BioSharing, itself originating from the Minimum Information about a Biomedical or Biological Investigation Portal. Along with data resources, FAIRsharing also includes standards and policies and has expanded beyond the life sciences. FAIRsharing explicitly excludes individual datasets, consistent with the inclusion criteria of the inventory, and requires that resources are 1) organised collections of data, 2) findable via an active website that allows users to browse and/or search, and 3) accessible regardless of specific license type. We retrieved only resource records for the life sciences category from the API and did not filter the results further.</p><p>To prepare the resources from re3data, FAIRSharing, and the inventory for comparison, white space was trimmed from the resource name, and resource URLs were cleaned by removing the scheme and any trailing slashes and then converting to lowercase. As noted above, resource names and URLs may vary slightly but significantly, so we compared by common name, full name when available, and URL separately, merged the results, and then deduplicated where both the name and URL matched to obtain the final number of resources found in common.</p></sec></sec></sec><sec sec-type="results" id="sec026"><title>3. Results</title><sec id="sec027"><title>3.1. Overview</title><p>We initially retrieved 21716 articles from Europe PMC using all data sources, but later restricted this to the 20880 which had PMIDs available since we found that the metadata associated with articles lacking PMIDs was often insufficient for further analyses. During the article classification task the model predicted a negative label for 16588 articles while 4292 articles were predicted to describe a biodata resource. Of those with a positive label, the NER model extracted at least one name (common or full) for 4006 articles. Those without at least one complete URL were removed, resulting in 3940 articles. After deduplicating articles that had the same &#x0201c;best name&#x0201d; and same extracted URL, 3565 potential resources were identified in the preliminary inventory. After selective manual review to evaluate and remove erroneous low probability resources and merge additional duplicates, the final inventory contains 3112 biodata resources (<xref rid="pone.0294812.g004" ref-type="fig">Fig 4</xref>).</p><fig position="float" id="pone.0294812.g004"><object-id pub-id-type="doi">10.1371/journal.pone.0294812.g004</object-id><label>Fig 4</label><caption><title>Counts of articles and resources as they passed through the pipeline.</title><p>The area of each circle is proportional to the count at that step. Most attrition occurs during the initial classification step that predicts which articles describe a biodata resource, while losses are relatively low as additional steps build and finalize the inventory.</p></caption><graphic xlink:href="pone.0294812.g004" position="float"/></fig></sec><sec id="sec028"><title>3.2. Training data and NLP tasks metrics</title><p>During curation of the 1634 records in the training dataset, initial inter-annotator agreement was high (89.4%) and increased to 97.1% once conflicting scores were reviewed, discussed, and reclassified. The training set took a total of 33 curation hours. While curation was relatively quick and straightforward, challenges fell into two main categories where it was difficult to distinguish between biodata resources and other resources that 1) are available solely as a tool or 2) belonged to a different disciplinary area (such as clinical health records).</p><p>For each of the article classification and NER tasks we divided the training datasets into 70/15/15 splits used for training, validation, and testing, respectively. Models were evaluated using Precision, Recall and the <italic toggle="yes">F</italic>1 scores. All pretrained models were fine-tuned and evaluated using the same training and validation sets. Models with the highest performance when run using the validation data were chosen for final implementation. Precision was used for comparing the article classification models, and <italic toggle="yes">F</italic>1 score was used for comparing the NER models. Performance of all fine-tuned models on both validation and test sets are provided in <xref rid="pone.0294812.s009" ref-type="supplementary-material">S5</xref> and <xref rid="pone.0294812.s010" ref-type="supplementary-material">S6</xref> Tables. For the article classification task BioMed-RoBERTa-RCT had highest precision on the validation set and had a precision of 0.975, <italic toggle="yes">F</italic>1 score of 0.821, and recall of 0.719 on test data that had not been seen during training. For the NER task, BioMed-RoBERTa-RCT had the highest <italic toggle="yes">F</italic>1 score on the validation set and had an <italic toggle="yes">F</italic>1 score of 0.717, precision of 0.689, and recall of 0.748 on test data.</p></sec><sec id="sec029"><title>3.3. Manual evaluations</title><p>In addition to NLP metrics above, we also manually evaluated results at two points in the project. To assess the viability of application of machine learning to this project and to determine if any improvements could be made to the strategy overall, precision was determined for a 10% random sample of preliminary results mid-way through the project. The second evaluation was performed prior to finalizing the inventory. This evaluation reviewed resources with low probabilities and suspected duplicates. The results of both evaluations are detailed below.</p><sec id="sec030"><title>3.3.1. Mid-project manual evaluation</title><p>In the mid-project evaluation of a 10% sample, 468 articles were manually reviewed. Of these, we found that 439/468 (0.938) articles were classified correctly. In <xref rid="pone.0294812.g005" ref-type="fig">Fig 5A</xref>, we show an example of a correctly classified article which was relatively straightforward while in <xref rid="pone.0294812.g005" ref-type="fig">Fig 5B</xref>, the text describes an entity that appears, on human reading, to be a tool that does not provide access to data [<xref rid="pone.0294812.ref068" ref-type="bibr">68</xref>, <xref rid="pone.0294812.ref069" ref-type="bibr">69</xref>]. Another scenario that proved challenging for the models was when the title-abstract described a research project for which data was deposited into a resource (such as Flybase [<xref rid="pone.0294812.ref070" ref-type="bibr">70</xref>]) but the article did not describe the resource itself. However, overall these errors were limited, and given the challenge of classification even for human curators, we judged that the machine learning based methodology was indeed viable for classification.</p><fig position="float" id="pone.0294812.g005"><object-id pub-id-type="doi">10.1371/journal.pone.0294812.g005</object-id><label>Fig 5</label><caption><p>Examples of (A) a correctly classified article and (B) an incorrectly classified article.</p></caption><graphic xlink:href="pone.0294812.g005" position="float"/></fig><p>In addition to evaluating the correctness of classifications, in the mid-project evaluation we looked at the results of the NER extraction for all 468 articles of the 10% sample to determine if extracted common and full names were correct, partially correct, or incorrect. A common name was predicted for 457 of the 468 (97.6%) in the sample, and in 425 of these predictions (93.0%), the common name with the highest probability was, in fact, the correct common name. Notably, even when not correct, only 10 (2.2%) were entirely incorrect (e.g., predicted as &#x0201c;the&#x0201d; instead of &#x0201c;WikiPathways Database&#x0201d;) while 22 (4.8%) were partially correct (e.g., predicted as &#x0201c;Open&#x0201d; instead of &#x0201c;Open TG-GATEs&#x0201d;). In reality, for several that were entirely incorrect, the name was so poorly articulated in the abstract that it was difficult for a human to determine a valid name. Full names were predicted less frequently on the whole (157/468, 33.5%) and, reflective of greater complexity (see <xref rid="pone.0294812.g006" ref-type="fig">Fig 6</xref> for an example), were less likely to be judged correct with 97 being correct (61.8%). However, only 7 (4.5%) were entirely incorrect and 53 were partially correct (33.8%). From these results, it was clear to us that, as was true with predicted classification, the method was viable for predicting resource names, with common names being the most likely identified.</p><fig position="float" id="pone.0294812.g006"><object-id pub-id-type="doi">10.1371/journal.pone.0294812.g006</object-id><label>Fig 6</label><caption><title>Example of correct extraction of common and partial extraction of full name.</title><p>Example of a detailed abstract where the common name of the resource, &#x0201c;ESTHER&#x0201d; (bold/blue), was only mentioned once but correctly predicted. The predicted full name, &#x0201c;Hydrolase&#x0201d; (bold/orange), was partially correct while the entire full name (peach) is much longer. The uncertainty is accurately reflected in the scores where the correctly predicted common name is associated with a probability of 0.9933 while the partially correct full name was lower at 0.7105.</p></caption><graphic xlink:href="pone.0294812.g006" position="float"/></fig><p>While it was clear from the results of the mid-project evaluation that the machine learning methods would be a useful technique to employ, we also recognized that the quality of inventory, as a collection of discrete resources, is important to the stakeholders. We explored putting greater weight on precision than <italic toggle="yes">F</italic>1 for both the classification and NER tasks, but we found that the subsequent hit to recall in the NER task resulted in the loss of too many viable predictions. To achieve higher reliability for the inventory then we choose a selectively mediated approach given the relatively small size of the inventory and manageable curation load. Based on the mid-project evaluation results we used the average probability of correctly predicted names, 0.978, to determine a threshold at which resources whose highest scoring predicted name (&#x0201c;best name,&#x0201d; regardless if common or full) had a probability below this threshold would be flagged for review by a curator in our finalized process. In the 468 articles from the 10% random sample, records with probabilities &#x02265; 0.978 (i.e. those proposed to not undergo human-mediated review in the future) contained 13/468 (2.8%) incorrect classifications and 5/468 (1.0%) incorrect best names. Therefore, we concluded that a selective manual evaluation at this threshold was likely to catch the majority of both classification errors and name errors and improve the quality of the final inventory.</p><p>In the mid-project evaluation, 7 articles from the classification test and 5 articles from the NER test set were found in the validation set used for mid-project evaluation. We considered retroactively removing/replacing these 7 articles to address the potentially deleterious effects of such data leakage but decided against these actions for several reasons. First, these articles made up only a very small portion of the mid-project evaluation set, and we did not look at them specifically, so their effects on decisions regarding ML model training/selection were negligible. Second, the only decision made regarding ML training/selection due to the mid-project evaluation was to use precision rather than <italic toggle="yes">F</italic>1-score for article classification model selection. Due to the very low portion of test set articles in the evaluation (&#x02264;1.5%), we are confident that such a decision would have been reached in their absence. Since we believe no portion of the model training or selection process was biased by the presence of these articles, the test sets still serve as representative samples for model evaluation. Third, retroactively removing/replacing these 7 articles would result in convoluting an already complex pipeline and reporting of methods. Ultimately, since our goal was a practical application of ML methods, we opted to simply openly disclose the issue.</p></sec><sec id="sec031"><title>3.3.2. Selective manual evaluation of preliminary inventory</title><p>With the results above, the pipeline was implemented and the preliminary inventory up to the point of manual evaluation was created. Of the 3566 records remaining after automated deduplication, 1033 (29.0%) were flagged for review due to a probability score &#x0003c; 0.978, 469 (13.2%) due to potential duplicate names, and 215 (6.0%) due to potential duplicate URLs.</p><p>Of the 1033 low probability flags, a curator determined that 805 be retained in the inventory and 228 (6.4% of the total and 22.1% of the flagged) be removed. The majority of those removed, 161/228 (70.6%), were removed because of a partially correct name, while 36/228 (15.8%) were removed for an incorrect name, 27/228 (11.8%) for incorrect classification, and 4/228 (1.8%) for erroneous URLs. As expected, the average probability of those removed (0.749) was much lower than the cut-off that triggered the review.</p><p>Of the 469 flagged for duplicate names, 355 (75.7%) were marked for merger, 54 (11.5%) were associated with records that would be removed due to low probability, 50 (10.7%) were not to be merged, and 10 (2.1%) required a partial merger (e.g. sets of &#x0003e; 2 potential duplicates where only some should be merged). Of the 215 flagged for duplicate URLs, 121 (56.3%) were marked for merger, 66 (30.7%) were associated with records that would be removed due to low probability, and 28 (13.0%) were not to be merged.</p></sec></sec><sec id="sec032"><title>3.4. URL analysis and testing</title><p>In the mid-project manual evaluation we found that, although rare, multi-URL abstracts pose a problem. In the 10% sample, 36/468 (7.7%) of abstracts contained 2 URLs and 4/468 (0.85%) contained &#x0003e; 2 URLs with the remaining containing a single URL. In the majority of 2-URL abstracts (26 of 36, ~ 72%), the correct URL was associated with the predicted name and for 6 of the remaining 10, predictions were low enough to trigger manual review, thereby allowing errors to be caught. However, abstracts with &#x0003e; 2 URLs were more often abstracts that covered multiple distinct biodata resources, such as those that describe a collection of resources located at national data centers. As these abstracts were few in number (representing &#x0003c; 1% of the corpus), they were removed instead of undertaking additional training to associate the correctly predicted name with the correct URL.</p><p>In the final inventory 2235/3112 (71.8%) resources had at least one URL which returned HTTP codes in the &#x0201c;2xx successful&#x0201d; or &#x0201c;3xx redirection&#x0201d; series, indicating a live site. However, we note that URLs that resolve with either 2xx or 3xx status codes can be misleading since a URL might resolve successfully but not actually point to the biodata resource. During previous efforts to create a census of databases published in <italic toggle="yes">Nucleic Acids Research</italic>, URLs were manually checked and coded when they failed to resolve to the database in question [<xref rid="pone.0294812.ref074" ref-type="bibr">74</xref>]. As this dataset is available and the websites of interest are the same, we analyzed this dataset to estimate how often URLs that appear to resolve successfully do not, in fact, resolve correctly. The variable &#x0201c;unavailable_message&#x0201d; contained two values for failed 2xx codes (&#x0201c;blank page&#x0201d; and &#x0201c;discontinued notice&#x0201d;) and five values for failed 3xx codes ("related generic commercial site redirect", "related generic government site redirect", "related generic publisher site redirect", "related generic research institution site redirect", and "unrelated site redirect"). Of the 2264 URLs that appeared successful in that study, analysis showed that 147 did not resolve properly (6.5%) with 66 resolving to webpages for a related research institution, 37 to an unrelated site, 27 to a discontinued notice, 6 to a related government webpage, 5 to a related publisher webpage, 3 to a related commercial webpage, and 3 to a blank page. We anticipate a similar false positive rate would apply to this work as well. Under this assumption, we estimate that 2090 of the 2235 live URLs pointed to the resource itself, equalling 2090/3112 (67.2%) of the inventory. Previous studies reported ~27% failure while noting that availability is highly time dependent and less popular resources (as determined by citations) are more likely to fail [<xref rid="pone.0294812.ref016" ref-type="bibr">16</xref>]. Additionally, 2451/3112 (78.8%) of resources had at least one URL archived in the Internet Archive&#x02019;s WayBack Machine.</p></sec><sec id="sec033"><title>3.5. Assessing the biodata resource inventory</title><p>After curation and processing to remove erroneous predictions and deduplicate records that were identified in the selective manual evaluation, the resulting inventory contained 3112 resources from 3705 unique articles. Post processing was completed to add additional metadata and check URLs. We provide the following key descriptive statistics to highlight how the inventory may be used to probe for additional information about the resources.</p><sec id="sec034"><title>3.5.1. Countries represented</title><p>Resource locations were assessed by geolocating the URL host IP address and by mining the author affiliations. For 1672 (53.7%) resources at least one IP address could be geolocated, with a total of 1679 IP address locations (<xref rid="pone.0294812.g007" ref-type="fig">Fig 7A</xref>). While our methods for identifying countries yielded a consistent output, it misses certain countries, especially for author affiliations where locations are reported more idiosyncratically. For instance, the ISO-3166-1 name for South Korea is &#x0201c;The Republic of Korea&#x0201d;, and if the name does not appear as such in the affiliations, it is missed. Additionally, false positives may occur, such as an affiliation with New Mexico (a state in the USA) being counted as Mexico (the country). However, as a preliminary assessment, 65 unique countries were found in author affiliations (<xref rid="pone.0294812.s004" ref-type="supplementary-material">S4 Fig</xref>) and 28 unique countries were found in the host IP address locations (<xref rid="pone.0294812.s003" ref-type="supplementary-material">S3 Fig</xref>). Despite the challenges with cleanly identifying countries, over twice as many countries were identified via author affiliations, indicating that global contributions go well beyond the discrete physical location of a resource. This further highlights the distributed nature of the overall infrastructure.</p><fig position="float" id="pone.0294812.g007"><object-id pub-id-type="doi">10.1371/journal.pone.0294812.g007</object-id><label>Fig 7</label><caption><title>Biodata resource geolocation metadata.</title><p>(A) URL host IP address coordinates (n = 1679). Transparency is constant for all points; darker regions indicate overlapping points. (B) Number of biodata resources per country after determining the country of origin for the most frequently identified funding agencies. Funding agencies that could not be mapped to a single country are not shown; specifically, 111 resources were funded by international agencies. Figures were created using the R ggplot2 package which obtains map data from Natural Earth [<xref rid="pone.0294812.ref071" ref-type="bibr">71</xref>], which is in the public domain.</p></caption><graphic xlink:href="pone.0294812.g007" position="float"/></fig></sec><sec id="sec035"><title>3.5.2. Metadata for follow-up analyses of funder and text mining</title><p>Funding of biodata resources can be obtained from the granting agency metadata provided for individual articles. Of the 3705 articles, one or more funding agencies were retrieved for 1916 articles (52.9%), which covers 1714/3112 (55.1%) of the biodata resources identified. Although a total of 1788 &#x0201c;unique&#x0201d; agency names were retrieved, the names reported are variable in that they are often free text values provided by article authors. Both PubMed Central and Europe PMC, which exchange data, make efforts to standardize funder information for their parent funders; however, smaller funders and funders outside of the US and Europe are more likely to be represented irregularly. We see how this challenge is exacerbated in our work by the reporting of increasingly diverse and granular funders as the number of associated biodata resources decreases to only 1 or 2, where reported funder names may be very specific (e.g. an academic department) yet vague (e.g. ambiguous with respect to which university), related to an individual (e.g. scholarships or fellowships of unclear origin), or attributed to a project which, on investigation, is found to be funded itself by multiple funders. Additionally, the funder names retrieved may be of varying organizational levels (e.g. both NIH as a parent and NIH NIGMS as a child), and the same funder can be cited in a single article for distinct grants. In this first instantiation of the inventory itself we left all agency names as is, but future iterations of the inventory may explore use of funder registries, such as the one being developed by CrossRef, to standardize funder names and map identifiers, where possible [<xref rid="pone.0294812.ref072" ref-type="bibr">72</xref>].</p><p>To begin assessing the global distribution of the most prevalent funders found here, the funder names associated with 3 or more biodata resources (200/1788, 11.2%) were evaluated by a curator to identify the country or region of the funding organization and verified by a second curator. As noted in prior work, funders themselves are diverse [<xref rid="pone.0294812.ref073" ref-type="bibr">73</xref>], and in addition to government agencies, academic and philanthropic organizations were also identified here. After deduplication of resources, 28 unique counties were identified, with each supporting anywhere from 3 to 570 biodata resources (<xref rid="pone.0294812.g007" ref-type="fig">Fig 7B</xref>).</p><p>The articles associated with the biodata resources within the inventory also provide opportunities to glean additional information about the resources themselves through text mining. For each article, Europe PMC provides in-house text mining results as annotations that cover database accessions and resource names of over 60 biodata resources as well as gene/protein names, organisms, diseases, chemicals, gene ontology terms and experimental methods [<xref rid="pone.0294812.ref017" ref-type="bibr">17</xref>]. Additional annotations submitted from the community cover specific interactions, targets, pathways, processes, and other terms [<xref rid="pone.0294812.ref074" ref-type="bibr">74</xref>]. Europe PMC offers a dedicated Annotations API for access to all available terms, and new text mining may also be undertaken on full text available via XML. Thus the vast majority of associated articles have text-mined terms already available for further analyses and the majority are available for additional full text analysis (<xref rid="pone.0294812.g008" ref-type="fig">Fig 8</xref>).</p><fig position="float" id="pone.0294812.g008"><object-id pub-id-type="doi">10.1371/journal.pone.0294812.g008</object-id><label>Fig 8</label><caption><title>Inventory text mining potential.</title><p>Text mining potential of (A) individual articles found to describe biodata resources, and (B) the collective articles describing a particular biodata resource.</p></caption><graphic xlink:href="pone.0294812.g008" position="float"/></fig></sec><sec id="sec036"><title>3.5.3. Overlap with resources found in <ext-link xlink:href="http://re3data.org" ext-link-type="uri">re3data.org</ext-link> and FAIRsharing</title><p>The machine learning-enabled approach used here represents an effort to identify resources at scale. We initially expected greater overlap with re3data and FAIRSharing, but only 536/3112 (17.2%) inventory resources were identified in these two registries; similarly, the majority of life science resources within both re3data (975/1189, 80.5%) and FAIRsharing (1161/1640, 70.8%) are not found in our inventory.</p></sec></sec><sec id="sec037"><title>3.6. Open science products</title><p>From the onset, our goal was to create a fully open project with products that could be reused by anyone and to a high level of reproducibility&#x02014;we consider this an explicit result of the project and describe these products here briefly (see <xref rid="pone.0294812.s011" ref-type="supplementary-material">S7 Table</xref> for listing and locations). The final inventory itself, along with all trained models, code, and data are available in both GitHub and in Zenodo. Within these deposits is the entire workflow, which is provided both as individual scripts as well as an automated Snakemake pipeline that allows execution of the entire analysis in a single command.</p><p>In addition to all of the code, iPython notebooks (ipynb) have also been created to facilitate 1) running the entire pipeline with model training and 2) running the prediction script itself from the highest scoring model to update the inventory. Since running the entire pipeline is computationally intensive and requires access to GPUs, the second notebook may be especially useful for updating the inventory without testing or retraining new models. Detailed READMEs for all products are available within GitHub and Zenodo, and a dedicated protocol has been created to provide step-by-step instructions for use of the iPython notebooks in Google Colab, which allows anyone to execute the code in a browser.</p></sec></sec><sec sec-type="conclusions" id="sec038"><title>4. Discussion</title><p>Collectively, biodata resources form a life sciences infrastructure that is widely distributed and difficult to describe [<xref rid="pone.0294812.ref075" ref-type="bibr">75</xref>]. While there are a number of highly visible and firmly established biodata resources, others are relatively small and serve specific research communities. In fact, individual resources vary wildly and a persistent, major challenge is simply knowing what biodata resources exist. Worldwide, several national or regional funders, for example in China, Europe, and the US, support institutes that provide major biodata resources, such as those that host gene sequences and protein structures. Such resources are well-known and easy to locate. However, a biodata resource can be established by anyone who wishes to share data and has access to the skills and technical infrastructure needed to create an online resource; that is, the barrier to entry is relatively low and many resources have been created by individual researchers motivated to share data. While this increases the availability of data and aligns with global efforts to increase research data sharing, such resources have proliferated to a point where it is no longer possible to know exactly how many resources exist [<xref rid="pone.0294812.ref076" ref-type="bibr">76</xref>]. This creates challenges for anyone searching for data as well as those who work to develop, maintain, and sustain the resources, including resource providers and research funders.</p><p>In an effort to address this issue, we implemented a method to identify thousands of biodata resources via a machine learning enabled pipeline. In this practical application of NLP techniques we found that several state-of-the-art BERT models performed well in both article classification and NER tasks. The selected article classification model, BioMed-RoBERTa-RCT, achieved very high precision as evaluated on the test set, which provides confidence that the model was not overfit on the training data and that there should be few false positives in the resulting inventory. The low number of false positives is important to maintain inventory quality and also to reduce error propagation since the NER model was used on all articles identified during the classification task. The NER model, also BioMed-RoBERTa-RCT, exhibited lower performance metrics than the article classification model, which may be accounted for in primarily two ways. First, determining the name of a resource proved difficult at times even for the curators, especially when the original authors were inconsistent in usage of the resource name. Second, while the article classification task requires a binary classification, the NER task includes five possible classes. This implies that, for instance, if a common name is predicted to be a full name, it is considered a misclassification and has a negative impact on the performance metrics even though the prediction is still valuable. While this paper presents preliminary efforts to provide a comprehensive proof-of-concept, additional work is already underway to further optimize the ML results. Even as preliminary work, we found these tasks performed well enough that the error rate could have been considered acceptable without remediation. While we ultimately decided to augment with a selective, human-mediated review to further enhance confidence and veracity in the resulting inventory, we conclude that the application of NLP models is a powerful tool that dramatically aids completion of what would otherwise be an entirely manual, time intensive, and less systematic process. We believe that this work provides a useful approach for addressing a major challenge in sustaining biodata resources&#x02014;simply being able to monitor an ever-evolving, distributed infrastructure.</p><p>The Global Biodata Coalition (GBC) was formed to ensure sustained support for biodata resources and to ensure continuity of the global infrastructure itself. However, the infrastructure itself is not well-defined, thus complicating discussions about sustainability. The GBC initiated this project in order to provide an overview of this infrastructure: how many biodata resources are there, where are they, and how are they funded? The GBC is using the results of the inventory to identify major funders of biodata resources who 1) may be interested in participating in the GBC or 2) are not currently funding biodata resources but might in future. Additionally, research funders themselves have begun using the inventory to identify biodata resources to which they are contributing support.</p><p>Previous and current efforts to create collections of data resources tend to rely on individual effort for discovery and curation. The results of such work are high quality and have succeeded in enabling the discoverability of thousands of distinct resources. This inventory does not seek to replace such highly curated collections but potentially it could be used to complement them. The main emphasis of this project was to gather together as many resources as possible using a single, reproducible method. We note, however, that many biodata resources were not identified through our pipeline for several reasons, including 1) biodata resources for which there are no published descriptions, 2) biodata resources described in articles that are not indexed in Europe PMC, and and 3) biodata resources for which descriptive articles have been published but that were missed using our methodology through exclusion, misclassification, or inability to extract a resource name. Furthermore, our corpus only included English-language articles.</p><p>While we initially expected to find many of the resources in existing registries, we were surprised by the low overlap. There are several factors that may impact this result. For example, the selection criteria may differ in subtle ways given that there is no universally shared definition of &#x0201c;data&#x0201d; itself. Additionally, some matches may have been missed due to name/URL variation, migrations, or mergers. A comprehensive follow-up that carefully reviews each resource would enable a better understanding of the similarities and differences between the distinct collections. As this follow-up would require a substantial amount of human-mediated curation, other notable collections that were not amenable to the automation utilized here, such as <italic toggle="yes">NAR&#x02019;s</italic> Molecular Biology Database Collection or Database Commons, could be examined as well. One potential use of the inventory is as a catalyst for outreach. For example, journals found to frequently publish biodata resource articles could be approached to encourage or even require registration for those publications. Additionally, the corresponding authors of the resources identified in the inventory could be contacted to encourage registration to increase the discoverability of their resources. While we designed this project assuming that updating the inventory will be necessary, in our ideal future state, all biodata resources are easily located elsewhere.</p><p>At the onset of this project, we identified openness and reproducibility as key to enabling updates, reuse, and extension of this work. A preliminary analysis of the inventory indicates that the availability of article metadata and the high percentage of full text articles will indeed enable reuse. In spite of inherent limitations found in the irregular representation of funding organizations and locations in the associated metadata, the inventory already provides a useful glimpse into this difficult-to-describe distributed infrastructure. For example, even a casual scan of funders revealed national organizations from around the world, including but not limited to, the Research Council of Norway, the Spanish Ministry of Science and Innovation, the Czech Science Foundation, the South African National Research Foundation, the Israel Science Foundation, the Qatar National Research Fund, the Indian Department of Health Research, the National Research Foundation of Korea, the Ministry of Science of Technology of Taiwan, the Australian Research Council, the National Agency for the Promotion of Research, Technological Development and Innovation of Argentina, the Mexican National Council of Science and Technology, and the Oneida Nation Foundation. We hope our efforts to make the inventory completely open and to develop the code in ways that make it accessible to the widest possible audience will help catalyze future work in understanding the global infrastructure of biodata resources.</p></sec><sec id="sec039" sec-type="supplementary-material"><title>Supporting information</title><supplementary-material id="pone.0294812.s001" position="float" content-type="local-data"><label>S1 Fig</label><caption><title>Europe PMC query.</title><p>(TIF)</p></caption><media xlink:href="pone.0294812.s001.tif"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material id="pone.0294812.s002" position="float" content-type="local-data"><label>S2 Fig</label><caption><title>Example of resource name extraction from combined title and abstract.</title><p>Process shows how the tokens are labeled using the BIO scheme and probability scores are output by the linear token classification layer of the BERT model. Tokens are then reassembled into words using the associated word indices (not shown), and the average probability score of the tokens is calculated. Trailing punctuation is removed from predicted resource names.</p><p>(TIF)</p></caption><media xlink:href="pone.0294812.s002.tif"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material id="pone.0294812.s003" position="float" content-type="local-data"><label>S3 Fig</label><caption><title>URL host IP address countries.</title><p>Choropleth map shows URL host IP address countries based on matches to ISO-3166-1 country names or Alpha-3 codes. Color is scaled to the number of times that country&#x02019;s name appeared as a host IP address location. Figure was created using the R ggplot2 package which obtains map data from Natural Earth [<xref rid="pone.0294812.ref071" ref-type="bibr">71</xref>], which is in the public domain.</p><p>(TIF)</p></caption><media xlink:href="pone.0294812.s003.tif"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material id="pone.0294812.s004" position="float" content-type="local-data"><label>S4 Fig</label><caption><title>Author affiliation countries.</title><p>Choropleth map shows author affiliation countries based on matches to ISO-3166-1 country names or Alpha-3 codes. Color is scaled to the number of times that country&#x02019;s name appeared in the author affiliations across all articles in the inventory. Figure was created using the R ggplot2 package which obtains map data from Natural Earth [<xref rid="pone.0294812.ref071" ref-type="bibr">71</xref>], which is in the public domain.</p><p>(TIF)</p></caption><media xlink:href="pone.0294812.s004.tif"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material id="pone.0294812.s005" position="float" content-type="local-data"><label>S1 Table</label><caption><title>Definitions consulted for &#x0201c;Life sciences biodata&#x0201d;.</title><p>(PDF)</p></caption><media xlink:href="pone.0294812.s005.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material id="pone.0294812.s006" position="float" content-type="local-data"><label>S2 Table</label><caption><title>Definitions consulted for &#x0201c;Biodata resource&#x0201d;.</title><p>(PDF)</p></caption><media xlink:href="pone.0294812.s006.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material id="pone.0294812.s007" position="float" content-type="local-data"><label>S3 Table</label><caption><title>APIs used.</title><p>(PDF)</p></caption><media xlink:href="pone.0294812.s007.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material id="pone.0294812.s008" position="float" content-type="local-data"><label>S4 Table</label><caption><title>Hyperparameters used for model fine-tuning for article classification and NER tasks.</title><p>(PDF)</p></caption><media xlink:href="pone.0294812.s008.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material id="pone.0294812.s009" position="float" content-type="local-data"><label>S5 Table</label><caption><title>Article classification model performance.</title><p>Performance metrics are shown for both the validation and test sets. Models are arranged in decreasing order of precision on the validation set, which was used for model selection.</p><p>(PDF)</p></caption><media xlink:href="pone.0294812.s009.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material id="pone.0294812.s010" position="float" content-type="local-data"><label>S6 Table</label><caption><title>NER model performance.</title><p>Performance metrics are shown for both the validation and test sets. Models are arranged in decreasing order of <italic toggle="yes">F</italic>1 score on the validation set, which was used for model selection.</p><p>(PDF)</p></caption><media xlink:href="pone.0294812.s010.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material id="pone.0294812.s011" position="float" content-type="local-data"><label>S7 Table</label><caption><title>Open science products.</title><p>(PDF)</p></caption><media xlink:href="pone.0294812.s011.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><ack><p>The authors would like to thank colleagues at the Chan Zuckerberg Initiative, in particular Dario Taraborelli, Donghui Li, Gully Burns, and Emanuele Bezzi, for their support and feedback on earlier versions of this study. We also thank Ken Youens-Clark formerly at The University of Arizona, Alise Ponsero at The University of Helsinki, and Bonnie Hurwitz at The University of Arizona for their mentorship of Kenneth Schackart. Additionally, we thank the Europe PMC team, especially Aravind Venkatesan, Mohamed Selim, and Melissa Harrison, for their guidance and expertise. Finally, we would like to acknowledge Jodie Forbes for detailed review of the associated code and documentation.</p><p>To reflect the contributions of the individual authors more fully, the following details are provided in addition to those mapped to the <ext-link xlink:href="https://casrai.org/credit/" ext-link-type="uri">CRediT Taxonomy</ext-link>: HJI&#x02014;Project conceptualization and planning; Manual data curation; Development of preliminary code for data analysis; Project oversight and administration; Data validation; Writing of manuscript; KES&#x02014;Manual data curation; Implementation of machine learning methodology; Design and implementation of code for processing and augmenting predicted resources, automation of pipelines, unit testing and static code checks, and data analysis; Creation of data visualizations and figures; Data validation; Writing of manuscript; AMI&#x02014;Design of the machine learning methodology; Implementation of code for training, prediction and evaluation of the NLP models used to classify articles and extract individual resources; Writing of manuscript; CEC&#x02014;Project conceptualization and planning; Manual data curation; Funding acquisition; Project oversight; Data validation; Writing of manuscript.</p></ack><ref-list><title>References</title><ref id="pone.0294812.ref001"><label>1</label><mixed-citation publication-type="journal"><name><surname>Drysdale</surname><given-names>R</given-names></name>, <name><surname>Cook</surname><given-names>CE</given-names></name>, <name><surname>Petryszak</surname><given-names>R</given-names></name>, <name><surname>Baillie-Gerritsen</surname><given-names>V</given-names></name>, <name><surname>Barlow</surname><given-names>M</given-names></name>, <name><surname>Gasteiger</surname><given-names>E</given-names></name>, <etal>et al</etal>. <article-title>The ELIXIR Core Data Resources: fundamental infrastructure for the life sciences</article-title>. <source>Bioinformatics</source>. <year>2020</year>;<volume>36</volume>: <fpage>2636</fpage>&#x02013;<lpage>2642</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btz959</pub-id>
<?supplied-pmid 31950984?><pub-id pub-id-type="pmid">31950984</pub-id></mixed-citation></ref><ref id="pone.0294812.ref002"><label>2</label><mixed-citation publication-type="journal"><name><surname>Gabella</surname><given-names>C</given-names></name>, <name><surname>Durinx</surname><given-names>C</given-names></name>, <name><surname>Appel</surname><given-names>R</given-names></name>. <article-title>Funding knowledgebases: Towards a sustainable funding model for the UniProt use case.</article-title>
<source>F1000Research; 2018.</source>
<comment>doi: </comment><pub-id pub-id-type="doi">10.12688/f1000research.12989.2</pub-id>
<?supplied-pmid 29333230?><pub-id pub-id-type="pmid">29333230</pub-id></mixed-citation></ref><ref id="pone.0294812.ref003"><label>3</label><mixed-citation publication-type="journal"><name><surname>Southan</surname><given-names>C</given-names></name>, <name><surname>Cameron</surname><given-names>G</given-names></name>. <article-title>D2.1: Database Provider Survey report for ELIXIR Work Package 2.</article-title>
<source>Zenodo</source>. <year>2017</year> [cited 2 Jan 2018]. <comment>doi: </comment><pub-id pub-id-type="doi">10.5281/zenodo.576013</pub-id></mixed-citation></ref><ref id="pone.0294812.ref004"><label>4</label><mixed-citation publication-type="journal"><name><surname>Bourne</surname><given-names>PE</given-names></name>, <name><surname>Lorsch</surname><given-names>JR</given-names></name>, <name><surname>Green</surname><given-names>ED</given-names></name>. <article-title>Perspective: Sustaining the big-data ecosystem</article-title>. <source>Nature</source>. <year>2015</year>;<volume>527</volume>: <fpage>S16</fpage>&#x02013;<lpage>S17</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/527S16a</pub-id>
<?supplied-pmid 26536219?><pub-id pub-id-type="pmid">26536219</pub-id></mixed-citation></ref><ref id="pone.0294812.ref005"><label>5</label><mixed-citation publication-type="journal"><name><surname>Anderson</surname><given-names>WP</given-names></name>. <article-title>Data management: A global coalition to sustain core data</article-title>. <source>Nature</source>. <year>2017</year>;<volume>543</volume>: <fpage>179</fpage>&#x02013;<lpage>179</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/543179a</pub-id>
<?supplied-pmid 28277502?><pub-id pub-id-type="pmid">28277502</pub-id></mixed-citation></ref><ref id="pone.0294812.ref006"><label>6</label><mixed-citation publication-type="journal"><name><surname>Discala</surname><given-names>C</given-names></name>, <name><surname>Benigni</surname><given-names>X</given-names></name>, <name><surname>Barillot</surname><given-names>E</given-names></name>, <name><surname>Vaysseix</surname><given-names>G</given-names></name>. <article-title>DBcat: a catalog of 500 biological databases</article-title>. <source>Nucleic Acids Research</source>. <year>2000</year>;<volume>28</volume>: <fpage>8</fpage>&#x02013;<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/28.1.8</pub-id>
<?supplied-pmid 10592168?><pub-id pub-id-type="pmid">10592168</pub-id></mixed-citation></ref><ref id="pone.0294812.ref007"><label>7</label><mixed-citation publication-type="journal"><name><surname>Blair</surname><given-names>J</given-names></name>, <name><surname>Gwiazdowski</surname><given-names>R</given-names></name>, <name><surname>Borrelli</surname><given-names>A</given-names></name>, <name><surname>Hotchkiss</surname><given-names>M</given-names></name>, <name><surname>Park</surname><given-names>C</given-names></name>, <name><surname>Perrett</surname><given-names>G</given-names></name>, <etal>et al</etal>. <article-title>Towards a catalogue of biodiversity databases: An ontological case study</article-title>. <source>Biodiversity Data Journal</source>. <year>2020</year>;<volume>8</volume>: <fpage>e32765</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3897/BDJ.8.e32765</pub-id>
<?supplied-pmid 32269475?><pub-id pub-id-type="pmid">32269475</pub-id></mixed-citation></ref><ref id="pone.0294812.ref008"><label>8</label><mixed-citation publication-type="other">National Institutes of Health. Open Domain-Specific Data Sharing Repositories. [cited 29 Jun 2022]. Available: <ext-link xlink:href="https://web.archive.org/web/20220629130906/https://www.nlm.nih.gov/NIHbmic/domain_specific_repositories.html" ext-link-type="uri">https://web.archive.org/web/20220629130906/https://www.nlm.nih.gov/NIHbmic/domain_specific_repositories.html</ext-link></mixed-citation></ref><ref id="pone.0294812.ref009"><label>9</label><mixed-citation publication-type="other">New Mexico State University. Finding Data Repositories. [cited 3 Jan 2023]. Available: <ext-link xlink:href="https://web.archive.org/web/20230103221358/https://nmsu.libguides.com/c.php?g=400282&#x00026;p=2901830#Biology" ext-link-type="uri">https://web.archive.org/web/20230103221358/https://nmsu.libguides.com/c.php?g=400282&#x00026;p=2901830#Biology</ext-link></mixed-citation></ref><ref id="pone.0294812.ref010"><label>10</label><mixed-citation publication-type="other">PLOS One. Recommended Repositories. [cited 27 Oct 2022]. Available: <ext-link xlink:href="https://web.archive.org/web/20221027180613/https://journals.plos.org/plosone/s/recommended-repositories" ext-link-type="uri">https://web.archive.org/web/20221027180613/https://journals.plos.org/plosone/s/recommended-repositories</ext-link></mixed-citation></ref><ref id="pone.0294812.ref011"><label>11</label><mixed-citation publication-type="other">Wikipedia. List of biological databases. Available: <ext-link xlink:href="https://web.archive.org/web/20220901083649/https://en.wikipedia.org/wiki/List_of_biological_databases" ext-link-type="uri">https://web.archive.org/web/20220901083649/https://en.wikipedia.org/wiki/List_of_biological_databases</ext-link></mixed-citation></ref><ref id="pone.0294812.ref012"><label>12</label><mixed-citation publication-type="journal"><name><surname>Rigden</surname><given-names>DJ</given-names></name>, <name><surname>Fern&#x000e1;ndez</surname><given-names>XM</given-names></name>. <article-title>The 2023 Nucleic Acids Research Database Issue and the online molecular biology database collection</article-title>. <source>Nucleic Acids Research</source>. <year>2023</year>;<volume>51</volume>: <fpage>D1</fpage>&#x02013;<lpage>D8</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gkac1186</pub-id>
<?supplied-pmid 36624667?><pub-id pub-id-type="pmid">36624667</pub-id></mixed-citation></ref><ref id="pone.0294812.ref013"><label>13</label><mixed-citation publication-type="journal"><name><surname>Pampel</surname><given-names>H</given-names></name>, <name><surname>Vierkant</surname><given-names>P</given-names></name>, <name><surname>Scholze</surname><given-names>F</given-names></name>, <name><surname>Bertelmann</surname><given-names>R</given-names></name>, <name><surname>Kindling</surname><given-names>M</given-names></name>, <name><surname>Klump</surname><given-names>J</given-names></name>, <etal>et al</etal>. <article-title>Making Research Data Repositories Visible: The re3data.org Registry.</article-title>
<source>PLOS ONE.</source>
<year>2013</year>;<volume>8</volume>: <fpage>e78080</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0078080</pub-id>
<?supplied-pmid 24223762?><pub-id pub-id-type="pmid">24223762</pub-id></mixed-citation></ref><ref id="pone.0294812.ref014"><label>14</label><mixed-citation publication-type="journal"><name><surname>Sansone</surname><given-names>S-A</given-names></name>, <name><surname>McQuilton</surname><given-names>P</given-names></name>, <name><surname>Rocca-Serra</surname><given-names>P</given-names></name>, <name><surname>Gonzalez-Beltran</surname><given-names>A</given-names></name>, <name><surname>Izzo</surname><given-names>M</given-names></name>, <name><surname>Lister</surname><given-names>AL</given-names></name>, <etal>et al</etal>. <article-title>FAIRsharing as a community approach to standards, repositories and policies</article-title>. <source>Nat Biotechnol</source>. <year>2019</year>;<volume>37</volume>: <fpage>358</fpage>&#x02013;<lpage>367</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41587-019-0080-8</pub-id>
<?supplied-pmid 30940948?><pub-id pub-id-type="pmid">30940948</pub-id></mixed-citation></ref><ref id="pone.0294812.ref015"><label>15</label><mixed-citation publication-type="journal"><name><surname>Bandrowski</surname><given-names>A</given-names></name>, <name><surname>Brush</surname><given-names>M</given-names></name>, <name><surname>Grethe</surname><given-names>JS</given-names></name>, <name><surname>Haendel</surname><given-names>MA</given-names></name>, <name><surname>Kennedy</surname><given-names>DN</given-names></name>, <name><surname>Hill</surname><given-names>S</given-names></name>, <etal>et al</etal>. <article-title>The Resource Identification Initiative: A cultural shift in publishing.</article-title>
<source>F1000Research;</source>
<year>2015</year>
<month>Nov</month>. Report No.: <volume>4</volume>:<fpage>134</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.12688/f1000research.6555.2</pub-id>
<?supplied-pmid 26594330?><pub-id pub-id-type="pmid">26594330</pub-id></mixed-citation></ref><ref id="pone.0294812.ref016"><label>16</label><mixed-citation publication-type="journal"><name><surname>Wren</surname><given-names>JD</given-names></name>, <name><surname>Georgescu</surname><given-names>C</given-names></name>, <name><surname>Giles</surname><given-names>CB</given-names></name>, <name><surname>Hennessey</surname><given-names>J</given-names></name>. <article-title>Use it or lose it: citations predict the continued online availability of published bioinformatics resources</article-title>. <source>Nucleic Acids Res</source>. <year>2017</year>;<volume>45</volume>: <fpage>3627</fpage>&#x02013;<lpage>3633</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gkx182</pub-id>
<?supplied-pmid 28334982?><pub-id pub-id-type="pmid">28334982</pub-id></mixed-citation></ref><ref id="pone.0294812.ref017"><label>17</label><mixed-citation publication-type="journal"><name><surname>Ferguson</surname><given-names>C</given-names></name>, <name><surname>Ara&#x000fa;jo</surname><given-names>D</given-names></name>, <name><surname>Faulk</surname><given-names>L</given-names></name>, <name><surname>Gou</surname><given-names>Y</given-names></name>, <name><surname>Hamelers</surname><given-names>A</given-names></name>, <name><surname>Huang</surname><given-names>Z</given-names></name>, <etal>et al</etal>. <article-title>Europe PMC in 2020</article-title>. <source>Nucleic Acids Research</source>. <year>2021</year>;<volume>49</volume>: <fpage>D1507</fpage>&#x02013;<lpage>D1514</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gkaa994</pub-id>
<?supplied-pmid 33180112?><pub-id pub-id-type="pmid">33180112</pub-id></mixed-citation></ref><ref id="pone.0294812.ref018"><label>18</label><mixed-citation publication-type="journal"><name><surname>K&#x000f6;ster</surname><given-names>J</given-names></name>, <name><surname>Rahmann</surname><given-names>S</given-names></name>. <article-title>Snakemake&#x02014;a scalable bioinformatics workflow engine</article-title>. <source>Bioinformatics</source>. <year>2012</year>;<volume>28</volume>: <fpage>2520</fpage>&#x02013;<lpage>2522</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/bts480</pub-id>
<?supplied-pmid 22908215?><pub-id pub-id-type="pmid">22908215</pub-id></mixed-citation></ref><ref id="pone.0294812.ref019"><label>19</label><mixed-citation publication-type="journal"><name><surname>Imker</surname><given-names>HJ</given-names></name>, <name><surname>Schackart</surname><given-names>KE</given-names></name>. <source>Open Science Implementation Plan for the Biodata Resource Inventory</source>. <year>2022</year> [cited 2 Dec 2022]. <comment>doi: </comment><pub-id pub-id-type="doi">10.5281/zenodo.7392518</pub-id></mixed-citation></ref><ref id="pone.0294812.ref020"><label>20</label><mixed-citation publication-type="journal"><name><surname>Heil</surname><given-names>BJ</given-names></name>, <name><surname>Hoffman</surname><given-names>MM</given-names></name>, <name><surname>Markowetz</surname><given-names>F</given-names></name>, <name><surname>Lee</surname><given-names>S-I</given-names></name>, <name><surname>Greene</surname><given-names>CS</given-names></name>, <name><surname>Hicks</surname><given-names>SC</given-names></name>. <article-title>Reproducibility standards for machine learning in the life sciences</article-title>. <source>Nat Methods</source>. <year>2021</year>;<volume>18</volume>: <fpage>1132</fpage>&#x02013;<lpage>1135</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41592-021-01256-7</pub-id>
<?supplied-pmid 34462593?><pub-id pub-id-type="pmid">34462593</pub-id></mixed-citation></ref><ref id="pone.0294812.ref021"><label>21</label><mixed-citation publication-type="journal"><name><surname>Schackart</surname><given-names>KE</given-names><suffix>III</suffix></name>, <name><surname>Imker</surname><given-names>HJ</given-names></name>, <name><surname>Cook</surname><given-names>CE</given-names></name>. <article-title>Detailed Implementation of a Reproducible Machine Learning-Enabled Workflow.</article-title>
<source>Zenodo</source>; <year>2023</year>
<month>Mar</month>. <comment>doi: </comment><pub-id pub-id-type="doi">10.5281/zenodo.7767793</pub-id></mixed-citation></ref><ref id="pone.0294812.ref022"><label>22</label><mixed-citation publication-type="journal"><name><surname>Chandra</surname><given-names>RV</given-names></name>, <name><surname>Varanasi</surname><given-names>BS</given-names></name>. <article-title>Python requests essentials.</article-title>
<source>Packt Publishing Ltd</source>; <year>2015</year>.</mixed-citation></ref><ref id="pone.0294812.ref023"><label>23</label><mixed-citation publication-type="journal"><name><surname>Wulff</surname><given-names>P</given-names></name>, <name><surname>Mientus</surname><given-names>L</given-names></name>, <name><surname>Nowak</surname><given-names>A</given-names></name>, <name><surname>Borowski</surname><given-names>A</given-names></name>. <article-title>Utilizing a Pretrained Language Model (BERT) to Classify Preservice Physics Teachers&#x02019; Written Reflections.</article-title>
<source>Int J Artif Intell Educ</source>. <year>2023</year>;<volume>33</volume>: <fpage>439</fpage>&#x02013;<lpage>466</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s40593-022-00290-6</pub-id></mixed-citation></ref><ref id="pone.0294812.ref024"><label>24</label><mixed-citation publication-type="journal"><name><surname>Devlin</surname><given-names>J</given-names></name>, <name><surname>Chang</surname><given-names>M-W</given-names></name>, <name><surname>Lee</surname><given-names>K</given-names></name>, <name><surname>Toutanova</surname><given-names>K</given-names></name>. <article-title>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.</article-title>
<source>arXiv:181004805 [cs].</source>
<year>2019</year> [cited 25 Apr 2022]. Available: <ext-link xlink:href="http://arxiv.org/abs/1810.04805" ext-link-type="uri">http://arxiv.org/abs/1810.04805</ext-link></mixed-citation></ref><ref id="pone.0294812.ref025"><label>25</label><mixed-citation publication-type="journal"><name><surname>Lee</surname><given-names>J</given-names></name>, <name><surname>Yoon</surname><given-names>W</given-names></name>, <name><surname>Kim</surname><given-names>S</given-names></name>, <name><surname>Kim</surname><given-names>D</given-names></name>, <name><surname>Kim</surname><given-names>S</given-names></name>, <name><surname>So</surname><given-names>CH</given-names></name>, <etal>et al</etal>. <article-title>BioBERT: a pre-trained biomedical language representation model for biomedical text mining</article-title>. <source>Bioinformatics</source>. <year>2019</year>; <fpage>btz682</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btz682</pub-id>
<?supplied-pmid 31501885?><pub-id pub-id-type="pmid">31501885</pub-id></mixed-citation></ref><ref id="pone.0294812.ref026"><label>26</label><mixed-citation publication-type="journal"><name><surname>Kanakarajan</surname><given-names>K raj</given-names></name>, <name><surname>Kundumani</surname><given-names>B</given-names></name>, <name><surname>Sankarasubbu</surname><given-names>M</given-names></name>. <article-title>BioELECTRA:Pretrained Biomedical text Encoder using Discriminators.</article-title>
<source>Proceedings of the 20th Workshop on Biomedical Language Processing. Online: Association for Computational Linguistics</source>; <year>2021</year>. pp. <fpage>143</fpage>&#x02013;<lpage>154</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.18653/v1/2021.bionlp-1.16</pub-id></mixed-citation></ref><ref id="pone.0294812.ref027"><label>27</label><mixed-citation publication-type="journal"><name><surname>Gururangan</surname><given-names>S</given-names></name>, <name><surname>Marasovi&#x00107;</surname><given-names>A</given-names></name>, <name><surname>Swayamdipta</surname><given-names>S</given-names></name>, <name><surname>Lo</surname><given-names>K</given-names></name>, <name><surname>Beltagy</surname><given-names>I</given-names></name>, <name><surname>Downey</surname><given-names>D</given-names></name>, <etal>et al</etal>. <article-title>Don&#x02019;t Stop Pretraining: Adapt Language Models to Domains and Tasks.</article-title>
<source>arXiv:200410964 [cs].</source>
<year>2020</year> [cited 4 May 2022]. Available: <ext-link xlink:href="http://arxiv.org/abs/2004.10964" ext-link-type="uri">http://arxiv.org/abs/2004.10964</ext-link></mixed-citation></ref><ref id="pone.0294812.ref028"><label>28</label><mixed-citation publication-type="journal"><name><surname>Peng</surname><given-names>Y</given-names></name>, <name><surname>Yan</surname><given-names>S</given-names></name>, <name><surname>Lu</surname><given-names>Z</given-names></name>. <source>Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets</source>. arXiv; 2019. Available: <ext-link xlink:href="http://arxiv.org/abs/" ext-link-type="uri">http://arxiv.org/abs/</ext-link><year>1906</year>.05474</mixed-citation></ref><ref id="pone.0294812.ref029"><label>29</label><mixed-citation publication-type="journal"><name><surname>Miolo</surname><given-names>G</given-names></name>, <name><surname>Mantoan</surname><given-names>G</given-names></name>, <name><surname>Orsenigo</surname><given-names>C</given-names></name>. <article-title>ELECTRAMed: a new pre-trained language representation model for biomedical NLP.</article-title>
<source>arXiv:210409585 [cs].</source>
<year>2021</year> [cited 22 Apr 2022]. Available: <ext-link xlink:href="http://arxiv.org/abs/2104.09585" ext-link-type="uri">http://arxiv.org/abs/2104.09585</ext-link></mixed-citation></ref><ref id="pone.0294812.ref030"><label>30</label><mixed-citation publication-type="journal"><name><surname>Gu</surname><given-names>Y</given-names></name>, <name><surname>Tinn</surname><given-names>R</given-names></name>, <name><surname>Cheng</surname><given-names>H</given-names></name>, <name><surname>Lucas</surname><given-names>M</given-names></name>, <name><surname>Usuyama</surname><given-names>N</given-names></name>, <name><surname>Liu</surname><given-names>X</given-names></name>, <etal>et al</etal>. <article-title>Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing.</article-title>
<source>ACM Trans Comput Healthcare.</source>
<year>2021</year>;<volume>3</volume>: <issue>2</issue>:<fpage>1</fpage>&#x02013;<lpage>2:23</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1145/3458754</pub-id></mixed-citation></ref><ref id="pone.0294812.ref031"><label>31</label><mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>F</given-names></name>, <name><surname>Shareghi</surname><given-names>E</given-names></name>, <name><surname>Meng</surname><given-names>Z</given-names></name>, <name><surname>Basaldella</surname><given-names>M</given-names></name>, <name><surname>Collier</surname><given-names>N</given-names></name>. <article-title>Self-Alignment Pretraining for Biomedical Entity Representations.</article-title>
<source>arXiv</source>; <year>2021</year>. <comment>doi: </comment><pub-id pub-id-type="doi">10.48550/arXiv.2010.11784</pub-id></mixed-citation></ref><ref id="pone.0294812.ref032"><label>32</label><mixed-citation publication-type="journal"><name><surname>Beltagy</surname><given-names>I</given-names></name>, <name><surname>Lo</surname><given-names>K</given-names></name>, <name><surname>Cohan</surname><given-names>A</given-names></name>. <article-title>SciBERT: A Pretrained Language Model for Scientific Text.</article-title>
<source>arXiv</source>; <year>2019</year>. <comment>doi: </comment><pub-id pub-id-type="doi">10.48550/arXiv.1903.10676</pub-id></mixed-citation></ref><ref id="pone.0294812.ref033"><label>33</label><mixed-citation publication-type="journal"><name><surname>Ramshaw</surname><given-names>LA</given-names></name>, <name><surname>Marcus</surname><given-names>MP</given-names></name>. <article-title>Text Chunking using Transformation-Based Learning.</article-title>
<source>arXiv</source>; <year>1995</year>. <comment>doi: </comment><pub-id pub-id-type="doi">10.48550/arXiv.cmp-lg/9505040</pub-id></mixed-citation></ref><ref id="pone.0294812.ref034"><label>34</label><mixed-citation publication-type="journal"><name><surname>Wolf</surname><given-names>T</given-names></name>, <name><surname>Debut</surname><given-names>L</given-names></name>, <name><surname>Sanh</surname><given-names>V</given-names></name>, <name><surname>Chaumond</surname><given-names>J</given-names></name>, <name><surname>Delangue</surname><given-names>C</given-names></name>, <name><surname>Moi</surname><given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Transformers: State-of-the-Art Natural Language Processing</article-title>. <source>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. Online: Association for Computational Linguistics;</source>
<year>2020</year>. pp. <fpage>38</fpage>&#x02013;<lpage>45</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.18653/v1/2020.emnlp-demos.6</pub-id></mixed-citation></ref><ref id="pone.0294812.ref035"><label>35</label><mixed-citation publication-type="journal"><name><surname>Lhoest</surname><given-names>Q</given-names></name>, <name><surname>Villanova del Moral</surname><given-names>A</given-names></name>, <name><surname>Jernite</surname><given-names>Y</given-names></name>, <name><surname>Thakur</surname><given-names>A</given-names></name>, <name><surname>von Platen</surname><given-names>P</given-names></name>, <name><surname>Patil</surname><given-names>S</given-names></name>, <etal>et al</etal>. <article-title>Datasets: A Community Library for Natural Language Processing. Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</article-title>. <source>Online and Punta Cana, Dominican Republic: Association for Computational Linguistics</source>; <year>2021</year>. pp. <fpage>175</fpage>&#x02013;<lpage>184</lpage>. Available: <ext-link xlink:href="https://aclanthology.org/2021.emnlp-demo.21" ext-link-type="uri">https://aclanthology.org/2021.emnlp-demo.21</ext-link></mixed-citation></ref><ref id="pone.0294812.ref036"><label>36</label><mixed-citation publication-type="journal"><name><surname>Bird</surname><given-names>S</given-names></name>, <name><surname>Klein</surname><given-names>E</given-names></name>, <name><surname>Loper</surname><given-names>E</given-names></name>. <article-title>Natural language processing with Python: analyzing text with the natural language toolkit.</article-title>
<source>O&#x02019;Reilly Media, Inc</source>.; <year>2009</year>.</mixed-citation></ref><ref id="pone.0294812.ref037"><label>37</label><mixed-citation publication-type="journal"><name><surname>Harris</surname><given-names>CR</given-names></name>, <name><surname>Millman</surname><given-names>KJ</given-names></name>, <name><surname>Walt</surname><given-names>SJ van der</given-names></name>, <name><surname>Gommers</surname><given-names>R</given-names></name>, <name><surname>Virtanen</surname><given-names>P</given-names></name>, <name><surname>Cournapeau</surname><given-names>D</given-names></name>, <etal>et al</etal>. <article-title>Array programming with NumPy</article-title>. <source>Nature</source>. <year>2020</year>;<volume>585</volume>: <fpage>357</fpage>&#x02013;<lpage>362</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41586-020-2649-2</pub-id>
<?supplied-pmid 32939066?><pub-id pub-id-type="pmid">32939066</pub-id></mixed-citation></ref><ref id="pone.0294812.ref038"><label>38</label><mixed-citation publication-type="journal"><issue>The pandas development team</issue>. <source>Pandas. Zenodo</source>; <year>2020</year>. <comment>doi: </comment><pub-id pub-id-type="doi">10.5281/zenodo.3509134</pub-id></mixed-citation></ref><ref id="pone.0294812.ref039"><label>39</label><mixed-citation publication-type="journal"><name><surname>Krekel</surname><given-names>H.</given-names></name>
<article-title>pytest: The pytest framework makes it easy to write small tests</article-title>, <source>yet scales to support complex functional testing</source>. <year>2004</year>. Available: <ext-link xlink:href="https://github.com/pytest-dev/pytest" ext-link-type="uri">https://github.com/pytest-dev/pytest</ext-link></mixed-citation></ref><ref id="pone.0294812.ref040"><label>40</label><mixed-citation publication-type="journal"><name><surname>Pedregosa</surname><given-names>F</given-names></name>, <name><surname>Varoquaux</surname><given-names>G</given-names></name>, <name><surname>Gramfort</surname><given-names>A</given-names></name>, <name><surname>Michel</surname><given-names>V</given-names></name>, <name><surname>Thirion</surname><given-names>B</given-names></name>, <name><surname>Grisel</surname><given-names>O</given-names></name>, <etal>et al</etal>. <article-title>Scikit-learn: Machine learning in Python</article-title>. <source>Journal of machine learning research</source>. <year>2011</year>;<volume>12</volume>: <fpage>2825</fpage>&#x02013;<lpage>2830</lpage>.</mixed-citation></ref><ref id="pone.0294812.ref041"><label>41</label><mixed-citation publication-type="journal"><collab>PyTorch Team</collab>. <source>PyTorch: An Imperative Style, High-Performance Deep Learning Library.</source>
<year>2019</year>. Available: <ext-link xlink:href="https://pytorch.org" ext-link-type="uri">https://pytorch.org</ext-link></mixed-citation></ref><ref id="pone.0294812.ref042"><label>42</label><mixed-citation publication-type="journal"><name><surname>Costa-Luis</surname><given-names>C da</given-names></name>, <name><surname>Larroque</surname><given-names>SK</given-names></name>, <name><surname>Altendorf</surname><given-names>K</given-names></name>, <name><surname>Mary</surname><given-names>H</given-names></name>, <name><surname>Sheridan</surname><given-names>R</given-names></name>, <name><surname>Korobov</surname><given-names>M</given-names></name>, <etal>et al</etal>. <article-title>tqdm: A fast, Extensible Progress Bar for Python and CLI.</article-title>
<source>Zenodo</source>; <year>2022</year>. <comment>doi: </comment><pub-id pub-id-type="doi">10.5281/zenodo.7046742</pub-id></mixed-citation></ref><ref id="pone.0294812.ref043"><label>43</label><mixed-citation publication-type="journal"><name><surname>Petrov</surname><given-names>A</given-names></name>, <name><surname>Larson</surname><given-names>SM</given-names></name>, <name><surname>Verma</surname><given-names>P</given-names></name>, <name><surname>Garg</surname><given-names>H</given-names></name>. <source>urllib3: Python HTTP library with thread-safe connection pooling, file post support, user friendly, and more.</source>
<year>2008</year>. Available: <ext-link xlink:href="https://github.com/urllib3/urllib3" ext-link-type="uri">https://github.com/urllib3/urllib3</ext-link></mixed-citation></ref><ref id="pone.0294812.ref044"><label>44</label><mixed-citation publication-type="journal"><name><surname>Niu</surname><given-names>J.</given-names></name>
<article-title>An Overview of Web Archiving.</article-title>
<source>D-Lib Magazine</source>. <year>2012</year>;<fpage>18</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1045/march2012-niu1</pub-id></mixed-citation></ref><ref id="pone.0294812.ref045"><label>45</label><mixed-citation publication-type="book"><ext-link xlink:href="http://ipinfo.io/" ext-link-type="uri">ipinfo.io/</ext-link>. <source>IP address API: geolocation, VPN detection, company data and more.</source>
<ext-link xlink:href="http://ipinfo.io/" ext-link-type="uri">ipinfo.io/</ext-link>; <year>2013</year>. Available: <ext-link xlink:href="https://ipinfo.io/" ext-link-type="uri">https://ipinfo.io/</ext-link></mixed-citation></ref><ref id="pone.0294812.ref046"><label>46</label><mixed-citation publication-type="other">ipapi: Real-time geolocation and reverse IP lookup JSON API. APILayer; Available: <ext-link xlink:href="https://ipapi.com/" ext-link-type="uri">https://ipapi.com/</ext-link></mixed-citation></ref><ref id="pone.0294812.ref047"><label>47</label><mixed-citation publication-type="other">Country Codes&#x02014;ISO 3166. International Organization for Standardization (ISO); Available: <ext-link xlink:href="https://www.iso.org/iso-3166-country-codes.html" ext-link-type="uri">https://www.iso.org/iso-3166-country-codes.html</ext-link></mixed-citation></ref><ref id="pone.0294812.ref048"><label>48</label><mixed-citation publication-type="journal"><name><surname>Davis</surname><given-names>TL</given-names></name>. <source>argparse: Command Line Optional and Positional Argument Parser</source>. <year>2022</year>. Available: <ext-link xlink:href="https://CRAN.R-project.org/package=argparse" ext-link-type="uri">https://CRAN.R-project.org/package=argparse</ext-link></mixed-citation></ref><ref id="pone.0294812.ref049"><label>49</label><mixed-citation publication-type="journal"><name><surname>Wickham</surname><given-names>H</given-names></name>, <name><surname>Fran&#x000e7;ois</surname><given-names>R</given-names></name>, <name><surname>Henry</surname><given-names>L</given-names></name>, <name><surname>M&#x000fc;ller</surname><given-names>K</given-names></name>. <source>dplyr: A Grammar of Data Manipulation.</source>
<year>2022</year>. Available: <ext-link xlink:href="https://CRAN.R-project.org/package=dplyr" ext-link-type="uri">https://CRAN.R-project.org/package=dplyr</ext-link></mixed-citation></ref><ref id="pone.0294812.ref050"><label>50</label><mixed-citation publication-type="journal"><name><surname>Jahn</surname><given-names>N.</given-names></name> europepmc: <source>R Interface to the Europe PubMed Central RESTful Web Service</source>. <year>2021</year>. Available: <ext-link xlink:href="https://CRAN.R-project.org/package=europepmc" ext-link-type="uri">https://CRAN.R-project.org/package=europepmc</ext-link></mixed-citation></ref><ref id="pone.0294812.ref051"><label>51</label><mixed-citation publication-type="journal"><name><surname>Wickham</surname><given-names>H.</given-names></name>
<source>forcats: Tools for Working with Categorical Variables (Factors).</source>
<year>2022</year>. Available: <ext-link xlink:href="https://CRAN.R-project.org/package=forcats" ext-link-type="uri">https://CRAN.R-project.org/package=forcats</ext-link></mixed-citation></ref><ref id="pone.0294812.ref052"><label>52</label><mixed-citation publication-type="journal"><name><surname>Kahle</surname><given-names>D</given-names></name>, <name><surname>Wickham</surname><given-names>H</given-names></name>. <article-title>ggmap: Spatial Visualization with ggplot2</article-title>. <source>The R Journal</source>. <year>2013</year>;<volume>5</volume>: <fpage>144</fpage>&#x02013;<lpage>161</lpage>.</mixed-citation></ref><ref id="pone.0294812.ref053"><label>53</label><mixed-citation publication-type="book"><name><surname>Wickham</surname><given-names>H.</given-names></name>
<source>ggplot2: Elegant Graphics for Data Analysis.</source>
<publisher-name>Springer-Verlag</publisher-name>
<publisher-loc>New York</publisher-loc>; <year>2016</year>. Available: <ext-link xlink:href="https://ggplot2.tidyverse.org" ext-link-type="uri">https://ggplot2.tidyverse.org</ext-link></mixed-citation></ref><ref id="pone.0294812.ref054"><label>54</label><mixed-citation publication-type="journal"><name><surname>Hester</surname><given-names>J</given-names></name>, <name><surname>Bryan</surname><given-names>J</given-names></name>. <source>glue: Interpreted String Literals.</source>
<year>2022</year>. Available: <ext-link xlink:href="https://CRAN.R-project.org/package=glue" ext-link-type="uri">https://CRAN.R-project.org/package=glue</ext-link></mixed-citation></ref><ref id="pone.0294812.ref055"><label>55</label><mixed-citation publication-type="journal"><name><surname>Iannone</surname><given-names>R</given-names></name>, <name><surname>Cheng</surname><given-names>J</given-names></name>, <name><surname>Schloerke</surname><given-names>B</given-names></name>, <name><surname>Hughes</surname><given-names>E</given-names></name>, <name><surname>Seo</surname><given-names>J</given-names></name>. <source>gt: Easily Create Presentation-Ready Display Tables.</source>
<year>2022</year>. Available: <ext-link xlink:href="https://CRAN.R-project.org/package=gt" ext-link-type="uri">https://CRAN.R-project.org/package=gt</ext-link></mixed-citation></ref><ref id="pone.0294812.ref056"><label>56</label><mixed-citation publication-type="journal"><name><surname>Wickham</surname><given-names>H.</given-names></name>
<source>httr: Tools for Working with URLs and HTTP.</source>
<year>2022</year>. Available: <ext-link xlink:href="https://CRAN.R-project.org/package=httr" ext-link-type="uri">https://CRAN.R-project.org/package=httr</ext-link></mixed-citation></ref><ref id="pone.0294812.ref057"><label>57</label><mixed-citation publication-type="journal"><name><surname>Ooms</surname><given-names>J.</given-names></name>
<article-title>The jsonlite Package: A Practical and Consistent Mapping Between JSON Data and R Objects</article-title>. <source>arXiv:14032805 [statCO].</source>
<year>2014</year>. Available: <ext-link xlink:href="https://arxiv.org/abs/1403.2805" ext-link-type="uri">https://arxiv.org/abs/1403.2805</ext-link></mixed-citation></ref><ref id="pone.0294812.ref058"><label>58</label><mixed-citation publication-type="journal"><name><surname>Bache</surname><given-names>SM</given-names></name>, <name><surname>Wickham</surname><given-names>H</given-names></name>. <source>magrittr: A Forward-Pipe Operator for R.</source>
<year>2022</year>. Available: <ext-link xlink:href="https://CRAN.R-project.org/package=magrittr" ext-link-type="uri">https://CRAN.R-project.org/package=magrittr</ext-link></mixed-citation></ref><ref id="pone.0294812.ref059"><label>59</label><mixed-citation publication-type="journal"><name><surname>Brownrigg</surname><given-names>R</given-names></name>, <name><surname>Minka</surname><given-names>TP</given-names></name>, <name><surname>Deckmyn</surname><given-names>A</given-names></name>, <name><surname>Becker</surname><given-names>RA</given-names></name>, <name><surname>Wilks</surname><given-names>AR</given-names></name>. <source>maps: Draw Geographical Maps.</source>
<year>2021</year>. Available: <ext-link xlink:href="https://CRAN.R-project.org/package=maps" ext-link-type="uri">https://CRAN.R-project.org/package=maps</ext-link></mixed-citation></ref><ref id="pone.0294812.ref060"><label>60</label><mixed-citation publication-type="journal"><name><surname>Henry</surname><given-names>L</given-names></name>, <name><surname>Wickham</surname><given-names>H</given-names></name>. <source>purrr: Functional Programming Tools.</source>
<year>2020</year>. Available: <ext-link xlink:href="https://CRAN.R-project.org/package=purrr" ext-link-type="uri">https://CRAN.R-project.org/package=purrr</ext-link></mixed-citation></ref><ref id="pone.0294812.ref061"><label>61</label><mixed-citation publication-type="journal"><name><surname>Neuwirth</surname><given-names>E.</given-names></name>
<source>RColorBrewer: ColorBrewer Palettes</source>. <year>2022</year>. Available: <ext-link xlink:href="https://CRAN.R-project.org/package=RColorBrewer" ext-link-type="uri">https://CRAN.R-project.org/package=RColorBrewer</ext-link></mixed-citation></ref><ref id="pone.0294812.ref062"><label>62</label><mixed-citation publication-type="journal"><name><surname>Wickham</surname><given-names>H</given-names></name>, <name><surname>Hester</surname><given-names>J</given-names></name>, <name><surname>Bryan</surname><given-names>J</given-names></name>. <source>readr: Read Rectangular Text Data.</source>
<year>2022</year>. Available: <ext-link xlink:href="https://CRAN.R-project.org/package=readr" ext-link-type="uri">https://CRAN.R-project.org/package=readr</ext-link></mixed-citation></ref><ref id="pone.0294812.ref063"><label>63</label><mixed-citation publication-type="journal"><name><surname>Wickham</surname><given-names>H</given-names></name>, <name><surname>Seidel</surname><given-names>D</given-names></name>. <source>scales: Scale Functions for Visualization.</source>
<year>2022</year>. Available: <ext-link xlink:href="https://CRAN.R-project.org/package=scales" ext-link-type="uri">https://CRAN.R-project.org/package=scales</ext-link></mixed-citation></ref><ref id="pone.0294812.ref064"><label>64</label><mixed-citation publication-type="journal"><name><surname>Wickham</surname><given-names>H.</given-names></name>
<source>stringr: Simple, Consistent Wrappers for Common String Operations</source>. <year>2019</year>. Available: <ext-link xlink:href="https://CRAN.R-project.org/package=stringr" ext-link-type="uri">https://CRAN.R-project.org/package=stringr</ext-link></mixed-citation></ref><ref id="pone.0294812.ref065"><label>65</label><mixed-citation publication-type="journal"><name><surname>M&#x000fc;ller</surname><given-names>K</given-names></name>, <name><surname>Wickham</surname><given-names>H</given-names></name>. <source>tibble: Simple Data Frames</source>. <year>2022</year>. Available: <ext-link xlink:href="https://CRAN.R-project.org/package=tibble" ext-link-type="uri">https://CRAN.R-project.org/package=tibble</ext-link></mixed-citation></ref><ref id="pone.0294812.ref066"><label>66</label><mixed-citation publication-type="journal"><name><surname>Wickham</surname><given-names>H</given-names></name>, <name><surname>Girlich</surname><given-names>M</given-names></name>. <source>tidyr: Tidy Messy Data</source>. <year>2022</year>. Available: <ext-link xlink:href="https://CRAN.R-project.org/package=tidyr" ext-link-type="uri">https://CRAN.R-project.org/package=tidyr</ext-link></mixed-citation></ref><ref id="pone.0294812.ref067"><label>67</label><mixed-citation publication-type="journal"><name><surname>Wickham</surname><given-names>H</given-names></name>, <name><surname>Hester</surname><given-names>J</given-names></name>, <name><surname>Ooms</surname><given-names>J</given-names></name>. <source>xml2: Parse XML.</source>
<year>2021</year>. Available: <ext-link xlink:href="https://CRAN.R-project.org/package=xml2" ext-link-type="uri">https://CRAN.R-project.org/package=xml2</ext-link></mixed-citation></ref><ref id="pone.0294812.ref068"><label>68</label><mixed-citation publication-type="journal"><name><surname>Lagan&#x000e0;</surname><given-names>A</given-names></name>, <name><surname>Acunzo</surname><given-names>M</given-names></name>, <name><surname>Romano</surname><given-names>G</given-names></name>, <name><surname>Pulvirenti</surname><given-names>A</given-names></name>, <name><surname>Veneziano</surname><given-names>D</given-names></name>, <name><surname>Cascione</surname><given-names>L</given-names></name>, <etal>et al</etal>. <article-title>miR-Synth: a computational resource for the design of multi-site multi-target synthetic miRNAs</article-title>. <source>Nucleic Acids Research</source>. <year>2014</year>;<volume>42</volume>: <fpage>5416</fpage>&#x02013;<lpage>5425</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gku202</pub-id>
<?supplied-pmid 24627222?><pub-id pub-id-type="pmid">24627222</pub-id></mixed-citation></ref><ref id="pone.0294812.ref069"><label>69</label><mixed-citation publication-type="journal"><name><surname>Ziemann</surname><given-names>M</given-names></name>, <name><surname>Kaspi</surname><given-names>A</given-names></name>, <name><surname>El-Osta</surname><given-names>A</given-names></name>. <article-title>Digital expression explorer 2: a repository of uniformly processed RNA sequencing data</article-title>. <source>GigaScience</source>. <year>2019</year>;<volume>8</volume>: <fpage>giz022</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/gigascience/giz022</pub-id>
<?supplied-pmid 30942868?><pub-id pub-id-type="pmid">30942868</pub-id></mixed-citation></ref><ref id="pone.0294812.ref070"><label>70</label><mixed-citation publication-type="book"><name><surname>Drysdale</surname><given-names>R.</given-names></name>
<article-title>FlyBase</article-title>. In: <name><surname>Dahmann</surname><given-names>C</given-names></name>, editor. <source>Drosophila: Methods and Protocols</source>. <publisher-loc>Totowa, NJ</publisher-loc>: <publisher-name>Humana Press</publisher-name>; <year>2008</year>. pp. <fpage>45</fpage>&#x02013;<lpage>59</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/978-1-59745-583-1_3</pub-id>
<?supplied-pmid 18641940?></mixed-citation></ref><ref id="pone.0294812.ref071"><label>71</label><mixed-citation publication-type="other">Patterson T, Kelso NV. World Map. Natural Earth; Available: <ext-link xlink:href="https://www.naturalearthdata.com/" ext-link-type="uri">https://www.naturalearthdata.com/</ext-link></mixed-citation></ref><ref id="pone.0294812.ref072"><label>72</label><mixed-citation publication-type="other">CrossRef. Funder Registry. [cited 23 Oct 2022]. Available: <ext-link xlink:href="https://web.archive.org/web/20221023092819/https://www.crossref.org/documentation/funder-registry/" ext-link-type="uri">https://web.archive.org/web/20221023092819/https://www.crossref.org/documentation/funder-registry/</ext-link></mixed-citation></ref><ref id="pone.0294812.ref073"><label>73</label><mixed-citation publication-type="journal"><name><surname>Imker</surname><given-names>HJ</given-names></name>. <article-title>Who Bears the Burden of Long-Lived Molecular Biology Databases?</article-title>
<source>Data Science Journal</source>. <year>2020</year>;<volume>19</volume>: <fpage>8</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.5334/dsj-2020-008</pub-id></mixed-citation></ref><ref id="pone.0294812.ref074"><label>74</label><mixed-citation publication-type="other">Europe PMC. Annotations. [cited 30 Dec 2022]. Available: <ext-link xlink:href="https://web.archive.org/web/20221230133943/https://europepmc.org/Annotations" ext-link-type="uri">https://web.archive.org/web/20221230133943/https://europepmc.org/Annotations</ext-link></mixed-citation></ref><ref id="pone.0294812.ref075"><label>75</label><mixed-citation publication-type="journal"><name><surname>Martin</surname><given-names>CS</given-names></name>, <name><surname>Repo</surname><given-names>S</given-names></name>, <name><surname>Arenas M&#x000e1;rquez</surname><given-names>J</given-names></name>, <name><surname>Blomberg</surname><given-names>N</given-names></name>, <name><surname>Lauer</surname><given-names>KB</given-names></name>, <name><surname>P&#x000e9;rez Sitj&#x000e0;</surname><given-names>X</given-names></name>, <etal>et al</etal>. <article-title>Demonstrating public value to funders and other stakeholders&#x02014;the journey of ELIXIR, a virtual and distributed research infrastructure for life science data</article-title>. <source>Annals of Public and Cooperative Economics</source>. <year>2021</year>;<volume>92</volume>: <fpage>497</fpage>&#x02013;<lpage>510</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1111/apce.12328</pub-id></mixed-citation></ref><ref id="pone.0294812.ref076"><label>76</label><mixed-citation publication-type="book"><collab>National Academies of Sciences, Engineering, and Medicine</collab>. <source>Life-Cycle Decisions for Biomedical Data: The Challenge of Forecasting Costs |.</source>
<publisher-loc>Washington, DC</publisher-loc>: <publisher-name>The National Academies Press</publisher-name>; <year>2020</year>. Available: <pub-id pub-id-type="doi">10.17226/25639</pub-id></mixed-citation></ref></ref-list></back><sub-article article-type="aggregated-review-documents" id="pone.0294812.r001" specific-use="decision-letter"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0294812.r001</article-id><title-group><article-title>Decision Letter 0</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Bernasconi</surname><given-names>Anna</given-names></name><role>Academic Editor</role></contrib></contrib-group><permissions><copyright-statement>&#x000a9; 2023 Anna Bernasconi</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Anna Bernasconi</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0294812" id="rel-obj001" related-article-type="reviewed-article"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>0</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="letter-date">31 Jul 2023</named-content>
</p><p><!-- <div> -->PONE-D-23-16263<!-- </div> --><!-- <div> -->A machine learning-enabled open biodata resource inventory from the scientific literature<!-- </div> --><!-- <div> -->PLOS ONE</p><p>Dear Dr. Imker,</p><p>Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we feel that it has merit but does not fully meet PLOS ONE&#x02019;s publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.</p><p>Please submit your revised manuscript by Sep 14 2023 11:59PM. If you will need more time than this to complete your revisions, please reply to this message or contact the journal office at&#x000a0;<email>plosone@plos.org</email>. When you're ready to submit your revision, log on to <ext-link xlink:href="https://www.editorialmanager.com/pone/" ext-link-type="uri">https://www.editorialmanager.com/pone/</ext-link> and select the 'Submissions Needing Revision' folder to locate your manuscript file.</p><p>Please include the following items when submitting your revised manuscript:<!-- </div> --><list list-type="bullet"><list-item><p>A rebuttal letter that responds to each point raised by the academic editor and reviewer(s). You should upload this letter as a separate file labeled 'Response to Reviewers'.</p></list-item><list-item><p>A marked-up copy of your manuscript that highlights changes made to the original version. You should upload this as a separate file labeled 'Revised Manuscript with Track Changes'.</p></list-item><list-item><p>An unmarked version of your revised paper without tracked changes. You should upload this as a separate file labeled 'Manuscript'.</p></list-item></list></p><p>If you would like to make changes to your financial disclosure, please include your updated statement in your cover letter. Guidelines for resubmitting your figure files are available below the reviewer comments at the end of this letter.</p><p>If applicable, we recommend that you deposit your laboratory protocols in protocols.io to enhance the reproducibility of your results. Protocols.io assigns your protocol its own identifier (DOI) so that it can be cited independently in the future. For instructions see: <ext-link xlink:href="https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols" ext-link-type="uri">https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols</ext-link>. Additionally, PLOS ONE offers an option for publishing peer-reviewed Lab Protocol articles, which describe protocols hosted on protocols.io. Read more information on sharing protocols at <ext-link xlink:href="https://plos.org/protocols?utm_medium=editorial-email&#x00026;utm_source=authorletters&#x00026;utm_campaign=protocols" ext-link-type="uri">https://plos.org/protocols?utm_medium=editorial-email&#x00026;utm_source=authorletters&#x00026;utm_campaign=protocols</ext-link>.</p><p>We look forward to receiving your revised manuscript.</p><p>Kind regards,</p><p>Anna Bernasconi, PhD</p><p>Academic Editor</p><p>PLOS ONE</p><p>Journal requirements:</p><p>When submitting your revision, we need you to address these additional requirements.</p><p>1. Please ensure that your manuscript meets PLOS ONE's style requirements, including those for file naming. The PLOS ONE style templates can be found at</p><p><ext-link xlink:href="https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf</ext-link> and</p><p>
<ext-link xlink:href="https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf</ext-link>
</p><p>2. Thank you for stating the following financial disclosure:</p><p>&#x0201c;This work was supported by the Chan Zuckerberg Initiative (chanzuckerberg.com), which is a member of the Global Biodata Coalition. This work was also funded by the Global Biodata Coalition (<ext-link xlink:href="http://globalbiodata.org" ext-link-type="uri">globalbiodata.org</ext-link>), a coalition of research funding organizations working towards sustainability of biodata resources worldwide.&#x0201d;</p><p>Please state what role the funders took in the study.&#x000a0; If the funders had no role, please state: "The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript."</p><p>If this statement is not correct you must amend it as needed.</p><p>Please include this amended Role of Funder statement in your cover letter; we will change the online submission form on your behalf.</p><p>3. We note that Figures 7,S3 and S4 in your submission contain [map/satellite] images which may be copyrighted. All PLOS content is published under the Creative Commons Attribution License (CC BY 4.0), which means that the manuscript, images, and Supporting Information files will be freely available online, and any third party is permitted to access, download, copy, distribute, and use these materials in any way, even commercially, with proper attribution. For these reasons, we cannot publish previously copyrighted maps or satellite images created using proprietary data, such as Google software (Google Maps, Street View, and Earth). For more information, see our copyright guidelines: <ext-link xlink:href="http://journals.plos.org/plosone/s/licenses-and-copyright" ext-link-type="uri">http://journals.plos.org/plosone/s/licenses-and-copyright</ext-link>.</p><p>We require you to either (1) present written permission from the copyright holder to publish these figures specifically under the CC BY 4.0 license, or (2) remove the figures from your submission:</p><p>a. You may seek permission from the original copyright holder of Figures 7,S3 and S4 to publish the content specifically under the CC BY 4.0 license.&#x000a0;</p><p>We recommend that you contact the original copyright holder with the Content Permission Form (<ext-link xlink:href="http://journals.plos.org/plosone/s/file?id=7c09/content-permission-form.pdf" ext-link-type="uri">http://journals.plos.org/plosone/s/file?id=7c09/content-permission-form.pdf</ext-link>) and the following text:</p><p>&#x0201c;I request permission for the open-access journal PLOS ONE to publish XXX under the Creative Commons Attribution License (CCAL) CC BY 4.0 (<ext-link xlink:href="http://creativecommons.org/licenses/by/4.0/" ext-link-type="uri">http://creativecommons.org/licenses/by/4.0/</ext-link>). Please be aware that this license allows unrestricted use and distribution, even commercially, by third parties. Please reply and provide explicit written permission to publish XXX under a CC BY license and complete the attached form.&#x0201d;</p><p>Please upload the completed Content Permission Form or other proof of granted permissions as an "Other" file with your submission.</p><p>In the figure caption of the copyrighted figure, please include the following text: &#x0201c;Reprinted from [ref] under a CC BY license, with permission from [name of publisher], original copyright [original copyright year].&#x0201d;</p><p>b. If you are unable to obtain permission from the original copyright holder to publish these figures under the CC BY 4.0 license or if the copyright holder&#x02019;s requirements are incompatible with the CC BY 4.0 license, please either i) remove the figure or ii) supply a replacement figure that complies with the CC BY 4.0 license. Please check copyright information on all replacement figures and update the figure caption with source information. If applicable, please specify in the figure caption text when a figure is similar but not identical to the original image and is therefore for illustrative purposes only.</p><p>The following resources for replacing copyrighted map figures may be helpful:</p><p>USGS National Map Viewer (public domain): <ext-link xlink:href="http://viewer.nationalmap.gov/viewer/" ext-link-type="uri">http://viewer.nationalmap.gov/viewer/</ext-link></p><p>The Gateway to Astronaut Photography of Earth (public domain): <ext-link xlink:href="http://eol.jsc.nasa.gov/sseop/clickmap/" ext-link-type="uri">http://eol.jsc.nasa.gov/sseop/clickmap/</ext-link></p><p>Maps at the CIA (public domain): <ext-link xlink:href="https://www.cia.gov/library/publications/the-world-factbook/index.html" ext-link-type="uri">https://www.cia.gov/library/publications/the-world-factbook/index.html</ext-link> and <ext-link xlink:href="https://www.cia.gov/library/publications/cia-maps-publications/index.html" ext-link-type="uri">https://www.cia.gov/library/publications/cia-maps-publications/index.html</ext-link></p><p>NASA Earth Observatory (public domain): <ext-link xlink:href="http://earthobservatory.nasa.gov/" ext-link-type="uri">http://earthobservatory.nasa.gov/</ext-link></p><p>Landsat: <ext-link xlink:href="http://landsat.visibleearth.nasa.gov/" ext-link-type="uri">http://landsat.visibleearth.nasa.gov/</ext-link></p><p>USGS EROS (Earth Resources Observatory and Science (EROS) Center) (public domain): <ext-link xlink:href="http://eros.usgs.gov/#" ext-link-type="uri">http://eros.usgs.gov/#</ext-link></p><p>Natural Earth (public domain): <ext-link xlink:href="http://www.naturalearthdata.com/" ext-link-type="uri">http://www.naturalearthdata.com/</ext-link></p><p>Additional Editor Comments:</p><p>Dear authors, please take into account all the comments made by the reviewers, who have thoroughly examined your manuscript. Please provide a revised version where changes/additions are highlighted in different color. Especially Rev. 2, who largely appreciated your work, has many suggestions for improvement and for increasing its readership. We will be glad to re-evaluate your work after.</p><p>[Note: HTML markup is below. Please do not edit.]</p><p>Reviewers' comments:</p><p>Reviewer's Responses to Questions</p><p>
<!-- <font color="black"> -->
<bold>Comments to the Author</bold>
</p><p>1. Is the manuscript technically sound, and do the data support the conclusions?</p><p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. <!-- </font> --></p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #2:&#x000a0;Partly</p><p>Reviewer #3:&#x000a0;Yes</p><p>**********</p><p><!-- <font color="black"> -->2. Has the statistical analysis been performed appropriately and rigorously? <!-- </font> --></p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #2:&#x000a0;N/A</p><p>Reviewer #3:&#x000a0;Yes</p><p>**********</p><p><!-- <font color="black"> -->3. Have the authors made all data underlying the findings in their manuscript fully available?</p><p>The <ext-link xlink:href="http://www.plosone.org/static/policies.action#sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data&#x02014;e.g. participant privacy or use of data from a third party&#x02014;those must be specified.<!-- </font> --></p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #2:&#x000a0;Yes</p><p>Reviewer #3:&#x000a0;Yes</p><p>**********</p><p><!-- <font color="black"> -->4. Is the manuscript presented in an intelligible fashion and written in standard English?</p><p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.<!-- </font> --></p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #2:&#x000a0;Yes</p><p>Reviewer #3:&#x000a0;Yes</p><p>**********</p><p><!-- <font color="black"> -->5. Review Comments to the Author</p><p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)<!-- </font> --></p><p>Reviewer #1:&#x000a0;General appreciation: The ML pipelines for the identification of biodata resources were diligently constructed with several verifications along the road. The results have been validated in several manners. The publication is mostly about the method, not about the resulting inventory (which may be at least as interesting).</p><p>Error to be corrected: Line 489: the figure says ESTHER, not ESTER</p><p>Elements that would be valuable to amend are:</p><p>* Lines 672-673: describes the "WHY?" of this inventory. However, this is not well explained nor convincing. The Global Biodata Coalition is about sustaining important databases worldwide and this publication aims to establish a method to describe the background landscape of data resources. Why is this useful? Why do we need the inventory and/or what will be done with it? How does it feed into the work of the Coalition?</p><p>* There is no mentioning about the language of the underlying data resources (this is on a corpus of English-language publications). This seems nevertheless relevant for a global inventory.</p><p>* Section 3.5.3: The section on the comparison with re3<ext-link xlink:href="http://data.org" ext-link-type="uri">data.org</ext-link> and FAIRSHARING could be worked out more diligently. The overlap is less than 20%, leading the authors to state that both methods are complementary. Being complementary implies that their purpose is similar and that the 3 inventories will feed into the work of the Global Biodata Coalition. (This again points to the WHY? of the work as they can only be complementary if the aim is similar.) There are alternative explanations possible that are not addressed: The underlying collections of resources are not at all comparable and therefore both inventories are not valid benchmarks. Or the method described by the authors is missing a large part of the resources. Further clarification is therefore needed. NAR would have been a useful source for a verification. Is there any other way to use the NAR data for verification through a human, manual check as the FAIRSHARING/re3<ext-link xlink:href="http://data.org" ext-link-type="uri">data.org</ext-link> verification has not allowed any firm conclusions?</p><p>* Section 3.4 about URL testing: 29% of the URLs did not resolve. There would be another 6.5% false positives. We know that many data resources are archived over time or disappear. Is this number of about 35% of data resources unavailable within what is expected based on the literature?</p><p>Reviewer #2:&#x000a0;Overall, the authors make a compelling case for the need for a pipeline to find biodata resources automatically based on the reliance of biological science on such resources. The focus on open science is also very valuable for future use and updates of such a repository of biodata resources. At the same time, the article needs more details on specific design choices as well as more exploration of the resulting repository to provide evidence for the authors' claims. Further, from a writing perspective, some of the sentences are too long and some content needs to be reorganized into different article sections. In general though, the idea is interesting and warrants publication after revisions. See below for more detailed revisions (in order of the article).</p><p>Major Revisions:</p><p>1. There are many long sentences. Example, in the introduction the last sentence of the 2nd paragraph is very long and confusing ("However, and again unlike physical sciences,..."). Another example is the last sentence of the first paragraph in the methods ("while there are limitations...").</p><p>2. One of the discussion points in the end is that the list of data repositories found can be used to contact the owners of the data repositories to register them. This point though is buried in the introduction in the paragraph that starts "Blair et al". More details about registering databases is necessary to foreshadow this finding and the importance of it in general.</p><p>3. The query used to retrieve publications that contain a data repository is not well explained. It is mentioned that they "developed a targeted query", but it is not clear to me how that was developed. More details appear later about the issue with other types of URLs. While later Figure S1 is pointed to with the query, it is not explained (data resources page 9). In terms of the query itself, the term "repository" is notably missing. Also "knowledge-base". Further, for training purposes on the article classifier, it is interesting that there are no true negative articles in the dataset. Meaning random articles that do not talk about data resources at all. On some level, one could think of any new article and classifying it as having a data resource or not immediately without the targeted query each time. Also, new words for data resources may appear and so would the query be updated to accommodate for this? In general, more details on the corpus construction would be beneficial.</p><p>4. One of the main evaluations of this work is a comparison to other data inventory organizations like re3data and FAIRsharing. In the methods, there needs to be an acknowledgement of the different possibilities with this comparison (i.e., what does a large overlap mean vs. a small overlap) and that in general, these inventories do not include all repositories. This should foreshadow section 3.5.3.</p><p>5. There needs to be a clear distinction between the methods and results sections. For example, under section 2.5.1, the last few sentences of the first paragraph are results. The methods should state that inter-annotator agreement was calculated and how it was calculated and that an error analysis was conducted. The results should be in results. It is not clear to me also where discussion fits into this. I think a separate section would be helpful. Without this distinction there is a fair amount of repetitive content.</p><p>6. A discussion on the interplay between the two tasks (article classification and NER) needs to be discussed. Errors will propagate between tasks.</p><p>7. It is mentioned that the best algorithm is chosen based on the validation set and I am unclear why this is not on the test set? This needs to be further clarified.</p><p>8. Precision was chosen over F1 for article classification. This is somewhat explained later and clearly recall is low based on the results. However, in methods this needs to be explained. Ideally, the motivation for focusing on different metrics exists in the introduction. (page 15) Some explanation exists on page 25 with "we explored putting greater weight on precision than F1&#x02026;".</p><p>9. Section 2.9 needs more details on the analyses performed on the inventory itself. The results mention a lot of methods around this that should be moved here. Further, other types of analyses like the publication dates of repositories, the number of articles each repository has, etc. would continue to highlight the value of this work.</p><p>10. The NLP results are interesting (section 3.2) and need to be discussed more. The precision is very high for the article classification and it is not clear to me why that is true. Also the test and validation sets disagree on the best performing algorithm. The test set has very high scores also. A mention of this here would be good to foreshadow the issue in data that is mentioned later.</p><p>11. The URL information should be introduced earlier (section 3.4) with the background on the analysis of resolving URLs and issues previous research has had. A discussion section is missing and so it is confusing that results also have discussion in it. Sections 3.5.1 and 3.5.2 are much more discussion based then just results. In 3.5.2, future work is mentioned that should be in a discussion section.</p><p>12. The overlap comparison (section 3.5.3) needs more details in it and a further analysis. The authors speculate at the differences but if the authors want to claim that their work complements the other work, then it needs to be clear how. Should all the repositories the authors found be added into the other inventories? Do they have different purposes? This is especially crucial when they claim they could reach out to authors to add their databases.</p><p>Minor Revisions:</p><p>1. A citation is missing for Blair et al on page 5.</p><p>2. Does the working definition of biodata include the data in biomedical knowledge-bases or ontologies?</p><p>3. It is mentioned that models are trained for max of 10 epochs. Why?</p><p>4. Classically the BIO/IBO/IOB scheme is B = beginning, I = inside, and O = outside. The otherwise is interesting here (page 15)</p><p>5. The mid-project evaluation is interesting and creates a very high probability threshold. The exact threshold is more results and so more explanation of where the threshold came from would be beneficial.</p><p>6. It is not clear how much work the manual curators did for the manual annotation. (The time they spent is also results.) Since the motivation is automation and saving time, more information on the time would be beneficial.</p><p>7. Please add percentages with the fractions. Also put the resulting numbers in parentheses without explaining it is F1 score). This will get rid of a lot of unnecessary text.</p><p>8. Figures:</p><p>a. Color does not show up with black and white printing. Check how it looks in black and white.</p><p>b. Figure 1 is blurry.</p><p>c. Figure 3 is a little confusing going bottom to top. I think it would be less confusing flipping it from top to bottom. It is also not clear what classification layer was used for the algorithms.</p><p>d. Figure 7 and 8 are hard to read in black and white printing.</p><p>9. How many articles were reviewed in the 10% sample (page 25). It is hard to understand with the denominator of 468. It seems that 18 were reviewed (13+5).</p><p>Exceptional:</p><p>1. The open science implementation plan is amazing! I like that the authors are implementing what they believe in.</p><p>2. It is great that the authors deduplicate articles but still save all articles. Maybe both the original article and the most recent one could be saved?!</p><p>3. Thank you for disclosing the data issues faced.</p><p>Reviewer #3:&#x000a0;The authors of the submitted manuscript report on a thorough work on producing an open catalogue of biodata resources. They describe the process of collecting and verifying information for such a catalogue. The authors used ML, NLP plus manual adjustments. The code and the catalogue itself are made available to the research community. While the used methods are straight forward, their usage is well justified and applying them to a large corpus of scientific publication is a time-consuming process. The manuscript is well written and structured, the reported results are of great importance. Therefore, I believe this manuscript should be accepted for a publication after minor revisions.</p><p>Suggestions for improvement of the current draft:</p><p>[133 &#x02018;used a machine-learning based approach&#x02019; It is not clear at the beginning of the manuscript what ml was employed? Is it using BERT? It should be explained from the beginning.</p><p>In my view, the manuscript could be shortened. For example, there is a bit of repetition in sections 2 and 3. Also, some parts could be moved to SI (supplementary information).</p><p>[555] &#x02018;111 resources were funded by international agencies...&#x02019; It is a lot of resources. It is not clear why funding agencies that could not be mapped to a single country were not shown.</p><p>[623] &#x02018;the majority of life science resources within both re3data (975/1189, 80.5%) and FAIRsharing 635 (1161/1640, 70.8%) are not found in our inventory&#x02019;. That is a real worry. This warrants a more detailed investigation, explanation and suggestion for a resolution.</p><p>Personally, I do not like the title: &#x02018;A machine learning-enabled open biodata resource inventory from the scientific literature&#x02019;. I suggest or to be more specific what ml was used, or drop mentioning of ml. I do not see why it is so important that ml was used to make it to the title. The important aspects are: open, re-usable, updatable, scientific literature driven.</p><p>Just to add, it was interesting to see the results of Mid-Project evaluation and iteration.</p><p>**********</p><p><!-- <font color="black"> -->6. PLOS authors have the option to publish the peer review history of their article (<ext-link xlink:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p><p>If you choose &#x0201c;no&#x0201d;, your identity will remain anonymous but your review may still be made public.</p><p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.<!-- </font> --></p><p>Reviewer #1:&#x000a0;No</p><p>Reviewer #2:&#x000a0;No</p><p>Reviewer #3:&#x000a0;<bold>Yes:&#x000a0;</bold>Larisa Soldatova</p><p>**********</p><p>[NOTE: If reviewer comments were submitted as an attachment file, they will be attached to this email and accessible via the submission site. Please log into your account, locate the manuscript record, and check for the action link "View Attachments". If this link does not appear, there are no attachment files.]</p><p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool,&#x000a0;<ext-link xlink:href="https://pacev2.apexcovantage.com/" ext-link-type="uri">https://pacev2.apexcovantage.com/</ext-link>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Registration is free. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email PLOS at&#x000a0;<email>figures@plos.org</email>. Please note that Supporting Information files do not need this step.</p></body></sub-article><sub-article article-type="author-comment" id="pone.0294812.r002"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0294812.r002</article-id><title-group><article-title>Author response to Decision Letter 0</article-title></title-group><related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0294812" id="rel-obj002" related-article-type="editor-report"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>1</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="author-response-date">14 Sep 2023</named-content>
</p><p>Our responses are provided in the uploaded Cover Letter and Response to Reviewers files. We will paste that text below, but it is probably much more readable in the PDFs provided as we do not know if line breaks will be preserved here. </p><p>EDITOR/Journal Requirements</p><p>1. Please ensure that your manuscript meets PLOS ONE's style requirements, including those for file naming. </p><p>** Our Response: Our resubmission has been checked against the PLOS ONE&#x02019;s style requirements including file naming. We believe it is compliant. </p><p>2. Thank you for stating the following financial disclosure:</p><p>&#x0201c;This work was supported by the Chan Zuckerberg Initiative (chanzuckerberg.com), which is a member of the Global Biodata Coalition. This work was also funded by the Global Biodata Coalition (<ext-link xlink:href="http://globalbiodata.org" ext-link-type="uri">globalbiodata.org</ext-link>), a coalition of research funding organizations working towards sustainability of biodata resources worldwide.&#x0201d;</p><p>Please state what role the funders took in the study.</p><p>** Our Response: Thank you for applying the changes online on our behalf. Our amended statement is as follows:</p><p>&#x0201c;This project was initiated by the Global Biodata Coalition as part of its programme of work, and which supported the work of CEC, KES, and HJI in planning and implementing the project. The Chan Zuckerberg Initiative supported the work of AMI in the development of machine learning methods.&#x0201d;</p><p>3. We note that Figures 7,S3 and S4 in your submission contain [map/satellite] images which may be copyrighted.</p><p>** Our Response: Figures 7, S3, and S4 were created using the R package ggplot2 (specifically the function ggplot2::map_data()), which gets the data using the R package maps. The documentation for the maps package states that the database used is the Natural Earth data project which, as listed above, is in the public domain (see <ext-link xlink:href="https://cran.r-project.org/web/packages/maps/readme/README.html" ext-link-type="uri">https://cran.r-project.org/web/packages/maps/readme/README.html</ext-link>). We have added this information to the figure captions and cited Natural Earth as necessary.</p><p>Additionally, all figures have been checked per reviewer 2&#x02019;s request and they have been checked in PACE per the decision letter request. The figure files provided in the revision have been downloaded from PACE. </p><p>REVIEWER Prompts/Comments</p><p>1. Is the manuscript technically sound, and do the data support the conclusions?</p><p>Reviewer #1: Yes</p><p>Reviewer #2: Partly</p><p>Reviewer #3: Yes</p><p>** Our Response: Actions taken to address Reviewer 2&#x02019;s &#x0201c;Partly&#x0201d; are below. </p><p>2. Has the statistical analysis been performed appropriately and rigorously?</p><p>Reviewer #1: Yes</p><p>Reviewer #2: N/A</p><p>Reviewer #3: Yes</p><p>** Our Response: No action needed. </p><p>3. Have the authors made all data underlying the findings in their manuscript fully available?</p><p>Reviewer #1: Yes</p><p>Reviewer #2: Yes</p><p>Reviewer #3: Yes</p><p>** Our Response: No action needed. </p><p>4. Is the manuscript presented in an intelligible fashion and written in standard English?</p><p>Reviewer #1: Yes</p><p>Reviewer #2: Yes</p><p>Reviewer #3: Yes</p><p>** Our Response: No action needed. </p><p>5. Review Comments to the Author</p><p>Reviewer #1: </p><p>General appreciation: The ML pipelines for the identification of biodata resources were diligently constructed with several verifications along the road. The results have been validated in several manners. The publication is mostly about the method, not about the resulting inventory (which may be at least as interesting).</p><p>** Our Response: We are gratified to read these positive comments. We did choose to focus this publication on the method itself, but we agree that the inventory is just as interesting and have commented below on potential follow-up work.</p><p>Error to be corrected: Line 489: the figure says ESTHER, not ESTER</p><p>** Our Response: This error has been corrected. Thank you for the keen eyes. </p><p>Elements that would be valuable to amend are:</p><p>Lines 672-673: describes the "WHY?" of this inventory. However, this is not well explained nor convincing. The Global Biodata Coalition is about sustaining important databases worldwide and this publication aims to establish a method to describe the background landscape of data resources. Why is this useful? Why do we need the inventory and/or what will be done with it? How does it feed into the work of the Coalition?</p><p>** Our Response: We appreciate this feedback and have added a paragraph to make the purpose and value of this work more explicit in Section 4. Discussion.</p><p>There is no mentioning about the language of the underlying data resources (this is on a corpus of English-language publications). This seems nevertheless relevant for a global inventory.</p><p>** Our Response: Thank you for catching this omission as this is very important to note. We edited the methods section to state that the Europe PMC API was accessed to obtain English-language articles, and we further revised to include this point in the discussion as well. </p><p>Section 3.5.3: The section on the comparison with re3<ext-link xlink:href="http://data.org" ext-link-type="uri">data.org</ext-link> and FAIRSHARING could be worked out more diligently. The overlap is less than 20%, leading the authors to state that both methods are complementary. Being complementary implies that their purpose is similar and that the 3 inventories will feed into the work of the Global Biodata Coalition. (This again points to the WHY? of the work as they can only be complementary if the aim is similar.) There are alternative explanations possible that are not addressed: The underlying collections of resources are not at all comparable and therefore both inventories are not valid benchmarks. Or the method described by the authors is missing a large part of the resources. Further clarification is therefore needed. NAR would have been a useful source for a verification. Is there any other way to use the NAR data for verification through a human, manual check as the FAIRSHARING/re3<ext-link xlink:href="http://data.org" ext-link-type="uri">data.org</ext-link> verification has not allowed any firm conclusions?</p><p>** Our Response: These are all terrific points, and we revised the text in the discussion to clarify. As the reviewer points out, there are many possible explanations. From the preliminary work presented, we know that carefully teasing apart the possibilities would certainly require a substantial amount of human curation and would constitute another study entirely. Our goal with this publication was to gauge reception of and interest in the inventory and our methods for assembling it. So while a more detailed analysis is out of the scope of this publication, which is already quite lengthy and detailed (too lengthy according to another reviewer), we absolutely agree that it is warranted and are very happy to hear there is interest in additional analyses.</p><p>Section 3.4 about URL testing: 29% of the URLs did not resolve. There would be another 6.5% false positives. We know that many data resources are archived over time or disappear. Is this number of about 35% of data resources unavailable within what is expected based on the literature?</p><p>** Our Response: It&#x02019;s roughly within expectations, although on the high side when adding in the false positive estimate. Previous studies reported ~27%, noting that it&#x02019;s highly time dependent and also appears related to popularity (as determined by citations). We haven&#x02019;t assessed the up/down breakdown by year or citation, but those values are included in the inventory if anyone wants to investigate. We added text to this extent in this section.</p><p>Reviewer #2: </p><p>Overall, the authors make a compelling case for the need for a pipeline to find biodata resources automatically based on the reliance of biological science on such resources. The focus on open science is also very valuable for future use and updates of such a repository of biodata resources. At the same time, the article needs more details on specific design choices as well as more exploration of the resulting repository to provide evidence for the authors' claims. Further, from a writing perspective, some of the sentences are too long and some content needs to be reorganized into different article sections. In general though, the idea is interesting and warrants publication after revisions. See below for more detailed revisions (in order of the article).</p><p>** Our Response: In addition to the specific response below, we&#x02019;d sincerely thank this reviewer for their careful reading and thoughtful consideration of our work. It is gratifying to see appreciation for our efforts toward open science and reproducibility. Their detailed suggestions and comments have been very helpful in shaping this manuscript into a more readable and useful addition to the literature. The reviewer did have many suggestions for restructuring that we considered in all cases and fully or partially implemented in many. We are very sympathetic to the reviewer&#x02019;s preference for a crisper and more linear presentation. However, we found this paper particularly difficult to write, in part because of the interactive nature of the process and the mid-project evaluation. Because of this, we deliberately sought out and followed PLOS One&#x02019;s guidance for structuring a discussion as we prepared the manuscript. This guidance (<ext-link xlink:href="https://plos.org/resource/how-to-write-conclusions/" ext-link-type="uri">https://plos.org/resource/how-to-write-conclusions/</ext-link>) encourages authors to focus on key findings. We have reworked the paper considerably in light of the reviewer&#x02019;s comments, but we did not revise the discussion to systematically cover all findings as the reviewer seemed to request. We also note that the other two reviewers did not seem to mind the structure we presented, with one specifically stating they found the manuscript well written and structured.</p><p>Major Revisions:</p><p>1. There are many long sentences. Example, in the introduction the last sentence of the 2nd paragraph is very long and confusing ("However, and again unlike physical sciences,..."). Another example is the last sentence of the first paragraph in the methods ("while there are limitations...").</p><p>** Our Response: We have made edits to reduce long sentences and improve the readability of our manuscript throughout, including the two examples given.</p><p>2. One of the discussion points in the end is that the list of data repositories found can be used to contact the owners of the data repositories to register them. This point though is buried in the introduction in the paragraph that starts "Blair et al". More details about registering databases is necessary to foreshadow this finding and the importance of it in general.</p><p>** Our Response: This is a very helpful suggestion.Text has been added. </p><p>3. The query used to retrieve publications that contain a data repository is not well explained. It is mentioned that they "developed a targeted query", but it is not clear to me how that was developed. More details appear later about the issue with other types of URLs. While later Figure S1 is pointed to with the query, it is not explained (data resources page 9). In terms of the query itself, the term "repository" is notably missing. Also "knowledge-base". Further, for training purposes on the article classifier, it is interesting that there are no true negative articles in the dataset. Meaning random articles that do not talk about data resources at all. On some level, one could think of any new article and classifying it as having a data resource or not immediately without the targeted query each time. Also, new words for data resources may appear and so would the query be updated to accommodate for this? In general, more details on the corpus construction would be beneficial.</p><p>** Our Response: We&#x02019;ve added text on query development to the method section. We&#x02019;ve also used &#x0201c;repository&#x0201d; as an example term which is used in different, but related, contexts that creates other challenges (e.g. conflation with code repositories and especially those associated with data analysis servers). We explicitly designed the pipeline so that a user-provided query can be provided. We&#x02019;re happy to make that feature more explicit, so this text was added there, too. </p><p>Regarding the &#x0201c;no true negatives&#x0201d; we see this point in theory, but in practice it did not work that way entirely. Although we developed a query to enrich the set with articles describing a resource, from our curation efforts we know that it didn&#x02019;t entirely exclude those that didn&#x02019;t. These were not always random articles but still true negatives for our purposes. For example, articles that described use of data and then referenced the URL for that data source in the abstract were common. Some others were quite left field. For example, computer science articles that included &#x0201c;WWW&#x0201d; and &#x0201c;data&#x0201d; in the abstract. To train the classifier on all articles certainly could be an interesting follow-up effort but a substantial one both in terms of labeling data and computation. For this effort, what we hoped to learn was if this strategy was going to help us generate a reasonably accurate inventory and what all would be needed post-NLP to make that inventory of use to those who we believed would be interested in it. </p><p>4. One of the main evaluations of this work is a comparison to other data inventory organizations like re3data and FAIRsharing. In the methods, there needs to be an acknowledgement of the different possibilities with this comparison (i.e., what does a large overlap mean vs. a small overlap) and that in general, these inventories do not include all repositories. This should foreshadow section 3.5.3.</p><p>** Our Response: This is a good point that may not be obvious to everyone. We have added text to address this observation in the methods, which now also contains additional details suggested in other points made by the reviewer. </p><p>5. There needs to be a clear distinction between the methods and results sections. For example, under section 2.5.1, the last few sentences of the first paragraph are results. The methods should state that inter-annotator agreement was calculated and how it was calculated and that an error analysis was conducted. The results should be in results. It is not clear to me also where discussion fits into this. I think a separate section would be helpful. Without this distinction there is a fair amount of repetitive content.</p><p>** Our Response: We are deeply sympathetic to this comment. When we tried a stricter delineation, the methods seemed disjointed without some allusion to what was learned and why we did x, y, z. We have taken a fresh look throughout though and pointed readers to results instead in more places, for example in the IAA. We have also revised to remove redundant content wherever possible. Please see our opening response regarding the discussion section. </p><p>6. A discussion on the interplay between the two tasks (article classification and NER) needs to be discussed. Errors will propagate between tasks.</p><p>** Our Response: This is a good point, and we revised the text in the discussion to touch on this. In particular, we find that since the article classification model had such high precision, the risk of error propagation is minimized, but it is certainly true that the names of things which are not biodata resources may still be predicted by the NER model.</p><p>7. It is mentioned that the best algorithm is chosen based on the validation set and I am unclear why this is not on the test set? This needs to be further clarified.</p><p>** Our Response: We are following the convention for ML model selection as can be found in Wulf et al., 2022 (now cited in the manuscript) which seemed most appropriate to our use case. We have revised the text in the methods section 2.5.1 when introducing the training data sets.</p><p>8. Precision was chosen over F1 for article classification. This is somewhat explained later and clearly recall is low based on the results. However, in methods this needs to be explained. Ideally, the motivation for focusing on different metrics exists in the introduction. (page 15) Some explanation exists on page 25 with "we explored putting greater weight on precision than F1&#x02026;".</p><p>** Our Response: We&#x02019;ve added text to the introduction and in Section 2.5.3. for the article classification task. </p><p>9. Section 2.9 needs more details on the analyses performed on the inventory itself. The results mention a lot of methods around this that should be moved here. Further, other types of analyses like the publication dates of repositories, the number of articles each repository has, etc. would continue to highlight the value of this work.</p><p>** Our Response: We&#x02019;ve added more detail, rearranged the results and methods some, and also moved supplemental material into newly created subsections in Section 2.9. With regard to additional analyses, our goal with this publication was to gauge reception of and interest in the inventory and our methods for assembling it. The preliminary analyses were intended to highlight what could be done with the inventory since there are many, many avenues for further analyses. In fact, the ideas suggested here are one direction and another reviewer suggested an entirely different direction. This article is already quite lengthy and complicated (another reviewer suggested we shorten it), so we believe more detailed analyses are out of the scope for this publication. However, we absolutely agree that it is warranted and are very happy to hear there is interest in additional analyses. </p><p>10. The NLP results are interesting (section 3.2) and need to be discussed more. The precision is very high for the article classification and it is not clear to me why that is true. Also the test and validation sets disagree on the best performing algorithm. The test set has very high scores also. A mention of this here would be good to foreshadow the issue in data that is mentioned later.</p><p>** Our Response: We have added more text to the discussion section to address the high precision of the article classification model on the test set, the lower performance of the NER model, and potential explanations for differences in performance. While it is true that the test and validation sets disagree, the model is selected based on the validation set, otherwise researchers risk biasing their selection to the test set results, rendering them no longer a good indicator of how the model will perform on unseen data.</p><p>11. The URL information should be introduced earlier (section 3.4) with the background on the analysis of resolving URLs and issues previous research has had. A discussion section is missing and so it is confusing that results also have discussion in it. Sections 3.5.1 and 3.5.2 are much more discussion based then just results. In 3.5.2, future work is mentioned that should be in a discussion section.</p><p>** Our Response: We&#x02019;ve moved text out of supplements into Section 3.4 to try address the reviewer&#x02019;s comments, but it is not clear to us where we would have introduced the URL information earlier so we respectfully decline this suggestion. Please see the opening response above in regards to the discussion. </p><p>12. The overlap comparison (section 3.5.3) needs more details in it and a further analysis. The authors speculate at the differences but if the authors want to claim that their work complements the other work, then it needs to be clear how. Should all the repositories the authors found be added into the other inventories? Do they have different purposes? This is especially crucial when they claim they could reach out to authors to add their databases.</p><p>** Our Response: Details have been added to the methods section to describe the registries, their selection criteria, and our access, filtering, and cleaning processes. This was an oversight on our part not to include this information, and we appreciate that the reviewer caught this omission. Additionally, we revised the discussion to state more clearly how our work may complement existing registries without saying that it does already and to emphasize that additional work must be done. To the best of our knowledge, neither re3data or FAIRsharing&#x02019;s processes for identifying resources are assisted by ML, so it seems to us that the method itself is one point of potential complementarity. It is not clear yet the extent to which the inventory will complement the actual collections of these registries, so we see how this may have been too premature to state. This has been revised as well. As far as additional analyses to get at that, we know from the preliminary work presented that this will certainly require a substantial amount of human curation and would constitute another study entirely. Similarly, &#x0201c;Should all the repositories the authors found be added into the other inventories?&#x0201d; is a terrific question, but it&#x02019;s not a question we can answer in the present study nor do we think we should try to address it alone. We&#x02019;re simply noting that since we have corresponding author information, at least such outreach is now a possibility. </p><p>Minor Revisions:</p><p>1. A citation is missing for Blair et al on page 5.</p><p>** Our Response: The citation has been added. Thank you for the keen eyes.</p><p>2. Does the working definition of biodata include the data in biomedical knowledge-bases or ontologies?</p><p>** Our Response: Computer Retrieval of Information on Scientific Projects Thesaurus (CRISP), National Cancer Institute Thesaurus (NCIT), Data Catalog Vocabulary (DCAT), and the Biomedical Resource Ontology (BRO) were all consulted as we put together definitions (see Tables S1 and S2). Or is the reviewer asking if these would meet the criteria for a biodata resource in our study? If so, yes, although we did not check to see if any of these surfaced. </p><p>3. It is mentioned that models are trained for max of 10 epochs. Why?</p><p>** Our Response: This was based on general convention as a starting point. The text has been revised to state this.</p><p>4. Classically the BIO/IBO/IOB scheme is B = beginning, I = inside, and O = outside. The otherwise is interesting here (page 15)</p><p>** Our Response: This was a typo that we've corrected. Thank you for the careful reading. </p><p>5. The mid-project evaluation is interesting and creates a very high probability threshold. The exact threshold is more results and so more explanation of where the threshold came from would be beneficial.</p><p>** Our Response: This comment seems to make our point above about the challenge between the methods and results section for this article. Is it &#x0201c;more results&#x0201d;? When we did that originally, it seemed awkward that it wasn&#x02019;t in the methods. We currently have an explicit parenthetical to reference readers to the results in that methods section, so we believe it&#x02019;s best to leave it as is. </p><p>6. It is not clear how much work the manual curators did for the manual annotation. (The time they spent is also results.) Since the motivation is automation and saving time, more information on the time would be beneficial.</p><p>** Our Response: We have this documentation so we revised the text in the methods to include the hours spent on curating the training set. We appreciate the reviewer&#x02019;s attention to such details throughout.</p><p>7. Please add percentages with the fractions. Also put the resulting numbers in parentheses without explaining it is F1 score). This will get rid of a lot of unnecessary text.</p><p>** Our Response: We have revised to add percentages and reviewed the text throughout. Note that because we chose to use precision in for classification, we were deliberately explicit in which metric was used in an effort to keep it clear for readers.</p><p>8. Figures:</p><p>a. Color does not show up with black and white printing. Check how it looks in black and white.</p><p>b. Figure 1 is blurry.</p><p>c. Figure 3 is a little confusing going bottom to top. I think it would be less confusing flipping it from top to bottom. It is also not clear what classification layer was used for the algorithms.</p><p>d. Figure 7 and 8 are hard to read in black and white printing.</p><p>** Our Response: Thank you for pointing out the issues with our figures. Figure 1 has been re-exported to ensure image quality. For Figure 3, the bottom-to-top orientation isn&#x02019;t unusual to see (e.g., Devlin et al., 2019 <ext-link xlink:href="https://doi.org/10.48550/arXiv.1810.04805" ext-link-type="uri">https://doi.org/10.48550/arXiv.1810.04805</ext-link>), and it&#x02019;s our own preference so we prefer to leave it as is. Regarding the classification layer, the text is more explicit by stating that a linear classification layer is used. We believe this figure borders on too complex already, so we prefer to leave it as is. Figure 7 has been modified such that the land-masses are white and the borders are drawn in black. We believe this improves contrast and readability in black and white. We have added a patterned fill to figure 8 to improve readability in black and white.</p><p>9. How many articles were reviewed in the 10% sample (page 25). It is hard to understand with the denominator of 468. It seems that 18 were reviewed (13+5).</p><p>** Our Response: All 468 were reviewed. We have revised the text in that section to clarify. </p><p>Exceptional:</p><p>1. The open science implementation plan is amazing! I like that the authors are implementing what they believe in.</p><p>** Our Response: We are very gratified to see acknowledgement of our open science efforts. Thank you for this!</p><p>2. It is great that the authors deduplicate articles but still save all articles. Maybe both the original article and the most recent one could be saved?!</p><p>** Our Response: We don&#x02019;t quite understand this comment. Do you mean drop all those between the first and the most recent? We saved all for the sake of replication and being able aggregate metrics (e.g., all citations, etc.). </p><p>3. Thank you for disclosing the data issues faced.</p><p>** Our Response: Thank you for this as well. We were uncertain what to do at the time, and it&#x02019;s validating to see transparency valued. </p><p>Reviewer #3: </p><p>The authors of the submitted manuscript report on a thorough work on producing an open catalogue of biodata resources. They describe the process of collecting and verifying information for such a catalogue. The authors used ML, NLP plus manual adjustments. The code and the catalogue itself are made available to the research community. While the used methods are straight forward, their usage is well justified and applying them to a large corpus of scientific publication is a time-consuming process. The manuscript is well written and structured, the reported results are of great importance. Therefore, I believe this manuscript should be accepted for a publication after minor revisions.</p><p>** Our Response: It was gratifying to see these very positive comments!</p><p>Suggestions for improvement of the current draft: [133 &#x02018;used a machine-learning based approach&#x02019; It is not clear at the beginning of the manuscript what ml was employed? Is it using BERT? It should be explained from the beginning.</p><p>** Our Response: We have revised the text to introduce our use of BERT much earlier. Thank you for catching this omission. </p><p>In my view, the manuscript could be shortened. For example, there is a bit of repetition in sections 2 and 3. Also, some parts could be moved to SI (supplementary information).</p><p>** Our Response: We did revise throughout to tighten the text and remove as much duplication as possible. It is not shorter due to suggestions from other reviewers; however, their suggestions were valuable and we think the additions strengthen the paper even whilst lengthening it. </p><p>[555] &#x02018;111 resources were funded by international agencies...&#x02019; It is a lot of resources. It is not clear why funding agencies that could not be mapped to a single country were not shown.</p><p>** Our Response: We extracted funding information for 1714 resources so that&#x02019;s 111/1714 (6.5%), which is not trivial but relatively small. We&#x02019;re not exactly sure how we would have mapped the multinational funders. For example, if we had tried to map all the individual countries associated with the EU, would we have included or excluded the UK as funding was both before and after Brexit? Or did the reviewer mean something else?</p><p>[623] &#x02018;the majority of life science resources within both re3data (975/1189, 80.5%) and FAIRsharing 635 (1161/1640, 70.8%) are not found in our inventory&#x02019;. That is a real worry. This warrants a more detailed investigation, explanation and suggestion for a resolution.</p><p>** Our Response: We absolutely agree that a more detailed investigation is warranted. We know from the preliminary work presented here, however, that this will certainly require a substantial amount of human curation and would constitute another study entirely. Our preliminary analysis suggests that none are entire subsets of each other, but without more careful investigation we don&#x02019;t know the true extent of the overlap (or lack thereof), so we have edited the text to be less premature in our conclusions. Regardless, our initial results are surprising enough to justify the follow-up work required, and we&#x02019;re glad there&#x02019;s interest in seeing it!</p><p>Personally, I do not like the title: &#x02018;A machine learning-enabled open biodata resource inventory from the scientific literature&#x02019;. I suggest or to be more specific what ml was used, or drop mentioning of ml. I do not see why it is so important that ml was used to make it to the title. The important aspects are: open, re-usable, updatable, scientific literature driven.</p><p>** Our Response: We were very gratified to see the reviewers' strong appreciation for open science! Thank you! In regards to dropping ML from the title, we&#x02019;d like to respectfully decline as ML was the main methodical approach so it seems important to forefront. We also think it would be good to keep the ML as the broad term to pique the interest of ML researchers and reinforce ML&#x02019;s utility to life sciences readers. </p><p>Just to add, it was interesting to see the results of Mid-Project evaluation and iteration.</p><p>** Our Response: Thank you!</p><p>6. PLOS authors have the option to publish the peer review history of their article (what does this mean?). </p><p>Reviewer #1: No</p><p>Reviewer #2: No</p><p>Reviewer #3: Yes: Larisa Soldatova</p><p>** Our Response: We respect the reviewers&#x02019; choices, although we&#x02019;d just like to say that it&#x02019;s too bad that Reviewer 2 especially didn&#x02019;t opt to be identified because they provided a very high quality review.</p><supplementary-material id="pone.0294812.s012" position="float" content-type="local-data"><label>Attachment</label><caption><p>Submitted filename: <named-content content-type="submitted-filename">PONE-D-23-16263 Response to Reviewers.pdf</named-content></p></caption><media xlink:href="pone.0294812.s012.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></body></sub-article><sub-article article-type="aggregated-review-documents" id="pone.0294812.r003" specific-use="decision-letter"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0294812.r003</article-id><title-group><article-title>Decision Letter 1</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Bernasconi</surname><given-names>Anna</given-names></name><role>Academic Editor</role></contrib></contrib-group><permissions><copyright-statement>&#x000a9; 2023 Anna Bernasconi</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Anna Bernasconi</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0294812" id="rel-obj003" related-article-type="reviewed-article"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>1</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="letter-date">29 Sep 2023</named-content>
</p><p><!-- <div> -->PONE-D-23-16263R1<!-- </div> --><!-- <div> -->A machine learning-enabled open biodata resource inventory from the scientific literature<!-- </div> --><!-- <div> -->PLOS ONE</p><p>Dear Dr. Imker,</p><p>Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we feel that it has merit but does not fully meet PLOS ONE&#x02019;s publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.</p><p>Please submit your revised manuscript by Nov 13 2023 11:59PM. If you will need more time than this to complete your revisions, please reply to this message or contact the journal office at&#x000a0;<email>plosone@plos.org</email>. When you're ready to submit your revision, log on to <ext-link xlink:href="https://www.editorialmanager.com/pone/" ext-link-type="uri">https://www.editorialmanager.com/pone/</ext-link> and select the 'Submissions Needing Revision' folder to locate your manuscript file.</p><p>Please include the following items when submitting your revised manuscript:<!-- </div> --><list list-type="bullet"><list-item><p>A rebuttal letter that responds to each point raised by the academic editor and reviewer(s). You should upload this letter as a separate file labeled 'Response to Reviewers'.</p></list-item><list-item><p>A marked-up copy of your manuscript that highlights changes made to the original version. You should upload this as a separate file labeled 'Revised Manuscript with Track Changes'.</p></list-item><list-item><p>An unmarked version of your revised paper without tracked changes. You should upload this as a separate file labeled 'Manuscript'.</p></list-item></list><!-- <div> -->If you would like to make changes to your financial disclosure, please include your updated statement in your cover letter. Guidelines for resubmitting your figure files are available below the reviewer comments at the end of this letter.</p><p>If applicable, we recommend that you deposit your laboratory protocols in protocols.io to enhance the reproducibility of your results. Protocols.io assigns your protocol its own identifier (DOI) so that it can be cited independently in the future. For instructions see: <ext-link xlink:href="https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols" ext-link-type="uri">https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols</ext-link>. Additionally, PLOS ONE offers an option for publishing peer-reviewed Lab Protocol articles, which describe protocols hosted on protocols.io. Read more information on sharing protocols at <ext-link xlink:href="https://plos.org/protocols?utm_medium=editorial-email&#x00026;utm_source=authorletters&#x00026;utm_campaign=protocols" ext-link-type="uri">https://plos.org/protocols?utm_medium=editorial-email&#x00026;utm_source=authorletters&#x00026;utm_campaign=protocols</ext-link>.</p><p>We look forward to receiving your revised manuscript.</p><p>Kind regards,</p><p>Anna Bernasconi, PhD</p><p>Academic Editor</p><p>PLOS ONE</p><p>Journal Requirements:</p><p>Please review your reference list to ensure that it is complete and correct. If you have cited papers that have been retracted, please include the rationale for doing so in the manuscript text, or remove these references and replace them with relevant current references. Any changes to the reference list should be mentioned in the rebuttal letter that accompanies your revised manuscript. If you need to cite a retracted article, indicate the article&#x02019;s retracted status in the References list and also include a citation and full reference for the retraction notice.</p><p>Additional Editor Comments:</p><p>Dear authors, all reviewers and myself agree that the manuscript has much improved with your revision. Reviewer 2 makes some minor comments that can help finalize your paper, making it ready for acceptance. Please address them in a minor revision.</p><p>[Note: HTML markup is below. Please do not edit.]</p><p>Reviewers' comments:</p><p>Reviewer's Responses to Questions</p><p>
<!-- <font color="black"> -->
<bold>Comments to the Author</bold>
</p><p>1. If the authors have adequately addressed your comments raised in a previous round of review and you feel that this manuscript is now acceptable for publication, you may indicate that here to bypass the &#x0201c;Comments to the Author&#x0201d; section, enter your conflict of interest statement in the &#x0201c;Confidential to Editor&#x0201d; section, and submit your "Accept" recommendation.<!-- </font> --></p><p>Reviewer #1:&#x000a0;All comments have been addressed</p><p>Reviewer #2:&#x000a0;(No Response)</p><p>Reviewer #3:&#x000a0;All comments have been addressed</p><p>**********&#x000a0;</p><p><!-- <font color="black"> -->2. Is the manuscript technically sound, and do the data support the conclusions?</p><p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. <!-- </font> --></p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #2:&#x000a0;Yes</p><p>Reviewer #3:&#x000a0;Yes</p><p>**********&#x000a0;</p><p><!-- <font color="black"> -->3. Has the statistical analysis been performed appropriately and rigorously? <!-- </font> --></p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #2:&#x000a0;N/A</p><p>Reviewer #3:&#x000a0;Yes</p><p>**********&#x000a0;</p><p><!-- <font color="black"> -->4. Have the authors made all data underlying the findings in their manuscript fully available?</p><p>The <ext-link xlink:href="http://www.plosone.org/static/policies.action#sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data&#x02014;e.g. participant privacy or use of data from a third party&#x02014;those must be specified.<!-- </font> --></p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #2:&#x000a0;Yes</p><p>Reviewer #3:&#x000a0;Yes</p><p>**********&#x000a0;</p><p><!-- <font color="black"> -->5. Is the manuscript presented in an intelligible fashion and written in standard English?</p><p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.<!-- </font> --></p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #2:&#x000a0;Yes</p><p>Reviewer #3:&#x000a0;Yes</p><p>**********&#x000a0;</p><p><!-- <font color="black"> -->6. Review Comments to the Author</p><p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)<!-- </font> --></p><p>Reviewer #1:&#x000a0;Thank you for adressing the different suggestions and comments. The manuscript has greatly improved and is very much worth publishing.</p><p>Reviewer #2:&#x000a0;I want to thank the reviewers for including my comments in their work. I do agree that the manuscript is more readable overall. In general, it seems the biggest difficulty with this paper is delineating the methods and the results section in part because of the mid-project evaluation. I do think the current delineation is much better and I have a few minor comments and places that can be cut out due to repetition to offer.</p><p>Minor comments (in order of appearance):</p><p>1. I am surprised by how short the training set curation took. That is great. It seems that the task was pretty simple for them to do which you may want to comment on in relation to the portion that gets manually reviewed based on the threshold for prediction. The idea being that manual review is quick and easy even if it needs to happen for almost half of them.</p><p>2. Section 3.3.1 (page 28): the paragraph after figure 6 is too long and mostly repeating the methods about the mid-project evaluation. The results are that the method chosen was the selectively mediated approach, the threshold of 0.978, and the sentences starting with "In the 468 articles from the 10% sample..." Potentially this paragraph should start with the last sentence because that sums up the main results for this section.</p><p>3. Section 3.3.1 (page 29): similarly to comment 2, the next paragraph starting with "During preparation of this manuscript, we realized..." is methods. The paragraph should start with "In the mid-project evaluation, 7 articles from the classification test and 5 articles from the NER test set were found..."</p><p>4. Section 3.3.2: There are a lot of records flagged for manual review (almost half if you add up all the different reasons for being flagged. Harkening back to comment 1, I think you can say that manual review is quick and easy so it doesn't matter that it is so much. It is also interesting to note the number that were flagged here vs. the test data if that is easy to do.</p><p>5. In general section 3.5 is a great example of just results and pretty short. I would still say that you can cut out part of the first sentence of section 3.5 starting with "After curation and processing to remove..." Instead the section can start with "The resulting inventory contained 3112 resources..."</p><p>6. Section 3.5.2: The first paragraph talks about the metadata and everything after "Both PubMed Central and Europe PMC, which exchange data,..." is introduction or discussion/future work. I don't think it belongs in results. Further the last paragraph in that section is also discussion/future work starting with "The articles associated with biodata resources within the inventory also provide opportunities to glean...". This whole paragraph is mostly stated as future work. If you want it to be results about the articles instead, then maybe providing an example of why they are useful or could be used would be helpful.</p><p>7. In the discussion section, the second paragraph states, "the selected article classification model achieved..." Please state the name of the models that performed the best for classification and NER.</p><p>8. In the discussion section, the added discussion on why the overlap between resources is low is great. One comment mentioned is that the selection criteria may differ in subtle ways. I guess can you give examples or do a very basic analysis of the differences?</p><p>9. In the discussion section (page 39). The sentence starting with "One potential use of the inventory as a catalyst for outreach." needs to start with "This is one potential use of the inventory..."</p><p>Response to authors comments on my review:</p><p>1. I see that you are using the validation set to choose the algorithm and then using the test set to report on unseen data. Thank you for the explanation.</p><p>2.Thank you for your comment about the "true negatives". It is very interesting to think about in theory vs. practice.</p><p>3. I hear the point about the manuscript being very long. I think mentioning more things in future work is totally fine. I do believe there is good reception of this work and that it is interesting.</p><p>4. I understand the authors' decision to keep the structure following PLOS One guidelines. Overall the structure is much clearer than before.</p><p>5. Minor revision comment 2: I was asking about the latter option of whether knowledge-bases and ontologies were included in your definition and find that interesting in general and maybe it should be mentioned as well. I like the discussion in the paper about how to define a biodata resource.</p><p>6. I do understand the difficulty with methods and results so take my comments around that with a grain of salt.</p><p>7. Adding F1 score makes sense when you do have two different metrics you use. Thank you for the response.</p><p>8. Thank you for the figure comments. All of that makes sense.</p><p>9. In terms of the deduplication comment I made in the exceptional category, I see that you do keep the articles so you are all good.</p><p>Reviewer #3:&#x000a0;I am satisfied with the revisions made. The authors have addressed the comments and suggestions by other reviewers reasonably well.</p><p>**********&#x000a0;</p><p><!-- <font color="black"> -->7. PLOS authors have the option to publish the peer review history of their article (<ext-link xlink:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p><p>If you choose &#x0201c;no&#x0201d;, your identity will remain anonymous but your review may still be made public.</p><p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.<!-- </font> --></p><p>Reviewer #1:&#x000a0;No</p><p>Reviewer #2:&#x000a0;<bold>Yes:&#x000a0;</bold>Mayla R Boguslav</p><p>Reviewer #3:&#x000a0;No</p><p>**********</p><p>[NOTE: If reviewer comments were submitted as an attachment file, they will be attached to this email and accessible via the submission site. Please log into your account, locate the manuscript record, and check for the action link "View Attachments". If this link does not appear, there are no attachment files.]</p><p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool,&#x000a0;<ext-link xlink:href="https://pacev2.apexcovantage.com/" ext-link-type="uri">https://pacev2.apexcovantage.com/</ext-link>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Registration is free. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email PLOS at&#x000a0;<email>figures@plos.org</email>. Please note that Supporting Information files do not need this step.</p></body></sub-article><sub-article article-type="author-comment" id="pone.0294812.r004"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0294812.r004</article-id><title-group><article-title>Author response to Decision Letter 1</article-title></title-group><related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0294812" id="rel-obj004" related-article-type="editor-report"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>2</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="author-response-date">3 Nov 2023</named-content>
</p><p>As provided in the "Response to Reviewers" documentment:</p><p>Reviewer Prompts/Comments</p><p>1. If the authors have adequately addressed your comments raised in a previous round</p><p>of review and you feel that this manuscript is now acceptable for publication, you may</p><p>indicate that here to bypass the &#x0201c;Comments to the Author&#x0201d; section, enter your conflict of</p><p>interest statement in the &#x0201c;Confidential to Editor&#x0201d; section, and submit your "Accept"</p><p>recommendation.</p><p>Reviewer #1: All comments have been addressed</p><p>Reviewer #2: (No Response)</p><p>Reviewer #3: All comments have been addressed</p><p>Our Response: No action needed.</p><p>2. Is the manuscript technically sound, and do the data support the conclusions?</p><p>Reviewer #1: Yes</p><p>Reviewer #2: Yes</p><p>Reviewer #3: Yes</p><p>Our Response: No action needed.</p><p>3. Has the statistical analysis been performed appropriately and rigorously?</p><p>Reviewer #1: Yes</p><p>Reviewer #2: N/A</p><p>Reviewer #3: Yes</p><p>Our Response: No action needed.</p><p>4. Have the authors made all data underlying the findings in their manuscript fully</p><p>available?</p><p>Reviewer #1: Yes</p><p>Reviewer #2: Yes</p><p>Reviewer #3: Yes</p><p>Our Response: No action needed.</p><p>5. Is the manuscript presented in an intelligible fashion and written in standard English?</p><p>Reviewer #1: Yes</p><p>Reviewer #2: Yes</p><p>Reviewer #3: Yes</p><p>Our Response: No action needed.</p><p>6. Review Comments to the Author</p><p>Reviewer #1</p><p>Thank you for addressing the different suggestions and comments. The</p><p>manuscript has greatly improved and is very much worth publishing.</p><p>Our Response: We are happy to hear so!</p><p>Reviewer #2:</p><p>I want to thank the reviewers for including my comments in their work. I do agree</p><p>that the manuscript is more readable overall. In general, it seems the biggest</p><p>difficulty with this paper is delineating the methods and the results section in part</p><p>because of the mid-project evaluation. I do think the current delineation is much</p><p>better and I have a few minor comments and places that can be cut out due to</p><p>repetition to offer.</p><p>Our Response: This is great for us to hear. Specific points are addressed below.</p><p>Minor comments (in order of appearance):</p><p>1. I am surprised by how short the training set curation took. That is great. It</p><p>seems that the task was pretty simple for them to do which you may want to</p><p>comment on in relation to the portion that gets manually reviewed based on the</p><p>threshold for prediction. The idea being that manual review is quick and easy</p><p>even if it needs to happen for almost half of them.</p><p>Our Response: Yes, relatively speaking, we found curation to be fairly</p><p>straightforward, which did make the mediated approach feasible. We revised the</p><p>text to make this point while presenting our rationale for doing the selective</p><p>mediated review.</p><p>2. Section 3.3.1 (page 28): the paragraph after figure 6 is too long and mostly</p><p>repeating the methods about the mid-project evaluation. The results are that the</p><p>method chosen was the selectively mediated approach, the threshold of 0.978,</p><p>and the sentences starting with "In the 468 articles from the 10% sample..."</p><p>Potentially this paragraph should start with the last sentence because that sums</p><p>up the main results for this section.</p><p>Our Response: We tried to revise as suggested, but the text was cumbersome</p><p>when placed elsewhere, in particular because it does contain results (e.g.,</p><p>precision vs F1 lowered recall to an unacceptable level for NER). This caused</p><p>the text to be quite disjointed, so we respectfully decline to implement this</p><p>suggestion.</p><p>3. Section 3.3.1 (page 29): similarly to comment 2, the next paragraph starting</p><p>with "During preparation of this manuscript, we realized..." is methods. The</p><p>paragraph should start with "In the mid-project evaluation, 7 articles from the</p><p>classification test and 5 articles from the NER test set were found..."</p><p>Our Response: We have revised this paragraph and moved some nonredundant</p><p>content to methods.</p><p>4. Section 3.3.2: There are a lot of records flagged for manual review (almost half</p><p>if you add up all the different reasons for being flagged. Harkening back to</p><p>comment 1, I think you can say that manual review is quick and easy so it doesn't</p><p>matter that it is so much. It is also interesting to note the number that were</p><p>flagged here vs. the test data if that is easy to do.</p><p>Our Response: We added this point explicitly in the method sections already per</p><p>suggestions above, so we respectfully decline as other suggested revisions</p><p>asked us to remove such explanatory text from the results sections.</p><p>5. In general section 3.5 is a great example of just results and pretty short. I</p><p>would still say that you can cut out part of the first sentence of section 3.5 starting</p><p>with "After curation and processing to remove..." Instead the section can start</p><p>with "The resulting inventory contained 3112 resources..."</p><p>Our Response: We respectfully decline this suggestion as we believe the</p><p>opening clause helps keep the reader oriented.</p><p>6. Section 3.5.2: The first paragraph talks about the metadata and everything</p><p>after "Both PubMed Central and Europe PMC, which exchange data,..." is</p><p>introduction or discussion/future work. I don't think it belongs in results. Further</p><p>the last paragraph in that section is also discussion/future work starting with "The</p><p>articles associated with biodata resources within the inventory also provide</p><p>opportunities to glean...". This whole paragraph is mostly stated as future work. If</p><p>you want it to be results about the articles instead, then maybe providing an</p><p>example of why they are useful or could be used would be helpful.</p><p>Our Response: Only the last half of the last sentence in this paragraph has</p><p>anything to do with future work, and even that was in direct relation to the results.</p><p>Our point about the irregular reporting of smaller funders (especially those</p><p>outside of the US and UK) directly precedes our results where we found</p><p>increasingly more granular funding sources reported. There is no good place in</p><p>the introduction or the discussion to bring this up and even if so, it would be too</p><p>far away from where this context is most helpful for the reader. We have edited</p><p>slightly, however, to make it more clear that we see this directly in the results of</p><p>our work.</p><p>7. In the discussion section, the second paragraph states, "the selected article</p><p>classification model achieved..." Please state the name of the models that</p><p>performed the best for classification and NER.</p><p>Our Response: We have edited to explicitly state the model names in the</p><p>discussion as well.</p><p>8. In the discussion section, the added discussion on why the overlap between</p><p>resources is low is great. One comment mentioned is that the selection criteria</p><p>may differ in subtle ways. I guess can you give examples or do a very basic</p><p>analysis of the differences?</p><p>Our Response: We have edited, and provide an example we point out that that</p><p>definition of &#x0201c;data&#x0201d; itself is not universally shared.</p><p>9. In the discussion section (page 39). The sentence starting with "One potential</p><p>use of the inventory as a catalyst for outreach." needs to start with "This is one</p><p>potential use of the inventory..."</p><p>Our Response: We have corrected the typo. Thank you for catching it.</p><p>Response to authors comments on my review:</p><p>1. I see that you are using the validation set to choose the algorithm and then</p><p>using the test set to report on unseen data. Thank you for the explanation.</p><p>Our Response: You&#x02019;re welcome.</p><p>2.Thank you for your comment about the "true negatives". It is very interesting to</p><p>think about in theory vs. practice.</p><p>Our Response: You&#x02019;re welcome.</p><p>3. I hear the point about the manuscript being very long. I think mentioning more</p><p>things in future work is totally fine. I do believe there is good reception of this</p><p>work and that it is interesting.</p><p>Our Response: Great to hear!</p><p>4. I understand the authors' decision to keep the structure following PLOS One</p><p>guidelines. Overall the structure is much clearer than before.</p><p>Our Response: Great to hear!</p><p>5. Minor revision comment 2: I was asking about the latter option of whether</p><p>knowledge-bases and ontologies were included in your definition and find that</p><p>interesting in general and maybe it should be mentioned as well. I like the</p><p>discussion in the paper about how to define a biodata resource.</p><p>Our Response: We did not restrict our definition to only experimental data, so</p><p>knowledge bases and ontologies could also meet the criteria and, in fact, did.</p><p>Two examples of ontologies in the inventory are FOAM (Functional Ontology</p><p>Assignments for Metagenomes) and ENVO (Environmental Ontology), while two</p><p>examples of KBs in the inventory are FROG-kb (Forensic Resource/Reference</p><p>on Genetics-knowledge base) and GPKB (Genomic and Proteomic Knowledge</p><p>Base). There may be others as well but we provide these just as examples to</p><p>know that ontologies and knowledge bases are included.</p><p>6. I do understand the difficulty with methods and results so take my comments</p><p>around that with a grain of salt.</p><p>Our Response: Excellent. Thank you!</p><p>7. Adding F1 score makes sense when you do have two different metrics you</p><p>use. Thank you for the response.</p><p>Our Response: You&#x02019;re welcome.</p><p>8. Thank you for the figure comments. All of that makes sense.</p><p>Our Response: Great!</p><p>9. In terms of the deduplication comment I made in the exceptional category, I</p><p>see that you do keep the articles so you are all good.</p><p>Our Response: Great! Thank you again for your time and terrific attention to</p><p>detail.</p><p>Reviewer #3</p><p>I am satisfied with the revisions made. The authors have addressed the</p><p>comments and suggestions by other reviewers reasonably well.</p><p>Our Response: We are very glad to hear so!</p><p>7. PLOS authors have the option to publish the peer review history of their article (what does</p><p>this mean?). If published, this will include your full peer review and any attached files.</p><p>Our Response: Great to have 2 of 3 allow their names open! We appreciate all of their time</p><p>and very helpful comments.</p><supplementary-material id="pone.0294812.s013" position="float" content-type="local-data"><label>Attachment</label><caption><p>Submitted filename: <named-content content-type="submitted-filename">PONE-D-23-16263 Second Response to Reviewers.pdf</named-content></p></caption><media xlink:href="pone.0294812.s013.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></body></sub-article><sub-article article-type="editor-report" id="pone.0294812.r005" specific-use="decision-letter"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0294812.r005</article-id><title-group><article-title>Decision Letter 2</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Bernasconi</surname><given-names>Anna</given-names></name><role>Academic Editor</role></contrib></contrib-group><permissions><copyright-statement>&#x000a9; 2023 Anna Bernasconi</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Anna Bernasconi</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0294812" id="rel-obj005" related-article-type="reviewed-article"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>2</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="letter-date">8 Nov 2023</named-content>
</p><p>A machine learning-enabled open biodata resource inventory from the scientific literature</p><p>PONE-D-23-16263R2</p><p>Dear Dr. Imker,</p><p>We&#x02019;re pleased to inform you that your manuscript has been judged scientifically suitable for publication and will be formally accepted for publication once it meets all outstanding technical requirements.</p><p>Within one week, you&#x02019;ll receive an e-mail detailing the required amendments. When these have been addressed, you&#x02019;ll receive a formal acceptance letter and your manuscript will be scheduled for publication.</p><p>An invoice for payment will follow shortly after the formal acceptance. To ensure an efficient process, please log into Editorial Manager at <ext-link xlink:href="http://www.editorialmanager.com/pone/" ext-link-type="uri">http://www.editorialmanager.com/pone/</ext-link>, click the 'Update My Information' link at the top of the page, and double check that your user information is up-to-date. If you have any billing related questions, please contact our Author Billing department directly at <email>authorbilling@plos.org</email>.</p><p>If your institution or institutions have a press office, please notify them about your upcoming paper to help maximize its impact. If they&#x02019;ll be preparing press materials, please inform our press team as soon as possible -- no later than 48 hours after receiving the formal acceptance. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information, please contact <email>onepress@plos.org</email>.</p><p>Kind regards,</p><p>Anna Bernasconi, PhD</p><p>Academic Editor</p><p>PLOS ONE</p><p>Additional Editor Comments (optional):</p><p>Dear authors, the paper has improved in the two revisions; all reviewers and myself agree that it can now be accepted for publication.</p><p>Reviewers' comments:</p></body></sub-article><sub-article article-type="editor-report" id="pone.0294812.r006" specific-use="acceptance-letter"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0294812.r006</article-id><title-group><article-title>Acceptance letter</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Bernasconi</surname><given-names>Anna</given-names></name><role>Academic Editor</role></contrib></contrib-group><permissions><copyright-statement>&#x000a9; 2023 Anna Bernasconi</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Anna Bernasconi</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0294812" id="rel-obj006" related-article-type="reviewed-article"/></front-stub><body><p>
<named-content content-type="letter-date">16 Nov 2023</named-content>
</p><p>PONE-D-23-16263R2 </p><p>A machine learning-enabled open biodata resource inventory from the scientific literature </p><p>Dear Dr. Imker:</p><p>I'm pleased to inform you that your manuscript has been deemed suitable for publication in PLOS ONE. Congratulations! Your manuscript is now with our production department. </p><p>If your institution or institutions have a press office, please let them know about your upcoming paper now to help maximize its impact. If they'll be preparing press materials, please inform our press team within the next 48 hours. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information please contact <email>onepress@plos.org</email>.</p><p>If we can help with anything else, please email us at <email>customercare@plos.org</email>.</p><p>Thank you for submitting your work to PLOS ONE and supporting open access. </p><p>Kind regards, </p><p>PLOS ONE Editorial Office Staff</p><p>on behalf of</p><p>Dr. Anna Bernasconi </p><p>Academic Editor</p><p>PLOS ONE</p></body></sub-article></article>