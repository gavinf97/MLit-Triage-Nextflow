<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd"> 
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-journalpublishing1.dtd?><?SourceDTD.Version 1.2?><?ConverterInfo.XSLTName jats2jats3.xsl?><?ConverterInfo.Version 1?><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id><journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id><journal-id journal-id-type="publisher-id">bioinformatics</journal-id><journal-title-group><journal-title>Bioinformatics</journal-title></journal-title-group><issn pub-type="ppub">1367-4803</issn><issn pub-type="epub">1367-4811</issn><publisher><publisher-name>Oxford University Press</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">8352508</article-id><article-id pub-id-type="pmid">33532838</article-id><article-id pub-id-type="doi">10.1093/bioinformatics/btab080</article-id><article-id pub-id-type="publisher-id">btab080</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Papers</subject><subj-group subj-group-type="category-toc-heading"><subject>Structural Bioinformatics</subject></subj-group></subj-group><subj-group subj-group-type="category-taxonomy-collection"><subject>AcademicSubjects/SCI01060</subject></subj-group></article-categories><title-group><article-title>Generating property-matched decoy molecules using deep learning</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-6241-0123</contrib-id><name><surname>Imrie</surname><given-names>Fergus</given-names></name><aff>
<institution>Oxford Protein Informatics Group, Department of Statistics, University of Oxford</institution>, Oxford OX1 3LB, <country country="GB">UK</country></aff></contrib><contrib contrib-type="author"><name><surname>Bradley</surname><given-names>Anthony R</given-names></name><aff>
<institution>Exscientia Ltd</institution>, The Schr&#x000f6;&#x00111;inger Building, Oxford Science Park, <country country="GB">Oxford OX4 4GE, UK</country></aff></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-1388-2252</contrib-id><name><surname>Deane</surname><given-names>Charlotte M</given-names></name><xref rid="btab080-cor1" ref-type="corresp"/><aff>
<institution>Oxford Protein Informatics Group, Department of Statistics, University of Oxford</institution>, Oxford OX1 3LB, <country country="GB">UK</country></aff><!--deane@stats.ox.ac.uk--></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name><surname>Valencia</surname><given-names>Alfonso</given-names></name><role>Associate Editor</role></contrib></contrib-group><author-notes><corresp id="btab080-cor1">To whom correspondence should be addressed. <email>deane@stats.ox.ac.uk</email></corresp></author-notes><pub-date pub-type="collection"><day>01</day><month>8</month><year>2021</year></pub-date><pub-date pub-type="epub" iso-8601-date="2021-02-03"><day>03</day><month>2</month><year>2021</year></pub-date><pub-date pub-type="pmc-release"><day>03</day><month>2</month><year>2021</year></pub-date><volume>37</volume><issue>15</issue><fpage>2134</fpage><lpage>2141</lpage><history><date date-type="received"><day>01</day><month>9</month><year>2020</year></date><date date-type="rev-recd"><day>05</day><month>1</month><year>2021</year></date><date date-type="editorial-decision"><day>27</day><month>1</month><year>2021</year></date><date date-type="accepted"><day>28</day><month>1</month><year>2021</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2021. Published by Oxford University Press.</copyright-statement><copyright-year>2021</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits 
unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><self-uri xlink:href="btab080.pdf"/><abstract><title>Abstract</title><sec id="s1"><title>Motivation</title><p>An essential step in the development of virtual screening methods is the use of established sets of actives and decoys for benchmarking and training. However, the decoy molecules in commonly used sets are biased meaning that methods often exploit these biases to separate actives and decoys, and do not necessarily learn to perform molecular recognition. This fundamental issue prevents generalization and hinders virtual screening method development.</p></sec><sec id="s2"><title>Results</title><p>We have developed a deep learning method (DeepCoy) that generates decoys to a user&#x02019;s preferred specification in order to remove such biases or construct sets with a defined bias. We validated DeepCoy using two established benchmarks, DUD-E and DEKOIS 2.0. For all 102 DUD-E targets and 80 of the 81 DEKOIS 2.0 targets, our generated decoy molecules more closely matched the active molecules&#x02019; physicochemical properties while introducing no discernible additional risk of false negatives. The DeepCoy decoys improved the Deviation from Optimal Embedding (DOE) score by an average of 81% and 66%, respectively, decreasing from 0.166 to 0.032 for DUD-E and from 0.109 to 0.038 for DEKOIS 2.0. Further, the generated decoys are harder to distinguish than the original decoy molecules via docking with Autodock Vina, with virtual screening performance falling from an AUC ROC of 0.70 to 0.63.</p></sec><sec id="s3"><title>Availability and implementation</title><p>The code is available at <ext-link xlink:href="https://github.com/oxpig/DeepCoy" ext-link-type="uri">https://github.com/oxpig/DeepCoy</ext-link>. Generated molecules can be downloaded from <ext-link xlink:href="http://opig.stats.ox.ac.uk/resources" ext-link-type="uri">http://opig.stats.ox.ac.uk/resources</ext-link>.</p></sec><sec id="s5"><title>Supplementary information</title><p>
<xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p></sec></abstract><funding-group><award-group award-type="grant"><funding-source>
<institution-wrap><institution>Engineering and Physical Sciences Research Council</institution><institution-id institution-id-type="DOI">10.13039/501100000266</institution-id></institution-wrap>
</funding-source><award-id>EP/N509711/1</award-id></award-group></funding-group><counts><page-count count="8"/></counts></article-meta></front><body><sec><title>1 Introduction</title><p>Virtual screening is a computational approach that is often used in early stage drug discovery to help find molecules that interact with protein targets with high affinity and specificity. Numerous prospective applications of virtual screening have been reported, reducing the cost and improving the hit-rate of experimental verification (e.g. <xref rid="btab080-B18" ref-type="bibr">Liu <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btab080-B19" ref-type="bibr">Lyu <italic toggle="yes">et al.</italic>, 2019</xref>).</p><p>There are a variety of datasets available for retrospectively benchmarking virtual screening methods. These sets consist of a collection of active and inactive molecules for a range of protein targets. Frequently used examples for structure-based virtual screening (SBVS) are DUD (<xref rid="btab080-B8" ref-type="bibr">Huang <italic toggle="yes">et al.</italic>, 2006</xref>) and DUD-E (<xref rid="btab080-B19" ref-type="bibr">Mysinger <italic toggle="yes">et al.</italic>, 2012</xref>), DEKOIS (<xref rid="btab080-B2" ref-type="bibr">Bauer <italic toggle="yes">et al.</italic>, 2013</xref>; <xref rid="btab080-B35" ref-type="bibr">Vogel <italic toggle="yes">et al.</italic>, 2011</xref>) and MUV (<xref rid="btab080-B26" ref-type="bibr">Rohrer and Baumann, 2009</xref>).</p><p>While experimentally verified inactives represent the gold standard for dataset construction (<xref rid="btab080-B13" ref-type="bibr">Lagarde <italic toggle="yes">et al.</italic>, 2015</xref>), suitable inactive molecules are often not available. As such, using presumed inactives, known as decoys, is typically necessary in SBVS datasets (<xref rid="btab080-B23" ref-type="bibr">R&#x000e9;au <italic toggle="yes">et al.</italic>, 2018</xref>). There are efforts to construct sets using only known inactives (e.g. <xref rid="btab080-B26" ref-type="bibr">Rohrer and Baumann, 2009</xref>; <xref rid="btab080-B32" ref-type="bibr">Tran-Nguyen <italic toggle="yes">et al.</italic>, 2020</xref>); however, these are relatively limited in size and breadth of protein targets and are not yet suitable for training general-purpose SBVS models using modern machine learning methods.</p><p>Bias in virtual screening datasets can be split into three main types: artificial enrichment, analogue bias and false negative bias (<xref rid="btab080-B23" ref-type="bibr">R&#x000e9;au <italic toggle="yes">et al.</italic>, 2018</xref>). Artificial enrichment captures the performance that can be attributed to the differences in chemical space between the active and decoy molecules. Analogue bias arises from limited diversity of the active molecules, while false negative bias describes the risk of active compounds being present in the decoy set, which could lead to an underestimation of the screening performance. It is crucial that benchmarking sets minimize these bias (e.g. <xref rid="btab080-B28" ref-type="bibr">Sieg <italic toggle="yes">et al.</italic>, 2019</xref>).</p><p>To achieve this, decoys are typically selected to match the chemical properties of active molecules while simultaneously ensuring structure mismatching to minimize the chance of decoys being binders (&#x02018;property-matched decoys&#x02019;, e.g. <xref rid="btab080-B1" ref-type="bibr">Adeshina <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btab080-B19" ref-type="bibr">Mysinger <italic toggle="yes">et al.</italic>, 2012</xref>).</p><p>Alternative approaches for decoy construction have also been proposed. For example, one criticism of property-matched decoys is that they inherently struggle to capture the chemical diversity present in screening libraries (<xref rid="btab080-B15" ref-type="bibr">Li <italic toggle="yes">et al.</italic>, 2020</xref>), and thus several reports have used property-unmatched decoys selected at random from a representative dataset (e.g. <xref rid="btab080-B31" ref-type="bibr">Sun <italic toggle="yes">et al.</italic>, 2016</xref>). In other publications, actives from other targets have been adopted to produce an &#x02018;actives as decoys&#x02019; set (e.g. <xref rid="btab080-B5" ref-type="bibr">Chen <italic toggle="yes">et al.</italic>, 2019</xref>).</p><p>However, SBVS methods should be able to discriminate between actives and inactives on the basis of structural information alone and not depend on exploiting differences in physicochemical properties between actives and inactives. Thus it is critical to ensure the physicochemical properties of decoys in benchmarking sets match those of the actives otherwise it is not possible to conclude whether predictive performance is due to understanding protein-ligand interactions or a result of the bias present in the benchmarking set (<xref rid="btab080-B20" ref-type="bibr">Nicholls, 2008</xref>; <xref rid="btab080-B34" ref-type="bibr">Verdonk <italic toggle="yes">et al.</italic>, 2004</xref>).</p><p>Property matching arbitrary actives is challenging and, despite improvements, still leads to substantial differences in molecular properties between actives and decoys (<xref rid="btab080-B4" ref-type="bibr">Chaput <italic toggle="yes">et al.</italic>, 2016</xref>). It has been shown that on several widely used datasets it is possible to discriminate actives from inactives from these properties alone (<xref rid="btab080-B28" ref-type="bibr">Sieg <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btab080-B36" ref-type="bibr">Wallach and Heifets, 2018</xref>). Hence closer matching is required to ensure retrospective testing is not over-optimistic (e.g. <xref rid="btab080-B34" ref-type="bibr">Verdonk <italic toggle="yes">et al.</italic>, 2004</xref>).</p><p>In recent years, many machine learning methods have been trained and evaluated on these datasets (e.g. <xref rid="btab080-B9" ref-type="bibr">Imrie <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btab080-B38" ref-type="bibr">W&#x000f3;jcikowski <italic toggle="yes">et al.</italic>, 2017</xref>). The reported results show that these methods substantially outperform other methodologies such as empirical and knowledge-based scoring functions at SBVS.</p><p>Concerningly, some reports have suggested that a driver of the retrospective performance of machine learning-based systems is hidden biases in the training data, such as physicochemical differences, and have questioned the extent to which such methods are learning to perform molecular recognition (<xref rid="btab080-B5" ref-type="bibr">Chen <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btab080-B28" ref-type="bibr">Sieg <italic toggle="yes">et al.</italic>, 2019</xref>). While prospective successes have demonstrated that such methods can be useful (e.g. <xref rid="btab080-B1" ref-type="bibr">Adeshina <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btab080-B29" ref-type="bibr">Stecula <italic toggle="yes">et al.</italic>, 2020</xref>), both <xref rid="btab080-B28" ref-type="bibr">Sieg <italic toggle="yes">et al.</italic> (2019)</xref> and <xref rid="btab080-B5" ref-type="bibr">Chen <italic toggle="yes">et al.</italic> (2019)</xref> emphasize the need for improved validation on unbiased datasets.</p><p>The challenges of decoy design are in part due to the inherent limitations of matching to an explicit, fixed database of potential decoys. While virtual libraries such as ZINC (<xref rid="btab080-B30" ref-type="bibr">Sterling and Irwin, 2015</xref>) have grown considerably, they still represent only a tiny fraction of potential drug-like chemical space (<xref rid="btab080-B21" ref-type="bibr">Polishchuk <italic toggle="yes">et al.</italic>, 2013</xref>) and are insufficient for closely matching core chemical properties of many active molecules.</p><p>
<xref rid="btab080-B37" ref-type="bibr">Wallach and Lilien (2011)</xref> pioneered the use of a generative approach to construct virtual decoy sets for the original DUD (<xref rid="btab080-B8" ref-type="bibr">Huang <italic toggle="yes">et al.</italic>, 2006</xref>) targets with tighter property matching than the decoys selected from ZINC. They used a rules-based algorithm employing a library of chemical building blocks and bridges to iteratively generate possible decoys. However, their method ignored synthetic feasibility and, despite clear improvements in property matching, has not been widely adopted.</p><p>Machine learning models for molecule generation have been proposed as an alternative to human-led design and rules-based transformations and have shown great promise in several molecular design tasks (e.g. <xref rid="btab080-B27" ref-type="bibr">Segler <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btab080-B40" ref-type="bibr">Zhavoronkov <italic toggle="yes">et al.</italic>, 2019</xref>).</p><p>In this work, we describe DeepCoy, a deep learning method using graph neural networks, to generate decoy molecules. DeepCoy takes as input an active molecule and generates property-matched decoy molecules. This eliminates the need to use a database to search for molecules and allows decoys to be generated for the requirements of a particular active molecule and the user&#x02019;s specification.</p><p>The properties can be chosen by the user depending on their objective, and in this article, we demonstrate the ability of DeepCoy to learn to produce decoy molecules with different sets of matched properties, highlighting the flexibility of our approach. We validated our generative model using two established SBVS benchmarks, DUD-E and DEKOIS 2.0. For all 102 DUD-E targets and 80 of the 81 DEKOIS 2.0 targets, our generated decoy molecules more closely matched the physicochemical properties deemed by the respective datasets to be non-informative for binding, improving property matching as measured by DOE score by 81% and 66% for DUD-E and DEKOIS 2.0, respectively.</p><p>Finally, we demonstrate that the generated decoys are harder to distinguish from active molecules than the original decoy molecules with docking using Autodock Vina (<xref rid="btab080-B33" ref-type="bibr">Trott and Olson, 2010</xref>). This ability to substantially reduce bias will benefit the development and improve generalization of structure-based virtual screening methods.</p></sec><sec><title>2 Materials and methods</title><p>This work describes a novel approach using deep learning to propose molecules that match a set of features provided by the user. We achieve this with a generative model using graph neural networks. Our model makes no underlying assumptions regarding the nature of the properties that are to be matched, and relies only on a training set of paired molecules exhibiting the desired similarities.</p><sec><title>2.1 Generative model</title><p>In order to generate decoys we use an adapted version of <xref rid="btab080-B10" ref-type="bibr">Imrie <italic toggle="yes">et al.</italic> (2020)</xref>, which was designed for linker generation. <xref rid="btab080-B10" ref-type="bibr">Imrie <italic toggle="yes">et al.</italic> (2020)</xref> builds on the generative process introduced by <xref rid="btab080-B17" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> (2018)</xref> that constructs molecules &#x02018;bond-by-bond&#x02019; in a breadth-first manner. The most substantial differences with <xref rid="btab080-B10" ref-type="bibr">Imrie <italic toggle="yes">et al.</italic> (2020)</xref> are the input data and goal of the generative process.</p><p>DeepCoy takes an active molecule as input and generates a new molecule that has similar physicochemical properties but is structurally dissimilar. This is achieved by building new molecules in an iterative manner &#x02018;bond-by-bond&#x02019; from a pool of atoms. In this framework, the user is able to control the maximum number of heavy atoms in the molecules and, if desired, specific heavy atoms or partial substructures.</p><p>Minimal chemical knowledge is directly incorporated in our model; this takes the form of a set of permitted atom types and basic atomic valency rules which ensure the chemical validity of generated molecules. The model is required to learn all other decisions required to generate molecules.</p><p>Our method learns through a supervised training procedure using pairs of molecules (<xref rid="btab080-F1" ref-type="fig">Fig.&#x000a0;1</xref>).Inspired by <xref rid="btab080-B11" ref-type="bibr">Jin <italic toggle="yes">et al.</italic> (2019)</xref>, we frame decoy generation as a multimodal graph-to-graph translation problem. We train DeepCoy to convert graphs of active molecules into property-matched decoys under an augmented variational autoencoder setting, employing standard gated-graph neural networks (<xref rid="btab080-B16" ref-type="bibr">Li <italic toggle="yes">et al.</italic>, 2016</xref>) in both the encoder and decoder. DeepCoy implicitly learns which properties to keep constant and is not explicitly told which properties to match, nor their values. This provides a highly flexible framework, and makes it possible to learn from pairs of molecules without quantifying their similarity.</p><fig position="float" id="btab080-F1"><label>Fig. 1.</label><caption><p>Illustration of training and generation procedures. (<bold>a</bold>) Pairs of structurally dissimilar molecules with similar physicochemical properties are provided as input. The model is trained to convert one molecule into the other from a combination of the encodings of both molecules. (<bold>b</bold>) At generation time, the model is given only the active molecule and is able to sample a diverse range of property-matched decoys by combining the encoding of the active molecule with random noise. Adapted from <xref rid="btab080-B10" ref-type="bibr">Imrie <italic toggle="yes">et al.</italic>, 2020</xref> under the terms of a CC BY 4.0 license</p></caption><graphic xlink:href="btab080f1" position="float"/></fig><p>We employed a training objective similar to the standard VAE loss, including a reconstruction loss and a Kullback-Leibler (KL) regularization term: 
<disp-formula id="E1"><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">Total</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">recon</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>&#x003bb;</mml:mo></mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The reconstruction loss, <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">recon</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, is composed of two terms resulting from the error in predicting the atom types and in reconstructing the sequence of steps required to produce the target molecule.</p><p>To improve the quality of generated molecules, we adopted a novel loss function that deviates from a standard cross entropy loss for the sequence of actions adopted by <xref rid="btab080-B10" ref-type="bibr">Imrie <italic toggle="yes">et al.</italic> (2020)</xref> and <xref rid="btab080-B17" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> (2018)</xref>. Instead of each step in the generative processes having equal importance, we reweighted the probabilities of actions by the frequencies of the induced subgraphs across the training set of molecules, leading to the revised cross-entropy loss: 
<disp-formula id="E2"><mml:math id="M2" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">L</mml:mi><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mo>*</mml:mo><mml:mo>&#x02009;</mml:mo><mml:mtext>log</mml:mtext><mml:mo>&#x02009;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mi>i</mml:mi></mml:munder></mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the probability of choosing action <italic toggle="yes">x<sub>i</sub></italic>, <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the reciprocal frequency of the induced local subgraph by taking action <italic toggle="yes">x<sub>i</sub></italic>, the sum is over all permitted actions, and <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> is the average of <italic toggle="yes">f</italic> over all permitted actions. This has the effect of reducing the chance of introducing local subgraphs that are not present in the training set. We observe that this change does not meaningfully affect the novelty of generated molecules compared to the standard cross-entropy loss.</p><p>For a more detailed description of the model, see <xref rid="btab080-B10" ref-type="bibr">Imrie <italic toggle="yes">et al.</italic> (2020)</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Information</xref>.</p></sec><sec><title>2.2 Training set</title><p>We constructed pairs of molecules to train our model from the 250 000 molecule subset of ZINC (<xref rid="btab080-B30" ref-type="bibr">Sterling and Irwin, 2015</xref>) selected at random by <xref rid="btab080-B7" ref-type="bibr">G&#x000f3;mez-Bombarelli <italic toggle="yes">et al.</italic> (2018)</xref> as follows.</p><p>We first characterized compounds by their physicochemical properties. The properties can be selected by the user and we demonstrate the effectiveness of our framework using multiple sets of properties (described in Section 2.4). Pairs of molecules were constructed to satisfy the following criteria: (i) identical heavy atom count and counts of specific heavy atoms (C, N, O, S, Cl, F), (ii) high similarity in property-space and (iii) low structural similarity. We measured similarity in property-space using the Euclidean distance between normalized property values and structural similarity by the Tanimoto similarity between the Morgan fingerprints (radius 2, 1024&#x02009;bits, <xref rid="btab080-B25" ref-type="bibr">Rogers and Hahn, 2010</xref>).</p><p>In order to create training sets for our large scale benchmarking experiments (see Section 2.4), we set the maximum permitted structural similarity between a pair of molecules at 0.15 and the maximum distance in property space to 0.20 for the assessment on DUD-E and 0.07 for DEKOIS 2.0. The thresholds were set to ensure roughly equal training set sizes and the differences were as a result of the different sets of properties to unbias. This resulted in a training set of 131&#x000a0;199 pairs for DUD-E and 103&#x000a0;170 for DEKOIS 2.0. We selected 1000 pairs for model validation, and used the remainder to train our model.</p></sec><sec><title>2.3 Assessment</title><p>Several metrics have been proposed to assess artificial enrichment and the risk of false negatives introduced by using putative decoy molecules. <xref rid="btab080-B35" ref-type="bibr">Vogel <italic toggle="yes">et al.</italic> (2011)</xref> proposed the deviation from optimal embedding score (DOE score) and the doppelganger score to assess the quality of physicochemical matching of decoys and risk of introducing latent active molecules, respectively. These metrics are our primary way of assessing the generated decoy molecules.</p><p>The DOE score measures the quality of the embedding of actives and decoys in chemical space by employing a series of receiver operating characteristic curves (ROC curves) for each active calculated using the physicochemical properties of interest. The DOE score is the average absolute difference between these ROC curves and a random distribution. An optimal embedding of actives and decoys achieves a DOE score of zero, while complete separation in physicochemical space results in an DOE score of 0.5.</p><p>The doppelganger score captures the structural similarity between actives and their most structurally related decoys. We generated functional fingerprints (similar to FCFP6) using RDKit (<xref rid="btab080-B14" ref-type="bibr">Landrum, 2006</xref>) for all compounds and evaluated the structural similarity between actives and decoys using the Tanimoto coefficient. For each decoy molecule, its doppelganger score is the maximum similarity across all actives. For each target, we report the mean doppelganger score over all decoys and the maximum structural similarity between an active and a decoy.</p><p>An alternate way to quantify the physicochemical property matching is via predictive models trained on such properties. Bias can be measured using machine learning performance directly (<xref rid="btab080-B28" ref-type="bibr">Sieg <italic toggle="yes">et al.</italic>, 2019</xref>) or a measure of bias can be derived from such models (<xref rid="btab080-B36" ref-type="bibr">Wallach and Heifets, 2018</xref>). We assessed bias using both approaches. First, we trained 1-nearest neighbor (1NN) and random forest (RF) models on all possible subsets of the physicochemical properties deemed non-informative for binding. We adopted 10-fold cross-validation on a per-target basis and assessed performance via the area under the ROC curve (AUC ROC), following <xref rid="btab080-B28" ref-type="bibr">Sieg <italic toggle="yes">et al.</italic> (2019)</xref>. In addition, we calculated AVE (<xref rid="btab080-B36" ref-type="bibr">Wallach and Heifets, 2018</xref>) using the same properties and cross-validation splits.</p><p>We also considered the virtual screening performance of docking using AutoDock Vina (<xref rid="btab080-B33" ref-type="bibr">Trott and Olson, 2010</xref>), specifically the smina (<xref rid="btab080-B12" ref-type="bibr">Koes <italic toggle="yes">et al.</italic>, 2013</xref>) implementation. Ligands were docked against the reference receptor within a box centered around the reference ligand with 8&#x02009;&#x000c5; of padding. We used smina&#x02019;s default arguments for exhaustiveness and sampling. We focused our analysis on performance as measured by AUC ROC.</p></sec><sec><title>2.4 Large scale benchmarking experiments</title><p>We assessed our method using two of the most popular SBVS datasets, DUD-E (<xref rid="btab080-B19" ref-type="bibr">Mysinger <italic toggle="yes">et al.</italic>, 2012</xref>) and DEKOIS 2.0 (<xref rid="btab080-B2" ref-type="bibr">Bauer <italic toggle="yes">et al.</italic>, 2013</xref>).</p><p>We trained a separate model for each of the datasets to demonstrate the flexibility of our method to learn to match different sets of properties. For DEKOIS 2.0, we used the same eight properties employed to construct the dataset (<xref rid="btab080-B2" ref-type="bibr">Bauer <italic toggle="yes">et al.</italic>, 2013</xref>). To assess whether our framework extends to a higher dimensional property space, we trained our model to match twenty-seven properties for our assessment on DUD-E, instead of only the original six properties selected by <xref rid="btab080-B19" ref-type="bibr">Mysinger <italic toggle="yes">et al.</italic> (2012)</xref>. Training set construction is described in Section 2.2 and a complete list of physicochemical properties is provided in <xref rid="sup1" ref-type="supplementary-material">Supplementary Information</xref>. Despite training for this broader array of properties and selecting the final decoys for the DUD-E set based on all 27 properties, we report results calculated using the original six DUD-E properties, unless otherwise stated. Not selecting the DeepCoy set optimally with respect to the original six DUD-E properties will result in inferior performance of DeepCoy, but will allow us to evaluate how our method performs when required to unbias a larger number of properties.</p><p>We filtered the active molecules in both datasets to exclude those containing rare atom types outside of the scope of our model (c. 1% of actives, see <xref rid="sup1" ref-type="supplementary-material">Supplementary Information</xref> for a list of permitted atom types). This led to no actives for DUD-E target FPPS due to the presence of phosphorus in all active molecules. To address this and demonstrate the flexibility of our generative approach, we trained a separate model for this target (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Information</xref> for more details). For each active, we generated 1000 candidate decoys using DeepCoy. We then selected final decoy sets using a similar pipeline to DEKOIS 2.0. Generated molecules were initially filtered by the difference in heavy atom counts and maximum doppelganger score using an iterative procedure until at least 100 candidate decoys remained. The final decoys were selected from these candidate decoys in a greedy manner based on the sum of the normalized property difference and LADS score (<xref rid="btab080-B2" ref-type="bibr">Bauer <italic toggle="yes">et al.</italic>, 2013</xref>). While this greedy selection policy is likely not optimal, we adopted it primarily due to its simplicity. We then compared the generated decoy sets to the original decoy sets using the metrics described in Section 2.3.</p></sec></sec><sec><title>3 Results and discussion</title><p>We assessed our ability to generate property-matched decoy molecules with varying requirements through two widely used SBVS datasets, DUD-E and DEKOIS 2.0. For both sets, we generated new decoy molecules and compared these to the original set, assessing the generated molecules with respect to the same physicochemical properties used to select the original decoys. We show that:
</p><list list-type="bullet"><list-item><p>DeepCoy generated decoys substantially improve property matching compared to the original database decoys.</p></list-item><list-item><p>DeepCoy generated decoys do not introduce additional risk of false negatives.</p></list-item><list-item><p>DeepCoy generated decoys are harder to distinguish from active molecules than the original DUD-E decoys with docking using AutoDock Vina, despite being as structurally dissimilar from the active molecules as the original decoys.</p></list-item></list><p>Our results demonstrate that our framework is an alternative to database approaches for selecting property-matched decoy molecules, while offering full flexibility to the user regarding choice of specific properties and how to choose the final decoys from the generated molecules.</p><sec><title>3.1 Physicochemical property matching</title><p>Across both DUD-E and DEKOIS 2.0, our generated decoy molecules more closely matched the physicochemical properties deemed by the respective datasets to be non-informative for binding than the original decoys (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Information</xref> for a full list of properties).</p><p>When selecting decoys based on the same properties as the original datasets, our generated decoys improved the DOE score by an average of 81% and 66%, respectively, decreasing from 0.166 to 0.032 for DUD-E and 0.109 to 0.038 for DEKOIS 2.0. In this setting, the DOE score was improved by using DeepCoy generated decoys for all 102 DUD-E targets (<xref rid="btab080-F2" ref-type="fig">Fig.&#x000a0;2</xref>) and 80 of the 81 DEKOIS 2.0 targets (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S1</xref>). The only DEKOIS 2.0 target that did not show an improvement in DOE score had DOE scores below 0.04, corresponding to an almost perfect embedding for both the DeepCoy and original decoy molecules. Finally, DeepCoy generated decoys achieved a DOE score below 0.1, indicating a close to optimal embedding (<xref rid="btab080-B2" ref-type="bibr">Bauer <italic toggle="yes">et al.</italic>, 2013</xref>), for 101 of the 102 DUD-E and 79 of the 81 DEKOIS 2.0 targets, while the original decoys only met this threshold for 32 DUD-E and 48 DEKOIS 2.0 targets.</p><fig position="float" id="btab080-F2"><label>Fig. 2.</label><caption><p>DOE scores of the original DUD-E set (blue) compared to the DeepCoy generated decoys (orange). For all targets, the DeepCoy generated decoys have lower DOE score (lower is better), with the average DOE score decreasing by 81% from 0.166 to 0.032. The <italic toggle="yes">x</italic>-axis displays each DUD-E target in the same order as they appear in the DUD-E database (<ext-link xlink:href="http://dude.docking.org/targets" ext-link-type="uri">http://dude.docking.org/targets</ext-link>). The targets with even indices are not labeled on the <italic toggle="yes">x</italic>-axis due to space limitations</p></caption><graphic xlink:href="btab080f2" position="float"/></fig><p>We selected our final decoy set for DUD-E using all 27 properties, rather than just the six used to construct the original dataset. The average DOE score of this set was 0.045, a comparable improvement of 73%, outperforming the original decoys for 98 of the 102 targets (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2</xref>). Importantly, the DeepCoy decoys experienced no drop in performance when all 27 properties were included in the calculation of DOE score, with an average score of 0.041 (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S3</xref>). In contrast, the original decoys experienced a substantial decline to 0.222, proving matching this larger set is non-trivial. This demonstrates the ability of DeepCoy to scale successfully to a high-dimensional property space to unbias.</p><p>A similar improvement can be seen when assessing property matching via the ability of machine learning models to predict whether a compound is an active or a decoy when trained on the physicochemical properties deemed non-informative for binding (<xref rid="btab080-F3" ref-type="fig">Fig.&#x000a0;3</xref>, <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S4</xref>). On the DUD-E set, using all 6 features, the median (average) AUC ROC decreased from 0.66 (0.66) to 0.55 (0.56) and 0.81 (0.80) to 0.67 (0.68) for the 1-nearest neighbor and random forest models, respectively, for the DeepCoy decoys compared to the original set. A similar reduction was observed when using any combination of the physicochemical properties (<xref rid="btab080-F3" ref-type="fig">Fig.&#x000a0;3</xref>).</p><fig position="float" id="btab080-F3"><label>Fig. 3.</label><caption><p>Results of the machine-learning based assessment of physicochemical property matching on DUD-E. Random forests were trained to predict whether a compound was an active or a decoy based on the unbiased features. Virtual screening performance was assessed by AUC ROC for the original DUD-E decoys and DeepCoy generated decoys. The DeepCoy generated decoys resulted in a reduction in the median per-target AUC ROC using all 6 features from 0.81 to 0.67 indicating a substantial reduction in bias</p></caption><graphic xlink:href="btab080f3" position="float"/></fig><p>Assessing bias using AVE also demonstrated a significant reduction in bias with a reduction in median AVE (using all 6 features) of 72% from 0.17 to 0.05 (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S5</xref>). As noted by <xref rid="btab080-B28" ref-type="bibr">Sieg <italic toggle="yes">et al.</italic> (2019)</xref>, while there is a notable correlation between AVE and machine learning performance, AVE does not always explain high predictive performance (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S6</xref>).</p><p>However, even with the much improved property matching of the DeepCoy decoys, there remains some signal in the physicochemical properties. This is in part due to the high level of similarity between many of active molecules in DUD-E, a factor that should be controlled for when constructing the dataset to ensure low levels of bias (<xref rid="btab080-B36" ref-type="bibr">Wallach and Heifets, 2018</xref>). This is exemplified by the DUD-E target SAHH. DeepCoy decoys substantially reduced the DOE for the DUD-E properties to 0.11 (original decoys: 0.19). However, when assessing the decoys using the larger set of 27 properties, it became very challenging to unbias the decoy set (DeepCoy DOE: 0.29, original DOE: 0.34) due to high levels of similarity within the active set. All 63 active molecules for SAHH contain a similar fused ring system, while around half of the active molecules have 4 stereocenters (<xref rid="btab080-F4" ref-type="fig">Fig.&#x000a0;4</xref>). The considerable structural similarity, coupled with the high number of stereocenters for molecules of this size, was the primary cause of the poor DOE scores and is highly challenging to overcome via better decoy selection alone.</p><fig position="float" id="btab080-F4"><label>Fig. 4.</label><caption><p>Four representative active ligands for DUD-E target SAHH. The 63 active molecules for SAHH have high levels of structural similarity, with all sharing similar fused rings systems. These ligands all have at least four stereocenters (highlighted in red, stereochemistry not shown), a property shared by over half of the active molecules for this target</p></caption><graphic xlink:href="btab080f4" position="float"/></fig></sec><sec><title>3.2 False negative bias</title><p>It is crucial that the improvement in property matching achieved by DeepCoy was not as a result of increasing the similarity between the active and decoy molecules, risking increasing false negative bias.</p><p>The average doppelganger score (<xref rid="btab080-B35" ref-type="bibr">Vogel <italic toggle="yes">et al.</italic>, 2011</xref>), a measure of the structural similarity between actives and decoys, remained consistent on the DUD-E set at 0.26 for the DeepCoy decoys and 0.25 for the original decoys, while the average maximum doppelganger score per target fell from 0.37 for the original decoys to 0.34 for the generated decoys. We saw similar results for the DEKOIS set; the average doppelganger score fell slightly (DeepCoy: 0.22, Original: 0.25), while there was a significant drop in maximum doppelganger score from 0.44 to 0.30 when using the DeepCoy decoys.</p><p>These results strongly suggest that the decoys generated by DeepCoy should not carry an increased risk of false negative bias compared to the original decoys.</p></sec><sec><title>3.3 Structure-based virtual screening</title><p>We further validated the quality of our generated decoys by docking the DUD-E set. Several publications have shown that most docking scoring functions are influenced by basic physicochemical properties (e.g. <xref rid="btab080-B4" ref-type="bibr">Chaput <italic toggle="yes">et al.</italic>, 2016</xref>). In particular, <xref rid="btab080-B37" ref-type="bibr">Wallach and Lilien (2011)</xref> showed that property mismatching can lead to an arbitrary increase <italic toggle="yes">or</italic> decrease in virtual screening performance of docking methods. Thus docking performance cannot be used alone to evaluate decoy molecules.</p><p>However, overall, better quality decoys should be harder to distinguish from active molecules, in particular if such decoys also more closely match the physicochemical properties of the active molecules and do not display an increased risk of false negatives.</p><p>The virtual screening performance of AutoDock Vina on the DUD-E set fell to an average per-target AUC ROC of 0.63 for the DeepCoy generated decoys compared to 0.70 for the original decoy molecules. There was a relatively high correlation between the per-target docking performance using the original and DeepCoy decoys (Pearson&#x02019;s R: 0.56, <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S11</xref>) driven by the active molecules, which are common between both sets. However, for 86 of the 102 targets, the DeepCoy decoys led to a lower AUC ROC than the original decoys.</p><p>The decrease in the discriminative power of SBVS is likely driven by the closer property matching of the generated decoys, consistent with other studies (e.g. <xref rid="btab080-B35" ref-type="bibr">Vogel <italic toggle="yes">et al.</italic>, 2011</xref>). This further reinforces the need for unbiased benchmarking sets, even for non-machine learning based scoring functions. For example, the original decoys for IGF1R resulted in a DOE score of 0.23, indicating a large mismatch between the active and decoy molecules. When this set was docked, Vina performed well with an AUC ROC of 0.81. In contrast, the DeepCoy generated decoys gave a DOE score of 0.02, a c. 90% reduction, and had a lower AUC ROC of 0.56. The inability for DeepCoy generated decoys to be easily separated from active molecules via docking together with the lack of additional risk of false negative is further validation of the suitability of these molecules for testing SBVS methods.</p><p>Deep learning-based SBVS methods (e.g. <xref rid="btab080-B22" ref-type="bibr">Ragoza <italic toggle="yes">et al.</italic>, 2017</xref>) have become increasingly popular due to their strong empirical performance. As discussed in Section 1, it has been suggested that, for models trained on DUD-E, a driver of this could be dataset biases (<xref rid="btab080-B5" ref-type="bibr">Chen <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btab080-B28" ref-type="bibr">Sieg <italic toggle="yes">et al.</italic>, 2019</xref>). To assess SBVS methods with an external validation set, <xref rid="btab080-B22" ref-type="bibr">Ragoza <italic toggle="yes">et al.</italic> (2017)</xref> utilized a subset of the datasets curated from ChEMBL (<xref rid="btab080-B3" ref-type="bibr">Bento <italic toggle="yes">et al.</italic>, 2014</xref>) by <xref rid="btab080-B24" ref-type="bibr">Riniker and Landrum (2013)</xref>, selecting the targets to ensure that models were evaluated on dissimilar binding sites to those in the training set.</p><p>Such an external test set should be more representative of real-world use and should not share biases with the training set. However, likely due to the use of decoy molecules from ZINC, the ChEMBL targets share similar biases to DUD-E as measured by the same metrics as our assessment of DUD-E and DEKOIS 2.0 (<xref rid="sup1" ref-type="supplementary-material">Supplementary Figs S7&#x02013;S9</xref>). In particular, random forests trained on the unbiased physicochemical properties of compounds in DUD-E achieved high virtual screening performance on the ChEMBL test sets (average AUC ROC DUD-E features 0.70, larger feature set 0.84, <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S10</xref>). In contrast, when trained on the DeepCoy decoys, the RF model had limited discriminative power on the ChEMBL test sets (average AUC ROC DUD-E features 0.54, larger feature set 0.57). We thus caution against using these datasets as external validation for models trained on DUD-E due to the similar physicochemical biases.</p><p>Since there is limited bias between the version of DUD-E employing DeepCoy decoys and the ChEMBL test sets, we can be more confident that predictive power on the ChEMBL test sets of models trained using DeepCoy decoys arises from the model having learnt meaningful features. We trained the convolutional neural network architectures of <xref rid="btab080-B22" ref-type="bibr">Ragoza <italic toggle="yes">et al.</italic> (2017)</xref> and <xref rid="btab080-B9" ref-type="bibr">Imrie <italic toggle="yes">et al.</italic> (2018)</xref> on the version of DUD-E employing DeepCoy decoys (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Information</xref> for more details). All of the CNN-based models outperformed AutoDock Vina on the ChEMBL test sets (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>). In particular, both gnina (<xref rid="btab080-B22" ref-type="bibr">Ragoza <italic toggle="yes">et al.</italic>, 2017</xref>) and DenseU (<xref rid="btab080-B9" ref-type="bibr">Imrie <italic toggle="yes">et al.</italic>, 2018</xref>) improved early enrichment by around 50% (1.0% ROC EF 11.0 and 11.2, respectively) compared to AutoDock Vina (7.5), while the performance of DenseFS (<xref rid="btab080-B9" ref-type="bibr">Imrie <italic toggle="yes">et al.</italic>, 2018</xref>) improved by 110% (16.0). These results demonstrate that DeepCoy decoys can be used to train complex SBVS models.</p></sec><sec><title>3.4 Synthesisability of generated decoys</title><p>A primary reason for selecting decoys from a virtual library of molecules is their high chance of synthesisability and the ability to purchase such compounds. However, for retrospective screening, or indeed training machine-learning models, decoys do not necessarily need to be synthetically feasible, but should be chemically possible (<xref rid="btab080-B39" ref-type="bibr">Yuriev, 2014</xref>).</p><p>A common criticism of molecules generated using <italic toggle="yes">de novo</italic> design methods is that they are not synthetically accessible. We assessed the synthetic feasibility of molecules using the synthetic accessibility score (SA score, <xref rid="btab080-B6" ref-type="bibr">Ertl and Schuffenhauer, 2009</xref>). SA score ranges from 1 (easy to make) to 10 (very difficult to make), with the majority of bioactive molecules falling between 2.5 and 4.5. The generated decoys have not been optimized for SA score nor selected based on this property. Despite this, the decoys generated by DeepCoy are, on average, relatively synthetically accessible, with an average SA score on the DEKOIS 2.0 set of 3.55 compared to 3.21 for the original decoys and 3.13 for the active molecules.</p><p>SA score is broadly a measure of molecular complexity, but with no regards to the precise functionality nor whether a given molecule should bind to a given target. Thus decoys should match the SA score (or a similar metric) of the active molecules, otherwise molecular complexity could become a distinguishing factor between actives and decoys.</p><p>As such, when generating decoys for DUD-E we included SA score as one of the properties to unbias. The DeepCoy decoys (average SA score: 3.27) more closely matched the SA score of the active molecules (2.99) than the original decoys (3.41). We further demonstrate the effect this has on the SA score of decoy molecules by examining FA7, the median performing target (measured by DOE score) for the original decoy molecules, and NRAM, a target for which the active molecules have relatively high SA scores. The distributions of SA scores for FA7 and NRAM are shown in <xref rid="btab080-F5" ref-type="fig">Figure&#x000a0;5</xref> (mean SA score FA7 actives 2.9, NRAM actives 4.0). The DeepCoy decoys much more closely matched the SA score of the actives molecules of both targets than the original decoys, which did not match the SA score of the actives molecules in either case. This exemplifies the mismatch between SA scores of active and decoy molecules for some targets in DUD-E and demonstrates the adaptability of our generative framework.</p><fig position="float" id="btab080-F5"><label>Fig. 5.</label><caption><p>Synthetic accessibility (SA) scores for the active molecules (blue), original DUD-E decoys (orange) and DeepCoy generated decoys (green) for DUD-E targets FA7 (<bold>A</bold>) and NRAM (<bold>B</bold>). The DeepCoy generated decoys much more closely match SA scores of the active molecules than the original DUD-E decoys for both targets</p></caption><graphic xlink:href="btab080f5" position="float"/></fig></sec><sec><title>3.5 Effect of number of generated candidate decoys per active</title><p>We investigated how the number of candidate decoys generated per active with DeepCoy affects the quality of the final decoy set. Ideally as few candidates would be generated as possible; however, generating more candidates is likely to lead to a higher quality final decoy set. This creates a trade-off between quality and computational requirements.</p><p>To explore this, we used the DEKOIS 2.0 target P38-alpha. This target achieved median performance as measured by DOE score with the original decoys, with a DOE score of 0.088 and doppelganger score of 0.22. We constructed multiple decoy sets by varying the number of candidate decoys generated by DeepCoy between 100 and 5000 per active molecule and selecting the best 30 as described previously.</p><p>Even generating only 100 candidates per active, the DOE score of the DeepCoy decoys was 0.079, representing an improvement over the original decoys of around 10%. As more candidates are generated, this difference rapidly increases (<xref rid="btab080-F6" ref-type="fig">Fig.&#x000a0;6</xref>), with a DOE score of 0.026 when 1000 candidates are generated, a 70% reduction compared to the original decoys. This continues to improve as more candidates are generated, albeit at a slower rate, reaching a score of 0.019 when 5000 are generated. The mean doppelganger score also decreased from 0.26 with 100 candidate per active to 0.23 when 5000 candidates were generated.</p><fig position="float" id="btab080-F6"><label>Fig. 6.</label><caption><p>The effect on the DOE score of the final decoy set as the number of candidate decoys generated by DeepCoy is varied for DEKOIS 2.0 target P38-alpha. In all cases, 30 decoys per active molecule are chosen. The DOE score for the DeepCoy generated decoys decreases rapidly as more candidates are generated, before slowing after 2000 potential decoys are generated. Even with only 100 candidates, the DOE score for the DeepCoy decoys is lower than the original decoys</p></caption><graphic xlink:href="btab080f6" position="float"/></fig><p>While there is a clear dependence between the quality of the final decoy set and the number of candidates generated, DeepCoy generated molecules outperformed the original decoys even when a very limited number of candidates were generated. Unlike a database approach where the maximum performance is limited by the dataset, in our framework the user can decide the desired level of property matching and risk of false negatives, generating additional candidate decoys until this is reached.</p></sec></sec><sec><title>4 Conclusion</title><p>We have developed a graph-based deep learning method for generating property-matched decoy molecules for virtual screening. Unlike almost all virtual screening benchmarks, our method does not rely on a database of molecules from which to select decoys but instead designs ones that are tailored to the active molecule.</p><p>We validated our generative model using two established structure-based virtual screening benchmarks, DUD-E and DEKOIS 2.0. For all 102 DUD-E targets and 80 of the 81 DEKOIS 2.0 targets, our generated decoy molecules more closely matched the physicochemical properties deemed by the respective datasets to be non-informative for binding, while introducing no additional false negative bias.</p><p>In particular, our generated decoys decreased the average DOE score from 0.166 to 0.032 for DUD-E and 0.109 to 0.038 for DEKOIS 2.0, an improvement of 81% and 66%, respectively. In addition, we demonstrated that they are no easier to distinguish than the original decoy molecules via docking with smina/Autodock Vina.</p><p>We believe that this substantial reduction in bias will benefit the development and improve generalization of structure-based virtual screening methods. Currently, methods can perform well on retrospective benchmarks without performing molecular recognition by simply learning underlying biases (<xref rid="btab080-B5" ref-type="bibr">Chen <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btab080-B28" ref-type="bibr">Sieg <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btab080-B36" ref-type="bibr">Wallach and Heifets, 2018</xref>). Thus it is unclear if improvements are genuine or due to more closely capturing these biases. However, when such models were trained on DeepCoy decoys which have limited bias and do not share significant bias with the test set, they displayed substantial predictive power (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>). While our generated decoys might contain new biases of which we are currently unaware, these results together with recent prospective successes (e.g. <xref rid="btab080-B29" ref-type="bibr">Stecula <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btab080-B1" ref-type="bibr">Adeshina <italic toggle="yes">et al.</italic>, 2020</xref>) is good evidence that such methods can learn to perform molecular recognition.</p><p>DeepCoy represents a novel approach to solve this problem, exhibiting substantial benefit over previous database-based methods. Our framework is highly customizable by the user and can naturally be combined with database search. While experimentally verified inactives should be used whenever possible, this is not practically feasible apart from for limited-size benchmarking sets (e.g. <xref rid="btab080-B26" ref-type="bibr">Rohrer and Baumann, 2009</xref>). As such, effective decoys are crucial to the development of structure-based virtual screening methods.</p></sec><sec sec-type="supplementary-material"><title>Supplementary Material</title><supplementary-material id="sup1" position="float" content-type="local-data"><label>btab080_Supplementary_Data</label><media xlink:href="btab080_supplementary_data.zip"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><ack id="ack1"><title>Acknowledgements</title><p>The authors thank David Ryan Koes for providing docked protein-ligand poses of the original DUD-E dataset and ChEMBL test sets.</p><sec><title>Funding</title><p>F.I. is supported by funding from the Engineering and Physical Sciences Research Council (EPSRC) and Exscientia (Reference: EP/N509711/1).</p><p>
<italic toggle="yes">Conflict of Interest:</italic> none declared.</p></sec></ack><ref-list id="ref1"><title>References</title><ref id="btab080-B1"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Adeshina</surname>
<given-names>Y.O.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2020</year>) 
<article-title>Machine learning classification can reduce false positives in structure-based virtual screening</article-title>. <source>Proc. Natl. Acad. Sci, USA</source>, <volume>117</volume>, <fpage>18477</fpage>&#x02013;<lpage>18488</lpage>.<pub-id pub-id-type="pmid">32669436</pub-id></mixed-citation></ref><ref id="btab080-B2"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Bauer</surname>
<given-names>M.R.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2013</year>) 
<article-title>Evaluation and optimization of virtual screening workflows with DEKOIS 2.0 &#x02013; a public library of challenging docking benchmark sets</article-title>. <source>J. Chem. Inf. Model</source>., <volume>53</volume>, <fpage>1447</fpage>&#x02013;<lpage>1462</lpage>.<pub-id pub-id-type="pmid">23705874</pub-id></mixed-citation></ref><ref id="btab080-B3"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Bento</surname>
<given-names>A.P.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2014</year>) 
<article-title>The ChEMBL bioactivity database: an update</article-title>. <source>Nucleic Acids Res</source>., <volume>42</volume>, <fpage>1083</fpage>&#x02013;<lpage>1090</lpage>.</mixed-citation></ref><ref id="btab080-B4"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Chaput</surname>
<given-names>L.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2016</year>) 
<article-title>Benchmark of four popular virtual screening programs: construction of the active/decoy dataset remains a major determinant of measured performance</article-title>. <source>J. Cheminf</source>., <volume>8</volume>, <fpage>56</fpage>.</mixed-citation></ref><ref id="btab080-B5"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Chen</surname>
<given-names>L.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2019</year>) 
<article-title>Hidden bias in the DUD-E dataset leads to misleading performance of deep learning in structure-based virtual screening</article-title>. <source>PLoS One</source>, <volume>14</volume>, <fpage>e0220113</fpage>&#x02013;<lpage>e0220122</lpage>.<pub-id pub-id-type="pmid">31430292</pub-id></mixed-citation></ref><ref id="btab080-B6"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Ertl</surname>
<given-names>P.</given-names>
</string-name>, <string-name><surname>Schuffenhauer</surname><given-names>A.</given-names></string-name></person-group> (<year>2009</year>) 
<article-title>Estimation of synthetic accessibility score of drug-like molecules based on molecular complexity and fragment contributions</article-title>. <source>J. Cheminf</source>., <volume>1</volume>, <fpage>8</fpage>.</mixed-citation></ref><ref id="btab080-B7"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>G&#x000f3;mez-Bombarelli</surname>
<given-names>R.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2018</year>) 
<article-title>Automatic chemical design using a data-driven continuous representation of molecules</article-title>. <source>ACS Cent. Sci</source>., <volume>4</volume>, <fpage>268</fpage>&#x02013;<lpage>276</lpage>.<pub-id pub-id-type="pmid">29532027</pub-id></mixed-citation></ref><ref id="btab080-B8"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Huang</surname>
<given-names>N.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2006</year>) 
<article-title>Benchmarking sets for molecular docking</article-title>. <source>J. Med. Chem</source>., <volume>49</volume>, <fpage>6789</fpage>&#x02013;<lpage>6801</lpage>.<pub-id pub-id-type="pmid">17154509</pub-id></mixed-citation></ref><ref id="btab080-B9"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Imrie</surname>
<given-names>F.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2018</year>) 
<article-title>Protein family-specific models using deep neural networks and transfer learning improve virtual screening and highlight the need for more data</article-title>. <source>J. Chem. Inf. Model</source>., <volume>58</volume>, <fpage>2319</fpage>&#x02013;<lpage>2330</lpage>.<pub-id pub-id-type="pmid">30273487</pub-id></mixed-citation></ref><ref id="btab080-B10"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Imrie</surname>
<given-names>F.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2020</year>) 
<article-title>Deep generative models for 3D linker design</article-title>. <source>J. Chem. Inf. Model</source>., <volume>60</volume>, <fpage>1983</fpage>&#x02013;<lpage>1995</lpage>.<pub-id pub-id-type="pmid">32195587</pub-id></mixed-citation></ref><ref id="btab080-B11"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Jin</surname>
<given-names>W.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2019</year>) Learning multimodal graph-to-graph translation for molecule optimization. In: <italic toggle="yes">Proceedings of the 7th International Conference on Learning Representations,</italic> New Orleans, LA, USA.</mixed-citation></ref><ref id="btab080-B12"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Koes</surname>
<given-names>D.R.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2013</year>) 
<article-title>Lessons learned in empirical scoring with smina from the CSAR 2011 benchmarking exercise</article-title>. <source>J. Chem. Inf. Model</source>., <volume>53</volume>, <fpage>1893</fpage>&#x02013;<lpage>1904</lpage>.<pub-id pub-id-type="pmid">23379370</pub-id></mixed-citation></ref><ref id="btab080-B13"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Lagarde</surname>
<given-names>N.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2015</year>) 
<article-title>Benchmarking data sets for the evaluation of virtual ligand screening methods: review and perspectives</article-title>. <source>J. Chem. Inf. Model</source>., <volume>55</volume>, <fpage>1297</fpage>&#x02013;<lpage>1307</lpage>.<pub-id pub-id-type="pmid">26038804</pub-id></mixed-citation></ref><ref id="btab080-B14"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Landrum</surname>
<given-names>G.</given-names>
</string-name>
</person-group> (<year>2006</year>) RDKit: Open-source cheminformatics. [Online; 1 May 2020, date last accessed).</mixed-citation></ref><ref id="btab080-B15"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Li</surname>
<given-names>H.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2020</year>) 
<article-title>Machine-learning scoring functions for structure-based virtual screening</article-title>. <source>WIREs Comput. Mol. Sci</source>., <volume>11</volume>, <fpage>e1478</fpage>.</mixed-citation></ref><ref id="btab080-B16"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Li</surname>
<given-names>Y.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2016</year>) Gated graph sequence neural networks. <source><italic toggle="yes">In:</italic></source> &#x000a0;<italic toggle="yes">Proceedings of the 4th International Conference on Learning Representations</italic>, San Juan, Puerto Rico.</mixed-citation></ref><ref id="btab080-B17"><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Liu</surname>
<given-names>Q.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2018</year>) <part-title>Constrained graph variational autoencoders for molecule design</part-title>. In: <source>Advances in Neural Information Processing Systems 31 (NeurIPS)</source>, Montr&#x000e9;al, Canada, pp. <fpage>7795</fpage>&#x02013;<lpage>7804</lpage>.</mixed-citation></ref><ref id="btab080-B18"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Liu</surname>
<given-names>S.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2019</year>) 
<article-title>Practical model selection for prospective virtual screening</article-title>. <source>J. Chem. Inf. Model</source>., <volume>59</volume>, <fpage>282</fpage>&#x02013;<lpage>293</lpage>.<pub-id pub-id-type="pmid">30500183</pub-id></mixed-citation></ref><ref id="btab080-B19"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Lyu</surname>
<given-names>J.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2019</year>) 
<article-title>Ultra-large library docking for discovering new chemotypes</article-title>. <source>Nature</source>, <volume>566</volume>, <fpage>224</fpage>&#x02013;<lpage>229</lpage>.<pub-id pub-id-type="pmid">30728502</pub-id></mixed-citation></ref><ref id="btab080-B20"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Mysinger</surname>
<given-names>M.M.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2012</year>) 
<article-title>Directory of useful decoys, enhanced (DUD-E): Better ligands and decoys for better benchmarking</article-title>. <source>J. Med. Chem</source>., <volume>55</volume>, <fpage>6582</fpage>&#x02013;<lpage>6594</lpage>.<pub-id pub-id-type="pmid">22716043</pub-id></mixed-citation></ref><ref id="btab080-B21"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Nicholls</surname>
<given-names>A.</given-names>
</string-name>
</person-group> (<year>2008</year>) 
<article-title>What do we know and when do we know it?</article-title> &#x000a0;<source>J. Comput. Aided Mol. Des</source>., <volume>22</volume>, <fpage>239</fpage>&#x02013;<lpage>255</lpage>.<pub-id pub-id-type="pmid">18253702</pub-id></mixed-citation></ref><ref id="btab080-B22"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Polishchuk</surname>
<given-names>P.G.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2013</year>) 
<article-title>Estimation of the size of drug-like chemical space based on GDB-17 data</article-title>. <source>J. Comput. Aided Mol. Des</source>., <volume>27</volume>, <fpage>675</fpage>&#x02013;<lpage>679</lpage>.<pub-id pub-id-type="pmid">23963658</pub-id></mixed-citation></ref><ref id="btab080-B23"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Ragoza</surname>
<given-names>M.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2017</year>) 
<article-title>Protein-ligand scoring with convolutional neural networks</article-title>. <source>J. Chem. Inf. Model</source>., <volume>57</volume>, <fpage>942</fpage>&#x02013;<lpage>957</lpage>.<pub-id pub-id-type="pmid">28368587</pub-id></mixed-citation></ref><ref id="btab080-B24"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>R&#x000e9;au</surname>
<given-names>M.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2018</year>) 
<article-title>Decoys selection in benchmarking datasets: overview and perspectives</article-title>. <source>Front. Pharmacol</source>., <volume>9</volume>, <fpage>11</fpage>.<pub-id pub-id-type="pmid">29416509</pub-id></mixed-citation></ref><ref id="btab080-B25"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Riniker</surname>
<given-names>S.</given-names>
</string-name>, <string-name><surname>Landrum</surname><given-names>G.A.</given-names></string-name></person-group> (<year>2013</year>) 
<article-title>Open-source platform to benchmark fingerprints for ligand-based virtual screening</article-title>. <source>J. Cheminf</source>., <volume>5</volume>, <fpage>26</fpage>.</mixed-citation></ref><ref id="btab080-B26"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Rogers</surname>
<given-names>D.</given-names>
</string-name>, <string-name><surname>Hahn</surname><given-names>M.</given-names></string-name></person-group> (<year>2010</year>) 
<article-title>Extended-connectivity fingerprints</article-title>. <source>J. Chem. Inf. Model</source>., <volume>50</volume>, <fpage>742</fpage>&#x02013;<lpage>754</lpage>.<pub-id pub-id-type="pmid">20426451</pub-id></mixed-citation></ref><ref id="btab080-B27"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Rohrer</surname>
<given-names>S.G.</given-names>
</string-name>, <string-name><surname>Baumann</surname><given-names>K.</given-names></string-name></person-group> (<year>2009</year>) 
<article-title>Maximum unbiased validation (MUV) data sets for virtual screening based on PubChem bioactivity data</article-title>. <source>J. Chem. Inf. Model</source>., <volume>49</volume>, <fpage>169</fpage>&#x02013;<lpage>184</lpage>.<pub-id pub-id-type="pmid">19434821</pub-id></mixed-citation></ref><ref id="btab080-B28"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Segler</surname>
<given-names>M.H.S.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2018</year>) 
<article-title>Generating focused molecule libraries for drug discovery with recurrent neural networks</article-title>. <source>ACS Cent. Sci</source>., <volume>4</volume>, <fpage>120</fpage>&#x02013;<lpage>131</lpage>.<pub-id pub-id-type="pmid">29392184</pub-id></mixed-citation></ref><ref id="btab080-B29"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Sieg</surname>
<given-names>J.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2019</year>) 
<article-title>In need of bias control: evaluating chemical data for machine learning in structure-based virtual screening</article-title>. <source>J. Chem. Inf. Model</source>., <volume>59</volume>, <fpage>947</fpage>&#x02013;<lpage>961</lpage>.<pub-id pub-id-type="pmid">30835112</pub-id></mixed-citation></ref><ref id="btab080-B30"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Stecula</surname>
<given-names>A.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2020</year>) 
<article-title>Discovery of novel inhibitors of a critical brain enzyme using a homology model and a deep convolutional neural network</article-title>. <source>J. Med. Chem</source>., <volume>63</volume>, <fpage>8867</fpage>&#x02013;<lpage>8875</lpage>.<pub-id pub-id-type="pmid">32787146</pub-id></mixed-citation></ref><ref id="btab080-B31"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Sterling</surname>
<given-names>T.</given-names>
</string-name>, <string-name><surname>Irwin</surname><given-names>J.J.</given-names></string-name></person-group> (<year>2015</year>) 
<article-title>ZINC 15 - ligand discovery for everyone</article-title>. <source>J. Chem. Inf. Model</source>., <volume>55</volume>, <fpage>2324</fpage>&#x02013;<lpage>2337</lpage>.<pub-id pub-id-type="pmid">26479676</pub-id></mixed-citation></ref><ref id="btab080-B32"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Sun</surname>
<given-names>H.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2016</year>) 
<article-title>Constructing and validating high-performance MIEC-SVM models in virtual screening for kinases: a better way for actives discovery</article-title>. <source>Sci. Rep</source>., <volume>6</volume>, <fpage>24817</fpage>.<pub-id pub-id-type="pmid">27102549</pub-id></mixed-citation></ref><ref id="btab080-B33"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Tran-Nguyen</surname>
<given-names>V.-K.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2020</year>) 
<article-title>LIT-PCBA: an unbiased data set for machine learning and virtual screening</article-title>. <source>J. Chem. Inf. Model</source>., <volume>60</volume>, <fpage>4263</fpage>&#x02013;<lpage>4273</lpage>.<pub-id pub-id-type="pmid">32282202</pub-id></mixed-citation></ref><ref id="btab080-B34"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Trott</surname>
<given-names>O.</given-names>
</string-name>, <string-name><surname>Olson</surname><given-names>A.</given-names></string-name></person-group> (<year>2010</year>) 
<article-title>AutoDock Vina: improving the speed and accuracy of docking with a new scoring function, efficient optimization and multithreading</article-title>. <source>J. Comput. Chem</source>., <volume>31</volume>, <fpage>455</fpage>&#x02013;<lpage>461</lpage>.<pub-id pub-id-type="pmid">19499576</pub-id></mixed-citation></ref><ref id="btab080-B35"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Verdonk</surname>
<given-names>M.L.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2004</year>) 
<article-title>Virtual screening using protein&#x02013;ligand docking: avoiding artificial enrichment</article-title>. <source>J. Chem. Inf. Comput. Sci</source>., <volume>44</volume>, <fpage>793</fpage>&#x02013;<lpage>806</lpage>.<pub-id pub-id-type="pmid">15154744</pub-id></mixed-citation></ref><ref id="btab080-B36"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Vogel</surname>
<given-names>S.M.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2011</year>) 
<article-title>DEKOIS: demanding evaluation kits for objective in silico screening &#x02013; a versatile tool for benchmarking docking programs and scoring functions</article-title>. <source>J. Chem. Inf. Model</source>., <volume>51</volume>, <fpage>2650</fpage>&#x02013;<lpage>2665</lpage>.<pub-id pub-id-type="pmid">21774552</pub-id></mixed-citation></ref><ref id="btab080-B37"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Wallach</surname>
<given-names>I.</given-names>
</string-name>, <string-name><surname>Heifets</surname><given-names>A.</given-names></string-name></person-group> (<year>2018</year>) 
<article-title>Most ligand-based classification benchmarks reward memorization rather than generalization</article-title>. <source>J. Chem. Inf. Model</source>., <volume>58</volume>, <fpage>916</fpage>&#x02013;<lpage>932</lpage>.<pub-id pub-id-type="pmid">29698607</pub-id></mixed-citation></ref><ref id="btab080-B38"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Wallach</surname>
<given-names>I.</given-names>
</string-name>, <string-name><surname>Lilien</surname><given-names>R.</given-names></string-name></person-group> (<year>2011</year>) 
<article-title>Virtual decoy sets for molecular docking benchmarks</article-title>. <source>J. Chem. Inf. Model</source>., <volume>51</volume>, <fpage>196</fpage>&#x02013;<lpage>202</lpage>.<pub-id pub-id-type="pmid">21207928</pub-id></mixed-citation></ref><ref id="btab080-B39"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>W&#x000f3;jcikowski</surname>
<given-names>M.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2017</year>) 
<article-title>Performance of machine-learning scoring functions in structure-based virtual screening</article-title>. <source>Sci. Rep</source>., <volume>7</volume>, <fpage>46710</fpage>.<pub-id pub-id-type="pmid">28440302</pub-id></mixed-citation></ref><ref id="btab080-B40"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Yuriev</surname>
<given-names>E.</given-names>
</string-name>
</person-group> (<year>2014</year>) 
<article-title>Challenges and advances in structure-based virtual screening</article-title>. <source>Fut. Med. Chem</source>., <volume>6</volume>, <fpage>5</fpage>&#x02013;<lpage>7</lpage>.</mixed-citation></ref><ref id="btab080-B41"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Zhavoronkov</surname>
<given-names>A.</given-names>
</string-name>
</person-group> &#x000a0;<etal>et al</etal> (<year>2019</year>) 
<article-title>Deep learning enables rapid identification of potent DDR1 kinase inhibitors</article-title>. <source>Nat. Biotechnol</source>., <volume>37</volume>, <fpage>1038</fpage>&#x02013;<lpage>1040</lpage>.<pub-id pub-id-type="pmid">31477924</pub-id></mixed-citation></ref></ref-list></back></article>