<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN" "JATS-archivearticle1-mathml3.dtd"> 
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">Nat Commun</journal-id><journal-id journal-id-type="iso-abbrev">Nat Commun</journal-id><journal-title-group><journal-title>Nature Communications</journal-title></journal-title-group><issn pub-type="epub">2041-1723</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">8100175</article-id><article-id pub-id-type="publisher-id">22869</article-id><article-id pub-id-type="doi">10.1038/s41467-021-22869-8</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>CopulaNet: Learning residue co-evolution directly from multiple sequence alignment for protein structure prediction</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0467-7858</contrib-id><name><surname>Ju</surname><given-names>Fusong</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8272-9190</contrib-id><name><surname>Zhu</surname><given-names>Jianwei</given-names></name><address><email>jianwzhu@microsoft.com</email></address><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Shao</surname><given-names>Bin</given-names></name><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Kong</surname><given-names>Lupeng</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Liu</surname><given-names>Tie-Yan</given-names></name><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Zheng</surname><given-names>Wei-Mou</given-names></name><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4119-4238</contrib-id><name><surname>Bu</surname><given-names>Dongbo</given-names></name><address><email>dbu@ict.ac.cn</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.424936.e</institution-id><institution-id institution-id-type="ISNI">0000 0001 2221 3902</institution-id><institution>Key Lab of Intelligent Information Processing, State Key Lab of Computer Architecture, Big-data Academy, </institution><institution>Institute of Computing Technology, Chinese Academy of Sciences, </institution></institution-wrap>Beijing, China </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.410726.6</institution-id><institution-id institution-id-type="ISNI">0000 0004 1797 8419</institution-id><institution>University of Chinese Academy of Sciences, </institution></institution-wrap>Beijing, China </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.466946.f</institution-id><institution-id institution-id-type="ISNI">0000 0001 2216 5314</institution-id><institution>Microsoft Research Asia, </institution></institution-wrap>Beijing, China </aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.486497.0</institution-id><institution-id institution-id-type="ISNI">0000 0004 1803 484X</institution-id><institution>Institute of Theoretical Physics, Chinese Academy of Sciences, </institution></institution-wrap>Beijing, China </aff></contrib-group><pub-date pub-type="epub"><day>5</day><month>5</month><year>2021</year></pub-date><pub-date pub-type="pmc-release"><day>5</day><month>5</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>12</volume><elocation-id>2535</elocation-id><history><date date-type="received"><day>15</day><month>10</month><year>2020</year></date><date date-type="accepted"><day>28</day><month>3</month><year>2021</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2021</copyright-statement><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article&#x02019;s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article&#x02019;s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">Residue co-evolution has become the primary principle for estimating inter-residue distances of a protein, which are crucially important for predicting protein structure. Most existing approaches adopt an indirect strategy, i.e., inferring residue co-evolution based on some hand-crafted features, say, a covariance matrix, calculated from multiple sequence alignment (MSA) of target protein. This indirect strategy, however, cannot fully exploit the information carried by MSA. Here, we report an end-to-end deep neural network, CopulaNet, to estimate residue co-evolution directly from MSA. The key elements of CopulaNet include: (i) an encoder to model context-specific mutation for each residue; (ii) an aggregator to model residue co-evolution, and thereafter estimate inter-residue distances. Using CASP13 (the 13th Critical Assessment of Protein Structure Prediction) target proteins as representatives, we demonstrate that CopulaNet can predict protein structure with improved accuracy and efficiency. This study represents a step toward improved end-to-end prediction of inter-residue distances and protein tertiary structures.</p></abstract><abstract id="Abs2" abstract-type="web-summary"><p id="Par2">Protein structure prediction is a challenge. A new deep learning framework, CopulaNet, is a major step forward toward end-to-end prediction of inter-residue distances and protein tertiary structures with improved accuracy and efficiency.</p></abstract><kwd-group kwd-group-type="npg-subject"><title>Subject terms</title><kwd>Machine learning</kwd><kwd>Protein structure predictions</kwd></kwd-group><funding-group><award-group><funding-source><institution>National Key Research and Development Program of China (2018YFC0910405, 2020YFA0907000) National Natural Science Foundation of China (31671369, 31770775, 62072435)</institution></funding-source></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; The Author(s) 2021</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1" sec-type="introduction"><title>Introduction</title><p id="Par3">Proteins play critical roles in a wide-range of biological processes including catalyzing metabolic reactions, responding to stimuli, and transporting molecules. These biological activities are largely determined by the fine details of protein tertiary structures <sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. Protein structures can be experimentally determined using nuclear magnetic resonance, X-ray crystallography, and cryogenic electron microscopy<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>; however, these technologies are usually difficult and time-consuming and cannot keep pace with the rapid accumulation of protein sequences<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>. An alternative way is protein structure prediction, which predicts structure for a target protein purely from its amino acid sequence. Generally speaking, protein structure prediction approaches are usually more efficient than the experimental technologies for protein structure determination<sup><xref ref-type="bibr" rid="CR4">4</xref>,<xref ref-type="bibr" rid="CR5">5</xref></sup>.</p><p id="Par4">Major progresses have been made during previous years in protein structure prediction and inter-residue contacts/distances have played important roles. Most of the recent protein structure prediction approaches, such as AlphaFold<sup><xref ref-type="bibr" rid="CR6">6</xref></sup> and trRosetta<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>, employ roughly the same three-step diagram: <italic>i</italic>) estimating inter-residue contacts/distances; <italic>ii</italic>) constructing a potential function based on the estimated contacts/distances; and <italic>iii</italic>) optimizing the potential function to build a tertiary structure with minimal potential. This diagram has been shown to be successful when the estimated inter-residue contacts/distances are sufficiently accurate.</p><p id="Par5">The state-of-the-art approaches to estimating the inter-residue contacts/distances share the same cornerstones, i.e., constructing multiple sequence alignment (MSA) for a target protein of interest and then performing residue co-evolution analysis on the resulting MSA<sup><xref ref-type="bibr" rid="CR8">8</xref>&#x02013;<xref ref-type="bibr" rid="CR10">10</xref></sup>. The underlying rational is that two residues in close spatial proximity always tend to co-evolve; thus, in turn, residue co-evolutions could be exploited to accurately estimate contacts/distances between residues. The co-evolution relationship is usually inferred from residue correlations carried by MSA. This strategy, however, is always hindered by the indirect correlations among residues: the indirect correlations could lead to transitivity in residue spatial proximity and thereafter incorrect estimation of inter-residue contacts/distances. To derive the direct couplings of residues, a variety of direct coupling analysis (DCA) methods have been proposed using precision matrix (the inverse of covariance matrix) or Potts model<sup><xref ref-type="bibr" rid="CR11">11</xref>&#x02013;<xref ref-type="bibr" rid="CR15">15</xref></sup>. Currently the DCA technique is widely used for estimating inter-residue contacts/distances, especially combined with deep neural networks for further refinement. For example, both AlphaFold<sup><xref ref-type="bibr" rid="CR6">6</xref></sup> and RaptorX<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> rely on the inter-residue contacts predicted by CCMpred, a DCA-based approach using the Potts model<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>.</p><p id="Par6">Although the DCA technique has been shown to be effective in estimating inter-residue contacts/distances, it still suffers from several drawbacks. An outstanding drawback is the considerable information loss after transforming MSAs into hand-crafted features, say covariance matrices. In fact, the DCA technique is founded on the premise that the direct couplings between two residues can be modeled using pairwise statistics such as covariance<sup><xref ref-type="bibr" rid="CR9">9</xref>,<xref ref-type="bibr" rid="CR10">10</xref></sup>. However, this premise does not always hold. We demonstrated this possibility using two artifactual proteins <italic>P</italic><sub>1</sub> and <italic>P</italic><sub>2</sub> as counterexamples (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>). In protein <italic>P</italic><sub>1</sub>, two residues <italic>R</italic><sub>1</sub> and <italic>R</italic><sub>2</sub> are close, whereas in protein <italic>P</italic><sub>2</sub>, they are far from each other. Despite the substantial difference in the constructed MSAs for <italic>P</italic><sub>1</sub> and <italic>P</italic><sub>2</sub>, the covariance matrices calculated from these MSAs are completely identical, causing the DCA technique to give identical distance estimations for proteins <italic>P</italic><sub>1</sub> and <italic>P</italic><sub>2</sub>. In fact, for these two MSAs, any statistic of a single residue, or pairwise statistics of two residues, cannot distinguish them. Like the approaches based on covariance matrix, the widely-used Potts model considers these two types of statistics only, and thus also suffers from the limitation illustrated in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>. Consequently, a more effective way to extract direct couplings between residues from MSAs is highly desirable.<fig id="Fig1"><label>Fig. 1</label><caption><title>The limitation of the covariance-based methods in estimating inter-residue distances.</title><p><bold>a</bold> Two artifactual proteins <italic>P</italic><sub>1</sub> and <italic>P</italic><sub>2</sub>. In protein <italic>P</italic><sub>1</sub>, two residues <italic>R</italic><sub>1</sub> and <italic>R</italic><sub>2</sub> are close, whereas in protein <italic>P</italic><sub>2</sub>, they are far from each other. <bold>b</bold> The MSAs constructed for the two proteins show considerable difference. <bold>c</bold> The covariance matrices calculated from these two MSAs are totally identical; thus, the covariance-based methods give the same estimation of inter-residue distances for protein <italic>P</italic><sub>1</sub> and <italic>P</italic><sub>2</sub>. This is contradict the true inter-residue distances. <bold>d</bold> Unlike the covariance matrices, the conditional joint-residue distribution <italic>P</italic>(<italic>R</italic><sub>1</sub>,&#x02009;<italic>R</italic><sub>2</sub>&#x02223;<italic>R</italic><sub>3</sub>) could effectively distinguish these two MSAs.</p></caption><graphic xlink:href="41467_2021_22869_Fig1_HTML" id="d32e485"/></fig></p><p id="Par7">Here, we report an end-to-end deep neural network framework, called CopulaNet, for estimating inter-residue distances. Unlike the existing methods, CopulaNet learns the conditional joint-residue distributions directly from MSAs rather than the hand-crafted features such as covariance matrices. The CopulaNet consists of three key elements, namely, an MSA encoder, a co-evolution aggregator, and a distance estimator. The MSA encoder processes each homologous protein in MSA individually, and embeds each residue to represent its context-specific mutations observed from homologous proteins of the target protein. For any two residues, the aggregator first calculates outer product of their embeddings derived from each homologous protein, then aggregates the outer products acquired from all homologous proteins using average pooling, and finally yields a measure of co-evolution between the two residues. Based on the obtained residue co-evolution, we use a two-dimensional residual network to estimate distance for any residue pairs.</p><p id="Par8">Using CopulaNet as a core module, we develop an approach (called ProFOLD) to protein structure prediction. Briefly speaking, ProFOLD transforms the estimated distances into a potential function, and realizes a tertiary structural conformation with minimal potential. In the following sections, we first demonstrate the concept of ProFOLD using protein T0992-D1 as an example, then apply it to predict structures for the CASP13 target proteins as representatives, and finally compare it with the state-of-the-art prediction approaches. We also present analysis of contributions by the key elements of CopulaNet.</p></sec><sec id="Sec2" sec-type="results"><title>Results</title><sec id="Sec3"><title>Approach summary</title><p id="Par9">The ProFOLD approach is summarized in Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>. Using the CASP13 target protein T0992-D1 as an example, we demonstrate the concept and main steps of ProFOLD for protein structure prediction.<fig id="Fig2"><label>Fig. 2</label><caption><title>Predicting protein tertiary structure using ProFOLD.</title><p>Here, we use the CASP13 target protein T0992-D1 as an example to describe the main steps of ProFOLD. Only the first 13 residues are shown here for the sake of clear description. First, we search this protein against sequence databases to identify its homologous proteins (2,807 proteins in total). Next, we use the acquired homologous protein to construct an MSA for this protein. Then we apply CopulaNet to infer residue co-evolution directly from the MSA. CopulaNet uses an MSA encoder to model the mutation information for each residue of the target protein, and then uses a co-evolution aggregator to measure the residue co-mutations. According to the acquired residue co-evolution information, the distance estimator estimates inter-residue distances. Finally, we transform the estimated distance distributions into a potential function, and then search for the structure conformation with the minimal potential. ProFOLD reports the structural conformation with sufficiently low potential as the final prediction result (TMscore: 0.84).</p></caption><graphic xlink:href="41467_2021_22869_Fig2_HTML" id="d32e511"/></fig></p><p id="Par10">Protein T0992-D1 consists of a total of 107 residues (only the first 13 residues are shown here for the sake of clear description). For this protein, we first identified its homologs through searching it against protein sequence databases including Uniclust30<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>, UniRef90<sup><xref ref-type="bibr" rid="CR19">19</xref></sup> and Metaclust50<sup><xref ref-type="bibr" rid="CR20">20</xref></sup>. The obtained homologous proteins (2807 domains in total) were organized into an MSA. Next, we applied CopulaNet to estimate inter-residue distances directly from the constructed MSA. Here, we inferred the distribution of inter-residue distance over pre-defined 37 bins, rather than a single distance value. Four examples of these distributions are shown in Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">1</xref>. In the case of residues LEU32 and TYR70, the most likely distance interval was predicted to be (7.5&#x0212b;, 8&#x0212b;), which covers the true distance 7.83&#x0212b;. Finally, we transformed the estimated distance distributions into a potential function, and then searched for the structure conformation with the minimal potential through potential minimization. ProFOLD reports the structural conformation with sufficiently low potential as the final prediction result (shown in the lower-right corner of Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>), which perfectly approximates the native structure (TMscore: 0.84).</p><p id="Par11">The core of our ProFOLD approach is CopulaNet, a deep neural network specially designed to learn inter-residue distances directly from MSA. CopulaNet achieves this objective using three key modules, namely, <italic>MSA encoder</italic>, <italic>co-evolution aggregator</italic>, and <italic>distance estimator</italic>, which are described as below.</p><p id="Par12"><italic>MSA encoder</italic> aims to model the mutations of each individual residue of target protein. Here, we represent an MSA with <italic>K</italic> homologous proteins as <italic>K</italic> pairwise alignments, each of which consists of a homologous protein aligned onto the target protein. For each individual alignment, MSA encoder identifies the mutations of each residue of the target protein, and embeds the mutations into a vector of 64 features.</p><p id="Par13">As a residue&#x02019;s mutation is highly related to its neighboring residues, the MSA encoder should consider a residue of interest together with its neighbors during embedding. For this end, we design the encoder as a 1D convolutional residual network<sup><xref ref-type="bibr" rid="CR21">21</xref></sup> with multiple convolution layers, thus enabling it to embed a residue together with its neighbors.</p><p id="Par14"><italic>Co-evolution aggregator</italic> measures the co-evolutions between each pair of residues. For any two residues, the aggregator first calculates outer product of their embedding features derived from a certain homologous protein. As the embedding features of a residue encode its mutations, the outer product of two residues&#x02019; embedding features could effectively measure the strength of co-mutations between them. Next, by using an average-pooling layer, the aggregator calculates the average outer product obtained from all homologous proteins, thus providing thorough information of co-evolutions between the two residues. Further details of outer product and average-pooling layer are shown in the Methods section and Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">2</xref>.</p><p id="Par15"><italic>Distance estimator</italic> aims to estimate inter-residue distances according to the acquired residue co-evolutions. Previous studies have revealed several structure-related patterns existing in the inter-residue distances. Specifically, two contacting parallel <italic>&#x003b2;</italic>-strands often form a diagonal line, whereas two contacting anti-parallel <italic>&#x003b2;</italic>-strands often form an anti-diagonal line. In contrast, two contacting helices usually form a dashed line<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>. Here, we apply a 2D-ResNet to learn these patterns, and thereafter assign these patterns to the estimated inter-residue distances.</p><p id="Par16">To alleviate the difficulty in distance estimation, we transform the distance estimation problem into a classification problem, which is much easier to accomplish. In particular, as performed by trRosetta<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>, we divide the inter-residue distance range into 37 intervals, i.e., (0&#x0212b;, 2.5&#x0212b;), (2.5&#x0212b;, 3.0&#x0212b;),&#x02009;&#x022ef;&#x02009;, (19.5&#x0212b;, 20.0&#x0212b;), and (20.0&#x0212b;,&#x02009;+&#x02009;<italic>&#x0221e;</italic>). For each residue pair, CopulaNet predicts a distance distribution over the 37 intervals instead of a single estimated distance value.</p></sec><sec id="Sec4"><title>Estimating inter-residue distances using CopulaNet</title><p id="Par17">Using CopulaNet, ProFOLD estimated inter-residue distances for all 104 CASP13 protein domains. For the sake of fair comparison, we evaluated these estimations in terms of precision of the predicted inter-residue contacts rather than inter-residue distances. Specifically, for two residues, we summed up the predicted probability mass of the intervals with distance below 8&#x0212b;, and used the sum as predicted probability for the two residue being in contact. As shown in Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>, on the 31 FM domains, ProFOLD achieved prediction precision of 0.840, 0.713 and 0.567 for the most probable <italic>L</italic>/5, <italic>L</italic>/2 and <italic>L</italic> long-range residue contacts, which is significantly higher than A7D (AlphaFold), the winner group of CASP13, by 0.128, 0.117 and 0.097, respectively. We also compared with the updated RaptorX<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>. The prediction results of the updated RaptorX were obtained through re-running it using identical MSA to ProFOLD (see Supplementary material for details). As shown in Supplementary Table&#x000a0;<xref rid="MOESM1" ref-type="media">1</xref>, ProFOLD achieved higher prediction precision than the state-of-the-art approaches.<fig id="Fig3"><label>Fig. 3</label><caption><title>Precision of the predicted inter-residue contacts.</title><p>Here, the most probable <italic>L</italic>/5, <italic>L</italic>/2 and <italic>L</italic> long-range residue contacts are shown, where <italic>L</italic> represents protein length. The phrase "long-range" refers to two residues with sequence separation over 24 residues. For all CASP13 target proteins, ProFOLD outperformed the state-of-the-art approaches. In particular, for the 31 FM domains, ProFOLD achieved precision of 0.840, 0.713 and 0.567 for the most probable <italic>L</italic>/5, <italic>L</italic>/2 and <italic>L</italic> contacts, which is significantly higher than AlphaFold, by 0.128, 0.117 and 0.097, respectively.</p></caption><graphic xlink:href="41467_2021_22869_Fig3_HTML" id="d32e653"/></fig></p><p id="Par18">We further analyzed the contributions of CopulaNet&#x02019;s components for estimating inter-residue distances. As mentioned above, the uniqueness of CopulaNet lies at the use of a learnable "encoder and aggregator&#x0201d; framework rather than traditional statistical models, to infer residue co-evolutions. The obtained residue co-evolutions are further fed into a 2D ResNet to assign the structure-related patterns to inter-residue distances. To examine the contributions by the encoder and aggregator, we built a variant that contains these components only through disabling the 2D ResNet in ProFOLD. The resulting variant, denoted as <italic>ProFOLD w/o R</italic>, was evaluated and compared against the standard ProFOLD.</p><p id="Par19">As shown in Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>, even using the "encoder and aggregator&#x0201d; framework alone, the variant <italic>ProFOLD w/o R</italic> achieved a precision of 0.382 for the top <italic>L</italic> contact predictions on the CASP13 FM targets. The application of the 2D ResNet in ProFOLD further improved the precision by 0.185. In addition, for both CASP13 FM targets and validation dataset, the performance of <italic>P</italic>roFOLD w/o R increases with the receptive field size, implying that encoding more neighbors surrounding residues will greatly facilitate distance estimating (Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>). In the study, we used an MSA encoder with a receptive field size of 33 (16 1D convolution layers, each layer with a kernel size of 3).<fig id="Fig4"><label>Fig. 4</label><caption><title>Precision of the predicted inter-residue contacts by the variant <italic>ProFOLD w/o R</italic>.</title><p><bold>a</bold> For the 31 CASP13 FM targets, the precision increases with the receptive field size and finally reaches 0.382. <bold>b</bold> On the validation set with 1820 proteins, the precision also increases with the receptive field size and finally reaches 0.424. Even using the "encoder and aggregator'' framework alone, the variant <italic>ProFOLD w/o R</italic> still outperformed CCMpred on the two datasets (0.219 and 0.382, respectively).</p></caption><graphic xlink:href="41467_2021_22869_Fig4_HTML" id="d32e698"/></fig></p><p id="Par20">We also implemented three baseline models through replacing the "encoder and aggregator&#x0201d; components of ProFOLD with covariance matrix (a full <italic>L</italic>&#x02009;&#x000d7;&#x02009;<italic>L</italic>&#x02009;&#x000d7;&#x02009;21&#x02009;&#x000d7;&#x02009;21 matrix) and CCMpred output (also a full <italic>L</italic>&#x02009;&#x000d7;&#x02009;<italic>L</italic>&#x02009;&#x000d7;&#x02009;21&#x02009;&#x000d7;&#x02009;21 matrix), respectively. The baseline model that trains our 2D ResNet using the CCMpred output together with sequence profile is denoted as baseline-CCM, whereas the baseline model that trains our 2D ResNet using covariance matrix together with sequence profile is denoted as baseline-Cov. We further implemented a baseline model (called baseline-CF) that uses comprehensive features, including amino acid types, sequence profile, predicted secondary structure, mutual information, covariance matrix and CCMpred output (see Supplementary material for further details).</p><p id="Par21">The performance of these two baseline models is summarized in Supplementary Table&#x000a0;<xref rid="MOESM1" ref-type="media">2</xref>. As shown in this table, on the 31 CASP13 FM targets, ProFOLD achieved higher precision for long-range contact predictions than the baseline model baseline-CCM (0.567 vs. 0.466, 0.713 vs. 0.603, and 0.840 vs. 0.738 for the most probable <italic>L</italic>, <italic>L</italic>/2 and <italic>L</italic>/5 contacts, respectively) and baseline-Cov (0.567 vs. 0.449, 0.713 vs. 0.591, 0.840 vs. 0.713 for the most probable <italic>L</italic>, <italic>L</italic>/2 and <italic>L</italic>/5 contacts, respectively). Although baseline-CF uses comprehensive features and shows performance improvement, ProFOLD still outperformed baseline-CF (0.567 vs. 0.481, 0.713 vs. 0.621, 0.840 vs. 0.749 for the most probable <italic>L</italic>, <italic>L</italic>/2 and <italic>L</italic>/5 contacts, respectively). The superiority of ProFOLD over these baseline models is also observed on the validation set, even if shallow 2DResNet is used.</p><p id="Par22">Taken together, these results clearly suggested that the main contribution to estimation of inter-residue distances comes from the learnable "encoder and aggregator&#x0201d; framework.</p></sec><sec id="Sec5"><title>Predicting protein tertiary structures using ProFOLD</title><p id="Par23">We applied ProFOLD to predict protein tertiary structures and compared it with the state-of-the-art approaches including AlphaFold (A7D group in CASP13)<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>, trRosetta<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>, top server groups, and top human groups reported by the CASP13 organizer. The prediction results of AlphaFold, top human groups and top server groups were downloaded from CASP13 official website (<ext-link ext-link-type="uri" xlink:href="https://predictioncenter.org/download_area/CASP13/predictions_trimmed_to_domains/">https://predictioncenter.org/download_area/CASP13/predictions_trimmed_to_domains/</ext-link>), whereas the prediction results of trRosetta were obtained through re-running it using identical MSA to ProFOLD. The details of these prediction results are summarized in Supplementary Table&#x000a0;<xref rid="MOESM1" ref-type="media">3</xref> and Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">3</xref>.</p><p id="Par24">As shown in Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>a and Supplementary Table&#x000a0;<xref rid="MOESM1" ref-type="media">3</xref>, on the 31 FM CASP13 datasets, ProFOLD outperformed the state-of-the-art approaches. Specifically, when using the popular cut-off threshold for high-quality structures (TMscore &#x02265;0.70)<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>, ProFOLD predicted high-quality structures for 18 out of the 31 domains, whereas AlphaFold and trRosetta predicted high-quality structure for only 12 and 7 domains, respectively. Moreover, the average TMscore of ProFOLD&#x02019;s prediction results is 0.662, which is much higher than that of trRosetta (0.584) and A7D (0.580). Head-to-head comparison clearly demonstrates the advantages of ProFOLD over AlphaFold: for 24 out of the 31 FM domains, ProFOLD outperformed AlphaFold (Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>b). ProFOLD also outperformed trRosetta on these FM targets (Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">4</xref>).<fig id="Fig5"><label>Fig. 5</label><caption><title>Quality of the predicted tertiary structures for CASP13 FM target proteins.</title><p><bold>a</bold> ProFOLD predicted more high-quality structures than the state-of-the-art approaches. When using the popular cut-off threshold for high-quality structures (TMscore &#x02265;0.70), ProFOLD predicted high-quality structures for 18 out of the 31 domains, whereas AlphaFold and trRosetta predicted high-quality structure for only 12 and 7 domains, respectively. <bold>b</bold> Head-to-head comparison clearly demonstrates the advantages of ProFOLD over AlphaFold: for 24 out of the 31 FM domains, ProFOLD outperformed AlphaFold.</p></caption><graphic xlink:href="41467_2021_22869_Fig5_HTML" id="d32e806"/></fig></p><p id="Par25">We also evaluated ProFOLD on the 61 CASP13 TBM and 12 TBM/FM target proteins. For these proteins, although similar template structures are available, ProFOLD predicted their structures in pure ab initio mode without any reference to the template structure information. As shown in Supplementary Table&#x000a0;<xref rid="MOESM1" ref-type="media">3</xref>, for these targets, the average TMscore of ProFOLD&#x02019;s prediction results is 0.784, which is extremely close to the state-of-the-art template-modeling approach Zhang-server (0.787). These results clearly illustrated that the structural information carried by templates might not be necessary for protein structure prediction. Using the accurate estimation of inter-residue distances by CopulaNet, ProFOLD could predict high-quality protein structures without aids of template structures.</p><p id="Par26">We further examined the possible factors that may affect the successful application of ProFOLD. Previous studies have already shown that the quality of predicted structures is highly related to <italic>M</italic><sub><italic>eff</italic></sub>, the number of effective homologous proteins recorded in MSA<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>. As shown in Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref>a, the correlation coefficient between the logarithm of <italic>M</italic><sub><italic>eff</italic></sub> and the quality of predicted structures by ProFOLD is as high as 0.69. Therefore, as long as the <italic>M</italic><sub><italic>eff</italic></sub> of a target protein exceeds 20, TMscore of the predicted structure for this protein is expected to be over 0.60 with high confidence. For proteins T0953s2-D3, T0981-D2, T0991-D1, and T0998-D1, ProFOLD could not predict high-quality structures. The reason might be the lack of sufficient homologous proteins: for these proteins, <italic>M</italic><sub><italic>eff</italic></sub> is as small as less than 20. How to improve CopulaNet and ProFOLD to suit the target proteins with only a few homologous proteins remains a future study.<fig id="Fig6"><label>Fig. 6</label><caption><title>Investigation of possible factors that might affect the&#x000a0;performance of ProFOLD.</title><p>Correlation between quality of the predicted structures and (<bold>a</bold>) <italic>M</italic><sub><italic>eff</italic></sub>, (<bold>b</bold>) the average probability of top <italic>L</italic> predicted contacts (PPC). For the CASP13 FM target proteins, the correlation coefficient between <italic>M</italic><sub><italic>eff</italic></sub> and TMscore of the predicted structures by ProFOLD is as high as 0.69. The correlation efficient between PPC and TMscore of the predicted structures is 0.82.</p></caption><graphic xlink:href="41467_2021_22869_Fig6_HTML" id="d32e878"/></fig></p><p id="Par27">For an approach to protein structure prediction, an interesting and important question is whether we can judge the quality of its prediction results in advance. When the native structure of target protein is already known, we can easily evaluate a predicted structure through comparing it with the native structure; however, thing will become challenging when the native structure is not available. Here, for each structure predicted by ProFOLD, we calculate the average probability of top <italic>L</italic> predicted contacts (denoted as PPC), and use it as estimated quality of the predicted structure. As shown in Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref>b, the correlation efficient between PPC and TMscore of the predicted structures is 0.82. This strong correlation enables us to judge the quality of predicted structure by ProFOLD in advance. Specifically, if a target protein has an estimated PPC over 0.60, the TMscore of the predicted structure by ProFOLD is expected to be over 0.60 with high confidence.</p><p id="Par28">When applying ProFOLD on a target protein having multiple domains, we can either predict structure for the whole target protein, or predict structure for each domain individually. In the above experiments, we evaluated our approach using MSAs constructed from domain sequences. For more thorough investigations, we have repeated the entire evaluation using MSAs constructed from the whole-target sequences. As shown in Supplementary Table&#x000a0;<xref rid="MOESM1" ref-type="media">3</xref>, when using the MSA constructed from the domain sequence, both trRosetta and ProFOLD predict better protein structures than using the MSA constructed from the whole-target sequences (0.668 vs. 0.620 for trRosetta, and 0.743 vs. 0.719 for ProFOLD). However, when considering the 31 FM target proteins only, ProFOLD performs slightly better with the MSA constructed from whole-target sequences.</p></sec><sec id="Sec6"><title>Contribution analysis of ProFOLD&#x02019;s components</title><p id="Par29">To better understand the contribution of ProFOLD&#x02019;s components, we built variants of ProFOLD through disabling each component individually and then compared these variants with the complete ProFOLD approach. In particular, we first disabled the 2D ResNet in distance estimator and thus obtained a variant called <italic>P</italic>roFOLD w/o R. We further disabled the MSA encoder and obtained another variant called <italic>ProFOLD w/o E+R</italic>. For any two residues in target protein, <italic>ProFOLD w/o E+R</italic> captures the correlation between them without consideration of their neighboring residues; thus, it has roughly the same power to the approach that uses covariance matrix for distance estimation.</p><p id="Par30">Using protein T1022s1-D1 as an example, we showed the qualitative comparison of the variants in Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>. When neither MSA encoder nor 2D ResNet is used, the variant <italic>ProFOLD w/o E+R</italic> performed poorly and failed to generate high-quality distance estimations. This result is consistent with the previous observation on the low performance of the covariance-based approaches<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>. When equipped with the MSA encoder module, the variant <italic>ProFOLD w/o R</italic> could generate relatively more accurate distance estimations than <italic>ProFOLD w/o E+R</italic>. Furthermore, as both MSA encoder and 2D ResNet are enabled, the complete ProFOLD approach gave distance estimations extremely close to the true distance values. These results emphasize the importance of considering neighboring residues in encoding step as well as using the 2D ResNet to learn structure-related patterns existing in inter-residue distances.<fig id="Fig7"><label>Fig. 7</label><caption><title>Comparison of the predicted inter-residue distances (bottom left) with the ground-truth distances (upper right) for protein T1022s1-D1.</title><p><bold>a</bold>
<italic>ProFOLD w/o E+R</italic> performed poorly and failed to generate high-quality distance estimations. <bold>b</bold> When equipped with the MSA encoder module, the variant <italic>ProFOLD w/o R</italic> could generate relatively accurate distance estimations. <bold>c</bold> When both MSA encoder and 2D ResNet are used, ProFOLD gave distance estimations extremely close to the real distance values.</p></caption><graphic xlink:href="41467_2021_22869_Fig7_HTML" id="d32e949"/></fig></p><p id="Par31">To investigate the effect of outer product in co-evolution aggregator, we built another variant of ProFOLD (called <italic>ProFOLD w/o OP</italic>) through disabling the outer product operation. Specifically, we removed the term <italic>g</italic>(<italic>i</italic>,&#x02009;<italic>j</italic>) from equation 2, thus modifying <italic>h</italic>(<italic>i</italic>,&#x02009;<italic>j</italic>) to be the concatenation of <italic>f</italic>(<italic>i</italic>) and <italic>f</italic>(<italic>j</italic>) only. As shown in Supplementary Figure&#x000a0;<xref rid="MOESM1" ref-type="media">5</xref>, for the short-range residue contacts (between two residues with sequence separation of 6&#x02013;11 residues), <italic>P</italic>roFOLD w/o OP showed roughly the same prediction precision as ProFOLD. This is reasonable as the convolution modules in MSA encoder has already effectively modeled the short range relationship. In contrast, for the long-range residue contacts, the prediction precision of <italic>ProFOLD w/o OP</italic> decreased sharply to be significantly lower than ProFOLD. This result clearly demonstrated the importance of the outer product operation in modeling the long-range residue contacts, which cannot be achieved using the convolutional network alone.</p></sec><sec id="Sec7"><title>Efficiency of ProFOLD for protein structure prediction</title><p id="Par32">As described above, ProFOLD learns residue co-evolutions directly from MSA rather than hand-crafted features such as covariance matrix. An MSA might have ten of thousands of homologous proteins, whereas the size of covariance matrix is fixed and determined by the target protein length only. Thus, it is interesting to investigate whether ProFOLD could accomplish protein structure prediction within reasonable time on an average computer.</p><p id="Par33">The three key elements of CopulaNet, i.e., <italic>MSA encoder</italic>, <italic>co-evolution aggregator</italic> and <italic>distance estimator</italic>, exhibit different characteristics in running time and memory requirement. Specifically, unlike the final distance estimator processing 2D information of inter-residue co-evolutions, <italic>MSA encoder</italic> processes 1D sequences only. Moreover, the outer product operations could be efficiently accomplished using the fast matrix multiplication provided by the existing deep neural network frameworks<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>. Thus, compared with distance estimator, both <italic>MSA encoder</italic> and <italic>co-evolution aggregator</italic> modules use only a small amount of computations, making the entire running time insensitive to the number of homologous proteins. Moreover, CopulaNet processes each homologous protein individually; thus, the number of homologous proteins in MSA has little effect on the amount of computer memory required for computing inter-residue distances. ProFOLD also uses MSA sampling and distance matrix cropping in training process, which could effectively constrain memory usage and avoid potential overfitting as well (see Method section and Supplementary material for further details).</p><p id="Par34">As results, for target proteins with less than 500 residues, ProFOLD could accomplish the whole structure prediction process within 3 hours on an average laptop computer (Intel CPU 2.8G Hz, 16G memory).</p></sec></sec><sec id="Sec8" sec-type="discussion"><title>Discussion</title><p id="Par35">The results presented here for protein structure prediction using ProFOLD have highlighted the special features of learning residue co-evolutions directly from MSA. The abilities of our approach have been clearly demonstrated using CASP13 target proteins as representatives with improved quality of the predicted structures. Using the end-to-end framework CopulaNet, ProFOLD could accurately estimate inter-residue distances and thereafter predict protein structures. The improved efficiency of ProFOLD is an additional advantage, mainly due to the succinct architecture of CopulaNet. It should also be mentioned that the basic idea and architecture of CopulaNet can be readily modified to calculate conditional joint distribution in other fields besides residue co-evolution.</p><p id="Par36">Although in the proof-of-concept study we demonstrated the application of CopulaNet in ab initio prediction of protein structures, the estimated inter-residue distances could also be used to assist template-based prediction approaches. For example, DeepThreader<sup><xref ref-type="bibr" rid="CR25">25</xref></sup> improves threading by incorporating inter-residue distances into scoring function. EigenThreader<sup><xref ref-type="bibr" rid="CR26">26</xref></sup> and CEThreader<sup><xref ref-type="bibr" rid="CR27">27</xref></sup> align target proteins with templates by considering eigenvector decomposition of the predicted inter-residue contacts. These approaches might benefit from the accurate estimation of inter-residue distances provided by CopulaNet.</p><p id="Par37">As CopulaNet attempts to learn residue co-evolution from MSA, it requires that MSA should have sufficient homolog proteins. For the MSAs with only a few homolog proteins, CopulaNet usually cannot accurately estimate inter-residue distances. How to reduce the amount requirement of homolog proteins remains a future study.</p><p id="Par38">Theoretical analysis suggests a possible failure case of our approach. Consider three residues <italic>r</italic><sub><italic>i</italic></sub>, <italic>r</italic><sub><italic>j</italic></sub>, and <italic>r</italic><sub><italic>k</italic></sub> in the target protein, where both <italic>r</italic><sub><italic>i</italic></sub> and <italic>r</italic><sub><italic>j</italic></sub> are in contact with <italic>r</italic><sub><italic>k</italic></sub> but there is no contact between <italic>r</italic><sub><italic>i</italic></sub> and <italic>r</italic><sub><italic>j</italic></sub>. If the sequence distance between <italic>r</italic><sub><italic>i</italic></sub> and <italic>r</italic><sub><italic>k</italic></sub> (and between <italic>r</italic><sub><italic>j</italic></sub> and <italic>r</italic><sub><italic>k</italic></sub>) is sufficiently long, MSA encoder cannot perfectly model the effect of <italic>r</italic><sub><italic>k</italic></sub> on <italic>r</italic><sub><italic>i</italic></sub> and <italic>r</italic><sub><italic>j</italic></sub>, thus perhaps causing ProFOLD to incorrectly report a contact for residue <italic>r</italic><sub><italic>i</italic></sub> and <italic>r</italic><sub><italic>j</italic></sub>. The increase of receptive field size in MSA encoder will partially alleviate this problem; however, when receptive field size is already large, further increase of it will bring limited gains. A perfect way to model long-distance influence among residues is another future study.</p><p id="Par39">In summary, our work on learning residue co-evolution directly from MSA, together with recent developments in constructing high-quality MSAs, will undoubtedly contribute to more accurate prediction of protein tertiary structures and thereafter understanding protein functions.</p></sec><sec id="Sec9"><title>Methods</title><sec id="Sec10"><title>Architecture of CopulaNet</title><p id="Par40">CopulaNet consists of three key modules, i.e., <italic>MSA encoder</italic>, <italic>co-evolution aggregator</italic>, and <italic>distance estimator</italic>.</p><p id="Par41"><italic>MSA encoder</italic> embeds residue mutations using a 1D convolutional residual network<sup><xref ref-type="bibr" rid="CR21">21</xref></sup>. The residual network has 8 residual blocks, and each residual block consists of two batch-norm layers, two 1D convolution layers with 64 filters (with kernel size of 3) and exponential linear unit (ELU)<sup><xref ref-type="bibr" rid="CR28">28</xref></sup> nonlinearities (Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">6</xref>).</p><p id="Par42"><italic>Co-evolution aggregator</italic> measures the co-mutations between two residues. Before presenting the design of <italic>co-evolution aggregator</italic> module, we describe the notations to be used first.</p><p id="Par43">Consider a target protein with <italic>L</italic> residues <italic>t</italic><sub>1</sub><italic>t</italic><sub>2</sub>&#x02009;&#x022ef;&#x02009;<italic>t</italic><sub><italic>L</italic></sub>, and a pre-built MSA containing <italic>K</italic> homologous proteins. By applying <italic>MSA encoder</italic> on the <italic>k</italic>-th homologous protein in MSA, we obtain a total of <italic>C</italic>&#x02009;&#x000d7;&#x02009;<italic>L</italic> embedding features, denoted as <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${X}_{k}\in {{\mathbb{R}}}^{C\times L}$$\end{document}</tex-math><mml:math id="M2"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2021_22869_Article_IEq1.gif"/></alternatives></inline-formula>, where <italic>C</italic> represents the number of output channels of <italic>MSA encoder</italic>. For residue <italic>t</italic><sub><italic>i</italic></sub> in the target protein, its embedding features extracted from all homologous proteins are aggregated together. The aggregated embedding features, denoted as <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f\in {{\mathbb{R}}}^{C\times L}$$\end{document}</tex-math><mml:math id="M4"><mml:mi>f</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2021_22869_Article_IEq2.gif"/></alternatives></inline-formula>, are calculated as follows.<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f(i)=\frac{1}{{M}_{{eff}}}\mathop{\sum }\limits_{k=1}^{K}{w}_{k}{X}_{k}(i),$$\end{document}</tex-math><mml:math id="M6"><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2021_22869_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where <italic>w</italic><sub><italic>k</italic></sub> denotes the weight of the <italic>k</italic>-th homologous protein, and <inline-formula id="IEq3"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${M}_{{eff}}=\mathop{\sum }\nolimits_{k = 1}^{K}{w}_{k}$$\end{document}</tex-math><mml:math id="M8"><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2021_22869_Article_IEq3.gif"/></alternatives></inline-formula> represents the sum weight of all homologous proteins. Following the convention established by PSICOV<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>, we calculate the weight <italic>w</italic><sub><italic>k</italic></sub> as the inverse of the number of similar homologous proteins that share at least 80% sequence identity with the <italic>k</italic>-th homolog, and thus <italic>M</italic><sub><italic>eff</italic></sub> represents the number of effective homologous proteins recorded in the MSA.</p><p id="Par44">For two residues <italic>t</italic><sub><italic>i</italic></sub> and <italic>t</italic><sub><italic>j</italic></sub> in target protein, the co-evolution aggregator measures their co-mutations using aggregated co-evolution features <inline-formula id="IEq4"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h(i,j)\in {{\mathbb{R}}}^{D}$$\end{document}</tex-math><mml:math id="M10"><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2021_22869_Article_IEq4.gif"/></alternatives></inline-formula>, where <italic>D</italic> denotes the number of output channels of <italic>c</italic>o-evolution aggregator (<italic>D</italic>&#x02009;=&#x02009;4224 in the study), and <italic>h</italic>(<italic>i</italic>,&#x02009;<italic>j</italic>) refers to the concatenation of the aggregated embedding features and their outer products:<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h(i,j)={CONCAT}\left(\right.f(i),f(j),g(i,j)\left)\right..$$\end{document}</tex-math><mml:math id="M12"><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mi>O</mml:mi><mml:mi>N</mml:mi><mml:mi>C</mml:mi><mml:mi>A</mml:mi><mml:mi>T</mml:mi><mml:mfenced open="("><mml:mrow/></mml:mfenced><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mfenced open=")"><mml:mrow/></mml:mfenced><mml:mo>.</mml:mo></mml:math><graphic xlink:href="41467_2021_22869_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>Here, <inline-formula id="IEq5"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$g(i,j)\in {{\mathbb{R}}}^{C\times C}$$\end{document}</tex-math><mml:math id="M14"><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2021_22869_Article_IEq5.gif"/></alternatives></inline-formula> represents the aggregated outer products of the embedding features for residue <italic>t</italic><sub><italic>i</italic></sub> and <italic>t</italic><sub><italic>j</italic></sub>, which is calculated as below.<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$g(i,j)=\frac{1}{{M}_{{eff}}}\mathop{\sum }\limits_{k=1}^{K}{w}_{k}[{X}_{k}(i)\otimes {X}_{k}(j)],$$\end{document}</tex-math><mml:math id="M16"><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02297;</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2021_22869_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>where &#x0201c;&#x02009;&#x02297;&#x02009;&#x0201d; represents the outer product operation.</p><p id="Par45">To summarize, the aggregated co-evolution features consist of <italic>C</italic>&#x02009;&#x000d7;&#x02009;2 aggregated embedding features and <italic>C</italic>&#x02009;&#x000d7;&#x02009;<italic>C</italic> aggregated outer product features. In this study, the output channel size <italic>C</italic> of <italic>MSA encoder</italic> is set as 64. Thus, the co-evolution aggregator generates a total of 4224 (64&#x02009;&#x000d7;&#x02009;2&#x02009;+&#x02009;64&#x02009;&#x000d7;&#x02009;64) aggregated co-evolution features for any two residues in target protein. An example of the outer product operation is shown in Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">2</xref> and explained in more details in Supplementary material.</p><p id="Par46"><italic>Distance estimator</italic> aims to estimate inter-residue distances according to the obtained residue co-evolution using a 2D-ResNet with 72 residual blocks. Each block consists of two batch-norm layers, two 2D dilated convolution layers, and exponential linear unit (ELU) nonlinearities.</p><p id="Par47">The further details of the training process are provided in Supplementary material.</p></sec><sec id="Sec11"><title>Hyperparameter settings of ProFOLD</title><p id="Par48">The hyperparameters of ProFOLD were set based on consideration of prediction performance and model size. Specifically, we tested three variants of the 2DResNet used by ProFOLD (72 residual blocks, 96 channels), including "shallow&#x0201d; 2DResNet with only 36 residual blocks, "deeper&#x0201d; 2DResNet with 96 residual blocks, and "wide&#x0201d; 2DResNet with 128 channels.</p><p id="Par49">As illustrated by Supplementary Table&#x000a0;<xref rid="MOESM1" ref-type="media">4</xref>, the "shallow ProFOLD&#x0201d; shows precision lower than the standard ProFOLD ("shallow ProFOLD": 0.544 vs. standard ProFOLD: 0.567 for the most <italic>L</italic> probable long-range contacts). Similar observations could be achieved for the two baseline models (Supplementary Table&#x000a0;<xref rid="MOESM1" ref-type="media">5</xref>). However, when using more channels, the "shallow but wide ProFOLD&#x0201d; shows roughly the same precision as "shallow ProFOLD&#x0201d;. These results demonstrated that the performance of ProFOLD is more sensitive to the number of residual blocks than the number of channels. We also observed that when further increasing the number of residual blocks, the precision is roughly fixed ("deeper ProFOLD": 0.570 vs. standard ProFOLD: 0.567 for the most <italic>L</italic> probable long-range contacts) but the number of parameters increases sharply.</p><p id="Par50">To balance performance and model size, we used a 2DResNet with 72 residual blocks and 96 channels in the study.</p></sec><sec id="Sec12"><title>Benchmark dataset</title><p id="Par51">In the study, we used the same benchmark dataset as AlphaFold<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>. Briefly speaking, the benchmark dataset was constructed through utilizing 35% sequence similarity cluster representatives of CATH (as of Mar. 16, 2018)<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>. It contains a total of 31,247 non-redundant domains, which was further partitioned into training and validation sets (containing 29,247 and 1,820 proteins, respectively). During the partitioning process, all domains from the same homologous superfamily were allocated to the same partition, thus avoiding potential overlap between partitions.</p><p id="Par52">We tested our methods on CASP13 targets, which consists of 104 domains derived from 71 official targets (the first target was released on May 1, 2018). The 104 domains are officially split into three categories: FM (31 domains), FM/TBM (12 domains) and TBM (61 domains). There is no overlap between training and test sets as the CATH database used in the study were released before testing set.</p></sec><sec id="Sec13"><title>MSA generation and representation</title><p id="Par53">ProFOLD takes multiple sequence alignment of target protein as its only input. For proteins in training and test set, we adopt the same pipeline to construct MSA, i.e., running DeepMSA<sup><xref ref-type="bibr" rid="CR30">30</xref></sup> (with default parameters) against sequence databases Uniclust30 (as of Oct., 2017), UniRef90 (as of Mar., 2018) and Metaclust50 (as of Jan., 2018). All these sequence databases were released before independent test sets and thus there is no overlap between sequence databases and test set.</p><p id="Par54">In the study, we represent the obtained MSA as a collection of sequence pairs. Each sequence pair contains the target protein and a homologous protein. We construct two equal-length strings by adding gaps in aligned sequences so that matching characters are aligned in successive positions (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>). Then we encode each position as a binary vector of 41 elements, including 20 elements for target protein and 21 elements for homologous protein. Here, the 20 elements for target protein represent 20 amino acid types, and the 21 elements include an extra element to represent gap.</p></sec><sec id="Sec14"><title>Structure determination using distance potential</title><p id="Par55">In the study, we build protein tertiary structures from the predicted inter-residue distances in a similar way to trRosetta<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>. Specifically, we first convert the estimated inter-residue distance distributions into a smooth potential function using the DFIRE<sup><xref ref-type="bibr" rid="CR31">31</xref></sup> paradigm. Then, we use <italic>MinMover</italic> in PyRosetta<sup><xref ref-type="bibr" rid="CR32">32</xref></sup> to search for the tertiary structure with the minimal potential, yielding coarse-grained models with residue centroid only. Finally, these coarse-grained models are refined into full-atom models by executing <italic>FastRelax</italic> in Rosetta.</p></sec><sec id="Sec15"><title>Network training setup</title><p id="Par56">To fit the memory limitation, and as a form of data augmentation, we take a sample of at most 1000 sequences from MSA for a target protein. The largest MSA in the training set consists of a total of 64,780 homologous proteins (for protein 3qhpA). Processing such large MSAs requires large memory, which exceeds the capacity of GPU used in the study. To suit the limited GPU capacity, we randomly extract at most 1,000 homologous proteins as representatives to construct an MSA with appropriate size. In addition, as performed by AlphaFold<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>, we also split the distance matrix of a target protein into 128&#x02009;&#x000d7;&#x02009;128 crops, each of which contains pairwise distances between a group of 128 consecutive residues and another group of 128 consecutive residues. The details of network settings are illustrated in Supplementary materials.</p><p id="Par57">Using both MSA sampling and distance matrix cropping in training process, we could effectively constrain memory usage and avoid potential overfitting as well. In addition, all the training parameters in the proposed neural network are independent of the size of target proteins. Hence, the neural network can handle target proteins and MSAs with arbitrary size during inference.</p></sec><sec id="Sec16"><title>Reporting Summary</title><p id="Par58">Further information on research design is available in the&#x000a0;<xref rid="MOESM3" ref-type="media">Nature Research Reporting Summary</xref> linked to this article.</p></sec></sec><sec sec-type="supplementary-material"><title>Supplementary information</title><sec id="Sec17"><supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="41467_2021_22869_MOESM1_ESM.pdf"><caption><p>Supplementary Information</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="MOESM2"><media xlink:href="41467_2021_22869_MOESM2_ESM.pdf"><caption><p>Peer Review File</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="MOESM3"><media xlink:href="41467_2021_22869_MOESM3_ESM.pdf"><caption><p>Reporting Summary</p></caption></media></supplementary-material></sec></sec></body><back><fn-group><fn><p><bold>Peer review information</bold>&#x02009;<italic>Nature Communications</italic> thanks Ivan Anishchanka and the other, anonymous, reviewer for their contribution to the peer review of this work. Peer reviewer reports are available.</p></fn><fn><p><bold>Publisher&#x02019;s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><sec><title>Supplementary information</title><p>The online version contains supplementary material available at 10.1038/s41467-021-22869-8.</p></sec><ack><title>Acknowledgements</title><p>We would like to thank the National Key Research and Development Program of China (2018YFC0910405, 2020YFA0907000), and the National Natural Science Foundation of China (31671369, 31770775, 62072435) for providing financial supports for this study and publication charges.</p></ack><notes notes-type="author-contribution"><title>Author contributions</title><p>D.B. directed the protein structure prediction project. F.J., D.B. and J.Z. conceived the study. F.J. designed and implemented the neural network, and performed the computation. F.J., J.Z., B.S., T.L., W.Z., and D.B. analyzed the experimental results. F.J., L.K. and D.B. established the mathematical framework. F.J. and D.B. wrote and revised the manuscript. All authors read and approved the manuscript.</p></notes><notes notes-type="data-availability"><title>Data availability</title><p>Our training, validation and test data splits are available via <ext-link ext-link-type="uri" xlink:href="http://protein.ict.ac.cn/ProFOLD">http://protein.ict.ac.cn/ProFOLD</ext-link>. The following versions of public datasets were used in this study: PDB 2018-03; CATH 2018-03; Uniclust30 2017-10; UniRef90 2018-03; and Metaclust 2018-01.</p></notes><notes notes-type="data-availability"><title>Code availability</title><p>All source codes and models of ProFOLD are publicly available through <ext-link ext-link-type="uri" xlink:href="https://github.com/fusong-ju/ProFOLD">https://github.com/fusong-ju/ProFOLD</ext-link>. We also developed a web server that is available through <ext-link ext-link-type="uri" xlink:href="http://protein.ict.ac.cn/ProFOLD">http://protein.ict.ac.cn/ProFOLD</ext-link>.</p></notes><notes id="FPar1" notes-type="COI-statement"><title>Competing interests</title><p id="Par59">The authors declare no competing interests.</p></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><mixed-citation publication-type="other">Branden, Carl and Tooze, John.&#x02009;<italic>Introduction to protein structure</italic>.&#x02009;Garland Science, New York, 2 edition, 1 1999.</mixed-citation></ref><ref id="CR2"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dill</surname><given-names>KA</given-names></name><name><surname>MacCallum</surname><given-names>JL</given-names></name></person-group><article-title>The protein-folding problem, 50 years on</article-title><source>Science</source><year>2012</year><volume>338</volume><fpage>1042</fpage><lpage>1046</lpage><pub-id pub-id-type="doi">10.1126/science.1219021</pub-id><pub-id pub-id-type="pmid">23180855</pub-id></element-citation></ref><ref id="CR3"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roy</surname><given-names>A</given-names></name><name><surname>Kucukural</surname><given-names>A</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name></person-group><article-title>I-TASSER: a unified platform for automated protein structure and function prediction</article-title><source>Nat. Protoc.</source><year>2010</year><volume>5</volume><fpage>725</fpage><lpage>738</lpage><pub-id pub-id-type="doi">10.1038/nprot.2010.5</pub-id><pub-id pub-id-type="pmid">20360767</pub-id></element-citation></ref><ref id="CR4"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>J</given-names></name><etal/></person-group><article-title>The I-TASSER suite: protein structure and function prediction</article-title><source>Nat. Methods</source><year>2015</year><volume>12</volume><fpage>7</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1038/nmeth.3213</pub-id><pub-id pub-id-type="pmid">25549265</pub-id></element-citation></ref><ref id="CR5"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuhlman</surname><given-names>B</given-names></name><name><surname>Bradley</surname><given-names>P</given-names></name></person-group><article-title>Advances in protein structure prediction and design</article-title><source>Nat. Rev. Mol. Cell Biol.</source><year>2019</year><volume>20</volume><fpage>681</fpage><lpage>697</lpage><pub-id pub-id-type="doi">10.1038/s41580-019-0163-x</pub-id><pub-id pub-id-type="pmid">31417196</pub-id></element-citation></ref><ref id="CR6"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Senior</surname><given-names>AW</given-names></name><etal/></person-group><article-title>Improved protein structure prediction using potentials from deep learning</article-title><source>Nature</source><year>2020</year><volume>577</volume><fpage>706</fpage><lpage>710</lpage><pub-id pub-id-type="doi">10.1038/s41586-019-1923-7</pub-id><pub-id pub-id-type="pmid">31942072</pub-id></element-citation></ref><ref id="CR7"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>J</given-names></name><etal/></person-group><article-title>Improved protein structure prediction using predicted interresidue orientations</article-title><source>Proc. Natl Acad. Sci. USA</source><year>2020</year><volume>117</volume><fpage>1496</fpage><lpage>1503</lpage><pub-id pub-id-type="doi">10.1073/pnas.1914677117</pub-id><pub-id pub-id-type="pmid">31896580</pub-id></element-citation></ref><ref id="CR8"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Altschuh</surname><given-names>DANI&#x000c8;LE</given-names></name><name><surname>Lesk</surname><given-names>AM</given-names></name><name><surname>Bloomer</surname><given-names>AC</given-names></name><name><surname>Klug</surname><given-names>A</given-names></name></person-group><article-title>Correlation of co-ordinated amino acid substitutions with function in viruses related to tobacco mosaic virus</article-title><source>J. Mol. Biol.</source><year>1987</year><volume>193</volume><fpage>693</fpage><lpage>707</lpage><pub-id pub-id-type="doi">10.1016/0022-2836(87)90352-4</pub-id><pub-id pub-id-type="pmid">3612789</pub-id></element-citation></ref><ref id="CR9"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weigt</surname><given-names>M</given-names></name><name><surname>White</surname><given-names>RA</given-names></name><name><surname>Szurmant</surname><given-names>H</given-names></name><name><surname>Hoch</surname><given-names>JA</given-names></name><name><surname>Hwa</surname><given-names>T</given-names></name></person-group><article-title>Identification of direct residue contacts in protein&#x02013;protein interaction by message passing</article-title><source>Proc. Natl Acad. Sci.</source><year>2009</year><volume>106</volume><fpage>67</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.1073/pnas.0805923106</pub-id><pub-id pub-id-type="pmid">19116270</pub-id></element-citation></ref><ref id="CR10"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Juan</surname><given-names>D</given-names></name><name><surname>Pazos</surname><given-names>F</given-names></name><name><surname>Valencia</surname><given-names>A</given-names></name></person-group><article-title>Emerging methods in protein co-evolution</article-title><source>Nat. Rev. Genet.</source><year>2013</year><volume>14</volume><fpage>249</fpage><lpage>261</lpage><pub-id pub-id-type="doi">10.1038/nrg3414</pub-id><pub-id pub-id-type="pmid">23458856</pub-id></element-citation></ref><ref id="CR11"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morcos</surname><given-names>F</given-names></name><etal/></person-group><article-title>Direct-coupling analysis of residue coevolution captures native contacts across many protein families</article-title><source>Proc. Natl Acad. Sci. USA</source><year>2011</year><volume>108</volume><fpage>E1293</fpage><lpage>E1301</lpage><pub-id pub-id-type="doi">10.1073/pnas.1111471108</pub-id><pub-id pub-id-type="pmid">22106262</pub-id></element-citation></ref><ref id="CR12"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marks</surname><given-names>DS</given-names></name><etal/></person-group><article-title>Protein 3D structure computed from evolutionary sequence variation</article-title><source>PLoS ONE</source><year>2011</year><volume>6</volume><fpage>e28766</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0028766</pub-id><pub-id pub-id-type="pmid">22163331</pub-id></element-citation></ref><ref id="CR13"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marks</surname><given-names>DS</given-names></name><name><surname>Hopf</surname><given-names>TA</given-names></name><name><surname>Sander</surname><given-names>C</given-names></name></person-group><article-title>Protein structure prediction from sequence variation</article-title><source>Nat. Biotechnol.</source><year>2012</year><volume>30</volume><fpage>1072</fpage><pub-id pub-id-type="doi">10.1038/nbt.2419</pub-id><pub-id pub-id-type="pmid">23138306</pub-id></element-citation></ref><ref id="CR14"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>DT</given-names></name><name><surname>Buchan</surname><given-names>DanielWA</given-names></name><name><surname>Cozzetto</surname><given-names>D</given-names></name><name><surname>Pontil</surname><given-names>M</given-names></name></person-group><article-title>PSICOV: precise structural contact prediction using sparse inverse covariance estimation on large multiple sequence alignments</article-title><source>Bioinformatics</source><year>2012</year><volume>28</volume><fpage>184</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btr638</pub-id><pub-id pub-id-type="pmid">22101153</pub-id></element-citation></ref><ref id="CR15"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ekeberg</surname><given-names>M</given-names></name><name><surname>L&#x000f6;vkvist</surname><given-names>C</given-names></name><name><surname>Lan</surname><given-names>Y</given-names></name><name><surname>Weigt</surname><given-names>M</given-names></name><name><surname>Aurell</surname><given-names>E</given-names></name></person-group><article-title>Improved contact prediction in proteins: using pseudolikelihoods to infer Potts models</article-title><source>Phys. Rev. E</source><year>2013</year><volume>87</volume><fpage>012707</fpage><pub-id pub-id-type="doi">10.1103/PhysRevE.87.012707</pub-id></element-citation></ref><ref id="CR16"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>J</given-names></name></person-group><article-title>Distance-based protein folding powered by deep learning</article-title><source>Proc. Natl Acad. Sci. USA</source><year>2019</year><volume>116</volume><fpage>16856</fpage><lpage>16865</lpage><pub-id pub-id-type="doi">10.1073/pnas.1821309116</pub-id><pub-id pub-id-type="pmid">31399549</pub-id></element-citation></ref><ref id="CR17"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seemayer</surname><given-names>S</given-names></name><name><surname>Gruber</surname><given-names>M</given-names></name><name><surname>S&#x000f6;ding</surname><given-names>J</given-names></name></person-group><article-title>CCMpred&#x02013;fast and precise prediction of protein residue&#x02013;residue contacts from correlated mutations</article-title><source>Bioinformatics</source><year>2014</year><volume>30</volume><fpage>3128</fpage><lpage>3130</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btu500</pub-id><pub-id pub-id-type="pmid">25064567</pub-id></element-citation></ref><ref id="CR18"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mirdita</surname><given-names>M</given-names></name><etal/></person-group><article-title>Uniclust databases of clustered and deeply annotated protein sequences and alignments</article-title><source>Nucleic Acids Res.</source><year>2017</year><volume>45</volume><fpage>D170</fpage><lpage>D176</lpage><pub-id pub-id-type="doi">10.1093/nar/gkw1081</pub-id><pub-id pub-id-type="pmid">27899574</pub-id></element-citation></ref><ref id="CR19"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suzek</surname><given-names>BE</given-names></name><etal/></person-group><article-title>UniRef clusters: a comprehensive and scalable alternative for improving sequence similarity searches</article-title><source>Bioinformatics</source><year>2015</year><volume>31</volume><fpage>926</fpage><lpage>932</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btu739</pub-id><pub-id pub-id-type="pmid">25398609</pub-id></element-citation></ref><ref id="CR20"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steinegger</surname><given-names>M</given-names></name><name><surname>S&#x000f6;ding</surname><given-names>J</given-names></name></person-group><article-title>Clustering huge protein sequence sets in linear time</article-title><source>Nat. Commun.</source><year>2018</year><volume>9</volume><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1038/s41467-018-04964-5</pub-id><pub-id pub-id-type="pmid">29317637</pub-id></element-citation></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="other">He, Kaiming, Zhang, Xiangyu, Ren, Shaoqing &#x00026; Sun, Jian. Deep residual learning for image recognition. In&#x02009;<italic>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</italic>,&#x02009; 770&#x02013;778, 2016.</mixed-citation></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="other">Zhang, Qi et al. ISSEC: Inferring contacts among protein secondary structure elements using deep object detection. <italic>BMC Bioinf.</italic><bold>21</bold>, 503&#x000a0;(2020).</mixed-citation></ref><ref id="CR23"><label>23.</label><mixed-citation publication-type="other">Xu, Jinbo, Mcpartlon, Matthew and Li, Jin. Improved protein structure prediction by deep learning irrespective of co-evolution information,&#x02009;<italic>bioRxiv</italic>,&#x02009;2020.</mixed-citation></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="other">Paszke, Adam, et al. PyTorch: an imperative style, high-performance deep learning library. In&#x02009;<italic>Advances in Neural Information Processing Systems</italic>,&#x02009; 8026&#x02013;8037, 2019.</mixed-citation></ref><ref id="CR25"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Bu</surname><given-names>D</given-names></name><name><surname>Xu</surname><given-names>J</given-names></name></person-group><article-title>Protein threading using residue co-variation and deep learning</article-title><source>Bioinformatics</source><year>2018</year><volume>34</volume><fpage>i263</fpage><lpage>i273</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/bty278</pub-id><pub-id pub-id-type="pmid">29949980</pub-id></element-citation></ref><ref id="CR26"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buchan</surname><given-names>DanielWA</given-names></name><name><surname>Jones</surname><given-names>DT</given-names></name></person-group><article-title>EigenTHREADER: analogous protein fold recognition by efficient contact map threading</article-title><source>Bioinformatics</source><year>2017</year><volume>33</volume><fpage>2684</fpage><lpage>2690</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btx217</pub-id><pub-id pub-id-type="pmid">28419258</pub-id></element-citation></ref><ref id="CR27"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>W</given-names></name><etal/></person-group><article-title>Detecting distant-homology protein structures by aligning deep neural-network based contact maps</article-title><source>PLoS Computational Biol.</source><year>2019</year><volume>15</volume><fpage>e1007411</fpage><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007411</pub-id></element-citation></ref><ref id="CR28"><label>28.</label><mixed-citation publication-type="other">Clevert, Djork-Arn&#x000e9;, Unterthiner, Thomas and Hochreiter, Sepp Fast and accurate deep network learning by exponential linear units (ELUs),&#x02009;<italic>arXiv preprint arXiv:1511.07289</italic>,&#x02009;2015.</mixed-citation></ref><ref id="CR29"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dawson</surname><given-names>NL</given-names></name><etal/></person-group><article-title>CATH: an expanded resource to predict protein function through structure and sequence</article-title><source>Nucleic Acids Res.</source><year>2017</year><volume>45</volume><fpage>D289</fpage><lpage>D295</lpage><pub-id pub-id-type="doi">10.1093/nar/gkw1098</pub-id><pub-id pub-id-type="pmid">27899584</pub-id></element-citation></ref><ref id="CR30"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>C</given-names></name><name><surname>Zheng</surname><given-names>W</given-names></name><name><surname>Mortuza</surname><given-names>SM</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name></person-group><article-title>DeepMSA: constructing deep multiple sequence alignment to improve contact prediction and fold-recognition for distant-homology proteins</article-title><source>Bioinformatics</source><year>2020</year><volume>36</volume><fpage>2105</fpage><lpage>2112</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btz863</pub-id><pub-id pub-id-type="pmid">31738385</pub-id></element-citation></ref><ref id="CR31"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>H</given-names></name><name><surname>Zhou</surname><given-names>Y</given-names></name></person-group><article-title>Distance-scaled, finite ideal-gas reference state improves structure-derived potentials of mean force for structure selection and stability prediction</article-title><source>Protein Sci.</source><year>2002</year><volume>11</volume><fpage>2714</fpage><lpage>2726</lpage><pub-id pub-id-type="doi">10.1110/ps.0217002</pub-id><pub-id pub-id-type="pmid">12381853</pub-id></element-citation></ref><ref id="CR32"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chaudhury</surname><given-names>S</given-names></name><name><surname>Lyskov</surname><given-names>S</given-names></name><name><surname>Gray</surname><given-names>JJ</given-names></name></person-group><article-title>PyRosetta: a script-based interface for implementing molecular modeling algorithms using rosetta</article-title><source>Bioinformatics</source><year>2010</year><volume>26</volume><fpage>689</fpage><lpage>691</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btq007</pub-id><pub-id pub-id-type="pmid">20061306</pub-id></element-citation></ref></ref-list></back></article>