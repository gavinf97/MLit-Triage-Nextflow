<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd"> 
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-journalpublishing1.dtd?><?SourceDTD.Version 1.2?><?ConverterInfo.XSLTName jats2jats3.xsl?><?ConverterInfo.Version 1?><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Gigascience</journal-id><journal-id journal-id-type="iso-abbrev">Gigascience</journal-id><journal-id journal-id-type="publisher-id">gigascience</journal-id><journal-title-group><journal-title>GigaScience</journal-title></journal-title-group><issn pub-type="epub">2047-217X</issn><publisher><publisher-name>Oxford University Press</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmcid">10783149</article-id><article-id pub-id-type="pmid">38206587</article-id>
<article-id pub-id-type="doi">10.1093/gigascience/giad111</article-id><article-id pub-id-type="publisher-id">giad111</article-id><article-categories><subj-group subj-group-type="heading"><subject>Technical Note</subject></subj-group><subj-group subj-group-type="category-taxonomy-collection"><subject>AcademicSubjects/SCI00960</subject><subject>AcademicSubjects/SCI02254</subject></subj-group></article-categories><title-group><article-title>Machine Learning Made Easy (MLme): a comprehensive toolkit for machine learning&#x02013;driven data analysis</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-3186-7478</contrib-id><name><surname>Akshay</surname><given-names>Akshay</given-names></name><aff>
<institution>Functional Urology Research Group, Department for BioMedical Research DBMR, University of Bern</institution>, <addr-line>3008 Bern</addr-line>, <country country="CH">Switzerland</country></aff><aff>
<institution>Graduate School for Cellular and Biomedical Sciences, University of Bern</institution>, <addr-line>3012 Bern</addr-line>, <country country="CH">Switzerland</country></aff><xref rid="afn1" ref-type="author-notes"/></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-9248-6348</contrib-id><name><surname>Katoch</surname><given-names>Mitali</given-names></name><aff>
<institution>Institute of Neuropathology, Universit&#x000e4;tsklinikum Erlangen, Friedrich-Alexander-Universit&#x000e4;t Erlangen-N&#x000fc;rnberg (FAU)</institution>, 91054 <addr-line>Erlangen</addr-line>, <country country="DE">Germany</country></aff><xref rid="afn1" ref-type="author-notes"/></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-5750-7801</contrib-id><name><surname>Shekarchizadeh</surname><given-names>Navid</given-names></name><aff>
<institution>Department of Medical Data Science, Leipzig University Medical Centre</institution>, <addr-line>04107 Leipzig</addr-line>, <country country="DE">Germany</country></aff><aff>
<institution>Center for Scalable Data Analytics and Artificial Intelligence (ScaDS.AI) Dresden/Leipzig</institution>, <addr-line>04105 Leipzig</addr-line>, <country country="DE">Germany</country></aff></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-3986-4028</contrib-id><name><surname>Abedi</surname><given-names>Masoud</given-names></name><aff>
<institution>Department of Medical Data Science, Leipzig University Medical Centre</institution>, <addr-line>04107 Leipzig</addr-line>, <country country="DE">Germany</country></aff></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-1399-7503</contrib-id><name><surname>Sharma</surname><given-names>Ankush</given-names></name><aff>
<institution>KG Jebsen Centre for B-cell Malignancies, Institute for Clinical Medicine, University of Oslo</institution>, <addr-line>0318 Oslo</addr-line>, <country country="NO">Norway</country></aff><aff>
<institution>Department of Cancer Immunology, Institute for Cancer Research, Oslo University Hospital</institution>, <addr-line>0310 Oslo</addr-line>, <country country="NO">Norway</country></aff></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-8271-014X</contrib-id><name><surname>Burkhard</surname><given-names>Fiona C</given-names></name><aff>
<institution>Functional Urology Research Group, Department for BioMedical Research DBMR, University of Bern</institution>, <addr-line>3008 Bern</addr-line>, <country country="CH">Switzerland</country></aff><aff>
<institution>Department of Urology, Inselspital University Hospital</institution>, 3010 <addr-line>Bern</addr-line>, <country country="CH">Switzerland</country></aff></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-0943-6236</contrib-id><name><surname>Adam</surname><given-names>Rosalyn M</given-names></name><aff>
<institution>Urological Diseases Research Center, Boston Children's Hospital</institution>, 02115 Boston, <addr-line>MA</addr-line>, <country country="US">USA</country></aff><aff>
<institution>Department of Surgery, Harvard Medical School</institution>, 02115 Boston, MA, <country country="US">USA</country></aff><aff>
<institution>Broad Institute of MIT and Harvard</institution>, <addr-line>Cambridge, 02142 MA</addr-line>, <country country="US">USA</country></aff></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-2042-1139</contrib-id><name><surname>Monastyrskaya</surname><given-names>Katia</given-names></name><aff>
<institution>Functional Urology Research Group, Department for BioMedical Research DBMR, University of Bern</institution>, <addr-line>3008 Bern</addr-line>, <country country="CH">Switzerland</country></aff><aff>
<institution>Department of Urology, Inselspital University Hospital</institution>, 3010 <addr-line>Bern</addr-line>, <country country="CH">Switzerland</country></aff></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-9625-6259</contrib-id><name><surname>Gheinani</surname><given-names>Ali Hashemi</given-names></name><!--Ali.HashemiGheinani@childrens.harvard.edu--><aff>
<institution>Functional Urology Research Group, Department for BioMedical Research DBMR, University of Bern</institution>, <addr-line>3008 Bern</addr-line>, <country country="CH">Switzerland</country></aff><aff>
<institution>Department of Urology, Inselspital University Hospital</institution>, 3010 <addr-line>Bern</addr-line>, <country country="CH">Switzerland</country></aff><aff>
<institution>Urological Diseases Research Center, Boston Children's Hospital</institution>, 02115 Boston, <addr-line>MA</addr-line>, <country country="US">USA</country></aff><aff>
<institution>Department of Surgery, Harvard Medical School</institution>, 02115 Boston, MA, <country country="US">USA</country></aff><aff>
<institution>Broad Institute of MIT and Harvard</institution>, <addr-line>Cambridge, 02142 MA</addr-line>, <country country="US">USA</country></aff><xref rid="cor1" ref-type="corresp"/></contrib></contrib-group><author-notes><corresp id="cor1">
<bold>Correspondence address:</bold> Ali Hashemi Gheinani, Urological Diseases Research Center, Boston Children's Hospital, Harvard Medical School and Broad Institute of MIT and Harvard, Cambridge, MA, USA. E-mail: <email>Ali.HashemiGheinani@childrens.harvard.edu</email></corresp><fn id="afn1"><p>Contributed equally.</p></fn></author-notes><pub-date pub-type="epub" iso-8601-date="2024-01-11"><day>11</day><month>1</month><year>2024</year></pub-date><pub-date pub-type="collection"><year>2024</year></pub-date><pub-date pub-type="pmc-release"><day>11</day><month>1</month><year>2024</year></pub-date><volume>13</volume><elocation-id>giad111</elocation-id><history><date date-type="received"><day>04</day><month>7</month><year>2023</year></date><date date-type="rev-recd"><day>20</day><month>9</month><year>2023</year></date><date date-type="accepted"><day>08</day><month>12</month><year>2023</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2024. Published by Oxford University Press GigaScience.</copyright-statement><copyright-year>2024</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><self-uri xlink:href="giad111.pdf"/><abstract><title>Abstract</title><sec id="abs1"><title>Background</title><p>Machine learning (ML) has emerged as a vital asset for researchers to analyze and extract valuable information from complex datasets. However, developing an effective and robust ML pipeline can present a real challenge, demanding considerable time and effort, thereby impeding research progress. Existing tools in this landscape require a profound understanding of ML principles and programming skills. Furthermore, users are required to engage in the comprehensive configuration of their ML pipeline to obtain optimal performance.</p></sec><sec id="abs2"><title>Results</title><p>To address these challenges, we have developed a novel tool called Machine Learning Made Easy (MLme) that streamlines the use of ML in research, specifically focusing on classification problems at present. By integrating 4 essential functionalities&#x02014;namely, Data Exploration, AutoML, CustomML, and Visualization&#x02014;MLme fulfills the diverse requirements of researchers while eliminating the need for extensive coding efforts. To demonstrate the applicability of MLme, we conducted rigorous testing on 6 distinct datasets, each presenting unique characteristics and challenges. Our results consistently showed promising performance across different datasets, reaffirming the versatility and effectiveness of the tool. Additionally, by utilizing MLme&#x02019;s feature selection functionality, we successfully identified significant markers for CD8<sup>+</sup> naive (BACH2), CD16<sup>+</sup> (CD16), and CD14<sup>+</sup> (VCAN) cell populations.</p></sec><sec id="abs3"><title>Conclusion</title><p>MLme serves as a valuable resource for leveraging ML to facilitate insightful data analysis and enhance research outcomes, while alleviating concerns related to complex coding scripts. The source code and a detailed tutorial for MLme are available at <ext-link xlink:href="https://github.com/FunctionalUrology/MLme" ext-link-type="uri">https://github.com/FunctionalUrology/MLme</ext-link>.</p></sec></abstract><kwd-group kwd-group-type="keywords"><kwd>machine learning</kwd><kwd>classification problems</kwd><kwd>data analysis</kwd><kwd>AutoML</kwd><kwd>visualization</kwd></kwd-group><funding-group><award-group award-type="grant"><funding-source>
<institution-wrap><institution>National Science Foundation</institution><institution-id institution-id-type="DOI">10.13039/100000001</institution-id></institution-wrap>
</funding-source><award-id>310030</award-id><award-id>175773</award-id><award-id>212298</award-id></award-group><award-group award-type="grant"><funding-source>
<institution-wrap><institution>Life Spinal Cord Research Foundation</institution></institution-wrap>
</funding-source><award-id>WFL-AT-06/19</award-id></award-group><award-group award-type="grant"><funding-source>
<institution-wrap><institution>Else Kr&#x000f6;ner-Fresenius-Stiftung</institution><institution-id institution-id-type="DOI">10.13039/501100003042</institution-id></institution-wrap>
</funding-source><award-id>2021_EKeA.33</award-id></award-group></funding-group><counts><page-count count="9"/></counts></article-meta></front><body><boxed-text position="float"><label>Key points</label><list list-type="bullet"><list-item><p>MLme is a novel tool that simplifies machine learning (ML) for researchers by integrating Data Exploration, AutoML, CustomML, and Visualization functionalities.</p></list-item><list-item><p>MLme improves efficiency and productivity by streamlining the ML workflow and eliminating the need for extensive coding efforts.</p></list-item><list-item><p>Rigorous testing on diverse datasets demonstrates MLme&#x02019;s promising performance in classification problems.</p></list-item><list-item><p>MLme provides intuitive interfaces for data exploration, automated ML, customizable ML pipelines, and result visualization.</p></list-item><list-item><p>Future developments aim to expand MLme&#x02019;s capabilities to include support for unsupervised learning, regression, hyperparameter tuning, and integration of user-defined algorithms.</p></list-item></list></boxed-text><sec sec-type="intro" id="sec2"><title>Introduction</title><p>In the realm of research, machine learning (ML) has emerged as a vital resource for analyzing intricate datasets that conventional statistical approaches struggle to interpret [<xref rid="bib1" ref-type="bibr">1&#x02013;5</xref>]. However, the integration of ML into research presents a multitude of challenges. Foremost, the construction and execution of an effective ML pipeline can be daunting, requiring deep domain expertise, extensive technical knowledge, and proficient programming skills. In addition, the utilization of ML techniques demands a comprehensive understanding of the underlying principles to ensure that the trained models are unbiased and transparent.</p><p>Multiple tools have been developed to streamline the process of building and executing ML pipelines (<xref rid="sup15" ref-type="supplementary-material">Supplementary Table S1</xref>) [<xref rid="bib6" ref-type="bibr">6&#x02013;16</xref>]. These tools often require a significant level of coding proficiency and extensive configuration to achieve optimal effectiveness. Additionally, many of these tools serve as algorithm recommenders, functioning by running multiple ML algorithms on user-provided data and providing model performance metrics. However, this approach can limit user input and guidance, as the tools tend to prioritize automated decision-making rather than allowing users to actively participate in the process. As a result, tailoring the ML models to specific research needs and ensuring that the models align with domain knowledge and expertise can be challenging. This lack of flexibility and limited user control potentially hinder the accuracy and applicability of the research outcomes.</p><p>Machine Learning Made Easy (MLme) is a comprehensive solution aimed at bridging the gap between researchers and the inherent technical complexities of ML. It facilitates the adoption of ML techniques by simplifying the ML workflow and minimizing the typically steep learning curve associated with ML. Through its intuitive interfaces, MLme enhances accessibility and usability for researchers of varying levels of technical expertise (Fig.&#x000a0;<xref rid="fig1" ref-type="fig">1</xref>).</p><fig position="float" id="fig1"><label>Figure 1:</label><caption><p>Graphical abstract. The input data for Machine Learning Made Easy (MLme) is a file with samples as rows and features as columns, with sample names in the first column and target classes in the last column. MLme provides various features to enhance usability. The data exploration feature enables users to explore the data and gain initial insights. For advanced users, the custom ML feature allows the creation of custom ML pipelines. Upon execution, MLme generates a compressed zip file containing inputParameter.pkl, script.py, and README.txt. Alternatively, users can opt for the AutoML feature, which applies a default ML pipeline to the input file. Both CustomML and AutoML produce a results.pkl file, which can be further analyzed using the visualization feature.</p></caption><graphic xlink:href="giad111fig1" position="float"/></fig><p>MLme offers 4 important components: Data Exploration, AutoML, CustomML, and Visualization, each serving a specific purpose in understanding and extracting meaningful information from the data within the ML workflow. Through the intuitive Data Exploration feature, users easily examine their datasets and gain preliminary understanding using an interactive interface. For advanced users, the CustomML interface within MLme provides a flexible platform to design and develop tailor-made ML pipelines that align with their specific research requirements. Furthermore, it facilitates effortless interpretation and analysis of results with rich visualization capabilities.</p></sec><sec id="sec3"><title>Key Features of MLme</title><p>MLme is a multifaceted toolkit that equips researchers with the functionalities necessary to effectively utilize ML in their research. It consists of 4 distinct web interfaces, each tailored to address specific research needs, ensuring a versatile and comprehensive experience for users.</p><sec id="sec3-1"><title>Data Exploration</title><p>The Data Exploration feature of MLme allows users to upload their datasets and explore them using a range of statistical visualizations, such as density plots, scatter matrix plots, area plots, and class distribution plots (<xref rid="sup15" ref-type="supplementary-material">Supplementary Fig. S1A</xref>). These visualizations and statistical summaries enable users to gain a comprehensive understanding of their data, including patterns and trends within the data, data distribution, and potential outliers. A density plot, for instance, can reveal how data are distributed, while a scatter matrix plot can identify potential correlations. Class distribution plots are particularly useful for comprehending the balance of target classes within the dataset, which can be crucial when designing a machine learning model.</p><p>Overall, the Data Exploration feature enables users to efficiently explore their datasets and acquire initial insights into their data. This knowledge can inform subsequent modeling decisions, ensuring that users are using the most appropriate modeling techniques for their specific dataset.</p></sec><sec id="sec3-2"><title>AutoML</title><p>The AutoML feature in MLme enables users to effortlessly extract meaningful information from their datasets using ML, even without extensive technical expertise (<xref rid="sup15" ref-type="supplementary-material">Supplementary Fig. S1B</xref>). With a preconfigured ML pipeline (Fig.&#x000a0;<xref rid="fig2" ref-type="fig">2</xref>), the AutoML handles essential preprocessing steps such as data resampling, scaling, and feature selection [<xref rid="bib17" ref-type="bibr">17</xref>]. These steps ensure that the input data are properly prepared for ML algorithms, enhancing the performance and reliability of subsequent trained models. The AutoML conducts training and evaluation of multiple classification models, including a dummy classifier. By employing diverse models, users gain a comprehensive understanding of their data and can identify the most effective algorithms for their specific dataset.</p><fig position="float" id="fig2"><label>Figure 2:</label><caption><p>Default ML Pipeline for AutoML. The default ML pipeline can be represented as a flowchart that starts by splitting the input dataset into training and independent test sets, provided the user has activated the test set option. Otherwise, the entire dataset is used for training. In the subsequent step, the training dataset is divided into <italic toggle="yes">n</italic> bins of equal size through stratified sampling. From these bins, k &#x02013; 1 are designated as training sets while the remainder becomes the test set. In the preprocessing step, low variance features are removed first, followed by data scaling and resampling. Subsequently, the SelectPercentile univariate feature selection method is applied to select important features, and 5 ML classification algorithms are trained. Model performance is assessed on the test set using 3 different methods, and multiple performance metrics are computed. This entire process is repeated for each unique bin in the k-fold corss validation (CV) method. The pipeline outputs a zip file comprising the log .txt and the results.pkl files. The user can examine the results by visualizing the contents of the pickle file using MLme.</p></caption><graphic xlink:href="giad111fig2" position="float"/></fig><p>After the pipeline is completed, the AutoML offers users various options for examining and interpreting the results. These options include intuitive and interactive plots, which help users gain a deeper understanding of the performance characteristics of the models. Additionally, users have the flexibility to download the results and explore them further using the Visualization interface at their convenience.</p></sec><sec id="sec3-3"><title>CustomML</title><p>The CustomML feature of MLme empowers users with moderate to advanced knowledge of the ML domain to design and customize an ML pipeline that caters to their specific research needs (<xref rid="sup15" ref-type="supplementary-material">Supplementary Fig. S2A</xref>). With its user-friendly and intuitive interface, users can easily include or exclude steps and algorithms using a simple toggle button. This eliminates the worry about writing complex programming scripts and allows focusing on selecting the most suitable steps and algorithms for the dataset.</p><p>CustomML offers an extensive range of preprocessing options, including 7 algorithms for data resampling, 19 algorithms for scaling, and a diverse array of feature selection algorithms to select relevant features from the dataset. Moreover, with 16 classification algorithms available, users can refine their pipeline to align with their research requirements. To provide a comprehensive understanding of the trained model&#x02019;s performance, CustomML supports 10 different evaluation methods and 14 evaluation metrics.</p><p>The customization options of CustomML are enhanced by allowing users to select the parameters value for all the provided algorithms, giving them greater control over the behavior of their developed pipeline. Once the pipeline is designed, it can be conveniently downloaded and executed either locally or on a cluster, offering flexibility in computing resources. The CustomML-generated ML pipeline produces a pickle file (.pkl) as an output upon completion, which contains all the results from the pipeline. This file can be uploaded to the Visualization interface, enabling users to interpret these results using various plots.</p></sec><sec id="sec3-4"><title>Visualization</title><p>The Visualization feature in MLme allows users to effortlessly interpret their results without the need for advanced programming skills or expertise in data visualization (<xref rid="sup15" ref-type="supplementary-material">Supplementary Fig. S2B</xref>). It provides a comprehensive range of plots and tables, covering fundamental as well as advanced options such as bar plots, heatmaps, and spider plots. These diverse visualization tools facilitate effective comparison of trained model performance.</p><p>Furthermore, this feature allows users to customize the appearance of their plots by selecting from over 50 different color palettes. Additionally, all generated plots are of high quality and are downloadable in high resolution, ensuring they are suitable for publication purposes. <xref rid="sup15" ref-type="supplementary-material">Supplementary Fig. S11</xref> showcases the available list of algorithms and diverse plot types within MLme for various machine learning stages.</p></sec></sec><sec sec-type="cases" id="sec4"><title>Use Cases</title><sec id="sec4-1"><title>Dataset selection criteria</title><p>The MLme application is evaluated using 7 distinct datasets (<xref rid="sup15" ref-type="supplementary-material">Supplementary Table S2</xref>) that are carefully chosen to ensure robustness. Factors such as sample size, diversity, class imbalance, and dimensionality are considered during the selection process. The selected datasets vary in sample size and diversity, providing a comprehensive assessment of the MLme application&#x02019;s performance across different data scales.</p><p>This includes datasets of varying sizes, from small (chronic lymphocytic leukemia [CLL] and cervical cancer study) to large (invasive breast carcinoma and body signal datasets), which test the application&#x02019;s scalability and efficiency. Imbalanced datasets, like invasive breast carcinoma (BRCA), are included to evaluate the MLme application&#x02019;s handling of class imbalance and prediction accuracy, which is particularly relevant in real-world scenarios, such as biological research. The datasets also address the challenge of high-dimensional features and low sample sizes, known as the curse of dimensionality. By including such datasets, MLme&#x02019;s ability to handle challenges is thoroughly assessed.</p><p>Furthermore, the glass identification dataset was selected as a nonbiological example, offering variation and enabling testing across diverse domains. This dataset, with multiple target classes, allows evaluation of the MLme application&#x02019;s performance in multiclass classification problems.</p></sec><sec id="sec4-2"><title>Dataset descriptions</title><p>The first dataset comprised messenger RNA (mRNA) patient data (<italic toggle="yes">n</italic> = 136) obtained from a study on CLL, which measured their transcriptome profiles [<xref rid="bib18" ref-type="bibr">18</xref>]. Our objective was to build a model that could classify male and female patients based on their transcriptomic profiles, using the top 5,000 most variable mRNAs (excluding Y chromosome genes). The second dataset was collected from a cervical cancer study that analyzed the expression levels of 714 microRNAs (miRNAs) in human samples (<italic toggle="yes">n</italic> = 58) [<xref rid="bib19" ref-type="bibr">19</xref>].</p><p>The third and fourth datasets were obtained from The Cancer Genome Atlas (TCGA), consisting of mRNA (<italic toggle="yes">n</italic> = 1,219) and miRNA (<italic toggle="yes">n</italic> = 1,207) sequencing data from patients with invasive BRCA, which were retrieved using the TCGAbiolinks package [<xref rid="bib20" ref-type="bibr">20</xref>] in <italic toggle="yes">R</italic>. For the BRCA mRNA dataset, we focused only on differentially expressed genes from edgeR (False discovery rate (FDR) &#x02264;0.001 and log fold change &#x0003e;&#x000b1;2) [<xref rid="bib21" ref-type="bibr">21</xref>]. Our goal was to train a model capable of distinguishing normal and tumor samples for both cervical cancer and TCGA&#x02013;BRCA datasets.</p><p>The fifth dataset consists of single-cell RNA (scRNA) sequencing data obtained from peripheral blood mononuclear cells (PBMCs) that were sequenced using 10&#x000d7; chromium technology [<xref rid="bib22" ref-type="bibr">22</xref>]. Among all the cell populations described in this study, we specifically utilized the scRNA datasets of CD8<sup>+</sup> naive, CD14<sup>+</sup>, and CD16<sup>+</sup> monocytes (<italic toggle="yes">n</italic> = 1,500) with the goal of identifying distinct markers for each of these cell populations.</p><p>The sixth dataset utilized in this study was the widely recognized glass identification dataset (<italic toggle="yes">n</italic> = 214) obtained from the University of California, Irvine ML repository [<xref rid="bib23" ref-type="bibr">23</xref>]. This dataset comprises 10 distinct features that represent oxide content of glass samples. The primary objective of this dataset is to classify different types of glass based on their oxide content.</p><p>The seventh dataset in our study comprises body signal data collected from 100,000 individuals through the National Health Insurance Service in Korea [<xref rid="bib24" ref-type="bibr">24</xref>]. This dataset includes 21 essential biological signals related to health, such as measurements of systolic blood pressure and total cholesterol levels. Our main goal with this dataset was to determine whether individuals consume alcohol based on the available biological signal information.</p></sec><sec id="sec4-3"><title>Results</title><p>To perform a thorough assessment of the MLme functionality, we utilized its CustomML feature to construct distinct ML pipelines for CLL, cervical cancer, body signal, and TCGA datasets. These pipelines entailed various processing steps, including data scaling and resampling using different algorithms, multiple ML classifiers, diverse evaluation methods, and metrics. Additionally, we employed the AutoML feature of MLme to train multiple models for both the PBMC and glass datasets. The top-performing models consistently achieved scores exceeding 90% for all computed metrics across all evaluated datasets except glass identification and body signal datasets. As anticipated, the dummy classifiers performed the worst among all the datasets (<xref rid="sup15" ref-type="supplementary-material">Supplementary Figs. S3&#x02013;S9</xref>). Additionally, we conducted a comparative analysis to assess the performance of MLme in comparison to Tree-based Pipeline Optimization Tool (TPOT) and hyperopt-sklearn on these datasets. The fact that all 3 tools demonstrated similar performance (<xref rid="sup15" ref-type="supplementary-material">Supplementary Fig. S10</xref>) for all datasets, except the glass dataset, underscores the reliability and consistency of the results produced by MLme. For hyperopt-sklearn, we configured it to comprehensively explore all classification algorithms and data transformations within the library while utilizing the tree-structured Parzen estimator algorithm for hyperparameter search. For TPOT, we employed a 5-minute runtime limit, a population size of 50, 5 generations, and default values for all other parameters.</p><p>To further demonstrate the applicability of MLme, we utilized its feature selection functionality from AutoML to identify the most important genes for classifying CD8<sup>+</sup> naive, CD14<sup>+</sup>, and CD16<sup>+</sup> monocyte cell populations from the PBMC dataset. By selecting the top 10% of the original input of 500 highly variable genes, MLme provided a list of 50 genes that are sufficient for classifying these cell types (Fig.&#x000a0;<xref rid="fig3" ref-type="fig">3A</xref>). These 50 genes exhibited a strong correspondence with their respective cell populations, except for 13 ribosomal genes (RPS and RPL) that showed similar expression levels across all 3 cell types.</p><fig position="float" id="fig3"><label>Figure 3:</label><caption><p>Identification of potential markers for CD8<sup>+</sup> naive, CD16<sup>+</sup>, and CD14<sup>+</sup> cell populations in the PBMC dataset. (<bold>A</bold>) Heatmap visualization showing the expression patterns of 50 genes selected by MLme. (<bold>B</bold>&#x02013;<bold>D</bold>) Expression levels of key markers specific to CD8<sup>+</sup> naive, CD16<sup>+</sup>, and CD14<sup>+</sup> cell populations, respectively, within each cell type.</p></caption><graphic xlink:href="giad111fig3" position="float"/></fig><p>Among the remaining 37 genes, we discovered classic markers for CD8<sup>+</sup> naive cells (TCF7 [<xref rid="bib25" ref-type="bibr">25</xref>, <xref rid="bib26" ref-type="bibr">26</xref>], LEF1 [<xref rid="bib25" ref-type="bibr">25</xref>], BACH2 [<xref rid="bib27" ref-type="bibr">27</xref>], BCL11B [<xref rid="bib28" ref-type="bibr">28</xref>], and THEMIS [<xref rid="bib29" ref-type="bibr">29</xref>]), which have been previously described in the literature (Fig.&#x000a0;<xref rid="fig3" ref-type="fig">3B</xref>). The list also included markers for the CD16<sup>+</sup> cell population, such as FCGR3A (CD16), TCF7L2, MS4A7, IFITM3, MTSS1, LST1, and WARS (Fig.&#x000a0;<xref rid="fig3" ref-type="fig">3C</xref>), which have been associated with CD16+ cells in previous studies [<xref rid="bib30" ref-type="bibr">30</xref>, <xref rid="bib31" ref-type="bibr">31</xref>]. Furthermore, our marker list encompassed known CD14<sup>+</sup> specific genes, including VCAN, a marker of monocytic lineage [<xref rid="bib32" ref-type="bibr">32</xref>]; CSF3R, previously described in the CD14<sup>+</sup> population [<xref rid="bib33" ref-type="bibr">33</xref>]; and NEAT1 (Fig.&#x000a0;<xref rid="fig3" ref-type="fig">3D</xref>). These findings validate the biological relevance of the selected genes and highlight the utility of the MLme tool in biomedical research.</p></sec></sec><sec id="sec5"><title>Implementation</title><p>The MLme is developed using the <italic toggle="yes">Dash</italic> library [<xref rid="bib34" ref-type="bibr">34</xref>] in the <italic toggle="yes">Python</italic> [<xref rid="bib35" ref-type="bibr">35</xref>] programming language. Plots are generated using <italic toggle="yes">Plotly</italic> [<xref rid="bib36" ref-type="bibr">36</xref>], <italic toggle="yes">matplotlib</italic> [<xref rid="bib37" ref-type="bibr">37</xref>], and <italic toggle="yes">bokeh</italic> [<xref rid="bib38" ref-type="bibr">38</xref>] libraries. <italic toggle="yes">Pandas</italic> [<xref rid="bib39" ref-type="bibr">39</xref>] and <italic toggle="yes">NumPy</italic> [<xref rid="bib40" ref-type="bibr">40</xref>] libraries are used to handle data storage and processing. The development of the ML pipeline is facilitated by employing the <italic toggle="yes">Scikit-Learn</italic> [<xref rid="bib41" ref-type="bibr">41</xref>] and <italic toggle="yes">Imbalanced Learn</italic> [<xref rid="bib42" ref-type="bibr">42</xref>] libraries.</p></sec><sec id="sec6"><title>Limitations</title><p>Currently, MLme focuses on classification problems since a substantial portion of research questions and available datasets are aligned with the domain of classification. This limitation hinders MLme&#x02019;s applicability to regression or unsupervised learning tasks. Additionally, the tool lacks built-in hyperparameter tuning capabilities. This absence of a key feature may hinder users in fine-tuning their models.</p><p>Overall, despite its limitations in handling regression and unsupervised ML problems, the current version of MLme is well equipped to develop pipelines for classification tasks. It is worth noting that users have the flexibility to choose values for all the parameters of a given algorithm through the user interface, to some extent mitigating the impact of the lack of built-in hyperparameter tuning.</p></sec><sec sec-type="conclusions" id="sec7"><title>Conclusion</title><p>Our article introduces a user-friendly tool called MLme, which offers a wide range of functionalities for ML analysis. Its primary goal is to make ML accessible to users of all skill levels by removing technical barriers. With the Data Exploration feature, users can efficiently explore datasets and gain initial insights into their data. The AutoML feature simplifies ML usage, allowing them to leverage ML capabilities without dealing with complex technicalities. Moreover, the CustomML functionality assists in creating personalized pipelines using an intuitive graphical user interface that caters to specific requirements, eliminating the need for coding complexities. Additionally, the Visualization features enable users to interactively explore and understand model performance, without extensive data visualization or coding expertise. In summary, MLme is a powerful and user-friendly tool that empowers researchers to enhance their research outcomes through ML.</p><p>However, it is crucial to emphasize that, despite their impressive capabilities, automated ML tools should never be regarded as a replacement for domain expertise. Users of MLme must maintain a strong awareness of the invaluable role that domain knowledge plays when using this software to address real-world problems. Consequently, expertise in the specific field remains irreplaceable, and MLme should be viewed as a complementary tool to augment, rather than replace, human understanding and insights.</p></sec><sec id="sec8"><title>Outlook</title><p>Despite the limitations mentioned above, there are several promising directions for future development of the MLme. Our primary objective is to expand the capabilities of MLme to include support for unsupervised learning and regression problems. This expansion will greatly enhance the tool&#x02019;s utility and enable its application in a broader range of ML tasks.</p><p>Recognizing the importance of hyperparameter tuning in optimizing models, we plan to incorporate hyperparameter tuning capabilities into the tool. This addition will enable users to fine-tune their models and improve overall performance, thereby increasing the effectiveness and reliability of MLme. Additionally, we intend to introduce a feature that allows users to upload and integrate their own algorithms into the pipeline. This feature will enable users to use their preferred algorithms, even if they are not currently available within the tool, thereby expanding its applicability and customization options.</p><p>By drawing inspiration from other similar tools like MLbox [<xref rid="bib11" ref-type="bibr">11</xref>], TransmogrifAI [<xref rid="bib9" ref-type="bibr">9</xref>], STREAMLINE [<xref rid="bib10" ref-type="bibr">10</xref>], AutoSklearn [<xref rid="bib16" ref-type="bibr">16</xref>], and Weka [<xref rid="bib6" ref-type="bibr">6</xref>], we aim to integrate advanced features into MLme. These include automated data cleaning, robust feature engineering, and efficient data imputation. These future developments aim to overcome the current limitations of MLme and enhance its functionality and adaptability. By addressing these limitations, we firmly believe that the MLme will evolve into a more comprehensive and valuable resource for ML practitioners.</p></sec><sec id="sec9"><title>Availability of Supporting Source Code and Requirements</title><p>Project name: Machine Learning Made Easy (MLme)</p><p>Project homepage: <ext-link xlink:href="https://github.com/FunctionalUrology/MLme" ext-link-type="uri">https://github.com/FunctionalUrology/MLme</ext-link></p><p>Operating system(s): Platform independent</p><p>Programming language: Python (version 3.9)</p><p>Other requirements: Docker or Python</p><p>License: GNU GPL</p><p>BioTool ID: MLme</p><p>SciCrunch ID: MLme (RRID: SCR_024439)</p></sec><sec sec-type="supplementary-material"><title>Supplementary Material</title><supplementary-material id="sup1" position="float" content-type="local-data"><label>giad111_GIGA-D-23-00182_Original_Submission</label><media xlink:href="giad111_giga-d-23-00182_original_submission.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material id="sup2" position="float" content-type="local-data"><label>giad111_GIGA-D-23-00182_Revision_1</label><media xlink:href="giad111_giga-d-23-00182_revision_1.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material id="sup3" position="float" content-type="local-data"><label>giad111_GIGA-D-23-00182_Revision_2</label><media xlink:href="giad111_giga-d-23-00182_revision_2.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material id="sup4" position="float" content-type="local-data"><label>giad111_GIGA-D-23-00182_Revision_3</label><media xlink:href="giad111_giga-d-23-00182_revision_3.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material id="sup5" position="float" content-type="local-data"><label>giad111_GIGA-D-23-00182_Revision_4</label><media xlink:href="giad111_giga-d-23-00182_revision_4.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material id="sup6" position="float" content-type="local-data"><label>giad111_Response_to_Reviewer_Comments_Original_Submission</label><media xlink:href="giad111_response_to_reviewer_comments_original_submission.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material id="sup7" position="float" content-type="local-data"><label>giad111_Response_to_Reviewer_Comments_Revision_1</label><media xlink:href="giad111_response_to_reviewer_comments_revision_1.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material id="sup8" position="float" content-type="local-data"><label>giad111_Response_to_Reviewer_Comments_Revision_2</label><media xlink:href="giad111_response_to_reviewer_comments_revision_2.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material id="sup9" position="float" content-type="local-data"><label>giad111_Response_to_Reviewer_Comments_Revision_3</label><media xlink:href="giad111_response_to_reviewer_comments_revision_3.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material id="sup10" position="float" content-type="local-data"><label>giad111_Reviewer_1_Report_Original_Submission</label><caption><p>Joe Greener -- 9/1/2023 Reviewed</p></caption><media xlink:href="giad111_reviewer_1_report_original_submission.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material id="sup11" position="float" content-type="local-data"><label>giad111_Reviewer_1_Report_Revision_1</label><caption><p>Joe Greener -- 10/2/2023 Reviewed</p></caption><media xlink:href="giad111_reviewer_1_report_revision_1.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material id="sup12" position="float" content-type="local-data"><label>giad111_Reviewer_2_Report_Original_Submission</label><caption><p>Ryan J. Urbanowicz -- 9/5/2023 Reviewed</p></caption><media xlink:href="giad111_reviewer_2_report_original_submission.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material id="sup13" position="float" content-type="local-data"><label>giad111_Reviewer_2_Report_Revision_1</label><caption><p>Ryan J. Urbanowicz -- 10/9/2023 Reviewed</p></caption><media xlink:href="giad111_reviewer_2_report_revision_1.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material id="sup14" position="float" content-type="local-data"><label>giad111_Reviewer_2_Report_Revision_2</label><caption><p>Ryan J. Urbanowicz -- 10/27/2023 Reviewed</p></caption><media xlink:href="giad111_reviewer_2_report_revision_2.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material id="sup15" position="float" content-type="local-data"><label>giad111_Supplemental_Files</label><media xlink:href="giad111_supplemental_files.zip"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><ack id="ack1"><title>Acknowledgement</title><p>We thank Pedro Perreira Amado for his invaluable contribution in testing MLme.</p></ack><sec sec-type="supplementary-material" id="sec10"><title>Additional Files</title><p>
<bold>Supplementary Fig. S1</bold>. Key features of Machine Learning Made Easy (MLme). (A) Data Exploration. (B) AutoML.</p><p>
<bold>Supplementary Fig. S2</bold>. Key features of Machine Learning Made Easy (MLme). (A) CustomML. (B) Visualization.</p><p>
<bold>Supplementary Fig. S3</bold>. Projection of metrics scores on 2-dimensional polar coordinates. The plots illustrate the performance scores of the top and worst 5 machine learning (ML) algorithms trained on the chronic lymphocytic leukemia (CLL) dataset, both during training (A) and testing (B). Each ML model is represented by a circle, and each vertex represents a specific performance metric. A circle with a larger shaded area indicates better performance.</p><p>
<bold>Supplementary Fig. S4</bold>. Projection of metrics scores on 2-dimensional polar coordinates. The plots illustrate the performance scores of the top and worst 5 machine learning (ML) algorithms trained on the cervical cancer dataset, both during training (A) and testing (B). Each ML model is represented by a circle, and each vertex represents a specific performance metric. A circle with a larger shaded area indicates better performance.</p><p>
<bold>Supplementary Fig. S5</bold>. Projection of metrics scores on 2-dimensional polar coordinates. The plots illustrate the performance scores of the top and worst 5 machine learning (ML) algorithms trained on the TCGA mRNA dataset, both during training (A) and testing (B). Each ML model is represented by a circle, and each vertex represents a specific performance metric. A circle with a larger shaded area indicates better performance.</p><p>
<bold>Supplementary Fig. S6</bold>. Projection of metrics scores on 2-dimensional polar coordinates. The plots illustrate the performance scores of the top and worst 5 machine learning (ML) algorithms trained on the TCGA miRNA dataset, both during training (A) and testing (B). Each ML model is represented by a circle, and each vertex represents a specific performance metric. A circle with a larger shaded area indicates better performance.</p><p>
<bold>Supplementary Fig. S7</bold>. Projection of metrics scores on 2-dimensional polar coordinates. The plots illustrate the performance scores of the top and worst 5 machine learning (ML) algorithms trained on the peripheral blood mononuclear cell (PBMC) dataset, both during training (A) and testing (B). Each ML model is represented by a circle, and each vertex represents a specific performance metric. A circle with a larger shaded area indicates better performance.</p><p>
<bold>Supplementary Fig. S8</bold>. Projection of metrics scores on 2-dimensional polar coordinates. The plots illustrate the performance scores of the top and worst 5 machine learning (ML) algorithms trained on the glass identification dataset, both during training (A) and testing (B). Each ML model is represented by a circle, and each vertex represents a specific performance metric. A circle with a larger shaded area indicates better performance.</p><p>
<bold>Supplementary Fig. S9</bold>. Projection of metrics scores on 2-dimensional polar coordinates. The plots illustrate the performance scores of the machine learning (ML) algorithms trained on the body signal dataset, both during training (A) and testing (B). Each ML model is represented by a circle, and each vertex represents a specific performance metric. A circle with a larger shaded area indicates better performance.</p><p>
<bold>Supplementary Fig. S10</bold>. Performance comparison of MLme, TPOT, and hyperopt-sklearn across multiple datasets. Each bar in (A), (B), and (C) represents the F1, accuracy, and recall scores, respectively, on the test data for each dataset.</p><p>
<bold>Supplementary Fig. S11</bold>. MLme&#x02019;s list of algorithms and diverse plot types for different machine learning stages. MLme offers an array of diverse plots suitable for both exploratory data analysis (EDA) (A) and visualizing outcomes derived from either AutoML or CustomML (B). MLme provides users with the flexibility to design their own machine learning pipelines. (C) The potential pipeline steps alongside corresponding algorithm choices and (D) the steps and corresponding algorithms included in MLme&#x02019;s default AutoML pipeline.</p><p>
<bold>Supplementary Table S1</bold>. Comparison of features between MLme and other similar machine learning automation tools.</p><p>
<bold>Supplementary Table S2</bold>. Example datasets used in this study.</p></sec><sec sec-type="data-availability" id="sec11"><title>Data Availability</title><p>All supporting data, including the input dataset, &#x0201c;inputParameters.pkl,&#x0201d; and &#x0201c;results.pkl&#x0201d; files, for all evaluated datasets, are available on Zenodo [<xref rid="bib43" ref-type="bibr">43</xref>]. The &#x0201c;results.pkl&#x0201d; files can be visualized using the Visualization feature of MLme. An archival copy of the source code and supporting data is also available via the <italic toggle="yes">GigaScience</italic> database, GigaDB [<xref rid="bib44" ref-type="bibr">44</xref>]. DOME-ML (Data, Optimisation, Model, and Evaluation in Machine Learning) annotation, supporting the current study, is available through DOME Wizard. The link to the DOME annotations for this study is available on GigaDB [<xref rid="bib44" ref-type="bibr">44</xref>].</p></sec><sec id="sec12"><title>Abbreviations</title><p>BRCA: breast carcinoma; CLL: chronic lymphocytic leukemia; miRNA: microRNA; ML: machine learning; MLme: Machine Learning Made Easy; mRNA: messenger RNA; PBMC: peripheral blood mononuclear cell; TCGA: The Cancer Genome Atlas.</p></sec><sec sec-type="COI-statement" id="sec13"><title>Competing Interests</title><p>The authors declare they have no competing interests.</p></sec><sec id="sec14"><title>Authors&#x02019; Contributions</title><p>K.M., A.H.G, A.A., and M.K. conceived the idea for the manuscript. A.A. and M.K. wrote the source code and conducted testing and debugging of the MLme. K.M., F.C.B., R.M.A., A.H.G., and A.S. provided feedback on the biological application of the tool. N.S., M.A., A.H.G., and A.S. provided technical feedback throughout the development phase and participated in testing and debugging. K.M., A.A., and M.K. wrote the manuscript with inputs from all the other authors. All authors contributed to proofreading and revising the manuscript.</p></sec><sec id="sec15"><title>Funding</title><p>We gratefully acknowledge the financial support of the Swiss National Science Foundation (SNF Grant 310030_175773 to F.C.B. and K.M., 212298 to F.C.B. and A.H.G.) and the Wings for Life Spinal Cord Research Foundation(WFL-AT-06/19 to K.M.). A.H.G. and R.M.A. are supported by R01 DK127673. M.K. is supported by the Else Kr&#x000f6;ner-Fresenius-Stiftung (EKFS 2021_EKeA.33). The authors acknowledge the financial support from the Federal Ministry of Education and Research of Germany and by the S&#x000e4;chsische Staatsministerium f&#x000fc;r Wissenschaft Kultur und Tourismus in the program Center of Excellence for AI-research &#x0201c;Center for Scalable Data Analytics and Artificial Intelligence Dresden/Leipzig&#x0201d; (project identification number: ScaDS.AI).</p></sec><ref-list id="ref1"><title>References</title><ref id="bib1"><label>1.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Lewis</surname>
<given-names>JE</given-names>
</string-name>, <string-name><surname>Kemp</surname><given-names>ML</given-names></string-name></person-group>. <article-title>Integration of machine learning and genome-scale metabolic modeling identifies multi-omics biomarkers for radiation resistance</article-title>. <source>Nat Commun</source>. <year>2021</year>;<volume>12</volume>:<fpage>2700</fpage>. <pub-id pub-id-type="doi">10.1038/s41467-021-22989-1</pub-id>.<pub-id pub-id-type="pmid">33976213</pub-id>
</mixed-citation></ref><ref id="bib2"><label>2.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Tollenaar</surname>
<given-names>V</given-names>
</string-name>, <string-name><surname>Zekollari</surname><given-names>H</given-names></string-name>, <string-name><surname>Lhermitte</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group>
<article-title>Unexplored Antarctic meteorite collection sites revealed through machine learning</article-title>. <source>Sci Adv</source>. <year>2022</year>;<volume>8</volume>:<fpage>eabj8138</fpage>. <pub-id pub-id-type="doi">10.1126/sciadv.abj8138</pub-id>.<pub-id pub-id-type="pmid">35080966</pub-id>
</mixed-citation></ref><ref id="bib3"><label>3.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Su</surname>
<given-names>Q</given-names>
</string-name>, <string-name><surname>Liu</surname><given-names>Q</given-names></string-name>, <string-name><surname>Lau</surname><given-names>RI</given-names></string-name>, <etal>et al.</etal></person-group>
<article-title>Faecal microbiome-based machine learning for multi-class disease diagnosis</article-title>. <source>Nat Commun</source>. <year>2022</year>;<volume>13</volume>:<fpage>6818</fpage>. <pub-id pub-id-type="doi">10.1038/s41467-022-34405-3</pub-id>.<pub-id pub-id-type="pmid">36357393</pub-id>
</mixed-citation></ref><ref id="bib4"><label>4.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Mart&#x000ed;nez</surname>
<given-names>BA</given-names>
</string-name>, <string-name><surname>Shrotri</surname><given-names>S</given-names></string-name>, <string-name><surname>Kingsmore</surname><given-names>KM</given-names></string-name>, <etal>et al.</etal></person-group>
<article-title>Machine learning reveals distinct gene signature profiles in lesional and nonlesional regions of inflammatory skin diseases</article-title>. <source>Sci Adv</source>. <year>2022</year>;<volume>8</volume>:<fpage>eabn4776</fpage>. <pub-id pub-id-type="doi">10.1126/sciadv.abn4776</pub-id>.<pub-id pub-id-type="pmid">35486723</pub-id>
</mixed-citation></ref><ref id="bib5"><label>5.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Chen</surname>
<given-names>Z</given-names>
</string-name>, <string-name><surname>Ma</surname><given-names>W</given-names></string-name>, <string-name><surname>Li</surname><given-names>Y</given-names></string-name>, <etal>et al.</etal></person-group>
<article-title>Using machine learning to estimate the incidence rate of intimate partner violence</article-title>. <source>Sci Rep</source>. <year>2023</year>;<volume>13</volume>:<fpage>5533</fpage>. <pub-id pub-id-type="doi">10.1038/s41598-023-31846-8</pub-id>.<pub-id pub-id-type="pmid">37015976</pub-id>
</mixed-citation></ref><ref id="bib6"><label>6.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Hall</surname>
<given-names>M</given-names>
</string-name>, <string-name><surname>Frank</surname><given-names>E</given-names></string-name>, <string-name><surname>Holmes</surname><given-names>G</given-names></string-name>, <etal>et al.</etal></person-group>
<article-title>The WEKA data mining software: an update</article-title>. <source>SIGKDD Explor Newsl</source>. <year>2009</year>;<volume>11</volume>:<fpage>10</fpage>&#x02013;<lpage>18</lpage>. <pub-id pub-id-type="doi">10.1145/1656274.1656278</pub-id>.</mixed-citation></ref><ref id="bib7"><label>7.</label><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Thornton</surname>
<given-names>C</given-names>
</string-name>, <string-name><surname>Hutter</surname><given-names>F</given-names></string-name>, <string-name><surname>Hoos</surname><given-names>HH</given-names></string-name>, <etal>et al.</etal></person-group>
<article-title>Auto-WEKA: combined selection and hyperparameter optimization of classification algorithms</article-title>. In: <source>Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</source>. <publisher-name>Association for Computing Machinery</publisher-name>; <year>2013</year>:847&#x02013;55. <pub-id pub-id-type="doi">10.1145/2487575.2487629</pub-id>.</mixed-citation></ref><ref id="bib8"><label>8.</label><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Frank</surname>
<given-names>E</given-names>
</string-name>, <string-name><surname>Hall</surname><given-names>MA</given-names></string-name>, <string-name><surname>Witten</surname><given-names>IH</given-names></string-name></person-group>. <source>The WEKA Workbench. Data Mining: Practical Machine Learning Tools and Techniques</source>. <publisher-name>Morgan Kaufmann</publisher-name>; <year>2016</year>.<ext-link xlink:href="https://www.cs.waikato.ac.nz/ml/weka/book.html" ext-link-type="uri">https://www.cs.waikato.ac.nz/ml/weka/book.html</ext-link></mixed-citation></ref><ref id="bib9"><label>9.</label><mixed-citation publication-type="other">
<person-group person-group-type="author">
<collab>Salesforce</collab>
</person-group>. <article-title>Transmogrifai</article-title>. 2019. <comment><ext-link xlink:href="https://docs.transmogrif.ai/en/stable/" ext-link-type="uri">https://docs.transmogrif.ai/en/stable/</ext-link></comment><year>. Accessed on 20 May 2023</year>.</mixed-citation></ref><ref id="bib10"><label>10.</label><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Urbanowicz</surname>
<given-names>R</given-names>
</string-name>, <string-name><surname>Zhang</surname><given-names>R</given-names></string-name>, <string-name><surname>Cui</surname><given-names>Y</given-names></string-name>, <etal>et al.</etal></person-group>
<article-title>STREAMLINE: a simple, transparent, end-to-end automated machine learning pipeline facilitating data analysis and algorithm comparison</article-title>. In: <person-group person-group-type="editor"><string-name><surname>Trujillo</surname><given-names>L</given-names></string-name>, <string-name><surname>Winkler</surname><given-names>SM</given-names></string-name>, <string-name><surname>Silva</surname><given-names>S</given-names></string-name>, <string-name><surname>Banzhaf</surname><given-names>W</given-names></string-name></person-group>, eds. <source>Genetic Programming Theory and Practice XIX</source>. <publisher-name>Springer Nature</publisher-name>Singapore; <year>2023</year>:<fpage>201</fpage>&#x02013;<lpage>31</lpage>. <pub-id pub-id-type="doi">10.1007/978-981-19-8460-0_9</pub-id>.</mixed-citation></ref><ref id="bib11"><label>11.</label><mixed-citation publication-type="other">
<person-group person-group-type="author">
<collab>Axel</collab>
</person-group>. <comment>AxeldeRomblay/MLBox</comment>. <source>GitHub</source>. <ext-link xlink:href="https://github.com/AxeldeRomblay/MLBox" ext-link-type="uri">https://github.com/AxeldeRomblay/MLBox</ext-link><year>Accessed on 20 May 2023.</year>;</mixed-citation></ref><ref id="bib12"><label>12.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Jin</surname>
<given-names>H</given-names>
</string-name>, <string-name><surname>Chollet</surname><given-names>F</given-names></string-name>, <string-name><surname>Song</surname><given-names>Q</given-names></string-name>, <etal>et al.</etal></person-group>
<article-title>AutoKeras: an AutoML library for deep learning</article-title>. <source>J Mach Learn Res</source>. <year>2023</year>;<volume>24</volume>:<fpage>1</fpage>&#x02013;<lpage>6</lpage>.</mixed-citation></ref><ref id="bib13"><label>13.</label><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Komer</surname>
<given-names>B</given-names>
</string-name>, <string-name><surname>Bergstra</surname><given-names>J</given-names></string-name>, <string-name><surname>Eliasmith</surname><given-names>CH-S</given-names></string-name></person-group>. Hyperopt-Sklearn. In: <person-group person-group-type="editor"><string-name><surname>Hutter</surname><given-names>F</given-names></string-name>, <string-name><surname>Kotthoff</surname><given-names>L</given-names></string-name>, <string-name><surname>Vanschoren</surname><given-names>J</given-names></string-name></person-group>, eds. <source>Automated Machine Learning: Methods, Systems, Challenges</source>. <publisher-name>Springer International Publishing</publisher-name>, Cham; <year>2019</year>:<fpage>97</fpage>&#x02013;<lpage>111</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-030-05318-5_5</pub-id>.</mixed-citation></ref><ref id="bib14"><label>14.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Le</surname>
<given-names>TT</given-names>
</string-name>, <string-name><surname>Fu</surname><given-names>W</given-names></string-name>, <string-name><surname>Moore</surname><given-names>JH</given-names></string-name></person-group>. <article-title>Scaling tree-based automated machine learning to biomedical big data with a feature set selector</article-title>. <source>Bioinformatics</source>. <year>2020</year>;<volume>36</volume>:<fpage>250</fpage>&#x02013;<lpage>6</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btz470</pub-id>.<pub-id pub-id-type="pmid">31165141</pub-id>
</mixed-citation></ref><ref id="bib15"><label>15.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>La&#x000a0;Cava</surname>
<given-names>W</given-names>
</string-name>, <string-name><surname>Williams</surname><given-names>H</given-names></string-name>, <string-name><surname>Fu</surname><given-names>W</given-names></string-name>, <etal>et al.</etal></person-group>
<article-title>Evaluating recommender systems for AI-driven biomedical informatics</article-title>. <source>Bioinformatics</source>. <year>2021</year>;<volume>37</volume>:<fpage>250</fpage>&#x02013;<lpage>6</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btaa698</pub-id>.<pub-id pub-id-type="pmid">32766825</pub-id>
</mixed-citation></ref><ref id="bib16"><label>16.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Feurer</surname>
<given-names>M</given-names>
</string-name>, <string-name><surname>Eggensperger</surname><given-names>K</given-names></string-name>, <string-name><surname>Falkner</surname><given-names>S</given-names></string-name>, <etal>et al.</etal></person-group>
<article-title>Auto-sklearn 2.0: hands-free AutoML via meta-learning</article-title>. <source>J Mach Learn Res</source>. <year>2022</year>;<volume>23</volume>:<fpage>261:11936</fpage>&#x02013;<lpage>96</lpage>.</mixed-citation></ref><ref id="bib17"><label>17.</label><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Akshay</surname>
<given-names>A</given-names>
</string-name>
</person-group>. <article-title>MLme: machine learning made easy</article-title>. <year>2023. Accessed on 20 May 2023</year>. <pub-id pub-id-type="doi">10.48546/WORKFLOWHUB.WORKFLOW.571.1</pub-id>.</mixed-citation></ref><ref id="bib18"><label>18.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Dietrich</surname>
<given-names>S</given-names>
</string-name>, <string-name><surname>Ole&#x0015b;</surname><given-names>M</given-names></string-name>, <string-name><surname>Lu</surname><given-names>J</given-names></string-name>, <etal>et al.</etal></person-group>
<article-title>Drug-perturbation-based stratification of blood cancer</article-title>. <source>J Clin Invest</source>. <year>2018</year>;<volume>128</volume>:<fpage>427</fpage>&#x02013;<lpage>45</lpage>. <pub-id pub-id-type="doi">10.1172/JCI93801</pub-id>.<pub-id pub-id-type="pmid">29227286</pub-id>
</mixed-citation></ref><ref id="bib19"><label>19.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Witten</surname>
<given-names>D</given-names>
</string-name>, <string-name><surname>Tibshirani</surname><given-names>R</given-names></string-name>, <string-name><surname>Gu</surname><given-names>SG</given-names></string-name>, <etal>et al.</etal></person-group>
<article-title>Ultra-high throughput sequencing-based small RNA discovery and discrete statistical biomarker analysis in a collection of cervical tumours and matched controls</article-title>. <source>BMC Biol</source>. <year>2010</year>;<volume>8</volume>:<fpage>58</fpage>. <pub-id pub-id-type="doi">10.1186/1741-7007-8-58</pub-id>.<pub-id pub-id-type="pmid">20459774</pub-id>
</mixed-citation></ref><ref id="bib20"><label>20.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Colaprico</surname>
<given-names>A</given-names>
</string-name>, <string-name><surname>Silva</surname><given-names>TC</given-names></string-name>, <string-name><surname>Olsen</surname><given-names>C</given-names></string-name>, <etal>et al.</etal></person-group>
<article-title>TCGAbiolinks: an R/bioconductor package for integrative analysis of TCGA data</article-title>. <source>Nucleic Acids Res</source>. <year>2016</year>;<volume>44</volume>:<fpage>e71</fpage>. <pub-id pub-id-type="doi">10.1093/nar/gkv1507</pub-id>.<pub-id pub-id-type="pmid">26704973</pub-id>
</mixed-citation></ref><ref id="bib21"><label>21.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Robinson</surname>
<given-names>MD</given-names>
</string-name>, <string-name><surname>Mccarthy</surname><given-names>DJ</given-names></string-name>, <string-name><surname>Smyth</surname><given-names>GK</given-names></string-name></person-group>. <article-title>edgeR: a bioconductor package for differential expression analysis of digital gene expression data</article-title>. <source>Bioinformatics</source>. <year>2010</year>;<volume>26</volume>:<fpage>139</fpage>&#x02013;<lpage>40</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btp616</pub-id>.<pub-id pub-id-type="pmid">19910308</pub-id>
</mixed-citation></ref><ref id="bib22"><label>22.</label><mixed-citation publication-type="book">
<comment>10x Genomics Home page. <ext-link xlink:href="https://www.10xgenomics.com" ext-link-type="uri">https://www.10xgenomics.com</ext-link>. Accessed on 20 May 2023.</comment>
</mixed-citation></ref><ref id="bib23"><label>23.</label><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Dua</surname>
<given-names>D</given-names>
</string-name>, <string-name><surname>Graff</surname><given-names>C</given-names></string-name></person-group>. <source>UCI Machine Learning Repository</source>. <year>2017</year>.<ext-link xlink:href="https://archive.ics.uci.edu/" ext-link-type="uri">https://archive.ics.uci.edu/</ext-link></mixed-citation></ref><ref id="bib24"><label>24.</label><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Her</surname>
<given-names>S</given-names>
</string-name>
</person-group>. <source>Smoking and drinking dataset with body signal</source>. <publisher-name>Kaggle</publisher-name>. Accessed on 20 May 2023. <comment><ext-link xlink:href="https://www.kaggle.com/datasets/sooyoungher/smoking-drinking-dataset" ext-link-type="uri">https://www.kaggle.com/datasets/sooyoungher/smoking-drinking-dataset</ext-link></comment></mixed-citation></ref><ref id="bib25"><label>25.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Xing</surname>
<given-names>S</given-names>
</string-name>, <string-name><surname>Li</surname><given-names>F</given-names></string-name>, <string-name><surname>Zeng</surname><given-names>Z</given-names></string-name>, <etal>et al.</etal></person-group>
<article-title>Tcf1 and Lef1 transcription factors establish CD8+ T cell identity through intrinsic HDAC activity</article-title>. <source>Nat Immunol</source>. <year>2016</year>;<volume>17</volume>:<fpage>695</fpage>&#x02013;<lpage>703</lpage>. <pub-id pub-id-type="doi">10.1038/ni.3456</pub-id>.<pub-id pub-id-type="pmid">27111144</pub-id>
</mixed-citation></ref><ref id="bib26"><label>26.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Zhang</surname>
<given-names>J</given-names>
</string-name>, <string-name><surname>Lyu</surname><given-names>T</given-names></string-name>, <string-name><surname>Cao</surname><given-names>Y</given-names></string-name>, <etal>et al.</etal></person-group>
<article-title>Role of TCF-1 in differentiation, exhaustion, and memory of CD8+ T cells: a review</article-title>. <source>FASEB J</source>. <year>2021</year>;<volume>35</volume>:<fpage>e21549</fpage>. <pub-id pub-id-type="doi">10.1096/fj.202002566r</pub-id><pub-id pub-id-type="pmid">33913198</pub-id>
</mixed-citation></ref><ref id="bib27"><label>27.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Roychoudhuri</surname>
<given-names>R</given-names>
</string-name>, <string-name><surname>Clever</surname><given-names>D</given-names></string-name>, <string-name><surname>Li</surname><given-names>P</given-names></string-name>, <etal>et al.</etal></person-group>
<article-title>BACH2 regulates CD8+ T cell differentiation by controlling access of AP-1 factors to enhancers</article-title>. <source>Nat Immunol</source>. <year>2016</year>;<volume>17</volume>:<fpage>851</fpage>&#x02013;<lpage>60</lpage>. <pub-id pub-id-type="doi">10.1038/ni.3441</pub-id>.<pub-id pub-id-type="pmid">27158840</pub-id>
</mixed-citation></ref><ref id="bib28"><label>28.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Helm</surname>
<given-names>EY</given-names>
</string-name>, <string-name><surname>Zelenka</surname><given-names>T</given-names></string-name>, <string-name><surname>Cismasiu</surname><given-names>VB</given-names></string-name>, <etal>et al.</etal></person-group>
<article-title>Bcl11b sustains multipotency and restricts effector programs of intestinal-resident memory CD8+ T cells</article-title>. <source>Sci Immunol</source>. <year>2023</year>;<volume>8</volume>:<fpage>eabn0484</fpage>. <pub-id pub-id-type="doi">10.1126/sciimmunol.abn0484</pub-id>.<pub-id pub-id-type="pmid">37115913</pub-id>
</mixed-citation></ref><ref id="bib29"><label>29.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Tang</surname>
<given-names>J</given-names>
</string-name>, <string-name><surname>Jia</surname><given-names>X</given-names></string-name>, <string-name><surname>Li</surname><given-names>J</given-names></string-name>, <etal>et al.</etal></person-group>
<article-title>Themis suppresses the effector function of CD8+ T cells in acute viral infection</article-title>. <source>Cell Mol Immunol</source>. <year>2023</year>;<volume>20</volume>:<fpage>512</fpage>&#x02013;<lpage>24</lpage>. <pub-id pub-id-type="doi">10.1038/s41423-023-00997-z</pub-id>.<pub-id pub-id-type="pmid">36977779</pub-id>
</mixed-citation></ref><ref id="bib30"><label>30.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Ancuta</surname>
<given-names>P</given-names>
</string-name>, <string-name><surname>Liu</surname><given-names>K-Y</given-names></string-name>, <string-name><surname>Misra</surname><given-names>V</given-names></string-name>, <etal>et al.</etal></person-group>
<article-title>Transcriptional profiling reveals developmental relationship and distinct biological functions of CD16+ and CD16- monocyte subsets</article-title>. <source>BMC Genomics</source>. <year>2009</year>;<volume>10</volume>:<fpage>403</fpage>. <pub-id pub-id-type="doi">10.1186/1471-2164-10-403</pub-id>.<pub-id pub-id-type="pmid">19712453</pub-id>
</mixed-citation></ref><ref id="bib31"><label>31.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Hu</surname>
<given-names>Y</given-names>
</string-name>, <string-name><surname>Hu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Xiao</surname><given-names>Y</given-names></string-name>, <etal>et al.</etal></person-group>
<article-title>Genetic landscape and autoimmunity of monocytes in developing Vogt&#x02013;Koyanagi&#x02013;Harada disease</article-title>. <source>Proc Natl Acad Sci USA</source>. <year>2020</year>;<volume>117</volume>:<fpage>25712</fpage>&#x02013;<lpage>21</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.2002476117</pub-id>.<pub-id pub-id-type="pmid">32989127</pub-id>
</mixed-citation></ref><ref id="bib32"><label>32.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Affandi</surname>
<given-names>AJ</given-names>
</string-name>, <string-name><surname>Olesek</surname><given-names>K</given-names></string-name>, <string-name><surname>Grabowska</surname><given-names>J</given-names></string-name>, <etal>et al.</etal></person-group>
<article-title>CD169 defines activated CD14+ monocytes with enhanced CD8+ T cell activation capacity</article-title>. <source>Front Immunol</source>. <year>2021</year>;<volume>12</volume>. <pub-id pub-id-type="doi">10.3389/fimmu.2021.697840</pub-id>.</mixed-citation></ref><ref id="bib33"><label>33.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Combes</surname>
<given-names>TW</given-names>
</string-name>, <string-name><surname>Orsenigo</surname><given-names>F</given-names></string-name>, <string-name><surname>Stewart</surname><given-names>A</given-names></string-name>, <etal>et al.</etal></person-group>
<article-title>CSF1R defines the mononuclear phagocyte system lineage in human blood in health and COVID-19</article-title>. <source>Immunother Adv</source>. <year>2021</year>;<volume>1</volume>:<fpage>ltab003</fpage>. <pub-id pub-id-type="doi">10.1093/immadv/ltab003</pub-id>.<pub-id pub-id-type="pmid">35915730</pub-id>
</mixed-citation></ref><ref id="bib34"><label>34.</label><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Hossain</surname>
<given-names>S</given-names>
</string-name>
</person-group>. <article-title>Visualization of bioinformatics data with Dash Bio</article-title>. <source>In: Proceedings of the 18th Python in Science Conference.</source><year>2019</year>:<fpage>126</fpage>&#x02013;<lpage>33</lpage>. <pub-id pub-id-type="doi">10.25080/Majora-7ddc1dd1-012</pub-id>.</mixed-citation></ref><ref id="bib35"><label>35.</label><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>van&#x000a0;Rossum</surname>
<given-names>G</given-names>
</string-name>
</person-group>. <article-title>Python Reference Manual</article-title>. <year>1995</year>Department of Computer Science. CWI.<comment>ISBN:978-1-4414-1269-0</comment></mixed-citation></ref><ref id="bib36"><label>36.</label><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Inc</surname>
<given-names>PT</given-names>
</string-name>
</person-group>. <article-title>Collaborative data science</article-title>. 2015. <comment><ext-link xlink:href="https://plot.ly" ext-link-type="uri">https://plot.ly</ext-link></comment>. Accessed on 20 May 2023.</mixed-citation></ref><ref id="bib37"><label>37.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Hunter</surname>
<given-names>JD</given-names>
</string-name>
</person-group>. <article-title>Matplotlib: a 2D graphics environment</article-title>. <source>Comput Sci Eng</source>. <year>2007</year>;<volume>9</volume>:<fpage>90</fpage>&#x02013;<lpage>5</lpage>. <pub-id pub-id-type="doi">10.1109/MCSE.2007.55</pub-id></mixed-citation></ref><ref id="bib38"><label>38.</label><mixed-citation publication-type="book">
<person-group person-group-type="author">
<collab>Bokeh Development Team</collab>
</person-group>. <source>Bokeh: Python Library for Interactive Visualization</source>. <year>2018</year>.<ext-link xlink:href="https://docs.bokeh.org/" ext-link-type="uri">https://docs.bokeh.org/</ext-link></mixed-citation></ref><ref id="bib39"><label>39.</label><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>McKinney</surname>
<given-names>W</given-names>
</string-name>
</person-group>. <article-title>Data structures for statistical computing in Python</article-title>. <source>In: Proceedings of the 9th Python in Science Conference.</source><year>2010</year>:<fpage>56</fpage>&#x02013;<lpage>61</lpage>. <pub-id pub-id-type="doi">10.25080/Majora-92bf1922-00a</pub-id>.</mixed-citation></ref><ref id="bib40"><label>40.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Harris</surname>
<given-names>CR</given-names>
</string-name>, <string-name><surname>Millman</surname><given-names>KJ</given-names></string-name>, <string-name><surname>Van&#x000a0;Der&#x000a0;Walt</surname><given-names>SJ</given-names></string-name></person-group>. <article-title>Array programming with NumPy</article-title>. <source>Nature</source>. <year>2020</year>;<volume>585</volume>:<fpage>357</fpage>&#x02013;<lpage>62</lpage>. <pub-id pub-id-type="doi">10.1038/s41586-020-2649-2</pub-id>.<pub-id pub-id-type="pmid">32939066</pub-id>
</mixed-citation></ref><ref id="bib41"><label>41.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Pedregosa</surname>
<given-names>F</given-names>
</string-name>, <string-name><surname>Varoquaux</surname><given-names>G</given-names></string-name>, <string-name><surname>Gramfort</surname><given-names>A</given-names></string-name>, <etal>et al.</etal></person-group>
<article-title>Scikit-learn: machine learning in Python</article-title>. <source>J Mach Learn Res</source>. <year>2011</year>;<volume>12</volume>:<fpage>2825</fpage>&#x02013;<lpage>30</lpage>.</mixed-citation></ref><ref id="bib42"><label>42.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Lema&#x00131;tre</surname>
<given-names>G</given-names>
</string-name>, <string-name><surname>Nogueira</surname><given-names>F</given-names></string-name></person-group>. <article-title>Imbalanced-learn: a Python toolbox to tackle the curse of imbalanced datasets in machine learning</article-title>.<year>2017</year>; <source>Journal of Machine Learning Research</source>. <volume>18</volume>(<issue>17</issue>):<fpage>1</fpage>&#x02013;<lpage>5</lpage>. <ext-link xlink:href="https://jmlr.org/papers/v18/16-365.html" ext-link-type="uri">https://jmlr.org/papers/v18/16-365.html</ext-link></mixed-citation></ref><ref id="bib43"><label>43.</label><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Akshay</surname>
<given-names>A</given-names>
</string-name>, <string-name><surname>Katoch</surname><given-names>M</given-names></string-name>, <string-name><surname>Shekarchizadeh</surname><given-names>N</given-names></string-name>, <etal>et al.</etal></person-group>
<article-title>Supporting data for &#x0201c;Machine Learning Made Easy (MLme): A Comprehensive Toolkit for Machine Learning-Driven Data Analysis.&#x0201d;</article-title>. <source>Zenodo repository.</source><year>2023.</year>; <pub-id pub-id-type="doi">10.5281/zenodo.8073635</pub-id>.</mixed-citation></ref><ref id="bib44"><label>44.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Akshay</surname>
<given-names>A</given-names>
</string-name>, <string-name><surname>Katoch</surname><given-names>M</given-names></string-name>, <string-name><surname>Shekarchizadeh</surname><given-names>N</given-names></string-name>, <etal>et al.</etal></person-group>
<article-title>Supporting data for &#x0201c;Machine Learning Made Easy (MLme): A Comprehensive Toolkit for Machine Learning&#x02013;Driven Data Analysis.&#x0201d;</article-title>. <source>GigaScience Database.</source><year>2023</year>. <pub-id pub-id-type="doi">10.5524/102486</pub-id>.</mixed-citation></ref></ref-list></back></article>