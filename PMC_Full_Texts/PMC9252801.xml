<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd"> 
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-journalpublishing1.dtd?><?SourceDTD.Version 1.2?><?ConverterInfo.XSLTName jats2jats3.xsl?><?ConverterInfo.Version 1?><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Nucleic Acids Res</journal-id><journal-id journal-id-type="iso-abbrev">Nucleic Acids Res</journal-id><journal-id journal-id-type="publisher-id">nar</journal-id><journal-title-group><journal-title>Nucleic Acids Research</journal-title></journal-title-group><issn pub-type="ppub">0305-1048</issn><issn pub-type="epub">1362-4962</issn><publisher><publisher-name>Oxford University Press</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">9252801</article-id><article-id pub-id-type="pmid">35489069</article-id><article-id pub-id-type="doi">10.1093/nar/gkac278</article-id><article-id pub-id-type="publisher-id">gkac278</article-id><article-categories><subj-group subj-group-type="category-taxonomy-collection"><subject>AcademicSubjects/SCI00010</subject></subj-group><subj-group subj-group-type="heading"><subject>Web Server Issue</subject></subj-group></article-categories><title-group><article-title>DeepLoc 2.0: multi-label subcellular localization prediction using protein language models</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Thumuluri</surname><given-names>Vineet</given-names></name><aff>
<institution>Indian Institute of Technology Madras</institution>, Chennai 600036, <country country="IN">India</country></aff><xref rid="FN1" ref-type="author-notes"/></contrib><contrib contrib-type="author"><name><surname>Almagro&#x000a0;Armenteros</surname><given-names>Jos&#x000e9; Juan</given-names></name><aff>
<institution>Novo Nordisk Foundation Center for Protein Research, Faculty of Health and Medical Sciences, University of Copenhagen</institution>, Copenhagen 2200, <country country="DK">Denmark</country></aff><aff>
<institution>Department of Genetics, Stanford University School of Medicine</institution>, Stanford 94305, CA, <country country="US">USA</country></aff><xref rid="FN1" ref-type="author-notes"/></contrib><contrib contrib-type="author"><name><surname>Johansen</surname><given-names>Alexander&#x000a0;Rosenberg</given-names></name><aff>
<institution>Department of Computer Science, Stanford University</institution>, Stanford 94305, CA, <country country="US">USA</country></aff><aff>
<institution>Department of Genetics, Stanford University School of Medicine</institution>, Stanford 94305, CA, <country country="US">USA</country></aff></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-9412-9643</contrib-id><name><surname>Nielsen</surname><given-names>Henrik</given-names></name><!--henni@dtu.dk--><aff>
<institution>Section&#x000a0;for Bioinformatics, Department of Health Technology, Technical University of Denmark</institution>, Kongens Lyngby 2800, <country country="DK">Denmark</country></aff><xref rid="FN2" ref-type="author-notes"/><xref rid="COR1" ref-type="corresp"/></contrib><contrib contrib-type="author"><name><surname>Winther</surname><given-names>Ole</given-names></name><aff>
<institution>Center for Genomic Medicine, Rigshospitalet (Copenhagen University Hospital)</institution>, Copenhagen 2100, <country country="DK">Denmark</country></aff><aff>
<institution>Department of Biology, Bioinformatics Centre, University of Copenhagen</institution>, Copenhagen 2200, <country country="DK">Denmark</country></aff><aff>
<institution>Section&#x000a0;for Cognitive Systems, Department of Applied Mathematics and Computer Science, Technical University of Denmark</institution>, Kongens Lyngby 2800, <country country="DK">Denmark</country></aff><xref rid="FN2" ref-type="author-notes"/></contrib></contrib-group><author-notes><corresp id="COR1">To whom correspondence should be addressed.&#x000a0;Email: <email>henni@dtu.dk</email></corresp><fn id="FN1"><p>The authors wish it to be known that, in their opinion, these authors should be regarded as Joint First Authors.</p></fn><fn id="FN2"><p>The authors wish it to be known that, in their opinion, these authors should be regarded as&#x000a0;Joint Last Authors.</p></fn></author-notes><pub-date pub-type="collection"><day>05</day><month>7</month><year>2022</year></pub-date><pub-date pub-type="epub" iso-8601-date="2022-04-30"><day>30</day><month>4</month><year>2022</year></pub-date><pub-date pub-type="pmc-release"><day>30</day><month>4</month><year>2022</year></pub-date><volume>50</volume><issue>W1</issue><fpage>W228</fpage><lpage>W234</lpage><history><date date-type="accepted"><day>19</day><month>4</month><year>2022</year></date><date date-type="rev-recd"><day>07</day><month>4</month><year>2022</year></date><date date-type="received"><day>05</day><month>2</month><year>2022</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2022. Published by Oxford University Press on behalf of Nucleic Acids Research.</copyright-statement><copyright-year>2022</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><self-uri xlink:href="gkac278.pdf"/><abstract><title>Abstract</title><p>The prediction of protein subcellular localization is of great relevance for proteomics research. Here, we propose an update to the popular tool DeepLoc with multi-localization prediction and improvements in both performance and interpretability. For training and validation, we curate eukaryotic and human multi-location protein datasets with stringent homology partitioning and enriched with sorting signal information compiled from the literature. We achieve state-of-the-art performance in DeepLoc 2.0 by using a pre-trained protein language model. It has the further advantage that it uses sequence input rather than relying on slower protein profiles. We provide two means of better interpretability: an attention output along the sequence and highly accurate prediction of nine different types of protein sorting signals. We find that the attention output correlates well with the position of sorting signals. The webserver is available at services.healthtech.dtu.dk/service.php?DeepLoc-2.0.</p></abstract><abstract abstract-type="graphical"><title>Graphical Abstract</title><p>
<fig position="float" id="ga1"><label>Graphical Abstract</label><caption><p>DeepLoc 2.0 uses a transformer-based protein language model to predict multi-label subcellular localization and provides interpretability via the attention and sorting signal prediction.</p></caption><graphic xlink:href="gkac278figgra1" position="float"/></fig>
</p></abstract><funding-group><award-group award-type="grant"><funding-source>
<institution-wrap><institution>Novo Nordisk Fonden</institution><institution-id institution-id-type="DOI">10.13039/501100009708</institution-id></institution-wrap>
</funding-source><award-id>NNF20OC0062606</award-id></award-group><award-group award-type="grant"><funding-source>
<institution-wrap><institution>Danish National Research Foundation</institution><institution-id institution-id-type="DOI">10.13039/501100001732</institution-id></institution-wrap>
</funding-source><award-id>P1</award-id></award-group></funding-group><counts><page-count count="7"/></counts></article-meta></front><body><sec sec-type="intro" id="SEC1"><title>INTRODUCTION</title><p>Identifying protein localization in different cellular compartments plays a key role in functional annotation. It can also aid in identifying drug targets (<xref rid="B1" ref-type="bibr">1</xref>), and understanding diseases linked to aberrant subcellular localization (<xref rid="B2" ref-type="bibr">2</xref>,<xref rid="B3" ref-type="bibr">3</xref>). Some proteins are known to localize in multiple cellular compartments (<xref rid="B4" ref-type="bibr">4&#x02013;6</xref>). Several biological mechanisms have been identified to explain the localization process, which involves short sequences known as sorting signals (<xref rid="B7" ref-type="bibr">7&#x02013;10</xref>).</p><p>Several machine learning-based methods exist for predicting subcellular localization. They can vary in the output prediction, i.e. single versus multi-location, or in the input features. YLoc+ (<xref rid="B11" ref-type="bibr">11</xref>) predicts multiple locations using biological features such as sorting signals, PROSITE (<ext-link xlink:href="http://prosite.expasy.org/" ext-link-type="uri">http://prosite.expasy.org/</ext-link>) patterns and optionally Gene Ontology (GO) terms from a database. Fuel-mLoc (<xref rid="B12" ref-type="bibr">12</xref>) on the other hand uses only GO terms from a custom database called ProSeq-GO to predict multiple locations for a variety of organisms. DeepLoc 1.0 (<xref rid="B13" ref-type="bibr">13</xref>) and LAProtT5 (<xref rid="B14" ref-type="bibr">14</xref>) predict a single location based on features extracted from only the sequence (sequence profiles in the case of DeepLoc) using deep learning models.</p><p>DeepLoc 1.0 uses a three stage deep learning approach for sequence classification. First, a feature representation for each amino acid in the sequence is generated. Then an attention-based pooling stage produces a single representation for the whole sequence. Finally, the prediction stage uses a classifier to output the subcellular labels.</p><p>DeepLoc 2.0 uses the same template while updating important aspects:</p><list list-type="bullet"><list-item><p>Dataset: We curate large strict homology partitioned datasets of eukaryotic (<xref rid="B15" ref-type="bibr">15</xref>) and human proteins (<xref rid="B16" ref-type="bibr">16</xref>) for training and independent testing. We also compiled a dataset with experimentally verified annotation of nine types of sorting signals.</p></list-item><list-item><p>Feature representation: We use a pre-trained protein transformer language model.</p></list-item><list-item><p>An attention plot visualizes what part of the input the model uses for its predictions. Thus pointing to regions responsible for localization and potentially containing sorting signals. We use supervised learning with regularization to improve the interpretability of the attention plot.</p></list-item><list-item><p>Prediction stage: We predict multiple labels for both the ten class subcellular localization and nine class sorting signals tasks.</p></list-item></list></sec><sec id="SEC2"><title>WEBSERVER</title><p>The webserver is free and open to all and there is no login requirement. It takes in a maximum of 500 input sequences in the FASTA format. The model&#x02019;s attention is shown in a figure&#x000a0;when the long result format is toggled. Regions with high attention values are used by the model for its prediction and they are indicative of the presence of sorting signals. Once the job is submitted, it enters a queue and a waiting page is shown. The users can provide an email address to be notified of the results or the page automatically redirects when the results become available. An example prediction page is shown in Figure&#x000a0;<xref rid="F1" ref-type="fig">1</xref>. Note that our model provides an output regardless of the input sequence. However, it is very difficult for us to judge whether a prediction is sensible if it is not a eukaryotic protein. Detailed estimate of prediction times is provided in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>.</p><fig position="float" id="F1"><label>Figure 1.</label><caption><p>An example snippet from the results page on the webserver. The prediction summary is available for download as a comma-separated file (CSV) at the top which consists of the predicted subcellular localization and sorting signals. The image or attention values of each plot can be separately downloaded. All the predicted subcellular localization and sorting signal labels are listed, along with the prediction score table. The predicted localizations in the table are highlighted in green. If no score crosses the threshold, the label closest to the threshold is chosen. High values in the logo-like plot signify important regions in the sequence for localization prediction that may correspond to sorting signals. This is meant to serve as a guideline and specialized tools such as SignalP or TargetP can be used for a more detailed and accurate analysis of these signals.</p></caption><graphic xlink:href="gkac278fig1" position="float"/></fig></sec><sec id="SEC3"><title>DATA</title><p>We curate three datasets: two datasets with subcellular localization labels for cross-validation and independent validation, respectively, and a third dataset consisting of sorting signal labels, both the presence and location within the sequence, which is a part of the cross-validation dataset. Detailed statistics regarding the distribution of subcellular localization labels in the datasets are provided in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S1</xref> (Figure&#x000a0;inspired by (<xref rid="B17" ref-type="bibr">17</xref>)).</p><sec id="SEC3-1"><title>SwissProt localization dataset</title><p>The protein data were extracted from the UniProt database release 2021_03 (<xref rid="B15" ref-type="bibr">15</xref>). The protein sequences and localization annotations were then filtered using the following criteria: eukaryotic, not fragments (these could have N-terminal or C-terminal sorting signals missing), encoded in the nucleus, &#x0003e;40 amino acids and experimentally annotated (ECO:0000269) subcellular localizations. These proteins can be categorized into one or multiple of these ten locations: Cytoplasm, Nucleus, Extracellular, Cell membrane, Mitochondrion, Plastid, Endoplasmic reticulum, Lysosome/Vacuole, Golgi apparatus, Peroxisome. The details of the sublocation mapping and the number of proteins in each category are provided in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S2</xref>. This dataset is used for 5-fold cross-validation after homology-based partitioning (<xref rid="sup1" ref-type="supplementary-material">Supplementary Section S1</xref>).</p></sec><sec id="SEC3-2"><title>Human protein atlas</title><p>The Human Protein Atlas (HPA) project provides subcellular localization of human proteins using confocal microscopy (<xref rid="B16" ref-type="bibr">16</xref>). The annotations are provided with four reliability labels: Enhanced, Supported, Approved, and Uncertain, based on various criteria such as antibody validation and experimental evidence in the literature. We consider only Enhanced and Supported annotations for our independent test set since these are the most reliable labels. This dataset is ensured to not have any sequences with a &#x0003e;30% global sequence identity with the Swissprot Localization dataset described above and is used for independent validation.</p></sec><sec id="SEC3-3"><title>Sorting signals</title><p>Annotated sorting signals that are experimentally verified were mainly compiled from the literature. <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S3</xref> is a list of signals and their sources. We excluded proteins that were not present in our constructed SwissProt Localization Dataset. This dataset is used in the cross-validation procedure.</p></sec></sec><sec id="SEC4"><title>DEEPLOC 2.0 OVERVIEW</title><p>As shown in Figure&#x000a0;<xref rid="F2" ref-type="fig">2</xref>, the method can be broadly divided into three stages, each of which is briefly described below. More detailed information can be found in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S2</xref>.</p><fig position="float" id="F2"><label>Figure 2.</label><caption><p>DeepLoc 2.0 uses a transformer-based protein language model to encode the input amino acid sequence. Then using an interpretable attention pooling mechanism a sequence representation is produced. The two prediction heads then utilize this representation to predict multiple labels for both the 10-type subcellular localization and 9-type sorting signal prediction tasks. Source of cell diagram: <ext-link xlink:href="https://commons.wikimedia.org/wiki/File:Simple_diagram_of_plant_cell_(blank).svg" ext-link-type="uri">https://commons.wikimedia.org/wiki/File:Simple_diagram_of_plant_cell_(blank).svg</ext-link>, attribution:&#x000a0;domdomegg, CC BY 4.0 &#x0003c;<ext-link xlink:href="https://creativecommons.org/licenses/by/4.0" ext-link-type="uri">https://creativecommons.org/licenses/by/4.0</ext-link>&#x0003e;, via Wikimedia Commons.</p></caption><graphic xlink:href="gkac278fig2" position="float"/></fig><sec id="SEC4-1"><title>Per-token representation using a transformer model</title><p>We utilize transformer-based language models (<xref rid="B18" ref-type="bibr">18</xref>) that have been successfully applied to the protein domain due to the abundance of unlabelled raw sequence data. They are trained in a self-supervised fashion on a large corpus, such as the UniRef50 database (<xref rid="B19" ref-type="bibr">19</xref>), using the masked language-modelling objective (<xref rid="B20" ref-type="bibr">20</xref>). The transformer is a deep learning method that uses multiple layers of the self-attention mechanism to produce representations that have been found to encode contact maps, taxonomy, and biophysical characteristics in their distributed representations (<xref rid="B21" ref-type="bibr">21&#x02013;27</xref>). We evaluated three publicly available transformer models, the 12-layer ESM (Evolutionary Scale Modelling, (<xref rid="B21" ref-type="bibr">21</xref>)) model with 84M parameters, the 33-layer ESM model with 650M parameters (<xref rid="B23" ref-type="bibr">23</xref>) and the 3B parameter ProtT5-XL-UniRef50 model (<xref rid="B24" ref-type="bibr">24</xref>), referred to as ESM12, ESM1b and ProtT5, respectively, throughout the rest of the manuscript. The output of the language model is a vector representation for each residue (token) in the input sequence.</p></sec><sec id="SEC4-2"><title>Sequence representation using attention pooling</title><p>The per-token representations are combined using attention (<xref rid="B28" ref-type="bibr">28</xref>): First, a scalar score is computed for each token by taking the dot-product of the representation with a learnable vector. The learnable vector is tuned using supervised learning by using both the subcellular localization labels as well as the sequence annotation of the sorting signals. We smooth the scalar scores along the sequence by applying a 1d Gaussian filter of width 5, clipped at one standard deviation, to account for signals being present in a contiguous set of residues. The attention weights over the sequence are then computed using the softmax function on the smoothed scores so that they sum to 1. The output representation is the attention weighted sum of the token representations. This attention pooled representation vector is used as input to the prediction stage. The attention weights, visualized in the webserver, and the prediction of the sorting signals provide a better understanding of the predictions of the model.</p></sec><sec id="SEC4-3"><title>Multi-label localization and signal type prediction</title><p>The prediction stage consists of two multi-layer perceptron (MLP) classifier heads. The first head is trained along with the learnable vector from the attention step for the ten-class multi-label subcellular localization task. A second head is trained after freezing the rest of the parameters for the nine-class sorting signal prediction task. We found that optimizing for both tasks simultaneously proved to be difficult, hence we trained them one after another. These classifiers output a probability for each label. A weighted focal loss (<xref rid="B29" ref-type="bibr">29</xref>) is used for each label independently and then the losses for all labels are averaged so that they are jointly optimized. A threshold for each output label is computed by maximizing Matthew&#x02019;s Correlation Coefficient (MCC) (<xref rid="B30" ref-type="bibr">30</xref>) on the training data. Accuracy-based metrics are susceptible to imbalance (<xref rid="B31" ref-type="bibr">31</xref>) that the MCC metric can handle better. Both these predictions are provided as outputs.</p></sec></sec><sec sec-type="results" id="SEC5"><title>RESULTS AND DISCUSSION</title><p>We chose YLoc+, DeepLoc 1.0, Fuel-mLoc, and LAProtT5 tools for comparison. These tools have public webservers or easily available local implementations. Since the outputs are different for each of the methods, we map the locations to the ten classes used in this work. We also reduce the Fuel-mLoc database by about 2% to remove close homologs to the test set for a fair comparison. The details of the mappings are provided in <xref rid="sup1" ref-type="supplementary-material">Supplementary Tables S4 and S5</xref>, modifications to the methods are described in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S3</xref>. Additionally, in <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S4</xref>, we provide insights from our experiments that the reader might find useful.</p><sec id="SEC5-1"><title>Multi-label classification results</title><p>On the cross-validation dataset (Table&#x000a0;<xref rid="tbl1" ref-type="table">1</xref>), DeepLoc 2.0 has the highest scores in all metrics. Details of the model performance based on the kingdom of the protein are provided in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S10</xref>.</p><table-wrap position="float" id="tbl1"><label>Table 1.</label><caption><p>Results on the SwissProt CV dataset</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1">Counts</th><th rowspan="1" colspan="1">DeepLoc 1.0 <sup>&#x003b2;</sup></th><th rowspan="1" colspan="1">YLoc+ <sup>&#x003b1;</sup></th><th colspan="2" align="center" rowspan="1">DeepLoc 2.0</th></tr><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1">ESM1b</th><th rowspan="1" colspan="1">ProtT5</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">Type</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Single</td><td rowspan="1" colspan="1">Multi</td><td rowspan="1" colspan="1">Multi</td><td rowspan="1" colspan="1">Multi</td></tr><tr><td rowspan="1" colspan="1">Pred. Num. Labels (Actual: 1.27)</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">1.00 &#x000b1; 0.00</td><td rowspan="1" colspan="1">1.57 &#x000b1; 0.02</td><td rowspan="1" colspan="1">1.27 &#x000b1; 0.02</td><td rowspan="1" colspan="1">1.26 &#x000b1; 0.02</td></tr><tr><td rowspan="1" colspan="1">Accuracy</td><td rowspan="1" colspan="1">28303</td><td rowspan="1" colspan="1">0.48 &#x000b1; 0.01</td><td rowspan="1" colspan="1">0.32 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.53 &#x000b1; 0.02</td><td rowspan="1" colspan="1">
<bold>0.55 &#x000b1; 0.02</bold>
</td></tr><tr><td rowspan="1" colspan="1">Jaccard</td><td rowspan="1" colspan="1">28303</td><td rowspan="1" colspan="1">0.56 &#x000b1; 0.01</td><td rowspan="1" colspan="1">0.50 &#x000b1; 0.01</td><td rowspan="1" colspan="1">0.68 &#x000b1; 0.01</td><td rowspan="1" colspan="1">
<bold>0.69 &#x000b1; 0.01</bold>
</td></tr><tr><td rowspan="1" colspan="1">MicroF1</td><td rowspan="1" colspan="1">28303</td><td rowspan="1" colspan="1">0.58 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.56 &#x000b1; 0.01</td><td rowspan="1" colspan="1">0.72 &#x000b1; 0.01</td><td rowspan="1" colspan="1">
<bold>0.73 &#x000b1; 0.01</bold>
</td></tr><tr><td rowspan="1" colspan="1">MacroF1</td><td rowspan="1" colspan="1">28303</td><td rowspan="1" colspan="1">0.47 &#x000b1; 0.01</td><td rowspan="1" colspan="1">0.42 &#x000b1; 0.01</td><td rowspan="1" colspan="1">0.64 &#x000b1; 0.01</td><td rowspan="1" colspan="1">
<bold>0.66 &#x000b1; 0.01</bold>
</td></tr><tr><td colspan="5" align="left" rowspan="1">MCC per location (&#x02191; is better)</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Cytoplasm</td><td rowspan="1" colspan="1">9870</td><td rowspan="1" colspan="1">0.45 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.38 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.61 &#x000b1; 0.01</td><td rowspan="1" colspan="1">
<bold>0.62 &#x000b1; 0.01</bold>
</td></tr><tr><td rowspan="1" colspan="1">Nucleus</td><td rowspan="1" colspan="1">9720</td><td rowspan="1" colspan="1">0.46 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.42 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.66 &#x000b1; 0.02</td><td rowspan="1" colspan="1">
<bold>0.69 &#x000b1; 0.01</bold>
</td></tr><tr><td rowspan="1" colspan="1">Extracellular</td><td rowspan="1" colspan="1">3301</td><td rowspan="1" colspan="1">0.78 &#x000b1; 0.05</td><td rowspan="1" colspan="1">0.61 &#x000b1; 0.05</td><td rowspan="1" colspan="1">
<bold>0.85 &#x000b1; 0.03</bold>
</td><td rowspan="1" colspan="1">
<bold>0.85 &#x000b1; 0.04</bold>
</td></tr><tr><td rowspan="1" colspan="1">Cell membrane</td><td rowspan="1" colspan="1">4187</td><td rowspan="1" colspan="1">0.53 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.44 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.64 &#x000b1; 0.01</td><td rowspan="1" colspan="1">
<bold>0.66 &#x000b1; 0.01</bold>
</td></tr><tr><td rowspan="1" colspan="1">Mitochondrion</td><td rowspan="1" colspan="1">2590</td><td rowspan="1" colspan="1">0.58 &#x000b1; 0.04</td><td rowspan="1" colspan="1">0.47 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.73 &#x000b1; 0.03</td><td rowspan="1" colspan="1">
<bold>0.76 &#x000b1; 0.02</bold>
</td></tr><tr><td rowspan="1" colspan="1">Plastid</td><td rowspan="1" colspan="1">1047</td><td rowspan="1" colspan="1">0.69 &#x000b1; 0.04</td><td rowspan="1" colspan="1">0.72 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.88 &#x000b1; 0.01</td><td rowspan="1" colspan="1">
<bold>0.90 &#x000b1; 0.01</bold>
</td></tr><tr><td rowspan="1" colspan="1">Endoplasmic reticulum</td><td rowspan="1" colspan="1">2180</td><td rowspan="1" colspan="1">0.32 &#x000b1; 0.04</td><td rowspan="1" colspan="1">0.17 &#x000b1; 0.04</td><td rowspan="1" colspan="1">0.52 &#x000b1; 0.01</td><td rowspan="1" colspan="1">
<bold>0.56 &#x000b1; 0.03</bold>
</td></tr><tr><td rowspan="1" colspan="1">Lysosome/Vacuole</td><td rowspan="1" colspan="1">1496</td><td rowspan="1" colspan="1">0.06 &#x000b1; 0.05</td><td rowspan="1" colspan="1">0.07 &#x000b1; 0.03</td><td rowspan="1" colspan="1">0.24 &#x000b1; 0.03</td><td rowspan="1" colspan="1">
<bold>0.28 &#x000b1; 0.04</bold>
</td></tr><tr><td rowspan="1" colspan="1">Golgi apparatus</td><td rowspan="1" colspan="1">1279</td><td rowspan="1" colspan="1">0.20 &#x000b1; 0.04</td><td rowspan="1" colspan="1">0.11 &#x000b1; 0.04</td><td rowspan="1" colspan="1">
<bold>0.36 &#x000b1; 0.06</bold>
</td><td rowspan="1" colspan="1">0.34 &#x000b1; 0.05</td></tr><tr><td rowspan="1" colspan="1">Peroxisome</td><td rowspan="1" colspan="1">304</td><td rowspan="1" colspan="1">0.15 &#x000b1; 0.04</td><td rowspan="1" colspan="1">0.05 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.48 &#x000b1; 0.05</td><td rowspan="1" colspan="1">
<bold>0.56 &#x000b1; 0.08</bold>
</td></tr></tbody></table><table-wrap-foot><fn id="T1TFN1"><p>
<bold>Bold</bold> values indicate the best score</p></fn><fn id="T1TFN2"><p>
<sup>&#x003b1;</sup> = GO-terms were not used</p></fn><fn id="T1TFN3"><p>
<sup>&#x003b2;</sup> = Retrained on this dataset</p></fn></table-wrap-foot></table-wrap><p>From Table&#x000a0;<xref rid="tbl2" ref-type="table">2</xref>, on the independent HPA benchmark, we find that DeepLoc 2.0 outperforms other tools on several metrics except for the accuracy and MCC for nucleus which are highest for the LAProtT5 method. The MCC for endoplasmic reticulum is highest for the DeepLoc 1.0 method. DeepLoc 2.0 predicts a realistic average number of labels per protein compared to other methods. <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S6</xref> contains the results for all the methods and variants we benchmarked on this dataset. <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S7</xref> contains a threshold-independent comparison using the Area under the ROC (AUC) metric for methods which also output a prediction score.</p><table-wrap position="float" id="tbl2"><label>Table 2.</label><caption><p>Results on the HPA independent test set</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1">Count</th><th rowspan="1" colspan="1">YLoc+</th><th rowspan="1" colspan="1">DeepLoc 1.0 <sup>&#x003b2;</sup></th><th rowspan="1" colspan="1">Fuel-mLoc</th><th rowspan="1" colspan="1">LAProtT5</th><th colspan="2" align="center" rowspan="1">DeepLoc 2.0</th></tr><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1">Animal<sup>&#x003b1;</sup></th><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1">Euk <sup>&#x003b3;, &#x003b8;</sup></th><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1">ESM1b</th><th rowspan="1" colspan="1">ProtT5</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">Type</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Multi</td><td rowspan="1" colspan="1">Single</td><td rowspan="1" colspan="1">Multi</td><td rowspan="1" colspan="1">Single</td><td rowspan="1" colspan="1">Multi</td><td rowspan="1" colspan="1">Multi</td></tr><tr><td rowspan="1" colspan="1">Pred. Num. Labels (Actual: 1.22)</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">1.44</td><td rowspan="1" colspan="1">0.89</td><td rowspan="1" colspan="1">1.00</td><td rowspan="1" colspan="1">0.94</td><td rowspan="1" colspan="1">1.15</td><td rowspan="1" colspan="1">1.21</td></tr><tr><td rowspan="1" colspan="1">Accuracy</td><td rowspan="1" colspan="1">1717</td><td rowspan="1" colspan="1">0.23</td><td rowspan="1" colspan="1">0.37</td><td rowspan="1" colspan="1">0.38</td><td rowspan="1" colspan="1">
<bold>0.45</bold>
</td><td rowspan="1" colspan="1">0.34</td><td rowspan="1" colspan="1">0.39</td></tr><tr><td rowspan="1" colspan="1">Jaccard</td><td rowspan="1" colspan="1">1717</td><td rowspan="1" colspan="1">0.41</td><td rowspan="1" colspan="1">0.42</td><td rowspan="1" colspan="1">0.46</td><td rowspan="1" colspan="1">0.52</td><td rowspan="1" colspan="1">0.48</td><td rowspan="1" colspan="1">
<bold>0.53</bold>
</td></tr><tr><td rowspan="1" colspan="1">MicroF1</td><td rowspan="1" colspan="1">1717</td><td rowspan="1" colspan="1">0.51</td><td rowspan="1" colspan="1">0.46</td><td rowspan="1" colspan="1">0.52</td><td rowspan="1" colspan="1">0.56</td><td rowspan="1" colspan="1">0.57</td><td rowspan="1" colspan="1">
<bold>0.60</bold>
</td></tr><tr><td rowspan="1" colspan="1">MacroF1</td><td rowspan="1" colspan="1">1717</td><td rowspan="1" colspan="1">0.34</td><td rowspan="1" colspan="1">0.35</td><td rowspan="1" colspan="1">0.39</td><td rowspan="1" colspan="1">0.43</td><td rowspan="1" colspan="1">0.44</td><td rowspan="1" colspan="1">
<bold>0.46</bold>
</td></tr><tr><td colspan="6" align="left" rowspan="1">MCC per location (&#x02191; is better)</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Cytoplasm</td><td rowspan="1" colspan="1">562</td><td rowspan="1" colspan="1">0.14</td><td rowspan="1" colspan="1">0.23</td><td rowspan="1" colspan="1">0.23</td><td rowspan="1" colspan="1">0.33</td><td rowspan="1" colspan="1">0.29</td><td rowspan="1" colspan="1">
<bold>0.36</bold>
</td></tr><tr><td rowspan="1" colspan="1">Nucleus</td><td rowspan="1" colspan="1">893</td><td rowspan="1" colspan="1">0.20</td><td rowspan="1" colspan="1">0.28</td><td rowspan="1" colspan="1">0.41</td><td rowspan="1" colspan="1">
<bold>0.45</bold>
</td><td rowspan="1" colspan="1">0.41</td><td rowspan="1" colspan="1">0.44</td></tr><tr><td rowspan="1" colspan="1">Cell membrane</td><td rowspan="1" colspan="1">287</td><td rowspan="1" colspan="1">0.20</td><td rowspan="1" colspan="1">0.23</td><td rowspan="1" colspan="1">0.32</td><td rowspan="1" colspan="1">0.30</td><td rowspan="1" colspan="1">0.34</td><td rowspan="1" colspan="1">
<bold>0.36</bold>
</td></tr><tr><td rowspan="1" colspan="1">Mitochondrion</td><td rowspan="1" colspan="1">196</td><td rowspan="1" colspan="1">0.37</td><td rowspan="1" colspan="1">0.39</td><td rowspan="1" colspan="1">0.33</td><td rowspan="1" colspan="1">0.59</td><td rowspan="1" colspan="1">
<bold>0.60</bold>
</td><td rowspan="1" colspan="1">0.56</td></tr><tr><td rowspan="1" colspan="1">Endoplasmic reticulum</td><td rowspan="1" colspan="1">77</td><td rowspan="1" colspan="1">0.12</td><td rowspan="1" colspan="1">
<bold>0.23</bold>
</td><td rowspan="1" colspan="1">0.14</td><td rowspan="1" colspan="1">0.22</td><td rowspan="1" colspan="1">0.20</td><td rowspan="1" colspan="1">0.17</td></tr><tr><td rowspan="1" colspan="1">Golgi apparatus</td><td rowspan="1" colspan="1">86</td><td rowspan="1" colspan="1">0.08</td><td rowspan="1" colspan="1">0.10</td><td rowspan="1" colspan="1">0.24</td><td rowspan="1" colspan="1">0.26</td><td rowspan="1" colspan="1">0.17</td><td rowspan="1" colspan="1">
<bold>0.31</bold>
</td></tr></tbody></table><table-wrap-foot><fn id="T2TFN1"><p>
<bold>Bold</bold> values indicate the best score</p></fn><fn id="T2TFN2"><p>
<sup>&#x003b1;</sup> = GO-terms were not used</p></fn><fn id="T2TFN3"><p>
<sup>&#x003b2;</sup> = Retrained on the new CV dataset</p></fn><fn id="T2TFN4"><p>
<sup>&#x003b3;</sup> = using local implementation</p></fn><fn id="T2TFN5"><p>
<sup>&#x003b8;</sup> = using reduced ProSeq database</p></fn></table-wrap-foot></table-wrap></sec><sec id="SEC5-2"><title>Sorting signal prediction results</title><sec id="SEC5-2-1"><title>Signal type prediction</title><p>Table&#x000a0;<xref rid="tbl3" ref-type="table">3</xref> shows that DeepLoc 2.0 is able to distinguish between the nine signal types in most of the cases with high accuracy (79%). The worst performance is obtained for nuclear export signals. Additionally, the table shows the performances we measured on the sorting signals dataset by three specialized predictors: SignalP 6.0 (<xref rid="B32" ref-type="bibr">32</xref>) for signal peptides, TargetP 2.0 (<xref rid="B33" ref-type="bibr">33</xref>) for mitochondrial and plastid transit peptides, and NetGPI 1.1 (<xref rid="B34" ref-type="bibr">34</xref>) for GPI anchors. Note that some of the sequences in the sorting signals dataset may have been included in the training sets of the specialized predictors, while the DeepLoc 2.0 values are cross-validated. DeepLoc 2.0 shows state-of-the-art performance in recognizing signal peptides and mitochondrial transit peptides. However, the specialized tools must be consulted in order to obtain the exact lengths of the sorting signals.</p><table-wrap position="float" id="tbl3"><label>Table 3.</label><caption><p>Results of signal type prediction; cross-validation</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="1" colspan="1"/><th colspan="2" align="center" rowspan="1">DeepLoc 2.0</th><th rowspan="1" colspan="1">Specialized</th></tr><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1">ESM1b</th><th rowspan="1" colspan="1">ProtT5</th><th rowspan="1" colspan="1">Predictor</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">MicroF1</td><td rowspan="1" colspan="1">0.87 &#x000b1; 0.01</td><td rowspan="1" colspan="1">0.87 &#x000b1; 0.02</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">MacroF1</td><td rowspan="1" colspan="1">0.80 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.80 &#x000b1; 0.03</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Accuracy</td><td rowspan="1" colspan="1">0.78 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.79 &#x000b1; 0.03</td><td rowspan="1" colspan="1"/></tr><tr><td colspan="4" align="left" rowspan="1">MCC per signal (&#x02191; is better)</td></tr><tr><td rowspan="1" colspan="1">SP</td><td rowspan="1" colspan="1">0.89 &#x000b1; 0.03</td><td rowspan="1" colspan="1">0.90 &#x000b1; 0.03</td><td rowspan="1" colspan="1">0.87 &#x000b1; 0.02 (<xref rid="B32" ref-type="bibr">32</xref>)</td></tr><tr><td rowspan="1" colspan="1">TM</td><td rowspan="1" colspan="1">0.71 &#x000b1; 0.07</td><td rowspan="1" colspan="1">0.66 &#x000b1; 0.05</td><td rowspan="1" colspan="1">-</td></tr><tr><td rowspan="1" colspan="1">MT</td><td rowspan="1" colspan="1">0.93 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.93 &#x000b1; 0.03</td><td rowspan="1" colspan="1">0.94 &#x000b1; 0.04 (<xref rid="B33" ref-type="bibr">33</xref>)</td></tr><tr><td rowspan="1" colspan="1">CH</td><td rowspan="1" colspan="1">0.85 &#x000b1; 0.07</td><td rowspan="1" colspan="1">0.86 &#x000b1; 0.09</td><td rowspan="1" colspan="1">0.96 &#x000b1; 0.03 (<xref rid="B33" ref-type="bibr">33</xref>)</td></tr><tr><td rowspan="1" colspan="1">TH</td><td rowspan="1" colspan="1">0.86 &#x000b1; 0.08</td><td rowspan="1" colspan="1">0.80 &#x000b1; 0.08</td><td rowspan="1" colspan="1">0.98 &#x000b1; 0.04 (<xref rid="B33" ref-type="bibr">33</xref>)</td></tr><tr><td rowspan="1" colspan="1">NLS</td><td rowspan="1" colspan="1">0.65 &#x000b1; 0.06</td><td rowspan="1" colspan="1">0.66 &#x000b1; 0.01</td><td rowspan="1" colspan="1">-</td></tr><tr><td rowspan="1" colspan="1">NES</td><td rowspan="1" colspan="1">0.49 &#x000b1; 0.20</td><td rowspan="1" colspan="1">0.46 &#x000b1; 0.17</td><td rowspan="1" colspan="1">-</td></tr><tr><td rowspan="1" colspan="1">PTS</td><td rowspan="1" colspan="1">0.85 &#x000b1; 0.06</td><td rowspan="1" colspan="1">0.90 &#x000b1; 0.05</td><td rowspan="1" colspan="1">-</td></tr><tr><td rowspan="1" colspan="1">GPI</td><td rowspan="1" colspan="1">0.85 &#x000b1; 0.06</td><td rowspan="1" colspan="1">0.86 &#x000b1; 0.06</td><td rowspan="1" colspan="1">0.91 &#x000b1; 0.01 (<xref rid="B34" ref-type="bibr">34</xref>)</td></tr></tbody></table><table-wrap-foot><fn id="T3TFN1"><p>SP = Signal Peoptide, TM = First transmembrane domain, MT = Mitochondrial transit peptide , CH = Chloroplast transit peptide, TH = Thylakoidal transit peptide, NLS = Nuclear localization signal, NES = Nuclear export signal, PTS = Peroxisomal targeting signal, GPI = GPI-anchor</p></fn></table-wrap-foot></table-wrap></sec><sec id="SEC5-2-2"><title>Attention-signal correlation</title><p>Table&#x000a0;<xref rid="tbl4" ref-type="table">4</xref> demonstrates that DeepLoc 2.0&#x02019;s attention is far better than that of DeepLoc 1.0 at providing insights into the sorting signals. The Kullback&#x02013;Leibler (KL) divergence, a direct measure of dissimilarity between attention and signal, is lower for DeepLoc 2.0. More detailed metrics and comparisons are available for each sorting signal in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Tables S8 and S9</xref>.</p><table-wrap position="float" id="tbl4"><label>Table 4.</label><caption><p>Quantitative comparison of interpretable attention; cross-validation</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1">DeepLoc 1.0 <sup>&#x003b2;</sup></th><th colspan="2" align="center" rowspan="1">DeepLoc 2.0</th></tr><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1">ESM1b</th><th rowspan="1" colspan="1">ProtT5</th></tr></thead><tbody><tr><td colspan="4" align="left" rowspan="1">KL Div (&#x02193; is better)</td></tr><tr><td rowspan="1" colspan="1">SP</td><td rowspan="1" colspan="1">1.31 &#x000b1; 0.57</td><td rowspan="1" colspan="1">1.04 &#x000b1; 0.91</td><td rowspan="1" colspan="1">0.99 &#x000b1; 0.86</td></tr><tr><td rowspan="1" colspan="1">TM</td><td rowspan="1" colspan="1">1.99 &#x000b1; 0.81</td><td rowspan="1" colspan="1">1.13 &#x000b1; 1.14</td><td rowspan="1" colspan="1">1.12 &#x000b1; 1.03</td></tr><tr><td rowspan="1" colspan="1">MT</td><td rowspan="1" colspan="1">0.92 &#x000b1; 0.38</td><td rowspan="1" colspan="1">0.51 &#x000b1; 0.54</td><td rowspan="1" colspan="1">0.50 &#x000b1; 0.48</td></tr><tr><td rowspan="1" colspan="1">CH</td><td rowspan="1" colspan="1">0.74 &#x000b1; 0.33</td><td rowspan="1" colspan="1">0.32 &#x000b1; 0.52</td><td rowspan="1" colspan="1">0.31 &#x000b1; 0.31</td></tr><tr><td rowspan="1" colspan="1">TH</td><td rowspan="1" colspan="1">0.90 &#x000b1; 0.31</td><td rowspan="1" colspan="1">0.19 &#x000b1; 0.29</td><td rowspan="1" colspan="1">0.24 &#x000b1; 0.16</td></tr><tr><td rowspan="1" colspan="1">NLS</td><td rowspan="1" colspan="1">3.11 &#x000b1; 1.02</td><td rowspan="1" colspan="1">2.63 &#x000b1; 1.52</td><td rowspan="1" colspan="1">2.60 &#x000b1; 1.32</td></tr><tr><td rowspan="1" colspan="1">NES</td><td rowspan="1" colspan="1">3.97 &#x000b1; 1.22</td><td rowspan="1" colspan="1">4.04 &#x000b1; 1.51</td><td rowspan="1" colspan="1">3.88 &#x000b1; 1.44</td></tr><tr><td rowspan="1" colspan="1">PTS</td><td rowspan="1" colspan="1">4.90 &#x000b1; 0.93</td><td rowspan="1" colspan="1">0.85 &#x000b1; 1.29</td><td rowspan="1" colspan="1">0.72 &#x000b1; 1.05</td></tr><tr><td rowspan="1" colspan="1">GPI</td><td rowspan="1" colspan="1">2.30 &#x000b1; 0.79</td><td rowspan="1" colspan="1">1.59 &#x000b1; 0.73</td><td rowspan="1" colspan="1">1.85 &#x000b1; 0.47</td></tr></tbody></table><table-wrap-foot><fn id="T4TFN1"><p>
<sup>&#x003b2;</sup> = Retrained on the new CV dataset</p></fn><fn id="T4TFN2"><p>Abbreviations same as in Table <xref rid="tbl3" ref-type="table">3</xref></p></fn></table-wrap-foot></table-wrap></sec></sec></sec><sec sec-type="conclusions" id="SEC6"><title>CONCLUSION</title><p>We provide a multi-label subcellular localization prediction tool, based on protein language models, that uses only the sequence information and outperforms existing methods. This is made possible by the use of a large curated dataset with annotations of multi-location proteins. Additionally, using a small dataset of sorting signals, we were able to improve the interpretability of the attention layer in our model. Thus, we can also provide the predicted signal type and important regions, which can give insights into relevant sections&#x000a0;of the protein sequence that are responsible for particular localization. The webserver is available at <ext-link xlink:href="https://services.healthtech.dtu.dk/service.php?DeepLoc-2.0" ext-link-type="uri">https://services.healthtech.dtu.dk/service.php?DeepLoc-2.0</ext-link>.</p></sec><sec sec-type="data-availability" id="SEC7"><title>DATA AVAILABILITY</title><p>The data used for training and testing are available at <ext-link xlink:href="https://services.healthtech.dtu.dk/service.php?DeepLoc-2.0" ext-link-type="uri">https://services.healthtech.dtu.dk/service.php?DeepLoc-2.0</ext-link>.</p></sec><sec sec-type="supplementary-material"><title>Supplementary Material</title><supplementary-material id="sup1" position="float" content-type="local-data"><label>gkac278_Supplemental_File</label><media xlink:href="gkac278_supplemental_file.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><sec id="SEC8"><title>SUPPLEMENTARY DATA</title><p>
<ext-link xlink:href="https://academic.oup.com/nar/article-lookup/doi/10.1093/nar/gkac278#supplementary-data" ext-link-type="uri">Supplementary Data</ext-link> are available at NAR Online.</p></sec><sec id="SEC9"><title>FUNDING</title><p>O.W. is supported by Novo Nordisk Fonden [NNF20OC0062606] and Danish National Research Foundation [the Pioneer Centre for AI, grant number P1]. Funding for open access charge: Public research funding (to O.W.).</p><p>
<italic toggle="yes">Conflict of interest statement</italic>. The downloadable version of DeepLoc 2.0 has been commercialized (it is licensed for a fee to commercial users). The revenue from these commercial sales is divided between the program developers and the Technical University of Denmark.</p></sec><ref-list id="REF1"><title>REFERENCES</title><ref id="B1"><label>1.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Rajendran</surname>
<given-names>L.</given-names>
</string-name>, <string-name><surname>Kn&#x000f6;lker</surname><given-names>H.-J.</given-names></string-name>, <string-name><surname>Simons</surname><given-names>K.</given-names></string-name></person-group>
<article-title>Subcellular targeting strategies for drug design and delivery</article-title>. <source>Nat. Rev. Drug Discov.</source><year>2010</year>; <volume>9</volume>:<fpage>29</fpage>&#x02013;<lpage>42</lpage>.<pub-id pub-id-type="pmid">20043027</pub-id></mixed-citation></ref><ref id="B2"><label>2.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Schmidt</surname>
<given-names>V.</given-names>
</string-name>, <string-name><surname>Willnow</surname><given-names>T.E.</given-names></string-name></person-group>
<article-title>Protein sorting gone wrong &#x02013; VPS10P domain receptors in cardiovascular and metabolic diseases</article-title>. <source>Atherosclerosis</source>. <year>2016</year>; <volume>245</volume>:<fpage>194</fpage>&#x02013;<lpage>199</lpage>.<pub-id pub-id-type="pmid">26724530</pub-id></mixed-citation></ref><ref id="B3"><label>3.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Guo</surname>
<given-names>Y.</given-names>
</string-name>, <string-name><surname>Sirkis</surname><given-names>D.W.</given-names></string-name>, <string-name><surname>Schekman</surname><given-names>R.</given-names></string-name></person-group>
<article-title>Protein sorting at the trans-Golgi network</article-title>. <source>Ann. Rev. Cell Dev. Biol.</source><year>2014</year>; <volume>30</volume>:<fpage>169</fpage>&#x02013;<lpage>206</lpage>.<pub-id pub-id-type="pmid">25150009</pub-id></mixed-citation></ref><ref id="B4"><label>4.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Delmolino</surname>
<given-names>L.M.</given-names>
</string-name>, <string-name><surname>Saha</surname><given-names>P.</given-names></string-name>, <string-name><surname>Dutta</surname><given-names>A.</given-names></string-name></person-group>
<article-title>Multiple mechanisms regulate subcellular localization of human CDC6</article-title>. <source>J. Biol. Chem.</source><year>2001</year>; <volume>276</volume>:<fpage>26947</fpage>&#x02013;<lpage>26954</lpage>.<pub-id pub-id-type="pmid">11346650</pub-id></mixed-citation></ref><ref id="B5"><label>5.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Millar</surname>
<given-names>A.H.</given-names>
</string-name>, <string-name><surname>Carrie</surname><given-names>C.</given-names></string-name>, <string-name><surname>Pogson</surname><given-names>B.</given-names></string-name>, <string-name><surname>Whelan</surname><given-names>J.</given-names></string-name></person-group>
<article-title>Exploring the function-location nexus: using multiple lines of evidence in defining the subcellular location of plant proteins</article-title>. <source>Plant Cell</source>. <year>2009</year>; <volume>21</volume>:<fpage>1625</fpage>&#x02013;<lpage>1631</lpage>.<pub-id pub-id-type="pmid">19561168</pub-id></mixed-citation></ref><ref id="B6"><label>6.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Popgeorgiev</surname>
<given-names>N.</given-names>
</string-name>, <string-name><surname>Jabbour</surname><given-names>L.</given-names></string-name>, <string-name><surname>Gillet</surname><given-names>G.</given-names></string-name></person-group>
<article-title>Subcellular localization and dynamics of the Bcl-2 family of proteins</article-title>. <source>Front. Cell Dev. Biol.</source><year>2018</year>; <volume>6</volume>:<fpage>13</fpage>.<pub-id pub-id-type="pmid">29497611</pub-id></mixed-citation></ref><ref id="B7"><label>7.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Leslie</surname>
<given-names>M.</given-names>
</string-name>
</person-group>
<article-title>Lost in translation</article-title>. <source>J. Cell Biol.</source><year>2005</year>; <volume>170</volume>:<fpage>338</fpage>&#x02013;<lpage>338</lpage>.<pub-id pub-id-type="pmid">16167405</pub-id></mixed-citation></ref><ref id="B8"><label>8.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Kanner</surname>
<given-names>E.M.</given-names>
</string-name>, <string-name><surname>Friedlander</surname><given-names>M.</given-names></string-name>, <string-name><surname>Simon</surname><given-names>S.M.</given-names></string-name></person-group>
<article-title>Co-translational targeting and translocation of the amino terminus of Opsin across the endoplasmic membrane requires GTP but Not ATP</article-title>. <source>J. Biol. Chem.</source><year>2003</year>; <volume>278</volume>:<fpage>7920</fpage>&#x02013;<lpage>7926</lpage>.<pub-id pub-id-type="pmid">12486130</pub-id></mixed-citation></ref><ref id="B9"><label>9.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Wang</surname>
<given-names>J.</given-names>
</string-name>, <string-name><surname>Chen</surname><given-names>J.</given-names></string-name>, <string-name><surname>Enns</surname><given-names>C.A.</given-names></string-name>, <string-name><surname>Mayinger</surname><given-names>P.</given-names></string-name></person-group>
<article-title>The first transmembrane domain of lipid phosphatase SAC1 promotes Golgi localization</article-title>. <source>PLoS ONE</source>. <year>2013</year>; <volume>8</volume>:<fpage>e71112</fpage>.<pub-id pub-id-type="pmid">23936490</pub-id></mixed-citation></ref><ref id="B10"><label>10.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Nielsen</surname>
<given-names>H.</given-names>
</string-name>, <string-name><surname>Tsirigos</surname><given-names>K.D.</given-names></string-name>, <string-name><surname>Brunak</surname><given-names>S.</given-names></string-name>, <string-name><surname>von&#x000a0;Heijne</surname><given-names>G.</given-names></string-name></person-group>
<article-title>A brief history of protein sorting prediction</article-title>. <source>Protein J.</source><year>2019</year>; <volume>38</volume>:<fpage>200</fpage>&#x02013;<lpage>216</lpage>.<pub-id pub-id-type="pmid">31119599</pub-id></mixed-citation></ref><ref id="B11"><label>11.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Briesemeister</surname>
<given-names>S.</given-names>
</string-name>, <string-name><surname>Rahnenf&#x000fc;hrer</surname><given-names>J.</given-names></string-name>, <string-name><surname>Kohlbacher</surname><given-names>O.</given-names></string-name></person-group>
<article-title>Going from where to why&#x02014;interpretable prediction of protein subcellular localization</article-title>. <source>Bioinformatics</source>. <year>2010</year>; <volume>26</volume>:<fpage>1232</fpage>&#x02013;<lpage>1238</lpage>.<pub-id pub-id-type="pmid">20299325</pub-id></mixed-citation></ref><ref id="B12"><label>12.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Wan</surname>
<given-names>S.</given-names>
</string-name>, <string-name><surname>Mak</surname><given-names>M.-W.</given-names></string-name>, <string-name><surname>Kung</surname><given-names>S.-Y.</given-names></string-name></person-group>
<article-title>FUEL-mLoc: feature-unified prediction and explanation of multi-localization of cellular proteins in multiple organisms</article-title>. <source>Bioinformatics</source>. <year>2016</year>; <volume>33</volume>:<fpage>749</fpage>&#x02013;<lpage>750</lpage>.</mixed-citation></ref><ref id="B13"><label>13.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Almagro&#x000a0;Armenteros</surname>
<given-names>J.J.</given-names>
</string-name>, <string-name><surname>S&#x000f8;nderby</surname><given-names>C.K.</given-names></string-name>, <string-name><surname>S&#x000f8;nderby</surname><given-names>S.K.</given-names></string-name>, <string-name><surname>Nielsen</surname><given-names>H.</given-names></string-name>, <string-name><surname>Winther</surname><given-names>O.</given-names></string-name></person-group>
<article-title>DeepLoc: prediction of protein subcellular localization using deep learning</article-title>. <source>Bioinformatics</source>. <year>2017</year>; <volume>33</volume>:<fpage>3387</fpage>&#x02013;<lpage>3395</lpage>.<pub-id pub-id-type="pmid">29036616</pub-id></mixed-citation></ref><ref id="B14"><label>14.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>St&#x000e4;rk</surname>
<given-names>H.</given-names>
</string-name>, <string-name><surname>Dallago</surname><given-names>C.</given-names></string-name>, <string-name><surname>Heinzinger</surname><given-names>M.</given-names></string-name>, <string-name><surname>Rost</surname><given-names>B.</given-names></string-name></person-group>
<article-title>Light attention predicts protein location from the language of life</article-title>. <source>Bioinform. Adv.</source><year>2021</year>; <volume>1</volume>:<fpage>vbab035</fpage>.</mixed-citation></ref><ref id="B15"><label>15.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>The&#x000a0;UniProt</surname>
<given-names>Consortium</given-names>
</string-name>
</person-group>
<article-title>UniProt: the universal protein knowledgebase</article-title>. <source>Nucleic Acids Res.</source><year>2016</year>; <volume>45</volume>:<fpage>D158</fpage>&#x02013;<lpage>D169</lpage>.<pub-id pub-id-type="pmid">27899622</pub-id></mixed-citation></ref><ref id="B16"><label>16.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Thul</surname>
<given-names>P.J.</given-names>
</string-name>, <string-name><surname>&#x000c5;kesson</surname><given-names>L.</given-names></string-name>, <string-name><surname>Wiking</surname><given-names>M.</given-names></string-name>, <string-name><surname>Mahdessian</surname><given-names>D.</given-names></string-name>, <string-name><surname>Geladaki</surname><given-names>A.</given-names></string-name>, <string-name><surname>Ait&#x000a0;Blal</surname><given-names>H.</given-names></string-name>, <string-name><surname>Alm</surname><given-names>T.</given-names></string-name>, <string-name><surname>Asplund</surname><given-names>A.</given-names></string-name>, <string-name><surname>Bj&#x000f6;rk</surname><given-names>L.</given-names></string-name>, <string-name><surname>Breckels</surname><given-names>L.M.</given-names></string-name><etal>et al</etal>.</person-group>
<article-title>A subcellular map of the human proteome</article-title>. <source>Science</source>. <year>2017</year>; <volume>356</volume>:<fpage>eaal3321</fpage>.<pub-id pub-id-type="pmid">28495876</pub-id></mixed-citation></ref><ref id="B17"><label>17.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Wan</surname>
<given-names>S.</given-names>
</string-name>, <string-name><surname>Mak</surname><given-names>M.-W.</given-names></string-name>, <string-name><surname>Kung</surname><given-names>S.-Y.</given-names></string-name></person-group>
<article-title>Sparse regressions for predicting and interpreting subcellular localization of multi-label proteins</article-title>. <source>BMC Bioinformatics</source>. <year>2016</year>; <volume>17</volume>:<fpage>97</fpage>.<pub-id pub-id-type="pmid">26911432</pub-id></mixed-citation></ref><ref id="B18"><label>18.</label><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Vaswani</surname>
<given-names>A.</given-names>
</string-name>, <string-name><surname>Shazeer</surname><given-names>N.</given-names></string-name>, <string-name><surname>Parmar</surname><given-names>N.</given-names></string-name>, <string-name><surname>Uszkoreit</surname><given-names>J.</given-names></string-name>, <string-name><surname>Jones</surname><given-names>L.</given-names></string-name>, <string-name><surname>Gomez</surname><given-names>A.N.</given-names></string-name>, <string-name><surname>Kaiser</surname><given-names>L.</given-names></string-name>, <string-name><surname>Polosukhin</surname><given-names>I.</given-names></string-name></person-group>
<person-group person-group-type="editor">
<string-name>
<surname>Guyon</surname>
<given-names>I.</given-names>
</string-name>, <string-name><surname>Luxburg</surname><given-names>U.V.</given-names></string-name>, <string-name><surname>Bengio</surname><given-names>S.</given-names></string-name>, <string-name><surname>Wallach</surname><given-names>H.</given-names></string-name>, <string-name><surname>Fergus</surname><given-names>R.</given-names></string-name>, <string-name><surname>Vishwanathan</surname><given-names>S.</given-names></string-name>, <string-name><surname>Garnett</surname><given-names>R.</given-names></string-name></person-group>
<article-title>Attention Is All You Need</article-title>. <source>Advances in Neural Information Processing Systems</source>. <year>2017</year>; <volume>30</volume>:<publisher-name>Curran Associates</publisher-name><fpage>5998</fpage>&#x02013;<lpage>6008</lpage>.</mixed-citation></ref><ref id="B19"><label>19.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Suzek</surname>
<given-names>B.E.</given-names>
</string-name>, <string-name><surname>Wang</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Huang</surname><given-names>H.</given-names></string-name>, <string-name><surname>McGarvey</surname><given-names>P.B.</given-names></string-name>, <string-name><surname>Wu</surname><given-names>C.H.</given-names></string-name><collab>the UniProt Consortium</collab></person-group>
<article-title>UniRef clusters: a comprehensive and scalable alternative for improving sequence similarity searches</article-title>. <source>Bioinformatics</source>. <year>2014</year>; <volume>31</volume>:<fpage>926</fpage>&#x02013;<lpage>932</lpage>.<pub-id pub-id-type="pmid">25398609</pub-id></mixed-citation></ref><ref id="B20"><label>20.</label><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Devlin</surname>
<given-names>J.</given-names>
</string-name>, <string-name><surname>Chang</surname><given-names>M.-W.</given-names></string-name>, <string-name><surname>Lee</surname><given-names>K.</given-names></string-name>, <string-name><surname>Toutanova</surname><given-names>K.</given-names></string-name></person-group>
<article-title>BERT: pre-training of deep bidirectional transformers for language understanding</article-title>. <source>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</source>. <year>2019</year>; <publisher-loc>Minneapolis, Minnesota</publisher-loc><publisher-name>Association for Computational Linguistics</publisher-name><fpage>4171</fpage>&#x02013;<lpage>4186</lpage>.</mixed-citation></ref><ref id="B21"><label>21.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Rives</surname>
<given-names>A.</given-names>
</string-name>, <string-name><surname>Meier</surname><given-names>J.</given-names></string-name>, <string-name><surname>Sercu</surname><given-names>T.</given-names></string-name>, <string-name><surname>Goyal</surname><given-names>S.</given-names></string-name>, <string-name><surname>Lin</surname><given-names>Z.</given-names></string-name>, <string-name><surname>Liu</surname><given-names>J.</given-names></string-name>, <string-name><surname>Guo</surname><given-names>D.</given-names></string-name>, <string-name><surname>Ott</surname><given-names>M.</given-names></string-name>, <string-name><surname>Zitnick</surname><given-names>C.L.</given-names></string-name>, <string-name><surname>Ma</surname><given-names>J.</given-names></string-name><etal>et al</etal>.</person-group>
<article-title>Biological Structure and Function Emerge from Scaling Unsupervised Learning to 250 Million Protein Sequences</article-title>. <source>Proc. Nati. Acad. Sci.</source><year>2021</year>; <volume>118</volume>:<fpage>e2016239118</fpage>.</mixed-citation></ref><ref id="B22"><label>22.</label><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Rao</surname>
<given-names>R.</given-names>
</string-name>, <string-name><surname>Liu</surname><given-names>J.</given-names></string-name>, <string-name><surname>Verkuil</surname><given-names>R.</given-names></string-name>, <string-name><surname>Meier</surname><given-names>J.</given-names></string-name>, <string-name><surname>Canny</surname><given-names>J.F.</given-names></string-name>, <string-name><surname>Abbeel</surname><given-names>P.</given-names></string-name>, <string-name><surname>Sercu</surname><given-names>T.</given-names></string-name>, <string-name><surname>Rives</surname><given-names>A.</given-names></string-name></person-group>
<person-group person-group-type="editor">
<string-name>
<surname>Meila</surname>
<given-names>M.</given-names>
</string-name>, <string-name><surname>Zhang</surname><given-names>T.</given-names></string-name></person-group>
<article-title>MSA Transformer</article-title>. <source>Proceedings of the 38th International Conference on Machine Learning, PMLR</source>. <year>2021</year>; <volume>139</volume>:<fpage>8844</fpage>&#x02013;<lpage>8856</lpage>.</mixed-citation></ref><ref id="B23"><label>23.</label><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Rao</surname>
<given-names>R.</given-names>
</string-name>, <string-name><surname>Meier</surname><given-names>J.</given-names></string-name>, <string-name><surname>Sercu</surname><given-names>T.</given-names></string-name>, <string-name><surname>Ovchinnikov</surname><given-names>S.</given-names></string-name>, <string-name><surname>Rives</surname><given-names>A.</given-names></string-name></person-group>
<article-title>Transformer protein language models are unsupervised structure learners</article-title>. <year>2020</year>; <comment>bioRxiv doi:</comment><comment>15 December 2020, preprint: not peer reviewed</comment><pub-id pub-id-type="doi">10.1101/2020.12.15.422761</pub-id>.</mixed-citation></ref><ref id="B24"><label>24.</label><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Elnaggar</surname>
<given-names>A.</given-names>
</string-name>, <string-name><surname>Heinzinger</surname><given-names>M.</given-names></string-name>, <string-name><surname>Dallago</surname><given-names>C.</given-names></string-name>, <string-name><surname>Rihawi</surname><given-names>G.</given-names></string-name>, <string-name><surname>Wang</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Jones</surname><given-names>L.</given-names></string-name>, <string-name><surname>Gibbs</surname><given-names>T.</given-names></string-name>, <string-name><surname>Feher</surname><given-names>T.</given-names></string-name>, <string-name><surname>Angerer</surname><given-names>C.</given-names></string-name>, <string-name><surname>Bhowmik</surname><given-names>D.</given-names></string-name><etal>et al</etal>.</person-group>
<article-title>ProtTrans: towards cracking the language of lifes code through self-supervised deep learning and high performance computing</article-title>. <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>. <year>2021</year>; <pub-id pub-id-type="doi">10.1109/TPAMI.2021.3095381</pub-id>.</mixed-citation></ref><ref id="B25"><label>25.</label><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Vig</surname>
<given-names>J.</given-names>
</string-name>, <string-name><surname>Madani</surname><given-names>A.</given-names></string-name>, <string-name><surname>Varshney</surname><given-names>L.R.</given-names></string-name>, <string-name><surname>Xiong</surname><given-names>C.</given-names></string-name>, <string-name><surname>Socher</surname><given-names>R.</given-names></string-name>, <string-name><surname>Rajani</surname><given-names>N.F.</given-names></string-name></person-group>
<article-title>BERTology meets biology: interpreting attention in protein language models</article-title>. <year>2021</year>; <comment>bioRxiv doi:</comment><comment>28 March 2021, preprint: not peer reviewed</comment><uri xlink:href="https://arxiv.org/abs/2006.15222">https://arxiv.org/abs/2006.15222</uri>.</mixed-citation></ref><ref id="B26"><label>26.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Brandes</surname>
<given-names>N.</given-names>
</string-name>, <string-name><surname>Ofer</surname><given-names>D.</given-names></string-name>, <string-name><surname>Peleg</surname><given-names>Y.</given-names></string-name>, <string-name><surname>Rappoport</surname><given-names>N.</given-names></string-name>, <string-name><surname>Linial</surname><given-names>M.</given-names></string-name></person-group>
<article-title>ProteinBERT: a universal deep-learning model of protein sequence and function</article-title>. <source>Bioinformatics</source>. <year>2022</year>; <volume>38</volume>:<fpage>2102</fpage>&#x02013;<lpage>2110</lpage>.</mixed-citation></ref><ref id="B27"><label>27.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Martiny</surname>
<given-names>H.-M.</given-names>
</string-name>, <string-name><surname>Almagro&#x000a0;Armenteros</surname><given-names>J.J.</given-names></string-name>, <string-name><surname>Johansen</surname><given-names>A.R.</given-names></string-name>, <string-name><surname>Salomon</surname><given-names>J.</given-names></string-name>, <string-name><surname>Nielsen</surname><given-names>H.</given-names></string-name></person-group>
<article-title>Deep protein representations enable recombinant protein expression prediction</article-title>. <source>Comput. Biol. Chem.</source><year>2021</year>; <volume>95</volume>:<fpage>107596</fpage>.<pub-id pub-id-type="pmid">34775287</pub-id></mixed-citation></ref><ref id="B28"><label>28.</label><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Bahdanau</surname>
<given-names>D.</given-names>
</string-name>, <string-name><surname>Cho</surname><given-names>K.</given-names></string-name>, <string-name><surname>Bengio</surname><given-names>Y.</given-names></string-name></person-group>
<person-group person-group-type="editor">
<string-name>
<surname>Bengio</surname>
<given-names>Y.</given-names>
</string-name>, <string-name><surname>LeCun</surname><given-names>Y.</given-names></string-name></person-group>
<article-title>Neural machine translation by jointly learning to align and translate</article-title>. <source>3rd International Conference on Learning Representations</source>. <year>2015</year>; <publisher-loc>San Diego, California</publisher-loc>.</mixed-citation></ref><ref id="B29"><label>29.</label><mixed-citation publication-type="book">
<person-group person-group-type="author">
<string-name>
<surname>Lin</surname>
<given-names>T.</given-names>
</string-name>, <string-name><surname>Goyal</surname><given-names>P.</given-names></string-name>, <string-name><surname>Girshick</surname><given-names>R.B.</given-names></string-name>, <string-name><surname>He</surname><given-names>K.</given-names></string-name>, <string-name><surname>Doll&#x000e1;r</surname><given-names>P.</given-names></string-name></person-group>
<article-title>Focal loss for dense object detection</article-title>. <source>2017 IEEE International Conference on Computer Vision (ICCV)</source>. <year>2017</year>; <fpage>2999</fpage>&#x02013;<lpage>3007</lpage>.</mixed-citation></ref><ref id="B30"><label>30.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Chicco</surname>
<given-names>D.</given-names>
</string-name>, <string-name><surname>Jurman</surname><given-names>G.</given-names></string-name></person-group>
<article-title>The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation</article-title>. <source>BMC Genomics</source>. <year>2020</year>; <volume>21</volume>:<fpage>6</fpage>.<pub-id pub-id-type="pmid">31898477</pub-id></mixed-citation></ref><ref id="B31"><label>31.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Wan</surname>
<given-names>S.</given-names>
</string-name>, <string-name><surname>Mak</surname><given-names>M.-W.</given-names></string-name>, <string-name><surname>Kung</surname><given-names>S.-Y.</given-names></string-name></person-group>
<article-title>mGOASVM: Multi-label protein subcellular localization based on gene ontology and support vector machines</article-title>. <source>BMC Bioinformatics</source>. <year>2012</year>; <volume>13</volume>:<fpage>290</fpage>.<pub-id pub-id-type="pmid">23130999</pub-id></mixed-citation></ref><ref id="B32"><label>32.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Teufel</surname>
<given-names>F.</given-names>
</string-name>, <string-name><surname>Almagro&#x000a0;Armenteros</surname><given-names>J.J.</given-names></string-name>, <string-name><surname>Johansen</surname><given-names>A.R.</given-names></string-name>, <string-name><surname>G&#x000ed;slason</surname><given-names>M.H.</given-names></string-name>, <string-name><surname>Pihl</surname><given-names>S.I.</given-names></string-name>, <string-name><surname>Tsirigos</surname><given-names>K.D.</given-names></string-name>, <string-name><surname>Winther</surname><given-names>O.</given-names></string-name>, <string-name><surname>Brunak</surname><given-names>S.</given-names></string-name>, <string-name><surname>von&#x000a0;Heijne</surname><given-names>G.</given-names></string-name>, <string-name><surname>Nielsen</surname><given-names>H.</given-names></string-name></person-group>
<article-title>SignalP 6.0 predicts all five types of signal peptides using protein language models</article-title>. <source>Nat. Biotechnol.</source><year>2022</year>; <pub-id pub-id-type="doi">10.1038/s41587-021-01156-3</pub-id>.</mixed-citation></ref><ref id="B33"><label>33.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Almagro&#x000a0;Armenteros</surname>
<given-names>J.J.</given-names>
</string-name>, <string-name><surname>Salvatore</surname><given-names>M.</given-names></string-name>, <string-name><surname>Emanuelsson</surname><given-names>O.</given-names></string-name>, <string-name><surname>Winther</surname><given-names>O.</given-names></string-name>, <string-name><surname>von&#x000a0;Heijne</surname><given-names>G.</given-names></string-name>, <string-name><surname>Elofsson</surname><given-names>A.</given-names></string-name>, <string-name><surname>Nielsen</surname><given-names>H.</given-names></string-name></person-group>
<article-title>Detecting sequence signals in targeting peptides using deep learning</article-title>. <source>Life Sci. Allian.</source><year>2019</year>; <volume>2</volume>:<fpage>e201900429</fpage>.</mixed-citation></ref><ref id="B34"><label>34.</label><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>G&#x000ed;slason</surname>
<given-names>M.H.</given-names>
</string-name>, <string-name><surname>Nielsen</surname><given-names>H.</given-names></string-name>, <string-name><surname>Almagro&#x000a0;Armenteros</surname><given-names>J.J.</given-names></string-name>, <string-name><surname>Johansen</surname><given-names>A.R.</given-names></string-name></person-group>
<article-title>Prediction of GPI-anchored proteins with pointer neural networks</article-title>. <source>Curr. Res. Biotechnol.</source><year>2021</year>; <volume>3</volume>:<fpage>6</fpage>&#x02013;<lpage>13</lpage>.</mixed-citation></ref></ref-list></back></article>