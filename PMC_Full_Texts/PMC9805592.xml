<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd"> 
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-journalpublishing1.dtd?><?SourceDTD.Version 1.2?><?ConverterInfo.XSLTName jats2jats3.xsl?><?ConverterInfo.Version 1?><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id><journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id><journal-id journal-id-type="publisher-id">bioinformatics</journal-id><journal-title-group><journal-title>Bioinformatics</journal-title></journal-title-group><issn pub-type="ppub">1367-4803</issn><issn pub-type="epub">1367-4811</issn><publisher><publisher-name>Oxford University Press</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">9805592</article-id><article-id pub-id-type="pmid">36420989</article-id><article-id pub-id-type="doi">10.1093/bioinformatics/btac759</article-id><article-id pub-id-type="publisher-id">btac759</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Paper</subject><subj-group subj-group-type="category-toc-heading"><subject>Structural Bioinformatics</subject></subj-group></subj-group><subj-group subj-group-type="category-taxonomy-collection"><subject>AcademicSubjects/SCI01060</subject></subj-group></article-categories><title-group><article-title>DeepRank-GNN: a graph neural network framework to learn patterns in protein&#x02013;protein interfaces</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>R&#x000e9;au</surname><given-names>Manon</given-names></name><aff>
<institution>Computational Structural Biology Group, Department of Chemistry, Bijvoet Centre, Faculty of Science, Utrecht University</institution>, Utrecht 3584CH, <country country="NL">The Netherlands</country></aff><xref rid="btac759-FM1" ref-type="author-notes"/></contrib><contrib contrib-type="author"><name><surname>Renaud</surname><given-names>Nicolas</given-names></name><aff>
<institution>Netherlands eScience Center</institution>, Amsterdam 1098 XG, <country country="NL">The Netherlands</country></aff><xref rid="btac759-FM1" ref-type="author-notes"/></contrib><contrib contrib-type="author"><name><surname>Xue</surname><given-names>Li C</given-names></name><aff>
<institution>Center for Molecular and Biomolecular Informatics, Radboudumc</institution>, Nijmegen 6525 GA, <country country="NL">The Netherlands</country></aff></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-7369-1322</contrib-id><name><surname>Bonvin</surname><given-names>Alexandre M J J</given-names></name><aff>
<institution>Computational Structural Biology Group, Department of Chemistry, Bijvoet Centre, Faculty of Science, Utrecht University</institution>, Utrecht 3584CH, <country country="NL">The Netherlands</country></aff><xref rid="btac759-cor1" ref-type="corresp"/><!--a.m.j.j.bonvin@uu.nl--></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name><surname>Cowen</surname><given-names>Lenore</given-names></name><role>Associate Editor</role></contrib></contrib-group><author-notes><fn id="btac759-FM1"><p>The authors wish it to be known that, in their opinion, the first two authors should be regarded as Joint First Authors.</p></fn><corresp id="btac759-cor1">To whom correspondence should be addressed. Email: <email>a.m.j.j.bonvin@uu.nl</email></corresp></author-notes><pub-date pub-type="collection"><month>1</month><year>2023</year></pub-date><pub-date pub-type="epub" iso-8601-date="2022-11-24"><day>24</day><month>11</month><year>2022</year></pub-date><pub-date pub-type="pmc-release"><day>24</day><month>11</month><year>2022</year></pub-date><volume>39</volume><issue>1</issue><elocation-id>btac759</elocation-id><history><date date-type="received"><day>25</day><month>11</month><year>2021</year></date><date date-type="rev-recd"><day>19</day><month>10</month><year>2022</year></date><date date-type="editorial-decision"><day>21</day><month>11</month><year>2022</year></date><date date-type="accepted"><day>23</day><month>11</month><year>2022</year></date><date date-type="corrected-typeset"><day>10</day><month>12</month><year>2022</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2022. Published by Oxford University Press.</copyright-statement><copyright-year>2022</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><self-uri xlink:href="btac759.pdf"/><abstract><title>Abstract</title><sec id="s1"><title>Motivation</title><p>Gaining structural insights into the protein&#x02013;protein interactome is essential to understand biological phenomena and extract knowledge for rational drug design or protein engineering. We have previously developed DeepRank, a deep-learning framework to facilitate pattern learning from protein&#x02013;protein interfaces using convolutional neural network (CNN) approaches. However, CNN is not rotation invariant and data augmentation is required to desensitize the network to the input data orientation which dramatically impairs the computation performance. Representing protein&#x02013;protein complexes as atomic- or residue-scale rotation invariant graphs instead enables using graph neural networks (GNN) approaches, bypassing those limitations.</p></sec><sec id="s2"><title>Results</title><p>We have developed DeepRank-GNN, a framework that converts protein&#x02013;protein interfaces from PDB 3D coordinates files into graphs that are further provided to a pre-defined or user-defined GNN architecture to learn problem-specific interaction patterns. DeepRank-GNN is designed to be highly modularizable, easily customized and is wrapped into a user-friendly python3 package. Here, we showcase DeepRank-GNN&#x02019;s performance on two applications using a dedicated graph interaction neural network: (i) the scoring of docking poses and (ii) the discriminating of biological and crystal interfaces. In addition to the highly competitive performance obtained in those tasks as compared to state-of-the-art methods, we show a significant improvement in speed and storage requirement using DeepRank-GNN as compared to DeepRank.</p></sec><sec id="s3"><title>Availability and implementation</title><p>DeepRank-GNN is freely available from <ext-link xlink:href="https://github.com/DeepRank/DeepRank-GNN" ext-link-type="uri">https://github.com/DeepRank/DeepRank-GNN</ext-link>.</p></sec><sec id="s5"><title>Supplementary information</title><p>
<xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p></sec></abstract><funding-group><award-group award-type="grant"><funding-source>
<institution-wrap><institution>Netherlands eScience Center</institution><institution-id institution-id-type="DOI">10.13039/100013407</institution-id></institution-wrap>
</funding-source><award-id>ASDI.2016.043</award-id></award-group><award-group award-type="grant"><funding-source>
<institution-wrap><institution>SURF Open Lab &#x02018;Machine</institution></institution-wrap>
</funding-source><award-id>AB/AM/10573</award-id></award-group><award-group award-type="grant"><funding-source>
<institution-wrap><institution>Computing Time on National Computer Facilities</institution></institution-wrap>
</funding-source><award-id>2018/ENW/00485366</award-id></award-group><award-group award-type="grant"><funding-source>
<institution-wrap><institution>Netherlands Organization for Scientific Research</institution></institution-wrap>
</funding-source></award-group><award-group award-type="grant"><funding-source>
<institution-wrap><institution>European Union Horizon 2020 project BioExcel</institution></institution-wrap>
</funding-source><award-id>823830</award-id></award-group><award-group award-type="grant"><funding-source>
<institution-wrap><institution>Hypatia Fellowship from Radboudumc</institution></institution-wrap>
</funding-source><award-id>Rv819.52706</award-id></award-group></funding-group><counts><page-count count="8"/></counts></article-meta></front><body><sec><title>1 Introduction</title><p>Protein&#x02013;protein interactions (PPIs) are essential in all cellular processes of living organisms including cell growth, structure, communication, protection and death. Adding the structural dimension to PPI is fundamental to understand normal and altered physiological processes and to propose solutions to restore them. In the past decades, a large number of isolated protein and PPI structures have been solved by experimental approaches (e.g. X-ray crystallography, nuclear magnetic resonance and cryogenic electron microscopy). The diversity and quantity of structural data recently enabled treating PPI data with machine learning approaches that were previously devoted to small molecule toxicity (<xref rid="btac759-B25" ref-type="bibr">Mayr <italic toggle="yes">et al.</italic>, 2016</xref>), affinity (<xref rid="btac759-B14" ref-type="bibr">Jim&#x000e9;nez <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btac759-B16" ref-type="bibr">Karlov <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btac759-B28" ref-type="bibr">Ragoza <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btac759-B35" ref-type="bibr">Son and Kim, 2021</xref>) and binding mode (<xref rid="btac759-B9" ref-type="bibr">Francoeur <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btac759-B26" ref-type="bibr">Morrone <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btac759-B36" ref-type="bibr">Torng and Altman, 2019</xref>) prediction.</p><p>Given the remarkable success of convolutional neural network (CNN) in retrieving patterns in images (<xref rid="btac759-B18" ref-type="bibr">Krizhevsky <italic toggle="yes">et al.</italic>, 2017</xref>), CNN approaches have been developed to learn interaction patterns in PPI interfaces (<xref rid="btac759-B31" ref-type="bibr">Renaud <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac759-B38" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2020</xref>) or to assess the quality of protein structures (<xref rid="btac759-B1" ref-type="bibr">Baldassarre <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac759-B27" ref-type="bibr">Pag&#x000e8;s <italic toggle="yes">et al.</italic>, 2019</xref>). The uniqueness of each approach originates from the designed network architecture and importantly, the data representation and resolution. An example is MASIF (<xref rid="btac759-B10" ref-type="bibr">Gainza <italic toggle="yes">et al.</italic>, 2020</xref>) that makes use of a high-level representation of proteins, focusing on their surface described as an ensemble of overlapping patches. The patches are fed into different CNNs in order to build relevant fingerprints that can be further used for ultra-fast interaction prediction tasks based on the complementarity or the similarity of the fingerprints. DOVE (<xref rid="btac759-B38" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2020</xref>) evaluates protein&#x02013;protein docking models using a 3D-CNN approach on a higher resolution&#x02014;atomic-level&#x02014;representation of the interface mapped into a 3D grid. Although no exhaustive benchmark exists with state-of-the-art approaches, both tools display high performance on the benchmark set used for their evaluation and hold the promise to improve over time with the availability of new data and the improvement of data storage and computation power. As the recent major advances made by Alphafold2 in predicting protein structures (<xref rid="btac759-B15" ref-type="bibr">Jumper <italic toggle="yes">et al.</italic>, 2021</xref>) and protein multimeric states are likely to lead to an exponential generation of multimers over years, including true and false partners, the availability of reliable quality assessment tools should become a strong ally to reach the ambitious objective of modeling of the entire interactome.</p><p>We have recently developed DeepRank (<ext-link xlink:href="https://github.com/DeepRank/deeprank" ext-link-type="uri">https://github.com/DeepRank/deeprank</ext-link>), an open-source configurable deep-learning framework wrapped into a user-friendly python3 package (<xref rid="btac759-B30" ref-type="bibr">Renaud <italic toggle="yes">et al.</italic>, 2020</xref>, <xref rid="btac759-B31" ref-type="bibr">2021</xref>). DeepRank maps atomic and residue-level features from PPI interfaces to 3D grids and applies a customizable 3D CNN pipeline to learn problem-specific interaction patterns. DeepRank was applied to two problems where it competed with- or outperformed state-of-the-art methods, including a machine learning-based model, iScore (<xref rid="btac759-B12" ref-type="bibr">Geng <italic toggle="yes">et al.</italic>, 2020</xref>) that makes use of a graph representation and the classical energy-based scoring function implemented in HADDOCK (<xref rid="btac759-B40" ref-type="bibr">van Zundert <italic toggle="yes">et al.</italic>, 2016</xref>).</p><p>CNNs however come with limitations: first, they are sensitive to the input PPI interface orientation which may require data augmentation (i.e. multiple rotations of the input data) for the network to provide consistent predictions regardless of the orientation of the PPI; second, the size of the 3D grid is pre-defined for all input data in DeepRank 0.2.0, which does not reflect the variety in interface sizes observed in experimental structures and may be problematic for large interfaces that do not fit inside the pre-defined grid size.</p><p>A solution to this problem is to use a graph representation of PPI interface. A graph is defined as an ensemble of nodes (e.g. atoms and residues) and edges (e.g. covalent bond and contacts), and is often represented with a feature matrix containing attributes assigned to each node of the graph, and an adjacency matrix&#x02014;or edge matrix&#x02014;describing the connectivity between the nodes. A graph neural network (GNN) iteratively updates a node&#x02019;s features integrating the node&#x02019;s neighborhood information (an operation called message passing). GNNs can be trained to learn the optimal updated node features to predict the properties of a single protein or a complex of proteins (<xref rid="btac759-B4" ref-type="bibr">Cao and Shen, 2020</xref>; <xref rid="btac759-B13" ref-type="bibr">Igashov <italic toggle="yes">et al.</italic>, 2021</xref>; <xref rid="btac759-B39" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2021</xref>). Contrary to CNNs, the convolution operations on graphs can be independent from Cartesian coordinates and only rely on the relative local connectivity between nodes, therefore making graphs rotational invariant. GNNs are also invariant with respect to the ordering of nodes in the feature and adjacency matrices, and the network can accept any size of graph, therefore more naturally representing the diversity of PPIs. Based on these arguments, different GNN-based tools have been designed for PPI site prediction (<xref rid="btac759-B8" ref-type="bibr">Fout <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btac759-B24" ref-type="bibr">Mahbub and Bayzid, 2022</xref>) and to assess the quality of protein&#x02013;protein complexes (<xref rid="btac759-B39" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2021</xref>). An example of the latter is the GNN version of DOVE (DOVE-GNN) that demonstrated significant improvement in the docking models classification task over the CNN version (<xref rid="btac759-B39" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2021</xref>).</p><p>Building up on our previous framework DeepRank (CNN based), we present here DeepRank-GNN (<xref rid="btac759-B29" ref-type="bibr">R&#x000e9;au and Renaud, 2021</xref>), a versatile software that takes advantage of the intrinsic properties of graph representation and graph convolutions. DeepRank-GNN converts PPI interfaces from 3D coordinates PDB files into graphs and enables the application of pre-defined or user-defined GNN architectures to train a network to make predictions related to the properties of PPI interfaces, such as the quality of a docking model or the likelihood that a given interface is biologically relevant. DeepRank-GNN can automatically compute docking-specific target values when reference PDB files are provided or assign user-provided target values to the graphs. We describe the main functionalities of DeepRank-GNN and showcase its application to the scoring of docking models and the discrimination of biological and crystal interfaces. Detailed documentation is available online at <ext-link xlink:href="https://deeprank-gnn.readthedocs.io/" ext-link-type="uri">https://deeprank-gnn.readthedocs.io/</ext-link>.</p></sec><sec><title>2 Materials and methods</title><sec><title>2.1 DeepRank-GNN overview</title><p>DeepRank-GNN is a python3 package that offers a complete framework to learn PPI interface patterns in an end-to-end fashion using GNN. The overall design of DeepRank-GNN was inherited from our previous package DeepRank that focuses on the scoring PPI using 3dcnn neural networks and consists of two mains parts (<xref rid="btac759-F1" ref-type="fig">Fig.&#x000a0;1</xref>) (i) the conversion of 3D PPI interfaces into interaction graphs with node and edge features using the networkx (<xref rid="btac759-B1200" ref-type="bibr">Hagberg <italic toggle="yes">et al.</italic>, 2008</xref>) and pdb2sql (<xref rid="btac759-B33" ref-type="bibr">Renaud and Geng, 2021b</xref>) packages and (ii) the training and the evaluation of a graph neural network model using PyTorch geometric (<xref rid="btac759-B7" ref-type="bibr">Paszke <italic toggle="yes">et al.</italic>, 2017</xref>). An overview of the software architecture is provided in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S1</xref>. We briefly present both parts below and refer the reader to the online documentation for further information (<ext-link xlink:href="https://deeprank-gnn.readthedocs.io/" ext-link-type="uri">https://deeprank-gnn.readthedocs.io/</ext-link>).</p><fig position="float" id="btac759-F1"><label>Fig. 1.</label><caption><p>Overview of the DeepRank-GNN framework. (<bold>A</bold>) DeepRank-GNN identifies interface residues and converts them into an interface graph. Internal edges are defined between residues from the same chain having heavy atoms within a 3&#x02009;&#x000c5; distance cutoff from each other, while external edges are defined between residues from different chains having heavy atoms within the 8.5&#x02009;&#x000c5; cutoff. (<bold>B</bold>) <italic toggle="yes">Example of GNN architecture</italic> (GINet). The graph representation of a PPI is split into two sub-graphs, i.e. the internal graph connecting atoms from the same protein and the external graph connecting atoms from distinct proteins. The two sub-graphs are sequentially passed to two consecutive convolution/activation/pooling layers. The two final graph representations are flattened using the mean value of each feature and merged before applying two fully connected layers. GCL, graph convolution layer; FCC, fully connected layer</p></caption><graphic xlink:href="btac759f1" position="float"/></fig><sec><title>2.1.1 Graph generation</title><p>DeepRank-GNN converts PPI interfaces into residue-level graphs (<xref rid="btac759-F1" ref-type="fig">Fig.&#x000a0;1A</xref>). It takes PDB 3D coordinate files as an input and defines the interface between two chains using pdb2sql (<xref rid="btac759-B33" ref-type="bibr">Renaud and Geng, 2021b</xref>), our PDB file parser using a structured query language (SQL). By default, the interface is defined by all the residues involved in intermolecular contacts, i.e. the residues of a given chain having a heavy atom within an 8.5&#x02009;&#x000c5; distance cutoff of any heavy atom from another chain. These contact residues form the nodes of the graph. <italic toggle="yes">Interface</italic> edges are defined between two contact residues from distinct chains presenting a minimal atomic distance smaller than 8.5&#x02009;&#x000c5;. In addition, <italic toggle="yes">internal</italic> edges are defined between two contact residues of the same chain provided they have heavy atoms within 3&#x02009;&#x000c5; from each other. These default distance cut-offs can be tailored by the user. The types of edges can be later considered to perform different convolution operations on the graph.</p><p>The graphs are stored in HDF5 format that is suited for large dataset storage and allows efficient memory usage and fast input/output operations during the network training.</p></sec><sec><title>2.1.2 Featurization</title><p>By default, DeepRank-GNN computes and assigns an ensemble of residue-level features to each node. Those are summarized in <xref rid="btac759-T1" ref-type="table">Table&#x000a0;1</xref>. The feature computation can rapidly become a limiting step if the computation speed is not optimized. In DeepRank-GNN, the assignment of residue type, charge, polarity and buried surface area features are considerably faster than the computation of the residue depth, i.e. the average distance of the atoms of a residue from the solvent accessible surface, and the half sphere exposure. Provided that the information brought by the two latter could implicitly be deduced from the buried surface area feature and the node environment, they are not calculated by default for the sake of time efficiency. Pre-computed position-specific scoring matrices (PSSM) are required for the assignment of PSSM-related features. We advise querying a dataset of pre-computed PSSM matrices such as the 3DCONS (<ext-link xlink:href="http://3dcons.cnb.csic.es/" ext-link-type="uri">http://3dcons.cnb.csic.es/</ext-link>), the Conserved Domains Database (<xref rid="btac759-B23" ref-type="bibr">Lu <italic toggle="yes">et al.</italic>, 2020</xref>) or using our in-house PSSM generation tool PSSMGen (<xref rid="btac759-B32" ref-type="bibr">Renaud and Geng, 2021a</xref>).</p><table-wrap position="float" id="btac759-T1"><label>Table 1.</label><caption><p>Features computed in DeepRank-GNN</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col valign="top" align="left" span="1"/><col valign="top" align="left" span="1"/><col valign="top" align="left" span="1"/><col valign="top" align="left" span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="left" span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1">Name of features</th><th align="center" rowspan="1" colspan="1">Full name</th><th align="center" rowspan="1" colspan="1">Description</th><th align="center" rowspan="1" colspan="1">Default</th><th align="center" rowspan="1" colspan="1">Number of parameters</th><th align="center" rowspan="1" colspan="1">Type</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">Type</td><td rowspan="1" colspan="1">Residue type</td><td rowspan="1" colspan="1">One-hot encoded</td><td rowspan="1" colspan="1">Default</td><td rowspan="1" colspan="1">20</td><td rowspan="1" colspan="1">Node feature</td></tr><tr><td rowspan="1" colspan="1">Charge</td><td rowspan="1" colspan="1">Residue charge</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Default</td><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">Node feature</td></tr><tr><td rowspan="1" colspan="1">Polarity</td><td rowspan="1" colspan="1">Residue polarity</td><td rowspan="1" colspan="1">One-hot encoded</td><td rowspan="1" colspan="1">Default</td><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">Node feature</td></tr><tr><td rowspan="1" colspan="1">BSA</td><td rowspan="1" colspan="1">Buried surface area</td><td rowspan="1" colspan="1">FreeSASA</td><td rowspan="1" colspan="1">Default</td><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">Node feature</td></tr><tr><td rowspan="1" colspan="1">PSSM</td><td rowspan="1" colspan="1">Position-specific scoring matrix</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Optional</td><td rowspan="1" colspan="1">20</td><td rowspan="1" colspan="1">Node feature</td></tr><tr><td rowspan="1" colspan="1">Cons</td><td rowspan="1" colspan="1">Conservation score&#x02014;from PSSM</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Optional</td><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">Node feature</td></tr><tr><td rowspan="1" colspan="1">ic</td><td rowspan="1" colspan="1">Information content&#x02014;from PSSM</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Optional</td><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">Node feature</td></tr><tr><td rowspan="1" colspan="1">Depth</td><td rowspan="1" colspan="1">Residue depth</td><td rowspan="1" colspan="1">MSMS&#x02014;Biopython</td><td rowspan="1" colspan="1">Optional</td><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">Node feature</td></tr><tr><td rowspan="1" colspan="1">hse</td><td rowspan="1" colspan="1">Residue half sphere exposure</td><td rowspan="1" colspan="1">Biopython</td><td rowspan="1" colspan="1">Optional</td><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">Node feature</td></tr><tr><td rowspan="1" colspan="1">Distance</td><td rowspan="1" colspan="1">Normalized distance</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1">Default</td><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">Edge feature</td></tr></tbody></table></table-wrap><p>To encode the relative positions of the nodes in the graph, and therefore the overall structure of the interface, we assign a distance feature to the internal and external edges. This distance feature is based on the smallest atomic distance between two residues (nodes) that is transformed into an interaction strength by <xref rid="E1" ref-type="disp-formula">equation&#x000a0;1</xref>.
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal">&#x02009;</mml:mi><mml:mi mathvariant="normal">tan</mml:mi><mml:mi mathvariant="normal">&#x02009;</mml:mi><mml:mi>h</mml:mi><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>#</mml:mo><mml:mo>,</mml:mo></mml:math></disp-formula>where <italic toggle="yes">x</italic> is the smallest distance between two residues (&#x000c5;).</p><p>The interaction strength ranges from 0 for long distances to 1.96 for null distances and provides a normalized feature of the internode distance. While other normalization functions could be used, we believe that the careful exploration regarding the influence of the normalization function on the performance of the training process is out of the scope of this manuscript.</p></sec><sec><title>2.1.3 Target assignment</title><p>Many different metrics have been developed to quantify the relevance of PPI interfaces and can be used as target values during the network training and evaluation phases. In a docking scenario where the goal is to identify near-native models, the user can provide a reference structure, i.e. the experimentally solved bound conformation of the complex, for DeepRank-GNN to automatically compute target values in the pre-processing stage based on CAPRI quality criteria (<xref rid="btac759-B19" ref-type="bibr">Lensink <italic toggle="yes">et al.</italic>, 2007</xref>) (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>). For other applications and/or use cases, a reference structure is not required and users may input their own problem-specific target values or develop new metric calculations and integrate these metrics in the computational workflow.</p></sec><sec><title>2.1.4 Model training/evaluation/test</title><p>All the prerequisites to train and to evaluate a GNN model are detailed in our online documentation. The user can run DeepRank-GNN in a regression or classification mode. The loss function is automatically set to mean square error (MSE) for regression tasks or to cross-entropy for classification tasks. Weights can be assigned to classes to balance the cross-entropy loss calculation in case of an imbalanced dataset. We also propose an automated weight computation that assigns weights inversely proportional to each class representation in the training set for classification tasks on imbalanced datasets (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Information</xref>).</p></sec><sec><title>2.1.5 Network</title><p>DeepRank-GNN provides a flexible structure allowing users to define their own network architectures or use pre-defined ones (see the online documentation).</p></sec><sec><title>2.1.6 Quality metrics</title><p>DeepRank-GNN provides tools to swiftly compute the quality metrics summarized in our online documentation (<ext-link xlink:href="https://deeprank-gnn.readthedocs.io/en/latest/tutorial.train_model.html#analysis" ext-link-type="uri">https://deeprank-gnn.readthedocs.io/en/latest/tutorial.train_model.html#analysis</ext-link>). Upon the definition of a threshold value to binarize the data, all classification metrics can be applied to continuous targets and prediction values.</p></sec></sec><sec><title>2.2 Application 1&#x02014;the scoring of docking models</title><p>We evaluated DeepRank-GNN&#x02019;s performance as a docking model scoring tool. We designed a GNN architecture that was trained and evaluated on the Docking Benchmark version 5 (BM5) dataset and further tested on an external set, the CAPRI scoreset.</p><sec><title>2.2.1 BM5 benchmark</title><p>The BM5 dataset has been designed for docking purposes and encompasses a non-redundant set of 231 complexes for which the individual structure of interacting proteins is available in a bound and an unbound conformation (<xref rid="btac759-B37" ref-type="bibr">Vreven <italic toggle="yes">et al.</italic>, 2015</xref>). We discarded the 56 antibody&#x02013;antigen complexes plus the complexes involving more than two chains and worked on the remaining 142 dimers. As described in <xref rid="btac759-B31" ref-type="bibr">Renaud <italic toggle="yes">et al.</italic> (2021)</xref>, we generated 25&#x000a0;300 models per complex using our integrative modeling software HADDOCK (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Information</xref>). The overall dataset comprises 3&#x000a0;592&#x000a0;600 models and is available from the SBGrid data repository <ext-link xlink:href="https://data.sbgrid.org/dataset/843/" ext-link-type="uri">https://data.sbgrid.org/dataset/843/</ext-link>.</p><p>We performed 10-fold cross-validation in which the training and the evaluation sets change over the folds while the test set remains constant. The test set consists of all docking models generated for 15 randomly selected complexes (379&#x000a0;500 models, 10% of the dataset, see <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S2</xref>). Each fold consists of 10% of the docking models per remaining complex without any models overlap between folds. Their composition preserves the distribution of CAPRI iRMSD classes (<xref rid="btac759-B19" ref-type="bibr">Lensink <italic toggle="yes">et al.</italic>, 2007</xref>) (reporting on the quality of the models) per complex. This was achieved using sklearn StratifiedKFold tool. The 127 complexes not included in the test set are then split into a training (80%, i.e. 102 complexes, 258&#x000a0;060 models) and an evaluation set (20%, i.e. 25 complexes, 63&#x000a0;250 models per fold). The detailed content of each fold&#x02019;s training and evaluation set is provided in our GitHub repository. A number of complexes displaying important clashes could not be converted into graphs.</p></sec><sec><title>2.2.2 CAPRI benchmark</title><p>The CAPRI score set (<xref rid="btac759-B22" ref-type="bibr">Lensink and Wodak, 2014</xref>) was used as an external test set. It consists of 13 protein dimers for a total of 16&#x000a0;666 models generated by over 40 different research teams using a variety of software. It is acknowledged as the most diverse set of docking models with targets of different complexity.</p><p>The HADDOCK (<xref rid="btac759-B40" ref-type="bibr">van Zundert <italic toggle="yes">et al.</italic>, 2016</xref>), iScore (<xref rid="btac759-B12" ref-type="bibr">Geng <italic toggle="yes">et al.</italic>, 2020</xref>), DOVE (<xref rid="btac759-B38" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2020</xref>) and DeepRank scores were computed on the CAPRI score set as described in <xref rid="btac759-B31" ref-type="bibr">Renaud <italic toggle="yes">et al.</italic>, 2021</xref>. Deeprank and DOVE are two CNN-based scoring approaches, iScore is graph-kernel based, and HADDOCK uses a classic scoring function that consists of a linear combination of energy terms (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Information</xref>). These scores for the BM5 and CAPRI score sets were obtained from the DeepRank paper (<xref rid="btac759-B31" ref-type="bibr">Renaud <italic toggle="yes">et al.</italic>, 2021</xref>) and can be downloaded from: <ext-link xlink:href="https://data.sbgrid.org/dataset/843/" ext-link-type="uri">https://data.sbgrid.org/dataset/843/</ext-link>.</p></sec><sec><title>2.2.3 Graph generation and target value computation</title><p>PPI interfaces were converted into graphs using the default DeepRank-GNN parameters, default nodes features (residue type, polarity, charge and BSA) and edge feature (distance) and additional PSSM information (PSSM profile, PSSM information content and PSSM conservation score). The PSSM information of each individual protein was downloaded from 3D CONS, by querying the unbound PDB structure of each complex's partners. 3D CONS PSSM matrices are computed using the iterative BLAST algorithm (PSIBLAST) on each chain of a PDB file. By providing a reference structure of the complex, i.e. an experimentally solved bound conformation, DeepRank-GNN automatically computes the fraction of native contacts (<italic toggle="yes">f</italic><sub>nat</sub>) that we used as the target value). As compared to the interface RMSD (iRMSD) or ligand RMSD (lRMSD) values, the <italic toggle="yes">f</italic><sub>nat</sub> value is capped between 0 and 1, thus giving the same weight to all bad quality models. For instance, two models very distant from the reference structure will be assigned a 0 <italic toggle="yes">f</italic><sub>nat</sub> value while they can be assigned very distinct iRMSD values (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S2</xref>), which can uselessly influence the network parameters optimization. In addition, the <italic toggle="yes">f</italic><sub>nat</sub> is less sensitive to the local motion at the interface of two proteins than the RMSD and is therefore more adapted to evaluate the quality of an interface.</p></sec><sec><title>2.2.4 Network</title><p>We introduce here a GNN architecture, dubbed graph interaction network (GINet), whose general structure is represented in <xref rid="btac759-F1" ref-type="fig">Figure&#x000a0;1B</xref> and detailed in <xref rid="sup1" ref-type="supplementary-material">Supplementary Information</xref>. As seen in this figure GINets are composed of a succession of graph convolution layers (GCL), non-linear activation (here ReLU) and pooling layers. Two distinct GCLs are applied at each convolution step. One GCL is applied on interface graphs, i.e. graphs with edges connecting nodes from distinct proteins, and a distinct GCL is used on internal graphs, i.e. graphs with edges connecting nodes from the same protein. The rationale behind this architecture is to extract information not only on the interaction itself but also on the propensity of each individual interface to establish an interaction.</p></sec><sec><title>2.2.5 Training</title><p>The network was trained over 20 epochs on batches of 128 shuffled graphs. We used the mean square error loss (MSE loss) function using the <italic toggle="yes">f</italic><sub>nat</sub> values as the ground truth and the Adam algorithm (<xref rid="btac759-B17" ref-type="bibr">Kingma and Ba, 2017</xref>) with a learning rate of 0.001 to minimize the loss. A complete epoch (23&#x000a0;500 3D models) required 2.4 <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mo>&#x000b1;</mml:mo></mml:math></inline-formula> 0.9&#x02009;h on 1 GPU (GeForce GTX 1080 Ti).</p></sec><sec><title>2.2.6 Metrics computation</title><p>The area under the ROC curve (AUC), the hit rate and the success rate are computed to evaluate the performance of the scoring functions. To meet the requirement of these metrics that evaluate the discriminating ability of a binary classifier, we binarized the <italic toggle="yes">f</italic><sub>nat</sub> data using a 0.3 threshold: docking models with a <italic toggle="yes">f</italic><sub>nat</sub><inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mo>&#x02265;</mml:mo><mml:mn>0.3</mml:mn><mml:mi mathvariant="normal">&#x000a0;</mml:mi></mml:math></inline-formula>are considered to be of acceptable quality, while those with a <italic toggle="yes">f</italic><sub>nat</sub> &#x0003c; 0.3 are considered non-acceptable. This threshold differs from the CAPRI standard <italic toggle="yes">f</italic><sub>nat</sub> &#x02018;acceptable&#x02019; quality threshold of 0.1 that is combined with additional iRMSD and lRMSD criteria (<xref rid="btac759-B19" ref-type="bibr">Lensink <italic toggle="yes">et al.</italic>, 2007</xref>). Herein, since no RMSD values are considered, we raised the acceptance threshold to the equivalent of the CAPRI standard <italic toggle="yes">f</italic><sub>nat</sub> &#x02018;medium&#x02019; quality threshold of 0.3 to avoid misclassifying poor quality models (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S1</xref>).</p><p>The ROC curve is defined as the fraction of true positive rate (TPR) as a function of the fraction false positive rate while navigating through the ranking provided by the scoring function. The AUC is the integral of the ROC curve and is equal to 1 for an ideal classifier and 0.5 for a random classifier. The hitrate is defined as the percentage of hits retrieved within the top <italic toggle="yes">N</italic> ranks. The success rate is the number of complexes for which at least one acceptable quality model is retrieved within the top <italic toggle="yes">N</italic>.</p></sec></sec><sec><title>2.3 Application 2</title><sec><title>2.3.1 MANY/DC benchmark</title><p>The MANY (<xref rid="btac759-B2" ref-type="bibr">Baskaran <italic toggle="yes">et al.</italic>, 2014</xref>) and the DC (<xref rid="btac759-B5" ref-type="bibr">Duarte <italic toggle="yes">et al.</italic>, 2012</xref>) datasets contain biological and crystal dimers, in balanced proportions (&#x0223c;50%/50%), the latter being the consequence of crystal packing. The crystal dimers are indistinguishable from the biologic ones without a consistent knowledge of the complex. While the surface of biological interfaces is often larger than those of reported crystal dimers in different datasets, the DC dataset has been tuned to include biological and crystal dimers of comparable interface area. Herein, we used 80% of the MANY dataset (4591 dimers) to train our model and 20% (1148 dimers) to evaluate it. The retained model, i.e. the one displaying the minimum loss on the training set, was further tested on the DC dataset (161 dimers). All datasets are available from the SBGrid data repository <ext-link xlink:href="https://data.sbgrid.org/dataset/843/" ext-link-type="uri">https://data.sbgrid.org/dataset/843/</ext-link>.</p></sec><sec><title>2.3.2 Graph generation and network architecture</title><p>The PPI interfaces were converted into residue graphs and each node was assigned PSSM information only (i.e. 20 features per node). The PSSM matrices from the DeepRank paper (<xref rid="btac759-B31" ref-type="bibr">Renaud <italic toggle="yes">et al.</italic>, 2021</xref>) were used. The exact same network architecture as described in Application 1 was used.</p></sec><sec><title>2.3.3 Training</title><p>The network was trained over 50 epochs on batches of 128 shuffled graphs. We used the cross-entropy loss function using the biological (1)/crystal (0) annotations as the ground truth and the Adam algorithm (<xref rid="btac759-B17" ref-type="bibr">Kingma and Ba, 2017</xref>) with a learning rate of 0.001 to minimize the loss. A complete epoch (5739 3D models) required 1&#x02009;min on 1 GPU (GeForce GTX 1080 Ti).</p></sec><sec><title>2.3.4 Metrics computation</title><p>For this binary classification problem, we computed the accuracy, the specificity, the sensitivity and the precision to evaluate the performance of the DeepRank-GNN model.</p></sec></sec></sec><sec><title>3 Results</title><sec><title>3.1 Application 1&#x02014;the scoring of docking models</title><p>Docking is an <italic toggle="yes">in silico</italic> modeling approach commonly used to predict the 3D structure of biomolecular complexes. Docking involves two steps: The sampling, i.e. the exploration of the conformational interaction space to generate 3D models, and the scoring that aims to identify near-native models out of the pool of generated docking models. As illustrated by the Critical Assessment of PRedicted Interactions (CAPRI) initiative that frequently proposes blind predictions of experimentally determined 3D structures of protein complexes, there is still room for scoring functions improvement (<xref rid="btac759-B20" ref-type="bibr">Lensink <italic toggle="yes">et al.</italic>, 2016</xref>, <xref rid="btac759-B21" ref-type="bibr">2021</xref>). Most scoring functions can be classified into physical energy-based, statistical potential-based and machine learning-based functions. They are constantly explored for improvement to either propose system-specific or broad-spectra scoring tools, which in some cases are also used to predict changes in binding affinities (<xref rid="btac759-B11" ref-type="bibr">Geng <italic toggle="yes">et al.</italic>, 2019</xref>).</p><p>Here, we demonstrate the use of DeepRank-GNN to score docking models of various complexes generated with a variety of docking software.</p><sec><title>3.1.1 Performance of 10-fold cross-validation on the BM5</title><p>Ten-fold cross-validation was performed to analyze the performance and robustness of DeepRank-GNN on the task of scoring docking models. For each fold, we trained our model on the BM5 data set using 258 060 docking structures from 102 distinct complexes (see Section 2). The trained GINet models were validated on 63 250 docking structures from 25 complexes (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S3</xref>). For each fold, we retained the generated model that minimizes the most the loss value on the evaluation set and evaluated its performance on the BM5 test set that consists of 375&#x000a0;700 docking structures from 15 complexes (described in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>). As shown in <xref rid="btac759-F2" ref-type="fig">Fig.&#x000a0;2</xref>, when defining positive docking models as those associated to a <italic toggle="yes">f<sub>nat</sub></italic> &#x02265; 0.3 and averaging the TPR over the number of BM5 test complexes, most GINet models globally perform equally or better than the HADDOCK scoring function for 8 out of 10 DeepRank-GNN models, yielding an AUC &#x02265; 0.95 on the test set. We however notice a variation in the performance depending on the data subset used for the training and the evaluation of the models, which is particularly clear when we consider not only the complex-averaged TPR but also the standard deviation (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S3</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S5</xref>) and the hit rates obtained on individual complexes (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S6</xref>), highlighting the dataset dependency of DeepRank-GNN performance. Among all DeepRank-GNN models, the highest performance is reached with the one generated in the fold6 (AUC&#x02009;=&#x02009;0.97&#x02009;&#x000b1;&#x02009;0.03). When training on all data (i.e. data from all folds), an AUC of 0.94&#x02009;&#x000b1;&#x02009;0.06 is obtained. This last model was used to further assess the performances of DeepRank-GNN. To ease the comparison with other software, we provide a similar analysis using the standard CAPRI acceptable threshold instead of the <italic toggle="yes">f</italic><sub>nat</sub> in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S4</xref>.</p><fig position="float" id="btac759-F2"><label>Fig. 2.</label><caption><p>Comparison of DeepRank-GNN with HADDOCK scoring function on the BM5 set. Average ROC curves obtained with the models retained for each DeepRank-GNN fold, for the model trained on the full training set and HADDOCK score. A true positive case corresponds to a complex with <italic toggle="yes">f</italic><sub>nat</sub> &#x0003e; 0.3 correctly predicted. The number of true positive rate values is averaged over the number of complexes in the test dataset. The dashed line represents a random classifier</p></caption><graphic xlink:href="btac759f2" position="float"/></fig></sec><sec><title>3.1.2 Rank correlation</title><p>Since rank correlation is a good indicator of the predictiveness of a score, we computed the Spearman <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mo>&#x003c1;</mml:mo></mml:math></inline-formula> correlation between the <italic toggle="yes">f</italic><sub>nat</sub> and the DeepRank-GNN scores obtained with the GINet model trained on the full dataset on the entire test set. We observe an average Spearman <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mo>&#x003c1;</mml:mo></mml:math></inline-formula> correlation of 0.49&#x02009;&#x000b1;&#x02009;0.14, the highest correlation being obtained for 1PPE (<inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mo>&#x003c1;</mml:mo></mml:math></inline-formula> = 0.63), the lowest for 2OZA (<inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mo>&#x003c1;</mml:mo><mml:mo>=</mml:mo><mml:mn>0.14</mml:mn></mml:math></inline-formula>) (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S7</xref>). Interestingly, 1PPE constitutes an <italic toggle="yes">easy</italic> case with 11.5% of good docking models (<italic toggle="yes">f</italic><sub>nat</sub><inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mo>&#x02265;</mml:mo><mml:mn>0.3</mml:mn></mml:math></inline-formula>) generated, while 2OZA constitutes a more difficult case with 4.7%. Overall, we observe a good ability to identify near-native models in the top-ranked model with impressive success rates of 66.7% (7, 12 and 14 over 15 test complexes) at top1, top5 and top10 and 73.3% at top50.</p><p>The performance considerably increases when considering only the HADDOCK refined models (i.e. it1 and itw models as defined in <xref rid="sup1" ref-type="supplementary-material">Supplementary Information</xref>) of the test set with an average Spearman correlation of 0.69&#x02009;&#x000b1;&#x02009;0.23, the highest correlation being obtained for 1PPE (<inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mo>&#x003c1;</mml:mo></mml:math></inline-formula> = 0.89), the lowest for 1F6M (<inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mo>&#x003c1;</mml:mo><mml:mo>=</mml:mo><mml:mn>0.02</mml:mn></mml:math></inline-formula>) (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S8</xref>). Here again, 1F6M constitutes a difficult case with 102 good models in the entire pool of docking models, 100 of them consisting in refined structure of the bound complex and representing very low diversity in the binding mode. The success rate is similar to the one on the entire set with 66.7% (10 over 15 test complexes) at top1, top5 and top10 and 93.3 at top50. In both scenarios, success rates of 46.7, 66.7 and 80% (7, 10 and 12 over 15) are obtained with HADDOCK scores for the top1, top5 and top10, respectively (<xref rid="btac759-T2" ref-type="table">Table&#x000a0;2</xref>). For convenience, a similar analysis using the classic CAPRI labels is provided in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S9</xref>.</p><table-wrap position="float" id="btac759-T2"><label>Table 2.</label><caption><p>AUC and success rates of HADDOCK and DeepRank-GNN (trained on the full training set) on the BM5 test dataset when considering HADDOCK refined models only</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col valign="top" align="left" span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="center" span="1"/><col valign="top" align="char" char="." span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1">AUC</th><th colspan="4" align="center" rowspan="1">Success rates (%)<hr/></th></tr><tr><th align="center" rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1">Top 1</th><th align="center" rowspan="1" colspan="1">Top 5</th><th align="center" rowspan="1" colspan="1">Top 10</th><th align="center" rowspan="1" colspan="1">Top50</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">DeepRank-GNN</td><td rowspan="1" colspan="1">0.85&#x02009;&#x000b1;&#x02009;0.16</td><td rowspan="1" colspan="1">
<bold>66.7</bold>
</td><td rowspan="1" colspan="1">66.7</td><td rowspan="1" colspan="1">66.7</td><td rowspan="1" colspan="1">
<bold>93.3</bold>
</td></tr><tr><td rowspan="1" colspan="1">HADDOCK</td><td rowspan="1" colspan="1">0.85</td><td rowspan="1" colspan="1">46.7</td><td rowspan="1" colspan="1">66.7</td><td rowspan="1" colspan="1">
<bold>80</bold>
</td><td rowspan="1" colspan="1">86.7</td></tr></tbody></table><table-wrap-foot><fn id="tblfn1"><p>The bold values indicate the best value for each column.</p></fn></table-wrap-foot></table-wrap></sec><sec><title>3.1.3 Comparison to external software on the CAPRI score test set</title><p>We evaluated the performance of DeepRank-GNN, DeepRank, DOVE, HADDOCK and iScore on the CAPRI score set. DeepRank and DOVE are two CNN-based scoring approaches, iScore is graph-kernel based, and HADDOCK uses a classic scoring function that consists of a linear combination of energy terms. The CAPRI score set consists of 13 complexes for which 497 to 1987 models have been generated by different groups using a wide diversity of docking tools and protocols (<xref rid="btac759-B22" ref-type="bibr">Lensink and Wodak, 2014</xref>). When considering the AUC DeepRank-GNN stands on top together with iScore with an average AUC of 0.71 and 0.64, respectively (<xref rid="btac759-T3" ref-type="table">Table&#x000a0;3</xref>). However, in terms of early enrichments (success rate of top <italic toggle="yes">N</italic> models for N&#x02009;&#x02264;&#x02009;5), iScore scores best followed by HADDOCK and GNN-DOVE (<xref rid="btac759-T3" ref-type="table">Table&#x000a0;3</xref>). Note that among these three tools, iScore and GNN-DOVE are using graph representations.</p><table-wrap position="float" id="btac759-T3"><label>Table 3.</label><caption><p>Comparison of the performance obtained on the CAPRI Scoreset</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col valign="top" align="left" span="1"/><col valign="top" align="center" span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1">AUC</th><th colspan="4" align="center" rowspan="1">Success rates (%)<hr/></th></tr><tr><th align="center" rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1">Top 1</th><th align="center" rowspan="1" colspan="1">Top 2</th><th align="center" rowspan="1" colspan="1">Top 5</th><th align="center" rowspan="1" colspan="1">Top100</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">iScore</td><td rowspan="1" colspan="1">0.64&#x02009;&#x000b1;&#x02009;0.29</td><td rowspan="1" colspan="1">
<bold>38.5</bold>
</td><td rowspan="1" colspan="1">
<bold>46.2</bold>
</td><td rowspan="1" colspan="1">46.2</td><td rowspan="1" colspan="1">
<bold>76.9</bold>
</td></tr><tr><td rowspan="1" colspan="1">DOVE</td><td rowspan="1" colspan="1">0.48&#x02009;&#x000b1;&#x02009;0.22</td><td rowspan="1" colspan="1">7.7</td><td rowspan="1" colspan="1">7.7</td><td rowspan="1" colspan="1">15.4</td><td rowspan="1" colspan="1">
<bold>76.9</bold>
</td></tr><tr><td rowspan="1" colspan="1">GNN-DOVE</td><td rowspan="1" colspan="1">0.54&#x02009;&#x000b1;&#x02009;0.23</td><td rowspan="1" colspan="1">15.4</td><td rowspan="1" colspan="1">30.8</td><td rowspan="1" colspan="1">
<bold>53.8</bold>
</td><td rowspan="1" colspan="1">
<bold>76.9</bold>
</td></tr><tr><td rowspan="1" colspan="1">DeepRank</td><td rowspan="1" colspan="1">0.59&#x02009;&#x000b1;&#x02009;0.28</td><td rowspan="1" colspan="1">15.4</td><td rowspan="1" colspan="1">15.4</td><td rowspan="1" colspan="1">15.4</td><td rowspan="1" colspan="1">69.2</td></tr><tr><td rowspan="1" colspan="1">DeepRank-GNN</td><td rowspan="1" colspan="1">
<bold>0.71&#x02009;&#x000b1;&#x02009;0.24</bold>
</td><td rowspan="1" colspan="1">7.7</td><td rowspan="1" colspan="1">23.1</td><td rowspan="1" colspan="1">38.5</td><td rowspan="1" colspan="1">
<bold>76.9</bold>
</td></tr><tr><td rowspan="1" colspan="1">HADDOCK</td><td rowspan="1" colspan="1">0.55&#x02009;&#x000b1;&#x02009;0.27</td><td rowspan="1" colspan="1">23.1</td><td rowspan="1" colspan="1">23.1</td><td rowspan="1" colspan="1">23.1</td><td rowspan="1" colspan="1">69.2</td></tr></tbody></table><table-wrap-foot><fn id="tblfn2"><p>
<italic toggle="yes">Note</italic>: A true positive case corresponds to a complex with <italic toggle="yes">f</italic><sub>nat</sub> &#x0003e; 0.3 correctly predicted. To ease the comparison with other software we provide a figure using the standard CAPRI acceptable threshold instead of the <italic toggle="yes">f</italic><sub>nat</sub> in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S9</xref>.</p></fn></table-wrap-foot></table-wrap></sec><sec><title>3.1.4 Computational performance</title><p>The graph representation of the interface not only provides a natural way of representing PPI interfaces, but it also considerably improves the computation performance in terms of storage, data generation and learning speed as compared to the use of grids and CNN. To quantify it, we compared the graph generation step of DeepRank-GNN to the grid generation step of DeepRank on the CAPRI score set (<xref rid="sup1" ref-type="supplementary-material">Supplementary Tables S4&#x02013;S6</xref>) as well as each protocol&#x02019;s training speed (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S7</xref>) using MPI distributed processes on 4 CPUs. The results show that the graph generation is on average 20 times faster than the 3D grid generation in CNN (0.65&#x02009;&#x000b1;&#x02009;0.31 versus 12.4&#x02009;&#x000b1;&#x02009;3.3&#x02009;second per model) and requires &#x0223c;22 times less storage space (0.14&#x02009;&#x000b1;&#x02009;0.1 versus 3.07&#x02009;&#x000b1;&#x02009;0.4 MB per model). It is worth noting that default settings were used for each approach and that DeepRank computes additional atomic-level descriptors leading to a total of 72 descriptors against 48 in DeepRank-GNN (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S8</xref>). To fairly compare the computation performance in the training phase, we retained comparable residue-level features for the two protocols corresponding to 48 and 58 features for DeepRank-GNN and DeepRank respectively, and split the CAPRI score set into 80% training and 20% evaluation sets. We trained the GINet model of DeepRank-GNN described in section 3.1 and the default 3D-CNN implemented in DeepRank over 10 epochs. The results show a remarkable speed difference, DeepRank-GNN being &#x0223c;25 times faster than DeepRank when no data augmentation is used in the latter (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S7</xref>).</p></sec></sec><sec><title>3.2. Application 2&#x02014;biological versus crystal interfaces classification</title><p>X-ray crystallography is, as per 2022, the most used experimental method to solve the 3D structure of proteins. Despite most X-ray structures being reliable and of high quality, it is not rare to obtain erroneous structures. Among the common errors are the incorrect residues fitting into the electron density maps and the observation of artificial oligomers due to crystal packing. The latter can lead to dramatically wrong conclusions and mislead researchers in their study. It is therefore essential to provide tools to annotate crystallographic dimers as reliable (i.e. biological) or not (crystal).</p><p>In this section, we evaluate the performance of DeepRank-GNN in discriminating biological and crystal interfaces from the DC dataset.</p><sec><title>3.2.1 DeepRank-GNN classification performances</title><p>Deeprank-GNN was trained and evaluated on 5739 dimers from the MANY dataset, with 80% of the dimers constituting the training set and 20% the validation set. The network was trained over 50 epochs and we retained the model minimizing the loss on the evaluation set. This model was further tested on the DC dataset that contains 80 biological and 81 crystal interfaces with comparable interface areas. We observe interesting performance with an accuracy of 82%, a specificity of 81%, a sensitivity of 83% and a precision of 82%. Note that 11 structures overlap between the DC and the MANY datasets and that removing them only slightly affects the performances (accuracy: 81%, specificity: 82%, sensitivity: 79.2%, precision: 80.3%).</p></sec><sec><title>3.2.2 Comparison to external software</title><p>We recently evaluated and published the performance of the non-commercial software PISA, PRODIGY-crystal and DeepRank on the DC dataset. The DeepRank-GNN model that we present here ranks second in terms of accuracy (82%) behind DeepRank (86%) and ahead of PISA (79%) and PRODIGY-CRYSTAL (74%) (<xref rid="btac759-T4" ref-type="table">Table&#x000a0;4</xref>).</p><table-wrap position="float" id="btac759-T4"><label>Table 4.</label><caption><p>Comparison of the accuracy obtained on the biological versus crystal interfaces classification task</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col valign="top" align="left" span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="center" span="1"/><col valign="top" align="char" char="." span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1">PISA</th><th rowspan="1" colspan="1">PRODIGY-Crystal</th><th rowspan="1" colspan="1">DeepRank</th><th rowspan="1" colspan="1">DeepRank-GNN</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">Accuracy (%)</td><td rowspan="1" colspan="1">79</td><td rowspan="1" colspan="1">74</td><td rowspan="1" colspan="1">
<bold>86</bold>
</td><td rowspan="1" colspan="1">82</td></tr></tbody></table></table-wrap></sec></sec></sec><sec><title>4 Conclusion</title><p>We have developed DeepRank-GNN, a new computational framework to learn and predict interaction patterns from protein&#x02013;protein interfaces. DeepRank-GNN is provided as a freely accessible python3 package (<ext-link xlink:href="https://github.com/DeepRank/DeepRank-GNN" ext-link-type="uri">https://github.com/DeepRank/DeepRank-GNN</ext-link>). The framework encompasses pre-processing tools that take PPI PDB files as input, converts the interface of interaction into residue-level graphs and automatically assigns biologically relevant features to the graphs. In the second step, the graphs can be used to train, evaluate and test a provided or user-defined GNN to make problem-specific predictions. DeepRank-GNN has been designed to be applied to various PPI-related projects and offers the users many options such as the possibility to select features, to use any type of target values, to reweight the scoring functions for classification tasks, to design their own GNN architecture etc.</p><p>As a demonstration, we applied DeepRank-GNN to the task of scoring docking models of various complexes from the Docking Benchmark 5 (BM5) and the CAPRI score set. The trained models (one per fold) globally display a data dependency, yet most of them compete with- or outperform the HADDOCK scoring function. The scoring performance of a model trained on the entire training set was further evaluated on the independent CAPRI score set and compared to HADDOCK, DeepRank, DOVE, GNN-DOVE and iScore. DeepRank-GNN and iScore rank 1st and 2nd in this task in terms of AUC, iSCore showing better early enrichment. Interestingly, among all scoring functions mentioned in this work, DeepRank-GNN is the only one that does not contain energy terms, highlighting that simple geometric and physico-chemical properties could be as informative as (or more than) the approximative energy terms used in most scoring functions. Further optimization of the hyperparameters of the GINet or the design and application of new GNNs could help improve the performance observed here.</p><p>We also trained a DeepRank-GNN network to discriminate biological interfaces from crystal interfaces. In this task, we obtained an accuracy of 82%, competitive with the state-of-the-art methods DeepRank (86%), PISA (79%) and PRODIGY-crystal (74%). The graph generation plus the DeepRank-GNN model training, evaluation and test were performed in less than 2&#x02009;h.</p><p>Overall, DeepRank-GNN is a versatile software that should help the community learn patterns from protein&#x02013;protein interfaces in a time-efficient manner. We present a single GNN architecture in this article that can be reused as such or derived and replaced. The DeepRank framework offers many perspectives of extension such as the application to single proteins (e.g. for genetic variant pathogenicity prediction), to larger multimeric states (e.g. for larger complex quality prediction), or the integration of other GNN architectures such as the E(n)-equivariant graph neural networks to run molecular dynamics simulations.</p></sec><sec sec-type="supplementary-material"><title>Supplementary Material</title><supplementary-material id="sup1" position="float" content-type="local-data"><label>btac759_Supplementary_Data</label><media xlink:href="btac759_supplementary_data.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><sec><title>Funding</title><p>The work was supported by an ASDI grant from the Netherlands eScience Center [ASDI.2016.043]; a SURF Open Lab &#x02018;Machine learning enhanced HPC applications&#x02019; [AB/AM/10573]; a &#x02018;Computing Time on National Computer Facilities&#x02019; [2018/ENW/00485366] from the Netherlands Organization for Scientific Research (NWO); the European Union Horizon 2020 project BioExcel [823830] and from a TOP-PUNT [718.015.001] to M.R. and A.M.J.J.B.; a Hypatia Fellowship from Radboudumc [Rv819.52706 to L.C.X.].</p><p>
<italic toggle="yes">Conflict of Interest</italic>: The authors have no conflict of interest to declare.</p></sec><sec><title>Software availability</title><p>The software is available on Github (<ext-link xlink:href="https://github.com/DeepRank/Deeprank-GNN" ext-link-type="uri">https://github.com/DeepRank/Deeprank-GNN</ext-link>) and the documentation is available online (<ext-link xlink:href="https://deeprank-gnn.readthedocs.io/" ext-link-type="uri">https://deeprank-gnn.readthedocs.io/</ext-link>). The models mentioned in the article, the content of the BM5 dataset, and the target and the predicted values for the BM5, CAPRI and DC test set are provided on GitHub (<ext-link xlink:href="https://github.com/DeepRank/Deeprank-GNN/tree/master/paper_pretrained_models" ext-link-type="uri">https://github.com/DeepRank/Deeprank-GNN/tree/master/paper_pretrained_models</ext-link>).</p></sec><sec sec-type="data-availability"><title>Data availability</title><p>The BM5 and CAPRI score set docking models are obtained from the DeepRank paper (<xref rid="btac759-B31" ref-type="bibr">Renaud <italic toggle="yes">et al.</italic>, 2021</xref>) and can be downloaded from: <ext-link xlink:href="https://data.sbgrid.org/dataset/843/" ext-link-type="uri">https://data.sbgrid.org/dataset/843/</ext-link>.</p></sec><ref-list id="ref1"><title>References</title><ref id="btac759-B1"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Baldassarre</surname>
<given-names>F.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2021</year>) <article-title>GraphQA: protein model quality assessment using graph convolutional networks</article-title>. <source>Bioinformatics</source>, <volume>37</volume>, <fpage>360</fpage>&#x02013;<lpage>366</lpage>.<pub-id pub-id-type="pmid">32780838</pub-id></mixed-citation></ref><ref id="btac759-B2"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Baskaran</surname>
<given-names>K.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2014</year>) <article-title>A PDB-wide, evolution-based assessment of protein-protein interfaces</article-title>. <source>BMC Struct. Biol</source>., <volume>14</volume>, <fpage>22</fpage>.<pub-id pub-id-type="pmid">25326082</pub-id></mixed-citation></ref><ref id="btac759-B4"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Cao</surname>
<given-names>Y.</given-names>
</string-name>, <string-name><surname>Shen</surname><given-names>Y.</given-names></string-name></person-group> (<year>2020</year>) <article-title>Energy-based graph convolutional networks for scoring protein docking models</article-title>. <source>Proteins: Struct., Funct. Bioinformatics</source>, <volume>88</volume>, <fpage>1091</fpage>&#x02013;<lpage>1099</lpage>.</mixed-citation></ref><ref id="btac759-B5"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Duarte</surname>
<given-names>J.M.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2012</year>) <article-title>Protein interface classification by evolutionary analysis</article-title>. <source>BMC Bioinformatics</source>, <volume>13</volume>, <fpage>334</fpage>.<pub-id pub-id-type="pmid">23259833</pub-id></mixed-citation></ref><ref id="btac759-B8"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Fout</surname>
<given-names>A.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2017</year>) Protein interface prediction using graph convolutional networks. In: <italic toggle="yes">Advances in Neural Information Processing Systems</italic>, Long Beach Conference Center, Los Angeles, USA.</mixed-citation></ref><ref id="btac759-B9"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Francoeur</surname>
<given-names>P.G.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2020</year>) <article-title>Three-dimensional convolutional neural networks and a cross-docked data set for structure-based drug design</article-title>. <source>J. Chem. Inf. Model</source>., <volume>60</volume>, <fpage>4200</fpage>&#x02013;<lpage>4215</lpage>.<pub-id pub-id-type="pmid">32865404</pub-id></mixed-citation></ref><ref id="btac759-B10"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Gainza</surname>
<given-names>P.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2020</year>) <article-title>Deciphering interaction fingerprints from protein molecular surfaces using geometric deep learning</article-title>. <source>Nat. Methods</source>, <volume>17</volume>, <fpage>184</fpage>&#x02013;<lpage>192</lpage>.<pub-id pub-id-type="pmid">31819266</pub-id></mixed-citation></ref><ref id="btac759-B11"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Geng</surname>
<given-names>C.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2019</year>) <article-title>Finding the &#x00394;&#x00394;G spot: are predictors of binding affinity changes upon mutations in protein&#x02013;protein interactions ready for it?</article-title><source>WIREs Comput. Mol. Sci</source>., <volume>9</volume>, <fpage>e1410</fpage>.</mixed-citation></ref><ref id="btac759-B12"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Geng</surname>
<given-names>C.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2020</year>) <article-title>iScore: a novel graph kernel-based function for scoring protein-protein docking models</article-title>. <source>Bioinformatics</source>, <volume>36</volume>, <fpage>112</fpage>&#x02013;<lpage>121</lpage>.<pub-id pub-id-type="pmid">31199455</pub-id></mixed-citation></ref><ref id="btac759-B1200"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Hagberg</surname>
<given-names>A.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2008</year>) <italic toggle="yes">Exploring network structure, dynamics, and function using networkx</italic>. <ext-link xlink:href="https://www.osti.gov/servlets/purl/960616" ext-link-type="uri">https://www.osti.gov/servlets/purl/960616</ext-link>.</mixed-citation></ref><ref id="btac759-B13"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Igashov</surname>
<given-names>I.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2021</year>) <article-title>VoroCNN: deep convolutional neural network built on 3D voronoi tessellation of protein structures</article-title>. <source>Bioinformatics</source>, <volume>37</volume>, <fpage>2332</fpage>&#x02013;<lpage>2339</lpage>.</mixed-citation></ref><ref id="btac759-B14"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Jim&#x000e9;nez</surname>
<given-names>J.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2018</year>) <article-title>KDEEP: protein&#x02013;ligand absolute binding affinity prediction via 3D-Convolutional neural networks</article-title>. <source>J. Chem. Inf. Model</source>., <volume>58</volume>, <fpage>287</fpage>&#x02013;<lpage>296</lpage><pub-id pub-id-type="pmid">29309725</pub-id></mixed-citation></ref><ref id="btac759-B15"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Jumper</surname>
<given-names>J.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2021</year>) <article-title>Highly accurate protein structure prediction with AlphaFold</article-title>. <source>Nature</source>, <volume>596</volume>, <fpage>583</fpage>&#x02013;<lpage>589</lpage>.<pub-id pub-id-type="pmid">34265844</pub-id></mixed-citation></ref><ref id="btac759-B16"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Karlov</surname>
<given-names>D.S.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2020</year>) <article-title>graphDelta: MPNN scoring function for the affinity prediction of protein&#x02013;ligand complexes</article-title>. <source>ACS Omega</source>, <volume>5</volume>, <fpage>5150</fpage>&#x02013;<lpage>5159</lpage>.<pub-id pub-id-type="pmid">32201802</pub-id></mixed-citation></ref><ref id="btac759-B17"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Kingma</surname>
<given-names>D.P.</given-names>
</string-name>, <string-name><surname>Ba</surname><given-names>J.L.</given-names></string-name></person-group> (<year>2017</year>) Adam: a method for stochastic optimization. <italic toggle="yes">arXiv:1412.6980 [cs]</italic>. January 2017.</mixed-citation></ref><ref id="btac759-B18"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Krizhevsky</surname>
<given-names>A.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2017</year>) <article-title>ImageNet classification with deep convolutional neural networks</article-title>. <source>Commun. ACM</source>, <volume>60</volume>, <fpage>84</fpage>&#x02013;<lpage>90</lpage>.</mixed-citation></ref><ref id="btac759-B19"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Lensink</surname>
<given-names>M.F.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2007</year>) <article-title>Docking and scoring protein complexes: CAPRI 3rd edition</article-title>. <source>Proteins</source>, <volume>69</volume>, <fpage>704</fpage>&#x02013;<lpage>718</lpage>.<pub-id pub-id-type="pmid">17918726</pub-id></mixed-citation></ref><ref id="btac759-B20"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Lensink</surname>
<given-names>M.F.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2016</year>) <article-title>Prediction of homoprotein and heteroprotein complexes by protein docking and template-based modeling: a CASP-CAPRI experiment</article-title>. <source>Proteins: Struct., Funct., Bioinformatics</source>, <volume>84</volume>, <fpage>323</fpage>&#x02013;<lpage>348</lpage>.</mixed-citation></ref><ref id="btac759-B21"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Lensink</surname>
<given-names>M.F.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2021</year>) <article-title>Prediction of protein assemblies, the next frontier: the CASP14-CAPRI experiment</article-title>. <source>Proteins</source>, <volume>89</volume>, <fpage>1800</fpage>&#x02013;<lpage>1823</lpage>.<pub-id pub-id-type="pmid">34453465</pub-id></mixed-citation></ref><ref id="btac759-B22"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Lensink</surname>
<given-names>M.F.</given-names>
</string-name>, <string-name><surname>Wodak</surname><given-names>S.J.</given-names></string-name></person-group> (<year>2014</year>) <article-title>Score_set: a CAPRI benchmark for scoring protein complexes</article-title>. <source>Proteins: Struct., Funct. Bioinformatics</source>, <volume>82</volume>, <fpage>3163</fpage>&#x02013;<lpage>3169</lpage>.</mixed-citation></ref><ref id="btac759-B23"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Lu</surname>
<given-names>S.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2020</year>) <article-title>CDD/SPARCLE: the conserved domain database in 2020</article-title>. <source>Nucleic Acids Res</source>., <volume>48</volume>, <fpage>D265</fpage>&#x02013;<lpage>D268</lpage>.<pub-id pub-id-type="pmid">31777944</pub-id></mixed-citation></ref><ref id="btac759-B24"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Mahbub</surname>
<given-names>S.</given-names>
</string-name>, <string-name><surname>Bayzid</surname><given-names>Md.S.</given-names></string-name></person-group> (<year>2022</year>) EGRET: edge aggregated graph attention networks and transfer learning improve protein-protein interaction site prediction. <italic toggle="yes">Briefings in Bioinformatics</italic>, <volume>23</volume>, bbab578. <pub-id pub-id-type="doi">10.1093/bib/bbab578</pub-id>.</mixed-citation></ref><ref id="btac759-B25"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Mayr</surname>
<given-names>A.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2016</year>) <article-title>DeepTox: toxicity prediction using deep learning</article-title>. <source>Front. Environ. Sci</source>., <volume>3</volume>, 1&#x02013;15. <pub-id pub-id-type="doi">10.3389/fenvs.2015.00080</pub-id>.</mixed-citation></ref><ref id="btac759-B26"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Morrone</surname>
<given-names>J.A.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2020</year>) <article-title>Combining docking pose rank and structure with deep learning improves protein-ligand binding mode prediction</article-title>. <source>J. Chem. Inf. Model</source>., <volume>60</volume>, <fpage>4170</fpage>&#x02013;<lpage>4179</lpage>.<pub-id pub-id-type="pmid">32077698</pub-id></mixed-citation></ref><ref id="btac759-B7"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Paszke</surname>
<given-names>A.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2017</year>) Automatic differentiation in PyTorch. In: <italic toggle="yes">NIPS 2017 Autodiff Workshop</italic>, Long Beach Conference Center, Los Angeles, USA.</mixed-citation></ref><ref id="btac759-B27"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Pag&#x000e8;s</surname>
<given-names>G.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2019</year>) <article-title>Protein model quality assessment using 3D oriented convolutional neural networks</article-title>. <source>Bioinformatics</source>, <volume>35</volume>, <fpage>3313</fpage>&#x02013;<lpage>3319</lpage>.<pub-id pub-id-type="pmid">30874723</pub-id></mixed-citation></ref><ref id="btac759-B28"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Ragoza</surname>
<given-names>M.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2017</year>) <article-title>Protein&#x02013;ligand scoring with convolutional neural networks</article-title>. <source>J. Chem. Inf. Model</source>., <volume>57</volume>, <fpage>942</fpage>&#x02013;<lpage>957</lpage>.<pub-id pub-id-type="pmid">28368587</pub-id></mixed-citation></ref><ref id="btac759-B29"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>R&#x000e9;au</surname>
<given-names>M.</given-names>
</string-name>, <string-name><surname>Renaud</surname><given-names>N.</given-names></string-name></person-group> (<year>2021</year>) <italic toggle="yes">DeepRank/Deeprank-GNN: 0.1.4</italic>. Zenodo, November 2021.</mixed-citation></ref><ref id="btac759-B30"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Renaud</surname>
<given-names>N.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2020</year>) <italic toggle="yes">DeepRank/deeprank v0</italic>.<italic toggle="yes">1</italic>.<italic toggle="yes">0</italic>. Zenodo, March 2020.</mixed-citation></ref><ref id="btac759-B31"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Renaud</surname>
<given-names>N.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2021</year>) DeepRank: a deep learning framework for data mining 3D protein-protein interfaces. <italic toggle="yes">bioRxiv</italic>. 2021.01.29.425727, February 2021. doi: <pub-id pub-id-type="doi">10.1101/2021.01.29.425727</pub-id>.</mixed-citation></ref><ref id="btac759-B32"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Renaud</surname>
<given-names>N.</given-names>
</string-name>, <string-name><surname>Geng</surname><given-names>C.</given-names></string-name></person-group> (<year>2021a</year>) <italic toggle="yes">PSSMGen</italic>. Zenodo, February 2021.</mixed-citation></ref><ref id="btac759-B33"><mixed-citation publication-type="other">
<person-group person-group-type="author">
<string-name>
<surname>Renaud</surname>
<given-names>N.</given-names>
</string-name>, <string-name><surname>Geng</surname><given-names>C.</given-names></string-name></person-group> (<year>2021b</year>) The pdb2sql python package: parsing, manipulation and analysis of PDB files using SQL queries. Zenodo, March 2021.</mixed-citation></ref><ref id="btac759-B35"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Son</surname>
<given-names>J.</given-names>
</string-name>, <string-name><surname>Kim</surname><given-names>D.</given-names></string-name></person-group> (<year>2021</year>) <article-title>Development of a graph convolutional neural network model for efficient prediction of protein-ligand binding affinities</article-title>. <source>PLoS One</source>, <volume>16</volume>, <fpage>e0249404</fpage>.<pub-id pub-id-type="pmid">33831016</pub-id></mixed-citation></ref><ref id="btac759-B36"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Torng</surname>
<given-names>W.</given-names>
</string-name>, <string-name><surname>Altman</surname><given-names>R.B.</given-names></string-name></person-group> (<year>2019</year>) <article-title>Graph convolutional neural networks for predicting drug-target interactions</article-title>. <source>J. Chem. Inf. Model</source>., <volume>59</volume>, <fpage>4131</fpage>&#x02013;<lpage>4149</lpage>.<pub-id pub-id-type="pmid">31580672</pub-id></mixed-citation></ref><ref id="btac759-B37"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Vreven</surname>
<given-names>T.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2015</year>) <article-title>Updates to the integrated protein-protein interaction benchmarks: docking benchmark version 5 and affinity benchmark version 2</article-title>. <source>J. Mol. Biol</source>., <volume>427</volume>, <fpage>3031</fpage>&#x02013;<lpage>3041</lpage>.<pub-id pub-id-type="pmid">26231283</pub-id></mixed-citation></ref><ref id="btac759-B38"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Wang</surname>
<given-names>X.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2020</year>) <article-title>Protein docking model evaluation by 3D deep convolutional neural networks</article-title>. <source>Bioinformatics</source>, <volume>36</volume>, <fpage>2113</fpage>&#x02013;<lpage>2118</lpage>.<pub-id pub-id-type="pmid">31746961</pub-id></mixed-citation></ref><ref id="btac759-B39"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>Wang</surname>
<given-names>X.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2021</year>) <article-title>Protein docking model evaluation by graph neural networks</article-title>. <source>Front. Mol. Biosci</source>., <volume>8</volume>, <fpage>647915</fpage>.<pub-id pub-id-type="pmid">34113650</pub-id></mixed-citation></ref><ref id="btac759-B40"><mixed-citation publication-type="journal">
<person-group person-group-type="author">
<string-name>
<surname>van Zundert</surname>
<given-names>G.C.P.</given-names>
</string-name>
</person-group>
<etal>et al</etal> (<year>2016</year>) <article-title>The HADDOCK2.2 web server: user-friendly integrative modeling of biomolecular complexes</article-title>. <source>J. Mol. Biol</source>., <volume>428</volume>, <fpage>720</fpage>&#x02013;<lpage>725</lpage>.<pub-id pub-id-type="pmid">26410586</pub-id></mixed-citation></ref></ref-list></back></article>