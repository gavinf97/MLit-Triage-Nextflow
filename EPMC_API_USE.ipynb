{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning NLP notebook for idenitfying ML methods papers in life science jorunal \n",
    "## 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: stage1_papers_downloaded/article_5.xml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Preprocess DOME data & get insights from the literature data for use with developing ML lit triage model \n",
    "\n",
    "# 1. Import Necessary Libraries  \n",
    "# Ensures that all required NLP libraries (NLTK, SpaCy, Scikit-learn, etc.) are available.  \n",
    "\n",
    "# 2. Text Cleaning & Normalization  \n",
    "# ✔ Lowercasing (Step 1.1) → Enables case-insensitive matching.  \n",
    "# ✔ Text Normalization (Step 1.8, moved earlier) → Expands contractions, converts numbers, standardizes abbreviations.  \n",
    "\n",
    "# 3. Tokenization & Basic Cleaning  \n",
    "# ✔ Tokenization (Step 1.2) → Splits text into individual words or subwords.  \n",
    "# ✔ Removing Punctuation (Step 1.3) → Ensures proper word separation.  \n",
    "# ✔ Removing Stopwords (Step 1.4) → Eliminates commonly occurring but uninformative words.  \n",
    "\n",
    "# 4. Lemmatization & Stemming  \n",
    "# ✔ Lemmatization OR Stemming (Step 1.5) → Converts words to their root form.  \n",
    "# (Lemmatization is preferable for accuracy; stemming is faster but less precise.)  \n",
    "\n",
    "# 5. Feature Extraction (Reorganized for clarity)  \n",
    "# ✔ Part-of-Speech (POS) Tagging & Counts (Step 1.6.1)  \n",
    "# ✔ Named Entity Recognition (NER) (Step 1.6.2)  \n",
    "# ✔ Term Frequency - Inverse Document Frequency (TF-IDF) (Step 1.6.3)  \n",
    "# ✔ Word Embeddings (Word2Vec, GloVe, BERT, etc.) (Step 1.6.4 - remove “FREQUENCIES” since embeddings are dense vectors, not simple word counts.)  \n",
    "\n",
    "# 6. Vectorization (Final Step)  \n",
    "# ✔ TF-IDF OR Embeddings (Step 1.9) → Converts text into a numerical representation suitable for ML models.  \n",
    "# (Vectorization is technically part of feature extraction, so this step can be merged with 1.6 if preferred.)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify using ml ontology and others rleevant ML words not within - eg: model types etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive corpus example and negative\n",
    "\n",
    "# Positive \n",
    "\n",
    "# Negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Determine if wider corpus of ML papers needed - automatically find some papers and then also preprocess\n",
    "# could dtermine using text word mining\n",
    "#random papers form lit suggest or negatiev search of terms - eg noo model/ml etc \n",
    "#  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Preprocess all ML papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Download all papers mentioning machine learning and AI from EPMC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Deploy ML model to predict if a paper is about ML or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Analyse top papers and journals insights from the literature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
