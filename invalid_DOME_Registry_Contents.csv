publication_pmid,matches_optimization/algorithm,matches_model/availability,publication_journal,publication_authors,matches_evaluation/availability,publication_created,matches_model/interpretability,publication_title,matches_evaluation/comparison,publication_year,publication_doi,uuid,matches_dataset/splits,matches_publication/updated,publication_skip,matches_publication/doi,matches_evaluation/method,publication_updated,public,matches_model/duration,shortid,matches_evaluation/measure,matches_publication/journal,matches_publication/pmid,matches_publication/title,publication_done,matches_model/output,matches_optimization/meta,matches_optimization/parameters,created,matches_dataset/provenance,matches_optimization/fitting,matches_optimization/config,matches_publication/authors,matches_dataset/availability,updated,matches_dataset/redundancy,matches_optimization/regularization,matches_optimization/encoding,matches_publication/year,matches_evaluation/confidence,matches_optimization/features,_id,score
29181236,"The algorithm used is a supervised machine learning algorithm for classification.
-However, the exact model type not mentioned or clear.
-Text refers to the model used as 'ANRS', a computer based interpretation algorithm was built by the French ANRS (Agence Nationale de Recherches sur le SIDA; National Agency for AIDS Research). ANRS classifies ARV resistance according to three levels: susceptible, intermediate, and resistant. ‚ÄòSusceptible‚Äô indicates that a particular ARV drug will be effective against HIV; ‚Äòintermediate‚Äô indicates that the ARV drug is partially effective; and if the ARV is not effective at all, it is classified ‚Äòresistant‚Äô.
-Further online searches do not clearly yield information on this model.","None available or linked. No GitHub, code repository available.",Healthcare Informatics Research ,Yashik Singh,Not available.,,"Black box. Next to no required information for model interpretation available. No datasets, no code, no parameters, features, data splits. Even the exact model algorithm in use is unclear beyond the fact it is a supervised machine learning model that performs classification.",Machine Learning to Improve the Effectiveness of ANRS in Predicting HIV Drug Resistance,Comparison not undertaken.,2017,10.4258/hir.2017.23.4.271 ,297b4cc8-9937-41b5-bfb3-7469fedc1fbe,"Unclear if whole dataset points = 
-46,000 total (23,000 protease seqs & 23,000 reverse transcriptase seqs) 
or 
-23,000 total (containing a mix of protease seqs and reverse transcriptase seqs.)
The former is stated at first but the splits noted later in the text align with the latter.

Text notes for the data splits:
-Training dataset: 18,400 protease seqs and reverse transcriptase seqs
-Testing dataset: 4,600 protease seqs and reverse transcriptase seqs
Unclear the distibution of these.

Distibutions unclear from text and not available in any figure/tables/files.",,,10.4258/hir.2017.23.4.271 , 5-fold cross-validation performed for model evaluation.,,True,No information on execution time or compute requirements.,otyepo566r,"Some performance metrics of the model are reported. However, these are not compared to the literature or other previously published models.

1. Accuracy percentages: provide an overall measure of how well the model performs by detailing the percentage of correct predictions.

2. Positive Predictive Value (PPV) and Negative Predictive Value (NPV): metrics for these were reported and indicate the probability of a positive/negative prediction being correct.

3. Statistical Significance (aZ-score): aZ-score greater than 1.98 reported. This would indicate a p-value less than 0.05 and a statistically significant result. ",Healthcare Informatics Research ,,Machine Learning to Improve the Effectiveness of ANRS in Predicting HIV Drug Resistance,,,,Not mentioned in text - difficult to infer/extrapolate as model type is also not specified.,2024-06-19T22:24:08.516Z,"Database - Stanford HIV drug resistance database (http://hivdb.stanford.edu/).

The data used is de-identified genotype-phenotype datasets: 23,000 protease gene sequences and 23,000 reverse transcriptase gene sequences.",Overfitting less likely due to 5-fold cross-validation and limited features in use. Underfitting may be possible but low info in text not clear to determine the fit likelihood. Parameter numbers unknown.,Configuration not available.,Yashik Singh,"Data was sourced from the Stanford HIV drug resistance database (http://hivdb.stanford.edu/).
However, the exact sequences and phenotype/genotype data used is not listed or avaialble in text/supplementary data. So the data used is not available nor the splits.",2024-06-19T22:24:08.516Z,"Some information in text on the splits.

Data is split by 5-fold cross-validation, this uses four folds for training and the remaining unseen fold for testing in each iteration.

However, the level of redundacy reduction (if any performed) is not clear in the text.",5-fold cross-validation technique was in use to help prevent overfitting. No others clearly noted in text.,No information in text on how the genotype seqs or phenotype data was encoded for the model.,,No confidence intervals reported. '88% ¬± 7.1% improvement' is noted but unclear if specific confidence metrics.,"Unclear from text - not explicitly stated. Text suggests after feature selection the top 10 features were selected for the model.

Yes - feature selection was performed and noted in text. The text mentions using ReliefF, MODTree filtering, FCBF filtering, and CFS filtering. These feature selection methods were used to identify the most relevant features (gene mutations) from the data for the ML task of predicting HIV drug resistance.",66735a8837ea6fa797a6c341,0.95
No,It is a geometric deep learning model.,The model and its source code is available at https://github.com/HannesStark/ EquiBind.,arXiv,"Hannes St√§rk, Octavian-Eugen Ganea, Lagnajit Pattanaik, Regina Barzilay, Tommi Jaakkola",Code to reproduce results with the provided model weights is available at https://github.com/HannesStark/ EquiBind.,,"No mention was made on the interoperability of the model. However, due to the complexity of the model, it appears to be a black box.",EQUIBIND: Geometric Deep Learning for Drug Binding Structure Prediction,"The model was compared to similar software and methods including QVINA, GNINA, SMINA, and GLIDE.
Also the combinations of the model with SMINA and QVINA was included in the benchmark.",2022,https://doi.org/10.48550/arXiv.2202.05146,242800d0-70de-4409-9b2f-bff40afacc32,"Of the 19 119 preprocessed complexes, 1512 were discovered in 2019 or later. From these, they randomly sampled 125 unique proteins and collected all new complexes containing them (363) to create the final test set.
From the remaining complexes that are older than 2019, we remove those with ligands contained in the test set, giving 17,347 complexes for training and validation. These are divided into 968 validation complexes, which share no ligands with the remaining 16,379 train complexes.",,,,The evaluation was carried out on an independent test set in two experiments: 1. Flexible blind self-docking and 2. Blind re-docking,,True,"In ""Flexible blind self-docking"" experiment, Standard EQUIBIND takes on average 0.16 second on 16 CPU cores and 0.04 second on a 6GB GTX 1060 GPU to process a task.",skg7vifrfy,"Authos used the ligand root mean square deviation (L-RMSD), the centroid distance, and the KabschRMSD as evaluation metics.",,,EQUIBIND: Geometric Deep Learning for Drug Binding Structure Prediction,,The model is close to a regression model by predicting the coordinates of the ligand-protein binding site alongside the bond angles and lengths of the ligand molecule.,The model combines Graph Matching Networks and E(3)-Equivariant Graph Neural Networks.,"Overall 15 parameters were reported.
Authors used search space strategy to obtain a strong performance on the validation set.",2024-05-03T14:31:02.390Z,"Authors used protein-ligand complexes from PDBBind in a time split manner.
The newest version, PDBBind v2020, contains 19,443 protein-ligand complexes with 3,890 unique receptors and 15,193 unique ligands.
",p is not larger than the number of training points. ,Code to reproduce results or perform fast docking with the provided model weights is available at https://github.com/HannesStark/ EquiBind.,"Hannes St√§rk, Octavian-Eugen Ganea, Lagnajit Pattanaik, Regina Barzilay, Tommi Jaakkola",The data and associated scripts available at https://github.com/HannesStark/EquiBind.,2024-05-03T14:31:02.390Z,A time split strategy was adopted by the authors.,"Authors optimized the model using ""Adam"" and did early stopping with patience of 150 epochs based on the percentage of predicted validation set complexes with an RMSD better than 2 A.",Both input molecules (ligand & receptor) are represented to the model as spatial k-nearest neighbor (k-NN) graphs.,,"MEAN, MED, 25TH, 50TH, 75TH, % below 5 and 2 AÀö was reported for the mentioned evaluation metrics. While the standard model performs relatively well, in most metrics the best results are obtained when EQUIBIND is combined with SMINA for fine-tuning.","For the Œ±-carbons in the receptor graph, authors used the residue type as a feature. The edges have two attributes.

In the ligand, the edges have features that are encoded in the same fashion as for the receptor. Meanwhile, the atoms have the following features: atomic number; chirality; degree; formal charge; implicit valence; the number of connected hydrogens; the number of radical electrons; hybridization type; whether or not it is in an aromatic ring; in how many rings it is; and finally, 6 features for whether or not it is in a ring of size 3, 4, 5, 6, 7, or 8.",6634f526ded6e7820f74a1b8,1
Not yet assigned,"The initial weights for the hidden layer are generated using the Glorot normal initializer, which uses ùêø1‚àíùëüùëíùëîùë¢ùëôùëéùëüùëñùëßùëéùë°ùëñùëúùëõ with the regularization parameter set to O(‚àö(2logp/n)). To train this model, mean of squares of errors (MSE) is used to calculate the loss in comparison with the response on the output layer. To train the model‚Äôs parameters with respect to the loss function, we used a stochastic gradient descent method called ‚ÄúAdam optimization‚Äù. ",,GigaScience,"Zhenjiang Fan, Kate F. Kernan, Aditya Sriram, Panayiotis V. Benos, Scott W. Canna, Joseph A. Carcillo, Soyeon Kim, and Hyun Jung Park",,,we developed the first computational method that explicitly learns nonlinear causal relations and estimates the effect size using a deep-neural network approach coupled with the knockoff framework.,Deep neural networks with knockoff features identify nonlinear causal relations and estimate effect sizes in complex biological systems.,"We compared our method to threeexisting methods, causalMGM, DAG-GNN, and NOTEAR.",2023,https://doi.org/10.1101/2021.07.17.452800,9b42e80b-19bd-49d8-b06e-3b8302ceb152,We used 10 fold cross validation in all the data sets. ,,0,,10-fold cross validation,,True,Within 6 hours for mid-sized samples.,ngjci1cyqx,Sensivitity and specificity,,Not yet assigned,Deep neural networks with knockoff features identify nonlinear causal relations and estimate effect sizes in complex biological systems.,0,Model classification.,,"Parameters	Value
Activation function	Rectified linear unit (ReLU)
Initial weight values	Glorot normal intializer
Regularization	ùêø1‚àíùëüùëíùëîùë¢ùëôùëéùëüùëñùëßùëéùë°ùëñùëúùëõ
Optimization	Adam optimization
Loss function	Mean of squares of errors (MSE)
FDR control rate	0.05
",2023-05-09T19:47:13.177Z,"We used a simulation data set, two public data, and one access-controlled data. Our simulation data are downloadable from our project website (https://github.com/ZhenjiangFan/DAG-deepVASE). TCGA breast invasive carcinoma (BRCA) data were downloaded from https://tcga.xenahubs.net, available under BRCA cohort, under gene expression RNAseq section, on IlluminaHiSeq (n=1,218) TCGA Hub. It consists of the gene expression RNAseq dataset (dataset ID: TCGA.BRCA.sampleMap/HiSeqV2) and the clinical phenotype dataset (dataset ID: TCGA.BRCA.sampleMap/BRCA_clinicalMatrix). To investigate the dietary effect of the human gut microbiome, we downloaded a cross-sectional data of 98 healthy volunteers from https://noble.gs.washington.edu/proj/DeepPINK/ that preprocessed the data set.",We used linear fit.,,"Zhenjiang Fan, Kate F. Kernan, Aditya Sriram, Panayiotis V. Benos, Scott W. Canna, Joseph A. Carcillo, Soyeon Kim, and Hyun Jung Park",,2023-05-09T19:48:29.691Z,"all datasets are without overlap, kept coincident for each trial of the algorithms.",We used ùêø1‚àíùëüùëíùëîùë¢ùëôùëéùëüùëñùëßùëéùë°ùëñùëúùëõ with the regularization parameter set to O(‚àö(2logp/n)).,"All the inputs have been normalized into the range [-1, 1] for fairness.",,better timing and accuracy,"We used a simulation data set, two public data, and one access-controlled data. Our simulation data are downloadable from our project website (https://github.com/ZhenjiangFan/DAG-deepVASE). TCGA breast invasive carcinoma (BRCA) data were downloaded from https://tcga.xenahubs.net, available under BRCA cohort, under gene expression RNAseq section, on IlluminaHiSeq (n=1,218) TCGA Hub. It consists of the gene expression RNAseq dataset (dataset ID: TCGA.BRCA.sampleMap/HiSeqV2) and the clinical phenotype dataset (dataset ID: TCGA.BRCA.sampleMap/BRCA_clinicalMatrix). To investigate the dietary effect of the human gut microbiome, we downloaded a cross-sectional data of 98 healthy volunteers from https://noble.gs.washington.edu/proj/DeepPINK/ that preprocessed the data set.",645aa34160bf612a3caabc1b,0.86
37126495,"Deep Residual Neural Network (ResNet) 
-Not a new algorithm ",Main ResMiCo GitHub (python package and snakemake pipeline): https://github.com/leylabmpi/ResMiCo - MIT license. Dataset simulation pipeline used available in Snakemake: https://doi.org/10.1093/bioinformatics/bts480 . Dockerfiles noted in the repo but no VMs/web server. Direct pip install possible from a command line and information in GitHub software repo but limitations noted for incompatibility with apple Mac machines due to chipset.  ,PLOS Computational Biology,"Olga Mineeva, Daniel Danciu, Bernhard Sch√∂lkopf, Ruth E. Ley, Gunnar R√§tsch, and Nicholas D. Youngblut",Large degree of the evaluation is noted throughout the text & figures or in S1 - Supplementary Material ResMiCo: increasing the quality of metagenome-assembled genomes with deep learning (https://journals.plos.org/ploscompbiol/article/file?type=supplementary&id=10.1371/journal.pcbi.1011001.s001). Statistical code for evaluation not clearly avaialble linked from text or within shared GitHub repository.,,"Moderately interpretable. GitHub available with model code & datasets hosted online. Important info detailed in paper but not precisely straight forward on all aspects. Tutorials available which are helpful to reuse the model: https://github.com/leylabmpi/ResMiCo/wiki/ResMiCo-SM-tutorial. However, this is a lightweight tutorial page and more information could be provided given the complex nature of the model used. More clarity around the large number of datasets mentioned in the evaluation would be helpful.",ResMiCo: Increasing the quality of metagenome-assembled genomes with deep learning,"The model was compared to other state of the art models for this prediction task:
-metaMIC  
-DeepMAsED  
-ALE 

The model was also compared to various benchmark datasets:
-CAMI datasets (gut, oral, skin)
-Mock communities (BMock12, MBARC-26)",2023,https://doi.org/10.1371/journal.pcbi.1011001,e9d0a4a1-31d9-4782-937b-885197f55f14,"18,000 total reference genomes selected from GTDB. Of these:
-Test: 9000 reference genomes used 
-Training: 9000 reference genomes used

10% of the training dataset was used as a validation set for the model selection.",,,,"Independent datasets were used to evalaute the model. 
For example the text notes that two CAMI datasets that simulate non-human biomes: CAMI-marine and CAMI-plant-associated were used to evaluate the model and corresponding AUPRC & AUROC shared.",,True,"There is a section dedicated to benchmarking the ResMiCo model resource requirements in the materials and methods.
-Using the CAMI gut dataset, ResMiCo ran > 2x faster with a GPU versus a CPU (108 ¬± 0.7 versus 38.7 ¬± 10.3 contigs per second).
-They further note the reccomendation to use multiple GPUs for training the model on larger datasets.
-While it is feasible to run the model with a CPU, this is at a much slower rate: 140,000 contigs in 1 hour with a single CPU.",hipgaatgji,"Various model performances measure metrics were reported in the text eg:
-Area Under the Precision-Recall Curve (AUPRC)
-Area Under the ROC Curve (AUROC)
-Precision and Recall",PLOS Computational Biology,,ResMiCo: Increasing the quality of metagenome-assembled genomes with deep learning,,,,"ResMiCo model has 562,573 parameters, of which 559,441 are trainable.",2024-06-16T20:27:10.713Z,"An existing database was the primary source of the data - Release 202 of the Genome Taxonomy Database (GTDB).
-18,000 reference genomes from the database were selected for further use.
-From this database the authors created a synthetic dataset comprised of bacterial and archaeal genomes with the simulation software 'Metagenome read simulation of multiple synthetic communities' (https://github.com/nick-youngblut/MGSIM).
-Illumina ART read simulator was used to generate paired-end Illumina reads of length 100 or 150 using either the default ‚ÄúIllumina HiSeq 2500‚Äù error profile or the ‚ÄúHiSeq2500L150R1/2‚Äù error profile used in CAMISIM.
-Information detailed with parameters of the simulation in 'Table 1. Parameter values used in the simulation pipeline.'","Yes, p much larger than number of training points. Trainable Parameters (559,441) vs. Features (14).",The list of optimised hyperparameters and the attempted values are provided in Table B in S1 Text. (https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011001#pcbi.1011001.s001). Unclear if further information available and this is unlikely based on the GitHub which is functionally in place to share reuse of the model vs considerations of sharing precise configuration information.  ,"Olga Mineeva, Daniel Danciu, Bernhard Sch√∂lkopf, Ruth E. Ley, Gunnar R√§tsch, and Nicholas D. Youngblut","Yes - data available: http://ftp.tue.mpg.de/ebio/projects/ResMiCo/
This is on the: MPI for Biology FTP server, author noted choice due to size of datasets.",2024-06-16T20:27:10.713Z,"The sets were split from the original 18,000 using a family taxonomic level split to divide these into training and test.

For redundancy reduction, max 50 genomes per species were included to avoid overfitting.

Random genome selection was used to divide the test and training in alignment with the 50 genomes max per species. 

",Early stopping likely used based on text information but not explicitly written in the text. Class imbalance handling and data augmentation approaches also noted in the text which can help prevent overfitting a model.,"Data encoding (0-1) detailed in supplemetary data 'Table A. The full list of positional features computed by ResMiCo pipeline'. The fifth column states preprocessing applied to the features of the table as used for the data encoding for the model: standardisation (Std), normalisation (Nrm), and one-hot encoding (Onh).",,Confidence intervals are not explictly mentioned in the text. If taking the other models as the baseline for camparison the reported AUPRC & AUROC are noted to outperform these throughout the text. More information for the confidence would be useful beyond comparisons already noted for the datasets and other models.,"14 features as noted in 'Fig 3. Feature ranked by their importance.'.

Feature selection was performed and noted in a dedicated paper subsection. ",666f4a9e37ea6fa797a6c20d,0.95
37489753,"MuLan-Methyl is an ensemble framework consists of five transformer-based language models.
",The source code is released (https://github.com/husonlab/mulan-methyl). A web server implementing the MuLan-Methyl approach is freely accessible at http://ab.cs.uni-tuebingen.de/software/mulan-methyl/.,GigaScience,"Wenhuan Zeng, Anupam Gautam, Daniel H Huson","Yes, it's available in the MuLan-Methyl manuscript and its supplementary files.",,"MuLan-Methyl is interpretable by utilizing the self-attention mechanism of transformer architecture. For example, attention score assigned to each tokens of each sample which predicted positive are used to discover methylation motifs.",MuLan-Methyl‚Äîmultiple transformer-based language models for accurate DNA methylation prediction,"Yes, MuLan-Methyl is compared with iDNA-ABF and iDNA-ABT on the iDNA-MS independent dataset, MuLan-Methyl outperforms 13 out of 17 sub-dataset.",2023,https://doi.org/10.1093/gigascience/giad054,8ac43578-356a-49dc-a0a1-f2bfd3a887e0,"The ratio of training and test set is 1:1.
Validation set is generated by sampling 20% training dataset.
The distribution of data types in the training and test sets is same.",,6,,We evaluated MuLan-Methyl on the iDNA-MS independent test dataset.,,True,In average one second.,bgldxl71jp,"MuLan-Methyl is evaluated by the following evaluation metrics: AUC, Accuracy, F1-score, Recall, and AUPR.
",,,MuLan-Methyl‚Äîmultiple transformer-based language models for accurate DNA methylation prediction,0,It's classification model.,The model doesn't use data from other ML algorithms as input.,"Here is the models' parameter:
Model Number of parameters
MuLan-Methyl-BERT 105,242,882
MuLan-Methyl-DistilBERT 62,714,114
MuLan-Methyl-ALBERT 11,045,122
MuLan-Methyl-XLNet 111,934,466
MuLan-Methyl-ELECTRA 29,336,578",2024-10-15T09:30:26.463Z,"Data source: iDNA-MS (Lv, Hao, et al. ""iDNA-MS: an integrated computational tool for detecting DNA modification sites in multiple genomes."" Iscience 23.4 (2020): 100991.)
Data are in classes,the data statistics for positive samples and negative samples in both training dataset and test dataset can be found in supplementary file of published paper.
","p is much larger than f, Overfitting is ruled out since the loss value of both training process and validation process has similar changing trends.","Yes, all the hyper-parameters are reported in MuLan-Methyl manuscript and its corresponding Github repository(https://github.com/husonlab/mulan-methyl).","Wenhuan Zeng, Anupam Gautam, Daniel H Huson","Data are public, can be obtained from iDNA-MS(http://lin-group.cn/server/iDNA-MS/), as well as MuLan-Methyl(https://github.com/husonlab/mulan-methyl).",2024-10-15T09:30:26.463Z,"The training and test set are split by iDNA-MS, they are independent.
","Yes, early stopping on validation dataset is conducted for preventing overfitting.",The input of MuLan-Methyl is processed by converting each sample' DNA sequences and its taxonomic lineages into a description. Each processed sample is further encoded by tokenizer of each language models.,,Performance metrics of our study doesn't have confidence intervals.,"Two features of each sample are used as input, one is sample's DNA sequence, another is its taxonomic lineage. No feature selection is performed.",670e363261d57eb8bca695a3,0.78
na,"We then trained various ML models employing a custom version of deepBreaks, an ML tool designed for exploring genotype-phenotype associations. For continuous phenotypes, deepBreaks fit models using twelve different existing ML linear regression algorithms including, Ridge Regression, Lasso Regression, Bayesian Regression, Lasso Least Angle Regression, Huber Regressor, Extremely Randomized Trees (Extra Trees), Extreme Gradient Boosting (xgboost), Light Gradient Boosting Machine (lightgbm), Random Forest, Decision Tree, and AdaBoost. deepBreaks takes aligned genotype data (DNA, RNA, Amino Acid) and some measure(s) of corresponding continuous or categorical phenotype data as input to train ML models. ","As mentioned earlier, all software, code and supporting data are available on our GitHub repository (10.5281/zenodo.10667840 or https://github.com/VisualPhysiologyDB/visual-physiology-opsin-db/). All data and code (software) is covered under a GNU General Public License (Version 3), in accordance with Open Source Initiative (OSI)-policies. ",GigaScience,"Seth A. Frazer, Mahdi Baghbanzadeh, Ali Rahnavard, Keith A. Crandall, Todd H. Oakley","Yes, this all available on our GitHub repository, (10.5281/zenodo.10667840 or https://github.com/VisualPhysiologyDB/visual-physiology-opsin-db/).",,"All models used are generally interpretable, primarily due to the nature of the feature selection process, treating each position on an amino acid sequence as a feature. 
For interpreting the contribution of sequence positions to the predictive models, we use the feature importance, coefficients, and weights as different algorithms have different kinds of
output. For xgboost and lightgbm the reported feature importance represents the number of times a feature appears in a tree. For AdaBoost, random forest, decision tree, extra tree, and
gradient boosting the importance of a feature is its Gini importance which is computed as the
normalized total reduction of the criterion brought by that feature.",Discovering genotype-phenotype relationships with machine learning and the Visual Physiology Opsin Database (VPOD),"We didn't compare to an existing publicly available ML methods. However, we compared performance of ML models to phylogenetic imputation, which estimates phenotypes using phylogenetic information. Phylogenetic imputation uses maximum likelihood (we will not abbreviate maximum likelihood as ML to avoid confusion with machine learning), assuming Brownian Motion to predict missing phenotypes using a phylogenetic tree, assuming more closely related species or sequences have more similar phenotypes. We randomly removed 50 opsin sequences, and their corresponding Œªmax values from each of the training datasets used to train our ML models (with the exception of the smaller MWS/LWS and invertebrate datasets, in which we only removed 15), then estimated the removed Œªmax values using phylogenetic imputation. We used the phylogenetic imputation sub-module of the phytools R package for performing imputation. We compared imputed and actual Œªmax using regression. ",2024,10.1101/2024.02.12.579993,00e4d4f8-2dd6-452a-b27c-72fe9296b09d,"For model training, a whole dataset it submitted to the algorithm training pipeline and it is randomly sampled to split the data such  that 80% is used for training, and 20% is used for model validation. The amount of data points in these splits/sets are dependent on the subset of data used to train the models. As mentioned earlier, VPOD_het_1.0 contains 864 unique opsin sequences and corresponding Œªmax values. From this we created eleven data subsets with varying levels of taxonomic and gene family inclusivity to test which factors most impact the reliability/performance of ML methods.",,0,,"For model evaluation and comparison, deepBreaks by default uses a 10-fold cross-validation approach and ranks
the models based on their average cross-validation score.
As we described in the methods of the main text ""we created eleven data subsets with varying levels of taxonomic and gene family inclusivity (Table 1) to test which factors most impact the reliability/performance of ML methods. We used naming conventions that include versioning to improve reproducibility and reliability of individual datasets and models. For example, one subset combines ultraviolet and SWS opsins, which we named VPOD_uss_het_1.0. Our convention is to name the subset (in this case USS = ‚ÄòUltraviolet and Short-wave Sensitive‚Äô opsins); name the source of phenotype data (heterologous = het), and record the version number of the dataset (1.0). We also created subsets for medium- and long-wave sensitive opsins (VPOD_mls_het_1.0) and all rod (Rh1) and rod-like (Rh2) opsins (VPOD_rod_het_1.0). Other subsets use species taxonomy, one for vertebrates (VPOD_vert_het_1.0) and another for invertebrates (VPOD_inv_het_1.0). For taxonomic subsets, we considered all sequences from phylum Chordata as ‚Äòvertebrates‚Äô and the rest as 'invertebrates‚Äô. Another subset excludes all mutant opsin sequences, called ‚Äòwild-types‚Äô (VPOD_wt_het_1.0). A final named subset is the whole data set (VPOD_wds_het_1.0). 
Using various subsets of data, we performed a number of experiments to better understand the performance of ML models in predicting Œªmax. First, to better understand how training data relate to model performance, R2 , and training data size, we gradually increased the size of training datasets, using the WDS, Vertebrate, WT, and Rod subsets separately, by adding between 15-50 randomly selected sequences at a time, repeating the process three times per data split (Table S1). We then analyzed the fit between the size of training data sets (x-axis) and model performance (y-axis), comparing six non-linear models with AIC to find the model that best explains the observed variation (Figure S2). Second, to understand if ML could predict known phenotypic changes due to experimental mutations, we queried the top performing WT model (which lacks data from artificially mutated sequences) using all experimentally mutated opsins to predict their phenotypes. We plotted these results using matplotlib [49] to visualize characteristics of poorly predicted outliers (e.g., taxonomic bias or sensitivity to mutations which caused large shifts in Œªmax from the WT). Third, we examined the ability of our models to predict Œªmax of thirty invertebrate opsins not in VPOD_1.0 because they are only known from physiological studies (Table S3, Figure S4). Here, we collected data both characterized by single-cell microspectrophotometry (MSP) or electroretinogram methods and with expression localized to cell-type by in-situ-hybridization (ISH), to link Œªmax to a specific opsin (the sequences and metadata can be found in ‚Äòmsp_erg_raw.txt‚Äô and ‚Äòmsp_erg_meta.tsv‚Äô, while the resulting predictions can be found under the ‚Äòmsp_tests‚Äô folder on our GitHub repository). Finally, we directly compared predictive capabilities of models trained on different data subsets by randomly selecting and removing the same 25 wild-type ultraviolet or short-wave sensitive opsins from the training data of the WDS, Vertebrate, WT, and UVS/SWS models before training and querying the model with those same sequences following training (Table S3, Figure S5). ""
",,True,"A single representative prediction, all the way to several hundred predictions, takes only a matter of seconds to complete on a normal desktop PC.  Additionally, training the models can completed in a matter of minutes on a desktop PC as well.  ",88n4lxv68p,The default performance metrics for regression and classification that deepBreaks uses are Mean Absolute Error (MAE) and F-score. The default list of metrics that deepBreaks reports are provided in the documentation provide predefined custom metrics or a set of metrics from the scikit-learn library in python.,,,Discovering genotype-phenotype relationships with machine learning and the Visual Physiology Opsin Database (VPOD),0,"The models used for our paper were all regression, but deepBreaks provides the option to also train classification models in an identical manner. ",,For all of the above-mentioned models deepBreaks by default uses the default hyperparameters from the scikit-learn library in python and a grid search (expandable by user preference) parameter set that is provided in the documentation.,2024-02-23T00:32:13.005Z,"The source of the data is from a database we compiled, the Visual Physiology Opsin Database (VPOD) (10.5281/zenodo.10667840 or https://github.com/VisualPhysiologyDB/visual-physiology-opsin-db/). VPOD_1.0 is a new database, available on GitHub, that currently includes all heterologously expressed animal opsins. We refer to a subset of the database with only heterologous data as VPOD_het_1.0, although for version 1.0, this is synonymous with the entire database. VPOD_het_1.0 relies on 68 publications, mainly primary sources, with dates ranging from the 1980‚Äôs to 2023. The database contains opsin sequences and phenotype data from 166 unique species (counting 35 reconstructed ancestors), including fishes, amphibians, reptiles, mammals, crustaceans, and bivalves. Altogether, VPOD_het_1.0 contains 864 unique opsin sequences and corresponding Œªmax values.","We did not focus on ruling out overfitting or underfitting, however these features may be present in the scikit-learn backend. ","Yes, they are likely available in the scikit-learn documentation. ","Seth A. Frazer, Mahdi Baghbanzadeh, Ali Rahnavard, Keith A. Crandall, Todd H. Oakley","The data set(s) supporting the results and all other code used in this article are available in the ‚ÄòVisual Physiology Opsin Database‚Äô GitHub repository, (10.5281/zenodo.10667840 or https://github.com/VisualPhysiologyDB/visual-physiology-opsin-db/). All data and code is covered under a GNU General Public License (Version 3), in accordance with Open Source Initiative (OSI)-policies.  DOME-ML (Data, Optimisation, Model, and Evaluation in Machine Learning) annotation, supporting the current study, is available through DOME Wizard.
",2024-02-23T00:35:32.655Z,"We used naming conventions that include versioning to improve reproducibility and reliability of individual datasets and models. For example, one subset combines ultraviolet and SWS opsins, which we named VPOD_uss_het_1.0 (n=280). Our convention is to name the subset (in this case USS = ‚ÄòUltraviolet and Short-wave Sensitive‚Äô opsins); name the source of phenotype data (heterologous = het), and record the version number of the dataset (1.0). We also created subsets for medium- and long-wave sensitive opsins (VPOD_mls_het_1.0)(n=91) and all rod (Rh1) and rod-like (Rh2) opsins (VPOD_rod_het_1.0)(n=352). Other subsets use species taxonomy, one for vertebrates (VPOD_vert_het_1.0)(n=721) and another for invertebrates (VPOD_inv_het_1.0)(n=143). For taxonomic subsets, we considered all sequences from phylum Chordata as ‚Äòvertebrates‚Äô and the rest as 'invertebrates‚Äô. Another subset excludes all mutant opsin sequences, called ‚Äòwild-types‚Äô (VPOD_wt_het_1.0)(n=318). A final named subset is the whole data set (VPOD_wds_het_1.0)(n=864). 
We used naming conventions that include versioning to improve reproducibility and reliability of individual datasets and models. For example, one subset combines ultraviolet and SWS opsins, which we named VPOD_uss_het_1.0 (n=280). Our convention is to name the subset (in this case USS = ‚ÄòUltraviolet and Short-wave Sensitive‚Äô opsins); name the source of phenotype data (heterologous = het), and record the version number of the dataset (1.0). We also created subsets for medium- and long-wave sensitive opsins (VPOD_mls_het_1.0)(n=91) and all rod (Rh1) and rod-like (Rh2) opsins (VPOD_rod_het_1.0)(n=352). Other subsets use species taxonomy, one for vertebrates (VPOD_vert_het_1.0)(n=721) and another for invertebrates (VPOD_inv_het_1.0)(n=143). For taxonomic subsets, we considered all sequences from phylum Chordata as ‚Äòvertebrates‚Äô and the rest as 'invertebrates‚Äô. Another subset excludes all mutant opsin sequences, called ‚Äòwild-types‚Äô (VPOD_wt_het_1.0)(n=318). A final named subset is the whole data set (VPOD_wds_het_1.0)(n=864). 
","We did not directly impliment any regularization measures, however I know certain models like the Light Gradient Boosted Machine and Xtreme Gradient Boosted Machine algorithms have regularization terms/parameters to limit overfitting.  That said, more information on this can be found in the scikit-learn documentation or in the corresponding literature for each machine learning algorithm type. ","The deepBreaks pipeline for preprocessing starts with dropping columns in the dataset that contain missing values over a certain threshold. The default threshold is 80% of the number of samples.  Dropping the zero-entropy (constant) features from the dataset, is the next step.   deepBreaks uses one-hot encoding to convert amino acid sequences into numerical values. One consequence of this encoding is any amino acids at a given position in the alignment, which are not present at that position in any training data, will be treated equivalently as unseen. For example, cases of only A and V at a highly conserved site in the training set that are presented with a sequence with T at that site will be considered as no A and no V. The models cannot distinguish the input whether it's T or other unseen amino acids at that site.  ",,,"The number of input features is variable depending on the length of the sequences following sequences alignment and the many preprocessing and feature selection steps. deepBreaks uses the Kruskal-Wallis tests (for continuous phenotypes)  to reduce the number of positions in the training data set and drop the redundant ones. This statistical test is used to assess the significance of each position by running tests on all the positions against the phenotype one by one. Those features where the p-value of their test against the phenotype is less than a threshold (default p-value = 0.25) will be dropped. A list of all features and their test p-values are provided a report to the user. Then, since deepBreaks considers each position in the sequences as a feature of our training dataset,  it checks for collinearity between our predictive variables, as it can cause issues for parameter estimation. To check for the relationship between
",65d7e78d1502715bfe53c582,0.9
39185700,We used a pre-trained Xception CNN as the backbone with an additional layer for TS/survival prediction and fine-tuning.,The source code is released via github: https://github.com/tovaroe/GBMatch_CNN (GPL 3.0),GigaScience,"Thomas Roetzer-Pejrimovsky, Karl-Heinz Nenning, Barbara Kiesel, Johanna Klughammer, Martin Rajchl, Bernhard Baumann, Georg Langs, Adelheid Woehrer",Evaluation results are covered in the manuscript. the Model output for the external TCGA validation dataset is available via the github page: https://github.com/tovaroe/GBMatch_CNN (GPL 3.0),,"The model is semi-interpretable. While the prediction of single image tiles is a black box, the mapping of tile prediction onto the whole slide scans allows for interpretability (discussed extensively in the manuscript).",Deep learning links localized digital pathology phenotypes with transcriptional subtype and patient outcome in glioblastoma,NA / no benchmark datasets available.,2024,https://doi.org/10.1093/gigascience/giae057,19954d39-0d13-4f99-9e5d-0624ccd5b638,"For model selection, the above mentioned 276 or 189 cases, respectively, were split into 5 equally sized fold for 5-fold CV, with similar distribution of transcriptional subtypes and survival, respectively.

The external validation data is derived from TCGA, consists of 178 cases and can be accessed via cBioPortal (https://www.cbioportal.org) and/or the GDC Data Portal (https://portal.gdc.cancer.gov). In contrast to the training dataset, the transcriptional subtypes were determined by RNAseq, but the overall distribution is similar, albeit with slightly more classical cases and fewer mesenchymal cases. Due to the strict selection critera for the study underlying the training dataset, the overall survival in the TCGA dataset was slightly lower.",,6,,5-fold CV and independent external test dataset,,True,"Depending on the slide scan size, a single prediction requires a few minutes on a workstation desktop PC.",2bpmmu8yav,"For prediction of the transcriptional subtype: accuracy, AUC.
For prediction of the survival: median overall survial and logrank test after groupint into high-risk and low-risk groups.",,,Deep learning links localized digital pathology phenotypes with transcriptional subtype and patient outcome in glioblastoma,0,,Not applicable,"No additional parameters werde set in the pre-trained Xception model. For prediction of survival, a 1-neuron layer was added as the ultimate layer, and for prediction of the transcriptional subtype, a 3-neuron layer was added.",2024-10-15T14:11:37.681Z,"The training data is derived from the publication ""The DNA methylation landscape of glioblastoma disease progression shows extensive heterogeneity in time and space"" (https://doi.org/10.1038/s41591-018-0156-x) and contains a total of 276 cases, 189 of which have information on the transcriptional subtype.

",Overfitting/Underfitting was ruled out by keeping track of the validation set error in 5-fold-CV during hyperparameter selection; And by fixing the pre-trained model parameters and only fine-tuning the last few layers.,Available via the github-page in the config.py (https://github.com/tovaroe/GBMatch_CNN),"Thomas Roetzer-Pejrimovsky, Karl-Heinz Nenning, Barbara Kiesel, Johanna Klughammer, Martin Rajchl, Bernhard Baumann, Georg Langs, Adelheid Woehrer","The splits for the training data are published in the corresponding github repository (https://github.com/tovaroe/GBMatch_CNN, GPL 3.0).",2024-10-15T14:11:37.681Z,"The external validation set is completely independent, as it is derived from TCGA.",Dropout (0.25),"Image tiles were used as input for the ML algorithm, the preprocessing was performed according to the keras implementation of the Xception model.",,NA / no other methods for comparison available,"Image tiles (512x512 px) were used as input, no additional feature selection was performed.",670e781961d57eb8bca6961f,0.78
