{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python script to download latest DOME Registry contents and maintain up to date file of all entries. (20241202)\n",
    "## Script will also offer a download of all related EPMC articles for NLP usage through their API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded and saved to 'DOME_Registry_Contents_2024-12-02.json'\n"
     ]
    }
   ],
   "source": [
    "# 1. Use the DOME API to download all entries of the DOME Registry and store in a file \n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the URL for the API call: check the API documentation for the correct URL on the DOME Registry website\n",
    "url = \"https://registry.dome-ml.org/api/review?skip=0&limit=250&text=%20&public=true&sort=publication.year&asc=true\"\n",
    "\n",
    "# Make an API request to the URL\n",
    "response = requests.get(url, headers={'accept': '*/*'})\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Get the current date in ISO format for file naming\n",
    "    current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Create the output file name\n",
    "    file_name = f\"DOME_Registry_Contents_{current_date}.json\"\n",
    "    \n",
    "    # Save the content to a file\n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        file.write(response.text)\n",
    "    \n",
    "    print(f\"Data downloaded and saved to '{file_name}'\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the data. Status code: {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b5c\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"16524483\",\n",
      "            \"updated\": \"01/28/2022 00:13:56\",\n",
      "            \"authors\": \"Wang H, Zheng H, Simpson D, Azuaje F\",\n",
      "            \"journal\": \"BMC Bioinformatics\",\n",
      "            \"title\": \"Machine learning approaches to supporting the identification of photoreceptor-enriched genes based on expression data.\",\n",
      "            \"doi\": \"10.1186/1471-2105-7-116\",\n",
      "            \"year\": \"2006\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"66a94333-8cd1-499c-86ef-0497a4c4dabc\",\n",
      "        \"shortid\": \"6i0xepuivt\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"01/28/2022 00:13:56\",\n",
      "            \"publication/authors\": \"Wang H, Zheng H, Simpson D, Azuaje F\",\n",
      "            \"publication/journal\": \"BMC Bioinformatics\",\n",
      "            \"publication/title\": \"Machine learning approaches to supporting the identification of photoreceptor-enriched genes based on expression data.\",\n",
      "            \"optimization/algorithm\": \"ensemble decision tree model\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/method\": \"five-fold cross-validation\",\n",
      "            \"dataset/availability\": \"yes, https://www.nature.com/articles/s41467-019-12812-3#Sec24\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b93\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"17374164\",\n",
      "            \"updated\": \"03/09/2022 10:14:51\",\n",
      "            \"authors\": \"Al-Shahib A, Breitling R, Gilbert DR\",\n",
      "            \"journal\": \"BMC Genomics\",\n",
      "            \"title\": \"Predicting protein function by machine learning on amino acid sequences--a critical evaluation.\",\n",
      "            \"doi\": \"10.1186/1471-2164-8-78\",\n",
      "            \"year\": \"2007\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"147ddf2b-6b53-4335-b62f-87994d284310\",\n",
      "        \"shortid\": \"nlj5x3dld8\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/09/2022 10:14:51\",\n",
      "            \"publication/authors\": \"Al-Shahib A, Breitling R, Gilbert DR\",\n",
      "            \"publication/journal\": \"BMC Genomics\",\n",
      "            \"publication/title\": \"Predicting protein function by machine learning on amino acid sequences--a critical evaluation.\",\n",
      "            \"optimization/algorithm\": \"Two stage neural network approach\",\n",
      "            \"optimization/features\": \"672 features\",\n",
      "            \"optimization/fitting\": \"Newly crystallized proteins should avoid overfitting \",\n",
      "            \"optimization/meta\": \"Yes, combination of different alignments  tested on independent datasets\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"Classification prediction of residue contact.\",\n",
      "            \"evaluation/comparison\": \"Performance achieved with methods based on automatic multiple sequence alignment calculation\",\n",
      "            \"evaluation/measure\": \"Precision as a function of effective aligned sequences\",\n",
      "            \"evaluation/method\": \"Independent dataset form CASP11\",\n",
      "            \"dataset/availability\": \"Casp 11 website (https://predictioncenter.org/casp11/index.cgi)\",\n",
      "            \"dataset/redundancy\": \"Not assessed. In principle de novo protein structure prediction experiments should involve protein with no similarity with those in public available databases\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"66030aaa1502715bfe53d65c\",\n",
      "        \"uuid\": \"600b20de-7c70-41af-ad39-33121af090ef\",\n",
      "        \"created\": \"2024-03-26T17:49:30.048Z\",\n",
      "        \"updated\": \"2024-03-26T17:49:30.048Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"17888165\",\n",
      "            \"authors\": \"Hui Lan, Rachel Carson , Nicholas J Provart and Anthony J Bonner\",\n",
      "            \"journal\": \"BMC Bioinformatics\",\n",
      "            \"title\": \"Combining classifiers to predict gene function in Arabidopsis thaliana using large-scale gene expression measurements\",\n",
      "            \"doi\": \"10.1186/1471-2105-8-358\",\n",
      "            \"year\": \"2007\"\n",
      "        },\n",
      "        \"shortid\": \"ysqyy92zyr\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches\": {\n",
      "            \"evaluation/comparison\": \"no comparison with other approaches perfomed\",\n",
      "            \"evaluation/confidence\": \"no confidence interval reported. No statistical significance over baselines has been computed\",\n",
      "            \"evaluation/measure\": \"ROC curve\",\n",
      "            \"evaluation/method\": \"cross validation\",\n",
      "            \"optimization/algorithm\": \"Different supervised and unsupervised learning algorithms: logistic regression, linear discriminant analysis, quadratic discriminant analysis, naive Bayes, k-nearest neighbors, PCA. No new algorithm developed.\",\n",
      "            \"optimization/encoding\": \"Gene expression data\",\n",
      "            \"optimization/features\": \"290 features. no feature selection performed.\",\n",
      "            \"optimization/fitting\": \"p is much lower than the number of features. Unclear how potential underfitting was handled\",\n",
      "            \"optimization/parameters\": \"Unclear, approximately in the range of the number of features\",\n",
      "            \"optimization/regularization\": \"Not adopted\",\n",
      "            \"model/duration\": \"not stated\",\n",
      "            \"model/interpretability\": \"Model is partially interpretable, since classifier paramenters can be used to assess how gene expression data related to gene response to stress.\",\n",
      "            \"dataset/provenance\": \"Data are extracted from different databases (TAIR, AtGenExpress Consortium, NASCArrays). Data are in classes. Npos and Nneg are not reported.\",\n",
      "            \"dataset/redundancy\": \"Random split has been adopted for cross-validation. No redundancy check performed.\",\n",
      "            \"dataset/splits\": \"Training set: 11553 data points, No test nor validation sets have been used.  Performance is scored using cross-validation only.\",\n",
      "            \"publication/authors\": \"Hui Lan, Rachel Carson , Nicholas J Provart and Anthony J Bonner\",\n",
      "            \"publication/journal\": \"BMC Bioinformatics\",\n",
      "            \"publication/title\": \"Combining classifiers to predict gene function in Arabidopsis thaliana using large-scale gene expression measurements\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"66041e5d1502715bfe53d70a\",\n",
      "        \"uuid\": \"b863eb51-d9ae-4fc0-bfd4-006db90d1631\",\n",
      "        \"created\": \"2024-03-27T13:25:49.790Z\",\n",
      "        \"updated\": \"2024-03-27T13:25:49.790Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"17570862\",\n",
      "            \"authors\": \"Blaise Gassend, Charles W O'Donnell, William Thies, Andrew Lee, Marten van Dijk and Srinivas Devadas\",\n",
      "            \"journal\": \"BMC Bioinformatics\",\n",
      "            \"title\": \"Learning biophysically-motivated parameters for alpha helix prediction\",\n",
      "            \"doi\": \"10.1186/1471-2105-8-S5-S3\",\n",
      "            \"year\": \"2007\"\n",
      "        },\n",
      "        \"shortid\": \"qx3ex71jye\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"evaluation/availability\": \"Not available\",\n",
      "            \"evaluation/comparison\": \"Cmparison with other approaches is missing. No baseline method is considered\",\n",
      "            \"evaluation/confidence\": \"Not reported\",\n",
      "            \"evaluation/measure\": \"accuracy and segment-overlap value for alpha helix (SOVa)\",\n",
      "            \"evaluation/method\": \"Repeated random traing/test split\",\n",
      "            \"optimization/algorithm\": \"support vector machine classifyer. The algorithm is not new.\",\n",
      "            \"optimization/encoding\": \"Residue are encoded with different propensity scale for a residues to by in alpha-helix or coil\",\n",
      "            \"optimization/features\": \"f=380. No feature selection performed. \",\n",
      "            \"optimization/fitting\": \"p is much lower than number of training points. Not clear how potential undefitting has been ruled out\",\n",
      "            \"optimization/regularization\": \"No regularization applied. Validation set not used.\",\n",
      "            \"model/interpretability\": \"Model is interpreatable, since paramenters learning by the SVM corresponds to interpretable paramenters of an energy function\",\n",
      "            \"model/output\": \"binary classification\",\n",
      "            \"dataset/provenance\": \"Data is extracted from the PDB. Data are in classes (alpha-helix vs other), however, it is not clear ho many alpha-helix residues (positive example) are present within the 300 proteins in the dataset. Dataset previsouly used in other studies and recognized by the community (no logner available)\",\n",
      "            \"dataset/redundancy\": \"All proteins in the dataset are non-homologous all-alpha proteins. Unclear how redundancy reduction is performed.\",\n",
      "            \"dataset/splits\": \"Traning set: 150 proteins; Testing set: 150 proteins. Distributions of data classess in training and testing not shown. No validation set adopted. \",\n",
      "            \"publication/authors\": \"Blaise Gassend, Charles W O'Donnell, William Thies, Andrew Lee, Marten van Dijk and Srinivas Devadas\",\n",
      "            \"publication/journal\": \"BMC Bioinformatics\",\n",
      "            \"publication/title\": \"Learning biophysically-motivated parameters for alpha helix prediction\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b1c\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"19091017\",\n",
      "            \"updated\": \"03/25/2022 13:35:02\",\n",
      "            \"authors\": \"Tsai RT, Dai HJ, Huang CH, Hsu WL\",\n",
      "            \"journal\": \"BMC Bioinformatics\",\n",
      "            \"title\": \"Semi-automatic conversion of BioProp semantic annotation to PASBio annotation.\",\n",
      "            \"doi\": \"10.1186/1471-2105-9-S12-S18\",\n",
      "            \"year\": \"2008\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"28fe7de1-ac05-4cf2-bfa8-d5ddd1ba32b8\",\n",
      "        \"shortid\": \"v536tc3b5t\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/25/2022 13:35:02\",\n",
      "            \"publication/authors\": \"Tsai RT, Dai HJ, Huang CH, Hsu WL\",\n",
      "            \"publication/journal\": \"BMC Bioinformatics\",\n",
      "            \"publication/title\": \"Semi-automatic conversion of BioProp semantic annotation to PASBio annotation.\",\n",
      "            \"optimization/algorithm\": \"A  non-linear, multi-layer convolutional Graph Neural Network (GNN) was trained to encode drug features, which were then fed to a Multi-Layer Perceptron (MLP) to output a probability distribution.  The probability distributions were passed to a SVM for the binary classification of nodes. The training was end-to-end.\",\n",
      "            \"optimization/config\": \"Yes. Hyperparameter settings for every method are reported. For neural models, hyperparameter candidates can be found in Table 1, Characteristics of the neural network models architecture can be found in text.\",\n",
      "            \"optimization/encoding\": \"Initially, each drug (or food molecule) is represented by a graph G of human PPI (with 15135 nodes and 177848 edges), with one binary feature per node (1 for anti-cancer, 0 for non anti-cancer).     A vector representation of the graph G is computed using a Graph Encoder, i.e. a GNN, which learns the systemic effect of drugs (or food molecules) on the PPI network.    \",\n",
      "            \"optimization/features\": \"Initial f0) = number of genes x number of drugs (15135x2048).  After the GNN step, each drug has an associated feature vector, so that the number of features is reduced to f < f(0). \",\n",
      "            \"optimization/fitting\": \"As far as one can tell, over-fitting could not be excluded (p >> N).  Indeed, regularization was performed.\",\n",
      "            \"optimization/regularization\": \"Yes.   L2 regularization on weights of the neural network was performed.    Space search:  1.10^(\\u22125), 1.10^(\\u22124), 5.10^(\\u22124).  \",\n",
      "            \"model/availability\": \"The code to reproduce the results can be downloaded from GitHub (https://github.com/ggonzalezp/hyperfoods)\",\n",
      "            \"model/duration\": \"Training time is expressed as milliseconds per sample per epoch, to facilitate the estimation of the total training time the proposed neural models would need for a different dataset.\",\n",
      "            \"model/interpretability\": \"Transparent : The attribution recall score for the best performing model is computed, to assess whether the model predicts drugs as anticancer preferentially based on the feature values in cancer-related genes, and found to be very high (85%). This means that the graph neural model classifies drugs as anticancer preferentially based on the value of the input features in cancer-related genes, which adds to the biological plausibility of the model. In addition, 6 use cases were invetigated. For all 6 drugs studied, over-represented pathways successfully recovered pathways described in the literature along with cancer-related\\n pathways. This means that the representations learned capture the mechanisms of action of drugs.\",\n",
      "            \"model/output\": \"Regression is the output by neural networks, i.e. a probability distribution for anticancer/non-anticancer categories), which is taken in input by SVM for a binary classification output.\",\n",
      "            \"evaluation/availability\": \"Yes. (https://github.com/ggonzalezp/hyperfoods)\",\n",
      "            \"evaluation/comparison\": \"A baseline input is used, in which all drug targets are set to zero. To motivate the use of network propagation, versions of the baseline and proposed methods without network propagation were also evaluated (for comparison to the method used in https://doi.org/10.1038/s41598-019-45349-y, which did not use network propagation). F1 score and AUPR were significantly higher with the adopted models.\",\n",
      "            \"evaluation/confidence\": \"Confidence intervals and statistical significance are reported. Statistically significant higher performance measures were obtained by the used model, relative to the baseline method and to the method without network propagation used in https://doi.org/10.1038/s41598-019-45349-y.\",\n",
      "            \"evaluation/measure\": \"Balanced accuracy, F1 score, AUPR. The last two are used as parameters which better capture the performance of a classifier in the case of a highly-imbalanced dataset.\",\n",
      "            \"evaluation/method\": \"Cross-validation. The model was also tested on an independent dataset of 7793 food molecules, for their classification as anti-cancer or not anti-cancer, available for future experimental tests. The model outputs a high anticancer likelihood for a given food molecule if said molecule acts on the interactome through similar mechanisms of action as those of FDA-approved anticancer drugs. Among the anticancer-predicted molecules, e.g. genistein and pterostilbene show the most promise as cancer preventing agents, as indicated by substantial experimental evidence, gained from the literature.\",\n",
      "            \"dataset/availability\": \"Yes :  data to reproduce the results can be downloaded from GitHub (https://github.com/ggonzalezp/hyperfoods).  All data were extracted from publicly available databases.\",\n",
      "            \"dataset/provenance\": \"\\\"Data were extracted from publicly available databases: UniProt, STRING STITCH; COSMIC, NCBI,  DrugBase, DrugCentral,  FooDB, KEGG, MSigDB.   The dataset contains 2048 drugs (training dataset).   The dataset had been previously used also in https://doi.org/10.1038/s41598-019-45349-y.     The procedure in [ https://doi.org/10.1038/s41598-019-45349-y ] was used to obtain classification labels for the cancer task (positive (anti-cancer drug)/negative (non anti-cancer drug): N_pos = 209 /N_neg = 1839 drugs).   \\n\",\n",
      "            \"dataset/splits\": \"A 5-fold cross-validation was performed to assess model performance. In each split, 20% of the data is kept as the test set; from the remaining 80%, 10% is used as a validation set to perform early stopping. All splits were generated stratifying samples with respect to labels.  To balance the positive/negative classes (only 10.2% of drugs are anticancer), the contribution of each class was re-scaled to the loss function so that it is inversely proportional to class frequencies of each class during training.  \"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b1d\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"18586734\",\n",
      "            \"updated\": \"04/18/2022 16:37:38\",\n",
      "            \"authors\": \"Klammer AA, Reynolds SM, Bilmes JA, MacCoss MJ, Noble WS\",\n",
      "            \"journal\": \"Bioinformatics\",\n",
      "            \"title\": \"Modeling peptide fragmentation with dynamic Bayesian networks for peptide identification.\",\n",
      "            \"doi\": \"10.1093/bioinformatics/btn189\",\n",
      "            \"year\": \"2008\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"56505402-9ea8-41a0-9132-ea658a7eee7f\",\n",
      "        \"shortid\": \"5867a1dxop\",\n",
      "        \"score\": 0.9,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"04/18/2022 16:37:38\",\n",
      "            \"publication/authors\": \"Klammer AA, Reynolds SM, Bilmes JA, MacCoss MJ, Noble WS\",\n",
      "            \"publication/title\": \"Modeling peptide fragmentation with dynamic Bayesian networks for peptide identification.\",\n",
      "            \"optimization/algorithm\": \"Boosted decision tree\",\n",
      "            \"optimization/config\": \"Authors state that BigML models will be shared without limitations.\",\n",
      "            \"optimization/encoding\": \"Global features.\",\n",
      "            \"optimization/features\": \"Apparently, 20 parameters from cytofluorometry and 4 parameters from standard biochemical laboratory data were used in input.    it is not mentioned whether some of the parameters related to primary diagnoses of other diseases, or related to age, ethnicity and sex were also used.   \",\n",
      "            \"optimization/fitting\": \"According to the author's statement, the AUROC values of the training (0.98) and of the testing (0.99) sets were \\\"most likely over-fitting\\\" -- (AUROC of the independent validation set resulted 0.8).                                                                                \",\n",
      "            \"optimization/parameters\": \"not reported. Most likely, however, the number of parameters was as in the software package by default.\",\n",
      "            \"optimization/regularization\": \"Tools eventually applied to avoid overfitting are not mentioned.\",\n",
      "            \"model/availability\": \"The materials, data, code and associated protocols are available to readers with application to the corresponding author and Waitemata privacy, security and governance group with a limited data sharing agreement.\",\n",
      "            \"model/interpretability\": \"Black box. No information about the optimized parameters were reported.\",\n",
      "            \"model/output\": \"Binary prediction of a positive or negative SARS-CoV-2 PCR result.\",\n",
      "            \"evaluation/availability\": \"The materials, data, code and associated protocols are available to readers with application to the corresponding author and Waitemata privacy, security and governance group with a limited data sharing agreement.\",\n",
      "            \"evaluation/comparison\": \"A comparison is reported between the boosted decision tree model and the highest univariate predictor for COVID-19 (highly fluorescent lymphocytes count % [HFLC%]).\",\n",
      "            \"evaluation/confidence\": \"AUROC from ML model was 0.80, from univariate predictor was 0.77, but the small difference was not statistically significant, according to 95% Confidence Intervals.\",\n",
      "            \"evaluation/measure\": \"AUROC (in spite of the much higher numerosity of negative versus positive samples in the datasets).\",\n",
      "            \"evaluation/method\": \"Validation (most likely 5-fold cross-validation, even if it not mentioned explicitly) on training set and validation on an independent set. Independent set: new data collected from 9 June 2020 to 24 August 2020 during New Zealand\\u2019s second wave.\",\n",
      "            \"dataset/availability\": \"The materials, data, code and associated protocols are available to readers with application to the corresponding author and Waitemata privacy, security and governance group with a limited data sharing agreement.     \",\n",
      "            \"dataset/provenance\": \"Upon ethics approval obtained locally at Waitemata District Health Board (New Zealand), hematology raw hospital data were downloaded from the Information Process Unit (IPU) of the hospitals.  Data from 43,761 patients were collected between 1 July 2019 and 8 June 2020 from two hospital's flow cytometry analyzers.     A total of 2168 of SARS-CoV-2 PCR tests could be matched to patients with Full Blood Counts (FBC) data.   9 patients with 102 FBCs were SARS-CoV-2 positive, 2159 patients with 15,243 FBCs were SARS-CoV-2 negative.\",\n",
      "            \"dataset/redundancy\": \"Since the 102 FBCs sample came from 9 positive patients only, independence seems doubtful. \",\n",
      "            \"dataset/splits\": \"Models were trained, tested and then validated in an independent cohort. Due to the low number of COVID-19 PCR-positive cases, serial results for each positive case were used for descriptive statistics and in ML models, \\\"in the assumption that this would include the various stages of the disease and convalescence\\\".    A total of 102 (N_pos) instances (serial FBCs in 9 patients identified during New Zealand\\u2019s first lockdown) and 204 (N_pos) control FBCs in unique patients were used for model training and testing.   For independent validation:  11 FBCs from 3 patients with COVID-19 were used for validation with 6770 controls.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b94\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"18221567\",\n",
      "            \"updated\": \"03/24/2022 13:09:43\",\n",
      "            \"authors\": \"Zhao XM, Wang Y, Chen L, Aihara K\",\n",
      "            \"journal\": \"BMC Bioinformatics\",\n",
      "            \"title\": \"Gene function prediction using labeled and unlabeled data.\",\n",
      "            \"doi\": \"10.1186/1471-2105-9-57\",\n",
      "            \"year\": \"2008\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"9052c56d-022c-45d9-8b82-58312399f0dc\",\n",
      "        \"shortid\": \"ali2ohlvnk\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/24/2022 13:09:43\",\n",
      "            \"publication/authors\": \"Zhao XM, Wang Y, Chen L, Aihara K\",\n",
      "            \"publication/journal\": \"BMC Bioinformatics\",\n",
      "            \"publication/title\": \"Gene function prediction using labeled and unlabeled data.\",\n",
      "            \"optimization/algorithm\": \"Learning Gaussian Bayesian networks with interventions\",\n",
      "            \"optimization/encoding\": \"Global features\",\n",
      "            \"optimization/features\": \"Expression level of the genes under different conditions\",\n",
      "            \"optimization/fitting\": \"Not assessed\",\n",
      "            \"optimization/parameters\": \"Increases with the size of the network. They scale with the number of possible edges\",\n",
      "            \"model/availability\": \"Matlab Code\\n http://www.plosone.org/article/fetchSingleRepresentation.action?uri=info:doi/10.1371/journal.pone.0150611.s002\",\n",
      "            \"model/output\": \"Network reconstruction\",\n",
      "            \"evaluation/comparison\": \"Comparison with state-of-the-art algorithms\",\n",
      "            \"evaluation/measure\": \"AUROC and AUPR\",\n",
      "            \"evaluation/method\": \"Evaluation of two datasets\",\n",
      "            \"dataset/provenance\": \"In silico gene expression data from DREAM Challenge 4\",\n",
      "            \"dataset/redundancy\": \"Not assessed\",\n",
      "            \"dataset/splits\": \"Networks of different sets of genes for wt and perturbed networks\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"66040f611502715bfe53d6e7\",\n",
      "        \"uuid\": \"804c2b2b-e663-4d3a-8042-7d2a35ad2122\",\n",
      "        \"created\": \"2024-03-27T12:21:53.450Z\",\n",
      "        \"updated\": \"2024-03-27T12:21:53.450Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"18808707\",\n",
      "            \"authors\": \"Iain Melvin, Jason Weston , Christina S Leslie and William S Noble\",\n",
      "            \"journal\": \"BMC Bioinformatics\",\n",
      "            \"title\": \"Combining classifiers for improved classification of proteins from sequence or structure\",\n",
      "            \"doi\": \"10.1186/1471-2105-9-389\",\n",
      "            \"year\": \"2008\"\n",
      "        },\n",
      "        \"shortid\": \"vwy8sti3pw\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches\": {\n",
      "            \"evaluation/availability\": \"yes, through the author website\",\n",
      "            \"evaluation/comparison\": \"Yes, with a single external tool (AutoSCOP)\",\n",
      "            \"evaluation/confidence\": \"not reported\",\n",
      "            \"evaluation/measure\": \"Per-class error rate\",\n",
      "            \"evaluation/method\": \"cross-validation and independent test set\",\n",
      "            \"optimization/algorithm\": \"Combined kNN and SVM. \",\n",
      "            \"optimization/config\": \"yes, hardcoded into the source code\",\n",
      "            \"optimization/encoding\": \"Protein primary sequence. Profile kernel is used for SVM\",\n",
      "            \"optimization/fitting\": \"Cannot be determined\",\n",
      "            \"optimization/parameters\": \"Not clearly declared.\",\n",
      "            \"optimization/regularization\": \"No  \",\n",
      "            \"model/availability\": \"yes, thrugh the author website\",\n",
      "            \"model/duration\": \"not reported\",\n",
      "            \"model/output\": \"multi-class classification\",\n",
      "            \"dataset/availability\": \"yes (URL)\",\n",
      "            \"dataset/provenance\": \"Data taken from SCOP database (release 1.69). Multi-class data where each class corresponds to a SCOP superfamily. Number of superfamilies is 74 and 1458 in in Set A  and Set B, respectively.  Number of proteins is 643 and 2182 in Set A and Set B, respectively.\",\n",
      "            \"dataset/redundancy\": \"Testing set should be independent, given that split has been perfomed at the level of SCOP superfamilies\",\n",
      "            \"dataset/splits\": \"Dataset A: N_train=543 (proteins), N_test=110 (proteins) ; Dataset B: N_train=1740 (proteins), N_test=442 (proteins)\",\n",
      "            \"publication/authors\": \"Iain Melvin, Jason Weston , Christina S Leslie and William S Noble\",\n",
      "            \"publication/journal\": \"BMC Bioinformatics\",\n",
      "            \"publication/title\": \"Combining classifiers for improved classification of proteins from sequence or structure\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b3a\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"19154573\",\n",
      "            \"updated\": \"02/23/2022 23:30:01\",\n",
      "            \"authors\": \"Brown JB, Akutsu T\",\n",
      "            \"journal\": \"BMC Bioinformatics\",\n",
      "            \"title\": \"Identification of novel DNA repair proteins via primary sequence, secondary structure, and homology.\",\n",
      "            \"doi\": \"10.1186/1471-2105-10-25\",\n",
      "            \"year\": \"2009\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"1fe140b6-a570-49cf-bccb-e58aa1719bec\",\n",
      "        \"shortid\": \"2d714axh0n\",\n",
      "        \"score\": 0.86,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/23/2022 23:30:01\",\n",
      "            \"publication/authors\": \"Brown JB, Akutsu T\",\n",
      "            \"publication/journal\": \"BMC Bioinformatics\",\n",
      "            \"publication/title\": \"Identification of novel DNA repair proteins via primary sequence, secondary structure, and homology.\",\n",
      "            \"optimization/algorithm\": \"The AdaBoost algorithm on a set of 80 Decision Trees was used, as implemented in the scikit learn package.             \",\n",
      "            \"optimization/config\": \"A web server implementing the \\u201copen-source\\u201d model was developed and is freely available at http://chemosimserver.unice.fr/predisweet/. The 32 descriptors for the \\u201cDragon\\u201d model, and 51 descriptors for the \\u201copen source\\u201d model are also reported.\",\n",
      "            \"optimization/encoding\": \"Drugs were encoded as a set of molecular descriptors.    Molecular descriptors were computed using the Dragonpackage ('Dragon\\\" descriptors), or RDKit, Mordred, and ChemoPy packages (\\u201copen-source\\u201d descriptors). \",\n",
      "            \"optimization/features\": \"\\\"For each molecule, 635 molecular descriptors for the Dragon dataset, and 506 features for the \\u201copen-source\\u201d dataset were used in the model.   For each of these two descriptors sets, the initial number of features had been reduced by removing near-constant features (two or less unique values), features with a standard deviation below 0.001, and features with a correlation greater than 0.95.       During cross-validation, selection of descriptors was done by keeping a given percentile of the highest ranked descriptors based on their Mutual Information with the endpoint. The optimal percentile of features was tuned as a parameter of the Grid Search.   \\n\\\"\",\n",
      "            \"optimization/fitting\": \"Optimization of the number of features used by the model\",\n",
      "            \"optimization/parameters\": \"Default defined in sklearn package\",\n",
      "            \"optimization/regularization\": \"Yes.  To avoid any model bias due to overfitting, the number of features used by the model is a hyperparameter that has been optimized. \",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"Regression (sweetness score)\",\n",
      "            \"evaluation/comparison\": \"Several regression algorithms from the python package scikit-learn were evaluated: Random Forest, SVM, AdaBoost Tree, and k-Nearest Neighbors. Five-fold cross validation was performed with hyperparameter tuning using a grid search. The AdaBoost Tree model was selected as the best performing model, using 32 descriptors for the \\u201cDragon\\u201d model, and 51 descriptors for the \\u201copen source\\u201d model.\",\n",
      "            \"evaluation/confidence\": \"Confidence intervals for coefficient of determination are shown in Fig. S2, but a statistical significance analysis among the different tested methods is not reported\",\n",
      "            \"evaluation/measure\": \"Correlation Coefficient (R^2), cross-validated Correlation Coefficient (Q^2), coefficient of determination (|R^2-R0^2)/R^2), slope of regression line (k). The quality of each prediction is also assessed based on three metrics, namely the applicability, reliability, and decidability domains, typically used in the Quantitative Structure-Activity Relationships field.\",\n",
      "            \"evaluation/method\": \"Cross-validation. Novel experiments: The virtual screening of a large database of natural compounds (4796) identified thousands of putative sweeteners, of which 3 were selected for in vitro functional assays of the human sweet taste receptor. Among them, arctiin, with a novel scaffold, was identified as a novel agonist of the T1R2/T1R3 sweet taste receptor.\",\n",
      "            \"dataset/availability\": \"Yes.  Dataset available in the SweetenersDB database http://sebfiorucci.free.fr/SweetenersDB/sweetenersDB.html  \",\n",
      "            \"dataset/provenance\": \"Dataset:  316 sugar/sweeteners compounds of known sweetness collected by the authors from literature sources in the SweetenersDB database . Already used previously by the same authors (in a less-updated version).   \",\n",
      "            \"dataset/redundancy\": \"The dataset  was split in training and validation sets using a Sphere Exclusion clustering algorithm.     The chemical space was mapped using t-SNE and PCA.\",\n",
      "            \"dataset/splits\": \"64 diverse compounds (20.3%) were selected for the validation set, leaving 252 compounds in the training set.     \"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b5d\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"19667082\",\n",
      "            \"updated\": \"04/06/2022 03:38:12\",\n",
      "            \"authors\": \"Wegrzyn JL, Lee JM, Liechty J, Neale DB\",\n",
      "            \"journal\": \"Bioinformatics\",\n",
      "            \"title\": \"PineSAP--sequence alignment and SNP identification pipeline.\",\n",
      "            \"doi\": \"10.1093/bioinformatics/btp477\",\n",
      "            \"year\": \"2009\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"3f2e8acd-75f4-4e37-b345-0b43034fdfd4\",\n",
      "        \"shortid\": \"zl2x79pdqc\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"04/06/2022 03:38:12\",\n",
      "            \"publication/authors\": \"Wegrzyn JL, Lee JM, Liechty J, Neale DB\",\n",
      "            \"publication/title\": \"PineSAP--sequence alignment and SNP identification pipeline.\",\n",
      "            \"optimization/algorithm\": \"Ensemble of a deep Residual Convolutional Neural Networks.\\t\",\n",
      "            \"optimization/encoding\": \"Each MHC allele was represented by a pseudo-sequence consisting of 34 amino acid residues in contact with the peptide.  All peptides sequences were padded on the right end to the same length, 30 for class I and 40 for class II, using a place-holder amino acid.     For each MHC- peptide pair, the MHC feature vector and the peptide feature matrix formed a final input matrix of size 1400 x 30 for class I MHC and 1400 x 40 for class II MHC. The difference between the peptide length L and the expected length L (9 for class I MHC and 15 for class II MHC) was encoded using a sigmoid function.\",\n",
      "            \"optimization/features\": \"Number of initial features on the order of 1400 x 30\",\n",
      "            \"optimization/fitting\": \"Possible redundancy in the sequences\",\n",
      "            \"optimization/parameters\": \"The model weights from the epoch with the lowest validation loss were selected.\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"Regression: The PUFFIN method takes as input a MHC-peptide pair and predicts a probabilistic distribution of peptide-MHC binding affinity. For Classification: positive examples were defined as the ones with a binding affinity stronger than 500 nM.\",\n",
      "            \"evaluation/comparison\": \"PUFFIN was compared to NetMHCpan, MHCflurry and MHCnuggets. Unlike those methods, PUFFIN provides uncertainty estimates for MHC-peptide affinity prediction. It is shown that PUFFIN\\u2019s uncertainty estimates are able to reflect the predictive error on unseen examples.\",\n",
      "            \"evaluation/confidence\": \"Confidence intervals are not reported. As mentioned in the text, there were no significant performance differences among the different tested methods.\",\n",
      "            \"evaluation/measure\": \"auROC, F1 score, mean-squared-error (MSE), R2, Spearman, correlation, and Point-Biserial correlation. For auROC, F1 score, and Point-Biserial correlation, positive examples were defined as the ones with a binding affinity stronger than 500 nM.\",\n",
      "            \"evaluation/method\": \"Cross-validation on training set and independent set\",\n",
      "            \"dataset/availability\": \"Class I MHC binding affinity data in IEDB\\nhttps://cbs.dtu.dk/services.NetMHCpan-3.0 (broken link)\\n\\nClass II MHC binding affinity data in IEDB\\nhttps://cbs.dtu.dk/services.NetMHCIIpan-3.2 (broken link)\\n\\nBenchmark dataset (used for comparison with other methods)\\nhttps://www.biorxiv.org/content/10.1101/154757v2  https://data.mendeley.com/datasets/jwhmrdx268/1\\nThe authors obtained data in the class I MHC-peptide binding affinity benchmark from personal correspondence with Bhattacharya et al. and they have deposited this dataset in Mendeley Data. The accession number for this data is Mendeley Data:\\nhttps://doi.org/10.17632/jwhmrdx268.1\\n\",\n",
      "            \"dataset/provenance\": \"Regression data\\n\\nClass I MHC binding affinity data in IEDB\\nBroken link\\n\\nClass II MHC binding affinity data in IEDB\\nBroken link\\n\\nBenchmark dataset (used for comparison with other methods)\\nCurated class I MHC benchmark dataset (https://www.biorxiv.org/content/10.1101/154757v2 https://data.mendeley.com/datasets/jwhmrdx268/1)  \\nTraining 176,985\\nTesting  26,888\",\n",
      "            \"dataset/redundancy\": \"Class I MHC binding affinity data in IEDB\\nFor analyses on class I MHC-peptide binding, the IEDB-based dataset of Nielsen et al (2016) was used, in which 5 cross-validation folds were created to ensure no peptide shares a 9-mer sequence with any peptide in a different fold. \\t\\n\\nClass II MHC binding affinity data in IEDB\\nFor analyses on class II MHC-peptide binding, the IEDB-based dataset of Jensen et al (2018) was used, in which 5 cross-validation folds were created in the same way as in Nielsen et al (2016).\\t\\n\\nBenchmark dataset (used for comparison with other methods)\\nThe dataset of Bhattacharya et al.(2017) was used, who constructed a benchmark in which no peptide in the test set has identical length and greater than 80% sequence identity to any peptide in the training Set.\",\n",
      "            \"dataset/splits\": \"Class I MHC binding affinity data in IEDB\\nOnly MHC alleles (114)  with more than 100 examples were included to ensure the quality of training.   1/8 of the training set was held out as a validation set.\\t\\n\\nClass II MHC binding affinity data in IEDB\\nOnly MHC alleles (55) with more than 100 examples were included to ensure the quality of training.   1/8 of the training set was held out as a validation set.\\t\\n\\nBenchmark dataset (used for comparison with other methods)\\n51 class I MHC alleles are covered in this dataset.   \"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6613fe1f1502715bfe53d929\",\n",
      "        \"uuid\": \"b05d78bd-b870-43e2-8313-2c6e8cc7a91a\",\n",
      "        \"created\": \"2024-04-08T14:24:31.559Z\",\n",
      "        \"updated\": \"2024-04-08T14:24:31.559Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"19692556\",\n",
      "            \"authors\": \"Bandyopadhyay S, Mitra R. \",\n",
      "            \"journal\": \"Bioinformatics\",\n",
      "            \"title\": \"TargetMiner: microRNA target prediction with systematic identification of tissue-specific negative examples\",\n",
      "            \"doi\": \"10.1093/bioinformatics/btp503\",\n",
      "            \"year\": \"2009\"\n",
      "        },\n",
      "        \"shortid\": \"vqpw9fqmuu\",\n",
      "        \"score\": 0.95,\n",
      "        \"matches\": {\n",
      "            \"evaluation/availability\": \"I could not find them.\",\n",
      "            \"evaluation/comparison\": \"Ten other methods (DIANA-microT, Micro Inspector, miRanda, MirTarget2, NBmiRTar, PicTar, PITA, RNA22, RNAhybrid, TargetScan) have been applied by the Authors to the same test data, reaching the conclusion that the better performance of their own method was probably due to the better negative training set they were able to individuate.\",\n",
      "            \"evaluation/confidence\": \"No confidence intervals are reported for any performance measure.\",\n",
      "            \"evaluation/measure\": \"Sensitivity, specificity (ROC curves), ACA (Average Classwise Accuracy) and MCC (Matthews Correlation Coefficient).\",\n",
      "            \"evaluation/method\": \"Independent dataset, experimentally validated, composed of 246 miRNA\\u2013transcript pairs, of  which 187 were positive, 59 negative. \",\n",
      "            \"optimization/algorithm\": \"Support Vector Machine (SVM). \",\n",
      "            \"optimization/config\": \"TargetMiner is available as an online tool at https://www.isical.ac.in/~bioinfo_miu/targetminer20.htm.       The optimized parameter values for C and \\u03b3 are given in text.  Both the 90 and 30 feature sets are explicitly reported in the Supplementary Materials, together with the identification numbers of the 578 data points.  \",\n",
      "            \"optimization/encoding\": \"kmer for seed region, base pairing frequencies in the nearby regions.\",\n",
      "            \"optimization/features\": \"Two SVM models were build, based on the 90 and 30 (top 30 F-score) features, respectively. The two SVM classifiers are referred to as TargetMiner* and TargetMiner.  The selection of the 30 top features was based on an F-score, which indicated the discriminating power of a given feature between positive and negative examples. The F-score was calculated based on the training set only.\",\n",
      "            \"optimization/fitting\": \"The number of features was less than 100, but not small (30 or 90), compared to the number of training points (n = 578). \",\n",
      "            \"optimization/parameters\": \"The two standard RBF SVM hyperparameters C and \\u03b3 were determined by a grid search with a 10-fold cross-validation on the training dataset. \",\n",
      "            \"optimization/regularization\": \"The parameter C was standardly used to control the tradeoff between training error and margin. \",\n",
      "            \"model/availability\": \"SVM software is standard.  TargetMiner is available as an online tool at https://www.isical.ac.in/~bioinfo_miu/targetminer20.htm.     Executables are given .  Data files of test sets are available.\",\n",
      "            \"model/duration\": \"Not reported\",\n",
      "            \"model/interpretability\": \"SVM is generally considered black box. However, some ante hoc interpretability is manifested in the feature generation step, which was based on miRNA / 3'-UTR mRNA hybridization characteristics, such as seed length and identification, thermodynamic duplex stability, combinatorial effect of miRNAs and multiple target sites in the 3-UTRs of target mRNA, importance of miRNA\\u2019s outseed segment to determine the target specificity, analysis of evolutionary conserved target sites.  Post-hoc analysis of single features effectiveness was not performed.  Indeed, that is in agreement with the Author's statement, \\\"Since our objective in this article is to demonstrate the utility of systematically identifying the negative examples, we have kept the feature selection part simple. A more sophisticated approach is expected to improve the performance and will be considered in the future\\\".\",\n",
      "            \"model/output\": \"Binary classification (target or non-target genes for miRNAs).\",\n",
      "            \"dataset/availability\": \"Yes. Supporting Information.\",\n",
      "            \"dataset/provenance\": \"Source of positive miRNAs: TarBase (Papadopoulos et al., 2009) and miRecords database (Xiao et al., 2009, Nucleic Acids Res., 37, D155\\u2013D158, Nucleic Acids Res., 37, D105\\u2013D110)  \\nA set of 289 miRNA transcript pairs (positive examples), and 289 negative examples were used as training dataset (total training data points npos + nneg =578).  \\nThe positive data had been used previously in other papers. The negative data are novel, and have been identified by the Authors by means of a complex analysis. A subset of the negative examples has been validated experimentally.\",\n",
      "            \"dataset/redundancy\": \"Not reported\",\n",
      "            \"dataset/splits\": \"The SVM model with RBF kernel was generated by a 10-fold cross-validation on the training dataset.  The distribution of + and - in each data split is not mentioned, but it can be deduced to have been half and half.\",\n",
      "            \"publication/authors\": \"Bandyopadhyay S, Mitra R. \",\n",
      "            \"publication/title\": \"TargetMiner: microRNA target prediction with systematic identification of tissue-specific negative examples\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b9d\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"20122221\",\n",
      "            \"updated\": \"02/07/2022 18:57:16\",\n",
      "            \"authors\": \"Yang Y, Zhao J, Morgan RL, Ma W, Jiang T\",\n",
      "            \"journal\": \"BMC Bioinformatics\",\n",
      "            \"title\": \"Computational prediction of type III secreted proteins from gram-negative bacteria.\",\n",
      "            \"doi\": \"10.1186/1471-2105-11-S1-S47\",\n",
      "            \"year\": \"2010\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"ed449019-062c-4769-99ec-83a325549f96\",\n",
      "        \"shortid\": \"hl7w8279ra\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/07/2022 18:57:16\",\n",
      "            \"publication/authors\": \"Yang Y, Zhao J, Morgan RL, Ma W, Jiang T\",\n",
      "            \"publication/journal\": \"BMC Bioinformatics\",\n",
      "            \"publication/title\": \"Computational prediction of type III secreted proteins from gram-negative bacteria.\",\n",
      "            \"optimization/algorithm\": \"Iterative Bayesian Model Averaging (BMA) algorithm.\",\n",
      "            \"optimization/features\": \"f=3.   The feature selection method to distinguish benign from malignant samples consisted of two steps: a LIMMA linear model, and an iterative BMA algorithm.   The R package LIMMA was used  to  select  significantly  differentially  expressed  genes (fold-change cutoff of >=2 and a p-value<0.01). To minimize the number of signature genes, the iterative BMA R package was applied, which accounts for model uncertainty and the dependency between signature genes.    The BMA step was applied to further reduce the number of signature genes from 43 to 3, and thus the costs associated with microarrays and time-consuming data analysis.\",\n",
      "            \"optimization/fitting\": \"\\nOver- or under- fit could probably be excluded a posteriori by the good predictive performance in independent test sets and novel experiments.\\n\",\n",
      "            \"optimization/parameters\": \"The authors do not mention parameters numbers different from standard. \",\n",
      "            \"model/availability\": \"Publicly available R packages.\",\n",
      "            \"model/interpretability\": \"No statement about ante-hoc interpretability of the model is made by the authors. The model looks to me black box. Post-hoc interpretability for the ipeptidylprolyl peptidase 4 (DPP4) gene is supported e.g. by literature reports that this gene significant increases in differentiated carcinomas vs. normal or benign thyroid nodules at average 46 times. However, the low univariate rankings of 2 of the 3 genes indicated that it was the genes combination, that resulted in good predictive power, and no attempt was made to explain such joint effect.\",\n",
      "            \"model/output\": \"Binary classification between benign and malignant thyroid tumors.\",\n",
      "            \"evaluation/comparison\": \"Despite the small number of genes in the panel, the ability to predict different categories of thyroid nodules was similar to that of published data from over 100 genes.\",\n",
      "            \"evaluation/confidence\": \"Confidence Intervals are reported, by which a performance similarity between the 3 genes panel and the 100 genes panel is claimed.\",\n",
      "            \"evaluation/measure\": \"Sensitivity, specificity, accuracy.\",\n",
      "            \"evaluation/method\": \"Independent datasets and novel experiment. Independent dataset: GSE33630, GSE27155 and GSE3678. Novel experiment: Thyroid tissue specimens excised intraoperatively from 70 patients undergoing primary thyroidectomies in Renji Hospital\",\n",
      "            \"dataset/availability\": \"Yes.  https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE29315, vhttps://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE33630, vhttps://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE27155, vhttps://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE3678   \",\n",
      "            \"dataset/provenance\": \"Source:   Four published datasets from the gene expression omnibus (GEO)  series  GSE29315, GSE33630,  GSE27155 and GSE3678.      N_pos=176 patients, N_neg=113 patients.   GSE29315 already used in (Finley et al, Ann Surg, 2004)  GSE27155 already used in (Giordano et al, Oncogene, 2005, and Giordano et al, Clin Cancer Res 2006).\",\n",
      "            \"dataset/splits\": \"Training set, GSE29315: N_pos_train=31, N_neg_train=40.         Testing sets, GSE33630: N_pos_test=60, N_neg_test=45.    GSE27155: N_pos_test=78, N_neg_test=21.  GSE3678:  N_pos_test=7, N_neg_test=7.    43.7% positives on training set,   57.1% positives on testing set GSE33630 ,  78.8% positives on testing set GSE27155,  50.0% positives on testing set GSE3678.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bb6\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"19994907\",\n",
      "            \"updated\": \"03/24/2022 13:42:10\",\n",
      "            \"authors\": \"Eng K, Scouten-Ponticelli SK, Sutton M, Berdis A\",\n",
      "            \"journal\": \"ACS Chem Biol\",\n",
      "            \"title\": \"Selective inhibition of DNA replicase assembly by a non-natural nucleotide: exploiting the structural diversity of ATP-binding sites.\",\n",
      "            \"doi\": \"10.1021/cb900218c\",\n",
      "            \"year\": \"2010\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"8bb488cc-4a32-481c-8c5c-82e9d7990c0e\",\n",
      "        \"shortid\": \"3p7aj2vzii\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/24/2022 13:42:10\",\n",
      "            \"publication/authors\": \"Eng K, Scouten-Ponticelli SK, Sutton M, Berdis A\",\n",
      "            \"publication/journal\": \"ACS Chem Biol\",\n",
      "            \"publication/title\": \"Selective inhibition of DNA replicase assembly by a non-natural nucleotide: exploiting the structural diversity of ATP-binding sites.\",\n",
      "            \"optimization/encoding\": \"the protein interaction data, gene expression profiles and protein\\ncomplex data for yeast genes are integrated into one functional linkage graph\",\n",
      "            \"optimization/features\": \"SVD technique was employed to reduce the dimensionality and remove noise. 13 features.\",\n",
      "            \"optimization/fitting\": \"to evaluate the functional similarity between a pair of genes, the Czekanowski-Dice distance was employed. After that, the functional similarity between any pair of genes was represented as a real value between 0 and 1\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/comparison\": \"The AGPS algorithm is different from existing methods, which have inappropriate assumptions about those genes that have no target annotation.\",\n",
      "            \"evaluation/measure\": \"precision, recall and F1\",\n",
      "            \"evaluation/method\": \"cross-validation and independent dataset\",\n",
      "            \"dataset/availability\": \"DOI: 10.1093/nar/gkh894, DOI: 10.1093/nar/gkj109, \",\n",
      "            \"dataset/provenance\": \"FunCat dataset used by DOI: 10.1093/nar/30.1.31, BioGRID database, SMD, MIPS\",\n",
      "            \"dataset/splits\": \"1) 13 general functional classes were selected, and 4049 genes have been annotated in total.\\n2) 82,633 pairs of interactions among 5,299 yeast genes, of which 4049 genes are annotated by the 13 functional classes. \\n3) 5,132 genes with 278 real value features for\\ngene expression data.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b3b\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"22913485\",\n",
      "            \"updated\": \"02/11/2022 16:40:03\",\n",
      "            \"authors\": \"Akella LM, Norton CN, Miller H\",\n",
      "            \"journal\": \"BMC Bioinformatics\",\n",
      "            \"title\": \"NetiNeti: discovery of scientific names from text using machine learning methods.\",\n",
      "            \"doi\": \"10.1186/1471-2105-13-211\",\n",
      "            \"year\": \"2012\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"b879f61f-b41d-4e82-ad6e-fd33b4e669f1\",\n",
      "        \"shortid\": \"ku9smf88dv\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/11/2022 16:40:03\",\n",
      "            \"publication/authors\": \"Akella LM, Norton CN, Miller H\",\n",
      "            \"publication/journal\": \"BMC Bioinformatics\",\n",
      "            \"publication/title\": \"NetiNeti: discovery of scientific names from text using machine learning methods.\",\n",
      "            \"optimization/algorithm\": \"Logistic regression.\",\n",
      "            \"optimization/features\": \"Only 5 predictors available, no selection applied in this work.  The 5 predictors were the result of a selection applied in a previous work (PMID: 21136905), by quantifying differentially expressed proteins in urine proteomes.\",\n",
      "            \"optimization/fitting\": \"Bootstrap cross-validation was used for the internal validation to ensure that overfitting is avoided. Following that, elastic net was used for the regularisation of the coefficients to obtain the final model.  \",\n",
      "            \"optimization/parameters\": \"The authors do not mention parameters numbers different from standard. \",\n",
      "            \"optimization/regularization\": \"Yes, use of elastic net.\",\n",
      "            \"model/availability\": \"Logistic regression: The \\u201cglmnet\\u201d package from R was used with elastic net regularisation. NN: Python packages tensorflow, keras, and scikit-learn. RF: The \\u201cparty\\u201d package from R. SVM: The \\u201csvmLinear\\u201d method from the \\u201ccaret\\u201d package in R was used. NF: The r-algorithm developed by Shor was used with a precision \\u03b5 = 0.001. Software implementation of this approach was developed within the Visual Studio 2013 environment.\",\n",
      "            \"model/interpretability\": \"Logistic Regression is generally considered transparent. In a previous work (PMID: 26240291) the authors examined the good predicting power of each of the 3 urine biomarkers (LYVE1, REG1A, and TFF1) taken separately. However, an explaination of the joint effect of the variables has not been attempted.\",\n",
      "            \"model/output\": \"Binary classification (high PDAC risk or not).\",\n",
      "            \"evaluation/comparison\": \"Logistic regression was compared to neural network (NN), neuro-fuzzy technology (NF), random forest (RF) and support vector machine (SVM). None of those additional approaches significantly outperformed logistic regression.\",\n",
      "            \"evaluation/confidence\": \"Inference for the ROC curves was based on cluster-robust standard errors that accounted for the serially correlated nature of the samples. It was not possible to create ROC curves and therefore AUC for RF and SVM since the outcome was not continuous. McNemar\\u2019s exact test was used to assess the significance of difference in SN at fixed SP and DeLong\\u2019s test was used to assess the significance of differences in AUC between approaches. Confidence intervals (CI 95%) for AUCs were derived based on the DeLong\\u2019s method to evaluate the uncertainty of an AUC; SN and SP 95% CI were derived using bootstrap replicates. To allow for multiple testing, both types of tests were adjusted using the Bonferroni correction.\",\n",
      "            \"evaluation/measure\": \"AUROC (except for RF and SVM) and sensitivity at clinically relevant specificity.\",\n",
      "            \"evaluation/method\": \"Independent dataset.\",\n",
      "            \"dataset/availability\": \"Data available on request from the corresponding author.\",\n",
      "            \"dataset/provenance\": \"Specimens collected at the Royal London Hospital, University College London Hospital, Liverpool University and the CNIO Madrid, Spain, plus further samples obtained from Pancreas Tissue Bank (https://www. bartspancreastissuebank.org.uk).  N_pos = 199 ( pancreatic ductal adenocarcinoma (PDAC) patients), N_neg = 180 (healthy patients). No previously used.\",\n",
      "            \"dataset/splits\": \"Random division in a 1:1 ratio for train and test.   N_pos_train = 96, N_neg_train = 95,  N_pos_test = 103, N_neg_test = 85.    50.3% positives on training set.   54.8% positives on test set.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b3c\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"22532634\",\n",
      "            \"updated\": \"05/20/2022 15:57:36\",\n",
      "            \"authors\": \"Pratt AG, Swan DC, Richardson S, Wilson G, Hilkens CM, Young DA, Isaacs JD\",\n",
      "            \"journal\": \"Ann Rheum Dis\",\n",
      "            \"title\": \"A CD4 T cell gene signature for early rheumatoid arthritis implicates interleukin 6-mediated STAT3 signalling, particularly in anti-citrullinated peptide antibody-negative disease.\",\n",
      "            \"doi\": \"10.1136/annrheumdis-2011-200968\",\n",
      "            \"year\": \"2012\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"74f23aa2-985c-49d2-9a0d-0d7b3e0f4bda\",\n",
      "        \"shortid\": \"p00ybazkxy\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"05/20/2022 15:57:36\",\n",
      "            \"publication/authors\": \"Pratt AG, Swan DC, Richardson S, Wilson G, Hilkens CM, Young DA, Isaacs JD\",\n",
      "            \"publication/journal\": \"Ann Rheum Dis\",\n",
      "            \"publication/title\": \"A CD4 T cell gene signature for early rheumatoid arthritis implicates interleukin 6-mediated STAT3 signalling, particularly in anti-citrullinated peptide antibody-negative disease.\",\n",
      "            \"optimization/algorithm\": \"LightGBM (a gradient boosting framework using tree based learning algorithms) is stated in the Supplementary to have been the algorithm of choice.\",\n",
      "            \"optimization/encoding\": \"For character data field (like sex, pathogenesis), the LabelEncoder method in Python was used (categorical features encoded as a one-hot numeric array).\",\n",
      "            \"optimization/features\": \"Starting from 24 features (clinical measurements commons to the 4 hospitals), 9 features were selected for training, by means of LASSO regression and filter methods (the latter being variance threshold, Pearson Correlation Coefficient, chi-square test and mutual information).\",\n",
      "            \"optimization/fitting\": \"The LightGBM algorithm is stated in its documentation likely to be over-fitting if not used with the appropriate parameters. \",\n",
      "            \"optimization/parameters\": \"The number of parameters was the standard for Python implementation of LightGBM.  Parameters were tuned to get good results by means of grid search, random search and the Python library Hyperopt.\",\n",
      "            \"optimization/regularization\": \"Yes.  The authors state that, \\\"to prevent overfitting, the index of colsample_bytree was set to 0.9\\\".    Other parameters tuning for over-fitting prevention is not mentioned. \",\n",
      "            \"model/availability\": \"The ML algorithms were implemented using Python 3.7.\",\n",
      "            \"model/duration\": \"The run time of FibroBox is mentioned in the Discussion to be only a few seconds.\",\n",
      "            \"model/interpretability\": \"No statement about ante-hoc interpretability of the model is made by the authors. This LightGBM model looks to me complex enough to result rather black box. Post-hoc analysis showed e.g. that the contribute of the Transient Elastography (TE) feature to the good predictability was very relevant, which is meaningful. An explaination for an eventual joint effect of the 9 features was not adressed.\",\n",
      "            \"model/output\": \"Classification. Case A: positive and negative samples are non-significant fibrosis vs. significant fibrosis. Case B: positive and negative samples are non-cirrhosis vs. cirrhosis.\",\n",
      "            \"evaluation/comparison\": \"FibroBox was compared to 3 other pre-existing predicting methods: TE (Transient Elastography), APRI (Aspartate transaminase-to-platelet ratio index), FIB-4 (fibrosis-4 index), the letter two being serum biomarkers. The LightGBM algorithm was coompared to Logistic regression and XGBoost.\",\n",
      "            \"evaluation/confidence\": \"Confidence intervals at 95% for AUROC, statistical significance confirmed for the difference between FibroBox and each of TE, APRI, FIB-4 methods, both for fibrosis and for cyrrhosis predictions.\",\n",
      "            \"evaluation/measure\": \"Precision, recall, F1-score, accuracy, AUROC. The latter was used for feature selection, and for comparison with other models.\",\n",
      "            \"evaluation/method\": \"5-fold cross-validation during training-testing. Two independent datasets were used as evaluation sets: the Anhui cohort (n = 408), and the Beijing cohort (n=332).\",\n",
      "            \"dataset/availability\": \"According to the author's statement, the data are not available because of patients\\u2019 privacy.\",\n",
      "            \"dataset/provenance\": \"Clinical data from 4 different hospitals in China (4 different cities) about piatients with chronic B virus hepatitis. N = 1289 (patients from 4 different cities).  N_pos (fibrosis) = 815, N_neg (fibrosis) = 474 ;    N_pos (cirrhosis) = 290, N_neg (cirrhosis) = 999.   Data not used by previous authors.\",\n",
      "            \"dataset/splits\": \"Training set:   N = 549  (patients from 2 different cities, joined together).  N_pos (fibrosis) = 382 / N_neg (fibrosis) = 167 ;    N_pos (cirrhosis) = 157 // N_neg (cirrhosis) = 392.   Test set Anhui:   N = 408 (independent patients dataset from Anhui city).  N_pos (fibrosis) = 254 // N_neg (fibrosis) = 154 ;    N_pos (cirrhosis) = 59 // N_neg (cirrhosis) = 359.     Test set Beijing:   N = 332 (independent patients dataset from Beijing city).  N_pos (fibrosis) = 179 // N_neg (fibrosis) = 153 ;    N_pos (cirrhosis) = 74 // N_neg (cirrhosis) = 258.        69.6% positives (fibrosis), 28.6% positives (cirrhosis) on training set.   62.3% positives (fibrosis), 14.5% positives (cirrhosis) on Anhui test set.  53.9% positives (fibrosis), 22.3% positives (cirrhosis) on Beijing test set.  \"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b84\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"22408447\",\n",
      "            \"updated\": \"01/31/2022 11:13:16\",\n",
      "            \"authors\": \"Zhao X, Ma Z, Yin M\",\n",
      "            \"journal\": \"Int J Mol Sci\",\n",
      "            \"title\": \"Using support vector machine and evolutionary profiles to predict antifreeze protein sequences.\",\n",
      "            \"doi\": \"10.3390/ijms13022196\",\n",
      "            \"year\": \"2012\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"052c537c-d355-4d83-9a5b-2587a9451a4d\",\n",
      "        \"shortid\": \"0zaakstjvr\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"01/31/2022 11:13:16\",\n",
      "            \"publication/authors\": \"Zhao X, Ma Z, Yin M\",\n",
      "            \"publication/journal\": \"Int J Mol Sci\",\n",
      "            \"publication/title\": \"Using support vector machine and evolutionary profiles to predict antifreeze protein sequences.\",\n",
      "            \"optimization/algorithm\": \"Four approaches were compared: logistic regression (LR), multivariate adaptive regression splines (MARS), artificial neural networks (ANN), random forest (RF). \",\n",
      "            \"optimization/features\": \"Exploratory data analyses resulted in removal of correlated predictors (\\u00b10.90).   In the end, 7 predictors were used (i.e. 7 types of environmental data -- air temperature, relative humidity, etc).  The \\u201cvarImp\\u201d function contained in the caret package was used to determine the relative predictor importance for each model. Each model was run using 3, 4, 5, 6, and 7 predictors. The most important variables were selected for the development of the final model.\",\n",
      "            \"optimization/fitting\": \"Over-fitting in MARS and ANN was discussed and prevented.   In LR and RF, over-fitting should not have been an issue.  Possible underfitting was probabiy there for LR, which, with a kappa of 0.16, indicated a low degree of similarity, between observed and predicted, beyond random chance.\",\n",
      "            \"optimization/parameters\": \"For LR, MARS, RF, the authors do not mention parameters numbers different from standard.   For ANN, weights can be deduced to have been in the range of 100. Their number depended on the number of nodes in the hidden layer, which was optimized using 10-fold cross-validation and the AUROC curve for model assessment.\",\n",
      "            \"optimization/regularization\": \"For MARS, the forward stepwise algorithm leads to an overfitted model which is then run through a backward stepwise algorithm where basis functions that contribute the least are removed (Friedman1991).   For RF,  to reduce overfitting, the tree was often pruned, resulting in a smaller tree with fewer splits. This was accomplished using the Gini index, which is a measure of variance across all classes\\u2014smaller values mean a more accurate prediction at that node.\",\n",
      "            \"model/availability\": \"Standard algorithms were used.\",\n",
      "            \"model/interpretability\": \"No statement about ante-hoc interpretability of the models is made by the authors. LR and MARS are generally considered interpretable models, while ANN and RF are generally considered not interpretable. Post-hoc feature importance analysis indicated as the most important ones soil moisture, precipitation, and air temperature (LR model), or soil temperature, soil moisture, and solar radiation (MARS, ANN, RF models) -- all of them in line with conclusions found in experimental literature.\",\n",
      "            \"model/output\": \"Classification (binary prediction). The continuous output of the LR, MARS, ANN was assigned as 'close to 1' or 'close to 0'.\",\n",
      "            \"evaluation/comparison\": \"Four approaches were compared: LR, MARS, ANN, RF. Model performance was compared based on the AUROC, kappa-metrics, and Brier score. The best measures were those of RF.\",\n",
      "            \"evaluation/confidence\": \"Model performance was compared based on the AUROC, kappa metrics, and Brier score. The AUROC of the RF model was highest at 0.74, significantly higher than LR (with a value of 0.57) but not significantly different from the ANN or MARS models. LR had a very low kappa value (0.16), while RF had kappa values between 0.43 and 0.57, higher than ANN and MARS values of between 0.35 and 0.5 and, therefore, has the best prediction potential among the four models tested in this study based on the kappa metric.\",\n",
      "            \"evaluation/measure\": \"Accuracy, sensitivity, specificity, AUROC.\",\n",
      "            \"dataset/provenance\": \"Total dataset composed of 535 in-field observations, N_pos = 84  (presence of spore-realising apothecia) and N_neg = 352 (absence of spore-realising apothecia).  Dataset not previously used.\",\n",
      "            \"dataset/splits\": \"The dataset was randomly split into training (70%) and testing (30%) using the \\u201ccreateDataPartition\\u201d function part of the caret package in R (version 3.2.4 for iOS).  Each model was trained with 10-fold cross-validation.    The random splitting of the data, model training, and assessment on the test set were performed 100 times to ascertain the variance of each model due to the random data splitting.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bad\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"22558141\",\n",
      "            \"updated\": \"03/24/2022 11:24:39\",\n",
      "            \"authors\": \"Wrzodek C, B\\u00fcchel F, Hinselmann G, Eichner J, Mittag F, Zell A\",\n",
      "            \"journal\": \"PLoS One\",\n",
      "            \"title\": \"Linking the epigenome to the genome: correlation of different features to DNA methylation of CpG islands.\",\n",
      "            \"doi\": \"10.1371/journal.pone.0035327\",\n",
      "            \"year\": \"2012\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"c3ffe65b-e1f7-4326-a75c-44891ea42eb2\",\n",
      "        \"shortid\": \"y6rde1aew5\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/24/2022 11:24:39\",\n",
      "            \"publication/authors\": \"Wrzodek C, B\\u00fcchel F, Hinselmann G, Eichner J, Mittag F, Zell A\",\n",
      "            \"publication/journal\": \"PLoS One\",\n",
      "            \"publication/title\": \"Linking the epigenome to the genome: correlation of different features to DNA methylation of CpG islands.\",\n",
      "            \"optimization/features\": \"f = 12.   Starting from 16,205 genes, 12 genes were at the end selected as differentially expressed in RA versus non-RA patients.  Differential expression was defined as a fold-change cut-off of 1.2, combined with a significance level cut-off of p<0.05 (Welch\\u2019s t-test), corrected for multiple testing using the false-discovery-rate method of Benjamini.\",\n",
      "            \"optimization/parameters\": \"\\nThe authors do not mention parameters numbers different from standard. \\n\",\n",
      "            \"model/availability\": \"Standard algorithms are used.\",\n",
      "            \"model/interpretability\": \"No statement about ante-hoc interpretability of the model is made by the authors. SVM is generally considered black box. Post-hoc analysis indicates that PB CD4 T cells in early RA are characterised by a predominant upregulation of biological pathways involved in cell cycle progression (ACPA-positive) and survival, death and apoptosis (ACPA-negative). ( ACPA = anti-citrullinated peptide antibodies)\",\n",
      "            \"model/output\": \"Binary prediction: RA or non-RA.\",\n",
      "            \"evaluation/comparison\": \"A transcriptional \\u2018risk metrics\\u2019 for ACPA-negative patients was bild, and the AUROC curve of the 12-gene signature was compared to the existing \\u2018Leiden prediction rule\\u2019 as a predictor of RA in the test set. No difference in the performance was seen in this case. However, by combining all features of the Leiden prediction rule with the 12-gene risk metric, and applying it to the ACPA-negative UA cohort (test set), the AUROC curve value improved from 0.74, SEM=0.08 (original Leiden prediction rule) to 0.84; SEM=0.06 (modified metric incorporating gene signature).\",\n",
      "            \"evaluation/confidence\": \"AUROC curve (original Leiden prediction rule)=0.74; SEM=0.08 versus area under ROC curve (modified metric incorporating gene signature)=0.84; SEM=0.06; p<0.001 in both cases.\",\n",
      "            \"evaluation/measure\": \"Sensitivity, specificity, positive and negative likelihood ratio.\",\n",
      "            \"evaluation/method\": \"Test set (independent dataset).\",\n",
      "            \"dataset/availability\": \"Yes.    Raw and processed microarray data used in this study is available via Gene Expression Omnibus at: http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?token=bviftkociimgsnk&acc=GSE20098\",\n",
      "            \"dataset/provenance\": \"CD4 T-cell transcriptomes from 173 UK patients, of which N_pos = 72  (RA, i.e. outcome Rheumatoid Arthritis), N_neg =101 (outcome Non-RA).  Not used in previous papers.\",\n",
      "            \"dataset/splits\": \"111 patients in training set, of which N_pos_train = 47  (RA), N_neg_train = 64 (Non-RA).    62 patients in testing set, of which N_pos_test = 25  (RA), N_neg_test = 37 (Non-RA).   42.3% positives on training set.   40.3% positives on test set.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b3d\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"23102953\",\n",
      "            \"updated\": \"03/08/2022 14:59:55\",\n",
      "            \"authors\": \"Gonz\\u00e1lez-Recio O, Jim\\u00e9nez-Montero JA, Alenda R\",\n",
      "            \"journal\": \"J Dairy Sci\",\n",
      "            \"title\": \"The gradient boosting algorithm and random boosting for genome-assisted evaluation in large data sets.\",\n",
      "            \"doi\": \"10.3168/jds.2012-5630\",\n",
      "            \"year\": \"2013\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"7f0eb63d-7a88-4b70-82f9-857b0399a39f\",\n",
      "        \"shortid\": \"9hqbg4dzys\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/08/2022 14:59:55\",\n",
      "            \"publication/authors\": \"Gonz\\u00e1lez-Recio O, Jim\\u00e9nez-Montero JA, Alenda R\",\n",
      "            \"publication/journal\": \"J Dairy Sci\",\n",
      "            \"publication/title\": \"The gradient boosting algorithm and random boosting for genome-assisted evaluation in large data sets.\",\n",
      "            \"optimization/algorithm\": \"SVM and RF.\",\n",
      "            \"optimization/features\": \"The study focused on 412 proteins (of the 1296 identified proteins in each proteome) quantified in more than 80% of urine samples, with missing values filled by local least squares imputation.  From those 412 proteins, 5 proteins (ACP2, CTSA, GM2A, MUC1, and SPARCL1) were selected as significant by an AUC-based random forest method. \",\n",
      "            \"optimization/fitting\": \"The authors do not mention overfitting issues, although their multivariate AUROCs showed very high values.\",\n",
      "            \"optimization/parameters\": \"The authors do not mention parameters numbers different from standard.  They mention the value of some parameters, without mentioning how they were chosen. \",\n",
      "            \"model/availability\": \"Data were analyzed using the publicly available RStudio (version 1.1.456) including R (version 3.6.0).\",\n",
      "            \"model/interpretability\": \"No statement about ante-hoc interpretability of the models is made by the authors. The RF and SVM are generally considered black box. Post-hoc analysis resulted somewhat interpretable, since the 5 selected features correspond to 5 urinary proteins that are considered likely to be related to DKD. However, their eventual joint effect remains not interpretable.\",\n",
      "            \"model/output\": \"Binary classification (PPG or GPG). The binary results of RF and SVM models were also transformed in disease prediction scores, which ranged from 0 to 1.\",\n",
      "            \"evaluation/comparison\": \"The performances of the SVM and RF models were compared to the predicting performance of the albumin-to-creatinine ratio, a simple biomarker for DKD which has been widely used so far.\",\n",
      "            \"evaluation/confidence\": \"The authors state that the AUROC of the two classifiers (SVM and RF) differed significantly from albumin-to-creatinine ratio (likelihood ratio test: p-value < 0.05). However, for the RF AUROC (value = 1.0) no confidence intervals are reported, and the confidence intervals for SVM AUROC are not further specified.\",\n",
      "            \"evaluation/measure\": \"AUROC. Comparison of disease prediction scores.\",\n",
      "            \"evaluation/method\": \"Cross-validation. Since the authors were unable to find a benchmarking study in the discovery of urine protein biomarkers, they evaluated the models with mRNA expression in the kidney. The SVM and RF models consisting of 5 urine proteins were applied to 4 publicly available GEO datasets: GSE99339, GSE47185, GSE30122, and GSE96804. However, the predictions on such datasets were not statistically significant.\",\n",
      "            \"dataset/availability\": \"Yes. Supporting Information.\",\n",
      "            \"dataset/provenance\": \"Proteomes of urine samples from 54 T2D (Type 2 Diabetes) patients from Pusan National University Hospital, South Korea. N_pos = 19 (poor prognosis group (PPG) due to DKD (Diabetic Kidney Disease), N_neg = 35 (good prognosis group (GPG), i.e. no DKD).   Not used in previous papers.\",\n",
      "            \"dataset/splits\": \"SVM model with linear kernel was generated by a 10 fold repeated three-fold cross validation.  The RF model was generated by a 3-fold cross validation method repeated 100 times.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bb2\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"25404408\",\n",
      "            \"updated\": \"03/28/2022 23:06:53\",\n",
      "            \"authors\": \"Ultsch A, L\\u00f6tsch J\",\n",
      "            \"journal\": \"BMC Genomics\",\n",
      "            \"title\": \"What do all the (human) micro-RNAs do?\",\n",
      "            \"doi\": \"10.1186/1471-2164-15-976\",\n",
      "            \"year\": \"2014\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"98d8027e-41f2-4b54-8fd6-20c9b51e7bdf\",\n",
      "        \"shortid\": \"w5mge5bmyl\",\n",
      "        \"score\": 0.52,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/28/2022 23:06:53\",\n",
      "            \"publication/authors\": \"Ultsch A, L\\u00f6tsch J\",\n",
      "            \"publication/journal\": \"BMC Genomics\",\n",
      "            \"publication/title\": \"What do all the (human) micro-RNAs do?\",\n",
      "            \"optimization/algorithm\": \"J48 Algorithm For Decision Tree (WEKA)   Decision tree J48 is the implementation of algorithm ID3 (Iterative Dichotomiser 3) developed by the WEKA project team. \",\n",
      "            \"optimization/encoding\": \"Global features\",\n",
      "            \"optimization/features\": \"Sequence-based statistics were derived through a customized feature extraction program and fed as a vector for each polymorphism to the J48 classification tree available in the WEKA classifier package.  9 features were used to enhance polymorphism prediction accuracy (as reported in https://nealelab.ucdavis.edu/adept2-overview/pinesap/).\",\n",
      "            \"model/availability\": \"Broken link (http://dendrome.ucdavis.edu/adept2/\\n resequencing.html). The customized pipeline for feature extraction is reported in a new link: https://nealelab.ucdavis.edu/adept2-overview/pinesap/\",\n",
      "            \"model/interpretability\": \"Input features are transparent (Sequence Depth, Local Average Quality, Alignment Quality) while their combination is not interpretable (Black box).\",\n",
      "            \"model/output\": \"Binary classifier (SNP predictions accepted or rejected).\",\n",
      "            \"evaluation/comparison\": \"Polyphred, Polybayes. Used for generating the features.\",\n",
      "            \"evaluation/measure\": \"Accuracy, sensitivity, specificity\",\n",
      "            \"evaluation/method\": \"Independent dataset of 120 unique sequences with 563 manually validated SNPs. Validation = All SNP calls were identified as based on visual inspection of Polyphred and Polybayes predictions in Consed.\",\n",
      "            \"dataset/provenance\": \"Source: Pinus taeda resequencing data, not further specified.  Training set is composed of a total of 300 validated sequences.  Test set is composed of 120 independent sequences, with 563 manually validated SNPs.\",\n",
      "            \"dataset/splits\": \"\\nTesting: 120 Sequences 563 manually validated SNPs\\n\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bb4\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"24675637\",\n",
      "            \"updated\": \"03/08/2022 13:05:23\",\n",
      "            \"authors\": \"Mahony S, Edwards MD, Mazzoni EO, Sherwood RI, Kakumanu A, Morrison CA, Wichterle H, Gifford DK\",\n",
      "            \"journal\": \"PLoS Comput Biol\",\n",
      "            \"title\": \"An integrated model of multiple-condition ChIP-Seq data reveals predeterminants of Cdx2 binding.\",\n",
      "            \"doi\": \"10.1371/journal.pcbi.1003501\",\n",
      "            \"year\": \"2014\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"8067befa-adce-4b5a-9da3-d16a3566a794\",\n",
      "        \"shortid\": \"36d464edpz\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/08/2022 13:05:23\",\n",
      "            \"publication/authors\": \"Mahony S, Edwards MD, Mazzoni EO, Sherwood RI, Kakumanu A, Morrison CA, Wichterle H, Gifford DK\",\n",
      "            \"publication/journal\": \"PLoS Comput Biol\",\n",
      "            \"publication/title\": \"An integrated model of multiple-condition ChIP-Seq data reveals predeterminants of Cdx2 binding.\",\n",
      "            \"optimization/algorithm\": \"\\\"Hybrid dynamic Bayesian network (DBN) / support\\nvector machine (SVM)\\\"\",\n",
      "            \"optimization/encoding\": \"\\\"Pre-processing: Input data obtained from MS/MS data, an aqueous soluble protein sample from E.coli lysate was reduced, carbamidomethylated and digested with trypsin.\\\"\",\n",
      "            \"optimization/features\": \"\\\"99-dimensional feature vectors generated by Riptide (Bayesian part)\\\"\",\n",
      "            \"optimization/parameters\": \"For the SVM, we use a Gaussian kernel, and hyperparameters C (soft margin penalty) and sigma (low case, width of the Gaussian). Hyperparameters are selected using five-fold nested cross-validation, where the parameter with the largest area under the ROC curve is selected.\",\n",
      "            \"model/availability\": \"Upon request (but did not try to get it, there is a link to a tar file with, it says, C++ and Python for the Riptide part, I did not examine the files)\",\n",
      "            \"evaluation/comparison\": \"SEQUEST, Percolator\",\n",
      "            \"evaluation/confidence\": \"\\\"q value, which is defined as the minimal false discovery rate threshold at which the\\n PSM is deemed significant\\\"\",\n",
      "            \"evaluation/measure\": \"Kind of discussed but did not see values\",\n",
      "            \"evaluation/method\": \"\\\"Comparison against SEQUEST (Riptide with the static SVM outperforms SEQUEST by 10.8% at a 1% false discovery rate) and Percolator\\\"\",\n",
      "            \"dataset/availability\": \"PSMs at http://noble.gs.washington.edu/proj/intense (also stated that availability is upon request but the URL indeed has links to the data)\",\n",
      "            \"dataset/provenance\": \"1208 peptide spectrum matches (PSMs) and 18149 mass spectra for validation\",\n",
      "            \"dataset/splits\": \"Positive and negative points for the Bayesian network are mentioned but no further info provided\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bb5\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"24977146\",\n",
      "            \"updated\": \"03/15/2022 11:52:26\",\n",
      "            \"authors\": \"Xu R, Zhou J, Liu B, Yao L, He Y, Zou Q, Wang X\",\n",
      "            \"journal\": \"Biomed Res Int\",\n",
      "            \"title\": \"enDNA-Prot: identification of DNA-binding proteins by applying ensemble learning.\",\n",
      "            \"doi\": \"10.1155/2014/294279\",\n",
      "            \"year\": \"2014\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"37b6eb38-2c74-40e9-9f75-95d27907ae41\",\n",
      "        \"shortid\": \"qto6tkwcli\",\n",
      "        \"score\": 0.48,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/15/2022 11:52:26\",\n",
      "            \"publication/authors\": \"Xu R, Zhou J, Liu B, Yao L, He Y, Zou Q, Wang X\",\n",
      "            \"publication/journal\": \"Biomed Res Int\",\n",
      "            \"publication/title\": \"enDNA-Prot: identification of DNA-binding proteins by applying ensemble learning.\",\n",
      "            \"optimization/algorithm\": \"The semantic role labeling (SRL) system BIOSMILE, which is based on Maximum entropy. \\n\\nNovel rule-based converter based on verb-by-verb conversion rules which describe under which conditions each mapping is valid.The algorithm used by the rule-generator compares corresponding framesets for a given verb sense, checks each argument in its PASBio frameset, and tries to find an argument in its BioProp frameset that has the same semantic role under a set of conditions. When a match is found, the algorithm maps a link between the two frameset arguments, which includes a description of required conditions, named entities (NEs) and keywords.\\n\",\n",
      "            \"optimization/encoding\": \"1)\\tTagging of 5 names entities (NEs), protein, Dnot reported, Rnot reported, cell line, and cell type, with NERBio recognition software. A dictionary was used to find other NE types, such as exon and intron.\\n2)\\tIdentification of the PAS objects of each sentence followed by classification of the semantic roles of the arguments according to BioProp format, using BIOSMILE SRL system.\\n3)\\tRule-based conversion from BioProp to PASBio annotation, using the novel rule-based converter.\\n\",\n",
      "            \"optimization/features\": \"Semantic roles of PAS objects following PASBio annotation\",\n",
      "            \"optimization/meta\": \"Yes. Combination of BIOSMILE SRL system output with novel rule-based converter. Independency not reported.\",\n",
      "            \"model/output\": \"Multi-label predictions\",\n",
      "            \"evaluation/comparison\": \"Comparison with ML-based SRL systems of other specific domains based on F-score performance\",\n",
      "            \"evaluation/measure\": \"Precision, recall, F-score\",\n",
      "            \"evaluation/method\": \"3-fold cross-validation\",\n",
      "            \"dataset/provenance\": \"Manually re-annotated 313 sentences, containing 2304 predicate-argument structures (PAS) annotated for 49 biomedical verbs.\",\n",
      "            \"dataset/splits\": \"Separation of dataset into 3 subsets. Ntrain = 2 subsets. Ntest = 1 subset. The process is repeated three times, with each of the test sets being used exactly once (3-fold cross-validation).\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"66732d6237ea6fa797a6c33c\",\n",
      "        \"shortid\": \"ats2zi61i5\",\n",
      "        \"uuid\": \"1dcb40c7-3c20-484d-9f45-bcf91cfd4d17\",\n",
      "        \"created\": \"2024-06-19T19:11:30.981Z\",\n",
      "        \"updated\": \"2024-06-19T19:11:30.981Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"24498380\",\n",
      "            \"authors\": \"Daniel Beck, James A. Foster\",\n",
      "            \"journal\": \"PLOS One\",\n",
      "            \"title\": \"Machine Learning Techniques Accurately Classify Microbial Communities by Bacterial Vaginosis Characteristics\",\n",
      "            \"doi\": \"10.1371/journal.pone.0087830\",\n",
      "            \"year\": \"2014\"\n",
      "        },\n",
      "        \"score\": 0.95,\n",
      "        \"matches\": {\n",
      "            \"evaluation/availability\": \"No availability of evaluation files, code, etc.\",\n",
      "            \"evaluation/comparison\": \"No comparison was made to any publicly available methods.\\n\\nNo benchmark datasets used or against simpler baselines compared to unless considering the complexity variances between the 3x models to be a simpler baseline varying by model complexity.\",\n",
      "            \"evaluation/confidence\": \"No confidence intervals or values noted in the text. \",\n",
      "            \"evaluation/measure\": \"The performance measures used to evaluate the accuracy of the 3x models were:\\n-The accuracy of the 3x models at performing the correct classification (above 90% for Nugent score BV + above 80% for Amsel criteria BV.)\\n-The receiver operator curves (ROCs) of the 3x models in 'Figure 2. A comparison of the classification accuracies for each machine learning technique'\",\n",
      "            \"evaluation/method\": \"10-fold cross-validation was noted as the primary evaluation method used in the text.\\n\\nAdditionally, the authors compare the 3x models on two datasets but these seem to be the same ones used to train the models. No clarity on splits or redundancy of the model data for the evalutaion vs training.\",\n",
      "            \"optimization/algorithm\": \"Text notes used of three machine learning algorithm types.\\n\\nML algorithms: \\n1. Gaussian process classifier\\n2. Random forests\\n3. Logistic regression \\n\\nNot new algorithms.\\n\\nChose these types as some are more efficient than others at the classification needed.\",\n",
      "            \"optimization/config\": \"No - not reported in text and no links to configurations.\",\n",
      "            \"optimization/encoding\": \"Not explicitly noted in text. Data will likely have been encoded for Microbial Taxa & BV status.\",\n",
      "            \"optimization/features\": \"Features noted to be algorithm specific across each of the 3x models created.\\n\\nTable 1. This table shows the fifteen most important features identified by the different classifiers.\\n-Based on this it can be inferred that the models had at least 15x features but does not list all or the total number.\\n\\nFeature selection seems to have been done as the author notes that they ranked the features by their apparent importance to each model.\",\n",
      "            \"optimization/fitting\": \"Potentially models were overfit. No exact p or f numbers to help determination. There are low dataset sizes noted in text (396 and 220). However, the text notes some overfitting prevention methods such as cross-validation and model complexity penalties.\",\n",
      "            \"optimization/parameters\": \"For the gaussian process classifier, Table 2. lists the parameter values used.\\n-6x parameters noted in the table and corresponding values.\\n\\nFor the random forest model,  the author notes use of R package 'randomForest' on default parameters. \\n\\nFor the logistic regression model, the author notes use of R package 'glmnet' on default parameters. \",\n",
      "            \"optimization/regularization\": \"Ten-fold cross validation was the primary technique employed to prevent overfitting.\",\n",
      "            \"model/availability\": \"No - no clear links to a code repository or GitHub from the publication.\",\n",
      "            \"model/duration\": \"The different classification techniques varied widely in computational time: \\n\\n-Logistic regression + random forests were noted as relatively quick to run, usually completing in less than an hour on a single laptop. \\n\\n-Gaussian process classifier is noted to have taken several hours longer to run.\",\n",
      "            \"model/interpretability\": \"Black box - missing a lot of key information. No GitHub linked for model code and no links to training/test data. Very poor use of the DOME related info breakdowns and 3x models poorly described overall in text making the interpretability black box like.\",\n",
      "            \"dataset/availability\": \"Only publications listed - by searching these publications the data only seems to be available for one of the two and linked from its text as supplementary data files (Ravel et al. in 2011 [8]:). Data splits not available. No licenses or URL.\",\n",
      "            \"dataset/provenance\": \"Data source: publications\\n\\nData type: 16S rRNA seq data (for understanding microbial communities - microbiome)\\n\\nThe data used consists of two different datasets drawn from studies published by:\\n-Ravel et al. in 2011 [8]:\\nRavel J, Gajer P, Abdo Z, Schneider GM, Koenig SSK, et al. (2011) Vaginal microbiome of reproductive-age women. Proceedings of the National Academy of Science USA 108: 4680\\u20134687.\\n\\n-Srinivasan et al. in 2012 [9]:\\nSrinivasan S, Hoffman NG, Morgan MT, Matsen FA, Fiedler TL, et al. (2012) Bacterial communities in women with bacterial vaginosis: high resolution phylogenetic analysis reveal relationships of microbiota to clinical criteria. PLoS One 7: 6.\",\n",
      "            \"dataset/redundancy\": \"No information relating to the redundancy between data splits evident in the text.\",\n",
      "            \"dataset/splits\": \"Data splits are not mentioned in the text.\\n\\nDataset sizes & data within:\\n-Ravel et al. dataset: 396 samples - included only asymptomatic participants\\n-Srinivasan et al. dataset: 220 samples - included women with and without a BV diagnosis.\",\n",
      "            \"publication/authors\": \"Daniel Beck, James A. Foster\",\n",
      "            \"publication/journal\": \"PLOS One\",\n",
      "            \"publication/title\": \"Machine Learning Techniques Accurately Classify Microbial Communities by Bacterial Vaginosis Characteristics\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b73\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"26834994\",\n",
      "            \"updated\": \"03/09/2022 11:07:20\",\n",
      "            \"authors\": \"Ekins S, Freundlich JS, Clark AM, Anantpadma M, Davey RA, Madrid P\",\n",
      "            \"journal\": \"F1000Res\",\n",
      "            \"title\": \"Machine learning models identify molecules active against the Ebola virus <i>in vitro</i>.\",\n",
      "            \"doi\": \"10.12688/f1000research.7217.3\",\n",
      "            \"year\": \"2015\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"874bbd17-26ef-4992-9473-d3a4a22d9280\",\n",
      "        \"shortid\": \"p9igs00nw2\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/09/2022 11:07:20\",\n",
      "            \"publication/authors\": \"Ekins S, Freundlich JS, Clark AM, Anantpadma M, Davey RA, Madrid P\",\n",
      "            \"publication/title\": \"Machine learning models identify molecules active against the Ebola virus <i>in vitro</i>.\",\n",
      "            \"optimization/algorithm\": \"Novel semi-supervised algorthm called AMVML (Adaptive Multi-View Multi-Label). No reason stated for not having published it before.\",\n",
      "            \"optimization/encoding\": \"Not transformed\",\n",
      "            \"optimization/features\": \"not reported, but could be inferred from the text.\",\n",
      "            \"optimization/parameters\": \"not reported, maybe could be inferred from the paper.\",\n",
      "            \"model/availability\": \"Yes for one specific case: https://github.com/alcs417/AMVML\",\n",
      "            \"model/interpretability\": \"Trasparent. Prediction based on similarity between different miRNAs and different diseases. If a given miRNA is associated to a given disease D, it might be associated only with diseases similar to D\",\n",
      "            \"model/output\": \"Regression (association probability with a disease)\",\n",
      "            \"evaluation/comparison\": \"Compared with other 4 methods for predicting miRNA-disease association. Statistical significance is given as proof for performance.\",\n",
      "            \"evaluation/confidence\": \"The performarce difference is statistically significant compared to other 4 algorithms\",\n",
      "            \"evaluation/measure\": \"Area Under Curve (AUC)\",\n",
      "            \"evaluation/method\": \"Leave-one-out validation and 5-fold cross-validation on Dataset 1\\n 5-fold cross validation on Dataset 3\",\n",
      "            \"dataset/availability\": \"Dataset 1: No.\\n\\nDataset 2: No.\\n\\nDataset 3. Yes. URL: https://portal.gdc.cancer.gov/projects/TCGA-THCA\",\n",
      "            \"dataset/provenance\": \"They use different datasets in the paper.\\n\\nDataset 1: obtained composing data from different databases. miRnot reported-disease association data were retrived from the database HMDD v2.0. They added miRnot reported information using data from the miRBase database and added disease information using MeSH descriptors. The final dataset was used to compose a matrix where miRnot reported associated to a disease was labeled 1 and 0 otherwise. N, N_pos, and N_neg not reported, but could be inferred from the text. \\n\\nDataset 2: miRnot reported-disease association data from HMDD v1.0\\n\\nDataset3: miRnot reported expression data associated with Tyroid cancer, retrived from The Cancer Genome Atlas (Project TCGA-THCA).\\n\\nDataset 1 not used in previous papers. Datasets 2 and 3 used in the community.\",\n",
      "            \"dataset/splits\": \"not reported, but could be inferred from the text.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b7e\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"25878156\",\n",
      "            \"updated\": \"01/24/2022 17:28:42\",\n",
      "            \"authors\": \"Connolly AT, Jensen AL, Baker KB, Vitek JL, Johnson MD\",\n",
      "            \"journal\": \"J Neurophysiol\",\n",
      "            \"title\": \"Classification of pallidal oscillations with increasing parkinsonian severity.\",\n",
      "            \"doi\": \"10.1152/jn.00840.2014\",\n",
      "            \"year\": \"2015\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"c3dde50f-83db-4289-96ec-dbfdca27594b\",\n",
      "        \"shortid\": \"duas5qkjag\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"01/24/2022 17:28:42\",\n",
      "            \"publication/authors\": \"Connolly AT, Jensen AL, Baker KB, Vitek JL, Johnson MD\",\n",
      "            \"publication/journal\": \"J Neurophysiol\",\n",
      "            \"publication/title\": \"Classification of pallidal oscillations with increasing parkinsonian severity.\",\n",
      "            \"optimization/config\": \"All analysis scripts are available on GitHub: https://github.com/umutcaglar/ecoli_multiple_growth_conditions (permanent archived version available via zenodo: 10.5281/zenodo.1294110)\",\n",
      "            \"optimization/encoding\": \"level of transcripts/proteins expression\",\n",
      "            \"optimization/features\": \"Number of transcripts/proteins in E.coli unspecified. Feature selection performed on training data with PCA: 10 features retained\",\n",
      "            \"optimization/fitting\": \"f = 10, N_train \\u2248 90 - Low dimensional SVM\",\n",
      "            \"optimization/parameters\": \"Kernel selected with a grid search and performance evaluation on the validation set\",\n",
      "            \"model/availability\": \"Allanalysis scripts are available on GitHub: https://github.com/umutcaglar/ecoli_multiple_growth_conditions (permanent archived version available via zenodo: 10.5281/zenodo.1294110)\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/comparison\": \"Different kernels are used. Random forests are used.\",\n",
      "            \"evaluation/confidence\": \"Distributions over the samples are reported, but no statistical evaluation is computed.\",\n",
      "            \"evaluation/measure\": \"F1 score\",\n",
      "            \"evaluation/method\": \"Independent test set + externa test set\",\n",
      "            \"dataset/availability\": \"All processed data are available on GitHub: https://github.com/umutcaglar/ecoli_multiple_growth_conditions (permanent archived version available via zenodo: 10.5281/zenodo.1294110)\",\n",
      "            \"dataset/provenance\": \"Previous publication: 155 E. coli samples (102 have both mRnot reported and protein abundance data; 50 have only mRnot reported abundance data; 3 have only protein abundance data). \\nExternal validation performed on 5 samples from a different publication.\",\n",
      "            \"dataset/redundancy\": \"No measure of independence provided\",\n",
      "            \"dataset/splits\": \"Diffent conditions are considered: carbon sources (glucose, glycerol, gluconate, and lactate),  sodium concentrations (base and high), and magnesium concentrations (low, base, and high). Different splits are therefore adopted.\\nSplitting: training/validation set:test set=80:20. Training:validation=75:25 (x 10 independent runs).\\nSemi-random split preserving the ratios of different conditions between the training/validation and the test subsets. \"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b96\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"25849257\",\n",
      "            \"updated\": \"03/21/2022 11:49:08\",\n",
      "            \"authors\": \"Gigu\\u00e8re S, Laviolette F, Marchand M, Tremblay D, Moineau S, Liang X, Biron \\u00c9, Corbeil J\",\n",
      "            \"journal\": \"PLoS Comput Biol\",\n",
      "            \"title\": \"Machine learning assisted design of highly active peptides for drug discovery.\",\n",
      "            \"doi\": \"10.1371/journal.pcbi.1004074\",\n",
      "            \"year\": \"2015\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"1212cc08-554d-44ca-a4b8-1544c008b3ce\",\n",
      "        \"shortid\": \"nlsxj0478u\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/21/2022 11:49:08\",\n",
      "            \"publication/authors\": \"Gigu\\u00e8re S, Laviolette F, Marchand M, Tremblay D, Moineau S, Liang X, Biron \\u00c9, Corbeil J\",\n",
      "            \"publication/journal\": \"PLoS Comput Biol\",\n",
      "            \"publication/title\": \"Machine learning assisted design of highly active peptides for drug discovery.\",\n",
      "            \"optimization/algorithm\": \"Random Forest\",\n",
      "            \"optimization/encoding\": \"random sample of (number of descriptors) ^(1/2) until the tree can no longer grow\",\n",
      "            \"optimization/features\": \"existing protein-ligand scoring function RF-Score and\\na new accessibility-like algorithm called CavSeek to compute structurally-based binding descriptors and descriptors pertaining to the composition and flexibility of the clefts.\",\n",
      "            \"model/interpretability\": \"transparent since there is a methodological feature selection.\",\n",
      "            \"evaluation/confidence\": \"Statistical confidence. The times assigned to each class are given so as to express the approximate level of confidence with which a class has been assigned from 100 repeats.\",\n",
      "            \"evaluation/measure\": \"Gini importance measure, RF-score and CavSeek\",\n",
      "            \"evaluation/method\": \"out-of-bag set and independent test set\",\n",
      "            \"dataset/provenance\": \"data were primarily collected from the online Allosteric Database (ASD)\",\n",
      "            \"dataset/redundancy\": \"selection of negative and positive for balanced datasets\",\n",
      "            \"dataset/splits\": \"allosteric sites (59), regular sites (99), orthosteric sited (159)\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b97\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"26495028\",\n",
      "            \"updated\": \"03/29/2022 21:41:26\",\n",
      "            \"authors\": \"Rodr\\u00edguez-Escobedo JG, Garc\\u00eda-Sep\\u00falveda CA, Cuevas-Tello JC\",\n",
      "            \"journal\": \"Comput Math Methods Med\",\n",
      "            \"title\": \"KIR Genes and Patterns Given by the A Priori Algorithm: Immunity for Haematological Malignancies.\",\n",
      "            \"doi\": \"10.1155/2015/141363\",\n",
      "            \"year\": \"2015\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"cfb3eddf-4a2d-4640-9d9e-8650193f3286\",\n",
      "        \"shortid\": \"r7jsdtsoxh\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/29/2022 21:41:26\",\n",
      "            \"publication/authors\": \"Rodr\\u00edguez-Escobedo JG, Garc\\u00eda-Sep\\u00falveda CA, Cuevas-Tello JC\",\n",
      "            \"publication/journal\": \"Comput Math Methods Med\",\n",
      "            \"publication/title\": \"KIR Genes and Patterns Given by the A Priori Algorithm: Immunity for Haematological Malignancies.\",\n",
      "            \"optimization/algorithm\": \"Deep Transfer Learning (type of Deep Neural Network)\",\n",
      "            \"optimization/regularization\": \"leave-one-compound-out cross-validation (LOOCV)\",\n",
      "            \"model/duration\": \"500 min\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/measure\": \"Accuracy, confusion matrices\",\n",
      "            \"dataset/availability\": \"https://bbbc.broadinstitute.org/ accession BBBC021\",\n",
      "            \"dataset/splits\": \"148649 cells. 1/2 source and 1/2 target\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b9c\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"25175491\",\n",
      "            \"updated\": \"05/20/2022 17:45:46\",\n",
      "            \"authors\": \"Zheng B, Liu J, Gu J, Lu Y, Zhang W, Li M, Lu H\",\n",
      "            \"journal\": \"Int J Cancer\",\n",
      "            \"title\": \"A three-gene panel that distinguishes benign from malignant thyroid nodules.\",\n",
      "            \"doi\": \"10.1002/ijc.29172\",\n",
      "            \"year\": \"2015\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"b96ff1c7-58ce-47a8-8d72-140992f72b1c\",\n",
      "        \"shortid\": \"0mlbkqclbr\",\n",
      "        \"score\": 0.43,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"05/20/2022 17:45:46\",\n",
      "            \"publication/authors\": \"Zheng B, Liu J, Gu J, Lu Y, Zhang W, Li M, Lu H\",\n",
      "            \"publication/journal\": \"Int J Cancer\",\n",
      "            \"publication/title\": \"A three-gene panel that distinguishes benign from malignant thyroid nodules.\",\n",
      "            \"optimization/algorithm\": \"Many algorithms compared: Decision Trees, Support Vector Machine, Neural Network (multilayer perceptron), Naive Bayes, Decision Rule\",\n",
      "            \"optimization/encoding\": \"Not clearly stated. They just mention the elimination of non valid attributes (e.g. missing or NaN value for some features) and the selection of attributes through Chi Square Evaluation.\",\n",
      "            \"optimization/features\": \"Not clearly stated (they say \\\"around 100\\\")\",\n",
      "            \"model/interpretability\": \"Both transparent (e.g. Decision Trees) and black box algorithms (e.g. Neural Networks) were used.\",\n",
      "            \"evaluation/comparison\": \"Comparison was made among the methods used, based on the ROC Area\",\n",
      "            \"evaluation/measure\": \"ROC Area\",\n",
      "            \"evaluation/method\": \"Experimental Validation\",\n",
      "            \"dataset/provenance\": \"Dataset generated by the authors. Total number of instances not clearly stated (they state \\\"around 250\\\"), but could be inferred from Supplementary Informations. N_pos or N_neg not reported Dataset not used in previous papers.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b9e\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"26068103\",\n",
      "            \"updated\": \"03/06/2022 17:08:06\",\n",
      "            \"authors\": \"Blondel M, Onogi A, Iwata H, Ueda N\",\n",
      "            \"journal\": \"PLoS One\",\n",
      "            \"title\": \"A Ranking Approach to Genomic Selection.\",\n",
      "            \"doi\": \"10.1371/journal.pone.0128570\",\n",
      "            \"year\": \"2015\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"e92f4f40-8f6b-4688-9bf5-24409e3eb9bb\",\n",
      "        \"shortid\": \"4ecj3a4lnj\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/06/2022 17:08:06\",\n",
      "            \"publication/authors\": \"Blondel M, Onogi A, Iwata H, Ueda N\",\n",
      "            \"publication/journal\": \"PLoS One\",\n",
      "            \"publication/title\": \"A Ranking Approach to Genomic Selection.\",\n",
      "            \"optimization/algorithm\": \"J48 Algorithm, A Priori Algorithm\",\n",
      "            \"model/duration\": \"no, the authors only described the machine, \\\"Weka software using a personal computer with a processor IntelCore i7with 2.3Ghz speed and 3 Gb memory.\\\"\",\n",
      "            \"model/interpretability\": \"transparent, the authors provided biological explanation some of scenarios\",\n",
      "            \"evaluation/measure\": \"\\ud835\\udc5d value, \\ud835\\udf122\",\n",
      "            \"evaluation/method\": \"statisctical evaluation\",\n",
      "            \"dataset/provenance\": \"300 healthy individuals (Mexican Reference Genomic Dnot reported Collection (MGDC-REF),)\\n43 patients with haematological malignancies (Haematology Department of Hospital Central \\u201cDr. Ignacio Morones Prieto\\u201d)\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b9f\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"26495028\",\n",
      "            \"updated\": \"03/08/2022 10:53:29\",\n",
      "            \"authors\": \"Rodr\\u00edguez-Escobedo JG, Garc\\u00eda-Sep\\u00falveda CA, Cuevas-Tello JC\",\n",
      "            \"journal\": \"Comput Math Methods Med\",\n",
      "            \"title\": \"KIR Genes and Patterns Given by the A Priori Algorithm: Immunity for Haematological Malignancies.\",\n",
      "            \"doi\": \"10.1155/2015/141363\",\n",
      "            \"year\": \"2015\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"432f82cf-b140-411c-917b-b6c655b11e1f\",\n",
      "        \"shortid\": \"r3o9d6vk1p\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/08/2022 10:53:29\",\n",
      "            \"publication/authors\": \"Rodr\\u00edguez-Escobedo JG, Garc\\u00eda-Sep\\u00falveda CA, Cuevas-Tello JC\",\n",
      "            \"publication/journal\": \"Comput Math Methods Med\",\n",
      "            \"publication/title\": \"KIR Genes and Patterns Given by the A Priori Algorithm: Immunity for Haematological Malignancies.\",\n",
      "            \"optimization/algorithm\": \"Novel, graph theory based approach to learn Generic String kernel (G\",\n",
      "            \"optimization/encoding\": \"Sequence to binding affinities and IC50\",\n",
      "            \"optimization/features\": \"Sequence (GS kernel), Synthetic data used.\",\n",
      "            \"optimization/fitting\": \"not a binary classification problem, hence positive negative training data not used.\",\n",
      "            \"optimization/parameters\": \"position-specific weight matrix (PSWM)\",\n",
      "            \"model/availability\": \"link given https://graal.ift.ulaval.ca/peptide-design/, but page not found\",\n",
      "            \"model/interpretability\": \"Transparent, graph model\",\n",
      "            \"model/output\": \"Predict a string of amino acids with antimicrobial properties.\",\n",
      "            \"evaluation/availability\": \"No, URL isn't working.\",\n",
      "            \"evaluation/comparison\": \"Pearson correlation of prediction with values in databases)\",\n",
      "            \"evaluation/confidence\": \"Correlation coefficient of 0.90 and 0.93 were reported for two different datasets used.\",\n",
      "            \"evaluation/measure\": \"Pearson correlation coefficient ( correlation of prediction with values in databases)\",\n",
      "            \"evaluation/method\": \"kernel ridge regression with training used for validation. Also performed lab experiments.\",\n",
      "            \"dataset/provenance\": \"Data taken from Wade 2002 (101 data points), Ufkes 1982 (31 data points),  its quantitative continuous data - peptide sequence and anti-microbial activity (binding affinity, IC50), hence no positive negative, \",\n",
      "            \"dataset/redundancy\": \"Synthetic data used\",\n",
      "            \"dataset/splits\": \"Data is peptide sequence and anti-microbial activity (binding affinity, IC50),  hence no pos and negative control,  first built a model to generate synthetic data and used 1000 of such data for training.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305ba0\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"26422234\",\n",
      "            \"updated\": \"03/09/2022 10:11:09\",\n",
      "            \"authors\": \"S\\u00f8ndergaard D, Pedersen CN\",\n",
      "            \"journal\": \"PLoS One\",\n",
      "            \"title\": \"PATBox: A Toolbox for Classification and Analysis of P-Type ATPases.\",\n",
      "            \"doi\": \"10.1371/journal.pone.0139571\",\n",
      "            \"year\": \"2015\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"d6ffe3b1-8da7-40dd-ae1e-a31ebb7c757c\",\n",
      "        \"shortid\": \"5i5yt6gjy3\",\n",
      "        \"score\": 0.33,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/09/2022 10:11:09\",\n",
      "            \"publication/authors\": \"S\\u00f8ndergaard D, Pedersen CN\",\n",
      "            \"publication/journal\": \"PLoS One\",\n",
      "            \"publication/title\": \"PATBox: A Toolbox for Classification and Analysis of P-Type ATPases.\",\n",
      "            \"optimization/algorithm\": \"Novel approach\",\n",
      "            \"model/availability\": \"Supplementary data of the article\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/comparison\": \"stochastic simulations\",\n",
      "            \"dataset/availability\": \"Yes, the Drosophila Bicoid data used in this study is available from the FlyEx database, http://urchin.spbcas.ru/flyex/\\n\",\n",
      "            \"dataset/provenance\": \"syntetic data and one public dataset\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305ba8\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"26495028\",\n",
      "            \"updated\": \"02/08/2022 15:10:18\",\n",
      "            \"authors\": \"Rodr\\u00edguez-Escobedo JG, Garc\\u00eda-Sep\\u00falveda CA, Cuevas-Tello JC\",\n",
      "            \"journal\": \"Comput Math Methods Med\",\n",
      "            \"title\": \"KIR Genes and Patterns Given by the A Priori Algorithm: Immunity for Haematological Malignancies.\",\n",
      "            \"doi\": \"10.1155/2015/141363\",\n",
      "            \"year\": \"2015\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"0f4944df-a1cc-4bf4-a6da-bb1ce13b71df\",\n",
      "        \"shortid\": \"74z8knxsmc\",\n",
      "        \"score\": 0.38,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/08/2022 15:10:18\",\n",
      "            \"publication/authors\": \"Rodr\\u00edguez-Escobedo JG, Garc\\u00eda-Sep\\u00falveda CA, Cuevas-Tello JC\",\n",
      "            \"publication/journal\": \"Comput Math Methods Med\",\n",
      "            \"publication/title\": \"KIR Genes and Patterns Given by the A Priori Algorithm: Immunity for Haematological Malignancies.\",\n",
      "            \"optimization/algorithm\": \"TargetScan - non-ML algorithm\",\n",
      "            \"optimization/parameters\": \"params provided in additional info\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"probability score\",\n",
      "            \"dataset/availability\": \"Yes, website URL\",\n",
      "            \"dataset/provenance\": \"Dataset links provided in Table 1\",\n",
      "            \"dataset/splits\": \"Some details provided in Additional information\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305ba9\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"25783485\",\n",
      "            \"updated\": \"02/28/2022 13:11:53\",\n",
      "            \"authors\": \"Engchuan W, Dhindsa K, Lionel AC, Scherer SW, Chan JH, Merico D\",\n",
      "            \"journal\": \"BMC Med Genomics\",\n",
      "            \"title\": \"Performance of case-control rare copy number variation annotation in classification of autism.\",\n",
      "            \"doi\": \"10.1186/1755-8794-8-S1-S7\",\n",
      "            \"year\": \"2015\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"35b090fd-315b-4d28-93d7-b2c94ae39deb\",\n",
      "        \"shortid\": \"0jrk3ke80f\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/28/2022 13:11:53\",\n",
      "            \"publication/authors\": \"Engchuan W, Dhindsa K, Lionel AC, Scherer SW, Chan JH, Merico D\",\n",
      "            \"publication/journal\": \"BMC Med Genomics\",\n",
      "            \"publication/title\": \"Performance of case-control rare copy number variation annotation in classification of autism.\",\n",
      "            \"optimization/algorithm\": \"SOMs and kNNs\",\n",
      "            \"optimization/parameters\": \"k = 5 neighbors;  Euclidean distance d(x1,x2), of 2, and a distance weight w(i),p of 2\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/comparison\": \"We decided to apply SOM and kNN for the Corg models, as previous methods such as the derivation of Corg stocks from classified vegetation types or the derivation via quantiles in a classification and regression tree (CART) approach had only \\n limited success.\",\n",
      "            \"evaluation/confidence\": \"ML training metrics\",\n",
      "            \"evaluation/measure\": \"bias and the root mean square error (RMSE)\",\n",
      "            \"dataset/provenance\": \"RapidEye data were used as the high spatial resolution reflects the spatial heterogeneity of carbon  https://doi.org/10.1016/j.actaastro.2009.06.008\",\n",
      "            \"dataset/splits\": \"104 in situ inventory plots\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305baa\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"25646976\",\n",
      "            \"updated\": \"03/03/2022 14:47:08\",\n",
      "            \"authors\": \"Jorda J, Liu Y, Bobik TA, Yeates TO\",\n",
      "            \"journal\": \"PLoS Comput Biol\",\n",
      "            \"title\": \"Exploring bacterial organelle interactomes: a model of the protein-protein interaction network in the Pdu microcompartment.\",\n",
      "            \"doi\": \"10.1371/journal.pcbi.1004067\",\n",
      "            \"year\": \"2015\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"6fbdbce3-56b4-4ceb-853f-9b5c4604cd2c\",\n",
      "        \"shortid\": \"7hxvmu9cij\",\n",
      "        \"score\": 0.95,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/03/2022 14:47:08\",\n",
      "            \"publication/authors\": \"Jorda J, Liu Y, Bobik TA, Yeates TO\",\n",
      "            \"publication/journal\": \"PLoS Comput Biol\",\n",
      "            \"publication/title\": \"Exploring bacterial organelle interactomes: a model of the protein-protein interaction network in the Pdu microcompartment.\",\n",
      "            \"optimization/algorithm\": \"Heterogeneous ensemble classifier baed on adaboost (but for unbalanced data), with 20 different based classifiers  including rule-based, SVM, tree-based and KNN-based classifiers.\",\n",
      "            \"optimization/config\": \"Not available, but there is a platform for the tool\",\n",
      "            \"optimization/encoding\": \"188 feature vector for each protein sequence with information on composition, distribution and physiochemical properties\",\n",
      "            \"optimization/features\": \"188 features per sequence. No feature selection appears to be performed.\",\n",
      "            \"optimization/fitting\": \"Nothing reported except for the claim that their method of selecting negative cases in function of their difficulty leads to less over-fitting.  No feature selection was performed, no cross-validation\",\n",
      "            \"optimization/meta\": \"There is not sufficient information.  They calculate a 188 feature vector with properties about the sequence composition, distribution and physiochemical properties, but they not provide details on whether these are predictions or actual calculations.\",\n",
      "            \"optimization/parameters\": \"Details on the parameters of each independent learner  in the ensemble are not reported. Their ensemble method uses a weight for each negative sample in the training set to tune the sampling of the negative instances\",\n",
      "            \"optimization/regularization\": \"not really\",\n",
      "            \"model/availability\": \"platform : http://bliulab.net/Ensemble-DNA-Prot/index.jsp\",\n",
      "            \"model/interpretability\": \"no interpretation provided, only performance assessment. Remains black box as it is based on 20 different learners.\",\n",
      "            \"model/output\": \"binary (I assume based on the pseudocode provided)\",\n",
      "            \"evaluation/comparison\": \"Compared to other methods : DNAbinder, DNA-prot, iDNA-prot They were all reimplemented in house on the same data sets.\",\n",
      "            \"evaluation/confidence\": \"value comparison, no statistical tests\",\n",
      "            \"evaluation/measure\": \"ACC, MCC, SE, SP and F1\",\n",
      "            \"evaluation/method\": \"independent data sets only\",\n",
      "            \"dataset/availability\": \"all data is made available via Supplementary information\",\n",
      "            \"dataset/provenance\": \"four datasets are used, two for training and two for testing. The first set consist of 146 positive and 250 negative cases.  They were obtained from two earlier publications on the same topic.  The second set is an expansion of the first, adding more negative instances. Te negative set is increases to 2125 instances. The third set is obtained from another publication, consisting of 92 positive and 100 negative instances.  The last set contains 823 positive and 823 negative instances, also extracted from another publication. \",\n",
      "            \"dataset/redundancy\": \"With the data sets, sequences with a pairwise identity larger or equal to 25% were removed.  All sequences in the test sets that had a pairwise sequence identity larger or equal to 40% were removed from the test sets (using CD-HIT).  \",\n",
      "            \"dataset/splits\": \"Data set 1 and.2 are used for training, dataset 3 and 4 for testing. \"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bae\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"25878156\",\n",
      "            \"updated\": \"01/21/2022 17:00:14\",\n",
      "            \"authors\": \"Connolly AT, Jensen AL, Baker KB, Vitek JL, Johnson MD\",\n",
      "            \"journal\": \"J Neurophysiol\",\n",
      "            \"title\": \"Classification of pallidal oscillations with increasing parkinsonian severity.\",\n",
      "            \"doi\": \"10.1152/jn.00840.2014\",\n",
      "            \"year\": \"2015\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"868e7e5a-159e-47dc-9571-2700b8d3541b\",\n",
      "        \"shortid\": \"f4zymru581\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"01/21/2022 17:00:14\",\n",
      "            \"publication/authors\": \"Connolly AT, Jensen AL, Baker KB, Vitek JL, Johnson MD\",\n",
      "            \"publication/journal\": \"J Neurophysiol\",\n",
      "            \"publication/title\": \"Classification of pallidal oscillations with increasing parkinsonian severity.\",\n",
      "            \"optimization/algorithm\": \"decision trees, naive Bayes,  k-nearest neighbor, K*, random decision forest and support vector machines with Gaussian radial basis function and linear kernel\",\n",
      "            \"optimization/features\": \"948 features from 15 categories but each training included a subset of them\",\n",
      "            \"model/availability\": \"http://www.cogsys.\\n cs.uni-tuebingen.de/software/dna-methylation/.\",\n",
      "            \"model/interpretability\": \"the algorithms were used in order to show the predictive performance of each feature and thus outline the correlation between features and classification\",\n",
      "            \"model/output\": \"binary classification\",\n",
      "            \"evaluation/comparison\": \"direct comparison is challenging since there are a lot of factors contributing in the final results. Some comparison is indeed presented from other publications.\",\n",
      "            \"evaluation/confidence\": \"To ensure a fair comparison, all analyses have been repeated ten times with a ten-fold cross-validation so the mean and standard deviation for each experiment are presented.\",\n",
      "            \"evaluation/measure\": \"accuracy, Matthews correlation coefficient (MCC) and the area under the receiver operating\\n characteristics curve (AUC), average absolute error (AAE)\",\n",
      "            \"evaluation/method\": \"Cross-validation and independent dataset\",\n",
      "            \"dataset/availability\": \" http://www.cogsys.cs.uni-tuebingen.de/software/dna-methylation/.\",\n",
      "            \"dataset/provenance\": \"not reportedME21 consortium, ENCODE consortium,  whole-genome catalogue of Dnot reported methylation in human, DOI: 10.1371/journal.pgen.1000438\",\n",
      "            \"dataset/splits\": \"56 methylated (112 unmethylated) instances for leukocytes, 73\\nmethylated (117 unmethylated) instances for HEK293, 44 methylated (142 unmethylated) instances for HEPG2, 43 methylated (142 unmethylated) instances for fibroblasts, and 32\\nmethylated (137 unmethylated) instances for trisomic fibroblasts\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b5e\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"27127534\",\n",
      "            \"updated\": \"03/30/2022 16:22:15\",\n",
      "            \"authors\": \"Wang MY, Li P, Qiao PL\",\n",
      "            \"journal\": \"Comput Math Methods Med\",\n",
      "            \"title\": \"The Virtual Screening of the Drug Protein with a Few Crystal Structures Based on the Adaboost-SVM.\",\n",
      "            \"doi\": \"10.1155/2016/4809831\",\n",
      "            \"year\": \"2016\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"10e71e8f-f4e5-4904-9a7b-9428370d1e99\",\n",
      "        \"shortid\": \"2t5i3s7g3y\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/30/2022 16:22:15\",\n",
      "            \"publication/authors\": \"Wang MY, Li P, Qiao PL\",\n",
      "            \"publication/journal\": \"Comput Math Methods Med\",\n",
      "            \"publication/title\": \"The Virtual Screening of the Drug Protein with a Few Crystal Structures Based on the Adaboost-SVM.\",\n",
      "            \"optimization/algorithm\": \"Multiple Linear Regression (MLR) \",\n",
      "            \"optimization/config\": \"Coefficients Estimates and Standard Errors of the predictors are reported.\",\n",
      "            \"optimization/encoding\": \"Global features\",\n",
      "            \"optimization/features\": \"The 110 numeric fields included in the platform were considered as the possible predictors with a backward elimination method. From the screening of every model, the authors selected the most significant ones (5 predictors) according to the F statistics of the ChiSquare coefficients.  From the text it appears that the feature elimination procedure was applied on the whole dataset.  \",\n",
      "            \"optimization/fitting\": \"Apparently both over-fitting and under-fitting can be excluded (p<N, f =5).  \",\n",
      "            \"optimization/parameters\": \"7 MLR parameters:  5 feature parameters, 1 intercept, 1 error term.\",\n",
      "            \"model/interpretability\": \"Transparent. All 5 features are clinical parameters known to be related to the AKU illness.\",\n",
      "            \"model/output\": \"Regression: prediction of patients PTI (Protein Thiolation Index) values, given the patients clinical information.\",\n",
      "            \"evaluation/confidence\": \"Significance of the model by F statistics.\",\n",
      "            \"evaluation/measure\": \"Adjusted coefficient of determination, Mean Standard Error, Maximum Absolute Difference Predicted vs Experimental\",\n",
      "            \"evaluation/method\": \"Independent validation set.\",\n",
      "            \"dataset/availability\": \"The database, hosting the dataset, is accessible via registration request:    http://www.bio.unisi.it/aku-db/\",\n",
      "            \"dataset/provenance\": \"Source:  AKU-related dataset, 203 patients in total.  Not used previously.\",\n",
      "            \"dataset/splits\": \"Training set: 181 patients, Validation set: 22 patients\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b5f\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"26930205\",\n",
      "            \"updated\": \"06/23/2022 04:51:07\",\n",
      "            \"authors\": \"Cho H, Berger B, Peng J\",\n",
      "            \"journal\": \"PLoS One\",\n",
      "            \"title\": \"Reconstructing Causal Biological Networks through Active Learning.\",\n",
      "            \"doi\": \"10.1371/journal.pone.0150611\",\n",
      "            \"year\": \"2016\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"55301cf1-e2b8-4e59-86d5-6502872104d6\",\n",
      "        \"shortid\": \"ftglxzast4\",\n",
      "        \"score\": 0.57,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"06/23/2022 04:51:07\",\n",
      "            \"publication/authors\": \"Cho H, Berger B, Peng J\",\n",
      "            \"publication/journal\": \"PLoS One\",\n",
      "            \"publication/title\": \"Reconstructing Causal Biological Networks through Active Learning.\",\n",
      "            \"optimization/encoding\": \"Yes, e.g. voxel resolution\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"Binary classification\",\n",
      "            \"evaluation/measure\": \"ROC curve\",\n",
      "            \"evaluation/method\": \"Cross validation\",\n",
      "            \"dataset/provenance\": \" distinguish 32 patients from 30 healthy control\",\n",
      "            \"dataset/splits\": \" distinguish 32 patients from 30 healthy control\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b60\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"26205532\",\n",
      "            \"updated\": \"06/23/2022 05:29:46\",\n",
      "            \"authors\": \"Kosciolek T, Jones DT\",\n",
      "            \"journal\": \"Proteins\",\n",
      "            \"title\": \"Accurate contact predictions using covariation techniques and machine learning.\",\n",
      "            \"doi\": \"10.1002/prot.24863\",\n",
      "            \"year\": \"2016\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"92789330-e8c7-4761-a47b-6758bb151af7\",\n",
      "        \"shortid\": \"m8bml54z62\",\n",
      "        \"score\": 0.9,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"06/23/2022 05:29:46\",\n",
      "            \"publication/authors\": \"Kosciolek T, Jones DT\",\n",
      "            \"publication/title\": \"Accurate contact predictions using covariation techniques and machine learning.\",\n",
      "            \"optimization/algorithm\": \"AdaBoost, Gradient boosting, Gaussian process, K-nearest neighbors, logistic regression, naive Bayes, Random forest, SVM (RBF)\",\n",
      "            \"optimization/config\": \"Yes, supporting information\",\n",
      "            \"optimization/encoding\": \"Mean imputation for missing values, normalization of continuous valued features to zero mean and unit variance.\",\n",
      "            \"optimization/features\": \"36 clinical attributes per patient per time-point\",\n",
      "            \"optimization/fitting\": \"Second feature selection process as part of the hyper-parameter tuning process, referred to as \\u201cautomated feature selection\\u201d in Fig 1. The automated method is based on the mutual information between each individual feature and sepsis class (case or control) to select top n features, 11 features selected for CPOnly DS, 35 (all) for CP+Clinical dataset.\",\n",
      "            \"optimization/parameters\": \"Ada boost: 3, Gradient Boosting: 2, kNN: 2, Logistic Regression: 1, Random Forest: 3, SVM: 2\",\n",
      "            \"optimization/regularization\": \"Nested k-fold cross-validation\",\n",
      "            \"model/availability\": \"https://github.com/chop-dbhi/sepsis_01, Data is in S3, unclear if project can be fully bootstrapped.\",\n",
      "            \"model/interpretability\": \"Transparent, names of models and parameters are provided\",\n",
      "            \"model/output\": \"probability score, classification into positive case if p > 0.5\",\n",
      "            \"evaluation/availability\": \"Yes, Supporting information, https://github.com/chop-dbhi/sepsis_01, MIT license (code)\",\n",
      "            \"evaluation/comparison\": \"Ada boost, Gradient Boosting, kNN, Logistic Regression, Random Forest, SVM\",\n",
      "            \"evaluation/confidence\": \"NA (The null hypothesis of equal inter-model distributions was rejected by the Friedman rank sum test with p-values of <0.001 for both the CPOnly and CP+Clinical datasets.)\",\n",
      "            \"evaluation/measure\": \"AUC, Specificity, PPV, NPV\",\n",
      "            \"evaluation/method\": \"k-fold cross validation, negative control dataset\",\n",
      "            \"dataset/availability\": \"Yes, Supporting information.\",\n",
      "            \"dataset/provenance\": \"Neonatal Intensive Care Unit (NICU) at the Children\\u2019s Hospital of Philadelphia, hospizalized infants with sepsis evaluation (culture positive, clinically positive)\",\n",
      "            \"dataset/redundancy\": \"not reported (there were pre-selection criteria for inclusion)\",\n",
      "            \"dataset/splits\": \"618 infants with 1188 sepsis evaluations, 110 culture positive, 265 clinically positive, 492 negative\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b7a\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"27191382\",\n",
      "            \"updated\": \"03/07/2022 10:49:51\",\n",
      "            \"authors\": \"Putin E, Mamoshina P, Aliper A, Korzinkin M, Moskalev A, Kolosov A, Ostrovskiy A, Cantor C, Vijg J, Zhavoronkov A\",\n",
      "            \"journal\": \"Aging (Albany NY)\",\n",
      "            \"title\": \"Deep biomarkers of human aging: Application of deep neural networks to biomarker development.\",\n",
      "            \"doi\": \"10.18632/aging.100968\",\n",
      "            \"year\": \"2016\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"fd5713cd-748e-4a55-889a-9ed418021731\",\n",
      "        \"shortid\": \"0qudu672ba\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/07/2022 10:49:51\",\n",
      "            \"publication/authors\": \"Putin E, Mamoshina P, Aliper A, Korzinkin M, Moskalev A, Kolosov A, Ostrovskiy A, Cantor C, Vijg J, Zhavoronkov A\",\n",
      "            \"publication/journal\": \"Aging (Albany NY)\",\n",
      "            \"publication/title\": \"Deep biomarkers of human aging: Application of deep neural networks to biomarker development.\",\n",
      "            \"optimization/algorithm\": \"neural network\",\n",
      "            \"optimization/encoding\": \"BioFSharp framework (available at: https://github.com/CSBiology/BioFSharp) and converted into a feature vector with 45 entries.\",\n",
      "            \"optimization/features\": \"The networks were trained using a minibatch size of 3 for 10 epoch.\",\n",
      "            \"optimization/parameters\": \"five dense layers with 128 nodes each\",\n",
      "            \"optimization/regularization\": \"Yes, \\u201cdropout\\u201d technique \",\n",
      "            \"model/availability\": \"webservice: (http://csbweb.bio.uni-kl.de/)\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/comparison\": \"ChemScore (Parker, 2002) \\n PeptideSieve (Mallick et al., 2007),\\n PeptideRank (Qeli et al., 2014),\\n CONSequence (Eyers et al., 2011), \\n ESPPredictor (Fusaro et al., 2009).\",\n",
      "            \"evaluation/confidence\": \"no statistical significance declared.\",\n",
      "            \"evaluation/measure\": \"normalized discounted cumulative gain (nDCG) metric\",\n",
      "            \"evaluation/method\": \"randomly selected 20% of the proteins in each assembly to use them as validation-data-sets, \\n 32 peptides from a QconCAT protein was experimentally validated\",\n",
      "            \"dataset/availability\": \"at the suplementary files  https://www.frontiersin.org/articles/10.3389/fpls.2018.01559/full#supplementary-material\\n\\n\",\n",
      "            \"dataset/provenance\": \"Yeast data set:  from the PRIDE repository \\nC. reinhardtii data set:  previous proteome-wide studies\\neach dataset filtered for single occurrence of all proteins\\n\\n\",\n",
      "            \"dataset/splits\": \"training datasets consisting of 2,652 yeast and 2,732 C. reinhardtii proteins\\ntwo validation datasets consisting of 664 yeast and 685 C. reinhardtii proteins\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b7b\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"27592011\",\n",
      "            \"updated\": \"03/13/2022 19:09:08\",\n",
      "            \"authors\": \"Sunseri J, Ragoza M, Collins J, Koes DR\",\n",
      "            \"journal\": \"J Comput Aided Mol Des\",\n",
      "            \"title\": \"A D3R prospective evaluation of machine learning for protein-ligand scoring.\",\n",
      "            \"doi\": \"10.1007/s10822-016-9960-x\",\n",
      "            \"year\": \"2016\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"4a3c8c15-7e55-4033-a570-4dd9364e7be4\",\n",
      "        \"shortid\": \"2imglukj27\",\n",
      "        \"score\": 0.52,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/13/2022 19:09:08\",\n",
      "            \"publication/authors\": \"Sunseri J, Ragoza M, Collins J, Koes DR\",\n",
      "            \"publication/journal\": \"J Comput Aided Mol Des\",\n",
      "            \"publication/title\": \"A D3R prospective evaluation of machine learning for protein-ligand scoring.\",\n",
      "            \"optimization/encoding\": \"The probes corresponding to the same gene were averaged. The gene expression data was preprocessed with quantile normalization\",\n",
      "            \"model/interpretability\": \"transparent, listed in the The CIN-associated gene selection section in Methods\",\n",
      "            \"evaluation/availability\": \"yes, Figure 1\",\n",
      "            \"evaluation/measure\": \"Accuracy, sensitivity, specificity, mcc\",\n",
      "            \"dataset/availability\": \"yes, GEO GSE39582\",\n",
      "            \"dataset/provenance\": \"GEO GSE39582\",\n",
      "            \"dataset/splits\": \"Within the 585 colon patients, there were 369 CIN+ and 112 CIN-, 93 CIMP+ and 420 CIMP-, 77 dMMR and 459 pMMR\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b7c\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"26746583\",\n",
      "            \"updated\": \"03/17/2022 23:10:43\",\n",
      "            \"authors\": \"Kandaswamy C, Silva LM, Alexandre LA, Santos JM\",\n",
      "            \"journal\": \"J Biomol Screen\",\n",
      "            \"title\": \"High-Content Analysis of Breast Cancer Using Single-Cell Deep Transfer Learning.\",\n",
      "            \"doi\": \"10.1177/1087057115623451\",\n",
      "            \"year\": \"2016\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"bad7ff2b-45e0-4386-ba20-6ff517bf0db5\",\n",
      "        \"shortid\": \"wd9oesbckf\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/17/2022 23:10:43\",\n",
      "            \"publication/authors\": \"Kandaswamy C, Silva LM, Alexandre LA, Santos JM\",\n",
      "            \"publication/journal\": \"J Biomol Screen\",\n",
      "            \"publication/title\": \"High-Content Analysis of Breast Cancer Using Single-Cell Deep Transfer Learning.\",\n",
      "            \"optimization/algorithm\": \" random forest and gradient boosting. Also ensemble method from different classifiers, Two separate values were used for the creation of each ensemble model \\u2013 scores sij and\\npredictions pij where i represents model number and j transcript.  The four ensemble\\napproaches included both algebraic combiners and voting methods as non-trainable methods, and a stacking generalizer as a meta-learner.\",\n",
      "            \"optimization/encoding\": \"Diamond alignment in SwissProt database\",\n",
      "            \"optimization/features\": \"9 features were extracted using a combination of custom Python scripts and known software CPAT, Diamond, RepeatMasker.\",\n",
      "            \"optimization/parameters\": \" gradient boosting parameters :  learning_rate, max_depth, subsample, n_estimators. \\nRandom forest parameters: only change from default parameters being n_estimators and min_samples_leaf.\",\n",
      "            \"model/duration\": \"measured in minutes\",\n",
      "            \"model/output\": \"classification binary if a transcript was or was not predicted as a lncRNA and stacking with\\n logistic regression for ensemble method\",\n",
      "            \"evaluation/comparison\": \"compared to GreeNC (uses a transcript filtering method, rather than a machine learning approaches).\",\n",
      "            \"evaluation/confidence\": \"(qualitative explanation) An important consideration of this tool is that it is not constrained by preconceived rules that may or may not appropriately classify lncRNA properties and the stacking generalizer model based on gradient boosting models will facilitate lncRNA identification without imposing arbitrary rules for lncRNA detection.\",\n",
      "            \"evaluation/measure\": \"accuracy, sensitivity, specificity and AUC values\",\n",
      "            \"evaluation/method\": \"10-fold cross-validation\",\n",
      "            \"dataset/availability\": \"(http://lncrnadb.org), (http://www.cuilab.cn/lncrnadisease), (http://www.ensembl.org), (https://araport-dev.tacc.utexas.edu)\",\n",
      "            \"dataset/provenance\": \"positive: lncRnot reporteddb v2.0, lncRnot reporteddisease , total of 436 unique, validated lncRnot reported sequences // negative: Ensembl, Araportv11 \",\n",
      "            \"dataset/redundancy\": \"variety of training datasets was used to maximize model diversity and samples were equally and randomly selected to get a balanced training\",\n",
      "            \"dataset/splits\": \" 8 different combinations of negative data from multiple species\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b7d\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"27491922\",\n",
      "            \"updated\": \"03/23/2022 12:35:43\",\n",
      "            \"authors\": \"Chen AS, Westwood NJ, Brear P, Rogers GW, Mavridis L, Mitchell JB\",\n",
      "            \"journal\": \"Mol Inform\",\n",
      "            \"title\": \"A Random Forest Model for Predicting Allosteric and Functional Sites on Proteins.\",\n",
      "            \"doi\": \"10.1002/minf.201500108\",\n",
      "            \"year\": \"2016\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"c0279a1e-2bf3-4fe2-8d40-9c9cc040608d\",\n",
      "        \"shortid\": \"o94lxlja8t\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/23/2022 12:35:43\",\n",
      "            \"publication/authors\": \"Chen AS, Westwood NJ, Brear P, Rogers GW, Mavridis L, Mitchell JB\",\n",
      "            \"publication/journal\": \"Mol Inform\",\n",
      "            \"publication/title\": \"A Random Forest Model for Predicting Allosteric and Functional Sites on Proteins.\",\n",
      "            \"optimization/algorithm\": \"Random Forest \",\n",
      "            \"optimization/features\": \"Number of features not reported\\n\\nThe feature selection was actually the main topic of the paper. The feature selection method is carefully described. In brief, features were selected passing through different steps: 1. initial filtering 2. Random Logistic Regression 3. Feature importance of Random Forest 4. evaluating the LogLoss of the prediction performed using different combination of the selected features.\",\n",
      "            \"model/availability\": \"Yes, the code is available at URL: https://github.com/bioinformatics-IBCH/logloss-beraf\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/comparison\": \"Compared with other classification models, all based on logistic regression.\",\n",
      "            \"evaluation/confidence\": \"No confidence intervals. No static significance claimed\",\n",
      "            \"evaluation/measure\": \"Precision, Recall, F1-score, Area Under Curve (AUC)\",\n",
      "            \"evaluation/method\": \"Independent Datasets (test sets)\",\n",
      "            \"dataset/availability\": \"Yes. \\n\\n-- Datasets for prostate cancer --\\nDataset 1 URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE74013\\nDataset 2 URL: https://portal.gdc.cancer.gov/projects/TCGA-PRAD\\nDataset 3 URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE55479\\nDataset 4 URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE38240\\nDataset 5 URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE73549\\n\\n-- Datasets for bladder cancer --\\nDataset 6 URL: https://portal.gdc.cancer.gov/projects/TCGA-BLCA\\n\\n-- Datasets for colorectal cancer --\\nDataset 7 URL: https://portal.gdc.cancer.gov/projects/TCGA-COAD\\nDataset 8 URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE74013\\n\\n-- Datasets for renal clear cells cancer --\\nDataset 9 URL: https://wiki.cancerimagingarchive.net/display/Public/TCGA-KIRC\\n\\n-- Datasets for renal papillary cell carcinoma --\\nDataset 10 URL: https://www.google.com/search?channel=trow5&client=firefox-b-d&q=TCGA+KIRP\",\n",
      "            \"dataset/provenance\": \"All the datasets are public. For all datasetes, pos refer to tumor sample, neg to non-tumor sample.\\n\\n-- Datasets for prostate cancer --\\nDataset 1: GEO dataset GSE74013 (N_pos = 21; N_neg = 27)\\nDataset 2: TCGA-PRAD (N_pos = 293; N_neg = 23)\\nDataset 3: GEO dataset GSE55479 (N_pos = 143; N_neg = 0)\\nDataset 4: GEO dataset GSE38240 (N_pos = 8; N_neg = 4)\\nDataset 5: GEO dataset GSE73549 (N_pos = 77; N_neg = 15)\\n\\n-- Datasets for bladder cancer --\\nDataset 6: TCGA-BLCA (N_pos = 335; N_neg = 23)\\n\\n-- Datasets for colorectal cancer --\\nDataset 7: TCGA-COAD (N_pos = 333; N_neg = 37)\\nDataset 8: GEO dataset GSE74013 (N_pos = 14; N_neg = 20)\\n\\n-- Datasets for renal clear cells cancer --\\nDataset 9: TGCA-KIRC (N_pos = 290; N_neg = 130)\\n\\n-- Datasets for renal papillary cell carcinoma --\\nDataset 10: TGCA-KIRP (N_pos = 252; N_neg = 167)\",\n",
      "            \"dataset/redundancy\": \"No redundancy stated for dataset splits. All the datasets are independent from each other\",\n",
      "            \"dataset/splits\": \"In all cases, the training dataset is used also for validation.\\n\\n-- Datasets for prostate cancer --\\nDataset 1: Splitted in Training (N_pos = 8; N_neg = 11) and Test set (N_pos = 13; N_neg = 16)\\nDataset 2: Splitted in Training (N_pos = 117; N_neg = 15) and Test set (N_pos = 176; N_neg = 23)\\nDataset 3: Used as test set (N_pos = 143; N_neg = 0)\\nDataset 4: Used as test set (N_pos = 8; N_neg = 4)\\nDataset 5: Used as test set (N_pos = 77; N_neg = 15)\\n\\n-- Datasets for bladder cancer --\\nDataset 6: Splitted in training (N_pos = 134; N_neg = 9) and test set (N_pos = 201; N_neg = 14)\\n\\n-- Datasets for colorectal cancer --\\nDataset 7: Splitted in training (N_pos = 133; N_neg = 15) and test set (N_pos = 200; N_neg = 22)\\nDataset 8: Splitted in training (N_pos = 6; N_neg = 9) and test set (N_pos = 8; N_neg = 11)\\n\\n-- Datasets for renal clear cells cancer --\\nDataset 9: Splitted in training (N_pos = 116; N_neg = 52) and test set (N_pos = 174; N_neg = 78)\\n\\n-- Datasets for renal papillary cell carcinoma --\\nDataset 10: Splitted in training (N_pos = 101; N_neg = 63) and test set (N_pos = 151; N_neg = 104)\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b85\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"27488918\",\n",
      "            \"updated\": \"02/09/2022 10:22:18\",\n",
      "            \"authors\": \"Liu HC, Goldenberg A, Chen Y, Lun C, Wu W, Bush KT, Balac N, Rodriguez P, Abagyan R, Nigam SK\",\n",
      "            \"journal\": \"J Pharmacol Exp Ther\",\n",
      "            \"title\": \"Molecular Properties of Drugs Interacting with SLC22 Transporters OAT1, OAT3, OCT1, and OCT2: A Machine-Learning Approach.\",\n",
      "            \"doi\": \"10.1124/jpet.116.232660\",\n",
      "            \"year\": \"2016\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"e9716212-a945-4dc9-b615-7fc1704b6dbf\",\n",
      "        \"shortid\": \"3htxdzl6gy\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/09/2022 10:22:18\",\n",
      "            \"publication/authors\": \"Liu HC, Goldenberg A, Chen Y, Lun C, Wu W, Bush KT, Balac N, Rodriguez P, Abagyan R, Nigam SK\",\n",
      "            \"publication/journal\": \"J Pharmacol Exp Ther\",\n",
      "            \"publication/title\": \"Molecular Properties of Drugs Interacting with SLC22 Transporters OAT1, OAT3, OCT1, and OCT2: A Machine-Learning Approach.\",\n",
      "            \"optimization/algorithm\": \"Elastic net regression, SVM  and deep autoencoder\",\n",
      "            \"optimization/encoding\": \"selected features from the deep learning autoencoder\",\n",
      "            \"optimization/features\": \"selected features from the deep learning autoencoder: \\\"Matlab code for training a deep autoencoder as described by Hinton and Salakhutdinov was obtained from Hinton's website (http://www.cs.toronto.edu/$hinton/MatlabForSciencePaper.html)\\\"\",\n",
      "            \"optimization/regularization\": \"Yes, variance-based mixture-fitting feature selection scheme\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/comparison\": \"they mentioned two similar studies: 10.1126/science.1127647 and 10.1038/nature12831\",\n",
      "            \"evaluation/measure\": \"lastic net models: average sensitivity 0.75, average specificity 0.78, AUROC 0.81\\n SVM models: average sensitivity 0.59, average specificity 0.56, AUROC 0.55\",\n",
      "            \"evaluation/method\": \"25-fold cross-validation\",\n",
      "            \"dataset/provenance\": \"source of data:  large pharmacogenomics studies: Genomics of Drug Sensitivity in Cancer Project (GDSC), and the Cancer Cell Line Encyclopedia (CCLE),\\nafter filtering, they created a single array of data containing information on 3577 features in 624 cell lines\",\n",
      "            \"dataset/splits\": \"for training a deep autoencoder: randomly split into training and testing datasets of 520 and 104 samples, respectively\\n\\nfor drug-sensitivity prediction: 25-fold cross-validation\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b86\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"27832081\",\n",
      "            \"updated\": \"02/21/2022 23:04:51\",\n",
      "            \"authors\": \"Willett DS, George J, Willett NS, Stelinski LL, Lapointe SL\",\n",
      "            \"journal\": \"PLoS Comput Biol\",\n",
      "            \"title\": \"Machine Learning for Characterization of Insect Vector Feeding.\",\n",
      "            \"doi\": \"10.1371/journal.pcbi.1005158\",\n",
      "            \"year\": \"2016\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"5de83145-b739-43f7-a0cf-8c223ddf45f9\",\n",
      "        \"shortid\": \"8ockqu6jl9\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/21/2022 23:04:51\",\n",
      "            \"publication/authors\": \"Willett DS, George J, Willett NS, Stelinski LL, Lapointe SL\",\n",
      "            \"publication/journal\": \"PLoS Comput Biol\",\n",
      "            \"publication/title\": \"Machine Learning for Characterization of Insect Vector Feeding.\",\n",
      "            \"optimization/config\": \"yes, in \\\"savedmodels\\\" folder in https://github.com/KlugerLab/deepcytof.git.\",\n",
      "            \"optimization/encoding\": \"sample denoising, calibration between target samples and a single reference source sample\\nand finally cell classification. We implement each of these tasks using the following three neural nets: (i) a denoising autoencoder (DAE) for handling missing data; (ii) an MMD-ResNet for calibrating between the target samples and a reference source sample; (iii) a\\ndepth-4 feed-forward neural net for classifying/gating cell types trained on a reference source sample.\",\n",
      "            \"optimization/parameters\": \"depth-4 feed-forward neural nets\",\n",
      "            \"optimization/regularization\": \"logarithmic transform, followed by rescaling\",\n",
      "            \"model/availability\": \"https://github.com/\\n KlugerLab/deepcytof.git.\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"cell classification\",\n",
      "            \"evaluation/confidence\": \"comparison with manually performed task\",\n",
      "            \"evaluation/measure\": \"F-measure statistic (the harmonic mean of precision\\n and recall)\",\n",
      "            \"evaluation/method\": \"independent dataset\",\n",
      "            \"dataset/provenance\": \" three CyTOF datasets consisting of 56, 136 and 16 PBMC samples\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b87\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"27855170\",\n",
      "            \"updated\": \"02/23/2022 17:15:55\",\n",
      "            \"authors\": \"Crisman TJ, Zelaya I, Laks DR, Zhao Y, Kawaguchi R, Gao F, Kornblum HI, Coppola G\",\n",
      "            \"journal\": \"PLoS One\",\n",
      "            \"title\": \"Identification of an Efficient Gene Expression Panel for Glioblastoma Classification.\",\n",
      "            \"doi\": \"10.1371/journal.pone.0164649\",\n",
      "            \"year\": \"2016\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"ae4b3d28-aac1-4f6c-87b5-cd0f72a69674\",\n",
      "        \"shortid\": \"xyv3h983ib\",\n",
      "        \"score\": 0.38,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/23/2022 17:15:55\",\n",
      "            \"publication/authors\": \"Crisman TJ, Zelaya I, Laks DR, Zhao Y, Kawaguchi R, Gao F, Kornblum HI, Coppola G\",\n",
      "            \"publication/journal\": \"PLoS One\",\n",
      "            \"publication/title\": \"Identification of an Efficient Gene Expression Panel for Glioblastoma Classification.\",\n",
      "            \"optimization/meta\": \"Yes. Protein structures/Protein sequences\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/measure\": \"ROC Curve\",\n",
      "            \"evaluation/method\": \"Independent dataset\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b95\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"27222432\",\n",
      "            \"updated\": \"03/16/2022 17:02:02\",\n",
      "            \"authors\": \"Schnoerr D, Grima R, Sanguinetti G\",\n",
      "            \"journal\": \"Nat Commun\",\n",
      "            \"title\": \"Cox process representation and inference for stochastic reaction-diffusion processes.\",\n",
      "            \"doi\": \"10.1038/ncomms11729\",\n",
      "            \"year\": \"2016\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"2882dbba-6819-442d-b027-50598cd5a0a6\",\n",
      "        \"shortid\": \"yirxngqbuc\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/16/2022 17:02:02\",\n",
      "            \"publication/authors\": \"Schnoerr D, Grima R, Sanguinetti G\",\n",
      "            \"publication/journal\": \"Nat Commun\",\n",
      "            \"publication/title\": \"Cox process representation and inference for stochastic reaction-diffusion processes.\",\n",
      "            \"optimization/algorithm\": \"Ensemble, incl. Adaboost Random Forrest, and SVM\",\n",
      "            \"optimization/fitting\": \"Class imbalance is compensated\",\n",
      "            \"optimization/parameters\": \"Protocol is clear\",\n",
      "            \"optimization/regularization\": \"No but kernel: RBF\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"Binary classification but evaluated a ranker: ROC\",\n",
      "            \"evaluation/measure\": \"ROC curve\",\n",
      "            \"evaluation/method\": \"Cross validation\",\n",
      "            \"dataset/splits\": \"100 pos, 2000 neg\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"665a01aa37ea6fa797a6bd7d\",\n",
      "        \"shortid\": \"23rrtkglve\",\n",
      "        \"uuid\": \"4871c35e-fd51-4036-abbc-783f8f4ca99a\",\n",
      "        \"created\": \"2024-05-31T16:58:18.981Z\",\n",
      "        \"updated\": \"2024-05-31T16:58:18.981Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"27875980\",\n",
      "            \"authors\": \"Guido Cordoni, Martin J. Woodward, Huihai Wu, Mishaal Alanazi, Tim Wallis and Roberto M. La Ragione\",\n",
      "            \"journal\": \"BMC Genomics\",\n",
      "            \"title\": \"Comparative genomics of European avian pathogenic E. Coli (APEC)\",\n",
      "            \"doi\": \"10.1186/s12864-016-3289-7\",\n",
      "            \"year\": \"2016\"\n",
      "        },\n",
      "        \"score\": 0.95,\n",
      "        \"matches\": {\n",
      "            \"evaluation/comparison\": \"No \",\n",
      "            \"evaluation/confidence\": \"No cross compaarison to other methods. From the text: Strong factor associations were reported (confidence 0.99):  1). ompT (protease) ==\\u2009>\\u2009hylP (haemolysin) 2). IroN (siderophore)\\u2009+\\u2009ompT (proteases) ==\\u2009>\\u2009hlyp (haemolysin) 3). ompT (proteases)\\u2009+\\u2009sitA (cell adhesion\\u2013metal ions binding==\\u2009>\\u2009hlyp (haemolysisn).  Significant factor associations were reported (confidence above 0.95): 4). IroN (siderophore)\\u2009+\\u2009sitA (cell adhesion\\u2013metal ions binding) ==\\u2009>\\u2009hlyP (haemolysisn conf:(0.96) 5). cva/cvi (bacteriocin immunity) ==\\u2009>\\u2009hlyP (haemolysisn) conf:(0.96) 6). hlyP (haemolysisn)\\u2009+\\u2009sitA (cell adhesion metal ions binding) ==\\u2009>\\u2009iron (siderophore) conf:(0.95) 7). hlyp(haemolysisn)\\u2009=\\u20091 sitA (cell adhesion\\u2013metal ions binding) ==\\u2009>\\u2009ompT (proteases) conf:(0.95).\",\n",
      "            \"evaluation/measure\": \"Apriori is an unsupervised learning algorithm, the concept of performance measures in the traditional sense (like accuracy or precision) doesn't directly apply. \",\n",
      "            \"evaluation/method\": \"The Apriori ML algorithm itself doesn't directly benefit from techniques like cross-validation typically used in supervised learning. \\n\\nThe 22 equally weighted factors covering virulence genes, R-type and phylogroup predicted factor associations were used in a standard ML Apriori algorithm implementation. This is a novel dataset.\",\n",
      "            \"optimization/algorithm\": \"To determine virulence factor associations the in the PCR isolates data they used machine learning and data mining software WEKA. Within WEKA the Apriori ML algorithm was applied to the data.\\n\\nThis Apriori ML algorithm is not new, first proposed in 1994.\",\n",
      "            \"optimization/config\": \"Apriori ML algorithm in WEKA software was used, leaving all the parameters on the default settings. \",\n",
      "            \"optimization/encoding\": \"No clear preprocessing was undertaken beyond standard data structuring for use in the ML alogrithm. 22 equally weighted factors covering virulence genes, R-type and phylogroup were checked for their presence in each of the 272 isolates. These DNA data virulence factors are available in spreadsheet like tables in the paper.\",\n",
      "            \"optimization/features\": \"None - not applicable to Apriori ML model. They use transactional datasets, in this case the 22 PCR virulence factors are the constituents of the transactional dataset in relation to each of the 272 isolates.\",\n",
      "            \"optimization/fitting\": \"No - unsupervised ML method, used to classify and no fitting is used for this. \",\n",
      "            \"optimization/meta\": \"No - Apriori ML alogrithm does not use meta-predictions as an input. \\n\\nWhile Apriori doesn't use meta-predictors, other algorithms for association rule learning might leverage them:\\nSEuqential Miner (SEQUOIA)or Constraint-based association rule learning.\",\n",
      "            \"optimization/parameters\": \"Provided a standard Apriori ML algorithm was implemented as indicated in the text, here are some of the key parameters that would be used:\\nMinimum Support \\nMinimum Confidence \\n\\nAlso sometimes used by the Apriori ML algorithm are:\\nMaximum Length \\nLift\\n\",\n",
      "            \"optimization/regularization\": \"No - not applicable for this unsupervised ML method. No regularistaion is used.\",\n",
      "            \"model/availability\": \"No, it seems no novel code was produced or shared if it was produced for the analysis. No GitHub or code repository linked. The primary ML related software used for the analysis is identified as the 'machine learning and data mining software WEKA' which is referenced in the text. (https://dl.acm.org/doi/10.1145/1656274.1656278)\",\n",
      "            \"model/duration\": \"Information not provided for the text on the ML section. It is unlikely a HPC machine was needed to run the analysis as the software was released in the early 2000s and uses a user friendly graphical user interface.  \",\n",
      "            \"model/interpretability\": \"Information and tutorials are available on the Apriori ML algorithm of the Weka software in online tutorials e.g. https://www.tutorialspoint.com/weka/weka_association.htm . As the default parameters were used, it is not a complete black box. However, the exact availability of the Weka tool's underlying code is not clear or easily available from the paper, e.g. no GitHub link. \",\n",
      "            \"model/output\": \"Classification model.\",\n",
      "            \"dataset/availability\": \"Data relevant to the ML methods:\\nThe PCR data was the determination of the presence of 22 equally weighted genetic factors covering virulence genes, R-type and phylogroup across 272 isolates. This data such as gene names, amplicon size in bp length and sequence 5\\u2032\\u20133\\u2032 are available in tables in the text - Tables 1, 2 and 3. \\n\\nData not relevant to the ML methods:\\nThe WGS sequences can be found on European Nucleotide Archive (EMBL-EBI) with project accession number PRJEB11876 (ERP013295) and on the NCBI database.\\nENA: http://www.ebi.ac.uk/ena/data/view/PRJEB11876\\nNCBI: https://www.ncbi.nlm.nih.gov/bioproject/PRJEB11876/  \",\n",
      "            \"dataset/provenance\": \"Avian pathogenic Escherichia coli (APEC) isolates were the primary data source and were collected through direct experimentation. \\n\\n272 APEC isolates were collected from the  UK (173), Germany (69) and Italy (30). These 272 isolates were then genetically characterised using multiplex polymerase chain reactions (PCRs) targeting 22 equally weighted factors covering virulence genes, R-type and phylogroup. This data was used for their ML approaches. \\n\\n95 of the 272 isolates were further analysed using Whole Genome Sequencing (WGS) to create whole genomes. This data was not used for their ML appraoches.\",\n",
      "            \"dataset/redundancy\": \"Data was not split. No training data used due to unsupervised classification ML model used.\",\n",
      "            \"dataset/splits\": \"No - no data split as unsupervised classification method used without labelled data included. \",\n",
      "            \"publication/authors\": \"Guido Cordoni, Martin J. Woodward, Huihai Wu, Mishaal Alanazi, Tim Wallis and Roberto M. La Ragione\",\n",
      "            \"publication/journal\": \"BMC Genomics\",\n",
      "            \"publication/title\": \"Comparative genomics of European avian pathogenic E. Coli (APEC)\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b39\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"26957000\",\n",
      "            \"updated\": \"02/23/2022 16:01:54\",\n",
      "            \"authors\": \"Jia CZ, He WY, Yao YH\",\n",
      "            \"journal\": \"J Biomol Struct Dyn\",\n",
      "            \"title\": \"OH-PRED: prediction of protein hydroxylation sites by incorporating adapted normal distribution bi-profile Bayes feature extraction and physicochemical properties of amino acids.\",\n",
      "            \"doi\": \"10.1080/07391102.2016.1163294\",\n",
      "            \"year\": \"2017\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"36e9870f-9db6-4673-90a4-ad00c967c0bd\",\n",
      "        \"shortid\": \"ie0f3buyr4\",\n",
      "        \"score\": 0.52,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/23/2022 16:01:54\",\n",
      "            \"publication/authors\": \"Jia CZ, He WY, Yao YH\",\n",
      "            \"publication/journal\": \"J Biomol Struct Dyn\",\n",
      "            \"publication/title\": \"OH-PRED: prediction of protein hydroxylation sites by incorporating adapted normal distribution bi-profile Bayes feature extraction and physicochemical properties of amino acids.\",\n",
      "            \"optimization/algorithm\": \"Random forest\",\n",
      "            \"optimization/encoding\": \"global features\",\n",
      "            \"optimization/features\": \"100. Iterative feature selection removing features with Pearson\\u2019s correlation coefficient > 0.8. Performed on all data.\",\n",
      "            \"optimization/parameters\": \"Number of parameters not specificed. Hyperparameter tuning was performed using randomised search with K-fold cross-validation to optimise the model parameters \",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/measure\": \"F1 score of 0.98\",\n",
      "            \"dataset/availability\": \"The features table dataset has not been made available. Authors made available the imaging data at https://www.ebi.ac.uk/biostudies/ with accession number S-BIAD161. Authors also report that features were extracted from images with CellProfiler 3.1.8 and provide the list of morphological and contextual measurements extracted to generate the features table (Table B of http://journals.plos.org/ploscompbiol/article/asset?unique&id=info:doi/10.1371/journal.pcbi.1009193.s002http://journals.plos.org/ploscompbiol/article/asset?unique&id=info:doi/10.1371/journal.pcbi.1009193.s002 )\",\n",
      "            \"dataset/provenance\": \"Imaging data produced by the same authors. 826 cells classified in 3 classes (no negative/positive binary classification).\",\n",
      "            \"dataset/splits\": \"90% training set 10% test set\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b3e\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"28696170\",\n",
      "            \"updated\": \"05/20/2022 17:19:51\",\n",
      "            \"authors\": \"Harteveld DOC, Grant MR, Pscheidt JW, Peever TL\",\n",
      "            \"journal\": \"Phytopathology\",\n",
      "            \"title\": \"Predicting Ascospore Release of Monilinia vaccinii-corymbosi of Blueberry with Machine Learning.\",\n",
      "            \"doi\": \"10.1094/PHYTO-04-17-0162-R\",\n",
      "            \"year\": \"2017\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"d1a1ce81-ead9-4970-ba09-10e679dcfc03\",\n",
      "        \"shortid\": \"lrlwou3dt7\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"05/20/2022 17:19:51\",\n",
      "            \"publication/authors\": \"Harteveld DOC, Grant MR, Pscheidt JW, Peever TL\",\n",
      "            \"publication/title\": \"Predicting Ascospore Release of Monilinia vaccinii-corymbosi of Blueberry with Machine Learning.\",\n",
      "            \"optimization/algorithm\": \"Statistical analysis and clustering (K-means)\",\n",
      "            \"optimization/encoding\": \"Trimming and segmentation over sequences\",\n",
      "            \"optimization/parameters\": \"Clusters number treated as a tuning parameter. Cross-validation approach to choose optimal K (looks like it was 5000 clusters)\",\n",
      "            \"model/availability\": \"https://github.com/zji90/SCATE and release used at https://doi.org/10.5281/zenodo.3711558\",\n",
      "            \"model/duration\": \"1-2 days. running SCATE to reconstruct regulome approximately takes 5 minutes per cell cluster on a computer with 10 computing cores (2.5 GHz CPU/core) and a total of 20GB RAM.\",\n",
      "            \"evaluation/comparison\": \"Across benchmarking datasets\",\n",
      "            \"evaluation/confidence\": \"p and q values\",\n",
      "            \"evaluation/method\": \"Benchmarking over 3 datasets with scATAC-seq data\",\n",
      "            \"dataset/provenance\": \"Provenance stated via references\",\n",
      "            \"dataset/redundancy\": \"Not applicable (it is a cluster approach)\",\n",
      "            \"dataset/splits\": \"Not applicable (it is a cluster approach)\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b61\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"27362985\",\n",
      "            \"updated\": \"01/26/2022 11:27:05\",\n",
      "            \"authors\": \"Adl AA, Lee HS, Qian X\",\n",
      "            \"journal\": \"IEEE/ACM Trans Comput Biol Bioinform\",\n",
      "            \"title\": \"Detecting Pairwise Interactive Effects of Continuous Random Variables for Biomarker Identification with Small Sample Size.\",\n",
      "            \"doi\": \"10.1109/TCBB.2016.2586042\",\n",
      "            \"year\": \"2017\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"006ff363-6c34-4593-86af-0aa3b8af83d1\",\n",
      "        \"shortid\": \"2so9xiaxer\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"01/26/2022 11:27:05\",\n",
      "            \"publication/authors\": \"Adl AA, Lee HS, Qian X\",\n",
      "            \"publication/journal\": \"IEEE/ACM Trans Comput Biol Bioinform\",\n",
      "            \"publication/title\": \"Detecting Pairwise Interactive Effects of Continuous Random Variables for Biomarker Identification with Small Sample Size.\",\n",
      "            \"optimization/algorithm\": \"neural network\",\n",
      "            \"optimization/encoding\": \"pECG signal features:\\n(A) QRS duration, \\n(B) QT interval, \\n(C) ST deviation, \\n(D) T wave duration, \\n(E) QRS amplitude \\n(F) T wave amplitude\",\n",
      "            \"optimization/parameters\": \" multiple setup was tested, selected with : 5 hidden layers and 7 hidden neurons per layer,\\n\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/measure\": \"sensitivity, PPV, F1-score\",\n",
      "            \"evaluation/method\": \"10-fold cross-validation\",\n",
      "            \"dataset/provenance\": \" 6132 pECG beats was used for training in three class: Control, Mild, Severe\",\n",
      "            \"dataset/splits\": \"10-fold cross-validation\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b62\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"29263361\",\n",
      "            \"updated\": \"01/28/2022 12:34:45\",\n",
      "            \"authors\": \"Nicola W, Clopath C\",\n",
      "            \"journal\": \"Nat Commun\",\n",
      "            \"title\": \"Supervised learning in spiking neural networks with FORCE training.\",\n",
      "            \"doi\": \"10.1038/s41467-017-01827-3\",\n",
      "            \"year\": \"2017\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"964f49d7-ae30-4db1-8d54-ca667d7e64d5\",\n",
      "        \"shortid\": \"84zp8aovt4\",\n",
      "        \"score\": 0.57,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"01/28/2022 12:34:45\",\n",
      "            \"publication/authors\": \"Nicola W, Clopath C\",\n",
      "            \"publication/journal\": \"Nat Commun\",\n",
      "            \"publication/title\": \"Supervised learning in spiking neural networks with FORCE training.\",\n",
      "            \"optimization/encoding\": \"six blood parameters (C-reactive protein, white cell count, bilirubin, creatinine, ALT and alkaline phosphatase)\",\n",
      "            \"optimization/fitting\": \"Removal of outliers, Synthetic Minority Over-Sampling Technique was used\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/comparison\": \"no direct comparision\",\n",
      "            \"evaluation/measure\": \"ROC AUC 0.84\\n 92% sensitivity, 94%specificity\",\n",
      "            \"evaluation/method\": \"10-fold cross-validation\",\n",
      "            \"dataset/availability\": \"Yes,  upon reasonable request from the corresponding author\",\n",
      "            \"dataset/provenance\": \"six available blood parameters (C-reactive protein, white cell count, bilirubin, creatinine, ALT and alkaline phosphatase) from 160203 individuals.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b63\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"28678787\",\n",
      "            \"updated\": \"01/31/2022 08:45:48\",\n",
      "            \"authors\": \"Zwierzyna M, Overington JP\",\n",
      "            \"journal\": \"PLoS Comput Biol\",\n",
      "            \"title\": \"Classification and analysis of a large collection of in vivo bioassay descriptions.\",\n",
      "            \"doi\": \"10.1371/journal.pcbi.1005641\",\n",
      "            \"year\": \"2017\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"f11b2731-c298-4706-b5fb-70d1068217da\",\n",
      "        \"shortid\": \"b171clx1jy\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"01/31/2022 08:45:48\",\n",
      "            \"publication/authors\": \"Zwierzyna M, Overington JP\",\n",
      "            \"publication/journal\": \"PLoS Comput Biol\",\n",
      "            \"publication/title\": \"Classification and analysis of a large collection of in vivo bioassay descriptions.\",\n",
      "            \"optimization/config\": \"Yes, Supporting information\",\n",
      "            \"optimization/features\": \"34 featuress mapped to genes altered in sample cohort (one of the three datasets). See Supplementary Material 1for details.\",\n",
      "            \"optimization/parameters\": \"nu (all kernels), gamma (radial, sigmoid, polynomial kernels), degree (polynomial kernel). 10000 iterations of three-fold cross validation, random split of training set into 2/3 train, 1/3 test set. Sensitivity is used to select the least varying model from top 5 models for each kernel. (more details in Supplementary Material 1)\",\n",
      "            \"optimization/regularization\": \"best model selection takes into account all previous cross-validation iterations every n (100) cross validations, random reordering of cross validation iterations (5x)\",\n",
      "            \"model/availability\": \"https://github.com/ciccalab/sysSVM, License not defined\",\n",
      "            \"evaluation/availability\": \"Supporting information and GitHub / R Project https://github.com/ciccalab/sysSVM\",\n",
      "            \"evaluation/comparison\": \"No comparison to other methods. Identified helper genes show similar properties to known cancer genes. Estimation based on pathway enrichment of identified novel genes (helpers) vs known cancer genes (drivers) based on functional association\",\n",
      "            \"evaluation/method\": \"Cross validation & independent datasets\",\n",
      "            \"dataset/availability\": \"Yes, supporting information, https://ega-archive.org/datasets/EGAD00001004775, https://ega-archive.org/datasets/EGAD00001004776, esophageal adenocarcinoma samples from OCCAM consortium / part of ICGC\",\n",
      "            \"dataset/provenance\": \"Data are EAC (esophageal adenocarcinoma) genes from 1) ICGC (261), TCGA (86), Other Study (21)\",\n",
      "            \"dataset/redundancy\": \"Training and validation are completely separate. Parameter optimization was based on training data with grid search using 10,000 iterations and three fold cross-validation on four different SVM classifiers using a linear, radial, sigmoid and polynomial kernel.\",\n",
      "            \"dataset/splits\": \"Training and validation data were completely independent (ICGC/Occam data for training, TCGA and additionaly study data for testing of robustness and validation)\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b64\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"28624633\",\n",
      "            \"updated\": \"02/02/2022 10:08:47\",\n",
      "            \"authors\": \"S\\u00e1nchez-Rodr\\u00edguez A, P\\u00e9rez-Castillo Y, Sch\\u00fcrer SC, Nicolotti O, Mangiatordi GF, Borges F, Cordeiro MNDS, Tejera E, Medina-Franco JL, Cruz-Monteagudo M\",\n",
      "            \"journal\": \"Drug Discov Today\",\n",
      "            \"title\": \"From flamingo dance to (desirable) drug discovery: a nature-inspired approach.\",\n",
      "            \"doi\": \"10.1016/j.drudis.2017.05.008\",\n",
      "            \"year\": \"2017\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"02cbd7a6-f8b7-425b-8d94-ec6d79a8aebc\",\n",
      "        \"shortid\": \"5a9ger6xi3\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/02/2022 10:08:47\",\n",
      "            \"publication/authors\": \"S\\u00e1nchez-Rodr\\u00edguez A, P\\u00e9rez-Castillo Y, Sch\\u00fcrer SC, Nicolotti O, Mangiatordi GF, Borges F, Cordeiro MNDS, Tejera E, Medina-Franco JL, Cruz-Monteagudo M\",\n",
      "            \"publication/journal\": \"Drug Discov Today\",\n",
      "            \"publication/title\": \"From flamingo dance to (desirable) drug discovery: a nature-inspired approach.\",\n",
      "            \"optimization/algorithm\": \"Diffusion (propagation) methods, Purer ML-based methods and naive baseline methods\",\n",
      "            \"optimization/encoding\": \"Associations were binarised\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"regression: ranking of genes in terms of their association scores to the disease\",\n",
      "            \"evaluation/comparison\": \"network topology, basic GBA approach\",\n",
      "            \"evaluation/confidence\": \"The rankings produced by the different algorithms were qualitatively compared using Spearman\\u2019s footrule\",\n",
      "            \"evaluation/measure\": \"20 hits, AUPRC, AUROC\",\n",
      "            \"dataset/provenance\": \"Open Targets platform,  at least 1,000 Open Targets associations. 22 diseases were considered\",\n",
      "            \"dataset/splits\": \"genetic association with disease. Based on given score some  associations were considered positive.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b65\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"28600868\",\n",
      "            \"updated\": \"02/08/2022 23:45:07\",\n",
      "            \"authors\": \"Sundaram L, Bhat RR, Viswanath V, Li X\",\n",
      "            \"journal\": \"Hum Mutat\",\n",
      "            \"title\": \"DeepBipolar: Identifying genomic mutations for bipolar disorder via deep learning.\",\n",
      "            \"doi\": \"10.1002/humu.23272\",\n",
      "            \"year\": \"2017\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"30e2b822-a203-454f-9cb8-41623505bcda\",\n",
      "        \"shortid\": \"ek6yatpcos\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/08/2022 23:45:07\",\n",
      "            \"publication/authors\": \"Sundaram L, Bhat RR, Viswanath V, Li X\",\n",
      "            \"publication/journal\": \"Hum Mutat\",\n",
      "            \"publication/title\": \"DeepBipolar: Identifying genomic mutations for bipolar disorder via deep learning.\",\n",
      "            \"optimization/algorithm\": \"K-means clustering, hierarchal clustering (HC), partitioning around medoids (PAM),\\nLSTM based on variational autoencoder (VAE)\\ndeep convolutional embedded clustering (DCEC)\\n\",\n",
      "            \"optimization/config\": \"platform: Intel Xeon Processor E5-2643 v4, 128 GB RAM and NVIDIA Quadro M4000 GPU.\\n K-means and HC: Python scikit-learn \\n PAM: R \\u2018cluster\\u2019 package\\n LSTM-VAE: https://github.com/bilalmirza8519/LSTM-VAE\\n DCEC: https://github.com/XifengGuo/DCEC\",\n",
      "            \"optimization/parameters\": \"K-means, HC, PAM: K = 6 based on prior biological knowledge\\n\\nLSTM-VAE: \\nthe input layer of dimension 7 \\u00d7 1\\nfirst layer generated 7 \\u00d7 n\\nsecond layer 7 \\u00d7 1\\n\\nDCEC: used as DOI: 10.1007/978-3-319-70096-0_39\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/comparison\": \"Comparison only betweeen models created by the authors\",\n",
      "            \"evaluation/measure\": \"pathway enrichment analysis using Reactome knowledgebase\",\n",
      "            \"dataset/provenance\": \"datasets are based on mouse strains generated by the lab itself\\nThe aggerated dataset has complete time-series (7 timepoints) data for 3479 proteins and 513 metabolites.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b66\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"28065610\",\n",
      "            \"updated\": \"02/15/2022 17:17:01\",\n",
      "            \"authors\": \"Real E, Asari H, Gollisch T, Meister M\",\n",
      "            \"journal\": \"Curr Biol\",\n",
      "            \"title\": \"Neural Circuit Inference from Function to Structure.\",\n",
      "            \"doi\": \"10.1016/j.cub.2016.11.040\",\n",
      "            \"year\": \"2017\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"8fbaaea0-bcec-4aaf-a34b-86f7471a84cc\",\n",
      "        \"shortid\": \"909naoy87e\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/15/2022 17:17:01\",\n",
      "            \"publication/authors\": \"Real E, Asari H, Gollisch T, Meister M\",\n",
      "            \"publication/journal\": \"Curr Biol\",\n",
      "            \"publication/title\": \"Neural Circuit Inference from Function to Structure.\",\n",
      "            \"optimization/algorithm\": \"Lasso regression\",\n",
      "            \"optimization/config\": \"Only values for alpha are provided\",\n",
      "            \"optimization/features\": \"24994 genomic transcripts, 1000 metabolites, four agronomic traits, CV on transcripts > 0.2 and PD > 1 (90th% - 10th%), 5467 genomic transcripts after CV filter\",\n",
      "            \"optimization/parameters\": \"Modified lasso regression, alpha (first layer), beta (second layer), gamma (third layer), 10-fold CV for all parameters, successively\",\n",
      "            \"optimization/regularization\": \"10-fold CV\",\n",
      "            \"model/interpretability\": \"Model is not available for evaluation\",\n",
      "            \"model/output\": \"Regression, outputs \\\"predictability\\\"\",\n",
      "            \"evaluation/availability\": \"Yes (not all parameters, evaluation based on \\\"Predictability\\\"), Supporting information\",\n",
      "            \"evaluation/comparison\": \"Lasso regression\",\n",
      "            \"dataset/availability\": \"Stated to use previously reported data, but no explicit reference provided. \",\n",
      "            \"dataset/provenance\": \"Previously reported data, 210 lines, 1619 bins (synthetic markers), 24994 genes transcripts, 1000 metabolites and four agronomic traits\",\n",
      "            \"dataset/redundancy\": \"Random choice from Cross-Validation\",\n",
      "            \"dataset/splits\": \"10-fold Cross-Validation\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b67\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"29219069\",\n",
      "            \"updated\": \"03/02/2022 17:27:58\",\n",
      "            \"authors\": \"Tang Y, Liu D, Wang Z, Wen T, Deng L\",\n",
      "            \"journal\": \"BMC Bioinformatics\",\n",
      "            \"title\": \"A boosting approach for prediction of protein-RNA binding residues.\",\n",
      "            \"doi\": \"10.1186/s12859-017-1879-2\",\n",
      "            \"year\": \"2017\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"e104aa68-ff85-4fed-bc9f-06f1cdc39835\",\n",
      "        \"shortid\": \"acyudepk6j\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/02/2022 17:27:58\",\n",
      "            \"publication/authors\": \"Tang Y, Liu D, Wang Z, Wen T, Deng L\",\n",
      "            \"publication/journal\": \"BMC Bioinformatics\",\n",
      "            \"publication/title\": \"A boosting approach for prediction of protein-RNA binding residues.\",\n",
      "            \"optimization/algorithm\": \"Random forest\",\n",
      "            \"optimization/config\": \"Yes, in Jupyter notebooks available on GitHub (https://github.com/knightlab-analyses/crossmodel_prediction).\",\n",
      "            \"optimization/encoding\": \"1)\\t16S rRnot reported raw amplicon sequencing data were processed and converted to sub-operational taxonomic unit (sOTU) abundance per sample (BIOM format) using the Deblur workflow. Taxonomies for sOTUs were assigned using the sklearn-based taxonomy classifier trained on the Greengenes 13_8 99% OTUs in QIIME 2. The sOTU table was rarefied to a depth of 2,000 sequences/sample to control for sequencing effort. A phylogeny was inferred using SAT\\u00e9-enabled phylogenetic placement, which was used to insert 16S Deblur sOTUs into Greengenes 13_8 at a 99% phylogeny.\\n2)\\tRaw LC-MS/MS data sets were converted to m/z extensible markup language (mzXML) in centroid mode using MSConvert. All mzXML files were cropped with an m/z range of 75.00 to 1,000.00 Da. Feature extraction was performed in MZmine2 with a signal intensity threshold of 2.0e5 and minimum peak width of 0.3 s. The maximum allowed mass and retention time tolerances were 10 ppm and 10 s, respectively. A local minimum search algorithm with a minimum relative peak height of 1% was used for chromatographic deconvolution; the maximum peak width was set to 1 min. The detected peaks were aligned across all samples using the above-mentioned retention time and mass tolerances, producing the final feature table used in these analyses. \\nMolecular networking in GNPS was performed to putatively identify molecular features using MS/MS-based spectral library matches.\\n\",\n",
      "            \"optimization/features\": \"1)\\tFirst data layer.16S rRnot reported amplicon sequencing-derived abundances of microbial taxonomies.\\n2)\\tSecond data layer. Quantified LC-MS/MS peaks of detected metabolites following preprocessing.\\n\",\n",
      "            \"optimization/fitting\": \"Cross-validation with all the samples from the same mouse appearing only in either training or validation data but not both, to avoid overoptimistic cross-validation accuracy scores because of the classifier learning idiosyncrasies of the individual itself rather than the treatment.\",\n",
      "            \"model/availability\": \"Yes, in Jupyter notebooks available on GitHub (https://github.com/knightlab-analyses/crossmodel_prediction).\",\n",
      "            \"model/interpretability\": \"Transparent. The abundance of each feature, 16S sequence and metabolite, was used as the score to plot the ROC curve and compute the AUC score. Features that can single-handedly distinguish IHH-exposed samples on ROC plots were highlighted.\",\n",
      "            \"model/output\": \"1) Binary predictions of IHH-exposed samples (positive) or air-exposed samples (negative) using total Ldlr-/- and ApoE-/- data as training and testing dataset, and vice versa.\\n 2) For longitudinal binary predictions of IHH-exposed samples (positive) or air-exposed samples (negative), using Ldlr-/- or ApoE-/- data per time point as training and testing dataset, and vice versa.\",\n",
      "            \"evaluation/availability\": \"Yes. Supplementary information.\",\n",
      "            \"evaluation/measure\": \"ROC curves, AUC score.\",\n",
      "            \"evaluation/method\": \"Cross-validation. Details not specified.\",\n",
      "            \"dataset/availability\": \"Yes, online under the following accession numbers: for metabolomics data, MSV000081482 (Ldlr knockout animal) at ftp://massive.ucsd.edu/MSV000081482, MSV000082813 (ApoE knockout animal) at ftp://massive.ucsd.edu/MSV000082813, and MSV000081853 (commercial standards) at ftp://massive.ucsd.edu/MSV000081853, and for microbiome data, ERP106495 (Ldlr knockout animals; EBI database) and ERP110592 (ApoE knockout animals).\",\n",
      "            \"dataset/provenance\": \"16S rRnot reported sequencing and untargeted liquid chromatography-tandem mass spectrometry (LC-MS/MS) data from fecal samples of atherosclerosis-prone, 10-week-old, male mice on a\\nC57BL/6J background. 24 knockout mice for ApoE (ApoE-/-) and 16 knockout mice for Ldlr (Ldlr-/-). Fecal samples were collected at baseline and twice each week. 6 weeks, 12 time points and 192 samples, for Ldlr-/- mice. 10 weeks, 20 time points and 480 samples, for ApoE-/- mice.\\n\",\n",
      "            \"dataset/redundancy\": \"Analytical standards for bile acids of interest were used with the same LC-MS/MS to ensure feature annotation.\\nData set stratification by genotypes and effect size calculation of each of the covariates within each mouse model to untangle the effect of genotype.\\n\",\n",
      "            \"dataset/splits\": \"1)\\tNpos=96 samples for 8 Ldlr-/- mice exposed to intermittent hypoxia and hypercapnia (IHH). Nneg=96 samples for 8 Ldlr-/- mice exposed to air. Ntrain=192 for Ldlr-/- mice. Ntest=480 for ApoE-/- mice.\\n2)\\tNpos=12 ApoE-/- mice exposed to intermittent hypoxia and hypercapnia (IHH). Nneg=12 ApoE-/- mice exposed to air. Ntrain=480 for ApoE-/- mice. Ntest=192 for Ldlr-/- mice.\\n\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b68\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"28624633\",\n",
      "            \"updated\": \"03/08/2022 10:24:58\",\n",
      "            \"authors\": \"S\\u00e1nchez-Rodr\\u00edguez A, P\\u00e9rez-Castillo Y, Sch\\u00fcrer SC, Nicolotti O, Mangiatordi GF, Borges F, Cordeiro MNDS, Tejera E, Medina-Franco JL, Cruz-Monteagudo M\",\n",
      "            \"journal\": \"Drug Discov Today\",\n",
      "            \"title\": \"From flamingo dance to (desirable) drug discovery: a nature-inspired approach.\",\n",
      "            \"doi\": \"10.1016/j.drudis.2017.05.008\",\n",
      "            \"year\": \"2017\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"f04fcb26-53d5-4ac0-8458-c45183b92b0c\",\n",
      "        \"shortid\": \"8ltvqe2m93\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/08/2022 10:24:58\",\n",
      "            \"publication/authors\": \"S\\u00e1nchez-Rodr\\u00edguez A, P\\u00e9rez-Castillo Y, Sch\\u00fcrer SC, Nicolotti O, Mangiatordi GF, Borges F, Cordeiro MNDS, Tejera E, Medina-Franco JL, Cruz-Monteagudo M\",\n",
      "            \"publication/journal\": \"Drug Discov Today\",\n",
      "            \"publication/title\": \"From flamingo dance to (desirable) drug discovery: a nature-inspired approach.\",\n",
      "            \"optimization/encoding\": \"processing of signals and the resulting values are converted to quantile rank.\",\n",
      "            \"optimization/features\": \"defaults classification labels lists or can be provided by the user\",\n",
      "            \"optimization/meta\": \"authors recommend to choose the model with the highest F1-score\",\n",
      "            \"optimization/parameters\": \"not clearly  stated\",\n",
      "            \"model/interpretability\": \"various methods to directly determine class of genes\",\n",
      "            \"evaluation/confidence\": \"qualitative description of the advantages of the presented pipeline\",\n",
      "            \"evaluation/measure\": \"precision and recall\",\n",
      "            \"evaluation/method\": \"Cross-validation and independent dataset\",\n",
      "            \"dataset/redundancy\": \"In order to avoid excessive numbers of false\\npositive calls due to this imbalance, we trained the\\nmodels to optimize the metric Kappa rather than accuracy, as Kappa accounts for imbalanced number of genes\\nbelonging to each class in training data\",\n",
      "            \"dataset/splits\": \"253 MAE genes and 1127 BAE genes\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b69\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"28807860\",\n",
      "            \"updated\": \"03/08/2022 13:39:24\",\n",
      "            \"authors\": \"Llanos F, Xie Z, Chandrasekaran B\",\n",
      "            \"journal\": \"J Neurosci Methods\",\n",
      "            \"title\": \"Hidden Markov modeling of frequency-following responses to Mandarin lexical tones.\",\n",
      "            \"doi\": \"10.1016/j.jneumeth.2017.08.010\",\n",
      "            \"year\": \"2017\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"d4ddd51f-3d4c-4c5d-8269-38a65992f2da\",\n",
      "        \"shortid\": \"0yzdxjimwz\",\n",
      "        \"score\": 0.43,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/08/2022 13:39:24\",\n",
      "            \"publication/authors\": \"Llanos F, Xie Z, Chandrasekaran B\",\n",
      "            \"publication/journal\": \"J Neurosci Methods\",\n",
      "            \"publication/title\": \"Hidden Markov modeling of frequency-following responses to Mandarin lexical tones.\",\n",
      "            \"optimization/algorithm\": \"regularized logistic regression and random forest\",\n",
      "            \"optimization/encoding\": \"Gene expression data, clinical variables.\",\n",
      "            \"optimization/features\": \"f=10 ?\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"Binary classification\",\n",
      "            \"evaluation/measure\": \"Balanced accuracy and ROC-AUC\",\n",
      "            \"evaluation/method\": \"10-fold nested cross-validation. No independent validation data\",\n",
      "            \"dataset/provenance\": \"Patient data from the  Rheumatoid Arthritis Medication Study (RAMS). N_pos=42, N_neg=43. Not previuolsy used. \",\n",
      "            \"dataset/splits\": \"Nested cross-validation split. N_pos, N_neg not available\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b6a\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"28747397\",\n",
      "            \"updated\": \"03/08/2022 18:05:03\",\n",
      "            \"authors\": \"Gao H, Aderhold A, Mangion K, Luo X, Husmeier D, Berry C\",\n",
      "            \"journal\": \"J R Soc Interface\",\n",
      "            \"title\": \"Changes and classification in myocardial contractile function in the left ventricle following acute myocardial infarction.\",\n",
      "            \"doi\": \"10.1098/rsif.2017.0203\",\n",
      "            \"year\": \"2017\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"4427eadc-dc28-4afb-8ae5-dcaf51935306\",\n",
      "        \"shortid\": \"oi6cru1897\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/08/2022 18:05:03\",\n",
      "            \"publication/authors\": \"Gao H, Aderhold A, Mangion K, Luo X, Husmeier D, Berry C\",\n",
      "            \"publication/journal\": \"J R Soc Interface\",\n",
      "            \"publication/title\": \"Changes and classification in myocardial contractile function in the left ventricle following acute myocardial infarction.\",\n",
      "            \"optimization/algorithm\": \"Yes: SVM\",\n",
      "            \"optimization/encoding\": \"Yes: sequence features (NVM, g-gap, TPC) and composition properties (CTD, pseAAC) \",\n",
      "            \"optimization/features\": \"Yes: 5 types of features (NVM, g-gap, TPC, CTD, pseAAC). Feature selection using ANOVA for g-gap and pseAAC, binomial distribution for TPC and Incremental feature selection.\\nand size of vectors (21, 60, 81, 400, 8000 depending on the feature extraction method...)\",\n",
      "            \"optimization/parameters\": \"Yes: parameters C and g, optimised by grid search space\",\n",
      "            \"optimization/regularization\": \"Yes: Parameter C, optimised by grid search space\",\n",
      "            \"model/availability\": \"No, only a prediction web service\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/comparison\": \"Yes: Comparison with other classifiers: J48, Bagging, Random Forest, Naive Bayes\\n Comparison with other published methods: HBPred, iGHBP, HBPred2.0\",\n",
      "            \"evaluation/confidence\": \"No: only comparing difference between performance measures\",\n",
      "            \"evaluation/measure\": \"Yes: Sensitivity, Specificity, Accuracy, Matthew correlation coefficient, AUC\",\n",
      "            \"evaluation/method\": \"Yes: on 5-fold training dataset and also on independent dataset\",\n",
      "            \"dataset/availability\": \"Yes: website url (http://lin-group.cn/server/HBPred2.0/download.html)\",\n",
      "            \"dataset/provenance\": \"Yes: previous paper\",\n",
      "            \"dataset/redundancy\": \"Yes: exclusion of identical sequences between testing and training datasets. Reduced redundancy within testing dataset (sequence identity >60% CD-HIT).\",\n",
      "            \"dataset/splits\": \"Yes, size of training and test set, including distribution N_pos N_neg\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b74\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"28881974\",\n",
      "            \"updated\": \"03/17/2022 23:25:21\",\n",
      "            \"authors\": \"Michel M, Men\\u00e9ndez Hurtado D, Uziela K, Elofsson A\",\n",
      "            \"journal\": \"Bioinformatics\",\n",
      "            \"title\": \"Large-scale structure prediction by improved contact predictions and model quality assessment.\",\n",
      "            \"doi\": \"10.1093/bioinformatics/btx239\",\n",
      "            \"year\": \"2017\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"23c26bad-c7ec-455d-aec5-edc6cea9e204\",\n",
      "        \"shortid\": \"28yy20yr51\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/17/2022 23:25:21\",\n",
      "            \"publication/authors\": \"Michel M, Men\\u00e9ndez Hurtado D, Uziela K, Elofsson A\",\n",
      "            \"publication/title\": \"Large-scale structure prediction by improved contact predictions and model quality assessment.\",\n",
      "            \"optimization/algorithm\": \"Algorithm 1 (TripletRes): neural network\\n\\nAlgorithm 2 (ResTriplet): neural network\",\n",
      "            \"optimization/encoding\": \"For each sequence a multiple sequence alignment (MSA) was performed.\",\n",
      "            \"optimization/features\": \"For each sequence three matrix features are generated: Covariance matrix, Precision Matrix, coupling parameters of the Potts model.\",\n",
      "            \"optimization/meta\": \"Algorithm 1: No.\\n\\nAlgorithm 2: Yes. The network is actually composed of two subnetworks (called Stage 1 and Stage 2 in the paper), the first giving the inputs to the second. \",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"The model produces a prediction of the contact map for each residue pair in the sequence alignment.\",\n",
      "            \"evaluation/comparison\": \"Not clear. They compare Algorithm 1 and Algorithm 2.\",\n",
      "            \"evaluation/confidence\": \"They claim statistical significance in the different performances of Algorithm 1 and Algorithm 2.\",\n",
      "            \"evaluation/measure\": \"Prediction accuracy (performed by CASP13 assesors)\",\n",
      "            \"evaluation/method\": \"Independent dataset (Dataset 2, i.e. CASP13)\",\n",
      "            \"dataset/availability\": \"Yes. \\n\\nDataset 1: URL: http://scop.berkeley.edu/\\n\\nDataset 2: URL: https://predictioncenter.org/casp13/\",\n",
      "            \"dataset/provenance\": \"Dataset 1: Protein sequences retrived from SCOPe 2.07 database. N = 7,671. Used in other papers. Dataset used for training.\\n\\nDataset 2: CASP13. Used in other papers. Dataset used for test. N = 122.\\n\\nThe paper is about the prediction of contact maps in the protein sequence, so data are not in classes and N_pos and N_neg do not apply (not reported from now on)\",\n",
      "            \"dataset/redundancy\": \"Dataset 1 (used for training) and Dataset 2 (used for test) are independent.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b76\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"29036374\",\n",
      "            \"updated\": \"03/23/2022 13:41:44\",\n",
      "            \"authors\": \"Li H, Shaham U, Stanton KP, Yao Y, Montgomery RR, Kluger Y\",\n",
      "            \"journal\": \"Bioinformatics\",\n",
      "            \"title\": \"Gating mass cytometry data by deep learning.\",\n",
      "            \"doi\": \"10.1093/bioinformatics/btx448\",\n",
      "            \"year\": \"2017\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"d7de0b56-fc2d-4ad5-a3d8-d33f721d5f36\",\n",
      "        \"shortid\": \"nzflw09djs\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/23/2022 13:41:44\",\n",
      "            \"publication/authors\": \"Li H, Shaham U, Stanton KP, Yao Y, Montgomery RR, Kluger Y\",\n",
      "            \"publication/title\": \"Gating mass cytometry data by deep learning.\",\n",
      "            \"optimization/algorithm\": \"Algorithm 1: they use a novel machine learning method for feature extraction, called Gaussian interaction profile kernel and autoencoder (GIPAE). \\n\\nAlgorithm 2: they use Random Forest for classification.\",\n",
      "            \"optimization/encoding\": \"Input information is transformed by GIPAE, in order to extract new features from data. The transformed data are then used for training a Random Forest algorithm.\",\n",
      "            \"model/availability\": \"The repository of the code exists at https://github.com/HanJingJiang/GIPAE but the actual code has been removed.\",\n",
      "            \"model/interpretability\": \"Algorithm 1: Transparent. Input features regarding diseases and drugs are transform to provide a sort of similarity measure between different drugs and different diseases. These information are then used to train Algorithm 2.\\n Algorithm 2: black box.\",\n",
      "            \"evaluation/comparison\": \"Compared with other predictors of drug-disease association: DrugNet, HGBI, KBMF, MBiRW, DRRS.\",\n",
      "            \"evaluation/confidence\": \"No confidence intervals or statistical significance stated.\",\n",
      "            \"evaluation/measure\": \"Sensitivity, Specificity, F1-score, and accuracy.\",\n",
      "            \"evaluation/method\": \"10-fold cross vaildation\",\n",
      "            \"dataset/availability\": \"Yes. Made available by the authors at: https://github.com/HanJingJiang/GIPAE. No License stated.\",\n",
      "            \"dataset/provenance\": \"Dataset 1: Cdataset (N_pos = 2532; N_neg = 2532); Used in previous papers.\\n\\nDataset 2: Fdataset (N_pos: 1933; N_neg = 1933); Used in previous papers.\\n\\nBoth databases contain established drug-disease interactions, that they used as positive cases. Negative cases generated randomly pairing diseases and drugs available in the databases. The number of negative cases generated is always equal to the number of positive cases. Both the dataset are integrated with information coming from other databases (PubChem, MeSH).\",\n",
      "            \"dataset/redundancy\": \"Dataset 1 and 2 are independent. No redundancies stated in 10-fold cross validation.\",\n",
      "            \"dataset/splits\": \"Both databases used as training and validation set using 10-fold cross-validation.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"660304301502715bfe53d658\",\n",
      "        \"uuid\": \"2783c6b5-d21f-4ac6-a776-4235d6631552\",\n",
      "        \"created\": \"2024-03-26T17:21:51.940Z\",\n",
      "        \"updated\": \"2024-03-26T17:21:51.940Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"28369334\",\n",
      "            \"authors\": \"He, B., Mortuza, S. M., Wang, Y., Shen, H. B., & Zhang, Y.\",\n",
      "            \"journal\": \"Bioinformatics\",\n",
      "            \"title\": \"NeBcon: Protein contact map prediction using neural network training coupled with na\\u00efve Bayes classifiers\",\n",
      "            \"doi\": \"10.1093/bioinformatics/btx164\",\n",
      "            \"year\": \"2017\"\n",
      "        },\n",
      "        \"shortid\": \"6jexahy331\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches\": {\n",
      "            \"evaluation/comparison\": \"Comparison has been perfomed using the test introduced in this study. No baseline approaches tested\",\n",
      "            \"evaluation/measure\": \"accuracy in contact prediction at different distance ranges (short, medium and long range contacts)\",\n",
      "            \"evaluation/method\": \"independent dataset\",\n",
      "            \"optimization/algorithm\": \"Naive Bayes combined with neural networks. The algorithm is not new.\",\n",
      "            \"optimization/config\": \"Not available\",\n",
      "            \"optimization/encoding\": \"Overall 717 sequence-based features are adopted, including MSA-derived, secondary structure (predicted), solvation (predicted), sequence separation between pairs of residues.\",\n",
      "            \"optimization/features\": \"517 features. no feature selection apparently performed.\",\n",
      "            \"optimization/fitting\": \"number of parameters, though not precisely estimated, is much lower than number of data points. Unclear how potential underfitting has been handled.\",\n",
      "            \"optimization/meta\": \"Yes, it adopts predictions obtained by other contact map prediction methods. It is not clear whether training data used for initial predictor are independent from test data of the meta predictor.\",\n",
      "            \"model/availability\": \"Source code and stanalone version available at the tool website.  License is not specified\",\n",
      "            \"model/duration\": \"not reported\",\n",
      "            \"model/interpretability\": \"model is black box\",\n",
      "            \"dataset/availability\": \"Yes, available at the tool website. No licence specified \",\n",
      "            \"dataset/provenance\": \"Data for training and testing were extracted from Protein Data Bank (PDB). Npos = 20636/26798/87200 (short/medium/long range residue contacts). Nneg = NA. Dataset firstly introduced in this study.\",\n",
      "            \"dataset/redundancy\": \"Redundancy between training and testing set is set to at most 25% pairswise sequence identity. \",\n",
      "            \"dataset/splits\": \"Training set: 517 proteins. Test set: 98 proteins. No validation set has been used. \",\n",
      "            \"publication/authors\": \"He, B., Mortuza, S. M., Wang, Y., Shen, H. B., & Zhang, Y.\",\n",
      "            \"publication/title\": \"NeBcon: Protein contact map prediction using neural network training coupled with na\\u00efve Bayes classifiers\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"66735a8837ea6fa797a6c341\",\n",
      "        \"shortid\": \"otyepo566r\",\n",
      "        \"uuid\": \"297b4cc8-9937-41b5-bfb3-7469fedc1fbe\",\n",
      "        \"created\": \"2024-06-19T22:24:08.516Z\",\n",
      "        \"updated\": \"2024-06-19T22:24:08.516Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"29181236\",\n",
      "            \"authors\": \"Yashik Singh\",\n",
      "            \"journal\": \"Healthcare Informatics Research \",\n",
      "            \"title\": \"Machine Learning to Improve the Effectiveness of ANRS in Predicting HIV Drug Resistance\",\n",
      "            \"doi\": \"10.4258/hir.2017.23.4.271 \",\n",
      "            \"year\": \"2017\"\n",
      "        },\n",
      "        \"score\": 0.95,\n",
      "        \"matches\": {\n",
      "            \"evaluation/availability\": \"Not available.\",\n",
      "            \"evaluation/comparison\": \"Comparison not undertaken.\",\n",
      "            \"evaluation/confidence\": \"No confidence intervals reported. '88% \\u00b1 7.1% improvement' is noted but unclear if specific confidence metrics.\",\n",
      "            \"evaluation/measure\": \"Some performance metrics of the model are reported. However, these are not compared to the literature or other previously published models.\\n\\n1. Accuracy percentages: provide an overall measure of how well the model performs by detailing the percentage of correct predictions.\\n\\n2. Positive Predictive Value (PPV) and Negative Predictive Value (NPV): metrics for these were reported and indicate the probability of a positive/negative prediction being correct.\\n\\n3. Statistical Significance (aZ-score): aZ-score greater than 1.98 reported. This would indicate a p-value less than 0.05 and a statistically significant result. \",\n",
      "            \"evaluation/method\": \" 5-fold cross-validation performed for model evaluation.\",\n",
      "            \"optimization/algorithm\": \"The algorithm used is a supervised machine learning algorithm for classification.\\n-However, the exact model type not mentioned or clear.\\n-Text refers to the model used as 'ANRS', a computer based interpretation algorithm was built by the French ANRS (Agence Nationale de Recherches sur le SIDA; National Agency for AIDS Research). ANRS classifies ARV resistance according to three levels: susceptible, intermediate, and resistant. \\u2018Susceptible\\u2019 indicates that a particular ARV drug will be effective against HIV; \\u2018intermediate\\u2019 indicates that the ARV drug is partially effective; and if the ARV is not effective at all, it is classified \\u2018resistant\\u2019.\\n-Further online searches do not clearly yield information on this model.\",\n",
      "            \"optimization/config\": \"Configuration not available.\",\n",
      "            \"optimization/encoding\": \"No information in text on how the genotype seqs or phenotype data was encoded for the model.\",\n",
      "            \"optimization/features\": \"Unclear from text - not explicitly stated. Text suggests after feature selection the top 10 features were selected for the model.\\n\\nYes - feature selection was performed and noted in text. The text mentions using ReliefF, MODTree filtering, FCBF filtering, and CFS filtering. These feature selection methods were used to identify the most relevant features (gene mutations) from the data for the ML task of predicting HIV drug resistance.\",\n",
      "            \"optimization/fitting\": \"Overfitting less likely due to 5-fold cross-validation and limited features in use. Underfitting may be possible but low info in text not clear to determine the fit likelihood. Parameter numbers unknown.\",\n",
      "            \"optimization/parameters\": \"Not mentioned in text - difficult to infer/extrapolate as model type is also not specified.\",\n",
      "            \"optimization/regularization\": \"5-fold cross-validation technique was in use to help prevent overfitting. No others clearly noted in text.\",\n",
      "            \"model/availability\": \"None available or linked. No GitHub, code repository available.\",\n",
      "            \"model/duration\": \"No information on execution time or compute requirements.\",\n",
      "            \"model/interpretability\": \"Black box. Next to no required information for model interpretation available. No datasets, no code, no parameters, features, data splits. Even the exact model algorithm in use is unclear beyond the fact it is a supervised machine learning model that performs classification.\",\n",
      "            \"dataset/availability\": \"Data was sourced from the Stanford HIV drug resistance database (http://hivdb.stanford.edu/).\\nHowever, the exact sequences and phenotype/genotype data used is not listed or avaialble in text/supplementary data. So the data used is not available nor the splits.\",\n",
      "            \"dataset/provenance\": \"Database - Stanford HIV drug resistance database (http://hivdb.stanford.edu/).\\n\\nThe data used is de-identified genotype-phenotype datasets: 23,000 protease gene sequences and 23,000 reverse transcriptase gene sequences.\",\n",
      "            \"dataset/redundancy\": \"Some information in text on the splits.\\n\\nData is split by 5-fold cross-validation, this uses four folds for training and the remaining unseen fold for testing in each iteration.\\n\\nHowever, the level of redundacy reduction (if any performed) is not clear in the text.\",\n",
      "            \"dataset/splits\": \"Unclear if whole dataset points = \\n-46,000 total (23,000 protease seqs & 23,000 reverse transcriptase seqs) \\nor \\n-23,000 total (containing a mix of protease seqs and reverse transcriptase seqs.)\\nThe former is stated at first but the splits noted later in the text align with the latter.\\n\\nText notes for the data splits:\\n-Training dataset: 18,400 protease seqs and reverse transcriptase seqs\\n-Testing dataset: 4,600 protease seqs and reverse transcriptase seqs\\nUnclear the distibution of these.\\n\\nDistibutions unclear from text and not available in any figure/tables/files.\",\n",
      "            \"publication/authors\": \"Yashik Singh\",\n",
      "            \"publication/journal\": \"Healthcare Informatics Research \",\n",
      "            \"publication/title\": \"Machine Learning to Improve the Effectiveness of ANRS in Predicting HIV Drug Resistance\",\n",
      "            \"publication/doi\": \"10.4258/hir.2017.23.4.271 \"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b3f\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"29790392\",\n",
      "            \"updated\": \"01/25/2022 16:07:48\",\n",
      "            \"authors\": \"Privratsky JR, Zhang J, Lu X, Rudemiller N, Wei Q, Yu YR, Gunn MD, Crowley SD\",\n",
      "            \"journal\": \"Am J Physiol Renal Physiol\",\n",
      "            \"title\": \"Interleukin 1 receptor (IL-1R1) activation exacerbates toxin-induced acute kidney injury.\",\n",
      "            \"doi\": \"10.1152/ajprenal.00104.2018\",\n",
      "            \"year\": \"2018\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"21016d93-6e18-4e47-83ec-458e3a565ffe\",\n",
      "        \"shortid\": \"3ggc5le2qz\",\n",
      "        \"score\": 0.52,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"01/25/2022 16:07:48\",\n",
      "            \"publication/authors\": \"Privratsky JR, Zhang J, Lu X, Rudemiller N, Wei Q, Yu YR, Gunn MD, Crowley SD\",\n",
      "            \"publication/journal\": \"Am J Physiol Renal Physiol\",\n",
      "            \"publication/title\": \"Interleukin 1 receptor (IL-1R1) activation exacerbates toxin-induced acute kidney injury.\",\n",
      "            \"optimization/algorithm\": \"Coarse decision trees and five-fold cross-validation.\",\n",
      "            \"optimization/encoding\": \"3D segmentation on MRI exams, enhancement maps calculated. Data reduced to fixed bin number of 16 greys levels. Combat harmonisation to reduce centre effect\",\n",
      "            \"optimization/features\": \"Features computed from 2D directional matrix and average over 2D directions and slices. \",\n",
      "            \"optimization/parameters\": \"102 texture parameters in 6 categories\",\n",
      "            \"model/output\": \"Classification (pCR or no pCR). HER2 expression levels wrt IHC and FISH\",\n",
      "            \"evaluation/comparison\": \"Comparison of different configurations. Spearman correlation\",\n",
      "            \"evaluation/measure\": \"Percentile, specificity, sensitivity, positive predict value, negative predict value, accuracy\",\n",
      "            \"dataset/provenance\": \"311 patients chosen out of 445 available records. \",\n",
      "            \"dataset/splits\": \"\\\"Split 80:20. Random splitting of the data resulted in 249 cases (150 pCR, 99 no pCR) in the training set and 62 cases (38 pCR, 24 no pCR) in the test set.\\\"\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b40\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"30046299\",\n",
      "            \"updated\": \"01/26/2022 14:34:16\",\n",
      "            \"authors\": \"Tian HY, Li SJ, Wu TQ, Yao M\",\n",
      "            \"journal\": \"Comput Intell Neurosci\",\n",
      "            \"title\": \"An Extreme Learning Machine Based on Artificial Immune System.\",\n",
      "            \"doi\": \"10.1155/2018/3635845\",\n",
      "            \"year\": \"2018\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"d6d6562d-8254-45bc-88b2-6a88827e9cf8\",\n",
      "        \"shortid\": \"mewdwg9y4z\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"01/26/2022 14:34:16\",\n",
      "            \"publication/authors\": \"Tian HY, Li SJ, Wu TQ, Yao M\",\n",
      "            \"publication/journal\": \"Comput Intell Neurosci\",\n",
      "            \"publication/title\": \"An Extreme Learning Machine Based on Artificial Immune System.\",\n",
      "            \"optimization/algorithm\": \"Random forest\",\n",
      "            \"optimization/encoding\": \"Global features\",\n",
      "            \"optimization/features\": \"Intra-stable miRnot reporteds (fourth quartile of ICCs; Q100) from the discovery cohort were used as a set of input features. Feature selection protocol identified the expression of 7 miRnot reported which maximize the performance of the method tested in cross-validation on the training set.\",\n",
      "            \"optimization/fitting\": \"Number of features ~ N_pos + N_neg and Number of parameters > N_pos + N_neg\",\n",
      "            \"optimization/parameters\": \"Random forest (mtry and ntree) optimized by grid search using 5-fold cross-validation with 10 randomized replicates. Predictive model built with randomForestSRC (v2.4.2) for R.\",\n",
      "            \"optimization/regularization\": \"Yes. miRnot reported normalization with NanoStringNorm (v1.1.20).\",\n",
      "            \"model/interpretability\": \"Black box. No information about the optimized parameters were reported.\",\n",
      "            \"model/output\": \"Binary classifier (high- and low-risk groups)\",\n",
      "            \"evaluation/confidence\": \"Confidence interval shows overlap between the performance on training and validation sets\",\n",
      "            \"evaluation/method\": \"cross-validation on training set and validation on an independent set\",\n",
      "            \"dataset/availability\": \"Raw data were deposited into the Gene Expression Omnibus (GSE86474, https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE86474).\",\n",
      "            \"dataset/provenance\": \"miRnot reported samples were extracted from prostate cancer patients cohorts, and profiling obtained.  The dataset was composed of N_pos = 61, N_neg = 78. Data not used previously.    An additional 'discovery' cohort was composed of 10 patients (all negatives) .  (Positive: high-risk patients, i.e. GS (Gleason grade) > 7. low-risk patients (GS = 6).\",\n",
      "            \"dataset/splits\": \"Training set: N_pos = 50, N_neg = 49.  Testing set: N_pos = 11, N_neg = 29.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b41\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"30295871\",\n",
      "            \"updated\": \"02/08/2022 16:25:04\",\n",
      "            \"authors\": \"Rappoport N, Shamir R\",\n",
      "            \"journal\": \"Nucleic Acids Res\",\n",
      "            \"title\": \"Multi-omic and multi-view clustering algorithms: review and cancer benchmark.\",\n",
      "            \"doi\": \"10.1093/nar/gky889\",\n",
      "            \"year\": \"2018\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"805d6ac8-7e63-41b2-a36b-427fbcf4b64c\",\n",
      "        \"shortid\": \"q3f9qsuitm\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/08/2022 16:25:04\",\n",
      "            \"publication/authors\": \"Rappoport N, Shamir R\",\n",
      "            \"publication/journal\": \"Nucleic Acids Res\",\n",
      "            \"publication/title\": \"Multi-omic and multi-view clustering algorithms: review and cancer benchmark.\",\n",
      "            \"optimization/algorithm\": \"SVM (RBF kernel), Logistic regression\",\n",
      "            \"optimization/encoding\": \"Log-transform, auto-scaling\",\n",
      "            \"optimization/features\": \"Correlation-based feature selection, LASSO, step-wise variable selection\",\n",
      "            \"model/availability\": \"NA (MetaboLights accession is private)\",\n",
      "            \"model/interpretability\": \"NA (missing or inaccessible model data and source code)\",\n",
      "            \"evaluation/availability\": \"Supporting information, potentially in MetaboLights repository under private accession MTBLS1695\",\n",
      "            \"evaluation/comparison\": \"SVM, logistic regression\",\n",
      "            \"evaluation/confidence\": \"p-values, CI (95%) for AUCs\",\n",
      "            \"evaluation/measure\": \"AUC, sensitivity, specificity\",\n",
      "            \"evaluation/method\": \"10-fold Cross-validation\",\n",
      "            \"dataset/availability\": \"MTBLS1695, study still private\",\n",
      "            \"dataset/provenance\": \"20 Alzheimer's Disease patients (AD), 10 Mild cognitive impairment (MCI) and 29 control patients. Metabolomics samples measured with HNMR and DI LC-MS/MS, identification of 142 metabolites with HNMR and 51 with DI LC-MS/MS, demographic information (age and gender)\",\n",
      "            \"dataset/redundancy\": \"Average of concentrations of overlapping metabolites between HNMR and DI LC-MS/MS. PCA to screen for and remove subjects outside of 95% percentile. Student\\u2019s t-test was performed to determine if there were any significantly different metabolites between AD, MCI, and age-matched controls (p < 0.05) when compared pairwise. Non-normally distributed data were analyzed using a Mann\\u2212Whitney U test and a Bonferroni correction was applied to account for multiple comparisons. To determine if sample demographics were statistically significantly different, a one-way analysis of variance analysis (ANOVA) was conducted using the IBM SPSS Statistics toolbox (v. 24.0).\",\n",
      "            \"dataset/splits\": \"20, 10, 29 (see provenance) * 142 metabolites, \"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b42\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"29720103\",\n",
      "            \"updated\": \"03/01/2022 19:41:49\",\n",
      "            \"authors\": \"Simopoulos CMA, Weretilnyk EA, Golding GB\",\n",
      "            \"journal\": \"BMC Genomics\",\n",
      "            \"title\": \"Prediction of plant lncRNA by ensemble machine learning classifiers.\",\n",
      "            \"doi\": \"10.1186/s12864-018-4665-2\",\n",
      "            \"year\": \"2018\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"051b93a6-4e37-4b9c-8cc9-05f531317aea\",\n",
      "        \"shortid\": \"ixx5zlqxpf\",\n",
      "        \"score\": 0.57,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/01/2022 19:41:49\",\n",
      "            \"publication/authors\": \"Simopoulos CMA, Weretilnyk EA, Golding GB\",\n",
      "            \"publication/journal\": \"BMC Genomics\",\n",
      "            \"publication/title\": \"Prediction of plant lncRNA by ensemble machine learning classifiers.\",\n",
      "            \"optimization/algorithm\": \"Logistic regression, SVM with linear or Gaussian kernels, and random forest were used to conduct supervised machine learning\",\n",
      "            \"optimization/features\": \"Due to the high dimensionality of the image features and relatively small sample size, overfitting of the data is likely; therefore, before building classification models, we performed feature selection to avoid the overfitting problem. Feature dimensionality was reduced by the mRMR algorithm42 using R package mRMRe. mRMR has been shown to be a robust feature selection algorithm in various tasks43,44,45. The mRMR algorithm was applied to all image features with regard to the class label of sample (i.e., TFE3-RCC or ccRCC) to select an informative and non-redundant set of features.\",\n",
      "            \"optimization/fitting\": \"See Features\",\n",
      "            \"optimization/regularization\": \"Yes, see Features\",\n",
      "            \"evaluation/measure\": \"AUC and confidence intervals were computed with the R package pROC.\",\n",
      "            \"evaluation/method\": \"In dataset 1, five-fold cross-validation was used. To further validate our method using an external validation set, classification models were trained using dataset 1 and evaluated using dataset 2\",\n",
      "            \"dataset/availability\": \"yes, processed, not raw\",\n",
      "            \"dataset/provenance\": \"The quantitative image features extracted from H&E stained whole-slide images are available from GitHub. No access to raw data provided\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b43\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"29849042\",\n",
      "            \"updated\": \"03/04/2022 12:54:32\",\n",
      "            \"authors\": \"Han X, Chen S, Flynn E, Wu S, Wintner D, Shen Y\",\n",
      "            \"journal\": \"Nat Commun\",\n",
      "            \"title\": \"Distinct epigenomic patterns are associated with haploinsufficiency and predict risk genes of developmental disorders.\",\n",
      "            \"doi\": \"10.1038/s41467-018-04552-7\",\n",
      "            \"year\": \"2018\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"c61651cd-193f-4b5e-aa19-77eed7eb2649\",\n",
      "        \"shortid\": \"217brrych3\",\n",
      "        \"score\": 0.86,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/04/2022 12:54:32\",\n",
      "            \"publication/authors\": \"Han X, Chen S, Flynn E, Wu S, Wintner D, Shen Y\",\n",
      "            \"publication/journal\": \"Nat Commun\",\n",
      "            \"publication/title\": \"Distinct epigenomic patterns are associated with haploinsufficiency and predict risk genes of developmental disorders.\",\n",
      "            \"optimization/algorithm\": \"deep learning, novel approach\",\n",
      "            \"optimization/config\": \"implemented with PyTorch [38] using an Nvidia TITAN Xp GPU.\",\n",
      "            \"optimization/encoding\": \"datasets, all images are first resized to 224 \\u00d7 224 in axial plane,\",\n",
      "            \"optimization/parameters\": \"Batch Normalization\\n\\n\\n\",\n",
      "            \"model/interpretability\": \"color maps using Grad-CAM\",\n",
      "            \"evaluation/comparison\": \"firstly comparision to COVID-Net method https://doi.org/10.1038/s41598-020-76550-z (Scientific Reports) by ROC AUC\\n further comparisions by p-value:\\n  - Series-Adapter https://scholar.google.com/scholar?as_q=Learning+multiple+visual+domains+with+residual+adapters&as_occt=title&hl=en&as_sdt=0%2C31 \\n  - Parallel-Adapter https://ieeexplore.ieee.org/document/8578945\\n  - MS-Net https://doi.org/10.1038/s41598-020-76550-z\",\n",
      "            \"evaluation/confidence\": \"outperforming the original\\n COVID-Net trained on each dataset by 12.16% and 14.23%\\n in AUC respectively,\",\n",
      "            \"evaluation/measure\": \"Accuracy, F1 score, Sensitivity, Precision, AUC\",\n",
      "            \"evaluation/method\": \"four-fold cross-validation\",\n",
      "            \"dataset/availability\": \"preprocessed data: https://drive.google.com/file/d/1JBp9RH9-yBEdtkNYDi6wWL79o62JD5Td/view   \\n\\n\",\n",
      "            \"dataset/provenance\": \"two public COVID-19 CT datasets: \\n -   https://www.medrxiv.org/content/10.1101/2020.04.24.20078584v3\\n2482 CT images from 120 patients,  N_pos 1252, N_neg 1230\\n\\n -   http://arxiv.org/abs/2003.13865\\nN_pos 349 CT images from 216 patients, \\nN_neg 397 CT images from 171 patients\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b44\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"30388153\",\n",
      "            \"updated\": \"03/06/2022 19:15:35\",\n",
      "            \"authors\": \"Caglar MU, Hockenberry AJ, Wilke CO\",\n",
      "            \"journal\": \"PLoS One\",\n",
      "            \"title\": \"Predicting bacterial growth conditions from mRNA and protein abundances.\",\n",
      "            \"doi\": \"10.1371/journal.pone.0206634\",\n",
      "            \"year\": \"2018\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"706c0f3d-b856-473d-9864-c48e3733bceb\",\n",
      "        \"shortid\": \"vecnt31t10\",\n",
      "        \"score\": 0.52,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/06/2022 19:15:35\",\n",
      "            \"publication/authors\": \"Caglar MU, Hockenberry AJ, Wilke CO\",\n",
      "            \"publication/journal\": \"PLoS One\",\n",
      "            \"publication/title\": \"Predicting bacterial growth conditions from mRNA and protein abundances.\",\n",
      "            \"optimization/algorithm\": \"Coarse decision trees\",\n",
      "            \"optimization/encoding\": \"Following ROC and correlation analysis, Breast MRIs were assessed according to the American College of Radiology (ACR) Breast Imaging Reporting and Data System (BI-RADS) lexicon.\\n\\nManual, expert review on the MRI exams and performed 3D segmentations of the whole tumour in the first post-contrast non-subtracted sequence using ITK-Snot reportedP software.\\n\\nSusceptibility artefacts related to post-biopsy changes, when\\npresent, were excluded from segmentation and only the largest\\nlesion was segmented in multifocal tumours. \\n\\nEnhancement maps were calculated as the percentage increase in signal from the pre-contrast image to the first post-contrast image. Radiomics and statistical analysis were performed using MATLAB and publicly available CERR (Computational Environment for Radiological Research) software.\\n\\nFurthermore, data was reduced to a fixed bin number of 16 grey levels and only an interpixel distance of one was considered. CERR analysis resulted in 102 texture parameters sub-divided into six categories - 22 first order statistics, 26 statistics based on grey level cooccurrence matrices, 16 statistics based on run length matrices, 16 statistics based on size zone matrices, 17 statistics based on neighborhood grey level dependence matrices, and finally five statistics based on neighborhood grey tone difference matrices.\\n\\nFeatures were computed for each 2D directional matrix and averaged over 2D directions and slices, since data was not isotropic. As patients were scanned at different sites, Combat harmonisation was performed to remove the centre effect (local vs. foreign scans) while retaining the pathophysiologic information (either HER2 expression or pathologic response). The harmonisation employed Bayes estimates to account for both additive and multiplicative scanner effects.\\n\\nUnivariate analysis was performed to identify significant parameters. Continuous variables were described as mean, standard deviation (SD), and range. The two-tailed Mann-Whitney U test for two independent samples was used to determine significant differences between groups. Correlation analysis was then employed to remove redundant parameters from advancement to model development. If a highly positive (> 0.9) or highly negative (< -0.9) correlation was noted, the parameter with the lowest area under the receiver operating curve (AUROC) was removed.\\n\",\n",
      "            \"optimization/features\": \"1)\\tThe final model to predict HER2 intratumour expression levels (IHC vs. FISH) utilized three MRI features. Lesion type and multifocality (clinical features) and large zone emphasis (radiomic feature).\\n2)\\tThe model to predict pCR status included six MRI parameters. Lesion type and size (clinical parameters) and variance, first order entropy, 90th percentile and zone length variance (radiomic parameters).\\n\",\n",
      "            \"optimization/parameters\": \"Coarse decision tree modelling was implemented in MATLAB, with the maximum number of splits set at four and utilizing Gini\\u2019s diversity index as the splitting criterion.\",\n",
      "            \"model/interpretability\": \"Transparent. Assessing the presence of statistically significant differences, using Mann-Whitney U-test and Chi-squared test, across clinical and MRI features of 1) IHC vs FISH and 2) pCR vs non-pCR groups, before including them to the final model.\",\n",
      "            \"model/output\": \"1) Binary predictions of IHC (positive) or FISH (negative) samples.\\n 2) Binary predictions of pCR (positive) or non-pCR (negative) samples.\",\n",
      "            \"evaluation/measure\": \"Sensitivity, specificity, diagnostic accuracy\",\n",
      "            \"evaluation/method\": \"5-fold cross validation\",\n",
      "            \"dataset/provenance\": \"Breast magnetic resonance imaging (MRI) and clinical data from 311 HER2 overexpressing breast cancer patients. \\n1)        Patients were classified into two groups based on HER2 expression level. Npos=279 patients with tumours that showed HER2 protein overexpression on immunohistochemistry (IHC 3+; IHC group). Nneg=32 patients with tumours that showed HER2 gene amplification detected by FISH in the absence of protein overexpression on IHC (IHC 2+ or 1+ to 2+; FISH group).\\n2)        Npos=188 patients with pathologic complete response (pCR), which was defined as no residual invasive carcinoma in the breast or axillary lymph nodes (ypT0/isN0) at surgical resection. Nneg=123 patients that are non-pCR.\\n\",\n",
      "            \"dataset/redundancy\": \"Inclusion criteria for this study were HER2 overexpressing breast cancer patients who underwent not reportedC and pretreatment state-of-the-art contrast-enhanced breast MRI. 70 were excluded because they did not have pretreatment breast MRI and 64 patients with outside images were excluded because of poor image quality.\",\n",
      "            \"dataset/splits\": \"For the prediction of pathological complete response, the data was split into training and test sets at a ratio of 4:1 (80% training and 20% test), with feature selection performed purely on the training set. Npos,train=150 patients with pCR. Npos,test=38 patients with pCR. Nneg,train=99 patients with non-pCR. Nneg,test=24 patients with non-pCR. \\nDue to the low number of cases in the minority class, this was not feasible for the comparison between the IHC and FISH groups.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b45\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"30388122\",\n",
      "            \"updated\": \"03/08/2022 14:37:33\",\n",
      "            \"authors\": \"Babalyan K, Sultanov R, Generozov E, Sharova E, Kostryukova E, Larin A, Kanygina A, Govorun V, Arapidi G\",\n",
      "            \"journal\": \"PLoS One\",\n",
      "            \"title\": \"LogLoss-BERAF: An ensemble-based machine learning model for constructing highly accurate diagnostic sets of methylation sites accounting for heterogeneity in prostate cancer.\",\n",
      "            \"doi\": \"10.1371/journal.pone.0204371\",\n",
      "            \"year\": \"2018\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"f792fa0e-c332-4321-9ab0-a504c495e7c3\",\n",
      "        \"shortid\": \"qxfdrs4tuj\",\n",
      "        \"score\": 0.57,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/08/2022 14:37:33\",\n",
      "            \"publication/authors\": \"Babalyan K, Sultanov R, Generozov E, Sharova E, Kostryukova E, Larin A, Kanygina A, Govorun V, Arapidi G\",\n",
      "            \"publication/journal\": \"PLoS One\",\n",
      "            \"publication/title\": \"LogLoss-BERAF: An ensemble-based machine learning model for constructing highly accurate diagnostic sets of methylation sites accounting for heterogeneity in prostate cancer.\",\n",
      "            \"optimization/algorithm\": \"Na\\u00efve Bayes, logistic regression, random forest, and artificial neural network models\",\n",
      "            \"optimization/features\": \"performed feature selection using the caret R package. from 89 initial features, redundant features were removed, attributes with an absolute correlation coefficient of 0.5 or greater were also removed. Last, specific features were selected using the recursive feature elimination (RFE) method. 20 features were finally selected. \",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/confidence\": \"ML algorithms metrics\",\n",
      "            \"evaluation/measure\": \"precision, recall, accuracy\",\n",
      "            \"dataset/availability\": \"yes in Supporting information section\",\n",
      "            \"dataset/provenance\": \"made their own dataset\",\n",
      "            \"dataset/splits\": \"Among 222 patients, 126 developed postinduction hypotension\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b46\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"29720103\",\n",
      "            \"updated\": \"03/22/2022 13:13:16\",\n",
      "            \"authors\": \"Simopoulos CMA, Weretilnyk EA, Golding GB\",\n",
      "            \"journal\": \"BMC Genomics\",\n",
      "            \"title\": \"Prediction of plant lncRNA by ensemble machine learning classifiers.\",\n",
      "            \"doi\": \"10.1186/s12864-018-4665-2\",\n",
      "            \"year\": \"2018\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"2ab96eb2-c809-4f94-9729-9573ca70ad20\",\n",
      "        \"shortid\": \"od7rdaz7w7\",\n",
      "        \"score\": 0.86,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/22/2022 13:13:16\",\n",
      "            \"publication/authors\": \"Simopoulos CMA, Weretilnyk EA, Golding GB\",\n",
      "            \"publication/journal\": \"BMC Genomics\",\n",
      "            \"publication/title\": \"Prediction of plant lncRNA by ensemble machine learning classifiers.\",\n",
      "            \"optimization/algorithm\": \"Random Forest, Support Vector Machine (SVM), Adaptative Boosting with a Decision Tree base estimator (AdaBoost Tree), and k-Nearest Neighbors. AdaBoost Tree was selected\",\n",
      "            \"optimization/encoding\": \"Every compound in the datasets were collected as SMILES strings and sanitized with RDKit. The resulting datasets consisted of 635 descriptors for the Dragon dataset, and 506 features for the \\u201copen-source\\u201d dataset. \",\n",
      "            \"optimization/features\": \"Five-fold cross validation was performed with hyperparameter tuning using a grid search.  The optimal percentile of features was tuned as a parameter of the Grid Search.\\n32 descriptors for the \\u201cDragon\\u201d model, and 51descriptors for the \\u201copen source\\u201d model\",\n",
      "            \"optimization/fitting\": \"To avoid any model bias due to overfitting, the number of features used by the model is a hyperparameter that has been optimized.\",\n",
      "            \"optimization/regularization\": \"Structures were standardized using the \\u201cstandardizer\\u201d from Python.\",\n",
      "            \"model/interpretability\": \"direct correlation between compound and sweetness\",\n",
      "            \"model/output\": \"regression to predict the logSw (relative sweetness)\",\n",
      "            \"evaluation/comparison\": \"e-Sweet platform (Zheng et al., 2019) is based on a consensus model of various\\n machine learning protocols. The performance of BitterSweet is comparable to\\n e-Sweet and Predisweet (R2 of 0.72 on our test set) but the protocol is still unpublished, and seven molecules of the test set has not been\\n considered as sweet.\",\n",
      "            \"evaluation/confidence\": \"statistical metrics\",\n",
      "            \"evaluation/measure\": \"predictive performance was evaluated based on criteria previously defined by: https://doi.org/10.1016/S1093-3263(01)00123-1.\\n correlation coefficient, coefficient of determination, slopes of the regression lines through the origin for the observed vs. predicted and predicted vs. observed values respectively, corresponding coefficients of determination, root mean squared error, mean absolute error\",\n",
      "            \"evaluation/method\": \"independent dataset\",\n",
      "            \"dataset/provenance\": \"316 sweet compounds from SweetenersDB dataset.\\nhttps://doi.org/10.1016/j.foodchem.2016.10.145\",\n",
      "            \"dataset/redundancy\": \"The updated SweetenersDB was split in training and test sets using a Sphere Exclusion clustering algorithm. \",\n",
      "            \"dataset/splits\": \"64 diverse compounds (20.3%) were selected for the test set, leaving 252 compounds in the training set\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b47\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"30008861\",\n",
      "            \"updated\": \"03/28/2022 23:21:09\",\n",
      "            \"authors\": \"Zhang TM, Huang T, Wang RF\",\n",
      "            \"journal\": \"Oncol Lett\",\n",
      "            \"title\": \"Cross talk of chromosome instability, CpG island methylator phenotype and mismatch repair in colorectal cancer.\",\n",
      "            \"doi\": \"10.3892/ol.2018.8860\",\n",
      "            \"year\": \"2018\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"39fb8263-4ce3-4283-87ed-5ceba5717b62\",\n",
      "        \"shortid\": \"9m31lscgpm\",\n",
      "        \"score\": 0.86,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/28/2022 23:21:09\",\n",
      "            \"publication/authors\": \"Zhang TM, Huang T, Wang RF\",\n",
      "            \"publication/journal\": \"Oncol Lett\",\n",
      "            \"publication/title\": \"Cross talk of chromosome instability, CpG island methylator phenotype and mismatch repair in colorectal cancer.\",\n",
      "            \"optimization/algorithm\": \"A series of classification methods, all from scimitar learn ; including SVM (best performance), RF and NB. \",\n",
      "            \"optimization/encoding\": \"The paper proposed sequence image normalisation for encoding.  yet very poorly explained and thus difficult to understand\",\n",
      "            \"optimization/features\": \"RGB matrices encoding sequences, yet unclear how this works exactly.\",\n",
      "            \"optimization/fitting\": \"many more features, if one considers that every RGB value as a feature.  \",\n",
      "            \"optimization/meta\": \"not features coming from other predictors, all raw data \",\n",
      "            \"optimization/parameters\": \"ML parameters are optmized, e.g.  regularization parameter c for SVM and number of trees for RF.  Not all parameters are systematically mentioned \",\n",
      "            \"optimization/regularization\": \"Cross-validation approaches\",\n",
      "            \"model/availability\": \"yes via GitHub\",\n",
      "            \"model/interpretability\": \"no obvious interpretation\",\n",
      "            \"model/output\": \"binary classification\",\n",
      "            \"evaluation/availability\": \"might be part of the githuv rep\",\n",
      "            \"evaluation/comparison\": \"method in ref [32], which has significantly worse performance.\",\n",
      "            \"evaluation/measure\": \"Accuracy, AUC, presicion and recall\",\n",
      "            \"dataset/availability\": \"from other papers, and requests can be made to the senior author. Data also available via GitHub link\",\n",
      "            \"dataset/provenance\": \"Comes from two of other publications [13] and [8]. Note that the purpose of this article is to show a new data representation for classification. First data set consist of 365 NGS samples, 108 are recently infected hosts and 257 are chronically infected hosts. The second set consists of 335 infected persons, 142 correspond to outbreaks with more than one person and 193 are isolated cases. the latter is used for clustering, so not further considered here\",\n",
      "            \"dataset/redundancy\": \"No stratification explicitly discussed, yet leave-one-outbreak out aims to resolve overlaps between the folds used for training and testing.\",\n",
      "            \"dataset/splits\": \"no separate validation set. Cross-validation is used, both classic 10-fold and \\\"leave-one-outbreak-out\\\", also under sampling of the larger set (chronically affected) is tested.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b48\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"30483279\",\n",
      "            \"updated\": \"03/28/2022 23:57:02\",\n",
      "            \"authors\": \"Zimmer D, Schneider K, Sommer F, Schroda M, M\\u00fchlhaus T\",\n",
      "            \"journal\": \"Front Plant Sci\",\n",
      "            \"title\": \"Artificial Intelligence Understands Peptide Observability and Assists With Absolute Protein Quantification.\",\n",
      "            \"doi\": \"10.3389/fpls.2018.01559\",\n",
      "            \"year\": \"2018\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"81c5e03c-ebb1-44ac-b252-0b787354659d\",\n",
      "        \"shortid\": \"v1vwcbzzui\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/28/2022 23:57:02\",\n",
      "            \"publication/authors\": \"Zimmer D, Schneider K, Sommer F, Schroda M, M\\u00fchlhaus T\",\n",
      "            \"publication/journal\": \"Front Plant Sci\",\n",
      "            \"publication/title\": \"Artificial Intelligence Understands Peptide Observability and Assists With Absolute Protein Quantification.\",\n",
      "            \"optimization/algorithm\": \"Yes: SVM (compared to KNN, adaboost, random forest, decision tree, logistic regression and XGBoost)\",\n",
      "            \"optimization/encoding\": \"Yes: sequence features (KNF/NC, KSNPF, PSNP, KSPSDP, PseDNC, CPD)\",\n",
      "            \"optimization/features\": \"Yes: 6 f. Wrapper method (sequence forward selection). ten-fold cross-validation on training dataset.\",\n",
      "            \"optimization/parameters\": \"Yes: box constraint and kernel scale, optimised by a grid search\",\n",
      "            \"optimization/regularization\": \"Yes:  box constraint parameter\",\n",
      "            \"model/availability\": \"No. Link to project (https://zhulab.ahu.edu.cn/m5CPred-SVM/) is broken\",\n",
      "            \"model/interpretability\": \"~Yes: Results for different feature selections\",\n",
      "            \"evaluation/comparison\": \"Yes: RNAm5Cfinder, iRNA-m5C, iRNAm5C-PseDNC, RNAm5CPred, PEA-m5C\",\n",
      "            \"evaluation/confidence\": \"No. Justification based only on evaluation values difference (acc, sn, sp, pre, mcc, f1, AUROC)\",\n",
      "            \"evaluation/measure\": \"accuracy, sensitivity, specificity, precision, Matthews correlation coefficient and F1-score, AUROC\",\n",
      "            \"evaluation/method\": \"independent datasets\",\n",
      "            \"dataset/availability\": \"Yes: Supp data of referenced publication,  and GEO query\",\n",
      "            \"dataset/provenance\": \"Yes: used by previous papers. N_pos and N_neg are given.\",\n",
      "            \"dataset/redundancy\": \"Yes: random selection with redundancy removal in pos and neg sets (>70% sequence identity CD-HIT)\",\n",
      "            \"dataset/splits\": \"Yes: Size of N_pos and N_neg for training and test sets.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b75\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"29133589\",\n",
      "            \"updated\": \"03/28/2022 00:12:23\",\n",
      "            \"authors\": \"Ding MQ, Chen L, Cooper GF, Young JD, Lu X\",\n",
      "            \"journal\": \"Mol Cancer Res\",\n",
      "            \"title\": \"Precision Oncology beyond Targeted Therapy: Combining Omics Data with Machine Learning Matches the Majority of Cancer Cells to Effective Therapeutics.\",\n",
      "            \"doi\": \"10.1158/1541-7786.MCR-17-0378\",\n",
      "            \"year\": \"2018\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"54b0bca4-f5c2-48bb-81d3-2aa6f88cbafc\",\n",
      "        \"shortid\": \"c80vqcn356\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/28/2022 00:12:23\",\n",
      "            \"publication/authors\": \"Ding MQ, Chen L, Cooper GF, Young JD, Lu X\",\n",
      "            \"publication/journal\": \"Mol Cancer Res\",\n",
      "            \"publication/title\": \"Precision Oncology beyond Targeted Therapy: Combining Omics Data with Machine Learning Matches the Majority of Cancer Cells to Effective Therapeutics.\",\n",
      "            \"optimization/algorithm\": \"Least absolute shrinkage and selection operator (LASSO).\",\n",
      "            \"optimization/config\": \"The code and the parameters used are available at: https://github.com/sailalithabollepalli/EpiSmokEr. No license specified.\",\n",
      "            \"optimization/encoding\": \"Training dataset are quantile-normalized before training.\",\n",
      "            \"optimization/features\": \"Number of f = 122.\",\n",
      "            \"optimization/parameters\": \"Number of p not reported, but could be inferred from the context.\",\n",
      "            \"optimization/regularization\": \"Introduction of a parameter \\\"lambda\\\" in the penalized log likelihood procedure for selecting the \\\"trainable\\\" parameter. Selection of the \\\"lambda\\\" parameter through cross-validation.\",\n",
      "            \"model/availability\": \"Code is available at: https://github.com/sailalithabollepalli/EpiSmokEr. No License provided.\",\n",
      "            \"model/interpretability\": \"Black box.\",\n",
      "            \"model/output\": \"Regression (probability scores of being Smoker, Former Smoker or Never Smoker)\",\n",
      "            \"evaluation/comparison\": \"Comparison with non-ML methods provided. An extensive comparison was not performed due to differences in the methods.\",\n",
      "            \"evaluation/measure\": \"Sensitivity and Specificity\",\n",
      "            \"evaluation/method\": \"Using independent dataset.\",\n",
      "            \"dataset/availability\": \"Dataset 1: yes. Dataset ID: EGAD00001000200; URL: https://ega-archive.org/datasets/EGAD00001000200; license: stated with specific Data Use Ontology (DUO) codes: DUO:0000005, DUO:0000026, DUO:0000027, DUO:0000029, DUO:0000019, DUO:0000028.\\n\\nDataset 2: no (available upon request at: https://thl.fi/en/web/thl-biobank/for-researchers/sample-collections/twin-study)\\n\\nDataset 3: yes. Dataset id: GSE42861; URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=gse42861; license: not reported\\n\\nDataset 4: yes. Dataset id: GSE50660; URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE50660; license: not reported\",\n",
      "            \"dataset/provenance\": \"For each dataset 3 categories are considered: Smokers (S), Former Smokers (FS), and Never Smokers (NS). For each dataset N_S, N_FS, and N_NS will be used for the number of Smokers, Former Smokers, and Never Smokers respectively. For each dataset only data related to Dnot reported methilation.\\n\\nDataset 1: data from 474 individuals from the Dietary, Lifestyle and Genetic determinants of Obesity and Metabolic syndrome (DILGOM). N_S = 113, N_FS = 118, N_NS = 243. Used in other papers.\\n\\nDstaset 2: data from 408 individuals from the Finnish Twin Cohort (FTC). N_S = 67; N_FS = 141; N_NS = 200. Used in other papers.\\n\\nDataset 3: data from 687 individuals from the GSE42861 in Gene Expression Omnibus (GEO). N_S = 266; N_FS = 228; N_NS = 193. Used in other papers.\\n\\nDataset 4: data from 464 individuals from the GSE50660 in Gene Expression Omnibus (GEO). N_S = 22; N_FS = 263, N_NS = 179.\",\n",
      "            \"dataset/redundancy\": \"Dataset 1, 2, 3 and 4 are independent from each other.\",\n",
      "            \"dataset/splits\": \"Dataset 1: Used as training test. Used for cross-validation randomly subdividing data in 90% training and 10% test data. Distribution of S, FS, and NS after random subdivisions is not reported\\n\\nDataset 2: used as independent set to verify generalization capability of the classifier. Distribution of S, FS, and NS stated above.\\n\\nDataset 3: used as independent set to verify generalization capability of the classifier. Distribution of S, FS, and NS stated above.\\n\\nDataset 4: used as independent set to verify generalization capability of the classifier. Distribution of S, FS, and NS stated above.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"65e843f41502715bfe53cd1e\",\n",
      "        \"uuid\": \"9bd31f10-4479-4940-810c-3e6a4bcfb1e3\",\n",
      "        \"created\": \"2024-03-06T10:22:44.950Z\",\n",
      "        \"updated\": \"2024-03-06T10:35:57.616Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"title\": \"P2Rank: machine learning based tool for rapid and accurate prediction of ligand binding sites from protein structure\",\n",
      "            \"authors\": \"Radoslav Kriv\\u00e1k, David Hoksza\",\n",
      "            \"journal\": \"Journal of cheminformatics\",\n",
      "            \"year\": \"2018\",\n",
      "            \"pmid\": \"30109435\",\n",
      "            \"doi\": \"10.1186/s13321-018-0285-8\",\n",
      "            \"done\": 6,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"shortid\": \"iblymem5cf\",\n",
      "        \"score\": 0.96,\n",
      "        \"matches\": {\n",
      "            \"evaluation/method\": \"The model was evaluated on two independent datasets. Disjunct with data points present in training and validation set.\",\n",
      "            \"evaluation/measure\": \"Instead of the conventional performance metrics, 3 reported metrics are as follows:\\n1. Identification success rate [%] measured by DCCcriterion (distance from pocket center to closest ligand atom) with 4 \\u00c5 threshold.\\n2. Average total number of binding sites predicted per protein by on a given dataset.\\n3. Average time required for prediction on a single protein.\",\n",
      "            \"evaluation/comparison\": \"The method was compared to other publicly available methods in the 3 mentioned metrics.\",\n",
      "            \"evaluation/confidence\": \"The confidence intervals are only reported for \\\"Average prediction time per protein\\\".\\nWhile the method is reported to perform best in the first 2 mentioned metrics, which is not the case in terms of prediction time, the difference is not substantial.\",\n",
      "            \"optimization/algorithm\": \"The used algorithm is a Random Forest Regression model.\\nThe model is not novel.\",\n",
      "            \"optimization/meta\": \"The algorithm is not a meta-predictor.\",\n",
      "            \"optimization/config\": \"The model is accessible through the URL of the GitHub repository.\",\n",
      "            \"optimization/encoding\": \"The model takes vectors of 35 numerical features as input.\",\n",
      "            \"optimization/features\": \"Every vector is composed of 35 numerical features.\\nNo mention on feature selection.\",\n",
      "            \"optimization/fitting\": \"The clear number of parameters is not mentioned.\\nNo assessment on over/under fitting was mentioned.\",\n",
      "            \"optimization/parameters\": \"Beside the hyper-parameters of Random Forest, the algorithm uses other parameters and \\\"cut-of's\\\", \\\"thresholds\\\", \\\"protrusion radius\\\", are explicitly mentioned.\\nIt is mentioned that only hyper-parameters are optimized on a separate dataset from training set.\\nThe method of optimization is not mentioned.\",\n",
      "            \"optimization/regularization\": \"A validation set was used to optimize the parameters before training on the training set.\",\n",
      "            \"model/interpretability\": \"The model has 200 trees, each grown with no depth limit using 6 features, this makes it challenging to interpret due to the sheer number of trees and their depth.\\nHowever, it is still possible to obtain feature importance scores.\",\n",
      "            \"model/output\": \"It is a regression model outputting numbers between 0 and 1.\",\n",
      "            \"model/duration\": \"It is mentioned that it requires under 1 s for prediction on one protein.\",\n",
      "            \"model/availability\": \"The software and the source code is publicly available through the provided link to the GitHub repository of the software.\\nIt is a stand-alone executable software, they currently have a web server, but at the time of publication the web server was under development.\\nURL: https://github.com/rdk/p2rank\\nLicence: MIT \",\n",
      "            \"dataset/provenance\": \"Training: CHEN11\\u2014a dataset of 251 proteins harboring 476 ligands introduced in LBS prediction benchmarking study.\\n\\nOptimization and validation: JOINED\\u2014consists of structures from several smaller datasets used in previous studies (B48/U48, B210, DT198, ASTEX) joined into one larger dataset. you can find the details below:\\nB48/U48\\u2014Datasets that contain a set of 48 proteins in a bound and unbound state.\\nB210\\u2014a benchmarking dataset of 210 proteins in bound state.\\nDT198\\u2014a dataset of 198 drug-target complexes.\\nASTEX\\u2014Astex Diverse set is a collection of 85 proteins that was introduced as a benchmarking dataset for molecular docking methods.\",\n",
      "            \"dataset/splits\": \"2 data splits were utilized:\\nTraining: CHEN11 dataset composed of 251 data points.\\nOptimization and validation: JOINED dataset composed of an overall  541 data points.\\nAll the data points are positive examples of protein-ligand complexes.\",\n",
      "            \"dataset/redundancy\": \"Datasets for training and validation purposes are selected arbitrarily.\\nTesting dataset is not mentioned.\\nOnly training set is mentioned to be non-redundant without explicit mention on the cutout identity percentage.\",\n",
      "            \"dataset/availability\": \"All the mentioned datasets are selected from previous studies and are publicly available.\\nDatasets are both mentioned through referencing to other studies and accessible through the URL: https://github.com/rdk/p2rank-datasets\",\n",
      "            \"publication/title\": \"P2Rank: machine learning based tool for rapid and accurate prediction of ligand binding sites from protein structure\",\n",
      "            \"publication/authors\": \"Radoslav Kriv\\u00e1k, David Hoksza\",\n",
      "            \"publication/journal\": \"Journal of cheminformatics\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6634f285ded6e7820f74a19a\",\n",
      "        \"shortid\": \"rejm27trh8\",\n",
      "        \"uuid\": \"a2eb5814-8cb1-4c0d-a2aa-96fda79bcc2d\",\n",
      "        \"created\": \"2024-05-03T14:19:49.660Z\",\n",
      "        \"updated\": \"2024-05-03T14:19:49.660Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"29679026\",\n",
      "            \"authors\": \"Jingxue Wang, Huali Cao, John Z. H. Zhang & Yifei Qi \",\n",
      "            \"journal\": \"Scientific Reports\",\n",
      "            \"title\": \"Computational Protein Design with Deep Learning Neural Networks\",\n",
      "            \"doi\": \"10.1038/s41598-018-24760-x\",\n",
      "            \"year\": \"2018\"\n",
      "        },\n",
      "        \"score\": 0.71,\n",
      "        \"matches\": {\n",
      "            \"evaluation/comparison\": \"The model was compared to a similar method called SPIN.\",\n",
      "            \"evaluation/confidence\": \"Standard deviation was reported. The results are not significantly better than the only method that was compared to (SPIN) with 3% improvement.\",\n",
      "            \"evaluation/measure\": \"The authors used the accuracy of top-k predictions from the model as the evaluation metric.\\nTop-K accuracy: if the native amino acid is within the top-K predictions (K amino acids that have the highest probabilities), the prediction is considered correct.\",\n",
      "            \"evaluation/method\": \"1. The model was solely evaluated on 3 proteins that are as follows:\\nAn all-\\u03b1 protein (PDB ID 2B8I60), an all-\\u03b2 protein (PDB ID 1HOE61), and a mixed \\u03b1\\u03b2 protein (PDB ID 2IGD).\\n2. The model was evaluated and compared to another method on a data set of 50 proteins.\",\n",
      "            \"optimization/algorithm\": \"The algorithm used is a classic neural network. \",\n",
      "            \"optimization/encoding\": \"Data was encoded by extracting features from protein residues and their N closest neighboring residues.\",\n",
      "            \"optimization/features\": \"The following input features were reported:\\n1. Cos and sin values of backbone dihedrals\\n2. Total solvent accessible surface area (SASA) of backbone atoms\\n3. Three-type secondary structure\\n4. C\\u03b1-C\\u03b1 distance to the central residue.\\n5. Unit vectors from the central residue to the neighbor residues\\n6. Number of backbone-backbone hydrogen bonds.\",\n",
      "            \"optimization/meta\": \"It is not a meta-predictor.\",\n",
      "            \"optimization/parameters\": \"The following parameters were reported:\\n1. Activation function: ReLU for all layers.\\n2. Loss function: Categorical cross entropy.\\n3. Optimization: SGD with Nesterov momentum (0.9) and learning rate of 0.01.\\n4. Batch size: 40,000.\\n5. Sample weighting: Adjusted based on residue type abundance\\n6. Epochs: 1000\",\n",
      "            \"model/interpretability\": \"No mention on interpretability was made. The model appears to be a black box.\",\n",
      "            \"model/output\": \"Ultimately, it is a classifier method that outputs the potential residue types at a target position based on the probability of 20 amino acids for that specific position.\",\n",
      "            \"dataset/availability\": \"Available from the corresponding author on \\\"reasonable request\\\".\",\n",
      "            \"dataset/provenance\": \"The authors used structures in PDB as the main data source.\\nThey clustered the structures based on different sequence identity thresholds. The resulted structure dataset consists of:\\n10173 (30% sequence identity), 14064 (50% sequence identity), and 17607 structures (90% sequence identity).\",\n",
      "            \"dataset/redundancy\": \"The authors trained their model on 3 redundancy-reduced datasets with 3 different sequence identity thresholds (30%, 50%, and 90%).\",\n",
      "            \"dataset/splits\": \"For training the model, the authors used a random split 5-fold cross-validation.\\nThe proportion of training and test data points used in cross-validation was not reported.\",\n",
      "            \"publication/authors\": \"Jingxue Wang, Huali Cao, John Z. H. Zhang & Yifei Qi \",\n",
      "            \"publication/journal\": \"Scientific Reports\",\n",
      "            \"publication/title\": \"Computational Protein Design with Deep Learning Neural Networks\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6634f47fded6e7820f74a1b0\",\n",
      "        \"shortid\": \"6qvzmhfton\",\n",
      "        \"uuid\": \"8106fd96-ea13-4cb8-84f9-4ac85aba9559\",\n",
      "        \"created\": \"2024-05-03T14:28:15.854Z\",\n",
      "        \"updated\": \"2024-05-03T14:28:15.854Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"30538725\",\n",
      "            \"authors\": \"Qiwan Hu, Mudong Feng, Luhua Lai, Jianfeng Pei\\n\",\n",
      "            \"journal\": \"Frontiers in Genetics\",\n",
      "            \"title\": \"Prediction of Drug-Likeness Using Deep Autoencoder Neural Networks\",\n",
      "            \"doi\": \"10.3389/fgene.2018.00585\",\n",
      "            \"year\": \"2018\"\n",
      "        },\n",
      "        \"score\": 0.71,\n",
      "        \"matches\": {\n",
      "            \"evaluation/comparison\": \"Accuracy was compared to a SVM model built by Li et al (Li et al., 2007).\",\n",
      "            \"evaluation/measure\": \"All models were evaluated by five indexes. The Accuracy, Specificity, Sensitivity, Matthews correlation coefficient (MCC), and area under the receiver operating characteristic curve (AUC).\",\n",
      "            \"evaluation/method\": \"They used a 5 fold cross-validation.\\nThe evaluation was not performed on an independent set.\\n\",\n",
      "            \"optimization/algorithm\": \"Algorithm is an autoencoder neural network.\",\n",
      "            \"optimization/encoding\": \"Authors used 2D descriptors to encode the molecules. Molecules after preprocessing were calculated by MOLD2 (Hong et al., 2008), resulting a descriptor matrix of \\u223c700 descriptors per molecule.\",\n",
      "            \"optimization/features\": \"\\u223c700 descriptors per molecule.\",\n",
      "            \"optimization/fitting\": \"The exact number of parameters not reported. As a strategy against overfitting, authors tried to optimized the weight of the positive and negative sample loss of the logarithmic likelihood loss function.\",\n",
      "            \"optimization/meta\": \"It is not a meta-predictor.\",\n",
      "            \"optimization/parameters\": \"Reported table of the hyperparameters:\\nInitializer = TruncatedNormal\\nNumber of hidden layers = 1\\nNumber of hidden layer nodes = 512\\nL2 Normalization term = 1e-4\\nDropout rate = 0.14\\nActivation = Relu\\nBatch size = 128\\nOptimizer = Adam\\nLoss = mse for AE, binary crossentropy for classifier\",\n",
      "            \"optimization/regularization\": \"As a strategy against overfitting, authors tried to optimized the weight of the positive and negative sample loss of the logarithmic likelihood loss function. They also used early stopping based on classification ACC on the \\\"test\\\" set.\",\n",
      "            \"model/interpretability\": \"No mention on interoperability. It appears to be a black box.\",\n",
      "            \"model/output\": \"It is a classifier model.\",\n",
      "            \"dataset/provenance\": \"3 manually built dataset pairs were used by authors to construct prediction models for drug-likeness.\\nDataset pair | Number of positive | Number of negative | Total\\nWDI/ACD | 38,260 | 288,540 | 326,800\\nMDDR/ZINC | 171,850 | 199,220 | 371,070\\nWORLDDRUG/ZINC | 3,380 | 199,220 | 202,600\\n\\nMDDR (MACCS-II Drug Data Report [MDDR], 2004), WDI (Li et al., 2007), ACD (Li et al., 2007), ZINC (Irwin et al., 2012; Sterling and Irwin, 2015), ZINC WORLD DRUG (Sterling and Irwin, 2015)\",\n",
      "            \"dataset/redundancy\": \"Authors randomly split the datasets.\\nThe training and test sets are not independent.\\nThey removed the duplicates appearing in both sets.\\n\",\n",
      "            \"dataset/splits\": \"Authors randomly split the datasets on the proportion of 9:1 as training set and \\\"validation\\\" (apparently used as the test set).\\nNo mention on stratified sampling to ensure the same distribution of positive and negative classes in the splits.\",\n",
      "            \"publication/authors\": \"Qiwan Hu, Mudong Feng, Luhua Lai, Jianfeng Pei\\n\",\n",
      "            \"publication/journal\": \"Frontiers in Genetics\",\n",
      "            \"publication/title\": \"Prediction of Drug-Likeness Using Deep Autoencoder Neural Networks\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6638a2f7b30933003cc215b9\",\n",
      "        \"shortid\": \"toe45v1h7a\",\n",
      "        \"uuid\": \"71898e53-9df0-464d-9e78-bb95274221ec\",\n",
      "        \"created\": \"2024-05-06T09:29:27.218Z\",\n",
      "        \"updated\": \"2024-05-06T09:29:27.218Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"30109435\",\n",
      "            \"authors\": \"Radoslav Kriv\\u00e1k, David Hoksza\",\n",
      "            \"journal\": \"Journal of cheminformatics\",\n",
      "            \"title\": \"P2Rank: machine learning based tool for rapid and accurate prediction of ligand binding sites from protein structure\",\n",
      "            \"doi\": \"10.1186/s13321-018-0285-8\",\n",
      "            \"year\": \"2018\"\n",
      "        },\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"optimization/algorithm\": \"The used algorithm is a Random Forest Regression model.\\nThe model is not novel.\",\n",
      "            \"optimization/config\": \"URL: https://github.com/rdk/p2rank. Licence: MIT\",\n",
      "            \"optimization/encoding\": \"The model takes vectors of 35 numerical features as input.\",\n",
      "            \"optimization/features\": \"Every vector is composed of 35 numerical features.\\nNo mention on feature selection.\",\n",
      "            \"optimization/fitting\": \"The clear number of parameters is not mentioned. No assessment on over/under fitting was mentioned.\",\n",
      "            \"optimization/meta\": \"The algorithm is not a meta-predictor.\",\n",
      "            \"optimization/parameters\": \"Beside the hyper-parameters of Random Forest, the algorithm uses other parameters and \\\"cut-of's\\\", thresholds\\\", \\\"protrusion radius\\\", are explicitly mentioned.\\nIt is mentioned that only hyper-parameters are optimized on a separate dataset from training set.\\nThe method of optimization is not mentioned.\",\n",
      "            \"optimization/regularization\": \"A validation set was used to optimize the parameters before training on the training set.\",\n",
      "            \"model/availability\": \"The software and the source code is publicly available through the provided link to the GitHub repository of the software. It is a stand-alone executable software, they currently have a web server, but at the time of publication the web server was under development. URL: https://github.com/rdk/p2rank. Licence: MIT\",\n",
      "            \"model/duration\": \"It is mentioned that it requires under 1 s for prediction on one protein.\",\n",
      "            \"model/interpretability\": \"The model has 200 trees, each grown with no depth limit using 6 features, this makes it challenging to interpret due to the sheer number of trees and their depth. However, it is still possible to obtain feature importance scores.\",\n",
      "            \"model/output\": \"It is a regression model outputting numbers between 0 and 1.\",\n",
      "            \"dataset/availability\": \"All the mentioned datasets are selected from previous studies and are publicly available.\\nDatasets are both mentioned through referencing to other studies and accessible through the URL: https://github.com/rdk/p2rank-datasets\",\n",
      "            \"dataset/provenance\": \"Training:  CHEN11\\u2014a dataset of 251 proteins harboring 476 ligands introduced in LBS prediction benchmarking study.\\nOptimization and validation: JOINED\\u2014consists of structures from several smaller datasets used in previous studies (B48/U48, B210, DT198, ASTEX) joined into one larger dataset. you can find the details below:\\nB48/U48\\u2014Datasets that contain a set of 48 proteins in a bound and unbound state.\\nB210\\u2014a benchmarking dataset of 210 proteins in bound state.\\nDT198\\u2014a dataset of 198 drug-target complexes.\\nASTEX\\u2014Astex Diverse set is a collection of 85 proteins that was introduced as a benchmarking dataset for molecular docking methods.\",\n",
      "            \"dataset/redundancy\": \"Datasets for training and validation purposes are selected arbitrarily.\\nTesting dataset is not mentioned.\\nOnly training set is mentioned to be non-redundant without explicit mention on the cutout identity percentage.\",\n",
      "            \"dataset/splits\": \"2 data splits were utilized:\\nTraining: CHEN11 dataset composed of 251 data points.\\nOptimization and validation: JOINED dataset composed of an overall  541 data points.\\nAll the data points are positive examples of protein-ligand complexes.\",\n",
      "            \"publication/authors\": \"Radoslav Kriv\\u00e1k, David Hoksza\",\n",
      "            \"publication/journal\": \"Journal of cheminformatics\",\n",
      "            \"publication/title\": \"P2Rank: machine learning based tool for rapid and accurate prediction of ligand binding sites from protein structure\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"664b2a75b30933003cc2184b\",\n",
      "        \"shortid\": \"2g7fzlkala\",\n",
      "        \"uuid\": \"4fb79024-ab54-4e22-889b-73335801c3bc\",\n",
      "        \"created\": \"2024-05-20T10:48:21.402Z\",\n",
      "        \"updated\": \"2024-05-20T10:48:21.402Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"28527154\",\n",
      "            \"authors\": \"Jain S, Grandits M, Richter L, Ecker GF. \",\n",
      "            \"journal\": \"Journal of Computer-Aided Molecular Design\",\n",
      "            \"title\": \"Structure based classification for bile salt export pump (BSEP) inhibitors using comparative structural modeling of human BSEP\",\n",
      "            \"doi\": \"10.1007/s10822-017-0021-x\",\n",
      "            \"year\": \"2018\"\n",
      "        },\n",
      "        \"score\": 1,\n",
      "        \"matches\": {\n",
      "            \"evaluation/availability\": \"Not available.\",\n",
      "            \"evaluation/comparison\": \"A comparison between the present structure-based models to a previous published method, by the same research group, that applied ligand-based models, was performed.  A comparison to a model, obtained using the scoring probability functions only, was performed. \",\n",
      "            \"evaluation/confidence\": \"No confidence intervals of performance metrics are given.\",\n",
      "            \"evaluation/measure\": \"Sensitivity, specificity, accuracy, G-mean, Matthews Correlation Coefficient, AUC-ROC.\",\n",
      "            \"evaluation/method\": \"Two independent test sets were used, containing 166 compounds (44 inhibitors and 122 noninhibitors), and 638 compounds (248 inhibitors and 390 non-inhibitors), respectively.  The first set was taken from the work of Pedersen JM, et al (2013) Toxicol Sci 136:328\\u2013343.  The second dataset (unpublished) was provided by AstraZeneca within the framework of the IMI project eTOX. (http://www.etoxproject.eu). Both studies provide in vitro inhibition data on human BSEP.\",\n",
      "            \"optimization/algorithm\": \"The open source software WEKA (version 3.7.10) was used for building binary classification models. The standard machine learning classifiers, J48, Random Forest, REPTree, LibSVM, and Naive Bayes, were used with the default parameters along with tenfold internal cross-validation.\",\n",
      "            \"optimization/config\": \"Not available.\",\n",
      "            \"optimization/encoding\": \"The initial dataset was curated according to the following steps: (1) removal of inorganic compounds using Instant JChem v.5.3, 2010, ChemAxon (http://www.chemaxon.com); (2) analysis and removal of mixtures formed by two or more large molecules; (3) deletion of organometallic compounds using MOE 2011.10 15; (4) identification and removal of compounds containing special atoms such as selenium or tellurium by means of an in-house MOE SVL script; (5) normalization of chemotypes using the ChemAxon\\u2019s Standardizer with the following settings: clean 2D, aromatize, mesomerize, neutralize, tautomerize and all transform options; (6) identification and elimination of nonunique structures using MOE; (7) deletion of compounds having permanent charges.    Different docking runs (using the docking software GOLD) and docking fitness functions were applied to the preprocessed training set.  Prior probability distributions for the inhibitor and non-inhibitor classes were calculated.\",\n",
      "            \"optimization/features\": \"The input for the set of the 5 ML models was a combination of the Xscore(ChemScore) scoring function, obtained by the GOLD docking runs, combined with physicochemical properties as descriptors for the training set. The physicochemical properties were MW (Molecular Weight) and log(P) (where P is the octanol-water partition coefficient of the compound).   No feature selection is mentioned.\",\n",
      "            \"optimization/fitting\": \"The standard number of parameters in the applied classifiers was much lower than the training points.  The possibility of under-fitting was not mentioned.\",\n",
      "            \"optimization/parameters\": \"The standard parameters in WEKA for the 5 chosen classifiers were used.  Their number is in the order of less than a dozen for each classifier. \",\n",
      "            \"optimization/regularization\": \"Not mentioned in text.\",\n",
      "            \"model/availability\": \"The open source software WEKA (version 3.7.10) was used.\",\n",
      "            \"model/duration\": \"Not reported.\\n\",\n",
      "            \"model/interpretability\": \"The input features were relatively transparent, being based on the quality of the docking poses and on two main reasonable physicochemical properties of the compounds.  The addition of the latters did improve the performance, which was in agreement with expectation.\",\n",
      "            \"model/output\": \"Binary classification (BSEP inhibitor or non-inhibitor).  \",\n",
      "            \"dataset/availability\": \"The training dataset has been taken from a cited publication (Warner DJ, et al (2012) Drug Metab Dispos Biol Fate Chem 40:2332\\u20132341), which however was not accessible without a fee.  One of the test sets in published, in the unprocessed form, in Pedersen JM, et al (2013) Toxicol Sci 136:328\\u2013343.\",\n",
      "            \"dataset/provenance\": \"The training dataset comprised 408 compounds:113 BSEP (bile salt export pump) inhibitors and 295 non-inhibitors, derived from a previous publication (Warner DJ, et al (2012) Drug Metab Dispos Biol Fate Chem 40:2332\\u20132341\",\n",
      "            \"dataset/redundancy\": \"A chemical space network (CSN) was constructed and analyzed in order to assess the structural similarity shared by the compounds of the inhibitor and non-inhibitor groups.  The majority of the nodes did not have a connection, indicating a high structural diversity in the training dataset.  A similar analysis showed a high structural diversity also for one of the test sets.\",\n",
      "            \"dataset/splits\": \"For all model, tenfold internal cross-validation was applied.  Distribution of data point in the splits is not reported.\",\n",
      "            \"publication/authors\": \"Jain S, Grandits M, Richter L, Ecker GF. \",\n",
      "            \"publication/journal\": \"Journal of Computer-Aided Molecular Design\",\n",
      "            \"publication/title\": \"Structure based classification for bile salt export pump (BSEP) inhibitors using comparative structural modeling of human BSEP\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b1e\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"31137222\",\n",
      "            \"updated\": \"03/18/2022 14:48:58\",\n",
      "            \"authors\": \"Tan JX, Li SH, Zhang ZM, Chen CX, Chen W, Tang H, Lin H\",\n",
      "            \"journal\": \"Math Biosci Eng\",\n",
      "            \"title\": \"Identification of hormone binding proteins based on machine learning methods.\",\n",
      "            \"doi\": \"10.3934/mbe.2019123\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"79228609-a725-4ad4-a390-21d4cfe00670\",\n",
      "        \"shortid\": \"rggiypqqgz\",\n",
      "        \"score\": 0.57,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/18/2022 14:48:58\",\n",
      "            \"publication/authors\": \"Tan JX, Li SH, Zhang ZM, Chen CX, Chen W, Tang H, Lin H\",\n",
      "            \"publication/journal\": \"Math Biosci Eng\",\n",
      "            \"publication/title\": \"Identification of hormone binding proteins based on machine learning methods.\",\n",
      "            \"optimization/algorithm\": \"Support vector machine (SVM) \",\n",
      "            \"optimization/encoding\": \"Global features. Gene Expression Profile\",\n",
      "            \"optimization/features\": \"The optimized method uses expression from 66 selected genes. The expression profile genes (genes nr = 16032) were first ranked by feature importance (gene expression) via the minimum redundancy maximum relevancy (mRMR) method, getting down to 500 genes. Subsequently, a SVM classifier was used to screen the optimal feature genes by the incremental feature selection (IFS) method. Optimal genes were selected maximizing the the MCC obtained with a Leave-One-Out Cross-Validation procedure on training set.\",\n",
      "            \"optimization/fitting\": \"not reported   The number of features were reduced to 66 by the feature selection algorithms, which however could have induce over-fitting by themselves.\",\n",
      "            \"optimization/regularization\": \"No. not reported how the regularization parameter in SVM was tuned.\",\n",
      "            \"model/interpretability\": \"Black box. PCA and GO-Term enrichment analysis on 66 selected genes shows an association with ribosomal protein-encoding, viral protein translation, and protein-membrane location.\",\n",
      "            \"model/output\": \"Classification (Covid swab positive or negative)\",\n",
      "            \"evaluation/method\": \"Leave-One-Out Cross-validation\",\n",
      "            \"dataset/availability\": \"Yes (GEO: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE152075)\",\n",
      "            \"dataset/provenance\": \"Data source:  Gene expression profiles from NCBI/GEO GSE152075.  Data points: 484 individuals.  N_pos (swabs Covid positive)= 430, N_neg (swabs Covid negative)= 34.  Used by at least one previous paper (PMID: 32898168).   \",\n",
      "            \"dataset/splits\": \"Due to sample imbalance, the python package imblearn was used to amplify the number of small samples to the same as that of large samples.  \"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b1f\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"30615300\",\n",
      "            \"updated\": \"03/21/2022 10:33:58\",\n",
      "            \"authors\": \"Plant D, Maciejewski M, Smith S, Nair N, Maximising Therapeutic Utility in Rheumatoid Arthritis Consortium, the RAMS Study Group., Hyrich K, Ziemek D, Barton A, Verstappen S\",\n",
      "            \"journal\": \"Arthritis Rheumatol\",\n",
      "            \"title\": \"Profiling of Gene Expression Biomarkers as a Classifier of Methotrexate Nonresponse in Patients With Rheumatoid Arthritis.\",\n",
      "            \"doi\": \"10.1002/art.40810\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"1b20e970-8ffe-4825-aebd-9e1d924a6d06\",\n",
      "        \"shortid\": \"r4ntb0iqha\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/21/2022 10:33:58\",\n",
      "            \"publication/authors\": \"Plant D, Maciejewski M, Smith S, Nair N, Maximising Therapeutic Utility in Rheumatoid Arthritis Consortium, the RAMS Study Group., Hyrich K, Ziemek D, Barton A, Verstappen S\",\n",
      "            \"publication/journal\": \"Arthritis Rheumatol\",\n",
      "            \"publication/title\": \"Profiling of Gene Expression Biomarkers as a Classifier of Methotrexate Nonresponse in Patients With Rheumatoid Arthritis.\",\n",
      "            \"optimization/algorithm\": \"composite model  with several stepp with different classification algorithms (hclust, K-means, mclust, Random Forest)\",\n",
      "            \"optimization/encoding\": \"global features (Rnot reported-Seq, Flow cytometry)\",\n",
      "            \"optimization/features\": \"features selection by Boruta algorithm ( 10.18637/jss.v036.i11 )\",\n",
      "            \"optimization/parameters\": \"Molecular subgroups discovery:\\n - Step 1: Unsupervised gene selection,\\n - Step 2: Robust consensus clustering (hclust, K-means, mclust)\\n - Step 3: Identification of molecular signature (one-way ANOVA and Random Forest),\\n - Step 4: Robustness classification\\n - Step 5: Classification of discordant patients\\n-> definition of 4 cluster\\n\\nComposite model for cluster prediction:\\n#1 xgboost-tree: predict C4 vs all\\n#2 multi-classification:  C1, C2, or C3\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/measure\": \"Accuracy (94.81% for the C4 prediction model, and 96.72% for the multi-classification model.)\",\n",
      "            \"evaluation/method\": \"independent dataset\",\n",
      "            \"dataset/availability\": \"All data included in this study is available upon request at ELIXIR Luxemburg ( https://doi.org/10.17881/th9v-xt85 )\",\n",
      "            \"dataset/provenance\": \"Clinical data collected by the authors\\nN_neg 330, N_pos 304\",\n",
      "            \"dataset/splits\": \"N_pos:\\nDiscovery 227 and Validation 77\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b20\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"30819107\",\n",
      "            \"updated\": \"03/23/2022 10:25:57\",\n",
      "            \"authors\": \"Vinogradova S, Saksena SD, Ward HN, Vigneau S, Gimelbrant AA\",\n",
      "            \"journal\": \"BMC Bioinformatics\",\n",
      "            \"title\": \"MaGIC: a machine learning tool set and web application for monoallelic gene inference from chromatin.\",\n",
      "            \"doi\": \"10.1186/s12859-019-2679-7\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"d70f673b-b310-4054-9672-a93679f1d817\",\n",
      "        \"shortid\": \"htsvoi90ft\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/23/2022 10:25:57\",\n",
      "            \"publication/authors\": \"Vinogradova S, Saksena SD, Ward HN, Vigneau S, Gimelbrant AA\",\n",
      "            \"publication/journal\": \"BMC Bioinformatics\",\n",
      "            \"publication/title\": \"MaGIC: a machine learning tool set and web application for monoallelic gene inference from chromatin.\",\n",
      "            \"optimization/algorithm\": \"the models included lasso and ridge based on linear relationships [14], support vector machine using kernel methods [15], tree-based random forest [16], and Xgboost\",\n",
      "            \"optimization/config\": \"yes, SI\",\n",
      "            \"optimization/encoding\": \"Dimension reduction was performed to avoid the \\u201ccurse of dimensionality\\u201d caused by a large number of variables compared with the size of the data. \",\n",
      "            \"optimization/features\": \"Among the 64 variables, we selected variables that are frequently encountered in clinical practice for prescription of biologics and excluded variables that are not referenced when prescribing biologics. As a result, 15 variables known to be of clinical importance were preselected (i.e., sex, age, baseline DAS28-ESR, methotrexate dose, steroid dose, erythrocyte sedimentation rate [ESR], C-reactive protein [CRP], rheumatoid factor [RF], anti-cyclic citrullinated peptide antibody [ACPA], anti-nuclear antibody [Anot reported], and five comorbidities). Subsequently, 20 variables that were highly correlated with the drug response (remission) of each bDMARD were selected. After selecting variables based on data, we created a prediction model by training with a fixed set of 35 variables. Missing data for variables (Additional file: Table S3) were replaced with the median value for each variable. With a similar logic, binary variables such as comorbidities were coded as 1 if \\u201cyes\\u201d and 0 if \\u201cno\\u201d or \\u201cno test\\u201d because \\u201cno\\u201d was the most common value.\",\n",
      "            \"optimization/fitting\": \"To avoid overfitting problems, the training and test sets were divided in a 7:3 ratio, and the models were trained with the training set; then, the prediction results were verified using the test set. For the training dataset, a 5-fold cross validation was performed to tune the hyperparameters determined as outside models (Additional file: Table S1 and Table S2). In this procedure, a grid search was conducted to evaluate all possible combinations of the hyperparameters. The grid search found optimal hyperparameters with the objective function of determining the area under the receiver operating characteristics (AUROC) in each model. Bootstrapping (random sampling with replacement) was also performed to obtain a median value for the AUROC curve and to determine the accuracy for reducing measurement variances caused by small samples when dividing between the training and test sets.\",\n",
      "            \"optimization/parameters\": \"a grid search was conducted to evaluate all possible combinations of the hyperparameters. The grid search found optimal hyperparameters with the objective function of determining the area under the receiver operating characteristics (AUROC) in each model\",\n",
      "            \"evaluation/comparison\": \"The no information rate, which is the largest proportion of the observed classes, was used as a baseline to determine the overall distribution of the classification and to compare with those of the machine learning models\",\n",
      "            \"evaluation/measure\": \"Bootstrapping (random sampling with replacement) was also performed to obtain a median value for the AUROC curve and to determine the accuracy for reducing measurement variances caused by small samples when dividing between the training and test sets.\",\n",
      "            \"dataset/availability\": \"Yes, Data are available from the Clinical Research Committee of KOBIO under the Korean College of Rheumatology for researchers who meet the criteria for access to confidential data\",\n",
      "            \"dataset/provenance\": \"This study used data from the KOBIO registry, which is a nationwide multicenter cohort in Korea that was established to evaluate the effectiveness and side effects of biologic therapies in patients with RA [13]. Patients in the registry were recruited from 38 hospitals since 2012, and their demographics, medications, comorbidities, extra-articular manifestations, disease activities, radiographic findings, and laboratory findings performed within 4 weeks prior to the patient\\u2019s visit were recorded with the date. The data from patients who were followed up annually were recorded on the KOBIO website (http://www.kobio.or.kr/kobio/), and these patients provided informed consent prior to registration. Ethical approval of the KOBIO-RA was obtained from the institutional review boards of all 38 participating institutions, including the Institutional Review Board of Inje University Seoul Paik Hospital (PAIK 2018-11-005).\",\n",
      "            \"dataset/splits\": \" the training and test sets were divided in a 7:3 ratio, and the models were trained with the training set\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b21\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"31058230\",\n",
      "            \"updated\": \"03/27/2022 14:51:24\",\n",
      "            \"authors\": \"Tripathi A, Xu ZZ, Xue J, Poulsen O, Gonzalez A, Humphrey G, Meehan MJ, Melnik AV, Ackermann G, Zhou D, Malhotra A, Haddad GG, Dorrestein PC, Knight R\",\n",
      "            \"journal\": \"mSystems\",\n",
      "            \"title\": \"Intermittent Hypoxia and Hypercapnia Reproducibly Change the Gut Microbiome and Metabolome across Rodent Model Systems.\",\n",
      "            \"doi\": \"10.1128/mSystems.00058-19\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"dd72ec96-8461-42d7-887c-700c90446755\",\n",
      "        \"shortid\": \"hk4hhg2svs\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/27/2022 14:51:24\",\n",
      "            \"publication/authors\": \"Tripathi A, Xu ZZ, Xue J, Poulsen O, Gonzalez A, Humphrey G, Meehan MJ, Melnik AV, Ackermann G, Zhou D, Malhotra A, Haddad GG, Dorrestein PC, Knight R\",\n",
      "            \"publication/title\": \"Intermittent Hypoxia and Hypercapnia Reproducibly Change the Gut Microbiome and Metabolome across Rodent Model Systems.\",\n",
      "            \"optimization/algorithm\": \"Linear Support Vector Classification\",\n",
      "            \"optimization/config\": \"Supplementary Information\",\n",
      "            \"optimization/encoding\": \"One-hot encoding as vectors\",\n",
      "            \"optimization/features\": \"Not defined, 1396 * number of genotypes\",\n",
      "            \"optimization/parameters\": \"not reported, multiple supervised ML methods were used with scikit-learn\",\n",
      "            \"model/availability\": \"https://github.com/jlanga/smsk_popoolation, MIT License\",\n",
      "            \"evaluation/availability\": \"Supporting information\",\n",
      "            \"evaluation/comparison\": \"Multiple supervised methods were compared, best method selection based on average accuracy.\",\n",
      "            \"dataset/availability\": \"Additional file 1, https://www.ncbi.nlm.nih.gov/sra/?term=PRJnot reported666033\",\n",
      "            \"dataset/provenance\": \"Custom sampling of 22 populations of honey bee in Europe and adjacent regions, total 2145 samples leading to 1.6 billion paired-end fragments. 1998 remained after removal of 62 outliers.\",\n",
      "            \"dataset/redundancy\": \"Selection of SNPs (Single Nucleotide Polymorphisms), originally 4400 selected, 4165 after QC check. 4094 SNPs were genotyped (71 failed base calling).\",\n",
      "            \"dataset/splits\": \"Training: 1391 samples (70% of 1998),  597 (30% of 1998) and 2505 independent samples (out-of-sample with known bee subspecies classification) for validation.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b22\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"30853547\",\n",
      "            \"updated\": \"03/28/2022 11:30:10\",\n",
      "            \"authors\": \"Chung NC, Mirza B, Choi H, Wang J, Wang D, Ping P, Wang W\",\n",
      "            \"journal\": \"Methods\",\n",
      "            \"title\": \"Unsupervised classification of multi-omics data during cardiac remodeling using deep learning.\",\n",
      "            \"doi\": \"10.1016/j.ymeth.2019.03.004\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"84fcc9b6-a284-4d43-8940-fee068877b2f\",\n",
      "        \"shortid\": \"3hsc5woplt\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/28/2022 11:30:10\",\n",
      "            \"publication/authors\": \"Chung NC, Mirza B, Choi H, Wang J, Wang D, Ping P, Wang W\",\n",
      "            \"publication/title\": \"Unsupervised classification of multi-omics data during cardiac remodeling using deep learning.\",\n",
      "            \"optimization/algorithm\": \"gradient boosted decision trees and random forests\",\n",
      "            \"optimization/parameters\": \"Python version 3.6.8,\\ngradient boosted decision trees: LightGBM v2.2.3\\nRF: scikit-learn v0.20.2\",\n",
      "            \"optimization/regularization\": \"\\\"The models were not retrained using SRM data to avoid overfitting and overestimating test performance. In addition, within the training set, cross-validation was used to develop the models to avoid overfitting to the training set.\\\"\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/availability\": \"yes, https://github.com/stanfordmlgroup/influenza-qtof/tree/master/data\",\n",
      "            \"evaluation/comparison\": \"costeffective comare to PCR tests and could be performed at the point-of-care comapre to RT-PCR test, no other methods for direct omparisonc\",\n",
      "            \"evaluation/measure\": \"AUC, sensitivity, specificity\",\n",
      "            \"evaluation/method\": \"novel experiments.\",\n",
      "            \"dataset/availability\": \"Conatact (hoganca@stanford.edu) is provided right the beggining of the \\\"Methods\\\" section of the papaer for further information and requests.\\n\\nThe data and code generated during this study were made available at https://github.com/stanfordmlgroup/influenza-qtof.\",\n",
      "            \"dataset/provenance\": \"samples from Stanford Health Care and Stanford Children\\u2019s Health,\\n1:1 ratio of positive to age and sex-matched negative controls.\\n\\nData collection was performed after the reference test (RT-PCR) and before the index test (metabolomics).\\nDiscovery cohort (from April 23 2015 to October 13 2019):  118 samples, N_neg 118 samples\\nvalidation cohort (December 21 2019 to February 18 2020): N_pos 48 samples, N_neg 48 samples\",\n",
      "            \"dataset/splits\": \"The final analysis included for discovery cohort:\\ntraining set:  94 positive, 92 negative\\ntest set: 24 positive, 26 negative\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b2c\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"31407406\",\n",
      "            \"updated\": \"02/10/2022 16:35:16\",\n",
      "            \"authors\": \"Li Y, Zhang C, Bell EW, Yu DJ, Zhang Y\",\n",
      "            \"journal\": \"Proteins\",\n",
      "            \"title\": \"Ensembling multiple raw coevolutionary features with deep residual neural networks for contact-map prediction in CASP13.\",\n",
      "            \"doi\": \"10.1002/prot.25798\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"14a845e7-557b-486b-8b10-d636b8a1c8f2\",\n",
      "        \"shortid\": \"0zyckt3df0\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/10/2022 16:35:16\",\n",
      "            \"publication/authors\": \"Li Y, Zhang C, Bell EW, Yu DJ, Zhang Y\",\n",
      "            \"publication/title\": \"Ensembling multiple raw coevolutionary features with deep residual neural networks for contact-map prediction in CASP13.\",\n",
      "            \"optimization/algorithm\": \"Weka platform used,  naive bases, logistic regression and random forests.  Only the latter is shown given its better performance. \",\n",
      "            \"optimization/encoding\": \"Not discussed explicitly.  metabolic data per patient was used,\",\n",
      "            \"optimization/features\": \"mass spectrum data is used.   Either focussing on a specific subset fo know compounds or the full VOC data (requiring extensive feature selection , see Fig2 of paper)\",\n",
      "            \"optimization/meta\": \"no \",\n",
      "            \"optimization/parameters\": \"Not detailed what the parameters were for the random forest. \",\n",
      "            \"optimization/regularization\": \"Thorough feature selection procedure (wrapper based) and two step cross-validation (10-fol)\",\n",
      "            \"model/interpretability\": \"No analysis provided\",\n",
      "            \"model/output\": \"classification (Ca+ vs HC, CA- vs HC and Ca+ vs Ca-)\",\n",
      "            \"evaluation/comparison\": \"focus on RF as performance of others is low (obvious for NB and regression)\",\n",
      "            \"evaluation/measure\": \"AUC and accuracry\",\n",
      "            \"dataset/availability\": \"previous publication gives some data but not the raw data\",\n",
      "            \"dataset/provenance\": \"Data comes from a previous paper : Koureas, Michalis, et al. \\\"Target analysis of volatile organic compounds in exhaled breath for lung cancer discrimination from other pulmonary diseases and healthy persons.\\\" Metabolites 10.8 (2020): 317. 85 patients (49Ca+ and 36 Ca-) and 52 control group individuals.\",\n",
      "            \"dataset/redundancy\": \"No mentioned how stratification is done in the cross-validation procedure.  Feature elimination is performed\",\n",
      "            \"dataset/splits\": \"No split in training/test /validation.  The splitting is done within a 10-fold cross-validation procedure. Three classes are possible, and predictors are designed for pairs of classes. \"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b2d\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"31462106\",\n",
      "            \"updated\": \"04/06/2022 18:58:39\",\n",
      "            \"authors\": \"Cicaloni V, Spiga O, Dimitri GM, Maiocchi R, Millucci L, Giustarini D, Bernardini G, Bernini A, Marzocchi B, Braconi D, Santucci A\",\n",
      "            \"journal\": \"FASEB J\",\n",
      "            \"title\": \"Interactive alkaptonuria database: investigating clinical data to improve patient care in a rare disease.\",\n",
      "            \"doi\": \"10.1096/fj.201901529R\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"488264e6-f952-472e-add0-e6d8fd6f5d1d\",\n",
      "        \"shortid\": \"2ee7tbw9bc\",\n",
      "        \"score\": 0.9,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"04/06/2022 18:58:39\",\n",
      "            \"publication/authors\": \"Cicaloni V, Spiga O, Dimitri GM, Maiocchi R, Millucci L, Giustarini D, Bernardini G, Bernini A, Marzocchi B, Braconi D, Santucci A\",\n",
      "            \"publication/journal\": \"FASEB J\",\n",
      "            \"publication/title\": \"Interactive alkaptonuria database: investigating clinical data to improve patient care in a rare disease.\",\n",
      "            \"optimization/algorithm\": \"CNN, explained in Methods and figure in SI. Predicts a value between 0 and 1 for each of the three classes: inclusion, exclusion and unchanged. Aim is to predict splicing size changes (including no change) after BPN15477 treatment.\",\n",
      "            \"optimization/config\": \"Code is available on GitHub (haven't checked it)\",\n",
      "            \"optimization/encoding\": \"Onehot encoding of concatenated triplets of 3 exons (details see paper)\",\n",
      "            \"optimization/features\": \"400x4 matrix for each exon triplet. No feature selection performed\",\n",
      "            \"optimization/fitting\": \"used L-1 regularisation to avoid overfitting (coefficient =0.6) in the convolutional layer and dropout strategy im the hidden layer\",\n",
      "            \"optimization/meta\": \"No data from other predictors is used\",\n",
      "            \"optimization/parameters\": \"Huge number of network parameters (2.5 million trainable parameters as mentioned by the authors). \",\n",
      "            \"optimization/regularization\": \"Overfitting limited through limitation on number of training epochs (12th epoch).  Comparison to 1000 other models with same structure using different random initialisations.  Evaluations done on separate validation and test sets\",\n",
      "            \"model/availability\": \"via GitHub\",\n",
      "            \"model/interpretability\": \"Method is black box but they provide an exhaustive evaluation of the predictions (compared to 1000 other models) and performed an analysis of the data, through other methods and experiments.\",\n",
      "            \"model/output\": \"classification (values between 0 and 1 for each class)\",\n",
      "            \"evaluation/comparison\": \"not relevant for this work,\",\n",
      "            \"evaluation/confidence\": \"Provided in detail (see statistical analysis section)\",\n",
      "            \"evaluation/measure\": \"AUC and precision recall\",\n",
      "            \"evaluation/method\": \"Data split in training, validation and testing. Experimental verification of predictions.\",\n",
      "            \"dataset/availability\": \"Data is provided as supplementary information (supplementary data 1) and via GEO\",\n",
      "            \"dataset/provenance\": \"Rnot reported-seq data produced by the authors. The set includes 934 exon triplets responding to a BPN15477b treatment. 245 with increased exon inclusion and 680 with increased exclusion. They added 382 exon triplets which did not trigger a response (negative set). Data is used for a three-class predictor. \",\n",
      "            \"dataset/redundancy\": \"No stratification wa reported\",\n",
      "            \"dataset/splits\": \"Data divided in training (178 inclusion responded, 478 exclusion responded and 268 unchanged), validation (51inclusion responded, 136 exclusion responded and 76 unchanged) and test set (25 inclusion responded, 68 exclusion responded and 38 unchanged). the data is split randomly over these 3 sets. \"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b2e\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"31176619\",\n",
      "            \"updated\": \"06/23/2022 03:07:23\",\n",
      "            \"authors\": \"Zeng H, Gifford DK\",\n",
      "            \"journal\": \"Cell Syst\",\n",
      "            \"title\": \"Quantification of Uncertainty in Peptide-MHC Binding Prediction Improves High-Affinity Peptide Selection for Therapeutic Design.\",\n",
      "            \"doi\": \"10.1016/j.cels.2019.05.004\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"9f2653e6-d8fb-455a-ac07-31ffd86fbf52\",\n",
      "        \"shortid\": \"1de6o2bxxv\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"06/23/2022 03:07:23\",\n",
      "            \"publication/authors\": \"Zeng H, Gifford DK\",\n",
      "            \"publication/journal\": \"Cell Syst\",\n",
      "            \"publication/title\": \"Quantification of Uncertainty in Peptide-MHC Binding Prediction Improves High-Affinity Peptide Selection for Therapeutic Design.\",\n",
      "            \"optimization/algorithm\": \"\\\"44 different types of ML classification algorithms available in WEKA (v3.8.2)\\\"\",\n",
      "            \"optimization/config\": \"Partially in the supplement: http://14.139.62.220/covidprognosis/supple.php\",\n",
      "            \"optimization/encoding\": \"global features\",\n",
      "            \"optimization/parameters\": \"no details provided, but p varies based on the models\",\n",
      "            \"optimization/regularization\": \"no details provided\",\n",
      "            \"model/availability\": \"only on the web: http://14.139.62.220/covidprognosis/\",\n",
      "            \"model/interpretability\": \"transparent: identification of proteins associated with labels based on feature selection methods in WEKA\",\n",
      "            \"model/output\": \"possibly both depending on the model\",\n",
      "            \"evaluation/availability\": \"Confusion matrices in the supplement: http://14.139.62.220/covidprognosis/supple.php\",\n",
      "            \"evaluation/comparison\": \"None, only the 44 different models used in the study were compared\",\n",
      "            \"evaluation/measure\": \"MCC, Accuracy, Sensitivity, Specificity, area under ROC\",\n",
      "            \"dataset/availability\": \"yes: https://www.olink.com/application/mgh-covid-19-study/ upon request\",\n",
      "            \"dataset/provenance\": \"clinical and normalized protein expression profile data for 306 COVID-19 patients and 78 other patients (control) from the Olink website; 42 pos and 264 neg\",\n",
      "            \"dataset/redundancy\": \"Not commented\",\n",
      "            \"dataset/splits\": \"only LOOCV was used\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b49\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"31132080\",\n",
      "            \"updated\": \"01/20/2022 15:22:27\",\n",
      "            \"authors\": \"Bernacki DT, Bryce SM, Bemis JC, Dertinger SD\",\n",
      "            \"journal\": \"Toxicol Sci\",\n",
      "            \"title\": \"Aneugen Molecular Mechanism Assay: Proof-of-Concept With 27 Reference Chemicals.\",\n",
      "            \"doi\": \"10.1093/toxsci/kfz123\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"f0595a6e-043d-4fb6-8569-dbdf82e84558\",\n",
      "        \"shortid\": \"l0wznwpm1x\",\n",
      "        \"score\": 0.33,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"01/20/2022 15:22:27\",\n",
      "            \"publication/authors\": \"Bernacki DT, Bryce SM, Bemis JC, Dertinger SD\",\n",
      "            \"publication/journal\": \"Toxicol Sci\",\n",
      "            \"publication/title\": \"Aneugen Molecular Mechanism Assay: Proof-of-Concept With 27 Reference Chemicals.\",\n",
      "            \"optimization/algorithm\": \"Classification and Regression Tree\",\n",
      "            \"optimization/features\": \"12 markers\",\n",
      "            \"model/interpretability\": \"Transparent - Lipid peroxidation was the most important predictor of the changes in LDL levels\",\n",
      "            \"dataset/provenance\": \"109 patients\",\n",
      "            \"dataset/splits\": \"60% training 40% validation\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b4a\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"31871774\",\n",
      "            \"updated\": \"01/25/2022 14:56:54\",\n",
      "            \"authors\": \"Xu W, Xu M, Wang L, Zhou W, Xiang R, Shi Y, Zhang Y, Piao Y\",\n",
      "            \"journal\": \"Signal Transduct Target Ther\",\n",
      "            \"title\": \"Integrative analysis of DNA methylation and gene expression identified cervical cancer-specific diagnostic biomarkers.\",\n",
      "            \"doi\": \"10.1038/s41392-019-0081-6\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"80e739c4-91d8-49a9-8620-1f876215ff63\",\n",
      "        \"shortid\": \"cqy67zmg5o\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"01/25/2022 14:56:54\",\n",
      "            \"publication/authors\": \"Xu W, Xu M, Wang L, Zhou W, Xiang R, Shi Y, Zhang Y, Piao Y\",\n",
      "            \"publication/journal\": \"Signal Transduct Target Ther\",\n",
      "            \"publication/title\": \"Integrative analysis of DNA methylation and gene expression identified cervical cancer-specific diagnostic biomarkers.\",\n",
      "            \"optimization/algorithm\": \"Random forest\",\n",
      "            \"optimization/encoding\": \"K-mer featurization (k=3,4,5) scheme for 5'-UTR, CDS and 3'-UTR.\",\n",
      "            \"optimization/fitting\": \"Risk of underfitting, since p=64 << N_total=2928.\",\n",
      "            \"optimization/parameters\": \"p=sqrt(f)=64, where f is the number of features. \",\n",
      "            \"model/availability\": \"Yes, GitHub https://github.com/wukevin/rnagps\",\n",
      "            \"model/interpretability\": \"Interpretable. Interpretation performed via RF feature importance\",\n",
      "            \"model/output\": \"Multi-class classification\",\n",
      "            \"evaluation/comparison\": \"Basset (Kelley et al., 2016), RNATracker (Yan et al.,. 2019). Baselines implemented with other tree-based approaches (e.g XGBoost), neural networks, convolutional networks, recurrent networks (long-short term memory, gated recurrent units).\",\n",
      "            \"evaluation/measure\": \"Accuracy, AUROC, AUPRC\",\n",
      "            \"evaluation/method\": \"10-fold cross-validation. Independent dataset\",\n",
      "            \"dataset/availability\": \"Raw APEX-seq data available at Gene Expression Omnibus (GEO) under accession GSE116008\",\n",
      "            \"dataset/provenance\": \"Training data: Rnot reported localization data from  APEX-seq results available in literature (Fazal et al., 2019). Eight localization classes: N_c1=1223,N_c2=768,N_c3=301,N_c4=208,N_c5=1361,N_c6=823,N_c7=159,N_c8=739.  Independent test data: ENCODE Project Consortium 2012, cell line HeLa-S3: N=7641, cell line K562: N=6359. Individual class abundance in independent data is unknown\",\n",
      "            \"dataset/redundancy\": \"Not handled\",\n",
      "            \"dataset/splits\": \"N_train=80%,N_test=10%,N_val=10%. ENCODE data used for testing\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b4b\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"30448611\",\n",
      "            \"updated\": \"01/26/2022 17:25:36\",\n",
      "            \"authors\": \"Sun H, Paixao L, Oliva JT, Goparaju B, Carvalho DZ, van Leeuwen KG, Akeju O, Thomas RJ, Cash SS, Bianchi MT, Westover MB\",\n",
      "            \"journal\": \"Neurobiol Aging\",\n",
      "            \"title\": \"Brain age from the electroencephalogram of sleep.\",\n",
      "            \"doi\": \"10.1016/j.neurobiolaging.2018.10.016\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"7ff7eafe-6d4e-4b8e-b924-ee81c0e447ff\",\n",
      "        \"shortid\": \"7rqpjvvf0w\",\n",
      "        \"score\": 0.48,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"01/26/2022 17:25:36\",\n",
      "            \"publication/authors\": \"Sun H, Paixao L, Oliva JT, Goparaju B, Carvalho DZ, van Leeuwen KG, Akeju O, Thomas RJ, Cash SS, Bianchi MT, Westover MB\",\n",
      "            \"publication/journal\": \"Neurobiol Aging\",\n",
      "            \"publication/title\": \"Brain age from the electroencephalogram of sleep.\",\n",
      "            \"optimization/algorithm\": \"Random forest\",\n",
      "            \"optimization/encoding\": \"MRI scans parceled into non-overlapping patches of V voxels. Patches represent nodes of a brain network, and the absolute values of Pearson\\u2019s correlation between patch pairs were considered the links between the node. Given N, the number of network nodes, 8N features for each subject\",\n",
      "            \"optimization/features\": \"f=?. Feature selection by Random Forest\",\n",
      "            \"model/interpretability\": \"Black box. Random forest used for feature seleciton\",\n",
      "            \"model/output\": \"Binary classification\",\n",
      "            \"evaluation/comparison\": \"Comparison with a standard baseline method based on Region-Of-Interest (ROI) segmentation\",\n",
      "            \"evaluation/measure\": \"Sensitivity, Specificity, Accuracy, ROC-AUC\",\n",
      "            \"evaluation/method\": \"Repeated 80%-20% cross-validation. No indipendent datasets\",\n",
      "            \"dataset/provenance\": \"MRI scans of Traumatic Brain Injury (TBI) subjects recruited in EpiBioS4Rx. Npos=16, Nneg=37. Not previously used in literature.\",\n",
      "            \"dataset/splits\": \"N_pos,train=13, N_neg_train=30, N_pos,test=3, N_neg_test=7. Not separate validation set.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b4c\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"30933970\",\n",
      "            \"updated\": \"02/11/2022 10:17:27\",\n",
      "            \"authors\": \"Liang C, Yu S, Luo J\",\n",
      "            \"journal\": \"PLoS Comput Biol\",\n",
      "            \"title\": \"Adaptive multi-view multi-label learning for identifying disease-associated candidate miRNAs.\",\n",
      "            \"doi\": \"10.1371/journal.pcbi.1006931\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"3cb70f9b-d503-4330-9b57-4a893f11f3b0\",\n",
      "        \"shortid\": \"p75y9vrkgn\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/11/2022 10:17:27\",\n",
      "            \"publication/authors\": \"Liang C, Yu S, Luo J\",\n",
      "            \"publication/journal\": \"PLoS Comput Biol\",\n",
      "            \"publication/title\": \"Adaptive multi-view multi-label learning for identifying disease-associated candidate miRNAs.\",\n",
      "            \"optimization/algorithm\": \"SVM, Adaboost with decision trees, Ensemble KNN, Random forest\",\n",
      "            \"optimization/encoding\": \"some data were transformed either by binning or one-hot encoding .  \",\n",
      "            \"optimization/features\": \"It's is unclear which features are exactly used. There is no clear summary table.  They used clinical test and patient data next to protein concentration information (HMGB1, NFL, p-181-tau).  Missing values were filled up with K-NN imputation.  They examine always 7 models (in terms of the feature set used), M1 is only clinical data the others use M1 plus a subset of the 3 proteins.\",\n",
      "            \"optimization/fitting\": \"number if features is smaller than number of samples. Cross-validation (I assume with random splits) to avoid over-fitting.\",\n",
      "            \"optimization/meta\": \"No, all raw data\",\n",
      "            \"optimization/parameters\": \"They are not reported (number of KNN in the ensemble, RF settings, adaboost)\",\n",
      "            \"optimization/regularization\": \"no validation set used.\",\n",
      "            \"model/interpretability\": \"They performed a feature importance analysis for the best models (M3 and M4) and showed partial dependency plots between classification and a series ofd features. No details on how this was produced.\",\n",
      "            \"model/output\": \"classification in two classes (impaired versus normal)\",\n",
      "            \"evaluation/comparison\": \"4 different methods were compared. No comparison with other method on their data.\",\n",
      "            \"evaluation/confidence\": \"paired t-test with p<0.05\",\n",
      "            \"evaluation/measure\": \"area under the curve\",\n",
      "            \"evaluation/method\": \"cross validation\",\n",
      "            \"dataset/availability\": \"data is not reported.\",\n",
      "            \"dataset/provenance\": \"In house produce experimental and clinical data (neurophysiological tests, age, education, ethnicity.  20 normal  and 40 neurologically impaired patients. New data not used in other studies.\",\n",
      "            \"dataset/redundancy\": \"not reported, although they claim that data leakage (which I assume is bad stratification) between folds was precluded.  No details on how.  I assume random fold separation, hence the 10 times repetition.\",\n",
      "            \"dataset/splits\": \"They employed 6-fold cross-validation (repeated 10 times), not needing split between training and test set.  they did not provide a validation set.  Pos=40, Neg=20 patients.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b4d\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"30769139\",\n",
      "            \"updated\": \"03/09/2022 09:50:58\",\n",
      "            \"authors\": \"Kargarfard F, Sami A, Hemmatzadeh F, Ebrahimie E\",\n",
      "            \"journal\": \"Gene\",\n",
      "            \"title\": \"Identifying mutation positions in all segments of influenza genome enables better differentiation between pandemic and seasonal strains.\",\n",
      "            \"doi\": \"10.1016/j.gene.2019.01.014\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"5d549370-43e5-4163-977c-59e9d5cadf79\",\n",
      "        \"shortid\": \"iugmhjifoe\",\n",
      "        \"score\": 0.52,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/09/2022 09:50:58\",\n",
      "            \"publication/authors\": \"Kargarfard F, Sami A, Hemmatzadeh F, Ebrahimie E\",\n",
      "            \"publication/title\": \"Identifying mutation positions in all segments of influenza genome enables better differentiation between pandemic and seasonal strains.\",\n",
      "            \"optimization/algorithm\": \"Novel approach called BioConceptVec. The paper explains why they used a novel approach\",\n",
      "            \"optimization/config\": \"Yes, available at URL: https://github.com/ncbi/BioConceptVec\",\n",
      "            \"model/availability\": \"Yes, available at URL: https://github.com/ncbi/BioConceptVec\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/comparison\": \"Compared with other methods (BioAgvWord and \\\"Yu et al.\\\")\",\n",
      "            \"evaluation/confidence\": \"No confidence interval\",\n",
      "            \"evaluation/measure\": \"Precision, Recall, F1-score, Area Under Curve (AUC)\",\n",
      "            \"evaluation/method\": \"Intrinsic and Extrinsic evaluation from 9 independent datasets\",\n",
      "            \"dataset/availability\": \"Yes. Dataset available at URL: https://github.com/ncbi/BioConceptVec\",\n",
      "            \"dataset/provenance\": \"Only one dataset employed, created using all PubMed abastracts \"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b4e\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"31404081\",\n",
      "            \"updated\": \"03/29/2022 01:42:53\",\n",
      "            \"authors\": \"Ledezma CA, Zhou X, Rodr\\u00edguez B, Tan PJ, D\\u00edaz-Zuccarini V\",\n",
      "            \"journal\": \"PLoS One\",\n",
      "            \"title\": \"A modeling and machine learning approach to ECG feature engineering for the detection of ischemia using pseudo-ECG.\",\n",
      "            \"doi\": \"10.1371/journal.pone.0220294\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"f2fcb740-5dca-4b4c-b5e1-8ea073ecc3e0\",\n",
      "        \"shortid\": \"lohsb5kzme\",\n",
      "        \"score\": 0.9,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/29/2022 01:42:53\",\n",
      "            \"publication/authors\": \"Ledezma CA, Zhou X, Rodr\\u00edguez B, Tan PJ, D\\u00edaz-Zuccarini V\",\n",
      "            \"publication/journal\": \"PLoS One\",\n",
      "            \"publication/title\": \"A modeling and machine learning approach to ECG feature engineering for the detection of ischemia using pseudo-ECG.\",\n",
      "            \"optimization/algorithm\": \" SVM, RF, XGBoost for feature ranking\",\n",
      "            \"optimization/config\": \"yes: https://github.com/taigangliu/HMMPred\",\n",
      "            \"optimization/encoding\": \"global features were derived from sequece-based features by averaging over protein length\",\n",
      "            \"optimization/features\": \"a range from 420 to 4020 was tested; 2000 in the final model\",\n",
      "            \"optimization/fitting\": \"a range of feature numbers was tested based on CVs; XGBoost feature ranking\",\n",
      "            \"optimization/parameters\": \"p = f+3 for SVM,  \",\n",
      "            \"optimization/regularization\": \"included in SVM (margin maximisation)\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"binary classification\",\n",
      "            \"evaluation/availability\": \"no raw evaluation files\",\n",
      "            \"evaluation/comparison\": \"comparisons with some existing predictors on the same datasets: DNAbinder, DNA-Prot, iDNA-Prot, iDNA-Prot|dis, Kmer1+ACC, iDNAPro-PseAAC, PseDNA-Pro, Local-DPP, HMMBinder\",\n",
      "            \"evaluation/measure\": \"Accuracy, sensitivity, specificity, MCC, AUC\",\n",
      "            \"evaluation/method\": \"Cross-validation, independent dataset\",\n",
      "            \"dataset/availability\": \"yes, https://github.com/taigangliu/HMMPred\",\n",
      "            \"dataset/provenance\": \"Two published datasets from literature: PDB1075 (525 pos and 550 neg) and PDB186 (93 pos and 93 neg)\",\n",
      "            \"dataset/redundancy\": \"sequences with more than 25% sequence similarity were removed\",\n",
      "            \"dataset/splits\": \"training: 525 pos / 550 neg; validation: 10-fold CV and jackknife CV; testing: 93 pos / 93 neg\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b56\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"31362694\",\n",
      "            \"updated\": \"03/13/2022 11:00:59\",\n",
      "            \"authors\": \"Wang J, Gribskov M\",\n",
      "            \"journal\": \"BMC Bioinformatics\",\n",
      "            \"title\": \"IRESpy: an XGBoost model for prediction of internal ribosome entry sites.\",\n",
      "            \"doi\": \"10.1186/s12859-019-2999-7\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"17ff2958-4461-4d8f-9c75-f7e3992a9bde\",\n",
      "        \"shortid\": \"i4p484v6d2\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/13/2022 11:00:59\",\n",
      "            \"publication/authors\": \"Wang J, Gribskov M\",\n",
      "            \"publication/journal\": \"BMC Bioinformatics\",\n",
      "            \"publication/title\": \"IRESpy: an XGBoost model for prediction of internal ribosome entry sites.\",\n",
      "            \"optimization/algorithm\": \"One class logistic regression. \",\n",
      "            \"optimization/encoding\": \"Cox regression analysis, least absolute shrinkage and selection operator (lasso), and Akaike information criterion (AIC) were used to identify the relevant genes to train the logistic regression model.\",\n",
      "            \"optimization/features\": \"8 input features selected using Cox regression analysis, least absolute shrinkage and selection operator (lasso), and Akaike information criterion (AIC)\",\n",
      "            \"optimization/fitting\": \"Not clearly stated, but could be inferred from the text that p is smaller than N. \",\n",
      "            \"optimization/parameters\": \"Not clearly stated, could be inferred from the text.\",\n",
      "            \"model/interpretability\": \"Transparent. The model generates a risk score according to the expression of the 8 selected genes.\",\n",
      "            \"evaluation/comparison\": \"The method was not compared to others.\",\n",
      "            \"evaluation/measure\": \"area under curve (AUC)\",\n",
      "            \"evaluation/method\": \"Independent dataset (using Dataset 2)\",\n",
      "            \"dataset/availability\": \"Dataset 1: Yes. URL: https://portal.gdc.cancer.gov/projects/TCGA-HNSC\\n\\nDataset 2: Yes. URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE41613 \",\n",
      "            \"dataset/provenance\": \"Dataset 1: Rnot reported-Seq data from The Cancer Genome Atlas for Head and Neck Squamous Cell Carcinoma (TGCA-HNSCC). N = 544; N_pos (survived patients) = 211, N_neg (not survived patients) = 280. Used in the community.\\n\\nDataset 2: GSE41613 from the Gene Expression Omnibus (GEO). N = 97; N_pos (survived patients) = 46, N_neg (not survived patients) = 50. Used in the community.\",\n",
      "            \"dataset/redundancy\": \"Dataset 1 and Dataset 2 are independent\",\n",
      "            \"dataset/splits\": \"Dataset 1: splitted in 50% for training and 50% for test. Split was conducted randomly. N_pos and N_neg for each subset not reported\\n\\nDataset 2: entirely used for test.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b6b\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"31466478\",\n",
      "            \"updated\": \"01/28/2022 21:38:37\",\n",
      "            \"authors\": \"Bollepalli S, Korhonen T, Kaprio J, Anders S, Ollikainen M\",\n",
      "            \"journal\": \"Epigenomics\",\n",
      "            \"title\": \"EpiSmokEr: a robust classifier to determine smoking status from DNA methylation data.\",\n",
      "            \"doi\": \"10.2217/epi-2019-0206\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"62a0f5bf-1440-4bce-855f-1beedf6af6f5\",\n",
      "        \"shortid\": \"dnrghw65xy\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"01/28/2022 21:38:37\",\n",
      "            \"publication/authors\": \"Bollepalli S, Korhonen T, Kaprio J, Anders S, Ollikainen M\",\n",
      "            \"publication/title\": \"EpiSmokEr: a robust classifier to determine smoking status from DNA methylation data.\",\n",
      "            \"optimization/config\": \"Hyperparameter values reported in the paper. Model available in bitbucket (https://bitbucket.org/alexeyg-com/irespredictor/src/v2/)\",\n",
      "            \"optimization/encoding\": \"340 global kmer features + 5440 local kmer features\",\n",
      "            \"optimization/features\": \"The final model includes 1281 individual trees and each tree incorporates 340 features. Features selected by XGBoost feature importance\",\n",
      "            \"optimization/parameters\": \"The final model includes 1281 individual trees and each tree incorporates 340 features. The\\nmaximum depth of each tree is set to be 6\",\n",
      "            \"model/availability\": \"Model available on bitbucket (https://bitbucket.org/alexeyg-com/irespredictor/src/v2/)\",\n",
      "            \"model/interpretability\": \"Feature interpreted by XGBoost feature importance\",\n",
      "            \"evaluation/comparison\": \"Compared with IRESpred\",\n",
      "            \"evaluation/measure\": \"Accuracy, sensitivity, specificity, precision, Matthews correlation\",\n",
      "            \"evaluation/method\": \"Independent set\",\n",
      "            \"dataset/availability\": \"Bitbucket available (https://bitbucket.org/alexeyg-com/irespredictor/src). Datasets non clearly labelled\",\n",
      "            \"dataset/provenance\": \"Training dataset (dataset 2): high throughput experimental data (doi: 10.1126/science.aad4939), filtered and annotated as in (doi:10.1371/journal.pcbi.1005734) describing an available predictor. \\n20872 examples: 2129 positive, 18743 negative.\\nTesting dataset (dataset 1): low throughput experimental data extracted from a public database (https://doi. org/10.1093/nar/gkp981).\\n167 examples: 116 positive, 51 negative.\",\n",
      "            \"dataset/redundancy\": \"Random split. Overall similarity in the dataset 2 was checked: 7.56% sequences have more\\nthan 80% identity, 15.3% sequences have more than 50% identity, and 17.02% sequences have more than 30% identity. There are no sequences with 100% identity-\\nSimilarity between dataset 1 and dataset 2 is not reported\",\n",
      "            \"dataset/splits\": \"Random split of dataset 2 in 90% training and 10% testing.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b6c\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"30970017\",\n",
      "            \"updated\": \"03/04/2022 17:32:12\",\n",
      "            \"authors\": \"Conti S, Karplus M\",\n",
      "            \"journal\": \"PLoS Comput Biol\",\n",
      "            \"title\": \"Estimation of the breadth of CD4bs targeting HIV antibodies by molecular modeling and machine learning.\",\n",
      "            \"doi\": \"10.1371/journal.pcbi.1006954\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"036db907-b055-40cb-b38e-3b1ef226ba31\",\n",
      "        \"shortid\": \"nfh7iw73hz\",\n",
      "        \"score\": 0.57,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/04/2022 17:32:12\",\n",
      "            \"publication/authors\": \"Conti S, Karplus M\",\n",
      "            \"publication/journal\": \"PLoS Comput Biol\",\n",
      "            \"publication/title\": \"Estimation of the breadth of CD4bs targeting HIV antibodies by molecular modeling and machine learning.\",\n",
      "            \"optimization/algorithm\": \"DT, CBA, Ripper\",\n",
      "            \"optimization/encoding\": \"global features (multiple sequence alignment)\",\n",
      "            \"optimization/features\": \"f = protein sequence length (200-900)\",\n",
      "            \"model/interpretability\": \"transparent: biological interpretation of identified rules (mutations)\",\n",
      "            \"model/output\": \"probability score\",\n",
      "            \"evaluation/confidence\": \"None for evaluation\",\n",
      "            \"evaluation/method\": \"mysterious \\\"test set\\\" mentioned only once\",\n",
      "            \"dataset/availability\": \"yes: supporting information\",\n",
      "            \"dataset/provenance\": \"new database search in Influenza Research Database; 10 protein datasets with 4240-5373 data points (around 2/3 are pos and 1/3 are neg in each dataset) \",\n",
      "            \"dataset/redundancy\": \"none reported\",\n",
      "            \"dataset/splits\": \"There is a mysterious \\\"test data\\\" set mentioned only once without any additional information.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b6d\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"30857591\",\n",
      "            \"updated\": \"03/08/2022 17:16:35\",\n",
      "            \"authors\": \"Tubiana J, Cocco S, Monasson R\",\n",
      "            \"journal\": \"Elife\",\n",
      "            \"title\": \"Learning protein constitutive motifs from sequence data.\",\n",
      "            \"doi\": \"10.7554/eLife.39397\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"0e3da6d0-101b-4136-926f-f122310fb98c\",\n",
      "        \"shortid\": \"v9brv84km1\",\n",
      "        \"score\": 0.86,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/08/2022 17:16:35\",\n",
      "            \"publication/authors\": \"Tubiana J, Cocco S, Monasson R\",\n",
      "            \"publication/title\": \"Learning protein constitutive motifs from sequence data.\",\n",
      "            \"optimization/algorithm\": \"Restricted Boltzmann Machines\",\n",
      "            \"optimization/config\": \"yes: https://github.com/jertubiana/ProteinMotifRBM\",\n",
      "            \"optimization/encoding\": \"aligned sequences\",\n",
      "            \"optimization/features\": \"MxNx21 where M is length and N is width of an MSA\",\n",
      "            \"optimization/fitting\": \"regularisation and model selection used\",\n",
      "            \"optimization/parameters\": \"not given explicitly, a different number of hidden units (1-400) were tested\",\n",
      "            \"optimization/regularization\": \"L2 and L2/L1\",\n",
      "            \"model/availability\": \"yes: https://github.com/jertubiana/ProteinMotifRBM\",\n",
      "            \"model/duration\": \"in the order of 1\\u20132 days on an Intel Xeon Phi processor with 2 \\u00d7 28 cores\",\n",
      "            \"model/interpretability\": \"yes: weights are interrelated for various case studies\",\n",
      "            \"model/output\": \"probability score\",\n",
      "            \"evaluation/comparison\": \"performance was compared to direct coupling-based methods, namely the Pseudo-Likelihood Method (plmDCA) and Boltzmann Machine (BM)\",\n",
      "            \"evaluation/measure\": \"PPV, accuracy (contact prediction task)\",\n",
      "            \"evaluation/method\": \"independent test (20% of initial data)\",\n",
      "            \"dataset/availability\": \"yes: https://github.com/jertubiana/ProteinMotifRBM\",\n",
      "            \"dataset/provenance\": \"supervised (contact prediction): 18 sets of multiple sequence alignments from pfam database + contact maps based on pdbs; \",\n",
      "            \"dataset/redundancy\": \"Reweighting procedure is applied: each sequence is assigned a weight equal to the inverse of the number of sequences with more than 90% identity\",\n",
      "            \"dataset/splits\": \"train/test: 80%/20% at random \"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b6e\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"31479437\",\n",
      "            \"updated\": \"03/28/2022 12:30:56\",\n",
      "            \"authors\": \"Picart-Armada S, Barrett SJ, Will\\u00e9 DR, Perera-Lluna A, Gutteridge A, Dessailly BH\",\n",
      "            \"journal\": \"PLoS Comput Biol\",\n",
      "            \"title\": \"Benchmarking network propagation methods for disease gene identification.\",\n",
      "            \"doi\": \"10.1371/journal.pcbi.1007276\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"73502b02-ed6c-48e0-9ab6-148d33d45944\",\n",
      "        \"shortid\": \"imwu5xtkc9\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/28/2022 12:30:56\",\n",
      "            \"publication/authors\": \"Picart-Armada S, Barrett SJ, Will\\u00e9 DR, Perera-Lluna A, Gutteridge A, Dessailly BH\",\n",
      "            \"publication/journal\": \"PLoS Comput Biol\",\n",
      "            \"publication/title\": \"Benchmarking network propagation methods for disease gene identification.\",\n",
      "            \"optimization/algorithm\": \"Kernel maximum mean discrepancy to select features + RF\",\n",
      "            \"optimization/encoding\": \"global features\",\n",
      "            \"optimization/features\": \" expression data of 23368 genes\",\n",
      "            \"optimization/parameters\": \"non-parametric method (it seems)\",\n",
      "            \"optimization/regularization\": \"None mentioned\",\n",
      "            \"model/availability\": \"Barely: https://github.com/Zhixun-Zhao/GeneMarker\",\n",
      "            \"model/interpretability\": \"transparent: identification of marker genes for lung cancer\",\n",
      "            \"evaluation/availability\": \"yes: supporting information\",\n",
      "            \"evaluation/comparison\": \"comparison with conventional t-test and fold change methods\",\n",
      "            \"evaluation/measure\": \"Recall, F1, Accuracy, MCC\",\n",
      "            \"evaluation/method\": \"10-fold CV\",\n",
      "            \"dataset/availability\": \"NCBI Gene Expression Om-nibus (https://www.ncbi.nlm.nih.gov/geo/): GSE86354 and GSE62944\",\n",
      "            \"dataset/provenance\": \"Three classes are three gene expression datasets collected before: 373 normal, 59 normal adjacent to tumour, and 541 tumour patients\",\n",
      "            \"dataset/redundancy\": \"None checked\",\n",
      "            \"dataset/splits\": \"10-fold CV\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b88\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"31874628\",\n",
      "            \"updated\": \"02/23/2022 14:14:06\",\n",
      "            \"authors\": \"Kim T, Lo K, Geddes TA, Kim HJ, Yang JYH, Yang P\",\n",
      "            \"journal\": \"BMC Genomics\",\n",
      "            \"title\": \"scReClassify: post hoc cell type classification of single-cell rNA-seq data.\",\n",
      "            \"doi\": \"10.1186/s12864-019-6305-x\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"96990d27-f206-43f3-ac18-2c14125e545c\",\n",
      "        \"shortid\": \"kbejtqvi3h\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/23/2022 14:14:06\",\n",
      "            \"publication/authors\": \"Kim T, Lo K, Geddes TA, Kim HJ, Yang JYH, Yang P\",\n",
      "            \"publication/journal\": \"BMC Genomics\",\n",
      "            \"publication/title\": \"scReClassify: post hoc cell type classification of single-cell rNA-seq data.\",\n",
      "            \"optimization/algorithm\": \"Bayesian, Support Vector Machine and Recursive Partitioning Forest\",\n",
      "            \"optimization/config\": \"Configuration avalailble in the supplementary material. models available http://molsync.com/ebola/ (link not working)\",\n",
      "            \"optimization/encoding\": \"Molecular descriptors: molecular function class fingerprints of maximum diameter 6 (FCFP_6), AlogP, molecular weight, number of rotatable bonds, number of rings, number of aromatic rings, number of hydrogen bond acceptors, number of hydrogen bond donors, and molecular fractional polar surface area\",\n",
      "            \"optimization/fitting\": \"Number of training examples is at least twice p_svm. Reduced risk of over- and under-fitting\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"Binary classification\",\n",
      "            \"evaluation/availability\": \"Partially available in supplementary material\",\n",
      "            \"evaluation/measure\": \"ROC-AUC, Confusion matrix, Sensitivity, Specificty\",\n",
      "            \"evaluation/method\": \"5-fold Cross-validation and Leave out 50% \\u00d7 100 fold cross validation. No independent test.\",\n",
      "            \"dataset/availability\": \"Yes, http://molsync.com/ebola/ (link not working)\",\n",
      "            \"dataset/provenance\": \"Dataset from literature (Madrid et al., 2013; Madrid et al., 2015). N_pos=41, N_neg=653\",\n",
      "            \"dataset/splits\": \"5-Fold Cross-validation split: N_pos_train ~= 33, N_neg_train ~= 522, N_pos_test ~= 8, N_neg_test ~= 131. Leave out 50% \\u00d7 100 fold cross validation: N_pos_train ~= 20, N_neg_train ~= 327, N_pos_test ~= 20, N_neg_test ~= 327\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b89\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"31856830\",\n",
      "            \"updated\": \"03/08/2022 14:15:46\",\n",
      "            \"authors\": \"Zhao Z, Peng H, Zhang X, Zheng Y, Chen F, Fang L, Li J\",\n",
      "            \"journal\": \"BMC Med Genomics\",\n",
      "            \"title\": \"Identification of lung cancer gene markers through kernel maximum mean discrepancy and information entropy.\",\n",
      "            \"doi\": \"10.1186/s12920-019-0630-4\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"0f6385d3-bd3b-4257-b8e8-3289261b719f\",\n",
      "        \"shortid\": \"b9ln75l2jr\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/08/2022 14:15:46\",\n",
      "            \"publication/authors\": \"Zhao Z, Peng H, Zhang X, Zheng Y, Chen F, Fang L, Li J\",\n",
      "            \"publication/journal\": \"BMC Med Genomics\",\n",
      "            \"publication/title\": \"Identification of lung cancer gene markers through kernel maximum mean discrepancy and information entropy.\",\n",
      "            \"optimization/algorithm\": \"Logistic regression, KNN, LDA, DT, RF, Gaussian processes (GP-ARD)\",\n",
      "            \"optimization/config\": \"partially: supplement\",\n",
      "            \"optimization/encoding\": \"global features\",\n",
      "            \"optimization/fitting\": \"a range of different model types was tested\",\n",
      "            \"optimization/parameters\": \"various but equal to f in most cases\",\n",
      "            \"optimization/regularization\": \"for some predictors, e.g. Lasso for logistic regression\",\n",
      "            \"model/interpretability\": \"transparent: identification of the main biomarkers\",\n",
      "            \"model/output\": \"both, depending on the model used\",\n",
      "            \"evaluation/comparison\": \"only among the models in the paper\",\n",
      "            \"evaluation/measure\": \"sensitivity, specificity, accuracy, AUROC\",\n",
      "            \"dataset/availability\": \"No, only ClinicalTrials.gov identifier: NCT01717573\",\n",
      "            \"dataset/provenance\": \"clinical trials, 11 pos and 27 neg\",\n",
      "            \"dataset/splits\": \"LOOCV for testing and internal LOOCV or 5-fold CV for validation\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b8a\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"31308377\",\n",
      "            \"updated\": \"03/28/2022 20:10:36\",\n",
      "            \"authors\": \"Mourikis TP, Benedetti L, Foxall E, Temelkovski D, Nulsen J, Perner J, Cereda M, Lagergren J, Howell M, Yau C, Fitzgerald RC, Scaffidi P, Oesophageal Cancer Clinical and Molecular Stratification (OCCAMS) Consortium., Ciccarelli FD\",\n",
      "            \"journal\": \"Nat Commun\",\n",
      "            \"title\": \"Patient-specific cancer genes contribute to recurrently perturbed pathways and establish therapeutic vulnerabilities in esophageal adenocarcinoma.\",\n",
      "            \"doi\": \"10.1038/s41467-019-10898-3\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"2c4e1331-5d62-4abc-a990-d4cea1bea700\",\n",
      "        \"shortid\": \"1r4k25lx15\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/28/2022 20:10:36\",\n",
      "            \"publication/authors\": \"Mourikis TP, Benedetti L, Foxall E, Temelkovski D, Nulsen J, Perner J, Cereda M, Lagergren J, Howell M, Yau C, Fitzgerald RC, Scaffidi P, Oesophageal Cancer Clinical and Molecular Stratification (OCCAMS) Consortium., Ciccarelli FD\",\n",
      "            \"publication/journal\": \"Nat Commun\",\n",
      "            \"publication/title\": \"Patient-specific cancer genes contribute to recurrently perturbed pathways and establish therapeutic vulnerabilities in esophageal adenocarcinoma.\",\n",
      "            \"optimization/algorithm\": \"hidden Markov models were trained for each class\",\n",
      "            \"optimization/encoding\": \"moving average window\",\n",
      "            \"optimization/features\": \"22 discrete intervals\",\n",
      "            \"optimization/fitting\": \"testing various sizes of the moving average window\",\n",
      "            \"optimization/parameters\": \"not clear\",\n",
      "            \"model/availability\": \"partially in the supplement\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"probability scores\",\n",
      "            \"evaluation/confidence\": \"Yes: SDs are given for each accuracy estimates\",\n",
      "            \"dataset/provenance\": \"Recorded FFRs to 4 Mandarin tones from 28 people\",\n",
      "            \"dataset/redundancy\": \"\\\"To avoid stimulus artifact bias, training and testing subsets alternated the same number of trials with opposite stimulus polarity\\\"\",\n",
      "            \"dataset/splits\": \"K-fold CV of varying K for each tone separately (a version of unsupervised learning)\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b8b\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"31148311\",\n",
      "            \"updated\": \"03/30/2022 16:46:29\",\n",
      "            \"authors\": \"Jing R, Li P, Ding Z, Lin X, Zhao R, Shi L, Yan H, Liao J, Zhuo C, Lu L, Fan Y\",\n",
      "            \"journal\": \"Hum Brain Mapp\",\n",
      "            \"title\": \"Machine learning identifies unaffected first-degree relatives with functional network patterns and cognitive impairment similar to those of schizophrenia patients.\",\n",
      "            \"doi\": \"10.1002/hbm.24678\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"fcd15280-77b1-4526-b2fc-1a1b8987db42\",\n",
      "        \"shortid\": \"nl91j0uju5\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/30/2022 16:46:29\",\n",
      "            \"publication/authors\": \"Jing R, Li P, Ding Z, Lin X, Zhao R, Shi L, Yan H, Liao J, Zhuo C, Lu L, Fan Y\",\n",
      "            \"publication/journal\": \"Hum Brain Mapp\",\n",
      "            \"publication/title\": \"Machine learning identifies unaffected first-degree relatives with functional network patterns and cognitive impairment similar to those of schizophrenia patients.\",\n",
      "            \"optimization/algorithm\": \"SVM with RBF kernel\",\n",
      "            \"optimization/features\": \"Yes, SMILES Chem structures with 250 fragments selected by MI\",\n",
      "            \"optimization/regularization\": \"Yes - intrinsic to SVM\",\n",
      "            \"model/interpretability\": \"Black box but voting schema is applied\",\n",
      "            \"evaluation/comparison\": \"Local baseline\",\n",
      "            \"evaluation/method\": \"Cross validation\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b98\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"31534955\",\n",
      "            \"updated\": \"01/28/2022 14:49:16\",\n",
      "            \"authors\": \"Jiang HJ, Huang YA, You ZH\",\n",
      "            \"journal\": \"Biomed Res Int\",\n",
      "            \"title\": \"Predicting Drug-Disease Associations via Using Gaussian Interaction Profile and Kernel-Based Autoencoder.\",\n",
      "            \"doi\": \"10.1155/2019/2426958\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"4fa6c779-0e82-43a8-8a08-65a2feaa0bad\",\n",
      "        \"shortid\": \"9t9rwycfgl\",\n",
      "        \"score\": 0.86,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"01/28/2022 14:49:16\",\n",
      "            \"publication/authors\": \"Jiang HJ, Huang YA, You ZH\",\n",
      "            \"publication/journal\": \"Biomed Res Int\",\n",
      "            \"publication/title\": \"Predicting Drug-Disease Associations via Using Gaussian Interaction Profile and Kernel-Based Autoencoder.\",\n",
      "            \"optimization/algorithm\": \"1) Elastic net linear model for affinity prediction, 2) linear regression models (linear and logistic) and neural network for pose prediction (active versus decoy).  The linear model was submitted for D3R\",\n",
      "            \"optimization/encoding\": \"1) training data is transformed into Boolean fingerprints, 2) training data for classifier is translated into numerical vectors\",\n",
      "            \"optimization/features\": \"no feature selection was performed. 2) classifier has 61 features and 1) size of bit pattern defines number of features in the regressor (2048 or more)\",\n",
      "            \"optimization/fitting\": \"classifier has less parameters than samples.  \",\n",
      "            \"optimization/meta\": \"They use a number of other methods to infer the feature that are used by the regressor and classification algorithm.  Not clerk what the overlap is.\",\n",
      "            \"optimization/parameters\": \"1) two parameters alpha and rho. 2) 1 for regressor and 20 hidden node/2 output node NN.decay and momentum parameters for training the network.\",\n",
      "            \"optimization/regularization\": \"Cross-validation performed to determine the generalisation of the predictions.\",\n",
      "            \"model/duration\": \"not mentioned but linear regression is fast\",\n",
      "            \"model/interpretability\": \"the weights of the regressor explain the importance of the features. The NN is black box\",\n",
      "            \"evaluation/comparison\": \"they compare only their own approaches\",\n",
      "            \"evaluation/confidence\": \"confidence bars given in bart plots. Significance is mentioned but no p-values are provided\",\n",
      "            \"evaluation/measure\": \"only AUC\",\n",
      "            \"evaluation/method\": \"Cross-validation when training the classifiers and the test set is independent as it is provided by the D3R challenge\",\n",
      "            \"dataset/availability\": \"they do not provide themselves the data they used in their regressor and classifier.\",\n",
      "            \"dataset/provenance\": \"1) regression data : 355 compounds from ChEMBL bioactivity database for training the regressor, 2) classification data : DUD-E dataset (102 target proteins, 20000 active molecules and more than a million decoy molecules); classes active/decoy. The validation/testing of the predictive methods is done on the D3R data form HSP90 and MAP4K4. They generate 29K poses for the former to test their predictors and 5329 poses for the latter. No mention of which ones are active fits and which ones are decoys. \",\n",
      "            \"dataset/redundancy\": \"The DUD-E set consists of a HSP90 target.  the authors make an independent set with this information, I assume to checkt the influence of the presence of this information own the classification.\",\n",
      "            \"dataset/splits\": \"The training and test set are completely separate (see explanations above).  Note imbalance in dataset for the classifier, which they overcome by also creating a balanced dataset for training. In the HSP90 test set there were 136 active and 44 inactive compounds (threshold set by authors on affinity).\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b99\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"31659164\",\n",
      "            \"updated\": \"06/26/2022 22:26:24\",\n",
      "            \"authors\": \"Akerberg BN, Gu F, VanDusen NJ, Zhang X, Dong R, Li K, Zhang B, Zhou B, Sethi I, Ma Q, Wasson L, Wen T, Liu J, Dong K, Conlon FL, Zhou J, Yuan GC, Zhou P, Pu WT\",\n",
      "            \"journal\": \"Nat Commun\",\n",
      "            \"title\": \"A reference map of murine cardiac transcription factor chromatin occupancy identifies dynamic and conserved enhancers.\",\n",
      "            \"doi\": \"10.1038/s41467-019-12812-3\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"2d650333-5e1b-4cc3-a7bb-512a00abfce0\",\n",
      "        \"shortid\": \"m6t40hhxhx\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"06/26/2022 22:26:24\",\n",
      "            \"publication/authors\": \"Akerberg BN, Gu F, VanDusen NJ, Zhang X, Dong R, Li K, Zhang B, Zhou B, Sethi I, Ma Q, Wasson L, Wen T, Liu J, Dong K, Conlon FL, Zhou J, Yuan GC, Zhou P, Pu WT\",\n",
      "            \"publication/journal\": \"Nat Commun\",\n",
      "            \"publication/title\": \"A reference map of murine cardiac transcription factor chromatin occupancy identifies dynamic and conserved enhancers.\",\n",
      "            \"optimization/algorithm\": \"21 DNNs + Elastic net as stacking model; GBoost; RF; DT; LR; kNN; Elastic net; SVM\",\n",
      "            \"optimization/config\": \"Only the summary for the DNNs architectures\",\n",
      "            \"optimization/encoding\": \"global features\",\n",
      "            \"optimization/fitting\": \"DNNs outperform baseline ML approaches\",\n",
      "            \"optimization/parameters\": \"around 5M\",\n",
      "            \"optimization/regularization\": \"Yes: dropout (p=0.2) after each layer, and L2 weight decay\",\n",
      "            \"model/availability\": \"http://www.aging.ai/ - looks proprietary\",\n",
      "            \"model/interpretability\": \"transparent: marker importance based on Permutation Feature Importance; discussion of top 10 features\",\n",
      "            \"model/output\": \"continuous labels\",\n",
      "            \"evaluation/comparison\": \"only a set of baseline models, based on R2 and accuracy\",\n",
      "            \"evaluation/measure\": \"epsilon-prediction accuracy (epsilon=10); R2; Pearson correlation (not reported); MAE (not reported)\",\n",
      "            \"evaluation/method\": \"seemingly independent test set\",\n",
      "            \"dataset/provenance\": \"62419 anonymized blood biochemistry records from Invitro Laboratory, Ltd.; continuous labels; dataset not used before\",\n",
      "            \"dataset/splits\": \"random 90/10 train-test split; 10-fold CV mentioned only in a figure\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305ba1\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"30891794\",\n",
      "            \"updated\": \"03/03/2022 13:08:10\",\n",
      "            \"authors\": \"Cui S, Luo Y, Tseng HH, Ten Haken RK, El Naqa I\",\n",
      "            \"journal\": \"Med Phys\",\n",
      "            \"title\": \"Combining handcrafted features with latent variables in machine learning for prediction of radiation-induced lung damage.\",\n",
      "            \"doi\": \"10.1002/mp.13497\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"01f23578-67f2-4b8c-ab9e-121a1b840b39\",\n",
      "        \"shortid\": \"zwmdye1tg8\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/03/2022 13:08:10\",\n",
      "            \"publication/authors\": \"Cui S, Luo Y, Tseng HH, Ten Haken RK, El Naqa I\",\n",
      "            \"publication/journal\": \"Med Phys\",\n",
      "            \"publication/title\": \"Combining handcrafted features with latent variables in machine learning for prediction of radiation-induced lung damage.\",\n",
      "            \"optimization/config\": \"Yes: text\",\n",
      "            \"optimization/encoding\": \"global features: distances are calculated by BLAST\",\n",
      "            \"optimization/features\": \"variable sequence lengths of around 1000 AAs\",\n",
      "            \"optimization/fitting\": \"a range of K values tested (1-50), 2 different CV protocols, weighted KNN\",\n",
      "            \"model/availability\": \"https://services.birc.au.dk/patbox/ - not available as of 09/03/2022\",\n",
      "            \"model/interpretability\": \"transparent: k=1 was selected, which is basically the sequence similarity method\",\n",
      "            \"model/output\": \"binary predictions\",\n",
      "            \"evaluation/comparison\": \"one other method based on ANN is mentioned in the text\",\n",
      "            \"evaluation/confidence\": \"standard deviation is reported in a figure based on 20*5 values\",\n",
      "            \"evaluation/method\": \"5-fold and 2-fold CV\",\n",
      "            \"dataset/provenance\": \"a dataset of 515 sequences annotated with experimentally verified subtypes; 11 classes\",\n",
      "            \"dataset/redundancy\": \"the dataset was also clustered at similarity thresholds of 30%, 50%, 75%, and 90%\",\n",
      "            \"dataset/splits\": \"20 runs of non-stratified 5-fold CVs and 2-fold CVs\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305ba2\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"30794638\",\n",
      "            \"updated\": \"03/29/2022 09:39:03\",\n",
      "            \"authors\": \"Masino AJ, Harris MC, Forsyth D, Ostapenko S, Srinivasan L, Bonafide CP, Balamuth F, Schmatz M, Grundmeier RW\",\n",
      "            \"journal\": \"PLoS One\",\n",
      "            \"title\": \"Machine learning models for early sepsis recognition in the neonatal intensive care unit using readily available electronic health record data.\",\n",
      "            \"doi\": \"10.1371/journal.pone.0212665\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"5574a8f7-41dd-4803-b335-00c1cbb28c34\",\n",
      "        \"shortid\": \"hwprilha6h\",\n",
      "        \"score\": 0.52,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/29/2022 09:39:03\",\n",
      "            \"publication/authors\": \"Masino AJ, Harris MC, Forsyth D, Ostapenko S, Srinivasan L, Bonafide CP, Balamuth F, Schmatz M, Grundmeier RW\",\n",
      "            \"publication/journal\": \"PLoS One\",\n",
      "            \"publication/title\": \"Machine learning models for early sepsis recognition in the neonatal intensive care unit using readily available electronic health record data.\",\n",
      "            \"optimization/algorithm\": \"Decision tree (C4.5)\",\n",
      "            \"model/interpretability\": \"Black box (~large decision-tree)\",\n",
      "            \"model/output\": \"Statistical analysis: association between features and disease\",\n",
      "            \"evaluation/measure\": \"P-value of association\",\n",
      "            \"dataset/splits\": \"Control & clinical sets (300 healthy individuals and 43 patients)\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bab\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"30590545\",\n",
      "            \"updated\": \"03/29/2022 00:49:10\",\n",
      "            \"authors\": \"Rawson TM, Hernandez B, Moore LSP, Blandy O, Herrero P, Gilchrist M, Gordon A, Toumazou C, Sriskandan S, Georgiou P, Holmes AH\",\n",
      "            \"journal\": \"J Antimicrob Chemother\",\n",
      "            \"title\": \"Supervised machine learning for the prediction of infection on admission to hospital: a prospective observational cohort study.\",\n",
      "            \"doi\": \"10.1093/jac/dky514\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"783e858f-5f8f-4b82-afb8-d61eaf60be03\",\n",
      "        \"shortid\": \"ek1c4fvz6e\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/29/2022 00:49:10\",\n",
      "            \"publication/authors\": \"Rawson TM, Hernandez B, Moore LSP, Blandy O, Herrero P, Gilchrist M, Gordon A, Toumazou C, Sriskandan S, Georgiou P, Holmes AH\",\n",
      "            \"publication/journal\": \"J Antimicrob Chemother\",\n",
      "            \"publication/title\": \"Supervised machine learning for the prediction of infection on admission to hospital: a prospective observational cohort study.\",\n",
      "            \"optimization/encoding\": \"global features (k-mers)\",\n",
      "            \"optimization/features\": \"not clear: in one place they mention 55-dimensional vectors, but also 4-mer frequencies (256) and 3 additional features.\",\n",
      "            \"optimization/parameters\": \"p = f\",\n",
      "            \"model/availability\": \"Not available for SVM, but the focus of the study was a non ML-based tool: https://github.com/seqcode/multigps\",\n",
      "            \"model/interpretability\": \"transparent: discriminative motif discovery touched upon\",\n",
      "            \"model/output\": \"binary classification\",\n",
      "            \"evaluation/confidence\": \"Not explicitly given but 20 replicates are shown in the ROC graphs\",\n",
      "            \"evaluation/method\": \"20 random replicates of train/test splits\",\n",
      "            \"dataset/provenance\": \"55 mouse ES ChIP-seq and DNaseI-seq experiments from a variety of sources, each with up to 4000 pos and 10000 negs.\",\n",
      "            \"dataset/redundancy\": \"mot checked\",\n",
      "            \"dataset/splits\": \"20 repetitions of random selection of 100 data points for testing\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bac\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"30950198\",\n",
      "            \"updated\": \"03/27/2022 20:48:59\",\n",
      "            \"authors\": \"Hu X, Xie W, Wu C, Xu S\",\n",
      "            \"journal\": \"Plant Biotechnol J\",\n",
      "            \"title\": \"A directed learning strategy integrating multiple omic data improves genomic prediction.\",\n",
      "            \"doi\": \"10.1111/pbi.13117\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"f0944313-d0c6-4160-94cb-b073fe88e4bd\",\n",
      "        \"shortid\": \"v1rge4dd87\",\n",
      "        \"score\": 0.52,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/27/2022 20:48:59\",\n",
      "            \"publication/authors\": \"Hu X, Xie W, Wu C, Xu S\",\n",
      "            \"publication/journal\": \"Plant Biotechnol J\",\n",
      "            \"publication/title\": \"A directed learning strategy integrating multiple omic data improves genomic prediction.\",\n",
      "            \"optimization/algorithm\": \"gradient boosting algorithm using 2 different weak learner models: OLS and RKHS regression; modification -> random boosting\",\n",
      "            \"optimization/encoding\": \"global features\",\n",
      "            \"optimization/features\": \"only 39714 SNPs mentioned\",\n",
      "            \"model/interpretability\": \"transparent: gene identification\",\n",
      "            \"evaluation/measure\": \"Pearson correlation, Estimated prediction bias (=\\\"average difference between predicted and observed responses in standard deviation units\\\")\",\n",
      "            \"evaluation/method\": \"independent test set\",\n",
      "            \"dataset/provenance\": \"1859 data points from another publication, continuous lables\",\n",
      "            \"dataset/redundancy\": \"data were split by the year of birth (before 2005 -> train, after -> test)\",\n",
      "            \"dataset/splits\": \"train/test: 1601/258 or 1574/235 (depending on the label type); 10-fold CV\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bb7\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"30877925\",\n",
      "            \"updated\": \"03/02/2022 16:41:47\",\n",
      "            \"authors\": \"Andersen SL, Briggs FBS, Winnike JH, Natanzon Y, Maichle S, Knagge KJ, Newby LK, Gregory SG\",\n",
      "            \"journal\": \"Mult Scler Relat Disord\",\n",
      "            \"title\": \"Metabolome-based signature of disease pathology in MS.\",\n",
      "            \"doi\": \"10.1016/j.msard.2019.03.006\",\n",
      "            \"year\": \"2019\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"a6fa00a2-c4cf-4004-b63f-2abb8ffd46bf\",\n",
      "        \"shortid\": \"vs7yv4y6i5\",\n",
      "        \"score\": 0.57,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/02/2022 16:41:47\",\n",
      "            \"publication/authors\": \"Andersen SL, Briggs FBS, Winnike JH, Natanzon Y, Maichle S, Knagge KJ, Newby LK, Gregory SG\",\n",
      "            \"publication/journal\": \"Mult Scler Relat Disord\",\n",
      "            \"publication/title\": \"Metabolome-based signature of disease pathology in MS.\",\n",
      "            \"optimization/algorithm\": \"Support Vector Machines\",\n",
      "            \"optimization/config\": \"Configuration and hyper-parameter configuration available in the main text\",\n",
      "            \"optimization/encoding\": \"Global features encoding frequency and total number of each amino acid, as well as of certain sets of amino acids (e.g. hydrophobic, charged, polar). Protein subdivided into four equally sized fragments and calculated the same feature values for each fragment and combination of fragments. Predicted the secondary structure using Prof, position of putative transmembrane helices using TMHMM and of disordered regions using DisEMBL (predicted features are processed using the above fragmentation strategy). \",\n",
      "            \"optimization/features\": \"f=2579. Feature selection performed using Wilcoxon signed-rank test\",\n",
      "            \"optimization/meta\": \"Yes, for computing some feature. No handling of potential dataset redundancy.\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"Multi-class classification\",\n",
      "            \"evaluation/method\": \"Repeated training/testing split (five times). No indipendent datasets\",\n",
      "            \"dataset/provenance\": \"Los Alamos National Laboratory Bioscience Division STD Sequence Databases. N_pos and N_neg for each functional class are unknown.\",\n",
      "            \"dataset/redundancy\": \"Redundancy between traiing/testing reduced with PSI-BLAST (e-value threshold set to 0.001)\",\n",
      "            \"dataset/splits\": \"Five independent training/testing splits with ratio 4:1. N_pos, N_neg for each training/testing is unknown. No separate validation set.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6638a402b30933003cc215c9\",\n",
      "        \"shortid\": \"3iham0l32l\",\n",
      "        \"uuid\": \"34249f84-1197-4a65-8ab2-a298da42e32a\",\n",
      "        \"created\": \"2024-05-06T09:33:54.347Z\",\n",
      "        \"updated\": \"2024-05-06T09:33:54.347Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"31877719\",\n",
      "            \"authors\": \"Floriane Montanari, Lara Kuhnke, Antonius Ter Laak, Djork-Arn\\u00e9 Clevert\",\n",
      "            \"journal\": \"Molecules\",\n",
      "            \"title\": \"Modeling Physico-Chemical ADMET Endpoints with Multitask Graph Convolutional Networks\\n\",\n",
      "            \"doi\": \"10.3390/molecules25010044\",\n",
      "            \"year\": \"2019\"\n",
      "        },\n",
      "        \"score\": 0.81,\n",
      "        \"matches\": {\n",
      "            \"evaluation/comparison\": \"The model was compared to simpler models developed by authors, including:\\nRandom Forest\\nFully-Connected Single Task Network\\nFully-Connected Multitask Network\\nSingle Task Graph Convultional Network\",\n",
      "            \"evaluation/confidence\": \"Standard deviations are reported in supplementary materials.\",\n",
      "            \"evaluation/measure\": \"The performance of such regression models is evaluated by the coefficient of determination r2 (which measures the concordance between predicted and experimental values) and the Spearman correlation coefficient rho (which measures the ranking capabilities of the models).\",\n",
      "            \"evaluation/method\": \"The model was evaluated a in cross-validation fashion for random and cluster split strategies.\\nIn time split method, the model that was trained on earlier measurements is evaluated on recent measurements.\",\n",
      "            \"optimization/algorithm\": \"Multiple models were used and compared, but the main model that was focused by the authors is a Multitask Graph Convolutional Neural Network\",\n",
      "            \"optimization/config\": \"The code to train multitask graph convolutional networks is available on github: https://github.com/fmonta/mtnngc_admet\",\n",
      "            \"optimization/encoding\": \"The authors used molecular graphs and 75 simple atomic descriptors as initial node features.\",\n",
      "            \"optimization/features\": \"75 atomic features for each atom in a molecule.\\nNo explanation on feature selection.\",\n",
      "            \"optimization/meta\": \"The model is not a meta-predictor\",\n",
      "            \"optimization/parameters\": \"The authors used the implementation of the Duvenaud algorithm in DeepChem v.1.2.1 and kept the architecture and hyperparameters suggested by the authors for ADMET predictions.\\n(Duvenaud, D.; Maclaurin, D.; Aguilera-Iparraguirre, J.; G\\u00f3mez-Bombarelli, R.; Hirzel, T.; Aspuru-Guzik, A.; Adams, R.P. Convolutional Networks on Graphs for Learning Molecular Fingerprints. In Proceedings of the Advances in Neural Information Processing Systems 28 (NIPS 2015), Montreal, QC, Canada, 7\\u201312 December 2015)\",\n",
      "            \"optimization/regularization\": \"cross validation was performed for random splits and cluster splits.\",\n",
      "            \"model/availability\": \"The code to train multitask graph convolutional networks is available on github: https://github.com/fmonta/mtnngc_admet\",\n",
      "            \"model/interpretability\": \"The model is a black box.\",\n",
      "            \"model/output\": \"The model is a regression model for predicting 7 ADMET endpoints.\",\n",
      "            \"dataset/provenance\": \"The authors used in-house (Bayer) datasets related to 10 ADMET endpoints\\n1. LogD (pH7.5) (LOD) = 76,548 \\n2. LogD (pH2.3) (LOA) = 236,280\\n3. Membrane affinity (LOM) = 64,506 \\n4. Human serum albumin binding (LOH) = 61,398 \\n5. Melting point (LMP) = 90,589 \\n6. Solubility (DMSO)  (LOO) = 38,841 \\n7. Solubility (powder) (LOP) = 2334 \\n8. Solubility (nephelometry) (LON )= 88,301 \\n9. Solubility (DMSO not fully dissolved) (LOX) = 7392 \\n10. Solubility (no assay annotation) (LOQ) = 50,016\",\n",
      "            \"dataset/redundancy\": \"Models were evaluated in both a cross-validation and a separate test set fashion.\\nDifferent splitting strategies were used that includes:\\n1. Cluster split using k-means to cluster the compounds (K = 10)\\n2. Random splits ensuring that each fold contains representatives from each task\\n3. Time splits with no cross-validation based on measurement dates, in which later measurements used as test sets\",\n",
      "            \"dataset/splits\": \"Different splitting strategies were used independently and only the test size for time split dataset is reported:\\nLOD = 32,794\\nLOA = 46,481\\nLOM = 197\\nLOH = 614\\nLMP = 55\\nLOO = 22,803\\nLOP = 935\",\n",
      "            \"publication/authors\": \"Floriane Montanari, Lara Kuhnke, Antonius Ter Laak, Djork-Arn\\u00e9 Clevert\",\n",
      "            \"publication/title\": \"Modeling Physico-Chemical ADMET Endpoints with Multitask Graph Convolutional Networks\\n\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"665d0af137ea6fa797a6bda1\",\n",
      "        \"shortid\": \"5bz7gjjsah\",\n",
      "        \"uuid\": \"ffea624d-972d-4b3e-85bb-4708bb5c26a1\",\n",
      "        \"created\": \"2024-06-03T00:14:41.897Z\",\n",
      "        \"updated\": \"2024-06-03T00:14:41.897Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"31199787\",\n",
      "            \"authors\": \"Kymberleigh A. Pagel, Danny Antaki, AoJie Lian, Matthew Mort, David N. Cooper, Jonathan Sebat, Lilia M. Iakoucheva, Sean D. Mooney, and Predrag Radivojac\",\n",
      "            \"journal\": \"PLOS Computational Biology\",\n",
      "            \"title\": \"Pathogenicity and functional impact of non-frameshifting insertion/deletion variation in the human genome\",\n",
      "            \"doi\": \"10.1371/journal.pcbi.1007112\",\n",
      "            \"year\": \"2019\"\n",
      "        },\n",
      "        \"score\": 0.95,\n",
      "        \"matches\": {\n",
      "            \"evaluation/availability\": \"No - no link/files /statistical code relating to the raw evaluation beyond text details.\",\n",
      "            \"evaluation/comparison\": \"Yes, the evaluation of MutPred-Indel included comparisons to both simpler baselines and publicly available methods.\\n\\nSimpler baseline: authors compared MutPred-Indel to MutPred2. They achieved this by simulating deletions and insertions using MutPred2 and showed that MutPred-Indel outperformed MutPred2 in this scenario (AUC of 0.903 vs 0.797)\\n\\nComparison to publicly available methods: authors also compared MutPred-Indel to other indel prediction methods like VEST-Indel and DDIG. MutPred-Indel achieved the highest AUC (0.897) compared to VEST-Indel (0.875) and DDIG-in (0.869). \",\n",
      "            \"evaluation/confidence\": \"Confidence intervals are not explicitly mentioned in the text. No clear indication of t-tests/other approaches to determine statistically significant method improvements beyond the direct AUC comparisons.\",\n",
      "            \"evaluation/measure\": \"The area under the receiver operating characteristic (ROC) curve is detailed and plotted in the evalaution section.\\n\\nThe paper notes the model: 'shows strong performance in cross-validation with the area under the ROC curve (AUC) of 0.908'. Figure 5 details the performance ROC curves under various comparisons such as against other prediction models such as 'CADD'.\",\n",
      "            \"evaluation/method\": \"Various evaluation methods were employed such as:\\n10-fold cross-validation, per-protein and per-cluster cross-validation and comparison of models with different feature sets.\",\n",
      "            \"optimization/algorithm\": \"The ML algorithm used in the paper is an ensemble of bagged two-layer feed-forward neural networks.\",\n",
      "            \"optimization/config\": \"No, not clearly available from the text or software website. Regarding parameters reporting, the text does note: 'Each pathogenicity predictor was developed with the Matlab 2016b Neural Network Toolbox as an ensemble of one hundred bagged two-layer feed-forward neural networks, where the following training parameters were not varied between alternative models'.\",\n",
      "            \"optimization/encoding\": \"Preprocessing was undertaken via Two-sample t-test and principal component analysis (PCA). Encoding used and detailed under feature engineering section such as numerical encoding.\",\n",
      "            \"optimization/features\": \"Precise number of input features not explicitly stated in main publication text. The structural and functional features of protein sequences are detailed in Table 3 of the text and fall into 5x categories with approximately 57 noted across these categories. \",\n",
      "            \"optimization/fitting\": \"Provided that the feature information and inferred parameter infromation (not easy to discern from text), the risk of overfitting is not very likely due to N >> p and the validation set. For underfitting this is mitigated by minimal feature reduction and 10-fold cross-validation employed, but this is dependent on significance of the features and risk grows if the features used are not significant enough. \",\n",
      "            \"optimization/parameters\": \"Without the precise feature count the number of parameters cannot be exactly determined. However, if to use the estimated number of features from Table 3 in the text (57 features from total of 5x categories), it could be inferred that with a network architecture of a two-layer feed-forward neural network with 10 hidden units would be 591.\",\n",
      "            \"optimization/regularization\": \"Yes, as the text mentions using a validation set, specifically retaining 25% of the training data being set aside for validation.\",\n",
      "            \"model/availability\": \"Source code GitHub repository for MutPred2: https://github.com/vpejaver/mutpred2 - MIT License. Primary resource website of the software (http://mutpred.mutdb.org/) offers  live web service for analyses and downloadable executable.\",\n",
      "            \"model/duration\": \"The standalone model executable can be used for genome-scale data sets. To install and run MutPred2, you will need about 50 GB of hard disk space and at least 4 GB RAM. No further information avaialble regarding prediction run times beyond this.\",\n",
      "            \"model/interpretability\": \"Somewhat of a black box from the text alone. In the text there are reasonable descriptions of the model but given the lack of publicly available model & code (eg: in Huggingface/other model hosting/no GitHub) and exact training & test datasets. It is somewhat of a blackbox if attempting to reproduce and interpret the exacts of the model given its complex ML algorithm nature being that of an ensemble of neural networks from the text alone. However, there is a GitHub online that can be found for the model and related datasets so this helps greatly with the model interpretability in conjunction with the text. However, it should be explictly linked for readers. The Matlab related files and info also not available on GitHub due to licensing.\",\n",
      "            \"model/output\": \"Classification - used to predict pathogenicity of indels\",\n",
      "            \"dataset/availability\": \"Training data:\\n-Positive class, disease causing indel variant data was sourced from the Human Gene Mutation Database (HGMD), professional version 2017. http://www.hgmd.cf.ac.uk\\n\\n-Negative class, putatively neutral indel variant data was sourced from the Genome Aggregation Database (gnomAD) databases. https://gnomad.broadinstitute.org/\\n\\nTest data:\\n-1. Somatic test set: Catalogue Of Somatic Mutations In Cancer (COSMIC) genome-wide screen data set (v85) & DataBase of Cancer Driver InDels (dbCID). \\n\\n-2. De novo test set: REACH Project & Simons Simplex Collection.\\n\\nThe publicly available data of the study derived from the above databases are available at http://mutpred.mutdb.org/ - training data: http://mutpred.mutdb.org/wo_exclusive_hgmd_mp2_training_data.txt\\n\\nAlso references in the text to other publications regarding some of the data sources. \",\n",
      "            \"dataset/provenance\": \"Data source: from databases - both pay to access (HGMD professional) and publicly available ones (COSMIC/gnomAD/+). \\n\\nData type: DNA - genetic variants, grouped as standard insertions and deletions (indels) and complex indels.\\nClass positive: disease causing sequence-retaining insertion, deletion, and complex indel variants. Unclear but likely: 1,296.\\nClass negative: putatively neutral insertion/deletion variants. Unclear but likely: 2,392.\\n\\nDetermination of exact number of training and test data points is difficult to ascertain due to poor alignment with numeric figures provided in the text to that of Table 2 which contains this information. The Table 2 itself is also difficult to interpret due to a second set of bracketed numbers beside each initial figure provided. Neither sets of numbers align exactly to the text and no clear key/description provided. \\n\\nDataset reuse/community recognised: data used is a subset of avilable data from reputable international databases. Large variety of databases leveraged and combined for training and test data.\",\n",
      "            \"dataset/redundancy\": \"How were the sets split?: \\nFor the training data:\\n-Validation set (25%): A quarter of the training data is used to fine-tune the model during training (resilient propagation method).\\n-Cross-validation (10-fold): The training data is divided into 10 folds. The model is trained on 9 folds and tested on the remaining one, repeated 10 times, to assess generalisability (AUC-ROC).\\n\\nAre the training and test sets independent?: \\nYes, indpendent test and training sets used.\\n\\nHow does the distribution compare to previously published ML datasets?:\\nMutPred-Indel is compared to three existing methods: DDIG-in, VEST-Indel, and CADD  but it uses the training data from the current study, not entirely independent datasets. The paper notes a 'paucity' of such data.\",\n",
      "            \"dataset/splits\": \"Training data set comprised of:\\n-5606 single residue deletions\\n-1033 single residue insertions\\n-2427 multi-residue insertions\\n-3052 multi-residue deletions\\n-1253 complex indel variants\\n\\nTest data sets: \\n2x test data sets were used to test the models classification efficacy.\\n1. Somatic mutation test sets: consisting of two sets of putatively damaging cancer causing somatic variants derived from information in COSMIC AND dbCID databases. Text seems to indicate 576 test data points based on the final sentence '(n = 576)' but not clear or explictly stated/documented in text.  \\n\\n2. De novo mutation test sets: consisting of non-frameshifting insertion/deletion variants curated from families affected by Autism Spectrum Disorder (ASD). Data sourced from REACH Project (2650 families) and the Simons Simplex Collection (SSC). Final test set after filtering is performed is composed of 1217 candidate de novo indels in 827 offspring (506 cases, 321 controls).\\n\\nSeparate validation set used, and if yes, how large was it?: \\nThe model training utilised the resilient propagation method and 25% of training data set aside for the validation.\",\n",
      "            \"publication/authors\": \"Kymberleigh A. Pagel, Danny Antaki, AoJie Lian, Matthew Mort, David N. Cooper, Jonathan Sebat, Lilia M. Iakoucheva, Sean D. Mooney, and Predrag Radivojac\",\n",
      "            \"publication/journal\": \"PLOS Computational Biology\",\n",
      "            \"publication/title\": \"Pathogenicity and functional impact of non-frameshifting insertion/deletion variation in the human genome\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b1b\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"32344344\",\n",
      "            \"updated\": \"03/22/2022 11:54:11\",\n",
      "            \"authors\": \"Bouysset C, Belloir C, Antonczak S, Briand L, Fiorucci S\",\n",
      "            \"journal\": \"Food Chem\",\n",
      "            \"title\": \"Novel scaffold of natural compound eliciting sweet taste revealed by machine learning.\",\n",
      "            \"doi\": \"10.1016/j.foodchem.2020.126864\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"8becb7c4-2b09-4c8a-b48f-eb340481376d\",\n",
      "        \"shortid\": \"fozqqtqf2d\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/22/2022 11:54:11\",\n",
      "            \"publication/authors\": \"Bouysset C, Belloir C, Antonczak S, Briand L, Fiorucci S\",\n",
      "            \"publication/journal\": \"Food Chem\",\n",
      "            \"publication/title\": \"Novel scaffold of natural compound eliciting sweet taste revealed by machine learning.\",\n",
      "            \"optimization/algorithm\": \"SVM classification method.\",\n",
      "            \"optimization/encoding\": \"The feature vectors are encoded in a bi-profile manner. This approach is explained in the paper (2.2.2. Adapted normal distribution bi-profile Bayes (ANBPB)).\",\n",
      "            \"optimization/features\": \"For feature extraction a modified version of classical bi-profile Bayes was used. Thirteen physicochemical features were selected. They used the jackknife test to select important features and optimize all parameters.\",\n",
      "            \"optimization/parameters\": \"2 parameters ( c = 4, \\u03b3 = 0.25 for the hydroxyproline prediction and\\nc = 4, \\u03b3 = 0.125 for the hydroxylysine prediction). Parameters were downloaded from http://www.matlabsky.com and optimized by the SVMcgForClass program. \",\n",
      "            \"model/availability\": \"The MATLAB package of OH-PRED is available as Supplementary files.\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/comparison\": \"iHyd-PseAAC (Xu, 2014) and PredHydroxy (Shi, 2015). Performance measures are compared.\",\n",
      "            \"evaluation/measure\": \"Sensitivity, specificity, accuracy.\",\n",
      "            \"evaluation/method\": \"Independent test dataset.\",\n",
      "            \"dataset/provenance\": \"265 candidate proteins containing hydroxylated prolines and 34 candidate proteins\\ncontaining hydroxylated lysines were collected from the UniProtKB/Swiss-Prot database (version 2014_1, www.uniprot.org). Sequence segments around the hydroxylation sites\\nand non-hydroxylation sites were extracted as positive and negative training datasets,\\nrespectively. \",\n",
      "            \"dataset/splits\": \"After removing the identical sequence, the original datasets contain 659\\npositive sites and 3855 negative sites for hydroxyproline from 112 proteins, and 97\\npositive sites and 855 negative sites for hydroxylysine from 25 proteins. The size of\\nthe negative datasets is much larger (approximate ratio of 1:6) than that of the positive training datasets. After addressing this problem, ratios of 1:1 and 1:3 of the number of positive samples and the number of negative samples were used to construct the negative training set. (Reduction of the negative set). \\nTest set is not described.\\nValidation set:  randomly split 10% of the samples from the dataset as an independent test dataset, and the remaining 90% of the samples as a training dataset.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b23\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"32220894\",\n",
      "            \"updated\": \"03/15/2022 15:36:27\",\n",
      "            \"authors\": \"Wu KE, Parker KR, Fazal FM, Chang HY, Zou J\",\n",
      "            \"journal\": \"RNA\",\n",
      "            \"title\": \"RNA-GPS predicts high-resolution RNA subcellular localization and highlights the role of splicing.\",\n",
      "            \"doi\": \"10.1261/rna.074161.119\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"282ed2ca-7c65-4eb6-9c7d-8c69881d722c\",\n",
      "        \"shortid\": \"039id1a4pi\",\n",
      "        \"score\": 0.57,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/15/2022 15:36:27\",\n",
      "            \"publication/authors\": \"Wu KE, Parker KR, Fazal FM, Chang HY, Zou J\",\n",
      "            \"publication/title\": \"RNA-GPS predicts high-resolution RNA subcellular localization and highlights the role of splicing.\",\n",
      "            \"optimization/algorithm\": \"Spathial, Random forest, LASSO\",\n",
      "            \"optimization/parameters\": \"R package randomForestSRC: \\\"The training was running with \\u201cimportance = TRUE,\\nblock size = 1\\u201d and set with all other parameters set to\\ndefaul\\\"\",\n",
      "            \"evaluation/measure\": \"AUCs for 2-, 3-, and 5-year OS were 0.527, 0.596 and 0.671, respectively\",\n",
      "            \"evaluation/method\": \"10-fold cross validation\",\n",
      "            \"dataset/availability\": \"no, they claim: \\\"Publicly available datasets were analyzed in this study. This data can be found here: The datasets collected in the current study are available in the TCGA3 and GEO repository.\\\"\\n\",\n",
      "            \"dataset/provenance\": \"public databases: 901 samples from The Cancer Genome Atlas cohort (TCGA-LUAD) and gene expression omnibus (GEO) database\",\n",
      "            \"dataset/splits\": \"10-fold cross validation\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b24\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"31161221\",\n",
      "            \"updated\": \"04/06/2022 16:25:21\",\n",
      "            \"authors\": \"Jeon J, Olkhov-Mitsel E, Xie H, Yao CQ, Zhao F, Jahangiri S, Cuizon C, Scarcello S, Jeyapala R, Watson JD, Fraser M, Ray J, Commisso K, Loblaw A, Fleshner NE, Bristow RG, Downes M, Vesprini D, Liu S, Bapat B, Boutros PC\",\n",
      "            \"journal\": \"J Natl Cancer Inst\",\n",
      "            \"title\": \"Temporal Stability and Prognostic Biomarker Potential of the Prostate Cancer Urine miRNA Transcriptome.\",\n",
      "            \"doi\": \"10.1093/jnci/djz112\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"f0936cfb-e3a1-44a1-b760-3897fce5b861\",\n",
      "        \"shortid\": \"nhcfgr8oi1\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"04/06/2022 16:25:21\",\n",
      "            \"publication/authors\": \"Jeon J, Olkhov-Mitsel E, Xie H, Yao CQ, Zhao F, Jahangiri S, Cuizon C, Scarcello S, Jeyapala R, Watson JD, Fraser M, Ray J, Commisso K, Loblaw A, Fleshner NE, Bristow RG, Downes M, Vesprini D, Liu S, Bapat B, Boutros PC\",\n",
      "            \"publication/journal\": \"J Natl Cancer Inst\",\n",
      "            \"publication/title\": \"Temporal Stability and Prognostic Biomarker Potential of the Prostate Cancer Urine miRNA Transcriptome.\",\n",
      "            \"optimization/algorithm\": \"Recursive feature elimination with cross-validation (RFECV) from sklearn. Random forest was used as the estimator.\",\n",
      "            \"optimization/config\": \"Data is available from authors upon request.\",\n",
      "            \"optimization/encoding\": \"1)\\tTo allow comparison between samples, all data were normalized to the internal standard in each chromatogram. The raw data consisting of 175 metabolites measured across 70 participants was normalized using min/max scaling. \\n2)\\tData imputation with IterativeImputer of sklearn was utilized to handle missing data. The trained imputer was tested by removing the data of one metabolite feature column and imputing the data afterward. The performance of the imputer was measured for each of the metabolites using R^2 metric. Metabolite columns with R^2 < 0.3 and more than 5% of missing values across all patients were removed.\\n3)\\tData standardization to zero mean and unit variance for each metabolite feature column. \\nData pre-processing step reduced the feature columns to 75 metabolites. \\n\",\n",
      "            \"optimization/features\": \"Metabolic profiles of 45 metabolites following data preprocessing. Recursive feature elimination with cross-validation (RFECV), using random forest, reduced the number of features to 15 metabolites.\",\n",
      "            \"model/availability\": \"Data is available from authors upon request.\",\n",
      "            \"model/interpretability\": \"Transparent. 15 selected metabolites following feature elimination, including stearic acid and ornithine, leading to best model performance. Unpaired t-test to identify metabolites with differences between CMD and non-CMD.\",\n",
      "            \"model/output\": \"The binary predictions of \\u201cCMD\\u201d and \\u201cnon-CMD\\u201d, with the latter combining both CAD and control group samples.\",\n",
      "            \"evaluation/availability\": \"Data is available from authors upon request.\",\n",
      "            \"evaluation/comparison\": \"1) One-way-ANOVA model and chi-squared analysis were fitted to test the statistical significance of clinical differences between different participant groups, followed by Tukey\\u2019s post hoc test. p < 0.05 was considered significant.\\n 2) Z-scores were calculated for each metabolite. An unpaired t-test was performed to identify metabolites that are different between each participant group.\",\n",
      "            \"evaluation/measure\": \"Receiver operating curves (ROC), precision\\u2013recall (PR) curves, AUC score, F1 score\",\n",
      "            \"evaluation/method\": \"5-fold cross-validation\",\n",
      "            \"dataset/availability\": \"Data is available from authors upon request.\",\n",
      "            \"dataset/provenance\": \"Profiles of 150 metabolites based on gas chromatography mass spectrometry (GC/MS) analysis of plasma samples from 70 postmenopausal women.\",\n",
      "            \"dataset/redundancy\": \"During GC/MS analysis tentative substances were not reported All known artificial peaks were identified and removed before data mining. The metabolic feature columns, which had more than 40% of data missing, were eliminated.\",\n",
      "            \"dataset/splits\": \"Npos=23 patients with coronary microvascular disease (CMD). Nneg=47 participants, including 21 patients with coronary artery disease (CAD) and 26 healthy participants as control group.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b25\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33039708\",\n",
      "            \"updated\": \"04/18/2022 16:33:16\",\n",
      "            \"authors\": \"Bitencourt AGV, Gibbs P, Rossi Saccarelli C, Daimiel I, Lo Gullo R, Fox MJ, Thakur S, Pinker K, Morris EA, Morrow M, Jochelson MS\",\n",
      "            \"journal\": \"EBioMedicine\",\n",
      "            \"title\": \"MRI-based machine learning radiomics can predict HER2 expression level and pathologic response after neoadjuvant therapy in HER2 overexpressing breast cancer.\",\n",
      "            \"doi\": \"10.1016/j.ebiom.2020.103042\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"1ac93280-f1b7-4064-8b5e-5e1553dbd65f\",\n",
      "        \"shortid\": \"9regsp7l7u\",\n",
      "        \"score\": 0.52,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"04/18/2022 16:33:16\",\n",
      "            \"publication/authors\": \"Bitencourt AGV, Gibbs P, Rossi Saccarelli C, Daimiel I, Lo Gullo R, Fox MJ, Thakur S, Pinker K, Morris EA, Morrow M, Jochelson MS\",\n",
      "            \"publication/title\": \"MRI-based machine learning radiomics can predict HER2 expression level and pathologic response after neoadjuvant therapy in HER2 overexpressing breast cancer.\",\n",
      "            \"optimization/algorithm\": \"Naive Bayes, SVM, Random Forests\",\n",
      "            \"optimization/encoding\": \"sliding window on sequence\",\n",
      "            \"optimization/features\": \"Fast Correlation Based Filter  and  Scatter Search  were used\",\n",
      "            \"model/availability\": \"yes, GitLab https://gitlab.com/mgarciat/genome-wide-prediction-of-topoisomerase-iibeta-binding\",\n",
      "            \"evaluation/measure\": \"ROC curves and AUC values\",\n",
      "            \"evaluation/method\": \"5-fold cross validation\",\n",
      "            \"dataset/availability\": \"yes, described at S1 table: https://deposition.proteinensemble.org/job/25e45232-2c53-409f-b734-bbc1710609a2\\n\\nall models and dataset at https://gitlab.com/mgarciat/genome-wide-prediction-of-topoisomerase-iibeta-binding\",\n",
      "            \"dataset/provenance\": \"yes, N_pos: 13128  N_neg: 32766\",\n",
      "            \"dataset/redundancy\": \"Correlation Feature Selection is used.\",\n",
      "            \"dataset/splits\": \"5-fold cross-validation\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b26\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"32620137\",\n",
      "            \"updated\": \"04/18/2022 16:44:10\",\n",
      "            \"authors\": \"Ji Z, Zhou W, Hou W, Ji H\",\n",
      "            \"journal\": \"Genome Biol\",\n",
      "            \"title\": \"Single-cell ATAC-seq signal extraction and enhancement with SCATE.\",\n",
      "            \"doi\": \"10.1186/s13059-020-02075-3\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"42bd8a6e-bec6-4f31-b0b6-e19be5f8c86f\",\n",
      "        \"shortid\": \"x35e8g9f2z\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"04/18/2022 16:44:10\",\n",
      "            \"publication/authors\": \"Ji Z, Zhou W, Hou W, Ji H\",\n",
      "            \"publication/journal\": \"Genome Biol\",\n",
      "            \"publication/title\": \"Single-cell ATAC-seq signal extraction and enhancement with SCATE.\",\n",
      "            \"optimization/algorithm\": \"SVM and Convolutional Neural Network (ImageNet architecture)\",\n",
      "            \"optimization/config\": \"Some hyperparameters specified in the main text\",\n",
      "            \"optimization/encoding\": \"150x150 pixel images (CNN). Image descrptors for SVM\",\n",
      "            \"optimization/features\": \"f=3 (pixel intensities) for CNN. f=3 for SVM (descriptors selected after PCA-based feature selection)\",\n",
      "            \"optimization/fitting\": \"Early stopping used to prevent overfitting (CNN)\",\n",
      "            \"model/availability\": \"Yes https://github.com/gkanfer/AI-PS\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"Binary classification\",\n",
      "            \"evaluation/confidence\": \"No confidence reported\",\n",
      "            \"evaluation/measure\": \"Accuracy, AUPRC\",\n",
      "            \"evaluation/method\": \"Independent testing\",\n",
      "            \"dataset/availability\": \"Yes, https://github.com/ gkanfer/AI-PS/tree/master/facs\",\n",
      "            \"dataset/provenance\": \"Parking and GFP-TFEB images generated in the same study\",\n",
      "            \"dataset/splits\": \"Training 80%, validation 15%, 5% Independent test data. N_pos and N_neg unknown for training data. For independent data: N_pos=5401, N_neg=4948.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b27\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33005419\",\n",
      "            \"updated\": \"05/20/2022 15:26:30\",\n",
      "            \"authors\": \"Lu XJ, Yang XJ, Sun JY, Zhang X, Yuan ZX, Li XH\",\n",
      "            \"journal\": \"Biomark Res\",\n",
      "            \"title\": \"FibroBox: a novel noninvasive tool for predicting significant liver fibrosis and cirrhosis in HBV infected patients.\",\n",
      "            \"doi\": \"10.1186/s40364-020-00215-2\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"db022eae-23a7-444b-b7ad-0e845a5ec029\",\n",
      "        \"shortid\": \"sfncop89n7\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"05/20/2022 15:26:30\",\n",
      "            \"publication/authors\": \"Lu XJ, Yang XJ, Sun JY, Zhang X, Yuan ZX, Li XH\",\n",
      "            \"publication/journal\": \"Biomark Res\",\n",
      "            \"publication/title\": \"FibroBox: a novel noninvasive tool for predicting significant liver fibrosis and cirrhosis in HBV infected patients.\",\n",
      "            \"optimization/encoding\": \"data normalised, missing data inputed using median value, data standardised using z-scores. \",\n",
      "            \"optimization/features\": \"10 clinical features, eight cancer biomarkers 29-gene NGS panel for mutations, 30 methylation-correlated blocks (feature-selected from 697 MCBs). \",\n",
      "            \"optimization/fitting\": \"parameter smaller than samples, features larger but still smaller than samples pin the training set, but univariate analysis reduced then number of features.\",\n",
      "            \"optimization/meta\": \"Features are coming from experimental data.  Four different predictors using different data are grouped in a stacked ensemble classifier, using Naive Bayes. \",\n",
      "            \"optimization/parameters\": \"linear kernel used in SVMs for each independent predictor.  Naive bayes sued to determine the optimal combination of these predictors.\",\n",
      "            \"optimization/regularization\": \"Cross-validations procedures and feature selection are used to reduce chances for over-fitting.  Evaluation based on independent validation set.\",\n",
      "            \"model/interpretability\": \"partially interpretable but no apart from feature analysis on the baseline predictors, nothing else reported\",\n",
      "            \"model/output\": \"classification in benign or malignant\",\n",
      "            \"evaluation/comparison\": \"no other methods are compared\",\n",
      "            \"evaluation/measure\": \"AUC. sensitivity and specificity\",\n",
      "            \"evaluation/method\": \"cross validation and independent set\",\n",
      "            \"dataset/availability\": \"patient clinical information available in SI, as well as the protein biomarker data cfDnot reported mutation and cfDnot reported methylation features. Link to raw data also provided (or via author)\",\n",
      "            \"dataset/provenance\": \"Data is experimentally derived from 125 patients. Training data divided over 84 positive and 41 negative instances. An independent validation set \",\n",
      "            \"dataset/splits\": \"Data is split into 96 for training and 29 for validation. The training set consisted of 69 positive and 27 negative, whereas the validation set is divided into 14 negative and 15 positive cases.  \"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b28\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"31857725\",\n",
      "            \"updated\": \"05/20/2022 16:23:02\",\n",
      "            \"authors\": \"Blyuss O, Zaikin A, Cherepanova V, Munblit D, Kiseleva EM, Prytomanova OM, Duffy SW, Crnogorac-Jurcevic T\",\n",
      "            \"journal\": \"Br J Cancer\",\n",
      "            \"title\": \"Development of PancRISK, a urine biomarker-based risk score for stratified screening of pancreatic cancer patients.\",\n",
      "            \"doi\": \"10.1038/s41416-019-0694-0\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"c9c5b90f-7cb6-4c2e-9fd0-85cb16728ff1\",\n",
      "        \"shortid\": \"6ed6jt5sbi\",\n",
      "        \"score\": 0.38,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"05/20/2022 16:23:02\",\n",
      "            \"publication/authors\": \"Blyuss O, Zaikin A, Cherepanova V, Munblit D, Kiseleva EM, Prytomanova OM, Duffy SW, Crnogorac-Jurcevic T\",\n",
      "            \"publication/journal\": \"Br J Cancer\",\n",
      "            \"publication/title\": \"Development of PancRISK, a urine biomarker-based risk score for stratified screening of pancreatic cancer patients.\",\n",
      "            \"optimization/algorithm\": \"Yes: SVM\",\n",
      "            \"optimization/encoding\": \"Yes: images features (fractal dimension, 2D wavelet coefficients, percolation score)\",\n",
      "            \"model/interpretability\": \"~Yes: comparison between different features\",\n",
      "            \"evaluation/measure\": \"Yes: accuracy = R-square and RMSE\",\n",
      "            \"evaluation/method\": \"independent dataset\",\n",
      "            \"dataset/provenance\": \"Yes: dataset generated by own experiment\",\n",
      "            \"dataset/splits\": \"~Yes but not very clear: 12 pos and 12 neg images, duplicated (image divided into four quadrant)->48 images pos and 48 images neg. divided: 80% cross-validation training set and 20% testing set.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b29\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"32344344\",\n",
      "            \"updated\": \"06/23/2022 03:30:18\",\n",
      "            \"authors\": \"Bouysset C, Belloir C, Antonczak S, Briand L, Fiorucci S\",\n",
      "            \"journal\": \"Food Chem\",\n",
      "            \"title\": \"Novel scaffold of natural compound eliciting sweet taste revealed by machine learning.\",\n",
      "            \"doi\": \"10.1016/j.foodchem.2020.126864\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"4fd5e711-86f0-4064-a357-31d2f610128b\",\n",
      "        \"shortid\": \"l9ylxpirie\",\n",
      "        \"score\": 0.43,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"06/23/2022 03:30:18\",\n",
      "            \"publication/authors\": \"Bouysset C, Belloir C, Antonczak S, Briand L, Fiorucci S\",\n",
      "            \"publication/journal\": \"Food Chem\",\n",
      "            \"publication/title\": \"Novel scaffold of natural compound eliciting sweet taste revealed by machine learning.\",\n",
      "            \"optimization/algorithm\": \"Novel approach (Preferential Subspace IDentification)\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/comparison\": \"neural dynamic mod- eling (NDM) e representational modeling (RM)\",\n",
      "            \"evaluation/measure\": \"cross-validated CC between the true and predicted behavior\",\n",
      "            \"dataset/availability\": \"Yes, Upon reasonable request from the corresponding author\",\n",
      "            \"dataset/provenance\": \"Two monkeys!\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b2f\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"32826857\",\n",
      "            \"updated\": \"01/26/2022 11:41:26\",\n",
      "            \"authors\": \"Takahashi Y, Ueki M, Tamiya G, Ogishima S, Kinoshita K, Hozawa A, Minegishi N, Nagami F, Fukumoto K, Otsuka K, Tanno K, Sakata K, Shimizu A, Sasaki M, Sobue K, Kure S, Yamamoto M, Tomita H\",\n",
      "            \"journal\": \"Transl Psychiatry\",\n",
      "            \"title\": \"Machine learning for effectively avoiding overfitting is a crucial strategy for the genetic prediction of polygenic psychiatric phenotypes.\",\n",
      "            \"doi\": \"10.1038/s41398-020-00957-5\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"0e4a9a17-a5bf-41d9-84a8-1eb49a8f35e5\",\n",
      "        \"shortid\": \"3qzygb13ir\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"01/26/2022 11:41:26\",\n",
      "            \"publication/authors\": \"Takahashi Y, Ueki M, Tamiya G, Ogishima S, Kinoshita K, Hozawa A, Minegishi N, Nagami F, Fukumoto K, Otsuka K, Tanno K, Sakata K, Shimizu A, Sasaki M, Sobue K, Kure S, Yamamoto M, Tomita H\",\n",
      "            \"publication/journal\": \"Transl Psychiatry\",\n",
      "            \"publication/title\": \"Machine learning for effectively avoiding overfitting is a crucial strategy for the genetic prediction of polygenic psychiatric phenotypes.\",\n",
      "            \"optimization/algorithm\": \"Deep neural network, end-to-end learning\",\n",
      "            \"optimization/config\": \"The overall architecture is available in supporting information and released in github (https://github.com/fusong-ju/ProFOLD). Webserver is indicated but not functional (http://protein.ict.ac.cn/ProFOLD)\",\n",
      "            \"optimization/encoding\": \"Multiple sequence alignment\",\n",
      "            \"optimization/features\": \"Given the MSA, for each pair target-homologous sequences, each position is encoded with a 41-valued vector. Total encoding = Sequence length x Number of homologous sequences in MSA (Max 1000) x 41. No feature selection applied.\",\n",
      "            \"optimization/fitting\": \"MSA sampling and distance matrix cropping in training process is adopted to avoid potential overfitting as well\",\n",
      "            \"optimization/parameters\": \"6.46 M to 16.46 M parameters. Performance evaluated on the validation set.\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"classification (interresidue contacts) and regression (interresidue distance)\",\n",
      "            \"evaluation/comparison\": \"RaptorX, AlphaFold, trRosetta\",\n",
      "            \"evaluation/confidence\": \"No confidence intervals nor statistical significance reported\",\n",
      "            \"evaluation/measure\": \"Precision of contact predictions at different thresholds\",\n",
      "            \"evaluation/method\": \"Independent test set\",\n",
      "            \"dataset/availability\": \"Yes, but the server is not working: http://protein.ict.ac.cn/ProFOLD\",\n",
      "            \"dataset/provenance\": \"PDB, CATH, CASP13. \\n31,247 non-redundant domains + 104 domains from CASP13 (test).\\nThe number of contacts (positive) and non contacts (negative) is not reported\",\n",
      "            \"dataset/redundancy\": \"Training/Validation: 35% sequence similarity cluster representatives of CATH (Mar 16, 2018). Test set released after 2018. Similarity with Training/Validation unclear\",\n",
      "            \"dataset/splits\": \"Training: 29,247 domains; Validation: 1,820 domains; Test: 104 domains. Number of positive and negative not reported\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b30\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"32300371\",\n",
      "            \"updated\": \"03/08/2022 12:38:13\",\n",
      "            \"authors\": \"Sang X, Xiao W, Zheng H, Yang Y, Liu T\",\n",
      "            \"journal\": \"Comput Math Methods Med\",\n",
      "            \"title\": \"HMMPred: Accurate Prediction of DNA-Binding Proteins Based on HMM Profiles and XGBoost Feature Selection.\",\n",
      "            \"doi\": \"10.1155/2020/1384749\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"bd99b02c-4c88-4e85-b466-4a97ef729643\",\n",
      "        \"shortid\": \"ij8nvrxx7j\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/08/2022 12:38:13\",\n",
      "            \"publication/authors\": \"Sang X, Xiao W, Zheng H, Yang Y, Liu T\",\n",
      "            \"publication/journal\": \"Comput Math Methods Med\",\n",
      "            \"publication/title\": \"HMMPred: Accurate Prediction of DNA-Binding Proteins Based on HMM Profiles and XGBoost Feature Selection.\",\n",
      "            \"optimization/algorithm\": \"Transfer learning with DL to extract features trained with stochastic gradient descent, SVM (linear kernel) for final classification into benign and malignant.\",\n",
      "            \"optimization/encoding\": \"Five preprocessing steps to prepare mammography images (identification of ROI, image and size normalisation, and data augmentation (flipping and rotations). Image size was  224x224x3 \",\n",
      "            \"optimization/features\": \"Handcrafted (455), clinical (5) and DL-based features (1024-dimensional vector) are used in the final classifier. MRMR is used for feature selection, reducing the number of features to 30 Hcr and 27 DL features, next to the clinical ones.\",\n",
      "            \"optimization/fitting\": \"There are 7x744 datapoints for training, yet this seems still limited given the complexity of the DL network to extract features. Not considering the DL, and only the SVM, things look better as the feature set is reduced to 62 features in total, so f > p.\",\n",
      "            \"optimization/meta\": \"Yes, for the DL feature extraction the VGG16 image-net trained network was used in combination with the Inception-V3 network into a fusion network.\",\n",
      "            \"optimization/parameters\": \"The DL has its weights and layers next to the epoch, learning rate, momentum and weight decay parameters.  All parameters for the fusion network were transferred rom VGG16 and Inception V3 into a DL fusion network.  They added three additional FC layers.\",\n",
      "            \"optimization/regularization\": \"SVM hyperparameters were tuned with grid-search and 10-fold cross-validation.  Tests were performed in an independent set and verified in an independent validation set.  Yet no stratification seems to be done.\",\n",
      "            \"model/interpretability\": \"black box due to DL, but relatively transparent in the final classification step with SVM. The question is how interpretable the DL features are.\",\n",
      "            \"model/output\": \"Benign or malignant mass.\",\n",
      "            \"evaluation/comparison\": \"No comparison made with other approaches.\",\n",
      "            \"evaluation/confidence\": \"yes, Dejong's test\",\n",
      "            \"evaluation/measure\": \"Confusion matrix, calculating AUC, accuracy, sensitivity, precision, and F-score. Statistical significance with Delong's test (P<0.05 was considered significant).\",\n",
      "            \"evaluation/method\": \"test set and independent validations set. Cross-validation when determining the optimal configuration of the SVM.\",\n",
      "            \"dataset/availability\": \"No download information provided, but article contains statement that \\\"the data will  be made available without undue reservation\\\"\",\n",
      "            \"dataset/provenance\": \"New cohort of 524 enrolled patients, 988 mammography images divided in 494 malignant and 494 benign masses.Data was preprocessed to be useful for DL work.  An additional validation set from another hospital is also used (58 patients). Not used before\",\n",
      "            \"dataset/redundancy\": \"No stratification effort\",\n",
      "            \"dataset/splits\": \"Data split 744 (training) and 244 (test) in a random manner. No details in Pos/Neg split but assumed to be equal.  \"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b32\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"32298292\",\n",
      "            \"updated\": \"03/23/2022 11:05:15\",\n",
      "            \"authors\": \"Kang AR, Lee J, Jung W, Lee M, Park SY, Woo J, Kim SH\",\n",
      "            \"journal\": \"PLoS One\",\n",
      "            \"title\": \"Development of a prediction model for hypotension after induction of anesthesia using machine learning.\",\n",
      "            \"doi\": \"10.1371/journal.pone.0231172\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"31990540-50aa-4378-b78d-4ee10a62bdda\",\n",
      "        \"shortid\": \"7kuh4ta7dl\",\n",
      "        \"score\": 0.48,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/23/2022 11:05:15\",\n",
      "            \"publication/authors\": \"Kang AR, Lee J, Jung W, Lee M, Park SY, Woo J, Kim SH\",\n",
      "            \"publication/journal\": \"PLoS One\",\n",
      "            \"publication/title\": \"Development of a prediction model for hypotension after induction of anesthesia using machine learning.\",\n",
      "            \"optimization/algorithm\": \"support vector machine (SVM) for which a linear C-SVM algorithm was applied, ii) decision trees, for which a Java open source implementation of the C4.5 algorithm (the J48 algorithm) was used and iii) the Naive Bayes (NB) classifier.\",\n",
      "            \"optimization/features\": \"Features based on cortical thickness (CTH) and hippocampal volumes (HCV) extracted\\nfrom brain scans were used to train the learning algorithms.\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/comparison\": \"Direct, Direct VOI, STAND-score, Atlas, COMPARE, CTH-SVM, CTH-J48, \\n CTH-NB, NTI, ROI, Feature Vector, HCV-SVM, HCV-J48, HCV-NB, Volume- SPM5,\\n Volume-FreeSurfer, Shape. These are machine learning techniques used for mild cognitive\\n impairment patients classification. Accuracy is compared in Table 1 of the paper.\",\n",
      "            \"dataset/availability\": \"Alzheimer \\u2019s Disease Neuroimaging Initiative (ADNI) (http://www.adni-info.org)\",\n",
      "            \"dataset/provenance\": \"Alzheimer \\u2019s Disease Neuroimaging Initiative (ADNI), online database.\\nDataset size: 994. Split into 2 dataset: CTH, n= 650 and HCV, n= 299.\",\n",
      "            \"dataset/splits\": \"CTH test set, n=167, training set n=483. HCV test set n=120, training set n=179.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b33\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"32878308\",\n",
      "            \"updated\": \"03/29/2022 09:10:15\",\n",
      "            \"authors\": \"Yilmaz A, Ugur Z, Bisgin H, Akyol S, Bahado-Singh R, Wilson G, Imam K, Maddens ME, Graham SF\",\n",
      "            \"journal\": \"Metabolites\",\n",
      "            \"title\": \"Targeted Metabolic Profiling of Urine Highlights a Potential Biomarker Panel for the Diagnosis of Alzheimer's Disease and Mild Cognitive Impairment: A Pilot Study.\",\n",
      "            \"doi\": \"10.3390/metabo10090357\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"e2d3109d-c453-483d-8eb9-5fe17cc3bf50\",\n",
      "        \"shortid\": \"tgx5ifo7mb\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/29/2022 09:10:15\",\n",
      "            \"publication/authors\": \"Yilmaz A, Ugur Z, Bisgin H, Akyol S, Bahado-Singh R, Wilson G, Imam K, Maddens ME, Graham SF\",\n",
      "            \"publication/title\": \"Targeted Metabolic Profiling of Urine Highlights a Potential Biomarker Panel for the Diagnosis of Alzheimer's Disease and Mild Cognitive Impairment: A Pilot Study.\",\n",
      "            \"optimization/algorithm\": \"5 algorithms used, LR, SVM, ANN, RF and XGBoost \",\n",
      "            \"optimization/encoding\": \"mRnot reported data for 17 out 48 relevant molecules was used. The values expressed the difference in expression between the cancer and corresponding adjacent tissue.\",\n",
      "            \"optimization/features\": \"17 features corresponding to the most relevant molecules, which were obtained from literature and an additional network analysis based on String. They tested with each ML algorithm all 2^17-1 (131071) feature combinations to see which ones lead to the best predictions. Selection was done on training set (I assume)\",\n",
      "            \"optimization/fitting\": \"No information about parameters of the model and the model implementation.\",\n",
      "            \"optimization/meta\": \"No data is used from other predictors, but the 5 predictors are used together as an ensemble to identify the most predictive features, i.e. the molecules useful for separating cases with good prognosis from bas ones\",\n",
      "            \"optimization/parameters\": \"No details provided about the ML algorithm parameters\",\n",
      "            \"optimization/regularization\": \"not clear.  They claim to have uses cross-validation but it is not explained in detail.\",\n",
      "            \"model/interpretability\": \"both, they used LR as well as ANN.\",\n",
      "            \"model/output\": \"Classification that is used to determine the most relevant set of features out of all 2^17-1 combinations.\",\n",
      "            \"evaluation/comparison\": \"No comparison is made, as this is not the main point of this paper.\",\n",
      "            \"evaluation/measure\": \"Only AUC was reported for the classifier, which is not the most suitable measure.\",\n",
      "            \"evaluation/method\": \"They claim to have used crossvalidation but it is not explained. They use independent sets to test their findings and to relate the survival of patients to these findings.\",\n",
      "            \"dataset/availability\": \"GEO and TCGA data is available. The 86 clinical cases are not reported, neither is the code provided for the ML part of the paper\",\n",
      "            \"dataset/provenance\": \"Pubmed for relevant molecules (48 mol based on 38 articles), GEO (GSE53625 179 data points), TCGA (TCGA-ESCC 82 data points, 37 used for validation) and own clinical samples (86 samples)\",\n",
      "            \"dataset/redundancy\": \"No mention made. Separation appears to be done randomly for the GEO set.  All the rest was used as validation.  No mention about the overlap between the sets.\",\n",
      "            \"dataset/splits\": \"179 split into 134 training and 45 testing ESCC cases (randomly), 17 out of 48 moulecues were used as features for the classification.  ESCC cases with survival times more than 3 years were labelled 1 and the others were labelled 0, no information about the number in each set.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b4f\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"32933477\",\n",
      "            \"updated\": \"01/18/2022 17:50:21\",\n",
      "            \"authors\": \"Klosa J, Simon N, Westermark PO, Liebscher V, Wittenburg D\",\n",
      "            \"journal\": \"BMC Bioinformatics\",\n",
      "            \"title\": \"Seagull: lasso, group lasso and sparse-group lasso regularization for linear regression models via proximal gradient descent.\",\n",
      "            \"doi\": \"10.1186/s12859-020-03725-w\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"e9544652-63df-4961-abc7-af965754adc8\",\n",
      "        \"shortid\": \"25pxfm641i\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"01/18/2022 17:50:21\",\n",
      "            \"publication/authors\": \"Klosa J, Simon N, Westermark PO, Liebscher V, Wittenburg D\",\n",
      "            \"publication/journal\": \"BMC Bioinformatics\",\n",
      "            \"publication/title\": \"Seagull: lasso, group lasso and sparse-group lasso regularization for linear regression models via proximal gradient descent.\",\n",
      "            \"optimization/algorithm\": \"SVM with RBF kernel\",\n",
      "            \"optimization/config\": \"partially - only some hyper-parameters are given in the text\",\n",
      "            \"optimization/encoding\": \"global features\",\n",
      "            \"optimization/features\": \"originally over 433; 39 after \\\"parameter optimisation\\\"; further reduced to 21 by max-relevance-max-distance algorithm\",\n",
      "            \"optimization/parameters\": \"39 or 21 (after dimension reduction using max-relevance-max-distance)\",\n",
      "            \"optimization/regularization\": \"yes, L2 regularisation\",\n",
      "            \"model/duration\": \"not given but should be instant\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"binary classification\",\n",
      "            \"evaluation/availability\": \"no raw evaluation files; confusion matrix is in the text\",\n",
      "            \"evaluation/measure\": \"Recall, Precision, Accuracy, MCC\",\n",
      "            \"evaluation/method\": \"5-fold CV; independent test set\",\n",
      "            \"dataset/availability\": \"yes, https://github.com/taozhy/identifying-vesicle-transport-proteins\",\n",
      "            \"dataset/provenance\": \"based on UniProt search; dataset published in 2019; 2533 pos and 9086 neg\",\n",
      "            \"dataset/redundancy\": \"The original data was processed by BLAST to get the sequence similarity to less than 30%; the test set was used before.\",\n",
      "            \"dataset/splits\": \"Train: 2214 (pos) and 2214 (neg) -> 5-fold CV; test 319 (pos) 1513 (neg);\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b50\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33329703\",\n",
      "            \"updated\": \"02/16/2022 09:43:09\",\n",
      "            \"authors\": \"Tian Y, Wang J, Qin C, Zhu G, Chen X, Chen Z, Qin Y, Wei M, Li Z, Zhang X, Lv Y, Cai G\",\n",
      "            \"journal\": \"Front Genet\",\n",
      "            \"title\": \"Identifying 8-mRNAsi Based Signature for Predicting Survival in Patients With Head and Neck Squamous Cell Carcinoma via Machine Learning.\",\n",
      "            \"doi\": \"10.3389/fgene.2020.566159\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"3785a62f-b82d-40db-9c45-88dbe0b8582f\",\n",
      "        \"shortid\": \"hlpvh7cgmc\",\n",
      "        \"score\": 0.48,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/16/2022 09:43:09\",\n",
      "            \"publication/authors\": \"Tian Y, Wang J, Qin C, Zhu G, Chen X, Chen Z, Qin Y, Wei M, Li Z, Zhang X, Lv Y, Cai G\",\n",
      "            \"publication/journal\": \"Front Genet\",\n",
      "            \"publication/title\": \"Identifying 8-mRNAsi Based Signature for Predicting Survival in Patients With Head and Neck Squamous Cell Carcinoma via Machine Learning.\",\n",
      "            \"optimization/algorithm\": \"Variant of random forest regression\",\n",
      "            \"optimization/config\": \"Hyperparameters reported in the paper\",\n",
      "            \"optimization/encoding\": \"Counts of all possible 3- to 8-letter-long sequence motifs present in the 5= and 3= UTRs\",\n",
      "            \"optimization/features\": \"200,000 features for UTR sequence motif analysis / using a random subset of features to identify the best candidate feature for splitting at each node\",\n",
      "            \"model/interpretability\": \"Transparent, T rich UTRs provide stability\",\n",
      "            \"dataset/availability\": \"Yes, https://www.ncbi.nlm.nih.gov/sra/SRP130967 (Sequences) https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE109174 (transcripts half-life)\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b51\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33324147\",\n",
      "            \"updated\": \"03/01/2022 14:21:27\",\n",
      "            \"authors\": \"Liu W, Zhang X, Qiao Y, Cai Y, Yin H, Zheng M, Zhu Y, Wang H\",\n",
      "            \"journal\": \"Front Neurosci\",\n",
      "            \"title\": \"Functional Connectivity Combined With a Machine Learning Algorithm Can Classify High-Risk First-Degree Relatives of Patients With Schizophrenia and Identify Correlates of Cognitive Impairments.\",\n",
      "            \"doi\": \"10.3389/fnins.2020.577568\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"0f17c012-ed0e-4766-801b-39bb206b5767\",\n",
      "        \"shortid\": \"caz69j3bqb\",\n",
      "        \"score\": 0.52,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/01/2022 14:21:27\",\n",
      "            \"publication/authors\": \"Liu W, Zhang X, Qiao Y, Cai Y, Yin H, Zheng M, Zhu Y, Wang H\",\n",
      "            \"publication/journal\": \"Front Neurosci\",\n",
      "            \"publication/title\": \"Functional Connectivity Combined With a Machine Learning Algorithm Can Classify High-Risk First-Degree Relatives of Patients With Schizophrenia and Identify Correlates of Cognitive Impairments.\",\n",
      "            \"optimization/algorithm\": \"Random Forest + Network Embedding  + Network Similarity\",\n",
      "            \"optimization/parameters\": \"3, Random Forest\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/comparison\": \"DeepWalk, Line, Node2Vec, GraRep, GF, Lap, lle (all Network Embedding methods)\",\n",
      "            \"evaluation/measure\": \"ROC-AUC, PR_AUC, Precision, Accuracy, F1, Recall\",\n",
      "            \"evaluation/method\": \"Cross validation\",\n",
      "            \"dataset/provenance\": \"Database HMDD3.0 (http://www.cuilab.cn/hmdde)\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b52\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33133228\",\n",
      "            \"updated\": \"03/07/2022 10:25:36\",\n",
      "            \"authors\": \"Tao Z, Li Y, Teng Z, Zhao Y\",\n",
      "            \"journal\": \"Comput Math Methods Med\",\n",
      "            \"title\": \"A Method for Identifying Vesicle Transport Proteins Based on LibSVM and MRMD.\",\n",
      "            \"doi\": \"10.1155/2020/8926750\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"827777a1-d886-4bc3-b9c3-91083dffda4f\",\n",
      "        \"shortid\": \"43nakaafp9\",\n",
      "        \"score\": 0.38,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/07/2022 10:25:36\",\n",
      "            \"publication/authors\": \"Tao Z, Li Y, Teng Z, Zhao Y\",\n",
      "            \"publication/journal\": \"Comput Math Methods Med\",\n",
      "            \"publication/title\": \"A Method for Identifying Vesicle Transport Proteins Based on LibSVM and MRMD.\",\n",
      "            \"optimization/features\": \"584, SVM-recursive feature elimination used for feature selection on training data only.\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"Binary predictions\",\n",
      "            \"evaluation/measure\": \"sensitivity, specificity, AUC-ROC curve\",\n",
      "            \"evaluation/method\": \"Independent dataset\",\n",
      "            \"dataset/provenance\": \"CT images from a total of 739 patients with gastric cancer. \",\n",
      "            \"dataset/splits\": \"286 training - 453 validation No info on N_pos and N_neg immediately available \"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b53\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"32324731\",\n",
      "            \"updated\": \"03/08/2022 15:42:05\",\n",
      "            \"authors\": \"Chen Q, Lee K, Yan S, Kim S, Wei CH, Lu Z\",\n",
      "            \"journal\": \"PLoS Comput Biol\",\n",
      "            \"title\": \"BioConceptVec: Creating and evaluating literature-based biomedical concept embeddings on a large scale.\",\n",
      "            \"doi\": \"10.1371/journal.pcbi.1007617\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"35561cc1-0576-4757-b30f-5bcd7b65ce52\",\n",
      "        \"shortid\": \"yuk8w6yxtm\",\n",
      "        \"score\": 0.48,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/08/2022 15:42:05\",\n",
      "            \"publication/authors\": \"Chen Q, Lee K, Yan S, Kim S, Wei CH, Lu Z\",\n",
      "            \"publication/journal\": \"PLoS Comput Biol\",\n",
      "            \"publication/title\": \"BioConceptVec: Creating and evaluating literature-based biomedical concept embeddings on a large scale.\",\n",
      "            \"optimization/algorithm\": \"Random Forests\",\n",
      "            \"optimization/encoding\": \"Rnot reported-Seq expression values in transcripts per million (TPM) were log2-transformed and normalized. \\nEstimation of relative immune cell relative infiltration and abundance  by using the method single\\u2011sample gene set enrichment analysis (ssGSEA) which identified gene sets from the Molecular Signatures Database that were enriched in TNBC Rnot reported-Seq data. 28 heterogeneous immune cells were classified according to gene sets. The degree of immune cell infiltration was determined by the ssGSEA scores. The immune signature was clustered into 3 populations, namely high\\u2011, medium\\u2011 and low\\u2011infiltration.\",\n",
      "            \"optimization/features\": \"Hundreds of variants, TMB data, were employed as input parameters, including the relative infiltration of the 28 types of heterogenous immune cells, somatic mutation counts, 78 immune\\u2011related molecules, and 50 signaling pathways from the HALLMARK collection. In total 782 features were used to assess cytolytic activity (CYT).\",\n",
      "            \"model/interpretability\": \"Feature importance score, relative contribution of each factor to the resulting immune response, for determining the most important features for CYT.\",\n",
      "            \"model/output\": \"Multi-label predictions\",\n",
      "            \"evaluation/comparison\": \"Factors that were associated with immune response in this analysis were consistent with established knowledge on antitumor immunity.\",\n",
      "            \"evaluation/confidence\": \"OOB samples providing estimates of model error rate for the decision trees.\",\n",
      "            \"evaluation/measure\": \"Out of bag (OOB) scores\",\n",
      "            \"dataset/availability\": \"The datasets generated and/or analyzed during the present\\nstudy are available in the TCGA database.\",\n",
      "            \"dataset/provenance\": \"Rnot reported-Seq expression values of immune regulatory molecules, including CTLA\\u20114, IDO1, LAG3, PDCD1, PDL1 and TIM3 across four types of breast cancer (HER2, luminal A, luminal B and TNBC) from The Cancer Genome Atlas (TCGA) database.\\nData for tumor mutation burden (TMB) from TCGA database.\\n\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b54\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33328863\",\n",
      "            \"updated\": \"03/15/2022 11:03:41\",\n",
      "            \"authors\": \"La Rocca M, Garner R, Amoroso N, Lutkenhoff ES, Monti MM, Vespa P, Toga AW, Duncan D\",\n",
      "            \"journal\": \"Front Neurosci\",\n",
      "            \"title\": \"Multiplex Networks to Characterize Seizure Development in Traumatic Brain Injury Patients.\",\n",
      "            \"doi\": \"10.3389/fnins.2020.591662\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"5a5db1d1-8e51-4dca-aee1-ec8f06e46300\",\n",
      "        \"shortid\": \"5iyltalim1\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/15/2022 11:03:41\",\n",
      "            \"publication/authors\": \"La Rocca M, Garner R, Amoroso N, Lutkenhoff ES, Monti MM, Vespa P, Toga AW, Duncan D\",\n",
      "            \"publication/journal\": \"Front Neurosci\",\n",
      "            \"publication/title\": \"Multiplex Networks to Characterize Seizure Development in Traumatic Brain Injury Patients.\",\n",
      "            \"optimization/algorithm\": \"Support Vector Machine with Linear kernel (Linear SVM)\",\n",
      "            \"optimization/encoding\": \"The subjects\\u2019 brains were parcellated into 200 regions of interest (ROIs) using the Craddock atlas. \\u03a4he RS-fMRI data were preprocessed to calculate FC measures between each pair of ROIs. \\nFriston-24 parameters were used to regress out the effects of head motion. To further reduce the effects of nuisance factors, signals from cerebrospinal fluid and white matter were also regressed out. \\nDARTEL toolbox was used to normalize the data and the resulting images were finally smoothed with a 6-mm full width at half maximum (FWHM) Gaussian kernel.\\nThe time series within each ROI were first band-pass filtered (0.01\\u20130.08 Hz) and then averaged. For each participant, FC was calculated between each ROI using Pearson\\u2019s correlation coefficients, resulting in 19900-dimensional FC feature vectors for each subject.\\nPatients with SCZ were labeled as 1, and HCs were labeled as -1.\\n\",\n",
      "            \"optimization/features\": \"FC measurements between each pair of the 200 brain ROIs were used as classification features. Feature selection was performed for data dimension reduction using F-score for feature ranking. The 644 highest-ranked FC features were used to build the classifier.\",\n",
      "            \"optimization/parameters\": \"Linear SVM was implemented using the LIBSVM toolbox with the parameter C set to the default value of 1.\",\n",
      "            \"optimization/regularization\": \"Yes. Linear SVM with C=1 and feature selection for data dimension reduction were selected to avoid overfitting.\",\n",
      "            \"model/interpretability\": \"Feature weight extraction from the Linear SVM model and feature selection for data dimension reduction, using F-score for feature ranking, were performed to interpret feature importance. This allowed for the identification of the 18 ROIs having weights that were at least 1 standard deviation greater than the average of the weights of all regions, thus making the greatest contribution to the model.\",\n",
      "            \"model/output\": \"1) Binary predictions.\\n 2) Classification score, which is the average of the 76 prediction labels. From a range of -1 to 1, a positive score indicates a SCZ pattern, and a negative score indicates a HC pattern. Binary predictions.\",\n",
      "            \"evaluation/confidence\": \"1) Permutation statistical testing.\\n 2) Semantic fluency test (animal version) was administered to evaluate the executive function and the semantic memory, which are severely affected in SCZ. The performance was analyzed using the number of correct words within 1 min. Statistical testing of the correlation between classification score and semantic fluency scores of FDR participants.\",\n",
      "            \"evaluation/measure\": \"Accuracy, sensitivity, specificity, ROC curve, AUC score.\",\n",
      "            \"evaluation/method\": \"Leave one-out cross-validation (LOOCV).\\n Independent dataset of 142 features obtained by masking DMN, FP, auditory, and sensorimotor brain networks. Similar training of a Linear SVM classifier and evaluation of the resulting metrics.\",\n",
      "            \"dataset/availability\": \"Declared availability upon request.\",\n",
      "            \"dataset/provenance\": \"Functional connectivity (FC) patterns obtained from resting-state functional magnetic resonance imaging (RS-fMRI).\\n1)\\tNpos=38 Schizophrenia (SCZ) patients and Nneg=38 healthy controls (HC)\\n2)\\tThe produced classifier was applied to Ntest=38 high-risk first-degree relatives (FDRs) to predict their cognitive performance.\\n\",\n",
      "            \"dataset/splits\": \"Leave one- out cross-validation, with Ntrain=37 and Ntest=1 for each iteration.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b55\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"32915751\",\n",
      "            \"updated\": \"03/28/2022 12:23:43\",\n",
      "            \"authors\": \"Wang Z, Liu Q, Dou Q\",\n",
      "            \"journal\": \"IEEE J Biomed Health Inform\",\n",
      "            \"title\": \"Contrastive Cross-Site Learning With Redesigned Net for COVID-19 CT Classification.\",\n",
      "            \"doi\": \"10.1109/JBHI.2020.3023246\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"2598df6d-6714-4983-8db6-20a2fe1309b4\",\n",
      "        \"shortid\": \"opx6a1juph\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/28/2022 12:23:43\",\n",
      "            \"publication/authors\": \"Wang Z, Liu Q, Dou Q\",\n",
      "            \"publication/journal\": \"IEEE J Biomed Health Inform\",\n",
      "            \"publication/title\": \"Contrastive Cross-Site Learning With Redesigned Net for COVID-19 CT Classification.\",\n",
      "            \"optimization/algorithm\": \"a version of Lasso-penalized Cox regression\",\n",
      "            \"optimization/encoding\": \"filtering of data points and features (SNPs)\",\n",
      "            \"optimization/features\": \"f = 533 000 SNPs; SNPs in linkage disequilibrium were removed, using a correlation threshold of 0.1 and resulting in 108 254 features (not clear if this was done only based on the training data). \",\n",
      "            \"optimization/parameters\": \"not reported explicitly; should be at least n+n^2 for n=108 254\",\n",
      "            \"optimization/regularization\": \"Yes: lasso + selecting only the SNPs involved in the top 1000 one-way and all the SNPs from the top 1000 two-way interactions models based on 2-fold CV.\",\n",
      "            \"model/interpretability\": \"transparent: identification of genes\",\n",
      "            \"evaluation/comparison\": \"Only comparison against previous state-of-the-art method, Survival MDR (Surv-MDR)\",\n",
      "            \"evaluation/confidence\": \"None for the model for the real data; two simulation studies were created to estimate the 5% type I error and power; the significance of the selected models (intermediate step) was evaluated by a 10000-fold permutation test.\",\n",
      "            \"evaluation/measure\": \"time-dependent ROC and its AUC\",\n",
      "            \"evaluation/method\": \"2-fold cross validation + independent test set.\",\n",
      "            \"dataset/availability\": \"Only unfiltered data: NCBI dbGaP repository phs001273.v3.p2, https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs001273.v3.p2.\",\n",
      "            \"dataset/provenance\": \"Originally, there were 533,631 SNPs from 57,775 individuals in the OncoArray-TRICL Consortium population-based study. The filtered data had 27722 individuals (14935 positive and 12787 negative cases). Two simulated datasets were also used to evaluate the type I error rate and power. \",\n",
      "            \"dataset/redundancy\": \"None between the splits, but participants who were close relatives (second degree relatives or closer) and duplicate individuals were filtered out from the beginning.\",\n",
      "            \"dataset/splits\": \"random sampling: 2/3 into a training set and 1/3 into the testing set; 2-fold cross-validation\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b6f\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33240258\",\n",
      "            \"updated\": \"02/09/2022 15:02:29\",\n",
      "            \"authors\": \"Jia J, Wang M, Ma Y, Teng J, Shi H, Liu H, Sun Y, Su Y, Meng J, Chi H, Chen X, Cheng X, Ye J, Liu T, Wang Z, Wan L, Zhou Z, Wang F, Yang C, Hu Q\",\n",
      "            \"journal\": \"Front Immunol\",\n",
      "            \"title\": \"Circulating Neutrophil Extracellular Traps Signature for Identifying Organ Involvement and Response to Glucocorticoid in Adult-Onset Still's Disease: A Machine Learning Study.\",\n",
      "            \"doi\": \"10.3389/fimmu.2020.563335\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"59ef281d-0bee-4188-a2b4-10dd495bb666\",\n",
      "        \"shortid\": \"f66mtky2wk\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/09/2022 15:02:29\",\n",
      "            \"publication/authors\": \"Jia J, Wang M, Ma Y, Teng J, Shi H, Liu H, Sun Y, Su Y, Meng J, Chi H, Chen X, Cheng X, Ye J, Liu T, Wang Z, Wan L, Zhou Z, Wang F, Yang C, Hu Q\",\n",
      "            \"publication/journal\": \"Front Immunol\",\n",
      "            \"publication/title\": \"Circulating Neutrophil Extracellular Traps Signature for Identifying Organ Involvement and Response to Glucocorticoid in Adult-Onset Still's Disease: A Machine Learning Study.\",\n",
      "            \"optimization/algorithm\": \"Multi-Layer Perceptron \",\n",
      "            \"optimization/regularization\": \"No, high ratio between the number of experimental values in the training and number of parameters in the model \",\n",
      "            \"model/availability\": \"Supplementary information\",\n",
      "            \"model/duration\": \"about 13 minutes\",\n",
      "            \"model/interpretability\": \"Black Box\",\n",
      "            \"evaluation/comparison\": \"Neural Network with two hidden layers, k-nearest neighbors, Random Forest, SVM\",\n",
      "            \"evaluation/confidence\": \"Confidence intervals\",\n",
      "            \"evaluation/measure\": \"Confusion matrix\",\n",
      "            \"dataset/availability\": \"Support information files.\",\n",
      "            \"dataset/provenance\": \"Database CATnot reportedP http://hiv.lanl.gov/catnap\",\n",
      "            \"dataset/splits\": \"3864 exact IC50 values are split randomly in half into a training set and a validation set.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b70\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"32218835\",\n",
      "            \"updated\": \"03/02/2022 11:14:34\",\n",
      "            \"authors\": \"Cheng J, Ding X, Xu S, Zhu B, Jia Q\",\n",
      "            \"journal\": \"Oncol Lett\",\n",
      "            \"title\": \"Gene expression profiling identified TP53<sup>Mut</sup>PIK3CA<sup>Wild</sup> as a potential biomarker for patients with triple-negative breast cancer treated with immune checkpoint inhibitors.\",\n",
      "            \"doi\": \"10.3892/ol.2020.11381\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"94f52be3-39fa-4f72-9fc2-9ab4ae112839\",\n",
      "        \"shortid\": \"st1jp9fgiv\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/02/2022 11:14:34\",\n",
      "            \"publication/authors\": \"Cheng J, Ding X, Xu S, Zhu B, Jia Q\",\n",
      "            \"publication/journal\": \"Oncol Lett\",\n",
      "            \"publication/title\": \"Gene expression profiling identified TP53<sup>Mut</sup>PIK3CA<sup>Wild</sup> as a potential biomarker for patients with triple-negative breast cancer treated with immune checkpoint inhibitors.\",\n",
      "            \"optimization/algorithm\": \"Several methods are tested to find the optimal feature subset for classification (see fig1 in the paper). Includes multi-layer perceptrons, random forest, SVM and a combination of a VAE with a MLP.\",\n",
      "            \"optimization/config\": \"some parts yes, other parts no\",\n",
      "            \"optimization/encoding\": \"not reported in this article (ref to earlier article)\",\n",
      "            \"optimization/features\": \"230 features, wrapper method with cross-validation to find the optimal subset.  VAE extraction applied also to data to identify other features\",\n",
      "            \"optimization/fitting\": \"double loop of cross validation (5-fold) and ,multiple runs to obtain statistically robust results. \",\n",
      "            \"optimization/meta\": \"not meta-predictions, everything is performed on the raw data. \",\n",
      "            \"optimization/parameters\": \"Not all details provided about the parameters for each model. RF optimised by verifying different depths (yet number of trees was not mentioned). No details about SVM. VAE and MLP are shown in figures\",\n",
      "            \"model/interpretability\": \"dependent on the classification approach. Most relevant features are explained. An expert should be able to get some understanding from the remaining features, yet interpreting the latent variables produced by the VAE will be complicated.\",\n",
      "            \"model/output\": \"binary prediction\",\n",
      "            \"evaluation/comparison\": \"no other methods compared\",\n",
      "            \"evaluation/confidence\": \"DeLong method to compare AUC's\",\n",
      "            \"evaluation/measure\": \"average AUC\",\n",
      "            \"evaluation/method\": \"double loop of cross-validations and multiple repeats to overcome the imbalance in the data set.\",\n",
      "            \"dataset/availability\": \"no \",\n",
      "            \"dataset/provenance\": \"106 patients with non small cell lung cancer, 22 positive (>=2) long radiation pneumotis and 84 (<2) negative patients. Each patient is annotated with 230 features. Patient data comes from another publication 28237401. Data does not seem to be downloadable.\",\n",
      "            \"dataset/splits\": \"System of inner and outer cross validation (5-fold) with multiple repeats of both loops. Distributions across sets or stratifications were not reported\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b71\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"32753502\",\n",
      "            \"updated\": \"03/04/2022 17:00:53\",\n",
      "            \"authors\": \"Gordon GC, Cameron JC, Gupta STP, Engstrom MD, Reed JL, Pfleger BF\",\n",
      "            \"journal\": \"mSystems\",\n",
      "            \"title\": \"Genome-Wide Analysis of RNA Decay in the Cyanobacterium <i>Synechococcus</i> sp. Strain PCC 7002.\",\n",
      "            \"doi\": \"10.1128/mSystems.00224-20\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"52d91d41-3b36-4240-bf74-f433787be438\",\n",
      "        \"shortid\": \"21vzta5ft2\",\n",
      "        \"score\": 0.33,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/04/2022 17:00:53\",\n",
      "            \"publication/authors\": \"Gordon GC, Cameron JC, Gupta STP, Engstrom MD, Reed JL, Pfleger BF\",\n",
      "            \"publication/title\": \"Genome-Wide Analysis of RNA Decay in the Cyanobacterium <i>Synechococcus</i> sp. Strain PCC 7002.\",\n",
      "            \"optimization/algorithm\": \"Random forest\",\n",
      "            \"model/interpretability\": \"Transparent. 12 metabolites were determined to be informative for MS status\",\n",
      "            \"evaluation/method\": \"Other experiments and literature.\",\n",
      "            \"dataset/provenance\": \"Untargeted two-dimensional gas chromatography and time-of-flight mass spectrometry. 12_pos and 13_neg\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b72\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33039708\",\n",
      "            \"updated\": \"03/27/2022 23:10:49\",\n",
      "            \"authors\": \"Bitencourt AGV, Gibbs P, Rossi Saccarelli C, Daimiel I, Lo Gullo R, Fox MJ, Thakur S, Pinker K, Morris EA, Morrow M, Jochelson MS\",\n",
      "            \"journal\": \"EBioMedicine\",\n",
      "            \"title\": \"MRI-based machine learning radiomics can predict HER2 expression level and pathologic response after neoadjuvant therapy in HER2 overexpressing breast cancer.\",\n",
      "            \"doi\": \"10.1016/j.ebiom.2020.103042\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"d6512a82-bc58-4d38-a7de-a80eecdc7a16\",\n",
      "        \"shortid\": \"4zvfuyfezh\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/27/2022 23:10:49\",\n",
      "            \"publication/authors\": \"Bitencourt AGV, Gibbs P, Rossi Saccarelli C, Daimiel I, Lo Gullo R, Fox MJ, Thakur S, Pinker K, Morris EA, Morrow M, Jochelson MS\",\n",
      "            \"publication/title\": \"MRI-based machine learning radiomics can predict HER2 expression level and pathologic response after neoadjuvant therapy in HER2 overexpressing breast cancer.\",\n",
      "            \"optimization/algorithm\": \"SVM, random forest, ensemble learning\",\n",
      "            \"optimization/config\": \"Some hyperparameters are given in the text.\",\n",
      "            \"optimization/encoding\": \"Global features\",\n",
      "            \"optimization/features\": \"PCA to capture at least 70%, projected to the range of 10-20 features \",\n",
      "            \"optimization/parameters\": \"Forced to be in the range of 10-20 + 4 (for SVM) by PCA to capture at least 70%\",\n",
      "            \"model/availability\": \"https://github.com/SydneyBioX/scReClassify; https://bioconductor.org/packages/release/bioc/html/scReClassify.html; GPL-3 license\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"multi-class reclassification (error correction)\",\n",
      "            \"evaluation/measure\": \"mean classification accuracy; adjusted Rand index\",\n",
      "            \"evaluation/method\": \"Training data only\",\n",
      "            \"dataset/availability\": \"yes for real-world data: https://www.ebi.ac.uk/arrayexpress/help/GEO_data.html (ids E-MTAB-3929, GSE87795, GSE60361, GSE82187)\",\n",
      "            \"dataset/provenance\": \"Simulated and real-world experimental scRnot reported-seq datasets: the simulated sets had 100 points for each of 3, 5, 7, or 9 classes. The real-world sets were 4 from literature (1059 points with 3 classes, 367 points with 6 classes, 3005 points with 7 classes and 705 points for 10 classes). Some of the labels of all the datasets were artificially corrupted.\",\n",
      "            \"dataset/splits\": \"multiple AdaSampling (self-supervision) \"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b7f\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33126877\",\n",
      "            \"updated\": \"02/23/2022 08:54:37\",\n",
      "            \"authors\": \"Luyapan J, Ji X, Li S, Xiao X, Zhu D, Duell EJ, Christiani DC, Schabath MB, Arnold SM, Zienolddiny S, Brunnstr\\u00f6m H, Melander O, Thornquist MD, MacKenzie TA, Amos CI, Gui J\",\n",
      "            \"journal\": \"BMC Med Genomics\",\n",
      "            \"title\": \"A new efficient method to detect genetic interactions for lung cancer GWAS.\",\n",
      "            \"doi\": \"10.1186/s12920-020-00807-9\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"82cf0bf2-90df-48f5-9e3f-8671010c3fc3\",\n",
      "        \"shortid\": \"58820ywq9x\",\n",
      "        \"score\": 0.86,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/23/2022 08:54:37\",\n",
      "            \"publication/authors\": \"Luyapan J, Ji X, Li S, Xiao X, Zhu D, Duell EJ, Christiani DC, Schabath MB, Arnold SM, Zienolddiny S, Brunnstr\\u00f6m H, Melander O, Thornquist MD, MacKenzie TA, Amos CI, Gui J\",\n",
      "            \"publication/journal\": \"BMC Med Genomics\",\n",
      "            \"publication/title\": \"A new efficient method to detect genetic interactions for lung cancer GWAS.\",\n",
      "            \"optimization/algorithm\": \"Random forest, Support Vector Machine (SVM), and SVM with LASSO feature selection.\",\n",
      "            \"optimization/config\": \"Yes. GitHub website. https://github.com/ShenLab/episcore\",\n",
      "            \"optimization/encoding\": \"For promoter features (H2A.Z, H3K27me3, H3K4me3, and H3K9ac), GappedPeaks were used to allow for broad domains of ChIP-seq signal. The assignment of a GapppedPeak to a gene followed these steps in order: \\n1)\\tFor each gene, only TSS of Ensembl canonical transcripts were used.\\n2)\\tA GappedPeak was assigned to a TSS if the GappedPeak overlaps with the upstream 5 kb to downstream 1 kb region around the TSS. This definition of basal cis-regulatory region around promoter was according to GREAT tool. Assigning one GappedPeak to multiple TSS was allowed.\\n3)\\tFor TSS having more than 1 GappedPeak assigned, only the closest one was kept.\\n4)\\tFor genes with multiple TSS and hence multiple assigned GappedPeaks, only the longest GappedPeak was kept.\\nAfter these four steps, if one gene had been associated with a GappedPeak, then the width of the peak was used as an epigenomic feature in the following machine learning models. If a gene had no associated GappedPeak, then the peak width is 0.\\n\\nCoverage of H3K27ac, H3K27me3, H3K36me3, H3K4me1, H3K4me3, H3K9me3, DNase I, and Rnot reported-seq data was used as input for EpiTensor to infer interacting enhancers across distant genomic regions. This was done as balance between more input data types and more cell types included, as not every cell type has all these histone modifications characterized.\\n\",\n",
      "            \"optimization/features\": \"The widths of called ChIP-seq peaks was used as promoter features. The counts of the interacting number of promoters and enhancers within pre-defined topologically associated domains (TADs) as enhancer features.\\nSpecifically, the results of peak width and number of interacting enhancers were consolidated into a matrix, with each row being a gene and each column representing a combination of a tissue and a data type, e.g. \\u201cH3K4me3 peak width in fetal heart\\u201d. One combination of a tissue and a data type was referred to as one epigenomic feature. This matrix was used as input for the machine learning models.\\n\",\n",
      "            \"optimization/parameters\": \"Alpha parameter equal to 1 for Lasso regularization. No further parameters were specified.\",\n",
      "            \"optimization/regularization\": \"Yes. LASSO regularization was used with SVM for overfitting prevention.\",\n",
      "            \"model/availability\": \"Yes. GitHub website. https://github.com/ShenLab/episcore\",\n",
      "            \"model/interpretability\": \"Epigenomic features critical for the prediction were determined by calculating a Spearman correlation coefficient between each epigenomic feature and Episcore (random forest model) prediction. \\n One epigenomic feature corresponds to a data type per certain tissue/cell type. To examine which data types are more important, these Spearman correlation coefficients were plotted by data type. \\n To examine what tissue/cell types are more important, the averaged z-score for each tissue/cell type was calculated by:\\n 1) Converting every Spearman correlation coefficient to a Z-score using mean and standard deviation specific to each data type and\\n 2) Average Z-scores from various data types for each tissue/cell type.\\n This analysis indicated that epigenomic features in stem cells, brain tissues, and fetal tissues contribute more to Episcore prediction than other features.\",\n",
      "            \"model/output\": \"Binary predictions. All training genes used to train the best performing Random Forest model, and then estimate the probabilities of being positive (HIS) for all genes. The whole process was repeated 30 times and the arithmetic mean of the 30 sets of probabilities was used as result.\",\n",
      "            \"evaluation/availability\": \"Yes. Supplementary Data.\",\n",
      "            \"evaluation/comparison\": \"Random Forest model performed better than SVM and SVM with Lasso, and it was chosen for training the final model (Episcore).\\n Comparison of Episcore with pLI scores from ExAC, Shet values, and ranks of mouse heart expression level, using de novo likely-gene-disrupting (LGD) variants identified in:\\n 1) A previously published whole exome sequencing study DDD (Deciphering Developmental Disorders consortium) of 1365 trio families with congenital heart disease (CHD).\\n 2) A second CHD WES cohort of 2645 parent\\u2212offspring trios from the Pediatric Cardiac Genomics Consortium (PCGC).\\n LGD variants include frameshift, nonsense and canonical splice site\\n mutations. Episcore achieved better performance in prioritizing LGD de novo variants than the other methods.\",\n",
      "            \"evaluation/confidence\": \"Permutation testing.\",\n",
      "            \"evaluation/measure\": \"ROC curve, AUC score, sensitivity, specificity\",\n",
      "            \"evaluation/method\": \"1) 100 randomized runs with Ntrain=90% and Ntest=10% for each run. 10-fold cross validation was applied.\\n 2) For the best performing model (Random Forest) all training data were used to train the final model.\",\n",
      "            \"dataset/availability\": \"Yes. Supplementary Data.\",\n",
      "            \"dataset/provenance\": \"ChIP-seq data, including uniformly processed peak calling results and peak width of promoter histone modifications from Roadmap and ENCODE projects for active (H3K4me3, H3K9ac, and H2A.Z) and repressive (H3K27me3) promoter modifications, and marks associated with enhancers (H3K4me1, H3K27ac, DNase I hypersensitivity sites). \\n\\nCurated haploinsufficient (HIS) genes, positive (Npos) training observations, were collected from haploinsufficient training genes used in previous studies and genes with haploinsufficient score of 3 in ClinGen Dosage Sensitivity Map.\\n\\nCurated haplosufficient (HS) genes, negative (Nneg) training observations, included genes deleted in two or more healthy people, based on CNVs detected in 2026 normal individuals.\\n\\nAll data were used in previous studies.\\n\",\n",
      "            \"dataset/redundancy\": \"Only genes with half or more of its length covered by any deletion were considered \\u201cdeleted\\u201d (HS genes) in an individual.\\n\\nThe initial raw training may have included some false positive and false negative genes, as it contained results from automated literature mining that is known to give noisy output. To optimize the performance, the following pruning of the raw training set was performed: \\n\\n1)\\tOnly protein-coding genes in autosomes were kept, as non-protein coding genes or genes on sex chromosomes may be under different mechanism of epigenomic regulation.\\n2)\\tFrom the positive training set, genes with sufficient contradictory evidence were removed (ExAC pLI \\u2264 0.1 and expected loss-of-function variants >1011).\\n3)\\tFrom the negative training set, genes with sufficient contradictory evidence (pLI \\u2265 0.2 and expected loss-of-function variants>10) were removed.\\n\",\n",
      "            \"dataset/splits\": \"Following pruning for the training set, Npos=287 curated haploinsufficient genes and Nneg=574 curated haplosufficient genes were considered for further analysis.\\n1)\\tNtrain=90%. Ntest=10%. 10-fold cross validation for training. 100 randomized runs.\\n2)\\tFinal training with all training data and estimation of probabilities.\\n\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b80\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"32681213\",\n",
      "            \"updated\": \"03/12/2022 19:15:18\",\n",
      "            \"authors\": \"Pulliam L, Liston M, Sun B, Narvid J\",\n",
      "            \"journal\": \"J Neurovirol\",\n",
      "            \"title\": \"Using neuronal extracellular vesicles and machine learning to predict cognitive deficits in HIV.\",\n",
      "            \"doi\": \"10.1007/s13365-020-00877-6\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"29042d14-1d9f-444e-b046-b5ec3e731b15\",\n",
      "        \"shortid\": \"g23kv6pr5v\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/12/2022 19:15:18\",\n",
      "            \"publication/authors\": \"Pulliam L, Liston M, Sun B, Narvid J\",\n",
      "            \"publication/journal\": \"J Neurovirol\",\n",
      "            \"publication/title\": \"Using neuronal extracellular vesicles and machine learning to predict cognitive deficits in HIV.\",\n",
      "            \"optimization/algorithm\": \"Stochastic gradient boosting and random forests\",\n",
      "            \"optimization/config\": \"Configuration and hyper-parameter configuration available in the main text (Table 2)\",\n",
      "            \"optimization/encoding\": \"Eleven features for describing complete lncRnot reported sequence: mRnot reported length, ORF length, GC%, Fickett score, hexamer score, alignment identity in SwissProt database, length of alignment in SwissProt database, proportion of alignment length and mRnot reported length (alignment length:mRnot reported length), proportion of alignment length and ORF length (alignment length:ORF), presence of transposable element, and sequence percent divergence from transposable element.\",\n",
      "            \"optimization/features\": \"f=11. Feature selection by Recursive feature elimination\",\n",
      "            \"model/availability\": \"Code not available\",\n",
      "            \"model/interpretability\": \"Transparent. Random forests provide feature importance\",\n",
      "            \"evaluation/comparison\": \"GreeNC method (transcript filtering, no machine-learning), CPAT\",\n",
      "            \"evaluation/confidence\": \"No confidence reported\",\n",
      "            \"evaluation/measure\": \"Sensitivity, Specificity, Accuracy, ROC-AUC\",\n",
      "            \"evaluation/method\": \"Cross-validation. No indipendent datasets\",\n",
      "            \"dataset/availability\": \"Yes, supplementary material.\",\n",
      "            \"dataset/provenance\": \"Positive data from lncRnot reporteddb v2, lncRnot reporteddisease. Negative data from Ensembl, Araport v11. Npos=436 lncRnot reported sequences. Nneg=? (total number of negative not known). Not previously used.\",\n",
      "            \"dataset/splits\": \"Ten different indipendent 10-fold cross-validation performed. N_pos and N_neg for training and testing unknown. \"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b8c\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33354569\",\n",
      "            \"updated\": \"03/03/2022 17:42:56\",\n",
      "            \"authors\": \"Li J, Liu Y, Zhang Z, Liu B, Wang Y\",\n",
      "            \"journal\": \"Biomed Res Int\",\n",
      "            \"title\": \"PmDNE: Prediction of miRNA-Disease Association Based on Network Embedding and Network Similarity Analysis.\",\n",
      "            \"doi\": \"10.1155/2020/6248686\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"4f8760d4-406b-4faf-bfce-2e05bee0335c\",\n",
      "        \"shortid\": \"akj12z17yv\",\n",
      "        \"score\": 0.57,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/03/2022 17:42:56\",\n",
      "            \"publication/authors\": \"Li J, Liu Y, Zhang Z, Liu B, Wang Y\",\n",
      "            \"publication/journal\": \"Biomed Res Int\",\n",
      "            \"publication/title\": \"PmDNE: Prediction of miRNA-Disease Association Based on Network Embedding and Network Similarity Analysis.\",\n",
      "            \"optimization/algorithm\": \"Gradient tree boosting\",\n",
      "            \"optimization/encoding\": \"global features\",\n",
      "            \"optimization/features\": \"63 + 63, Incremental Feature Selection\",\n",
      "            \"model/availability\": \"http://dlab.org.cn/PredRBR/ (not working)\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"Binary predictions\",\n",
      "            \"evaluation/comparison\": \"BindN, PPRint, BindN+, RNABindR2.0, RNABindRPlus, SNBRFinder\",\n",
      "            \"evaluation/measure\": \"sensitivity, specificity, accuracy, precision, F-measure, MCC score\",\n",
      "            \"evaluation/method\": \"Independent dataset\",\n",
      "            \"dataset/availability\": \"http://dlab.org.cn/PredRBR/ (not working now)\",\n",
      "            \"dataset/provenance\": \"Used by previous papers\",\n",
      "            \"dataset/redundancy\": \" eliminating sequences more similar than 40%\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b8d\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"32545899\",\n",
      "            \"updated\": \"05/20/2022 15:07:04\",\n",
      "            \"authors\": \"Ahn HS, Kim JH, Jeong H, Yu J, Yeom J, Song SH, Kim SS, Kim IJ, Kim K\",\n",
      "            \"journal\": \"Int J Mol Sci\",\n",
      "            \"title\": \"Differential Urinary Proteome Analysis for Predicting Prognosis in Type 2 Diabetes Patients with and without Renal Dysfunction.\",\n",
      "            \"doi\": \"10.3390/ijms21124236\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"e735e3a3-1291-4134-b91b-e7eed358f5e6\",\n",
      "        \"shortid\": \"ebmz3cuuuq\",\n",
      "        \"score\": 0.57,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"05/20/2022 15:07:04\",\n",
      "            \"publication/authors\": \"Ahn HS, Kim JH, Jeong H, Yu J, Yeom J, Song SH, Kim SS, Kim IJ, Kim K\",\n",
      "            \"publication/journal\": \"Int J Mol Sci\",\n",
      "            \"publication/title\": \"Differential Urinary Proteome Analysis for Predicting Prognosis in Type 2 Diabetes Patients with and without Renal Dysfunction.\",\n",
      "            \"optimization/algorithm\": \"Single linear-nonlinear cascade models (LN), linear-nonlinear-sum-nonlinear (LNSN), linear-nonlinear-sum-nonlinear-feedback (LNSNF), linear-nonlinear-feedback-sum-\\nnonlinear-feedback (LNFSNF) and LNFDSNF models. (to predict firing rates of ganglion cells)\",\n",
      "            \"optimization/fitting\": \"Fitting is performed but the fitting algorithm is not explained.\",\n",
      "            \"optimization/parameters\": \"~100-150 parameters\",\n",
      "            \"optimization/regularization\": \"yes. A \\\"fitting algorithm\\\" is mentioned but the technique is not explained.\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"The model gives as output the neuron's spike rate (time course of the firing rate).\",\n",
      "            \"evaluation/comparison\": \"Comparison between models used in the paper.\",\n",
      "            \"evaluation/confidence\": \"Median and variance of cells across models.\",\n",
      "            \"dataset/provenance\": \"The data comes from a direct experiment. They consider firing rates of ~200 ganglion cells.\",\n",
      "            \"dataset/splits\": \"Training set: ~80% of the data. Test set: ~20% of the data.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b92\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33679869\",\n",
      "            \"updated\": \"03/28/2022 00:44:11\",\n",
      "            \"authors\": \"Sun S, Fei K, Zhang G, Wang J, Yang Y, Guo W, Yang Z, Wang J, Xue Q, Gao Y, He J\",\n",
      "            \"journal\": \"Front Genet\",\n",
      "            \"title\": \"Construction and Comprehensive Analyses of a METTL5-Associated Prognostic Signature With Immune Implication in Lung Adenocarcinomas.\",\n",
      "            \"doi\": \"10.3389/fgene.2020.617174\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"1a0158e9-2f41-4c14-9b7e-4d7369584811\",\n",
      "        \"shortid\": \"3p5oxxtlts\",\n",
      "        \"score\": 1,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/28/2022 00:44:11\",\n",
      "            \"publication/authors\": \"Sun S, Fei K, Zhang G, Wang J, Yang Y, Guo W, Yang Z, Wang J, Xue Q, Gao Y, He J\",\n",
      "            \"publication/journal\": \"Front Genet\",\n",
      "            \"publication/title\": \"Construction and Comprehensive Analyses of a METTL5-Associated Prognostic Signature With Immune Implication in Lung Adenocarcinomas.\",\n",
      "            \"optimization/algorithm\": \"1) various methods for classification and clustering. Both supervised and unsupervised.\\n2) first network-based feature ranking method for selection of top genes, then SVM for classification\",\n",
      "            \"optimization/config\": \"1) No\\n 2) No\",\n",
      "            \"optimization/encoding\": \"1) Not applicable\\n2) Not applicable\",\n",
      "            \"optimization/features\": \"1)50 and 200 input variables.\\n2) 6,168 genes as input features for network-based feature ranking method, and then top T (1,5,10...,50)\",\n",
      "            \"optimization/fitting\": \"1) average over a wide range of K to avoid overfitting for KNN-based methods\\n2) Not applicable\",\n",
      "            \"optimization/meta\": \"1) yes. Some in similar ways. Some other vary from unsupervised to supervised learning.\\n2) No\",\n",
      "            \"optimization/parameters\": \"1) based on the complexity of each pattern\\n2) p=2, with complexity parameter C = 100 and RBF kernel with \\u03c3 = 1\",\n",
      "            \"optimization/regularization\": \"1) No\\n2) No\",\n",
      "            \"model/availability\": \"1)No\\n 2) No\",\n",
      "            \"model/duration\": \"1) a few seconds\\n 2) not applicable\",\n",
      "            \"model/interpretability\": \"1) transparent since results are based on statistics.\\n 2) transparent since results are based on statistics.\",\n",
      "            \"model/output\": \"1) regression\\n 2) classification\",\n",
      "            \"evaluation/availability\": \"1) No\\n 2) No\",\n",
      "            \"evaluation/comparison\": \"1) LASSO. The performance of LASSO is worse than all the other non-linear methods when we have relatively small numbers of samples.\\n 2) Not applicable\",\n",
      "            \"evaluation/confidence\": \"1)All the measurements are based on the statistics estimated from data.\\n 2) p-values\",\n",
      "            \"evaluation/measure\": \"1) AUC (area under ROC curve) values\\n 2) AUC and p-values\",\n",
      "            \"evaluation/method\": \"1) Not applicable\\n 2) 10-fold cross-validation and independent Dataset\",\n",
      "            \"dataset/availability\": \"1) No\\n2) No\",\n",
      "            \"dataset/provenance\": \"1) We simulate random datasets by extending a casecontrol model adopted in https://doi.org/10.1186/1752-0509-2-10, for evaluation of all methods.\\n2)USA dataset for breast cancer metastasis\",\n",
      "            \"dataset/redundancy\": \"1) Simulation of three different types of interaction patterns between two interacting variables xi, xj and the outcome y: \\u201csimple\\u201d, \\u201ccomplex\\u201d, and \\u201cvery complex\\u201d. Among six pairs of interacting variables, simulation of the data by including two pairs of each pattern. Depending on the outcome then they assigned a value drawn from an equally weighted Mixture-of-Gaussian with various Gaussian components for each pattern case.\\n2) not applicable\",\n",
      "            \"dataset/splits\": \"1) Randomly assignment of outcome variable y uniformly distributed in {0, 1}. Generation of input variables: random generation of 50 input variables, randomly select six of them to simulate the individual effects and another six distinct pairs of other variables from all 1, 225 possible variable pairs to simulate significant interactive effects on disease outcome y.\\nCreation of 1,000 datasets for each one of the following sample sizes: 20, 40, 60, 80, 100, 120, and 140.\\n2) USA(train): n=286, 107 metastasis cases\\nNetherlands(test): n=295, 79  metastasis cases\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b9a\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33349236\",\n",
      "            \"updated\": \"03/19/2022 20:19:10\",\n",
      "            \"authors\": \"Basodi S, Baykal PI, Zelikovsky A, Skums P, Pan Y\",\n",
      "            \"journal\": \"BMC Genomics\",\n",
      "            \"title\": \"Analysis of heterogeneous genomic samples using image normalization and machine learning.\",\n",
      "            \"doi\": \"10.1186/s12864-020-6661-6\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"4f314982-05d0-429f-aa3f-d163dc7c0834\",\n",
      "        \"shortid\": \"l4cnu26i2o\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/19/2022 20:19:10\",\n",
      "            \"publication/authors\": \"Basodi S, Baykal PI, Zelikovsky A, Skums P, Pan Y\",\n",
      "            \"publication/journal\": \"BMC Genomics\",\n",
      "            \"publication/title\": \"Analysis of heterogeneous genomic samples using image normalization and machine learning.\",\n",
      "            \"optimization/algorithm\": \"random forest\",\n",
      "            \"optimization/config\": \"Partially yes: in the text\",\n",
      "            \"optimization/encoding\": \"global features\",\n",
      "            \"optimization/features\": \"All datasets were combined and normalized using the R package limma, and batch effects were adjusted using ComBat. Then the optimal number of features (48 out of presumably 753) was selected using all datasets, potentially leading to contamination. Then subsets of 48 features were used to train models (based on dataset 1), and the best model was chosen (based on datasets 2-5 + genetic algorithm) and evaluated (based on dataset 6).\",\n",
      "            \"model/interpretability\": \"Partially transparent: the features (genes) selected in the final model were scrutinized for other associations.\",\n",
      "            \"model/output\": \"4-class classification\",\n",
      "            \"evaluation/availability\": \"Only final accuracy values for training, test, and combined datasets in the supporting information.\",\n",
      "            \"evaluation/comparison\": \"Baselines: VarSelRF and simple RFE as an alternative to their feature selection; benchmarking: ClaNC by Verhaak et al. (claimed to be the standard in the field).\",\n",
      "            \"evaluation/confidence\": \"Only standard deviations for the accuracy values are provided\",\n",
      "            \"evaluation/method\": \"Cross-validation, independent dataset\",\n",
      "            \"dataset/provenance\": \"6 experimental datasets from the literature (803 = 171+296+46+27+35+228) and 4 classes. The raw data is not reported to evaluate the imbalances\",\n",
      "            \"dataset/redundancy\": \"Not studied\",\n",
      "            \"dataset/splits\": \"575 data points in the training and validation sets; 228 in the test set; the raw data is not reported to evaluate the imbalances\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b9b\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"32286325\",\n",
      "            \"updated\": \"03/29/2022 07:28:13\",\n",
      "            \"authors\": \"Cheng J, Han Z, Mehra R, Shao W, Cheng M, Feng Q, Ni D, Huang K, Cheng L, Zhang J\",\n",
      "            \"journal\": \"Nat Commun\",\n",
      "            \"title\": \"Computational analysis of pathological images enables a better diagnosis of TFE3 Xp11.2 translocation renal cell carcinoma.\",\n",
      "            \"doi\": \"10.1038/s41467-020-15671-5\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"4df4e637-ba5a-4be5-83d3-aed3e3c4742c\",\n",
      "        \"shortid\": \"du3gc2b5fz\",\n",
      "        \"score\": 0.48,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/29/2022 07:28:13\",\n",
      "            \"publication/authors\": \"Cheng J, Han Z, Mehra R, Shao W, Cheng M, Feng Q, Ni D, Huang K, Cheng L, Zhang J\",\n",
      "            \"publication/journal\": \"Nat Commun\",\n",
      "            \"publication/title\": \"Computational analysis of pathological images enables a better diagnosis of TFE3 Xp11.2 translocation renal cell carcinoma.\",\n",
      "            \"optimization/algorithm\": \"Random Forests Classification\",\n",
      "            \"optimization/encoding\": \"EPG waveform recordings were manually classified into 6 feeding states: C, D, E1, E2, G, NP. Fast Fourier transform of EPG recordings. The 6 frequencies with the highest magnitudes, often harmonics, were extracted and used for further analysis.\",\n",
      "            \"optimization/features\": \"Main periodic components of the time series\",\n",
      "            \"model/output\": \"Multi-label predictions on 6 different feeding states. Binary predictions between phloem (E1 and E2) and non-phloem (C, D, NP, and G) feeding states.\",\n",
      "            \"evaluation/confidence\": \"95% confidence intervals. Confusion matrices.\",\n",
      "            \"evaluation/measure\": \"Average of: Accuracy, Sensitivity, Specificity, Positive Predictive value, Negative Predictive value, Prevalence, Detection Rate, Detection Prevalence, Balanced Accuracy.\",\n",
      "            \"evaluation/method\": \"1) 3 repeats of 10-fold cross validation for each EPG recording.\\n 2) Leave-one-out cross-validation. 3 repeats of 10-fold cross validation for 5% of 26 EPG recordings (train). 1 EPG recording for testing.\",\n",
      "            \"dataset/provenance\": \"27 electrical penetration graph (EPG) waveform recordings \\ntotaling 470 hours on nine different citrus varieties. Not previously used.\",\n",
      "            \"dataset/redundancy\": \"1)\\tA classification model was trained and used for predictions on each EPG recording independently. \\n2)\\tRandom selection of 5% of 26 EPG recordings used as training and 1 EPG recording as testing. 27 repeats (Leave-one-out cross-validation). \",\n",
      "            \"dataset/splits\": \"1)\\tData split for each EPG recording. Ntrain = 5%. Ntest = 95%. 3 splits.\\n2)\\tNtrain = 5% from each of 26 EPG recordings. Ntest = 100% from 1 EPG recording (27th). \"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305ba4\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33425719\",\n",
      "            \"updated\": \"03/02/2022 16:10:05\",\n",
      "            \"authors\": \"Li J, Zhang C, Wei J, Zheng P, Zhang H, Xie Y, Bai J, Zhu Z, Zhou K, Liang X, Xie Y, Qin T\",\n",
      "            \"journal\": \"Front Oncol\",\n",
      "            \"title\": \"Intratumoral and Peritumoral Radiomics of Contrast-Enhanced CT for Prediction of Disease-Free Survival and Chemotherapy Response in Stage II/III Gastric Cancer.\",\n",
      "            \"doi\": \"10.3389/fonc.2020.552270\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"961066cf-8ef7-40b4-9b4f-2659655f5c2f\",\n",
      "        \"shortid\": \"82s7pnn2t8\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/02/2022 16:10:05\",\n",
      "            \"publication/authors\": \"Li J, Zhang C, Wei J, Zheng P, Zhang H, Xie Y, Bai J, Zhu Z, Zhou K, Liang X, Xie Y, Qin T\",\n",
      "            \"publication/journal\": \"Front Oncol\",\n",
      "            \"publication/title\": \"Intratumoral and Peritumoral Radiomics of Contrast-Enhanced CT for Prediction of Disease-Free Survival and Chemotherapy Response in Stage II/III Gastric Cancer.\",\n",
      "            \"optimization/algorithm\": \"Random Forest classifier\",\n",
      "            \"optimization/encoding\": \"For each ortholog group, its corresponding protein sequences were aligned with MUSCLE. The multiple sequence alignments were subsequently input in PhyML for the construction of phylogenetic trees using the Maximum Likelihood method. For amino acid and nucleotide-based tree construction in PhyML, the LG and HKY85 substitution matrices were used, respectively. Additionally, distance matrices were calculated for each tree, where the distance between two leaves corresponds to the sum of the branch lengths separating them. \\n\\nComparing two trees can be subject to artefacts and lead in some cases to spurious correlations if speciation events are not taken in account. For this reason, some of the co-evolution features also involve the Tree of Life (ToL) of the 34 genomes studied, which originated from submitting sequences of their respective 16S ribosomal Rnot reported to similar treatment. Since distances in the ToL are computed from a nucleotide-based substitution matrix, the distances in the ToL matrix were rescaled for proper comparison with the protein-based distance matrices.\\n\",\n",
      "            \"optimization/features\": \"For each protein pair, 7 coevolution features measuring the pairwise tree similarities have been defined. \\nOf these, 4 features are based on pairwise comparison of the distance matrices, as defined in the mirrortree approach, and whose metrics correspond to the linear correlation coefficient between the two matrices in consideration. Let A and B be the two MCP ortholog groups, mA and mB their respective matrices, tA and tB their trees. The parameter mirrorAB is the correlation between mA and mB, mirrorA is between mA and ToL, and mirrorB is between mB and ToL. The fourth descriptor, mirrorAB-ToL, involves an adaptation of the mirror tree, also known as tol-mirror, which measures the correlation between mA and mB after removing the background similarity inherent to speciation events in the ToL.\\nThe remaining 3 topological features are derived from the Icong index, defined as the probability that the Maximum Agreement Subtree (MAST) between two trees is arising by chance. Along the same idea, topological similarities were computed between tree A and ToL, tree B and ToL, and finally A and B (topA, topB, topAB).\\n\",\n",
      "            \"model/interpretability\": \"Not explicitly interpreted. Comparison of classification performance for fewer features and evaluation of their discriminatory power individually by ranking their accuracies in the context of an unsupervised analysis. Results support the importance of all features for optimal model performance.\",\n",
      "            \"model/output\": \"Binary predictions of pos for an interacting protein group pair and neg for those not interacting. For prediction probability is less than 0.7 then the result is neg, and for equal or greater than 0.7 the result is pos (increased specificity).\",\n",
      "            \"evaluation/availability\": \"Yes. Supporting information.\",\n",
      "            \"evaluation/confidence\": \"High training accuracy for experimentally characterized PPIs, 15 of 16 correctly predicted as pos. Claiming support for the high specificity criterion.\",\n",
      "            \"evaluation/measure\": \"ROC curve, AUC score\",\n",
      "            \"evaluation/method\": \"10-fold cross-validation. Experimental confirmation of a predicted positive PPI from the testing dataset.\",\n",
      "            \"dataset/availability\": \"Yes. Supporting information.\",\n",
      "            \"dataset/provenance\": \"Training dataset of 40 pairs of Pdu protein sequences whose presence or absence of physical, protein-protein interactions (PPIs) could be experimentally validated via binding assays, complementation and expression studies or crystallographic data.\\n\\nTesting dataset of protein orthologs collected from 34 bacterial genomes in the KEGG database and collapsed among 22 orthologous protein groups, which represent types of bacterial microcompartment (MCP) proteins known to be associated with the propanediol utilizing (Pdu) system.\\n\",\n",
      "            \"dataset/redundancy\": \"Incomplete or erroneous annotations of the Pdu gene products were corrected after sequence comparison with the Pdu operon from Salmonella enterica LT2, the best-characterized strain in terms of Pdu MCP.\",\n",
      "            \"dataset/splits\": \"For the training set, Npos=16 interacting and Nneg=24 non-interacting protein pairs.\\nFor the testing set, pairwise combinations of the 22 orthologous protein groups resulted in 231 unique protein pairs that needed to be classified.\\n\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305ba5\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"32858131\",\n",
      "            \"updated\": \"03/16/2022 15:35:06\",\n",
      "            \"authors\": \"Grundler F, Mesnage R, Goutzourelas N, Tekos F, Makri S, Brack M, Kouretas D, Wilhelmi de Toledo F\",\n",
      "            \"journal\": \"Food Chem Toxicol\",\n",
      "            \"title\": \"Interplay between oxidative damage, the redox status, and metabolic biomarkers during long-term fasting.\",\n",
      "            \"doi\": \"10.1016/j.fct.2020.111701\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"d692ec44-aeae-4a41-9383-a899977f51f3\",\n",
      "        \"shortid\": \"mhyzrdvtd1\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/16/2022 15:35:06\",\n",
      "            \"publication/authors\": \"Grundler F, Mesnage R, Goutzourelas N, Tekos F, Makri S, Brack M, Kouretas D, Wilhelmi de Toledo F\",\n",
      "            \"publication/journal\": \"Food Chem Toxicol\",\n",
      "            \"publication/title\": \"Interplay between oxidative damage, the redox status, and metabolic biomarkers during long-term fasting.\",\n",
      "            \"optimization/algorithm\": \"Random Forest (RF), Conditional Inference Forest (CF), SVM with Linear kernel, Neural network.\",\n",
      "            \"optimization/encoding\": \"Clinical categorization of de novo and inherited CNVs as pathogenic, uncertain or benign following clinical annotation guidelines. Large and very rare CNVs were also classified as pathogenic. \\nGene annotations based on CNVs. Gene-set construction, based on CNV gene annotations.\",\n",
      "            \"optimization/features\": \"Clinically categorized CNVs. CNV annotated genes. 20 curated gene-sets of neurobiological relevance. Total gene count.\",\n",
      "            \"optimization/fitting\": \"Stratified 3-fold cross-validation was used to avoid overfitting. \\nThe absence of overfitting was further assessed by replacing real classification features with randomized features based on gene identity permutation. \\nFeature selection was based on the feature relevance metrics calculated on the data subset used for training, and performed independently for every training set, to avoid any overfitting issues.\\nAdditionally, all subsets presented a gender composition similar to the full dataset.\\n\",\n",
      "            \"optimization/parameters\": \"For RF and CF default settings were used unless otherwise specified.\\nFor Linear SVM the cost parameter was kept at default as 1 and class weights were kept even. Each feature was independently normalized and rescaled to a 0-1 interval prior to being input into the classifier.\\nThe Neural Network was built with two middle layers of 100 and 50 nodes each, a learning rate of 0.005 with a 0.9 momentum. The network was trained through back-propagation, and without feature normalization or scaling.\\n\",\n",
      "            \"model/interpretability\": \"Feature selection for RF based on Mean Decrease Accuracy (MDA) and Mean Decrease Gini. Feature selection for CF based on MDA was performed with and without step-wise decorrelation, and on MRMR (Minimum Redundancy Maximum Relevance Feature Selection). Reported in Additional information.\\n Black box for SVM with Linear kernel and Neural network.\",\n",
      "            \"model/output\": \"Prediction probabilities. Binary predictions.\",\n",
      "            \"evaluation/comparison\": \"Comparison and evaluation of algorithms\\u2019 performance by splitting data into: \\n 1) all subjects, \\n 2) subjects with de novo CNVs, and \\n 3) subjects with pathogenic CNVs\\n Moreover, evaluating algorithms\\u2019 performance by splitting observations (CNVs) into:\\n 1) Total CNVs, \\n 2) gain CNVs, and \\n 3) loss CNVs\\n Additionally, evaluating algorithms\\u2019 performance by separating features, following feature selection, into:\\n 1) top 20 ranking features\\n 2) top 15% ranking features\\n 1) top 40% ranking features\\n CF reported as an optimal classification approach based on comparisons with different algorithms and the respective AUC scores.\",\n",
      "            \"evaluation/measure\": \"AUC score.\\n Percentage of correctly classified ASD subjects, which was calculated as the number of ASD subjects correctly predicted in at least 15 out of 20 iterations divided by the study total (Npos=1892).\",\n",
      "            \"evaluation/method\": \"Stratified 3-fold cross-validation.\",\n",
      "            \"dataset/availability\": \"Yes. Stage-1 CNV calls are available in dbGAP as phs000267.v3.p2. Stage-2 CNV calls are available in dbGAP as phs000267.v4.p2. Supplementary files for rare variants of ASD subjects and controls.\",\n",
      "            \"dataset/provenance\": \"Rare Copy Number Variation (CNV) data and comprehensive gene annotations from Npos=1892 Autism Spectrum Disorder ASD subjects (1623 males and 270 females), and Nneg=2342 platform-matched controls (1093 males and 1250 females) with at least one rare CNV (frequency 1% or less). All subjects (Npos) are of European\\nancestry and Caucasian ethnicity.\\nData were collected from previous studies: Autism Genome Project (AGP), SAGE (Study of Addiction Genetics and Environment), Ontario Colorectal Cancer study, HABC (Health Aging and Body Composition).\\n\",\n",
      "            \"dataset/redundancy\": \"Subjects with karyotypic abnormalities, Fragile X syndrome or other\\ngenetic syndromes causing congenital malformations were excluded from the analysis. Only samples meeting quality thresholds were used for CNV analysis. CNVs (of size 30 kb or greater) were detected using an analytical pipeline optimized for Illumina 1M arrays. All de novo CNVs were experimentally validated. Samples with copy number variation greater than 7.5 MB were excluded.\\n\",\n",
      "            \"dataset/splits\": \"Only subjects harboring at least one rare genic CNV were used for classification, as features would be constantly zero for the other subjects, but all subjects were considered when reporting percentage \\u201cexplained\\u201d statistics. This resulted in a subset of Npos=1570 ASD subjects (80.8%) and Nneg=1916 controls (81.8%).\\nRandom division into 3 equal and stratified subsets. Ntrain = 2 subsets. Ntest=1 subset. This process was repeated 3 times without re-dividing the dataset.\\n\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bb3\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33126851\",\n",
      "            \"updated\": \"03/18/2022 11:23:23\",\n",
      "            \"authors\": \"Chen X, Xiong Y, Liu Y, Chen Y, Bi S, Zhu X\",\n",
      "            \"journal\": \"BMC Bioinformatics\",\n",
      "            \"title\": \"m5CPred-SVM: a novel method for predicting m5C sites of RNA.\",\n",
      "            \"doi\": \"10.1186/s12859-020-03828-4\",\n",
      "            \"year\": \"2020\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"10fa32b7-b2d7-4aeb-9de4-351d2c086bf9\",\n",
      "        \"shortid\": \"y6wfiqd2mt\",\n",
      "        \"score\": 0.86,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/18/2022 11:23:23\",\n",
      "            \"publication/authors\": \"Chen X, Xiong Y, Liu Y, Chen Y, Bi S, Zhu X\",\n",
      "            \"publication/journal\": \"BMC Bioinformatics\",\n",
      "            \"publication/title\": \"m5CPred-SVM: a novel method for predicting m5C sites of RNA.\",\n",
      "            \"optimization/algorithm\": \"Support Vector Machine (SVM)\",\n",
      "            \"optimization/encoding\": \"Different data processing methods for transforming input protein sequences:\\n1)\\tTripeptide (k=3) frequency in protein sequence: Considering all possible subsequences of length k in the query protein sequence and dividing the number of occurrences of each k-mer by the total number of possible k-mers.\\n2)\\tSecondary structure: For each protein in each dataset SSPro was used to obtain a secondary structure role for each amino acid in the protein in question.\\n3)\\tFrequency Priors: Scanning database of known Dnot reported repair proteins for the frequencies of each type of amino acid, and using this information to determine if a query protein not belonging to the known database has a similar percentage of each type of amino acid (vf+) or not (vf-).\\n4)\\tBLAST homology: Homology positive or negative assessment and return of value, vb+ or vb-, if BLAST e-value is lower or higher than a 0.001 threshold, respectively.\\n\",\n",
      "            \"optimization/features\": \"1)\\tPrimary Sequence\\n2)\\tPrimary Sequence and Secondary Structure\\n3)\\tPrimary Sequence and Frequency Priors\\n4)\\tPrimary Sequence and Homology\\n5)\\tPrimary Structure, Secondary Structure, Homology\\n6)\\tBLAST Homology\\n\",\n",
      "            \"optimization/meta\": \"Yes. Utilization of BLAST in protein sequences data encoding for homology features.\",\n",
      "            \"optimization/regularization\": \"Yes, manually setting the gamma value of the radial basis function (RBF) similarity-metric.\",\n",
      "            \"model/availability\": \"Yes. Web server: https://sunflower.kuicr.kyoto-u.ac.jp/~jbbrown/dnaRepairPrediction/v2/index.py\",\n",
      "            \"model/duration\": \"Yes. Available report in Additional information.\",\n",
      "            \"model/interpretability\": \"Comparing model performance following training on datasets with different features.\",\n",
      "            \"model/output\": \"Binary predictions. SVM scores or BLAST e-value as outputs, and comparisons with thresholds to determine the prediction (DNA repair protein or Not)\",\n",
      "            \"evaluation/availability\": \"Yes. Additional information.\",\n",
      "            \"evaluation/comparison\": \"The transformation based SVM experimental results were compared with independent BLAST trials. A continuum of thresholds was used in order to obtain ROC curves and compare different techniques.\",\n",
      "            \"evaluation/confidence\": \"Pairwise comparisons of classifiers using both the parametric t-test and non-parametric Wilcoxon Signed-Rank Test.\",\n",
      "            \"evaluation/measure\": \"ROC curves, AUC scores\",\n",
      "            \"evaluation/method\": \"1) 5-fold cross-validation\\n 2) One-versus-one-versus-rest cross-validation. This technique differs in that for k-fold validation, one portion is still set aside for evaluation, but instead of k - 1 portions of data for training, only a single portion is used for training, and the k - 2 remaining portions are used as a reference homology database for querying training and test data. The end goal this technique is to combine homology and sequence data in an unbiased way and obtain a realistic estimate of method performance.\",\n",
      "            \"dataset/availability\": \"Yes. Additional information.\",\n",
      "            \"dataset/provenance\": \"1)\\tFirst dataset of protein sequences for identification experiments of Dnot reported repair proteins. Gene Ontology (GO) annotated proteins from PDB. Npos=557 and Nneg=1443 total protein sequences. Npos=114 and Nneg=353 protein sequences with 90% sequence similarity. Npos=76 and Nneg=215 protein sequences with 50% sequence similarity.\\n2)\\tSecond dataset of protein sequences for identification experiments of Dnot reported repair proteins. Gene Ontology (GO) annotated proteins from Uniprot:\\n-\\tProtein sequences of \\u201cBase Excision Repair\\u201d, Npos=2624 and Nneg=4723 for total protein sequences, Npos=1721 and Nneg=2924 protein sequences with 90% sequence similarity, and Npos=630 and Nneg=1200 protein sequences with 50% sequence similarity.\\n-\\tProtein sequences of \\u201cDnot reported Dealyklation\\u201d, Npos=25 and Nneg=7322 for total protein sequences.\\n-\\tProtein sequences of \\u201cDnot reported synthesis during Dnot reported repair\\u201d, Npos=28 and Nneg=7319 for total protein sequences.\\n-\\tProtein sequences of \\u201cDouble Strand Break repair\\u201d, Npos=364 and Nneg=6983 for total protein sequences, Npos=266 and Nneg=4379 protein sequences with 90% sequence similarity and Npos=174 and Nneg=1656 protein sequences with 50% sequence similarity.\\n-\\tProtein sequences of \\u201cError-prone Dnot reported repair\\u201d, Npos=46 and Nneg=7301 for total protein sequences, Npos=36 and Nneg=4609 protein sequences with 90% sequence similarity.\\n-\\tProtein sequences of \\u201cMismatch repair\\u201d, Npos=1777 and Nneg=5570 for total protein sequences, Npos=1020 and Nneg=3625 protein sequences with 90% sequence similarity and Npos=468 and Nneg=1362 protein sequences with 50% sequence similarity.\\n-\\tProtein sequences of \\u201cNucleotide Excision Repair\\u201d, Npos=2106 and Nneg=5241 for total protein sequences, Npos=1325 and Nneg=3320 protein sequences with 90% sequence similarity and Npos=363 and Nneg=1467 protein sequences with 50% sequence similarity.\\n-\\tProtein sequences of \\u201cPostreplication repair\\u201d, Npos=28 and Nneg=7319 for total protein sequences.\\n-\\tProtein sequences of GO \\u201cRegulation of Dnot reported repair\\u201d, Npos=264 and Nneg=7083 for total protein sequences, Npos=174 and Nneg=4471 protein sequences with 90% sequence similarity, and Npos=114 and Nneg=1716 protein sequences with 50% sequence similarity.\\n-\\tProtein sequences of GO \\u201cSingle Strand Break repair\\u201d, Npos=40 and Nneg=4605 for total protein sequences, and Npos=25 and Nneg=1805 protein sequences with 90% sequence similarity.\\n3)\\t31 vertebrate genomes from ENSEMBL for identification of novel, Dnot reported repair-related proteins.\\n\",\n",
      "            \"dataset/redundancy\": \"Overlaps between protein sequence datasets of 0%(unfiltered), 50% and 90% sequence similarity. Only Dnot reported repair pathways which were consisted of at least 25 proteins, were considered. Removed redundancy of protein sequences which belong to more than one pathway. Removed proteins which contain the following keywords in their GO descriptions: putative, similar, possible/possibly, probable/probably, theoretical, and hypothetical.\",\n",
      "            \"dataset/splits\": \"5-fold and one-versus-one-versus-rest cross-validation. not reported further.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6603fdf31502715bfe53d6df\",\n",
      "        \"uuid\": \"7cb19427-d4cb-4038-8225-3fabb2f4f585\",\n",
      "        \"created\": \"2024-03-27T11:07:31.027Z\",\n",
      "        \"updated\": \"2024-03-27T11:07:31.027Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33225896\",\n",
      "            \"authors\": \"Xin Liu, Liang Wang, Jian Li, Junfeng Hu and Xiao Zhang\",\n",
      "            \"journal\": \"BMC Genomics\",\n",
      "            \"title\": \"Mal-Prec: computational prediction of protein Malonylation sites via machine learning based feature integration\",\n",
      "            \"doi\": \"10.1186/s12864-020-07166-w\",\n",
      "            \"year\": \"2020\"\n",
      "        },\n",
      "        \"shortid\": \"2b9h7u472x\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches\": {\n",
      "            \"evaluation/comparison\": \"comparison with other methods performed on the benchmark dataset introduced in this study. No baseline method included in the benchmark\",\n",
      "            \"evaluation/measure\": \"standard mesures for classification: accuracy, sensitivity, specificity, F1 and MCC\",\n",
      "            \"evaluation/method\": \"cross-validation and independent dataset\",\n",
      "            \"optimization/algorithm\": \"Dimensionality reduction (PCA) followed by classifier (SVM). The algorithm is not new. \",\n",
      "            \"optimization/encoding\": \"Peptides are represented using: spaced dipeptide composition, physicochemical featurs, one-hot encoding\",\n",
      "            \"optimization/features\": \"f=614 before PCA, f=100 after PCA. \",\n",
      "            \"optimization/fitting\": \"Npos+Nneg>p. No specific strategies to rule out underfitting\",\n",
      "            \"optimization/parameters\": \"p=100 (SVM)\",\n",
      "            \"optimization/regularization\": \"No overfitting prevention strategies seem to have been applied\",\n",
      "            \"model/availability\": \"yes, source code is available at GitHub. No License is present.\",\n",
      "            \"model/duration\": \"not reported\",\n",
      "            \"model/interpretability\": \"model is black box\",\n",
      "            \"dataset/availability\": \"Yes, data available at GitHub\",\n",
      "            \"dataset/provenance\": \"Data taken from literature. Data are in classes. Npos=1735, Nneg=1735. Dataset not previuosly used for ML applications.\",\n",
      "            \"dataset/redundancy\": \"Overall redundancy is set to 40% protein pairwise sequence identity at most. \",\n",
      "            \"dataset/splits\": \"Training set: 2775 data points. Testing set: 695 data points. No separate validation set used. Distributions of data are consistent between training and testing.\",\n",
      "            \"publication/authors\": \"Xin Liu, Liang Wang, Jian Li, Junfeng Hu and Xiao Zhang\",\n",
      "            \"publication/journal\": \"BMC Genomics\",\n",
      "            \"publication/title\": \"Mal-Prec: computational prediction of protein Malonylation sites via machine learning based feature integration\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6638eae3b30933003cc215e9\",\n",
      "        \"shortid\": \"dq30wdbow2\",\n",
      "        \"uuid\": \"321f38fb-6765-48e6-8db4-12e72da58b47\",\n",
      "        \"created\": \"2024-05-06T14:36:19.663Z\",\n",
      "        \"updated\": \"2024-05-06T14:36:19.663Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33431047\",\n",
      "            \"authors\": \"Bowen Tang, Skyler T Kramer, Meijuan Fang, Yingkun Qiu, Zhen Wu, Dong Xu\",\n",
      "            \"journal\": \"Journal of Cheminformatics\",\n",
      "            \"title\": \"A self-attention based message passing neural network for predicting molecular lipophilicity and aqueous solubility\",\n",
      "            \"doi\": \"10.1186/s13321-020-0414-z\",\n",
      "            \"year\": \"2020\"\n",
      "        },\n",
      "        \"score\": 0.95,\n",
      "        \"matches\": {\n",
      "            \"evaluation/availability\": \"All data sets and code are available at GitHub: https://github.com/tbwxmu/ SAMPN.\",\n",
      "            \"evaluation/comparison\": \"In each task, authors built RF, MPN, SAMPN, multiMPN and multi-SAMPN models to explore the relationship between the target property and the molecular structure. \",\n",
      "            \"evaluation/confidence\": \"Standard deviations are reported for each of the used metrics.\",\n",
      "            \"evaluation/measure\": \"Multiple metrics were used to evaluate the performance of the model: mean absolute error (MAE), root mean squared error (RMSE), mean squared error (MSE),\\ncoefcient of determination (R2) and Pearson correlation coefcient (PC).\",\n",
      "            \"evaluation/method\": \"The model was evaluated through a 10-fold cross-validation that uses 10% of the data as the test set.\",\n",
      "            \"optimization/algorithm\": \"In principle it is an explainable graph neural network. It is not a novel model and was mainly adopted from Deepchem MPN (message passing network).\",\n",
      "            \"optimization/config\": \"All data sets and code are available at GitHub: https://github.com/tbwxmu/ SAMPN.\",\n",
      "            \"optimization/encoding\": \"The SMILES representations of molecules are converted into directed graphs before training the model. The graphs consisted of nodes and edges, where the number of nodes equals the number of atoms, and edges are always double the number of bonds (bidirectional).\",\n",
      "            \"optimization/features\": \"Following features for nodes and edges were reported by the authors:\\n\\nAttribute | Description | Dimension \\n**Node** \\nAtom type  | All currently known chemical elements | 118       \\nDegree | Number of heavy atom neighbors  | 6         \\nFormal charge  | Charge assigned to an atom (-2, -1, 0, 1, 2) | 5         \\nChirality label | R, S, unspecified, and unrecognized type of chirality | 4         \\nHybridization | sp, sp2, sp3, sp3d, or sp3d2 | 5         \\nAromaticity | Aromatic atom or not | 1         \\n\\n**Edge** \\nBond type | Single, double, triple, or aromatic | 4         \\nRing | Whether the bond is in a ring | 1         \\nBond stereo | Nature of the bond\\u2019s stereochemistry (none, any, Z, E, cis, or trans) | 6         \",\n",
      "            \"optimization/fitting\": \"The used dataset is fairly small, considering that ANN is used as the model algorithm and it easily overfit on small datasets. Authors adopted a 10-fold cross validation strategy to improve generalization.\",\n",
      "            \"optimization/meta\": \"It is not a meta-predictor.\",\n",
      "            \"optimization/parameters\": \"Hyperparameters were tuned via grid search using the Hyperopt package (v0.1.2).\\nRMSE on the validation set guided the search for optimal hyperparameter combinations.\\n\\nFollowing parameters and their associated range were reported by the authors.\\nActivation function = Tanh, ELU, LeakyReLU, ReLU, PReLU, SELU\\nSteps of message passing = 2\\u20136 \\nGraph embedding size = 32\\u2013512 \\nDropout rate = 0.0\\u20130.4 \\nLayers of fully connected network = 1\\u20133\",\n",
      "            \"optimization/regularization\": \"Authors adopted a 10-fold cross validation strategy to improve generalization.\",\n",
      "            \"model/availability\": \"All data sets and code are available at GitHub: https://github.com/tbwxmu/ SAMPN.\",\n",
      "            \"model/interpretability\": \"The attention mechanism of the model indicates the degree to which each atom of the molecule contributes to the property of interest, and these results are visualized. Hence, it is interpretable.\",\n",
      "            \"model/output\": \"It is a regressor model.\",\n",
      "            \"dataset/availability\": \"All data sets and code are available at GitHub: https://github.com/tbwxmu/SAMPN.\",\n",
      "            \"dataset/provenance\": \"The lipophilicity data was obtained from CHEMBL3301361 by AstraZeneca, comprising 4200 molecules.\\nAqueous solubility data, sourced from the online chemical database and modeling environment (OCHEM), includes 1311 experimental records.\",\n",
      "            \"dataset/redundancy\": \"The splits were performed randomly.\\nFor the initial data preprocessing, duplicate molecules were removed so that each chemical structure in the data was unique.\",\n",
      "            \"dataset/splits\": \"The training set comprises 80% of the data, while the test set contains 10%.\\nAdditionally, a separate validation set, constituting 10% of the data, was employed for parameter selection.\\nDataset distributions are provided in supplementary material.\",\n",
      "            \"publication/authors\": \"Bowen Tang, Skyler T Kramer, Meijuan Fang, Yingkun Qiu, Zhen Wu, Dong Xu\",\n",
      "            \"publication/journal\": \"Journal of Cheminformatics\",\n",
      "            \"publication/title\": \"A self-attention based message passing neural network for predicting molecular lipophilicity and aqueous solubility\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b2a\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"34297718\",\n",
      "            \"updated\": \"01/18/2022 16:56:16\",\n",
      "            \"authors\": \"Rozova VS, Anwer AG, Guller AE, Es HA, Khabir Z, Sokolova AI, Gavrilov MU, Goldys EM, Warkiani ME, Thiery JP, Zvyagin AV\",\n",
      "            \"journal\": \"PLoS Comput Biol\",\n",
      "            \"title\": \"Machine learning reveals mesenchymal breast carcinoma cell adaptation in response to matrix stiffness.\",\n",
      "            \"doi\": \"10.1371/journal.pcbi.1009193\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"b11547a3-b7fc-4667-b0c8-24f256717893\",\n",
      "        \"shortid\": \"1nvj60arng\",\n",
      "        \"score\": 0.43,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"01/18/2022 16:56:16\",\n",
      "            \"publication/authors\": \"Rozova VS, Anwer AG, Guller AE, Es HA, Khabir Z, Sokolova AI, Gavrilov MU, Goldys EM, Warkiani ME, Thiery JP, Zvyagin AV\",\n",
      "            \"publication/journal\": \"PLoS Comput Biol\",\n",
      "            \"publication/title\": \"Machine learning reveals mesenchymal breast carcinoma cell adaptation in response to matrix stiffness.\",\n",
      "            \"optimization/algorithm\": \"Novel approach (Regression Plane)\",\n",
      "            \"optimization/config\": \"heuristic hyperparameter initialization methods\",\n",
      "            \"optimization/encoding\": \"position and features of each cell to be analyzed\",\n",
      "            \"evaluation/method\": \"cross validation and novel experiments\",\n",
      "            \"dataset/availability\": \"Yes, https://data.broadinstitute.org/bbbc/image_sets.html https://doi.org/10.6084/m9.figshare.c.5067638.v1 http://www.mitocheck.org/mitotic_cell_atlas/downloads/v1.0.1/mitotic_cell_atlas_v1.0.1_fulldata.zip https://doi.org/10.6084/m9.figshare.c.5075093.v1\",\n",
      "            \"dataset/provenance\": \"Synthetic dataset + 3 original datasets\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b2b\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"34168145\",\n",
      "            \"updated\": \"02/08/2022 00:18:31\",\n",
      "            \"authors\": \"Bertoni M, Duran-Frigola M, Badia-I-Mompel P, Pauls E, Orozco-Ruiz M, Guitart-Pla O, Alcalde V, Diaz VM, Berenguer-Llergo A, Brun-Heath I, Villegas N, de Herreros AG, Aloy P\",\n",
      "            \"journal\": \"Nat Commun\",\n",
      "            \"title\": \"Bioactivity descriptors for uncharacterized chemical compounds.\",\n",
      "            \"doi\": \"10.1038/s41467-021-24150-4\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"91f62631-e353-48e7-b960-4aef0562c730\",\n",
      "        \"shortid\": \"r23jj6bm7u\",\n",
      "        \"score\": 0.43,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/08/2022 00:18:31\",\n",
      "            \"publication/authors\": \"Bertoni M, Duran-Frigola M, Badia-I-Mompel P, Pauls E, Orozco-Ruiz M, Guitart-Pla O, Alcalde V, Diaz VM, Berenguer-Llergo A, Brun-Heath I, Villegas N, de Herreros AG, Aloy P\",\n",
      "            \"publication/journal\": \"Nat Commun\",\n",
      "            \"publication/title\": \"Bioactivity descriptors for uncharacterized chemical compounds.\",\n",
      "            \"optimization/algorithm\": \"Random Forest\",\n",
      "            \"optimization/encoding\": \"Amplicon Sequence Variants (ASV) used as features in a relative abundance matrix\",\n",
      "            \"optimization/features\": \"Depending on the dataset, from 50 to 5000\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"dataset/availability\": \"Yes. Original dataset: https://www.ncbi.nlm.nih.gov/bioproject/?term=PRJnot reported417767\",\n",
      "            \"dataset/provenance\": \"4 datasets, 3 form previous papers and 1 original. \"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b31\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"34388102\",\n",
      "            \"updated\": \"02/17/2022 09:36:07\",\n",
      "            \"authors\": \"An J, Cai Q, Qu Z, Gao Z\",\n",
      "            \"journal\": \"IEEE J Biomed Health Inform\",\n",
      "            \"title\": \"COVID-19 Screening in Chest X-Ray Images Using Lung Region Priors.\",\n",
      "            \"doi\": \"10.1109/JBHI.2021.3104629\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"628354fa-6ad5-4a13-9ba2-0c5e5b0fd8dc\",\n",
      "        \"shortid\": \"k4k0b6uu1l\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/17/2022 09:36:07\",\n",
      "            \"publication/authors\": \"An J, Cai Q, Qu Z, Gao Z\",\n",
      "            \"publication/journal\": \"IEEE J Biomed Health Inform\",\n",
      "            \"publication/title\": \"COVID-19 Screening in Chest X-Ray Images Using Lung Region Priors.\",\n",
      "            \"optimization/algorithm\": \"Logistic Regression\",\n",
      "            \"optimization/config\": \"Yes, the 6 parameters resulted from training are reported on the paper\",\n",
      "            \"optimization/encoding\": \"Feature selection (operated on the training set finding the top 5 significant features)\\nImputation of missing data points through MICE\\nBalancing on the dataset (regarding pos and neg cases) through SMOTE\",\n",
      "            \"optimization/features\": \"5 selected out of 18. The 5 more relevant feature were selected using chi-square test to identify the feature which significantly differ between the \\\"pos\\\" cases and the \\\"neg\\\" cases.\\n\\nIt is not clear whether the feature selection was performed just on training data. \",\n",
      "            \"optimization/parameters\": \"6 (inferred from the context)\",\n",
      "            \"model/availability\": \"Yes, the code is available at: https://github.com/tawsifur/Mortality-severity-prediction-using-blood-biomarkers\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"Regression (survival probability)\",\n",
      "            \"evaluation/availability\": \"Yes, it is available at: https://github.com/tawsifur/Mortality-severity-prediction-using-blood-biomarkers\",\n",
      "            \"evaluation/comparison\": \"Compared with Random Forest, Support Vector machine, K-nearest neighbor, XGBoost, and Extra-tree\",\n",
      "            \"evaluation/confidence\": \"The performance metrics have confidence intervals. No statistical significance is claimed.\",\n",
      "            \"evaluation/measure\": \"Accuracy, Precision, Sensitivity, F1-Score, Specificity, AUC\",\n",
      "            \"evaluation/method\": \"Predictor evaluated on independent datasets\",\n",
      "            \"dataset/availability\": \"Dataset 1: publicy available with the publication at doi: https://doi.org/10.1016/j.imu.2019.100275. Dataset splits not reported.\\n\\nDataset 2: publicy available with the publication at doi: https://doi.org/10.1101/2020.11.02.365536\",\n",
      "            \"dataset/provenance\": \"Dataset 1: 387 patients labeled as \\\"survived\\\" (pos) (N_pos = 335) and \\\"dead\\\" (neg) (N_neg = 49).\\n\\nDataset 2: 375 patients labeled as \\\"survived\\\" (pos) (N_pos = 201) and \\\"dead\\\" (neg) (N_neg = 174).\\n\\nBoth datasets used in previous publications.\",\n",
      "            \"dataset/redundancy\": \"No redundancy between the subsets.\",\n",
      "            \"dataset/splits\": \"Dataset 1 was splitted in two subsets. 80% of the data used for training and validation; 20% of the data used for testing.\\n\\nDataset 2 was entirely used for testing\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b34\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"34372798\",\n",
      "            \"updated\": \"02/21/2022 11:17:51\",\n",
      "            \"authors\": \"Li MX, Sun XM, Cheng WG, Ruan HJ, Liu K, Chen P, Xu HJ, Gao SG, Feng XS, Qi YJ\",\n",
      "            \"journal\": \"BMC Cancer\",\n",
      "            \"title\": \"Using a machine learning approach to identify key prognostic molecules for esophageal squamous cell carcinoma.\",\n",
      "            \"doi\": \"10.1186/s12885-021-08647-1\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"0ade3d57-3ebf-4c42-af9c-48b4b4fd2e54\",\n",
      "        \"shortid\": \"agwmu9cbwt\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/21/2022 11:17:51\",\n",
      "            \"publication/authors\": \"Li MX, Sun XM, Cheng WG, Ruan HJ, Liu K, Chen P, Xu HJ, Gao SG, Feng XS, Qi YJ\",\n",
      "            \"publication/journal\": \"BMC Cancer\",\n",
      "            \"publication/title\": \"Using a machine learning approach to identify key prognostic molecules for esophageal squamous cell carcinoma.\",\n",
      "            \"optimization/algorithm\": \"Random Forest\",\n",
      "            \"optimization/config\": \"No, but full code is available.\",\n",
      "            \"optimization/encoding\": \"No tranformation.\",\n",
      "            \"optimization/features\": \"5 lncRnot reported sequences selected from 731. A ML algorithm based on random forest was used for feature selection. Feature selection was operated on training data only.\",\n",
      "            \"optimization/meta\": \"Yes. Feature selection operated using ML. The set used for feature selection is the same used for the training of the classifier, but the validation for the classifier is operated on independent dataset (Dataset 2 and 3).\",\n",
      "            \"model/availability\": \"Yes, code available at: https://github.com/guoqingbao/PanCancerLncRNA\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/availability\": \"Yes, the evaluation procedure and code is available at: https://github.com/guoqingbao/PanCancerLncRNA\",\n",
      "            \"evaluation/comparison\": \"The model is not compared with others.\",\n",
      "            \"evaluation/measure\": \"Area Under Curve (AUC)\",\n",
      "            \"evaluation/method\": \"Test set derived from Dataset 1; Independent Datasets 2 and 3.\",\n",
      "            \"dataset/availability\": \"Dataset 1: URL: https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga\\n\\nDataset 2: URL: https://ocg.cancer.gov/programs/target\\n\\nDataset 3: URL: https://proteomics.cancer.gov/programs/cptac\",\n",
      "            \"dataset/provenance\": \"Dataset 1: Rnot reported-seq data from The Cancer Genome Atlas for different patients affected by different types of cancer. To the end of ML classification, patients where classified as \\\"High risk\\\" or \\\"Low risk\\\" based on the Overall Survival time. N = 2210; distribution of High risk and Low risk patients not reported Used in other papers.\\n\\nDataset 2: Rnot reported-seq data from Therapeutically Applicable Research to Generate Effective Treatments (TARGET) dataset (N = 1122). Used in other papers.\\n\\nDataset 3: Rnot reported-seq data from Clinical Proteomic Tumor Analysis Consortium (CPTAC) dataset (N=391). Used in other papers.\",\n",
      "            \"dataset/redundancy\": \"Dataset splits for Dataset 1 do not overlap. \\n\\nDataset 1, 2 and 3 are independent from each other.\",\n",
      "            \"dataset/splits\": \"Dataset 1 divided in training set (N = 1878) and test set (N = 332). Distribution of High and Low risk patients not reported\\n\\nDatasets 2 and 3 used as independent test set. Distribution of High and Low risk patients not reported\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b35\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33169030\",\n",
      "            \"updated\": \"03/16/2022 16:40:33\",\n",
      "            \"authors\": \"Sani OG, Abbaspourazad H, Wong YT, Pesaran B, Shanechi MM\",\n",
      "            \"journal\": \"Nat Neurosci\",\n",
      "            \"title\": \"Modeling behaviorally relevant neural dynamics enabled by preferential subspace identification.\",\n",
      "            \"doi\": \"10.1038/s41593-020-00733-0\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"b3b4561c-e904-4def-89cd-783ff01a3b12\",\n",
      "        \"shortid\": \"dmb4u51v5o\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/16/2022 16:40:33\",\n",
      "            \"publication/authors\": \"Sani OG, Abbaspourazad H, Wong YT, Pesaran B, Shanechi MM\",\n",
      "            \"publication/journal\": \"Nat Neurosci\",\n",
      "            \"publication/title\": \"Modeling behaviorally relevant neural dynamics enabled by preferential subspace identification.\",\n",
      "            \"optimization/encoding\": \"Aminoacid sequences enriched with physicochemical proprieties from AAindex (for each amino-acid)\",\n",
      "            \"optimization/features\": \"3318. No feature selection strategy.\",\n",
      "            \"optimization/fitting\": \"The number of features is huge, but no strategy for overfitting prevention was adopted.\",\n",
      "            \"model/availability\": \"The classiffier is available at: https://pitgroup.org/bap/; the source code is not available.\",\n",
      "            \"model/interpretability\": \"Transparent. The support vector machine linearly separates samples based on the physicochemical features of the aminoacids.\",\n",
      "            \"model/output\": \"Classification (amyloidogenic or nonamyloidogenic)\",\n",
      "            \"evaluation/comparison\": \"Compared with another algorithm, but the comparison is only based on the accuracy.\",\n",
      "            \"evaluation/confidence\": \"No confidence intervals or statistical significance stated.\",\n",
      "            \"evaluation/measure\": \"Accuracy, ROC curve, Area Under Curve (AUC)\",\n",
      "            \"evaluation/method\": \"Prediction on the test set.\",\n",
      "            \"dataset/availability\": \"Yes. URL for waltz database: http://waltzdb.switchlab.org/\",\n",
      "            \"dataset/provenance\": \"Waltz database of hexapeptides, classified in amyloidogenic (pos) and nonamyloidogenic (neg). N_pos = 541; N_neg = 901. Dataset used in other papers. Dataset enriched with physicochemical proprieties of amino-acids derived from AAindex. \",\n",
      "            \"dataset/redundancy\": \"The two dataset have no overlaps.\",\n",
      "            \"dataset/splits\": \"Dataset splitted in test set (N_pos = 158; N_neg = 309) and training set (N_pos = 383; N_neg = 592)\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b36\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33464298\",\n",
      "            \"updated\": \"03/21/2022 08:46:51\",\n",
      "            \"authors\": \"Kanfer G, Sarraf SA, Maman Y, Baldwin H, Dominguez-Martin E, Johnson KR, Ward ME, Kampmann M, Lippincott-Schwartz J, Youle RJ\",\n",
      "            \"journal\": \"J Cell Biol\",\n",
      "            \"title\": \"Image-based pooled whole-genome CRISPRi screening for subcellular phenotypes.\",\n",
      "            \"doi\": \"10.1083/jcb.202006180\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"621ff42a-1daa-4b6d-b190-e35478b9af68\",\n",
      "        \"shortid\": \"kr8wmng69g\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/21/2022 08:46:51\",\n",
      "            \"publication/authors\": \"Kanfer G, Sarraf SA, Maman Y, Baldwin H, Dominguez-Martin E, Johnson KR, Ward ME, Kampmann M, Lippincott-Schwartz J, Youle RJ\",\n",
      "            \"publication/journal\": \"J Cell Biol\",\n",
      "            \"publication/title\": \"Image-based pooled whole-genome CRISPRi screening for subcellular phenotypes.\",\n",
      "            \"optimization/algorithm\": \"Combination of three DenseNet-121, the output of which was combined in a final fully connected layer. \",\n",
      "            \"optimization/encoding\": \"The classifier input data are generated by an unsupervised ML algorithm (MS-AdaNet). No transformation is stated for the input data of MS-AdaNet.\",\n",
      "            \"optimization/features\": \"The inputs of the algorithm are three images. The definition of the images is not reported\",\n",
      "            \"optimization/meta\": \"Yes. The classifier input data are generated using an unsupervised ML algorithm extracting three image features from Chest X Rays scans. Such unsupervised ML algorithm is a convolutional adversarial network (they call that \\\"MS-AdaNet\\\").\\n\\nThey train and test MS-AdaNet on a independent dataset to prove its ability in extrating features. However they trained this algorithm also on the dataset use for classification when the MS-AdaNet is used as input for the classifier.\",\n",
      "            \"optimization/regularization\": \"No overfitting prevention strategy is mentioned.\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/comparison\": \"Compared with other methods presented in literature.\",\n",
      "            \"evaluation/confidence\": \"No confidence intervals or statistical significance provided.\",\n",
      "            \"evaluation/measure\": \"Accuracy, F1 score, Recall, and Precision\",\n",
      "            \"evaluation/method\": \"5-fold cross-validation\",\n",
      "            \"dataset/availability\": \"Yes. They used a public dataset published in a previous paper. Paper doi: 10.1109/ACCESS.2020.3010287\",\n",
      "            \"dataset/provenance\": \"Public dataset of Chest X Rays scans labeled for \\\"normal\\\", \\\"viral pneumonia\\\", and \\\"COVID-19\\\". N_normal = 1341; N_viral_pneumonia = 1345; N_covid19 = 219. Used in previous papers.\",\n",
      "            \"dataset/redundancy\": \"Only one dataset is used. They used 5-fold cross-validation on the dataset for evaluation.\",\n",
      "            \"dataset/splits\": \"No test or validation set used. They used 5-fold cross-validation on the dataset for evaluation. Distribution of the classes in the splits not reported\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b37\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33953201\",\n",
      "            \"updated\": \"03/06/2022 18:09:45\",\n",
      "            \"authors\": \"Ju F, Zhu J, Shao B, Kong L, Liu TY, Zheng WM, Bu D\",\n",
      "            \"journal\": \"Nat Commun\",\n",
      "            \"title\": \"CopulaNet: Learning residue co-evolution directly from multiple sequence alignment for protein structure prediction.\",\n",
      "            \"doi\": \"10.1038/s41467-021-22869-8\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"4d57e85d-7eba-478f-9400-c8f4acb9fdcc\",\n",
      "        \"shortid\": \"1bn52lke7u\",\n",
      "        \"score\": 0.57,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/06/2022 18:09:45\",\n",
      "            \"publication/authors\": \"Ju F, Zhu J, Shao B, Kong L, Liu TY, Zheng WM, Bu D\",\n",
      "            \"publication/journal\": \"Nat Commun\",\n",
      "            \"publication/title\": \"CopulaNet: Learning residue co-evolution directly from multiple sequence alignment for protein structure prediction.\",\n",
      "            \"optimization/algorithm\": \"Neural network\",\n",
      "            \"optimization/encoding\": \"n-dimensional vectors\",\n",
      "            \"optimization/regularization\": \"Yes, Global orthogonal regularization (alpha = 1)\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"dataset/availability\": \"Yes, https://chemicalchecker.org/\",\n",
      "            \"dataset/provenance\": \"Public database\",\n",
      "            \"dataset/splits\": \"Size not reported 80:20 train-test split\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b38\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"34099697\",\n",
      "            \"updated\": \"03/07/2022 21:14:17\",\n",
      "            \"authors\": \"Gao D, Morini E, Salani M, Krauson AJ, Chekuri A, Sharma N, Ragavendran A, Erdin S, Logan EM, Li W, Dakka A, Narasimhan J, Zhao X, Naryshkin N, Trotta CR, Effenberger KA, Woll MG, Gabbeta V, Karp G, Yu Y, Johnson G, Paquette WD, Cutting GR, Talkowski ME, Slaugenhaupt SA\",\n",
      "            \"journal\": \"Nat Commun\",\n",
      "            \"title\": \"A deep learning approach to identify gene targets of a therapeutic for human splicing disorders.\",\n",
      "            \"doi\": \"10.1038/s41467-021-23663-2\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"9bbabc44-4041-4c29-aacc-649db0ba034b\",\n",
      "        \"shortid\": \"ix9p2rdt6k\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/07/2022 21:14:17\",\n",
      "            \"publication/authors\": \"Gao D, Morini E, Salani M, Krauson AJ, Chekuri A, Sharma N, Ragavendran A, Erdin S, Logan EM, Li W, Dakka A, Narasimhan J, Zhao X, Naryshkin N, Trotta CR, Effenberger KA, Woll MG, Gabbeta V, Karp G, Yu Y, Johnson G, Paquette WD, Cutting GR, Talkowski ME, Slaugenhaupt SA\",\n",
      "            \"publication/journal\": \"Nat Commun\",\n",
      "            \"publication/title\": \"A deep learning approach to identify gene targets of a therapeutic for human splicing disorders.\",\n",
      "            \"optimization/algorithm\": \"Generalized Linear models, SVM, NN, Random Forests and XGBoost,\",\n",
      "            \"optimization/encoding\": \"Normalization according to an external reference Gut. 2014;63(11):1700\\u201310. https://doi.org/10.1136/gutjnl-2013-305806.\",\n",
      "            \"optimization/features\": \"No description\",\n",
      "            \"optimization/fitting\": \"No description\",\n",
      "            \"optimization/parameters\": \"No description\",\n",
      "            \"model/interpretability\": \"Linear models and ensemble methods\",\n",
      "            \"model/output\": \"both regression and classification\",\n",
      "            \"evaluation/comparison\": \"No comparison\",\n",
      "            \"evaluation/confidence\": \"Unpaired or paired Student t-test and log-rank tests for Kaplan-Meier\",\n",
      "            \"evaluation/method\": \"one training set, one test set and one validation set.\",\n",
      "            \"dataset/availability\": \"No. However, raw data can be downloaded  as data sets can be of GSE53625 from GEO (https://www.ncbi.nlm.nih.gov/geo/) and 37 ESCC cases with Asian ancestry from TCGA (UCSC Xena, https://xena.ucsc.edu/).\",\n",
      "            \"dataset/provenance\": \"Downloaded from public sources\",\n",
      "            \"dataset/redundancy\": \"No similarity check\",\n",
      "            \"dataset/splits\": \"Train set of 134 samples, test of 45 samples, and a validation sets consisting of 86 samples. No mention to N_pos or N_neg.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b57\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33810341\",\n",
      "            \"updated\": \"02/18/2022 08:57:44\",\n",
      "            \"authors\": \"Keresztes L, Sz\\u00f6gi E, Varga B, Farkas V, Perczel A, Grolmusz V\",\n",
      "            \"journal\": \"Biomolecules\",\n",
      "            \"title\": \"The Budapest Amyloid Predictor and Its Applications.\",\n",
      "            \"doi\": \"10.3390/biom11040500\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"396609c8-552f-4eed-9c3e-18a8c4238dd0\",\n",
      "        \"shortid\": \"bd02oq0dn5\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/18/2022 08:57:44\",\n",
      "            \"publication/authors\": \"Keresztes L, Sz\\u00f6gi E, Varga B, Farkas V, Perczel A, Grolmusz V\",\n",
      "            \"publication/title\": \"The Budapest Amyloid Predictor and Its Applications.\",\n",
      "            \"optimization/encoding\": \"global features invlude various clinical characteristis of sampes.\",\n",
      "            \"optimization/features\": \"4(Plasma samples were used to measure cell-free Dnot reported, NE-Dnot reported, MPO-Dnot reported,\\nand citH3-Dnot reported complexes from training and validation sets.)\",\n",
      "            \"optimization/parameters\": \"Grid search and Gaussian radial basis function kernels were implemented for tuning parameters.\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"classification: binary predictions\",\n",
      "            \"evaluation/comparison\": \"novel approach\",\n",
      "            \"evaluation/confidence\": \"svms accuracy\",\n",
      "            \"evaluation/measure\": \"ROC, AUC, sensitivity, specificity\",\n",
      "            \"evaluation/method\": \"indipendent dataset\",\n",
      "            \"dataset/availability\": \"in supplementary files\",\n",
      "            \"dataset/provenance\": \"they created the dataset\",\n",
      "            \"dataset/splits\": \"training set: 40 (23 active and 17 inactive) patients & 24 healthy, validation set: 26 (18 active and 8 inactive) patients & 16 healthy\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b58\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"32991297\",\n",
      "            \"updated\": \"02/18/2022 09:58:28\",\n",
      "            \"authors\": \"Bao G, Xu R, Wang X, Ji J, Wang L, Li W, Zhang Q, Huang B, Chen A, Zhang D, Kong B, Yang Q, Yuan C, Wang X, Wang J, Li X\",\n",
      "            \"journal\": \"IEEE J Biomed Health Inform\",\n",
      "            \"title\": \"Identification of lncRNA Signature Associated With Pan-Cancer Prognosis.\",\n",
      "            \"doi\": \"10.1109/JBHI.2020.3027680\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"9d6ac10d-1ae3-42d0-bc30-3a9363a41b6f\",\n",
      "        \"shortid\": \"lmmde595pw\",\n",
      "        \"score\": 0.86,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/18/2022 09:58:28\",\n",
      "            \"publication/authors\": \"Bao G, Xu R, Wang X, Ji J, Wang L, Li W, Zhang Q, Huang B, Chen A, Zhang D, Kong B, Yang Q, Yuan C, Wang X, Wang J, Li X\",\n",
      "            \"publication/journal\": \"IEEE J Biomed Health Inform\",\n",
      "            \"publication/title\": \"Identification of lncRNA Signature Associated With Pan-Cancer Prognosis.\",\n",
      "            \"optimization/algorithm\": \"SVM (FITCSVM)\",\n",
      "            \"optimization/config\": \"No. URL given for model availability but link is broken (not sure what exact information was available in the URL)\",\n",
      "            \"optimization/encoding\": \"Yes: specific sequence features\\n(k-nucleotide frequency (KNF), k-spaced nucleotide pair frequency (KSNPF), position-specific nucleotide propensity (PSNP), k-spaced position-specific dinucleotide propensity (KSPSDP), pseudo dinucleotide composition (PseDNC), Chemical property with density (CPD))\\n\",\n",
      "            \"optimization/features\": \"Yes: number of features and feature selection on the ten-fold cross-validation dataset using sequential forward feature selection (SFS)\",\n",
      "            \"optimization/fitting\": \"No exclusion mentioned\",\n",
      "            \"optimization/parameters\": \"Yes: 2 (box constraint and kernel scale)\\nSelected through grid search on ten-fold cross-validation dataset\",\n",
      "            \"optimization/regularization\": \"Yes (sequential forward feature selection (SFS) to reduce redundant features)\",\n",
      "            \"model/availability\": \"Website URL (but link is broken)\",\n",
      "            \"model/interpretability\": \"Transparent at the level of the feature selection (evaluation results for different combinations of features), put in connection with mean sequence difference between positive and negative sets\",\n",
      "            \"evaluation/comparison\": \"Comparison of SVM with other classifiers (KNN, Adaboost, random forests, decision tree, logistic regression and XGBoost) on the same cross-validation dataset.\\n Comparison of their best method (SVM) with five other existing methods with webserver availability (RNAm5Cfinder, iRNA-m5C, iRNAm5C-PseDNC and RNAm5Cpred, PEA-m5C). Table presenting algorithm class and features used by these methods is presented.\",\n",
      "            \"evaluation/confidence\": \"List of so-called \\u201csignificantly higher\\u201c performance metric values in favor of their method, but without confidence interval or explicit p-values or even name of test performed.\",\n",
      "            \"evaluation/measure\": \"Accuracy, sensitivity, specificity, precision, Matthews correlation coefficient and F1-score.\\n Area under ROC and PRC\",\n",
      "            \"evaluation/method\": \"Independent test set\",\n",
      "            \"dataset/availability\": \"Yes, supposedly. Datasets are supposed to be available through URL (https://zhulab.ahu.edu.cn/m5CPred-SVM/) but link does not respond\",\n",
      "            \"dataset/provenance\": \"Yes: source of data. Used by previous papers.\",\n",
      "            \"dataset/redundancy\": \"Yes: procedure to remove sequences with similarity >70% is applied in negative and positive datasets\",\n",
      "            \"dataset/splits\": \"Yes: size of training, validation and test sets as well as distribution of N_pos and N_neg are given.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b59\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"34070374\",\n",
      "            \"updated\": \"03/26/2022 18:39:06\",\n",
      "            \"authors\": \"Arredondo Eve A, Tunc E, Liu YJ, Agrawal S, Erbak Yilmaz H, Emren SV, Aky\\u0131ld\\u0131z Ak\\u00e7ay F, Mainzer L, \\u017durauskien\\u0117 J, Madak Erdogan Z\",\n",
      "            \"journal\": \"Metabolites\",\n",
      "            \"title\": \"Identification of Circulating Diagnostic Biomarkers for Coronary Microvascular Disease in Postmenopausal Women Using Machine-Learning Techniques.\",\n",
      "            \"doi\": \"10.3390/metabo11060339\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"26486d2e-e909-4b8a-a883-ec4878c2a8e0\",\n",
      "        \"shortid\": \"65taxw9gs8\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/26/2022 18:39:06\",\n",
      "            \"publication/authors\": \"Arredondo Eve A, Tunc E, Liu YJ, Agrawal S, Erbak Yilmaz H, Emren SV, Aky\\u0131ld\\u0131z Ak\\u00e7ay F, Mainzer L, \\u017durauskien\\u0117 J, Madak Erdogan Z\",\n",
      "            \"publication/title\": \"Identification of Circulating Diagnostic Biomarkers for Coronary Microvascular Disease in Postmenopausal Women Using Machine-Learning Techniques.\",\n",
      "            \"optimization/algorithm\": \"Novel prediction algorithm: Smooth-Threshold Multivariate Genetic Prediction (STMGP)\",\n",
      "            \"optimization/features\": \"They prepared SNP data, phenotype data, and covariate data for both the training and test\\ndatasets for the input of the function (3 features).\",\n",
      "            \"optimization/parameters\": \"2 tuning parameters.\",\n",
      "            \"optimization/regularization\": \"Strategy to reduce overfitting: screening and building penalized regression models.\",\n",
      "            \"model/availability\": \"The program code for STMGP (STMGP v1.0), including the function used in the study, is available via CRAN, the official R package archive.\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/comparison\": \"The performance of STMGP was evaluated in terms of prediction accuracy and\\n the degree of overfitting, and compared with that of other state-of-the-art methods, which included, in addition to PRS and GBLUP, summary-data-based best linear-unbiased prediction (SBLUP) , BayesR (a Bayesian hierarchical model for complex trait analysis) , and ridge regression (penalized regression model).\",\n",
      "            \"evaluation/confidence\": \"STMGP showed the highest prediction accuracy with the lowest degree of overfitting, although there was no significant difference in prediction accuracy.\",\n",
      "            \"evaluation/method\": \"The performance of STMGP was evaluated in terms of prediction accuracy and the degree of overfitting.\",\n",
      "            \"dataset/provenance\": \"SNP data for a total of 9966 subjects: 4974 training cohort subjects living in Miyagi prefecture recruited by Tohoku University and 4992 validation cohort subjects living in Iwate prefecture recruited by Iwate Medical University. \",\n",
      "            \"dataset/redundancy\": \"Training and test sets are independent. Subjects with a low call rate (<0.98, n = 2 in the training cohort and n = 3 in the validation cohort) were excluded.\\nThey detected 2156 close-relationship pairs (620 in the training cohort and 1536 in the validation cohort) using the identity-by-descent method in PLINK software among the training cohort, the validation cohort, or between these cohorts. Then, in each of these pairs, a subject with lower call rates was excluded. Variants with low call rates, low Hardy\\u2013Weinberg equilibrium exact-test P values, or low minor-allele frequencies were filtered out. Subjects without outcome or covariate information (n = 669 in the training cohort and n = 408 in the validation cohort) were excluded. Finally, 3685 subjects in the training cohort and 3048 subjects in the validation cohort with 615,386 variants were subjected to prediction analyses.\",\n",
      "            \"dataset/splits\": \"After filtering, 3685 subjects in the training cohort and 3048 subjects in the validation cohort with 615,386 variants were subjected to prediction analyses.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b5a\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"34229736\",\n",
      "            \"updated\": \"03/29/2022 22:22:24\",\n",
      "            \"authors\": \"Koo BS, Eun S, Shin K, Yoon H, Hong C, Kim DH, Hong S, Kim YG, Lee CK, Yoo B, Oh JS\",\n",
      "            \"journal\": \"Arthritis Res Ther\",\n",
      "            \"title\": \"Machine learning model for identifying important clinical features for predicting remission in patients with rheumatoid arthritis treated with biologics.\",\n",
      "            \"doi\": \"10.1186/s13075-021-02567-y\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"fff9d12e-3bb2-4353-9447-8540487d7c84\",\n",
      "        \"shortid\": \"h1b95pkq6c\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/29/2022 22:22:24\",\n",
      "            \"publication/authors\": \"Koo BS, Eun S, Shin K, Yoon H, Hong C, Kim DH, Hong S, Kim YG, Lee CK, Yoo B, Oh JS\",\n",
      "            \"publication/journal\": \"Arthritis Res Ther\",\n",
      "            \"publication/title\": \"Machine learning model for identifying important clinical features for predicting remission in patients with rheumatoid arthritis treated with biologics.\",\n",
      "            \"optimization/algorithm\": \"The VGG-16 network architecture (Simonyan & Zisserman, 2014) has been updated to replace the last block containing the softmax classification with a fully-connected layer\\n(FCL).\",\n",
      "            \"optimization/encoding\": \"Data augmentation: blur (+ affine transform), contrast (+ affine transform), noise (+ affine transform). In total, for every image in the original dataset, additional 150 images have been generated through the presented augmentation process.\",\n",
      "            \"optimization/features\": \"The extracted features are flattened: input feature vector [7*7*512].\",\n",
      "            \"optimization/fitting\": \"They report overfitting and state that they will evaluate the performance of the network training against the overfitting in future research activity.\",\n",
      "            \"optimization/parameters\": \"The weights of the VGG-16 network have been preserved from the pre-trained model. FCL layer network which consists of 2-layers. The first layer is activated by the ReLU function and consists of 256 nodes, followed by the second layer consisting of 16 nodes activated by softmax.\",\n",
      "            \"model/duration\": \"The cloud-based deployment of the CPU-only Tensorflow with Keras library has resulted\\n in the computational time between 2 s to 2.99 s for the classification of the input image and provide a response to the mobile application.\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"dataset/provenance\": \"Data collection was conducted through samples aggregated from mango\\nplants. Data is composed of images. \\nThey perform 3 experimental scenarios: Dataset size (510, 46.500, 62.047).\",\n",
      "            \"dataset/splits\": \"The overall original dataset has been divided into three subsets\\nnamely (i) training; (ii) validation and (iii) testing with 60%, 20% and\\n20% respectively.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b5b\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"34099048\",\n",
      "            \"updated\": \"06/23/2022 03:51:32\",\n",
      "            \"authors\": \"Gonzalez G, Gong S, Laponogov I, Bronstein M, Veselkov K\",\n",
      "            \"journal\": \"Hum Genomics\",\n",
      "            \"title\": \"Predicting anticancer hyperfoods with graph convolutional networks.\",\n",
      "            \"doi\": \"10.1186/s40246-021-00333-4\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"d8f4a424-12a1-40cc-8bde-3f756df2316b\",\n",
      "        \"shortid\": \"v4efeulceq\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"06/23/2022 03:51:32\",\n",
      "            \"publication/authors\": \"Gonzalez G, Gong S, Laponogov I, Bronstein M, Veselkov K\",\n",
      "            \"publication/journal\": \"Hum Genomics\",\n",
      "            \"publication/title\": \"Predicting anticancer hyperfoods with graph convolutional networks.\",\n",
      "            \"optimization/algorithm\": \"accelerated generalized gradient descent. \",\n",
      "            \"optimization/encoding\": \"SVD for groups' separation\",\n",
      "            \"optimization/parameters\": \"p=6. penalty parameter \\u03bb,  \\u03b1 \\u2208 [0, 1] is the mixing parameter which convexly links the penalties, \\u03b5_rel relative accuracy,  groups from SVD, weights for each explanatory variable, proportion \\u03be \\u03bbmin = \\u03be\\u03bbmax.\",\n",
      "            \"optimization/regularization\": \"Yes. Regularization paths for the lasso, group lasso, sparse-group lasso, and IPF-lasso for linear regression models\",\n",
      "            \"model/availability\": \"yes in Additional files and https://github.com/jklosa/seagull\",\n",
      "            \"model/duration\": \"20'-5h compared to 45h of previous methods\",\n",
      "            \"model/output\": \"regression of methylation age of mice. Eventually, seagull provides a sequence of penalty parameters and calculates the corresponding path of solutions.\",\n",
      "            \"evaluation/comparison\": \"comparison of the outcome of seagull to that of the established R package SGL 1.3\",\n",
      "            \"evaluation/confidence\": \"the results of seagull and SGL were very similar (R^2 > 0.99)\",\n",
      "            \"evaluation/measure\": \"MSE of predicted age based on methylation data, squared correlation coefficient R^2 between predicted and chronological age, the number\\n of features with an estimated effect different from zero, the execution\\n time needed to compute the entire regularization path.\",\n",
      "            \"evaluation/method\": \"independent dataset\",\n",
      "            \"dataset/availability\": \"Yes. https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE80672\",\n",
      "            \"dataset/provenance\": \"The data set is publicly available\\nand described in detail in https://doi.org/10.1016/j.cmet.2017.03.016 \\n141 data points, problem of regression for predicting chronological age of mice based on their methylation profiles.\",\n",
      "            \"dataset/redundancy\": \"\\u0391ll age classes appeared almost equally in both sets.\",\n",
      "            \"dataset/splits\": \"training (n = 75) and validation(n = 66)\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b77\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"34603483\",\n",
      "            \"updated\": \"04/06/2022 17:27:29\",\n",
      "            \"authors\": \"Zhang S, Qu R, Wang P, Wang S\",\n",
      "            \"journal\": \"Comput Math Methods Med\",\n",
      "            \"title\": \"Identification of Novel COVID-19 Biomarkers by Multiple Feature Selection Strategies.\",\n",
      "            \"doi\": \"10.1155/2021/2203636\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"ea4a498a-ad09-4fe4-9fba-a01b495ea341\",\n",
      "        \"shortid\": \"6ykikkh959\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"04/06/2022 17:27:29\",\n",
      "            \"publication/authors\": \"Zhang S, Qu R, Wang P, Wang S\",\n",
      "            \"publication/journal\": \"Comput Math Methods Med\",\n",
      "            \"publication/title\": \"Identification of Novel COVID-19 Biomarkers by Multiple Feature Selection Strategies.\",\n",
      "            \"optimization/algorithm\": \"Novel approach: They develop a machine learning model to predict BA based on 2 large sleep EEG data sets. The model is described in the paper.\",\n",
      "            \"optimization/config\": \"yes, included in the paper.\",\n",
      "            \"optimization/encoding\": \"EEG signals are notch-filtered at 60 Hz to reduce line noise, and bandpass filtered from 0.5 Hz to 20 Hz to reduce myogenic artifacts.\\nFor 30s-epochs, those with absolute amplitude larger than 500 m V are removed to minimize movement artifacts. Epochs containing flat EEG for more than 2 seconds are also removed. We also exclude EEGs contaminated by electrocardiogram, indicated by 1 Hz harmonic in the EEG spectrogram. To reduce interparticipant variance, the amplitude of each EEG channel is normalized to have zero median and unit interquartile range across the whole night. The total amount of data removed by these preprocessing procedures is\\n7% in the MGH data set and 9% in the SHHS data set.\",\n",
      "            \"optimization/features\": \"They extract 102 features from each 30-second epoch covering both time and frequency domains. For each EEG recording, they average the features in each of the 5 sleep stages overtime, yielding 102 x 5 = 510 features per EEG.\",\n",
      "            \"optimization/fitting\": \"One strength of the study is the use of large data sets. The number of EEGs involved in this study is large among relevant \\u201cBA\\u201d studies. The large size of the data sets helps to ensure the statistical power as well and to minimize selection bias. A large training set helps ensure that the trained model does not overfit to a particular data set, improving the ability togeneralize when applied beyond the training set. A large testing set allows accurate statistical measurement of how accurately the\\nmodel performs.\",\n",
      "            \"optimization/parameters\": \"one. To determine the optimal hyperparameter, they randomly select 300 EEGs from the training set to serve as internal validation data.\",\n",
      "            \"model/interpretability\": \"Transparent. The use of a parametric model, improves model interpretation by inspecting each EEG feature and comparing to the age norm for each feature explicitly. An example is provided in Figure 5 of the paper.\",\n",
      "            \"evaluation/confidence\": \"The method reports statistical significant results.\",\n",
      "            \"evaluation/method\": \"The model is validated on a longitudinal cohort from a subset of the SHHS data set without neurological or cardiovascular disease.\",\n",
      "            \"dataset/provenance\": \"2 large sleep EEG data sets: the Massachusetts General Hospital (MGH) sleep lab\\ndata set (N = 2532; ages 18-80); and the Sleep Heart Health Study (SHHS, N =1974; ages 40-80)\",\n",
      "            \"dataset/redundancy\": \"They maintain strict separation of training and testing participants.\",\n",
      "            \"dataset/splits\": \"The MGH data set (N =2532) was partitioned into a healthy training set (N = 1343) used to train the model, and a testing set (N =1189) to evaluate model performance.\\n\\nAs validation, they used a subset of the SHHS data set where each participant underwent 2 study visits, referred as SHHS1 and SHHS2. The data set contains 987 adults for a total of 1974 nights of EEG recorded. They trained the model in 2 ways. First, they trained the model on 752 participants with paired EEGs (1504 EEGs) from both visits and tested on the held out 235 participants with paired EEGs (470 EEGs) in both visits. They trained the model on the 2365 EEGs from healthy participants in MGH data set. We then predicted BA on the 1974 paired EEGs in SHHS as the testing set.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b78\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33535965\",\n",
      "            \"updated\": \"03/28/2022 20:30:14\",\n",
      "            \"authors\": \"Momeni J, Parejo M, Nielsen RO, Langa J, Montes I, Papoutsis L, Farajzadeh L, Bendixen C, C\\u0103uia E, Charri\\u00e8re JD, Coffey MF, Costa C, Dall'Olio R, De la R\\u00faa P, Drazic MM, Filipi J, Galea T, Golubovski M, Gregorc A, Grigoryan K, Hatjina F, Ilyasov R, Ivanova E, Janashia I, Kandemir I, Karatasou A, Kekecoglu M, Kezic N, Matray ES, Mifsud D, Moosbeckhofer R, Nikolenko AG, Papachristoforou A, Petrov P, Pinto MA, Poskryakov AV, Sharipov AY, Siceanu A, Soysal MI, Uzunov A, Zammit-Mangion M, Vingborg R, Bouga M, Kryger P, Meixner MD, Estonba A\",\n",
      "            \"journal\": \"BMC Genomics\",\n",
      "            \"title\": \"Authoritative subspecies diagnosis tool for European honey bees based on ancestry informative SNPs.\",\n",
      "            \"doi\": \"10.1186/s12864-021-07379-7\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"bfdbba26-c83c-43c0-8067-6e78c75facb7\",\n",
      "        \"shortid\": \"m2bccoqnyy\",\n",
      "        \"score\": 0.57,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/28/2022 20:30:14\",\n",
      "            \"publication/authors\": \"Momeni J, Parejo M, Nielsen RO, Langa J, Montes I, Papoutsis L, Farajzadeh L, Bendixen C, C\\u0103uia E, Charri\\u00e8re JD, Coffey MF, Costa C, Dall'Olio R, De la R\\u00faa P, Drazic MM, Filipi J, Galea T, Golubovski M, Gregorc A, Grigoryan K, Hatjina F, Ilyasov R, Ivanova E, Janashia I, Kandemir I, Karatasou A, Kekecoglu M, Kezic N, Matray ES, Mifsud D, Moosbeckhofer R, Nikolenko AG, Papachristoforou A, Petrov P, Pinto MA, Poskryakov AV, Sharipov AY, Siceanu A, Soysal MI, Uzunov A, Zammit-Mangion M, Vingborg R, Bouga M, Kryger P, Meixner MD, Estonba A\",\n",
      "            \"publication/journal\": \"BMC Genomics\",\n",
      "            \"publication/title\": \"Authoritative subspecies diagnosis tool for European honey bees based on ancestry informative SNPs.\",\n",
      "            \"optimization/algorithm\": \"Logistic regression model.\",\n",
      "            \"optimization/encoding\": \"Feature selection.\",\n",
      "            \"optimization/features\": \"Hybrid feature selection schema based on information gain and sequential backward\\nfeature selection (SBFS).\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/measure\": \"96.2% sensitivity and 95.2% specificity\",\n",
      "            \"evaluation/method\": \"tenfold cross-validation\",\n",
      "            \"dataset/availability\": \"Yes. Supplementary material of the paper.\",\n",
      "            \"dataset/provenance\": \"307 cervical tumor samples from The Cancer Genome Atlas, 113 normal.\",\n",
      "            \"dataset/splits\": \"The data were randomly divided into ten different sets. Nine sets were used for training, and the remaining set was used for validation.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b79\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"34254032\",\n",
      "            \"updated\": \"06/23/2022 03:40:26\",\n",
      "            \"authors\": \"Gladding PA, Ayar Z, Smith K, Patel P, Pearce J, Puwakdandawa S, Tarrant D, Atkinson J, McChlery E, Hanna M, Gow N, Bhally H, Read K, Jayathissa P, Wallace J, Norton S, Kasabov N, Calude CS, Steel D, Mckenzie C\",\n",
      "            \"journal\": \"Future Sci OA\",\n",
      "            \"title\": \"A machine learning PROGRAM to identify COVID-19 and other diseases from hematology data.\",\n",
      "            \"doi\": \"10.2144/fsoa-2020-0207\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"1788b70c-e3a7-4a8f-96a4-95a8ea1f3f40\",\n",
      "        \"shortid\": \"9ydtb6du8j\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"06/23/2022 03:40:26\",\n",
      "            \"publication/authors\": \"Gladding PA, Ayar Z, Smith K, Patel P, Pearce J, Puwakdandawa S, Tarrant D, Atkinson J, McChlery E, Hanna M, Gow N, Bhally H, Read K, Jayathissa P, Wallace J, Norton S, Kasabov N, Calude CS, Steel D, Mckenzie C\",\n",
      "            \"publication/journal\": \"Future Sci OA\",\n",
      "            \"publication/title\": \"A machine learning PROGRAM to identify COVID-19 and other diseases from hematology data.\",\n",
      "            \"optimization/algorithm\": \"ML prediction algorithm was developed based on an artificial neural network (ANN; JMP software, v12.0.1).\",\n",
      "            \"optimization/encoding\": \"Data were comprised of AUC values from each of the 26 cases.\",\n",
      "            \"optimization/features\": \"2 factors.\",\n",
      "            \"optimization/parameters\": \"3 hidden nodes.\",\n",
      "            \"model/availability\": \"Model developed based on an artificial neural network (ANN; JMP software, v12.0.1). There is no executable file available.\",\n",
      "            \"model/interpretability\": \"Transparent: classifies chemicals based on AUC parameters. Small dataset, few features and parameters considered.\",\n",
      "            \"model/output\": \"Classification (4 classes).\",\n",
      "            \"evaluation/comparison\": \"No comparison.\",\n",
      "            \"evaluation/confidence\": \"25 of 26 cases correctly assigned. There is a table with the probability of each case to be correctly classified.\",\n",
      "            \"evaluation/method\": \"Cross-validation, using a leave-one-out approach.\",\n",
      "            \"dataset/availability\": \"Available upon request to the authors.\",\n",
      "            \"dataset/provenance\": \"Data from previous publication and direct experiments. N= 26.\",\n",
      "            \"dataset/splits\": \"training set n = 26, divided in 4 classes. Class 1 = 10 elements, class 2 = 12, class 3 = 3, class 4 = 1.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b81\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"34573923\",\n",
      "            \"updated\": \"02/28/2022 14:25:46\",\n",
      "            \"authors\": \"Rahman T, Al-Ishaq FA, Al-Mohannadi FS, Mubarak RS, Al-Hitmi MH, Islam KR, Khandakar A, Hssain AA, Al-Madeed S, Zughaier SM, Chowdhury MEH\",\n",
      "            \"journal\": \"Diagnostics (Basel)\",\n",
      "            \"title\": \"Mortality Prediction Utilizing Blood Biomarkers to Predict the Severity of COVID-19 Using Machine Learning Technique.\",\n",
      "            \"doi\": \"10.3390/diagnostics11091582\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"10dbaffe-4a11-44af-a1ac-7efd84988759\",\n",
      "        \"shortid\": \"7cpzfr4v7k\",\n",
      "        \"score\": 0.9,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/28/2022 14:25:46\",\n",
      "            \"publication/authors\": \"Rahman T, Al-Ishaq FA, Al-Mohannadi FS, Mubarak RS, Al-Hitmi MH, Islam KR, Khandakar A, Hssain AA, Al-Madeed S, Zughaier SM, Chowdhury MEH\",\n",
      "            \"publication/journal\": \"Diagnostics (Basel)\",\n",
      "            \"publication/title\": \"Mortality Prediction Utilizing Blood Biomarkers to Predict the Severity of COVID-19 Using Machine Learning Technique.\",\n",
      "            \"optimization/algorithm\": \"Multi-view clustering methods (early and late integration, similarity based, dimension reduction and statistical methods)\",\n",
      "            \"optimization/encoding\": \"No, not in detail.\\nClass of feature used are described (gene sequence, expression and methylation) but no detail on encoding (only reference to source of data)\",\n",
      "            \"optimization/features\": \"Yes, indirectly: processed raw data and algorithm for feature selection are given\",\n",
      "            \"optimization/fitting\": \"No exclusion mentioned\",\n",
      "            \"optimization/parameters\": \"Number of clusters: algorithm for selection is presented (elbow method) \\nOther parameters are not directly given but protocol used to select them are given (= if available: adherence to the guidelines given by the packages developers) \",\n",
      "            \"optimization/regularization\": \"Yes, regularization may be used by some methods (but not clear in the publication what was really implemented in the used packages)\\ne.g.\\nLeast Absolute Shrinkage and Selection Operator regularization is used by iCluster\\nNuclear norm regularization is used by LRACluster\\nA regularization term is used by rMKL-LPP\\nSparsity regularization is used by Canonical Correlation Analysis (CCA)\",\n",
      "            \"model/availability\": \"Yes (GitHub)\",\n",
      "            \"model/duration\": \"Yes (runtime in seconds on Windows desktop for eight methods and Linux cluster for one methods)\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"Produces clusters\",\n",
      "            \"evaluation/availability\": \"Yes (supporting information)\",\n",
      "            \"evaluation/comparison\": \"Comparison of logranks\\u2019 test p-values and number of enriched clinical parameters\",\n",
      "            \"evaluation/confidence\": \"No. But no claiming of performance difference\",\n",
      "            \"evaluation/measure\": \"Logrank test (differential survival between clusters)\\n Chi-squared test and Kruskal-Wallis (clinical labels (six) enrichement in clusters)\",\n",
      "            \"evaluation/method\": \"Extrinsic measures (clinical labels)\",\n",
      "            \"dataset/availability\": \"Yes (supporting information and website URL)\",\n",
      "            \"dataset/provenance\": \"Yes (The Cancer Genome Atlas)\",\n",
      "            \"dataset/redundancy\": \"No dataset split  (unsupervised machine learning)\",\n",
      "            \"dataset/splits\": \"No dataset split  (unsupervised machine learning)\\nLabels used to assess performance are given in raw datasets\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b82\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33465072\",\n",
      "            \"updated\": \"03/23/2022 16:36:18\",\n",
      "            \"authors\": \"Mart\\u00ednez-Garc\\u00eda PM, Garc\\u00eda-Torres M, Divina F, Terr\\u00f3n-Bautista J, Delgado-Sainz I, G\\u00f3mez-Vela F, Cort\\u00e9s-Ledesma F\",\n",
      "            \"journal\": \"PLoS Comput Biol\",\n",
      "            \"title\": \"Genome-wide prediction of topoisomerase II\\u03b2 binding by architectural factors and chromatin accessibility.\",\n",
      "            \"doi\": \"10.1371/journal.pcbi.1007814\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"98d62f4d-4577-4892-9130-684c6464d69c\",\n",
      "        \"shortid\": \"conhqw242m\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/23/2022 16:36:18\",\n",
      "            \"publication/authors\": \"Mart\\u00ednez-Garc\\u00eda PM, Garc\\u00eda-Torres M, Divina F, Terr\\u00f3n-Bautista J, Delgado-Sainz I, G\\u00f3mez-Vela F, Cort\\u00e9s-Ledesma F\",\n",
      "            \"publication/journal\": \"PLoS Comput Biol\",\n",
      "            \"publication/title\": \"Genome-wide prediction of topoisomerase II\\u03b2 binding by architectural factors and chromatin accessibility.\",\n",
      "            \"optimization/algorithm\": \"AIS-ELM is compared with DS-ELM, PSOELM, SaE-ELM, traditional ELM,SVM, and Back Propagation.\",\n",
      "            \"optimization/encoding\": \"All the inputs have been normalized into the range [-1, 1] for fairness.\",\n",
      "            \"optimization/features\": \"1) Ecoli 7, Diabetes 8, Epileptic Seizure 179, Heart Disease 75, Iris 4, Glass 9, Image 19, Satellite 36\\n2)Breast Cancer 32, Parkinson 26,  SinC 1, Servo 4,  Yacht Hydro 13\",\n",
      "            \"optimization/parameters\": \"p=5, the parameters for AIS-ELM are set as follows: \\ud835\\udc4e(antibody population) =10,\\ud835\\udc4f = 50(bit position of the last \\u201con\\u201d bit starting from the most significant bit),\\ud835\\udf00 = 0.1(stimulus region),\\ud835\\udc58 = 5(number of bits that must be flipped to mutate),\\ud835\\udc5f = 0.2(mutation probability)\",\n",
      "            \"model/duration\": \"1) 1-37 seconds\\n 2) 13-33 seconds\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"1) classification\\n 2) regression\",\n",
      "            \"evaluation/confidence\": \"better timing and accuracy\",\n",
      "            \"evaluation/measure\": \"Means and Standard Deviation and training time\",\n",
      "            \"evaluation/method\": \"20-fold cross validation\",\n",
      "            \"dataset/provenance\": \"1) Ecoli, Pima Indians Diabetes\\n(Diabetes), Epileptic Seizure, Iris, Heart Disease, Glass Identification\\n(Glass), Image Segmentation (Image), and Statlog\\n(Satellite)\\n2) Breast Cancer, Parkinson, SinC, Servo, and Yacht Hydro (Yacht)\",\n",
      "            \"dataset/redundancy\": \"all datasets are without overlap, kept coincident for each trial of the algorithms.\",\n",
      "            \"dataset/splits\": \"1) Ecoli train: 180 val:78 test:78, Diabetes train: 384 val:22 test:192, Epileptic Seizure train: 6000 val:2750 test:2750, Heart Disease train: 150 val:76 test:76, Iris train: 70 val:40  test:40, Glass train: 100 val:57 test:57, Image train: 1200 val:555 test:555, Satellite train: 3435 val:1500 test:1500\\n2)Breast Cancer train:98 val:50 test:50, Parkinson train:500 val:270 test:270,  SinC train:5000 val:2500 test:2500, Servo train:384 val:192 test:192,  Yacht Hydro train:150 val:79 test:79\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b83\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"34419924\",\n",
      "            \"updated\": \"03/28/2022 16:40:10\",\n",
      "            \"authors\": \"Hogan CA, Rajpurkar P, Sowrirajan H, Phillips NA, Le AT, Wu M, Garamani N, Sahoo MK, Wood ML, Huang C, Ng AY, Mak J, Cowan TM, Pinsky BA\",\n",
      "            \"journal\": \"EBioMedicine\",\n",
      "            \"title\": \"Nasopharyngeal metabolomics and machine learning approach for the diagnosis of influenza.\",\n",
      "            \"doi\": \"10.1016/j.ebiom.2021.103546\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"b8fe2726-03eb-495c-bdf4-3ad68e43c7a5\",\n",
      "        \"shortid\": \"hilwjyqhpx\",\n",
      "        \"score\": 0.29,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/28/2022 16:40:10\",\n",
      "            \"publication/authors\": \"Hogan CA, Rajpurkar P, Sowrirajan H, Phillips NA, Le AT, Wu M, Garamani N, Sahoo MK, Wood ML, Huang C, Ng AY, Mak J, Cowan TM, Pinsky BA\",\n",
      "            \"publication/title\": \"Nasopharyngeal metabolomics and machine learning approach for the diagnosis of influenza.\",\n",
      "            \"optimization/algorithm\": \"T-distributed stochastic neighbor embedding (t-SNE).\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"dataset/provenance\": \"Data from experiments.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b8e\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33510068\",\n",
      "            \"updated\": \"02/23/2022 14:26:24\",\n",
      "            \"authors\": \"Skolariki K, Terrera GM, Danso SO\",\n",
      "            \"journal\": \"Neural Regen Res\",\n",
      "            \"title\": \"Predictive models for mild cognitive impairment to Alzheimer's disease conversion.\",\n",
      "            \"doi\": \"10.4103/1673-5374.306071\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"a17d89ff-989f-4293-97a5-94abd04679d9\",\n",
      "        \"shortid\": \"b365zwv48h\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/23/2022 14:26:24\",\n",
      "            \"publication/authors\": \"Skolariki K, Terrera GM, Danso SO\",\n",
      "            \"publication/journal\": \"Neural Regen Res\",\n",
      "            \"publication/title\": \"Predictive models for mild cognitive impairment to Alzheimer's disease conversion.\",\n",
      "            \"optimization/algorithm\": \"Deep convolutional neural network trained using gradient descent by standard backpropagation algorithm.\",\n",
      "            \"optimization/encoding\": \"Moving window length across the input sequences by the convolutional kernels and formation of feature maps. One-hot-encoding was used to create vectors for all the types of genotypes available, to ensure that all the categories are equidistant from each other.\",\n",
      "            \"optimization/features\": \"Featured maps formed from filtered exonic variants, one-hot encoded per chromosome.\",\n",
      "            \"optimization/fitting\": \"Application of a batch normalization layer after the max-pooling layer contributes to avoiding overfitting the data. Additionally, balanced training, validation and testing datasets were used.\",\n",
      "            \"optimization/parameters\": \"The deep convolutional network takes in a 23-channel input, with each input being the one-hot encoded variants of a chromosome. Initializing weights to reduce the loss function at each epoch.\",\n",
      "            \"optimization/regularization\": \"Yes. Reduction of feature dimension using L1 regularization with penalty parameter C = 0.85. Less than 1% of the total features remain.\",\n",
      "            \"model/duration\": \"Training the model end-to-end takes close to 6 hours on Nvidia Tesla M40 servers.\",\n",
      "            \"model/interpretability\": \"Black box. Reduced performance due to repeated feature subsampling supports the importance of all features in model performance and the absence of sequencing method artifacts.\",\n",
      "            \"model/output\": \"Classification with binary predictions.\",\n",
      "            \"evaluation/comparison\": \"Decision trees and random forests.\",\n",
      "            \"evaluation/confidence\": \"Higher performance metrics of the convolutional neural network (e.g., accuracy = 0.65) than those of the comparing algorithms (accuracy = 0.55). Confidence intervals were not calculated, and statistical testing was not applied.\",\n",
      "            \"evaluation/measure\": \"Accuracy, Precision, Recall, F1-Score, AUC score, ROC curve.\",\n",
      "            \"dataset/provenance\": \"Exome sequencing data for 1000 samples. Npos = 500 (control group). Nneg = 500 (disease group). Ntrain = 500. Ntest = 500. Data were provided from the Regents of the University of California under the challenge \\u201cBipolar Exomes\\u201d.\",\n",
      "            \"dataset/redundancy\": \"Random sampling from the pool of 1000 samples and balanced datasets between train, validation, and test datasets.\",\n",
      "            \"dataset/splits\": \"Npos,train = 200. Nneg,train = 200. Validation set present. Npos,validation = 50. Nneg,validation = 50. Npos,test = 249. Nneg,test = 251.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b8f\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33946997\",\n",
      "            \"updated\": \"03/12/2022 20:11:43\",\n",
      "            \"authors\": \"Koureas M, Kalompatsios D, Amoutzias GD, Hadjichristodoulou C, Gourgoulianis K, Tsakalof A\",\n",
      "            \"journal\": \"Molecules\",\n",
      "            \"title\": \"Comparison of Targeted and Untargeted Approaches in Breath Analysis for the Discrimination of Lung Cancer from Benign Pulmonary Diseases and Healthy Persons.\",\n",
      "            \"doi\": \"10.3390/molecules26092609\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"35bd5800-8ba0-4243-bf5c-09f8cfdd9734\",\n",
      "        \"shortid\": \"47cb9iahma\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/12/2022 20:11:43\",\n",
      "            \"publication/authors\": \"Koureas M, Kalompatsios D, Amoutzias GD, Hadjichristodoulou C, Gourgoulianis K, Tsakalof A\",\n",
      "            \"publication/title\": \"Comparison of Targeted and Untargeted Approaches in Breath Analysis for the Discrimination of Lung Cancer from Benign Pulmonary Diseases and Healthy Persons.\",\n",
      "            \"optimization/encoding\": \"Fragments of atoms and bonds (ISIDA Fragmentor software) scaled to the interval [0-1]\",\n",
      "            \"optimization/features\": \"Yes: 5-25 features per model, randomly selected among 250 most informative on training dataset (removal of features returning nearly constant values (about for 99%) and selection of top-250 according to Mutual Information Quotient score (Minimal Redundancy Maximal Relevance mRMR algorithm))\",\n",
      "            \"optimization/meta\": \"Yes: model aggregation (ensemble modeling) and multi-criteria decision making\\nTrained on the same dataset\",\n",
      "            \"optimization/parameters\": \"2 LSSVM parameters (RBF kernel (\\u03c32) and regularization (\\u03b3)) \\nMinimization of the misclassification rate of the 10-fold cross-validated training dataset\",\n",
      "            \"optimization/regularization\": \"Yes: \\u03b3 parameter (LSSVM) \",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"Classification and score based on LSSVM scores\",\n",
      "            \"evaluation/measure\": \"Accuracy (Acc), Sensitivity (Se), Specificity (Sp) and Balanced Classification Rate (BCR)\\n Area Under the Accumulation Curve (AUAC); Area under the Receiver Operating Characteristic Curve (ROC); Enrichment factor (EF) and Boltzmann-enhanced discrimination of ROC (BEDROC)\",\n",
      "            \"evaluation/method\": \"Independent dataset\",\n",
      "            \"dataset/availability\": \"Yes, in supporting information\",\n",
      "            \"dataset/provenance\": \"Yes (ChEMBL-NTD Novartis dataset and dataset from previous publication)\",\n",
      "            \"dataset/redundancy\": \"Yes, independent training, test and external test sets generated using sphere exclusion algorithms\",\n",
      "            \"dataset/splits\": \"Yes: N_pos and N_neg for training, test and external test sets\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b90\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33953203\",\n",
      "            \"updated\": \"03/16/2022 16:16:20\",\n",
      "            \"authors\": \"Szkalisity A, Piccinini F, Beleon A, Balassa T, Varga IG, Migh E, Molnar C, Paavolainen L, Timonen S, Banerjee I, Ikonen E, Yamauchi Y, Ando I, Peltonen J, Pieti\\u00e4inen V, Honti V, Horvath P\",\n",
      "            \"journal\": \"Nat Commun\",\n",
      "            \"title\": \"Regression plane concept for analysing continuous cellular processes with machine learning.\",\n",
      "            \"doi\": \"10.1038/s41467-021-22866-x\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"92182157-6ae9-46f7-873c-ac1450fee9f5\",\n",
      "        \"shortid\": \"fnmlhciok7\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/16/2022 16:16:20\",\n",
      "            \"publication/authors\": \"Szkalisity A, Piccinini F, Beleon A, Balassa T, Varga IG, Migh E, Molnar C, Paavolainen L, Timonen S, Banerjee I, Ikonen E, Yamauchi Y, Ando I, Peltonen J, Pieti\\u00e4inen V, Honti V, Horvath P\",\n",
      "            \"publication/journal\": \"Nat Commun\",\n",
      "            \"publication/title\": \"Regression plane concept for analysing continuous cellular processes with machine learning.\",\n",
      "            \"optimization/algorithm\": \"Word2Vec + Random Forest\",\n",
      "            \"model/availability\": \"Soft available separately.\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"model/output\": \"Multiclass Multilabel Classification\",\n",
      "            \"evaluation/measure\": \"precision, recall, F1-score\",\n",
      "            \"dataset/provenance\": \"Yes, CheMBL\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b91\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33953534\",\n",
      "            \"updated\": \"03/18/2022 15:31:10\",\n",
      "            \"authors\": \"Uthamacumaran A, Suarez NG, Banir\\u00e9 Diallo A, Annabi B\",\n",
      "            \"journal\": \"Cancer Inform\",\n",
      "            \"title\": \"Computational Methods for Structure-to-Function Analysis of Diet-Derived Catechins-Mediated Targeting of In Vitro Vasculogenic Mimicry.\",\n",
      "            \"doi\": \"10.1177/11769351211009229\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"b3a17544-6140-497c-a0d5-c3ee482dce5e\",\n",
      "        \"shortid\": \"mnu68fbrdn\",\n",
      "        \"score\": 0.95,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/18/2022 15:31:10\",\n",
      "            \"publication/authors\": \"Uthamacumaran A, Suarez NG, Banir\\u00e9 Diallo A, Annabi B\",\n",
      "            \"publication/journal\": \"Cancer Inform\",\n",
      "            \"publication/title\": \"Computational Methods for Structure-to-Function Analysis of Diet-Derived Catechins-Mediated Targeting of In Vitro Vasculogenic Mimicry.\",\n",
      "            \"optimization/algorithm\": \"FORCE method using Izhikevich, Theta and LIF neuron models. It does not seem to be a novel approach as they mention building upon others.\",\n",
      "            \"optimization/config\": \"Not sure. MatLab code is available so I guess it is possible to change the hyper-parameter configuration there. See https://senselab.med.yale.edu/ModelDB/ShowModel?model=190565\",\n",
      "            \"optimization/encoding\": \"I did not see it in the text\",\n",
      "            \"optimization/features\": \"I did not see it in the text\",\n",
      "            \"optimization/fitting\": \"I did not see it in the text\",\n",
      "            \"optimization/meta\": \"I did not see it in the text\",\n",
      "            \"optimization/parameters\": \"There is a box listing parameters and their values. They mention previous works for tuning the parameters (not sure if they cover all of the parameters though)\",\n",
      "            \"optimization/regularization\": \"I did not see it in the text\",\n",
      "            \"model/availability\": \"Yes, see https://senselab.med.yale.edu/ModelDB/ShowModel?model=190565 (also in GitHub at https://github.com/ModelDBRepository/190565) I did not see a license\",\n",
      "            \"model/interpretability\": \"It did not look very transparent to me\",\n",
      "            \"model/output\": \"It produces a reproduction, e.g. given a song, the neural network is trained to reproduce it.\",\n",
      "            \"evaluation/availability\": \"I did not see it in the text but it could be part of the available code\",\n",
      "            \"evaluation/comparison\": \"Izhikevich, Theta and LIF models are used\",\n",
      "            \"evaluation/confidence\": \"I did not see it in the text\",\n",
      "            \"evaluation/measure\": \"Accuracy is mentioned in the text.\",\n",
      "            \"evaluation/method\": \"For the songs, it looks like they compared the waves but I did not see a clear mention on how the method was evaluated\",\n",
      "            \"dataset/availability\": \"Availability of data is not reported There is availability of the code (mentioned as data availability). If the data is part of the code repo, I did not see it. Only *.m files for MatLab\",\n",
      "            \"dataset/provenance\": \"Multiple ML pipelines are discussed. Data source is mentioned only for 1 of them (zebra finch singing) via an article reference (so it seems to have been used by a previous paper). I did not find any mention of data points.\",\n",
      "            \"dataset/redundancy\": \"I did not find it in the text\",\n",
      "            \"dataset/splits\": \"I did not find any of this in the text\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305ba6\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33828982\",\n",
      "            \"updated\": \"03/02/2022 13:51:09\",\n",
      "            \"authors\": \"Cui Y, Li Y, Xing D, Bai T, Dong J, Zhu J\",\n",
      "            \"journal\": \"Front Oncol\",\n",
      "            \"title\": \"Improving the Prediction of Benign or Malignant Breast Masses Using a Combination of Image Biomarkers and Clinical Parameters.\",\n",
      "            \"doi\": \"10.3389/fonc.2021.629321\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"cf9dcd08-f887-4f92-837d-6a795fe980ec\",\n",
      "        \"shortid\": \"wa4n4o4gna\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/02/2022 13:51:09\",\n",
      "            \"publication/authors\": \"Cui Y, Li Y, Xing D, Bai T, Dong J, Zhu J\",\n",
      "            \"publication/journal\": \"Front Oncol\",\n",
      "            \"publication/title\": \"Improving the Prediction of Benign or Malignant Breast Masses Using a Combination of Image Biomarkers and Clinical Parameters.\",\n",
      "            \"optimization/algorithm\": \"\\u201cA priori\\u201d algorithm\",\n",
      "            \"optimization/encoding\": \"Yes: Presence/absence of genes\",\n",
      "            \"optimization/features\": \"Yes (13 features)\",\n",
      "            \"optimization/fitting\": \"No exclusion\",\n",
      "            \"optimization/parameters\": \"2 parameters (minimum support threshold and confidence levels)\",\n",
      "            \"model/availability\": \"Yes (URL http://www.cs.waikato.ac.nz/~ml/weka/index.html)\",\n",
      "            \"model/interpretability\": \"Transparent: 24 most frequent rules generated by the apriori algorithm are detailed\",\n",
      "            \"model/output\": \"Binary prediction (statistical classifier)\",\n",
      "            \"evaluation/availability\": \"Yes: confusion matrix in publication\",\n",
      "            \"evaluation/comparison\": \"Univariate statistical analysis (Fishers\\u2019 exact test) and decision tree classifier (J48 ID3)\",\n",
      "            \"evaluation/confidence\": \"Chi-squared test p-value comparison\",\n",
      "            \"evaluation/measure\": \"chi-squared test\",\n",
      "            \"evaluation/method\": \"Evaluation on the training dataset\",\n",
      "            \"dataset/provenance\": \"Yes (Mexican Reference Genomic Dnot reported Collection (MGDC-REF) ). Source of data and number of positives and negatives given, negative dataset was used by a previous paper.\",\n",
      "            \"dataset/redundancy\": \"No, only training set\",\n",
      "            \"dataset/splits\": \"Yes: number of N_pos and N_neg\\nNo data splits. Only training set\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305ba7\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"34112769\",\n",
      "            \"updated\": \"03/29/2022 23:01:05\",\n",
      "            \"authors\": \"Soret P, Le Dantec C, Desvaux E, Foulquier N, Chassagnol B, Hubert S, Jamin C, Barturen G, Desachy G, Devauchelle-Pensec V, Boudjeniba C, Cornec D, Saraux A, Jousse-Joulin S, Barbarroja N, Rodr\\u00edguez-Pint\\u00f3 I, De Langhe E, Beretta L, Chizzolini C, Kov\\u00e1cs L, Witte T, PRECISESADS Clinical Consortium., PRECISESADS Flow Cytometry Consortium., Bettacchioli E, Buttgereit A, Makowska Z, Lesche R, Borghi MO, Martin J, Courtade-Gaiani S, Xuereb L, Guedj M, Moingeon P, Alarc\\u00f3n-Riquelme ME, Laigle L, Pers JO\",\n",
      "            \"journal\": \"Nat Commun\",\n",
      "            \"title\": \"A new molecular classification to drive precision treatment strategies in primary Sj\\u00f6gren's syndrome.\",\n",
      "            \"doi\": \"10.1038/s41467-021-23472-7\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"001278bf-79ae-42c1-b064-88bbc3e18183\",\n",
      "        \"shortid\": \"e1fgv8jwbe\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/29/2022 23:01:05\",\n",
      "            \"publication/authors\": \"Soret P, Le Dantec C, Desvaux E, Foulquier N, Chassagnol B, Hubert S, Jamin C, Barturen G, Desachy G, Devauchelle-Pensec V, Boudjeniba C, Cornec D, Saraux A, Jousse-Joulin S, Barbarroja N, Rodr\\u00edguez-Pint\\u00f3 I, De Langhe E, Beretta L, Chizzolini C, Kov\\u00e1cs L, Witte T, PRECISESADS Clinical Consortium., PRECISESADS Flow Cytometry Consortium., Bettacchioli E, Buttgereit A, Makowska Z, Lesche R, Borghi MO, Martin J, Courtade-Gaiani S, Xuereb L, Guedj M, Moingeon P, Alarc\\u00f3n-Riquelme ME, Laigle L, Pers JO\",\n",
      "            \"publication/journal\": \"Nat Commun\",\n",
      "            \"publication/title\": \"A new molecular classification to drive precision treatment strategies in primary Sj\\u00f6gren's syndrome.\",\n",
      "            \"optimization/algorithm\": \"support vector machine (SVM)\",\n",
      "            \"optimization/encoding\": \"Each 30- to 120-s paired recording was converted into a single bipolar LFP. The multitaper method was used to calculate a spectrogram of the LFP. using a 2-s window with 10% window steps, resulting in a 1-Hz frequency resolution. Time windows containing movement artifacts were visually identified and removed. The spectrogram was averaged over the remaining windows to produce a single power spectral density (PSD) for each paired\\nrecording. An additional feature set was created with phase-amplitude coupling (PAC).\",\n",
      "            \"optimization/features\": \"The entire feature set including both spectral and PAC components contained 206 features.  Feature selection was performed. The lasso regularization technique with 10-fold cross-vali-\\ndation was used to perform feature selection through least-squares regression with a penalty on the size of the estimated coefficients. This procedure finds the combination of features that produces the minimum mean-square error (MSE). Lasso regularization was performed separately for the spectral and PAC feature sets.\",\n",
      "            \"optimization/fitting\": \"Large number of features. Feature selection was performed to reduce the number of features used for the classificationto avoid overfitting.\",\n",
      "            \"optimization/regularization\": \"yes: The lasso regularization technique with 10-fold cross-validation was used to perform feature selection through least-squares regression with a penalty on the size of the estimated coefficients\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/measure\": \"Sensitivity/specificity measures for each subject/class.\",\n",
      "            \"evaluation/method\": \"10-fold cross-validation\",\n",
      "            \"dataset/provenance\": \"669 paired recordings were made across 3 subjects. Data are divided in 4 classes of (276, 149, 157, 87 points each). Data source: experiment.\",\n",
      "            \"dataset/splits\": \"90% of the data was used for training and the remaining 10% was used for testing.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305baf\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"34372798\",\n",
      "            \"updated\": \"02/02/2022 10:53:38\",\n",
      "            \"authors\": \"Li MX, Sun XM, Cheng WG, Ruan HJ, Liu K, Chen P, Xu HJ, Gao SG, Feng XS, Qi YJ\",\n",
      "            \"journal\": \"BMC Cancer\",\n",
      "            \"title\": \"Using a machine learning approach to identify key prognostic molecules for esophageal squamous cell carcinoma.\",\n",
      "            \"doi\": \"10.1186/s12885-021-08647-1\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"7207b60b-e1a1-41bd-bc26-c3720ecbca51\",\n",
      "        \"shortid\": \"fv16isykca\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"02/02/2022 10:53:38\",\n",
      "            \"publication/authors\": \"Li MX, Sun XM, Cheng WG, Ruan HJ, Liu K, Chen P, Xu HJ, Gao SG, Feng XS, Qi YJ\",\n",
      "            \"publication/journal\": \"BMC Cancer\",\n",
      "            \"publication/title\": \"Using a machine learning approach to identify key prognostic molecules for esophageal squamous cell carcinoma.\",\n",
      "            \"optimization/algorithm\": \"Probabilistic machine learning algorithms like Na\\u00efve Bayes and Maximum Entropy.\",\n",
      "            \"optimization/encoding\": \"Strings of text are tokenized and pre-filtered to select candidates.\",\n",
      "            \"optimization/features\": \"4-5 features are indicated.\",\n",
      "            \"optimization/parameters\": \"The parameters are estimated via hill climbing approaches (Improved Iterative Scaling (IIS), Generalized Iterative Scaling (GIS)) and Limited-Memory Variable Metric optimization (L-BFGS). The number of parameters is not reported\",\n",
      "            \"model/availability\": \"The software system implementing NetiNeti can be accessed at http://namefinding.ubio.org.\",\n",
      "            \"model/interpretability\": \"black box\",\n",
      "            \"evaluation/comparison\": \"TaxonFinder and FAT tool.\",\n",
      "            \"evaluation/confidence\": \"The recall for TaxonFinder is significantly lower compared to NetiNeti, while the precisions are comparable. . The FAT approach has lower precision and recall values compared to NetiNeti and TaxonFinder.\",\n",
      "            \"evaluation/measure\": \"Precision and recall values.\",\n",
      "            \"evaluation/method\": \"PubMed Central ids used for evaluation of NetiNeti.\",\n",
      "            \"dataset/availability\": \"The American Seashell book and a list of PubMed Central ids used for evaluation of NetiNeti can be found at http://ubio.org/netinetifiles\",\n",
      "            \"dataset/provenance\": \"Data source are databases.\",\n",
      "            \"dataset/splits\": \"A total of about 40,000 positive examples together with another set of about 43,000\\nnegative examples were used to generate a training set of 83,000 examples for the two class labels.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bb0\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33995917\",\n",
      "            \"updated\": \"03/16/2022 12:48:49\",\n",
      "            \"authors\": \"Dully V, Wilding TA, M\\u00fchlhaus T, Stoeck T\",\n",
      "            \"journal\": \"Comput Struct Biotechnol J\",\n",
      "            \"title\": \"Identifying the minimum amplicon sequence depth to adequately predict classes in eDNA-based marine biomonitoring using supervised machine learning.\",\n",
      "            \"doi\": \"10.1016/j.csbj.2021.04.005\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"87a282cd-4534-4ee9-a07e-455260a89a6a\",\n",
      "        \"shortid\": \"kottgt7uak\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/16/2022 12:48:49\",\n",
      "            \"publication/authors\": \"Dully V, Wilding TA, M\\u00fchlhaus T, Stoeck T\",\n",
      "            \"publication/journal\": \"Comput Struct Biotechnol J\",\n",
      "            \"publication/title\": \"Identifying the minimum amplicon sequence depth to adequately predict classes in eDNA-based marine biomonitoring using supervised machine learning.\",\n",
      "            \"optimization/config\": \"http: //59.73.198.144/AFP_PSSM/\",\n",
      "            \"optimization/encoding\": \"Evolutionary Information, Amino Acid and Dipeptide Composition, Chou\\u2019s Pseudo Amino acid Composition\",\n",
      "            \"optimization/features\": \"400, PSSM-400 (composition of occurrences of each type of amino acid corresponding to each type of amino acids in protein sequence)\",\n",
      "            \"optimization/meta\": \"4 SVM models based on amino acids composition, dipeptides composition,\\nChou\\u2019s PseAAC and PSSM-400\",\n",
      "            \"optimization/parameters\": \"p=2, regularization parameter C and the kernel width parameter \\u03b3.\",\n",
      "            \"model/duration\": \"20 seconds for 500 amino acids sequences\",\n",
      "            \"evaluation/comparison\": \"comparison with work from 10.1016/j.jtbi.2010.10.037. this study obtains accuracy\",\n",
      "            \"evaluation/confidence\": \"Model's accuracy\",\n",
      "            \"evaluation/measure\": \"sensitivity (S_n), specificity (S_p), and accuracy (Acc), ROC\",\n",
      "            \"evaluation/method\": \"Ten-fold cross validation & independent testing dataset\",\n",
      "            \"dataset/provenance\": \"source: 10.1016/j.jtbi.2010.10.037\\n481 antifreeze proteins and 9493 non-antifreeze proteins\",\n",
      "            \"dataset/redundancy\": \"To get rid of redundancy and homology bias,\\nthe sequences with \\u226540% sequence similarity have been removed using program CD-HIT\",\n",
      "            \"dataset/splits\": \"training dataset contains 300 antifreeze proteins randomly selected from the 481 antifreeze proteins and 300 non-antifreeze proteins randomly selected from the 9493 non-antifreeze proteins. The test dataset contains the remaining 181 antifreeze proteins and 9193 non-antifreeze proteins.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bb1\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"34093642\",\n",
      "            \"updated\": \"03/07/2022 11:16:44\",\n",
      "            \"authors\": \"Sardar R, Sharma A, Gupta D\",\n",
      "            \"journal\": \"Front Genet\",\n",
      "            \"title\": \"Machine Learning Assisted Prediction of Prognostic Biomarkers Associated With COVID-19, Using Clinical and Proteomics Data.\",\n",
      "            \"doi\": \"10.3389/fgene.2021.636441\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"dcfa96ac-4881-4efa-baf5-2907ca1a48a8\",\n",
      "        \"shortid\": \"3rafrbsxow\",\n",
      "        \"score\": 0.95,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/07/2022 11:16:44\",\n",
      "            \"publication/authors\": \"Sardar R, Sharma A, Gupta D\",\n",
      "            \"publication/journal\": \"Front Genet\",\n",
      "            \"publication/title\": \"Machine Learning Assisted Prediction of Prognostic Biomarkers Associated With COVID-19, Using Clinical and Proteomics Data.\",\n",
      "            \"optimization/algorithm\": \"Support Vector Machine (SVM) classification with RBF kernel\",\n",
      "            \"optimization/config\": \"Method and data are available to the public upon request.\",\n",
      "            \"optimization/encoding\": \"Calculated amino acid composition in terms of different secondary structures strand (E), helix (H) and coil (C), and solvent accessibility states (buried (B) and exposed (E)), with a method called SSE-ACC. The value of each dimension is calculated by\\n\\nf_i^j=  (N_i^j)/L\\n\\nwhere j = {H, E, C}, N_i^j is the frequency of amino acid i in secondary structure element j, and L is the length of the sequence. The value is calculated similarly for solvent accessibility states.\\n\",\n",
      "            \"optimization/features\": \"100 features. The first 60 features are used to describe the frequency of each amino acid in each of the three possible secondary structure elements. The last 40 dimensions represent the frequency of each amino acid having each of the two possible solvent accessibility states.\",\n",
      "            \"optimization/fitting\": \"Single input for SVM method. Optimization through grid search.\",\n",
      "            \"optimization/parameters\": \"The parameters used for the redundant data set are g = 0.25, C = 4. The parameters used for the non-redundant data set are g =0.5, C = 4. Grid search was used for parameter optimization.\",\n",
      "            \"optimization/regularization\": \"Yes, by setting the regularization parameter C=4. L2 regularization adds an L2 penalty equal to the square of the magnitude of coefficients.\",\n",
      "            \"model/availability\": \"Method and data are available to the public upon request.\",\n",
      "            \"model/duration\": \"The whole computation process took several ten hours. All computation tasks were conducted on a Pentium IV desktop PC with dual CPU (2.8 GHz) and 2 GB RAM.\",\n",
      "            \"model/interpretability\": \"Black box. Not investigating feature importance.\",\n",
      "            \"model/output\": \"Classification, i.e. binary predictions based on the probability of a predicted positive case being p > 0.01.\",\n",
      "            \"evaluation/availability\": \"Method and data are available to the public upon request.\",\n",
      "            \"evaluation/comparison\": \"EffectiveT3, T3SS prediction. Known classifiers for T3SS effector prediction. SVC with cross-validation but with different data encoding.\",\n",
      "            \"evaluation/confidence\": \"Only the non-redundant data were used for the comparisons. Very low precision from EffectiveT3 (recall of 72.2% and precision of 17.9%) and T3SS prediction (recall of 83.3% and precision of 24%) due to being developed in less imbalanced and non-realistic training sets. For different data encoding methods, the recall and precision of effectors were 55.6% and 84.5%, respectively, which were over 5% lower than those of the proposed SSE-ACC method.\",\n",
      "            \"evaluation/measure\": \"Accuracy, Recall, Precision.\",\n",
      "            \"evaluation/method\": \"5-fold cross-validation. Independent dataset. A single predicted positive case of the independent dataset was validated through wet-lab experiments.\",\n",
      "            \"dataset/availability\": \"Method and data are available to the public upon request.\",\n",
      "            \"dataset/provenance\": \"Redundant dataset of type III effectors. Positive cases were identified type III effector (T3SE) proteins from Pseudomonas syringae (P. syringae) pv. tomato strain DC3000, P. syringae pv. syringae strain B728a and P. syringae pv. phaseolicola strain 1448A. Negative cases were all the proteins extracted from the genome of P. syringae pv. tomato strain DC3000, excluding proteins related to type III secretion system (T3SS) and hypothetical proteins. 4,062 proteins total. Npos = 283 protein sequences. Nneg = 3,779 protein sequences. \\nNon-redundant dataset of type III effectors. Removal of all homologous proteins (redundant), with sequence similarity greater than 60% from redundant dataset of type III effectors. 3,532 proteins total. Npos = 108 protein sequences. Nneg = 3,424 protein sequences.\\nOnly the first 100 N-terminal residues were used in both datasets. They were not previously used.\",\n",
      "            \"dataset/redundancy\": \"Homology present within positive cases. Possibility of overestimating negative cases due to the presence of uncharacterized T3SE proteins within them.\",\n",
      "            \"dataset/splits\": \"5-fold cross validation was performed. No information about the sizes of training and testing data sets.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bb8\",\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"34258160\",\n",
      "            \"updated\": \"03/19/2022 17:28:38\",\n",
      "            \"authors\": \"Liu QX, Zhou D, Han TC, Lu X, Hou B, Li MY, Yang GX, Li QY, Pei ZH, Hong YY, Zhang YX, Chen WZ, Zheng H, He J, Dai JG\",\n",
      "            \"journal\": \"Adv Sci (Weinh)\",\n",
      "            \"title\": \"A Noninvasive Multianalytical Approach for Lung Cancer Diagnosis of Patients with Pulmonary Nodules.\",\n",
      "            \"doi\": \"10.1002/advs.202100104\",\n",
      "            \"year\": \"2021\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"5ad4302c-53ed-4207-b229-6528206e2f0b\",\n",
      "        \"shortid\": \"4ord5sdl9n\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"publication/updated\": \"03/19/2022 17:28:38\",\n",
      "            \"publication/authors\": \"Liu QX, Zhou D, Han TC, Lu X, Hou B, Li MY, Yang GX, Li QY, Pei ZH, Hong YY, Zhang YX, Chen WZ, Zheng H, He J, Dai JG\",\n",
      "            \"publication/journal\": \"Adv Sci (Weinh)\",\n",
      "            \"publication/title\": \"A Noninvasive Multianalytical Approach for Lung Cancer Diagnosis of Patients with Pulmonary Nodules.\",\n",
      "            \"optimization/algorithm\": \"KStar (K-NN ?), Not novel, Multilayer perceptron, C4.5\",\n",
      "            \"optimization/encoding\": \"Gene expression data\",\n",
      "            \"optimization/features\": \"No feature selection.\",\n",
      "            \"optimization/parameters\": \"Depends on algorithms tested.\",\n",
      "            \"model/interpretability\": \"Black box\",\n",
      "            \"evaluation/comparison\": \"KStar, comparison vs. MLP, C4.5\",\n",
      "            \"evaluation/measure\": \"Rappel/Precision, AUR\",\n",
      "            \"evaluation/method\": \"Cross validation\",\n",
      "            \"dataset/availability\": \"Yes but need to contact the authors apparently\",\n",
      "            \"dataset/provenance\": \"Yes,  Prof. Connie Cepko at Harvard Medical School, claimed publicly available\",\n",
      "            \"dataset/redundancy\": \"Yes, cross-validation\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6634f332ded6e7820f74a19e\",\n",
      "        \"shortid\": \"lf0lzc5ed0\",\n",
      "        \"uuid\": \"68023bc8-b676-4d1f-a508-977183349803\",\n",
      "        \"created\": \"2024-05-03T14:22:42.850Z\",\n",
      "        \"updated\": \"2024-05-03T14:22:42.850Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"34290238\",\n",
      "            \"authors\": \"Gang Hu, Akila Katuwawala, Kui Wang, Zhonghua Wu, Sina Ghadermarzi, Jianzhao Gao & Lukasz Kurgan\",\n",
      "            \"journal\": \"Nature Communications\",\n",
      "            \"title\": \"flDPnn: Accurate intrinsic disorder prediction with putative propensities of disorder functions\",\n",
      "            \"doi\": \"10.1038/s41467-021-24773-7\",\n",
      "            \"year\": \"2021\"\n",
      "        },\n",
      "        \"score\": 0.9,\n",
      "        \"matches\": {\n",
      "            \"evaluation/comparison\": \"The model was compared to other disorder prediction methods, such as IUPred, Espritz, and Spot-Disorder.\",\n",
      "            \"evaluation/confidence\": \"Confidence intervals were not reported. The results indicate superior performance compared to other similar methods and software.\",\n",
      "            \"evaluation/measure\": \"F1-score, MCC, and ROC-AUC are reported as performance metrics.\",\n",
      "            \"evaluation/method\": \"The evaluation is based on the performance of the model on the test dataset.\",\n",
      "            \"optimization/algorithm\": \"Deep feedforward neural network. \\nIt is not a novel algorithm.\",\n",
      "            \"optimization/config\": \"Authors released the code for flDPnn at https://gitlab.com/sina.ghadermarzi/fldpnn.\",\n",
      "            \"optimization/encoding\": \"A protein sequence is analyzed by other previously mentioned algorithms to create sequence profiles, the sequences profiles are encoded and passed to the main ML models created by the authors.\",\n",
      "            \"optimization/features\": \"The profiles are encoded into three feature sets.\",\n",
      "            \"optimization/meta\": \"Multiple predictors are used to generate sequence profiles that are later fed into the ML model.\\nIUPred, PSIPRED, DisoRDPbind, DFLpred, fMoRFpred.\",\n",
      "            \"optimization/parameters\": \"The exact number of parameters not reported.\\nAuthors empirically selected the hyper-parameters including number of layers and the number of nodes in the hidden layer by a grid search.\",\n",
      "            \"optimization/regularization\": \"Authors clustered the data points using CD-HIT (sequence similarity clustering technique) to prevent overfitting.\",\n",
      "            \"model/availability\": \"Authors released the code for flDPnn at https://gitlab.com/sina.ghadermarzi/fldpnn.\",\n",
      "            \"model/duration\": \"5 to 10 s per protein.\",\n",
      "            \"model/interpretability\": \"No mention was made on interpretability. The models seems to be a black box.\",\n",
      "            \"model/output\": \"It is a classifier.\",\n",
      "            \"dataset/availability\": \"Not splits, but the source data was collected by parsing the publicly available DisProt repository (https://www.disprot.org/).\",\n",
      "            \"dataset/provenance\": \"745 experimentally annotated proteins from the DisProt 7.0 database.\\nDisProt has been used frequently by other communities and publications in the field of disorder prediction.\",\n",
      "            \"dataset/redundancy\": \"Data split was done randomly.\\nTest dataset was reduced to 176 proteins that share <25% sequence similarity to the training proteins.\",\n",
      "            \"dataset/splits\": \"Training dataset: 445 proteins\\nValidation dataset: 100 proteins\\nTest dataset: 200 proteins\",\n",
      "            \"publication/authors\": \"Gang Hu, Akila Katuwawala, Kui Wang, Zhonghua Wu, Sina Ghadermarzi, Jianzhao Gao & Lukasz Kurgan\",\n",
      "            \"publication/journal\": \"Nature Communications\",\n",
      "            \"publication/title\": \"flDPnn: Accurate intrinsic disorder prediction with putative propensities of disorder functions\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"664b2a16b30933003cc21843\",\n",
      "        \"shortid\": \"y38upwlhxf\",\n",
      "        \"uuid\": \"9ef704d3-b4f4-461f-aa23-03871338dc04\",\n",
      "        \"created\": \"2024-05-20T10:46:46.631Z\",\n",
      "        \"updated\": \"2024-05-20T10:46:46.631Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"34706730\",\n",
      "            \"authors\": \"Jiao S, Zou Q, Guo H, Shi L. \",\n",
      "            \"journal\": \"Journal of Translational Medicine\",\n",
      "            \"title\": \"iTTCA-RF: a random forest predictor for tumor T cell antigens\",\n",
      "            \"doi\": \"10.1186/s12967-021-03084-x\",\n",
      "            \"year\": \"2021\"\n",
      "        },\n",
      "        \"score\": 0.95,\n",
      "        \"matches\": {\n",
      "            \"evaluation/availability\": \"Not available\",\n",
      "            \"evaluation/comparison\": \"The Authors compared iTTCA-RF with iTTCA-Hybrid (published by Charoenkwan P, et al (2020) Anal Biochem. 599:113747, PMID: 32333902) on the same training andd testing datasets.\\nThe BACC, AUC, Sn, Sp and MCC metrics of the Authors' model on the training set were between 3.6% and 9.0% higher than those of iTTCA-Hybrid, respectively. The same metrics on the independent test were between 0.8% and 4.6% higher.  \",\n",
      "            \"evaluation/confidence\": \"No confidence intervals are reported for any performance measure. Therefore, the statistic significance of the Author's claim can not be calculated.\",\n",
      "            \"evaluation/measure\": \"Balanced Accuracy, AUC, Specifity, Sensitivity, Matthews Correlation Coefficient. \",\n",
      "            \"evaluation/method\": \"Independent dataset (n=197 data points, of which 122 positive, 75 negative). \",\n",
      "            \"optimization/algorithm\": \"The best performing machine learning algorithm was searched among the following 6 standard classifers: random forest (RF), support vector machine (SVM), adaboost (AB), logistic regression (LR), bagging, and gradient boosting machine (GBM), all of them in the implementation of the scikit-learn package.  The best performer turned out to be Random Forest (RF).\",\n",
      "            \"optimization/config\": \"The training and testing datasets are freely accessible at http://lab.malab.cn/~acy/iTTCA.\",\n",
      "            \"optimization/encoding\": \"The protein sequences (T-cell epitopes) were preliminarily encoded using 4 kinds of feature extraction methods: global protein sequence descriptors (GPSD), grouped amino acid and peptide composition (GAAPC), pseudo amino acid composition (PAAC), and adaptive skip dipeptide composition (ASDC).   The iLearn tool package was used to generate the 4 type of sequence features.\",\n",
      "            \"optimization/features\": \"The following two-step feature selection technique to search for the optimal feature subset was applied:  First, the maximum relevance maximum distance (MRMD) algorithm was used to analyze the feature importance of the involved vectors. Then, after application of the incremental feature selection (IFS) strategy, different feature subsets were generated for optimization for each considered classifcation algorithms.      The best performance model was finally constructed using the top 263 selected features.\",\n",
      "            \"optimization/fitting\": \"The number of features was 263, at risk of overfitting. The somewhat lower performance metrics on the test set, relative to the training set, could indicate some overfitting in the model optimization procedure.   The Author's did not claim to have ruled out overfitting, but they have taken some preventive measures, namely the SMOTE-Tomek for balancing the numerosity of the training positive and negative sets and an accurate feature selection strategies.\",\n",
      "            \"optimization/parameters\": \"The number of paramenters was the standard one for each of the 6 classifiers. The hyper-parameters were optimized using grid search, with the search ranges presented in the Supplements. \",\n",
      "            \"optimization/regularization\": \"As mentioned, the Authors have taken some preventive measures: the SMOTE-Tomek for balancing the numerosity of the training positive and negative sets and an accurate feature selection strategies.\",\n",
      "            \"model/availability\": \"The online prediction server was made freely accessible at http://lab.malab.cn/~acy/iTTCA.   All test classifiers were applied as in the Scikit-learn implementation.\",\n",
      "            \"model/duration\": \"Not reported.\",\n",
      "            \"model/interpretability\": \"The MRMD feature selection method selected a subset of features that were strongly correlated with the class label and have low redundancy between features.  However, no analysis of a possible interpretability have been reported in the publication.    \",\n",
      "            \"model/output\": \"Binary classification (TTCA or not TTCA) (TTCA = tumor T cell antigens).  \",\n",
      "            \"dataset/availability\": \"\\\"Availability of data and materials\\nPublicly available datasets were analyzed in this study. This data can be found here: http://lab.malab.cn/~acy/iTTCA.\\\"\",\n",
      "            \"dataset/provenance\": \"A non-redundant dataset of 592 tumor T cell antigens (positive samples, ca 60%) and 393 tumor T cell antigens (negative samples, ca. 40%) was used (n=985).  It was an already existing dataset (generated and used in Charoenkwan P, et al (2020) Anal Biochem. 599:113747, PMID: 32333902).  \\nGiven that 80% of the samples were randomly selected as the training dataset, the latter had 788 data points (470 positive, 318 negative),\",\n",
      "            \"dataset/redundancy\": \"The Authors state that the dataset from (Charoenkwan P, et al (2020) Anal Biochem. 599:113747, PMID: 32333902) was not redundant.  However, the latter Authors, in describing the building of the datatset, only state that \\\"Duplicate peptides were removed\\\", and do not mention any analysis of degree of pairwise identity.\",\n",
      "            \"dataset/splits\": \"80% of the 985 samples were randomly selected as the training dataset and the remaining 20% of samples were taken as the independent test dataset.          Tenfold cross-validation of the training set was used during models optimization.      To balance the positive and negative samples in the training set, the Authors used the integrated resampling technique SMOTE-Tomek, a combination of over- and under-sampling methods: synthetic minority over-sampling technique (SMOTE) (Chawla NV, et al. (2002) J Artif Intell Res.16:321\\u201357) and Tomek\\u2019s links (Tomek) (Tomek I. Two modifcations of CNN. (1976) IEEE Trans Syst Man Cybern.SMC6(11):769\\u201372.). Such hybrid-sampling approach, according to the Authors, can simultaneously avoid the shortcomings of overftting and loss of key information caused by SMOTE and Tomek, respectively.\",\n",
      "            \"publication/authors\": \"Jiao S, Zou Q, Guo H, Shi L. \",\n",
      "            \"publication/journal\": \"Journal of Translational Medicine\",\n",
      "            \"publication/title\": \"iTTCA-RF: a random forest predictor for tumor T cell antigens\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"664b2a4db30933003cc21847\",\n",
      "        \"shortid\": \"t7m3dsf9ni\",\n",
      "        \"uuid\": \"85fd4f8b-595f-4be3-8d57-2d351b44e1ce\",\n",
      "        \"created\": \"2024-05-20T10:47:41.132Z\",\n",
      "        \"updated\": \"2024-05-20T10:47:41.132Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33584803\",\n",
      "            \"authors\": \"Yu X, Pan X, Zhang S, Zhang YH, Chen L, Wan S, Huang T, Cai YD.\",\n",
      "            \"journal\": \"Frontiers in Genetics\",\n",
      "            \"title\": \"Identification of Gene Signatures and Expression Patterns During Epithelial-to-Mesenchymal Transition From Single-Cell Expression Atlas\",\n",
      "            \"doi\": \"10.3389/fgene.2020.605012\",\n",
      "            \"year\": \"2021\"\n",
      "        },\n",
      "        \"score\": 0.95,\n",
      "        \"matches\": {\n",
      "            \"evaluation/availability\": \"Not available\",\n",
      "            \"evaluation/comparison\": \"No comparisons.\",\n",
      "            \"evaluation/confidence\": \"No confidence intervals for MCC were reported.\",\n",
      "            \"evaluation/measure\": \"MCC (Matthews Correlation Coefficient).\",\n",
      "            \"evaluation/method\": \"Cross-validation.   There were no independent datasets or novel experiments.\",\n",
      "            \"optimization/algorithm\": \"Standard Random Forest (RF) and Support Vector Machine (SVM) algorithms were used.   In addition, repeated incremental pruning to produce error reduction (RIPPER) was applied to produce classification rules for classifying samples from different TCs.  \",\n",
      "            \"optimization/config\": \"Not reported.\",\n",
      "            \"optimization/encoding\": \"Each TC was encoded with the expression levels of 49,585 genes.\",\n",
      "            \"optimization/features\": \"\\nBoruta feature selection (Kursa and Rudnicki (2010) J. Statist. Softw. Artic. 36, 1\\u201313) and minimum redundancy maximum relevance (mRMR) method (Peng et al (2005) IEEE Transact. Patt. Anal. Mach. Intel. 27, 1226\\u20131238) were used, to evaluate the importance of each feature. Key features were then selected, and fed into the incremental feature selection (IFS) with supervised classifiers to identify the optimal gene signatures for screening different TCs.   The IFS was run with SVM, RIPPER, and RF, respectively.   The optimal numbers of features turned out to be 169 (SVM), 159 (RF), 38 (RIPPER).\\n\",\n",
      "            \"optimization/fitting\": \"After SMOTE application, the number of datapoints was 624.    The Authors first used Boruta to select relevant features, resulting in 237 features (genes). After mRMR and IFS, the subsets of features with the optimal classification performance were obtained.  The numbers of features were 169 (SVM), 159 (RF), 38 (RIPPER).     Given the very high Accuracy (>= 0.979) and MCC (>= 0.934) values, obtained with all three classifiers, the methods seem to be at risk of overfitting.   While the high number of features could be a reason for the probable overfitting in SVM and RF, the RIPPER model might eventually have had different sources of overfitting.      \",\n",
      "            \"optimization/parameters\": \"The authors do not mention parameters numbers different from standard.  \",\n",
      "            \"optimization/regularization\": \"Not reported.\",\n",
      "            \"model/availability\": \"The algorithms and software packages used in this publication were all standard or already published.\",\n",
      "            \"model/duration\": \"No reported.\",\n",
      "            \"model/interpretability\": \"According to the Authors, \\\"SVM and RF are \\u201cblackbox\\u201d methods. [...] RIPPER can generate interpretable classification rules.\\\"    Ante-hoc techniques for transparency in SVM and RF were not applied, since feature selection was performed in a completely automatic manner.  Post-hoc analysis was partially interpretable, since several of the selected features were genes already known to be involved in the Epithelial-to-Mesenchymal Transition.  In addition, GO term and KEGG pathway enrichment results were consistent with the known differences between epithelial and mesenchymal cells.\",\n",
      "            \"model/output\": \"Binary classification (the optimal set of genes (features) should be able to clearly separate Epithelial from Mesenchymal cell status).  \",\n",
      "            \"dataset/availability\": \"\\\"Data Availability Statement -- Publicly available datasets were analyzed in this study. This data can be found here: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE110357.\\\"\",\n",
      "            \"dataset/provenance\": \"The datasets were obtained from the study of Pastushenko et al (2018) at https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE110357. The number of data points (mouse Tumor Cells (TCs), each one with single-cell gene expression profiles) was 383.  The datapoints of the 1\\u00b0 dataset were 71 epithelial YFP + Epcam + skin squamous cell carcinoma TCs and the datapoints of the 2\\u00b0 dataset were 312 mesenchymal-like YFP + Epcam \\u2212 skin squamous cell carcinoma TCs.   Epithelial YFP + Epcam + TCs and mesenchymal-like YFP + Epcam \\u2212 TCs represent different EMT (Epithelial-to-Mesenchymal Transition states.   Gene expression differences may reveal the cascade mechanisms of tumor migration and invasion.\",\n",
      "            \"dataset/redundancy\": \"Not applicable.\",\n",
      "            \"dataset/splits\": \"10 fold cross validation.   To balance the two datasets, so that the numbers of epithelial tumor and mesenchymal TCs were equal, the tool \\u201cSMOTE\\u201d (Synthetic Minority Over-samplingTEchnique) in Weka was used, to generate new samples in the class of epithelial TC.   \",\n",
      "            \"publication/authors\": \"Yu X, Pan X, Zhang S, Zhang YH, Chen L, Wan S, Huang T, Cai YD.\",\n",
      "            \"publication/journal\": \"Frontiers in Genetics\",\n",
      "            \"publication/title\": \"Identification of Gene Signatures and Expression Patterns During Epithelial-to-Mesenchymal Transition From Single-Cell Expression Atlas\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6677746e37ea6fa797a6c4a5\",\n",
      "        \"shortid\": \"0kf7cnsa5t\",\n",
      "        \"uuid\": \"341f3bec-3507-4c4b-8d19-c88ba8867202\",\n",
      "        \"created\": \"2024-06-23T01:03:42.235Z\",\n",
      "        \"updated\": \"2024-06-23T01:03:42.235Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"34662334\",\n",
      "            \"authors\": \"Nicolas Arning, Samuel K. Sheppard, Sion Bayliss, David A. Clifton, and Daniel J. Wilson\",\n",
      "            \"journal\": \"PLOS Genetics\",\n",
      "            \"title\": \"Machine learning to predict the source of campylobacteriosis using whole genome data\",\n",
      "            \"doi\": \"10.1371/journal.pgen.1009436\",\n",
      "            \"year\": \"2021\"\n",
      "        },\n",
      "        \"score\": 0.95,\n",
      "        \"matches\": {\n",
      "            \"evaluation/availability\": \"No - not available from the text or from the GitHub.\",\n",
      "            \"evaluation/comparison\": \"The performance of the machine learning models generated in the study for were compared to the most commonly used source attribution method. This method is called 'iSource' and relies on multi-locus sequence typing (MLST) data. \\nThe comparison against this method helps establish a comparison baseline for assessing the improvement offered by the new machine learning models developed.\\n\\nThe study does perform comparisons between the 14x different machine learning models generated using various data types (MLST, cgMLST, WGS). This helps identify which models perform best with different levels of genomic information. Some of these models could be considered as simpler baselines (k-nearest neighbour) to the more complex deep learning models employed (Recurrent Neural Network.).\",\n",
      "            \"evaluation/confidence\": \"Confidence intervals and statistical significance testing - not very prominent or clear in the main text. For the accuracy, the authors does report ' 81.3\\u00b12%/84.6\\u00b10% accuracy' confidence intervals for the cgMLST data used with the XGBoost classifier model. Other model accuracy confidence intervals are noted in Fig 1.\",\n",
      "            \"evaluation/measure\": \"Several performance metrics were used to evaluate the machine learning models in the study:\\n\\n-Precision (positive predictive value) \\n-Recall (sensitivity)\\n-F1\\n-Negative predictive value\\n-Specificity \\n-Speed\\n-Misclassification Matrix\\n\\nHowever some key performance evaluation metrics were not noted such as area under the ROC Curve (AUC). Additionally, while in the text it states these perfomance measures were taken, it appears only a subset of these are actually clearly detailed and not for all models.\\n\\nMost of the performance measure metrics are detailed in Fig 2. and Fig 3.\",\n",
      "            \"evaluation/method\": \"Evaluation methods used include:\\n-Five-fold cross-validation\\n-Comparison to existing methods\\n-Performance of the models evaluated on different data types (core genome data vs whole genome sequence data)\",\n",
      "            \"optimization/algorithm\": \"14x total ML algorithms were used in the study, these are classified as:\\n-Simple learners (6x)\\n-Ensemble learners (3x)\\n-Deep learners (5x)\\n\\nFull breakdown below:\\n\\nSimple learners\\n1. K-nearest neighbour\\n2. Ridge Regression\\n3. SVM (Linear Kernel)\\n4. SVM (RBF Kernel)\\n5. Naive Bayesian\\n6. Decision tree\\n\\nEnsemble learners\\n7. Random forest\\n8. Extra-randomised forest\\n9. XGBoost\\n\\nDeep learners\\n10. 1D-Convolutional NN\\n11. Shallow Dense NN\\n12. Deep Dense NN\\n13. Recurrent NN\\n14. LSTM NN\\n\\nThese are fully detailed in Fig 1. \",\n",
      "            \"optimization/config\": \"Not clear, standard deposition of one of the models (XGboost) in GitHub relating to the paper but not clear if with corresponding hyperparameter configurations, optimization schedule, model files and optimization parameters. These are not well described in the text beyond some hyperparameters.\",\n",
      "            \"optimization/encoding\": \"Several encoding methods were used and varied depending on the data source (MLST vs. WGS). Missing values were handled differently for each data type. Nucleotides of the data were one-hot encoded and k-mers were used to capture sequence information.\",\n",
      "            \"optimization/features\": \"Number of features (f) used as input is 100,000 (ostensibly for all 14x models).\\n\\nFeature selection was perfomed:\\n-Variance Threshold: reduced number of k-mers by discarding those present/absent in over 99% of samples.\\n-Chi-Square Test: evaluated dependence of source labels on individual k-mers using the training data, and from this the top 100,000 k-mers with the highest scores were chosen.\",\n",
      "            \"optimization/fitting\": \"p is unknown in relation to f for fit evaluation. The study used early stopping and 5-fold cross-validation approaches to avoid overfitting.  \",\n",
      "            \"optimization/parameters\": \"Number of parameters not clearly detailed in text for the 14x models generated.\",\n",
      "            \"optimization/regularization\": \"Early stopping: was used during the training. Training was run for 500 generations with early stopping after 50 generations.  No additional validation set clearly noted in text.\",\n",
      "            \"model/availability\": \"Somewhat available - the ML model code repository for the publication is named 'aiSource' and can be found from: https://github.com/narning1992/aiSource. The GitHub contains a downlaodable Python script. No container provided or other run methods clearly noted/linked. Further, it is unclear if all 14x models are available. It seems that only the XGboost model is in the repository.\",\n",
      "            \"model/duration\": \"Unclear for which model, but like the XGboost one, some information provided on execution time:\\n\\n-Possible to run on well provisioned desktop, no GPU explicitly needed. \\n-The prediction detailed in the paper took 892 milliseconds on a Dell OptiPlex 7060 desktop using ten threads on an Intel Core i7-8700 CPU and 16 GB RAM.\\n\\nHowever, all 14x models no clear breakdown of training or standard predicition compute needs.\",\n",
      "            \"model/interpretability\": \"Poor interpretablity of the 14x models - largely black boxes. Exact dataset componenets used are available and clearly described in a machine actionable TSV. Data stored in an open database and accessible. However, for the GitHub linked it is not clear if there are all 14x ML model codes available on GitHub and linked from the paper, no docker containers either for easy redployment. The GitHub seems to only hold the code of the XGboost model generated in the stufy and none of the 13x others, this makes the models black boxes. Paraemeters for the models not described and number of models in the text make the paper very complex to hone in on the specific models or their exact info points. Some machine learning interpretability aspects well covered and considered but the information on model optimisations is poor overall. \",\n",
      "            \"dataset/availability\": \"The data used is detailed in supplementary file 'S1 Table.'. Table contains all samples used in this study and their corresponding PubMLST accession IDs, sequence types, clonal complexes, source labels, predicted labels, generalist index, country of isolation, year of sampling, Campylobacter species and whether they have been used in either training or testing the machine learner.\\nhttps://doi.org/10.1371/journal.pgen.1009436.s001\\n\\nTable is also available on Figshare: https://figshare.com/articles/dataset/Table_containing_all_samples_used_in_this_study_and_their_corresponding_PubMLST_accession_IDs_sequence_types_clonal_complexes_source_labels_predicted_labels_generalist_index_country_of_isolation_year_of_sampling_Campylobacter_species_and_wh/16827740\\n\\nThe data itself is hosted in the publicly available open access database: https://pubmlst.org/.\",\n",
      "            \"dataset/provenance\": \"Data source: database - PubMLST, databases for molecular typing\\nand microbial genome diversity.\\n\\nData type: DNA - genomic data.\\n\\nTotal data points: 5,799 isolate genomes from C. jejuni and C. coli genomes. These were from various source experiments and host species. Genome source species distribution:\\n-Chicken: 4147\\n-Cattle: 716\\n-Sheep: 584\\n-Bird: 212\\n-Environment: 140 \\n\\nNot a community recognised data set, this is a novel dataset composed of publicly available data from an open database for the ML models generation in this study.\",\n",
      "            \"dataset/redundancy\": \"Data sets were split at a ratio of:\\n-Training: 75%\\n-Testing: 25%\\n\\nThe test and training sets were kept independent for the model generation based on text description.\",\n",
      "            \"dataset/splits\": \"Of the total dataset 5,799 data points, these were divided into training (75% = 4,349 approx) and testing (25% = 1,450 approx) sets.\\n\\nThe data corresponded to 3x designated classess:\\n-MLST sequencing type \\n-MLST clonal complex \\n-MLST core genome \\n\\nFor the distributions the authors used phylogeny-aware sorting, wherein all members of one sequencing type were sorted entirely into either training or testing sets. This is detailed in S1 Table.\\n\\nNo separate validation set used as the model is evaluated using five-fold cross-validation with the dataset detailed.  \",\n",
      "            \"publication/authors\": \"Nicolas Arning, Samuel K. Sheppard, Sion Bayliss, David A. Clifton, and Daniel J. Wilson\",\n",
      "            \"publication/journal\": \"PLOS Genetics\",\n",
      "            \"publication/title\": \"Machine learning to predict the source of campylobacteriosis using whole genome data\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"667846cb37ea6fa797a6c4b0\",\n",
      "        \"shortid\": \"3ahkdhcjev\",\n",
      "        \"uuid\": \"725073a0-1dc7-4be3-b693-04fd39944947\",\n",
      "        \"created\": \"2024-06-23T16:01:15.774Z\",\n",
      "        \"updated\": \"2024-06-23T16:01:15.774Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"34104645\",\n",
      "            \"authors\": \"Yan Liu, Hui Geng, Bide Duan, Xiuzhi Yang, Airong Ma, and Xiaoyan Ding\",\n",
      "            \"journal\": \"BioMed Research International\",\n",
      "            \"title\": \"Identification of Diagnostic CpG Signatures in Patients with Gestational Diabetes Mellitus via Epigenome-Wide Association Study Integrated with Machine Learning\",\n",
      "            \"doi\": \"10.1155/2021/1984690\",\n",
      "            \"year\": \"2021\"\n",
      "        },\n",
      "        \"score\": 0.95,\n",
      "        \"matches\": {\n",
      "            \"evaluation/availability\": \"No \",\n",
      "            \"evaluation/comparison\": \"No - no clear indication of comparison to other methods using benchmark datasets. Authors did note this was a novel usage of SVM for this classification task meaning there may not have been other methods to compare to.\",\n",
      "            \"evaluation/confidence\": \"No confidence intervals noted in the text related to the SVM model performance.\",\n",
      "            \"evaluation/measure\": \"Limited performance measures reported in the text.\\n\\nArea Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) was used as the primary performance metric for the SVM model in the GDM study.\\n\\nReported Values: AUC values for three datasets:\\n-Training Set (GSE88929): AUC = 0.8138\\n-Testing Set (GSE88929): AUC = 0.7576\\n-Independent Validation Set (GSE102177): AUC = 0.6667\\n\\nAdditional performance measure metrics like accuracy, precision, recall, or F1-score could also be used and are absent from the text/related files.\",\n",
      "            \"evaluation/method\": \"Independent dataset used to validate the model. This was the GSE102177 dataset kept independent for model evaluation and contained 18 samples and 18 controls. \",\n",
      "            \"optimization/algorithm\": \"Support vector machine (SVM) ML algorithm - this is not a new algorithm.\\n\\nWhy chosen: \\n-Previous SVM model usage success for prognosis and diagnosis of disease, such as diabetes mellitus.\\n-Previous successful use and application of SVMs for GDM research.\\n-Novelty of usage for CpG methylation biomarkers.\",\n",
      "            \"optimization/config\": \"No - no configuration available. Little info in text on these model optimisation info points.\",\n",
      "            \"optimization/encoding\": \"No clear information of how the SVM input data was encoded. \\u03b2-values of CpG sites from the data seem to have been used but no further information on how these were encoded.\",\n",
      "            \"optimization/features\": \"Input features, (f) = 6 \\n\\n\\u03b2-values of CpG sites used as features: text notes using the \\u03b2-values of 6 CpG sites for model development. These \\u03b2-values directly represent the features that were used in the model for classification.\\n\\nYes: feature selection was performed to determine these 6x.\",\n",
      "            \"optimization/fitting\": \"Fitting not clearly addressed in the text, very little information on optimising the fit to avoid over-/under- fitting case for the SVM model. Parameter size unkown but most likely somewhat larger than features used. Small number of features used (f=6). Training set size is not very large, only 66. \",\n",
      "            \"optimization/parameters\": \"Parameters used for the SVM ML model are unclear.\\n\\nIn the simplest case there was potentially 6 parameters used based on the 6x CpG sites noted and their \\u03b2-values for the model. However, given the model type there it is very likely there were more than 6x parameters used. e.g. kernel function or tuned hyperparameters.\",\n",
      "            \"optimization/regularization\": \"None clearly mentioned in text if used. Validation data set noted but not in context of use for early stopping.\",\n",
      "            \"model/availability\": \"No source code released or GitHub/ code repository available from the text.\",\n",
      "            \"model/duration\": \"No contextual SVM ML model execution time information in text.\",\n",
      "            \"model/interpretability\": \"Black box - no model source code linked in a repository (No GitHub/Zenodo/other). Dataset info for the training and test set is available in supplementary file. Less clear for separate valdation dataset. Very poor model optimisation information in the text/suppl. files which is also heavily contributing to black box model nature.  \",\n",
      "            \"dataset/availability\": \"Two DNA methylation datasets GSE88929 and GSE102177 with clinical information were downloaded from the GEO database (http://www.ncbi.nlm.nih.gov/geo/). Splits are noted in the text and use of the dataset data points for test, training and validation.\\n\\nTable S3 provided in supplementary data contains the sample information of the training set and testing set in the GSE88929 datasets.\",\n",
      "            \"dataset/provenance\": \"Data source: GEO database\\n\\nDatat type: DNA methylation data\\n\\nAcronym note: Gestational diabetes mellitus (GDM)\\n\\nTwo DNA methylation datasets GSE88929 and GSE102177 with clinical information were downloaded from the GEO database (http://www.ncbi.nlm.nih.gov/geo/). Both datasets were measured by the Illumina HumanMethylation450 BeadChip assays. \\n\\n-GSE88929 dataset: contained 68 umbilical cord blood samples from the newborns of mothers with GDM and 64 controls without GDM [12]. \\n\\n-GSE102177 dataset: consisted of the peripheral blood samples from 18 fullsibling pairs that were exposed to different conditions of intrauterine hyperglycemia (GDM pregnancy or non-GDM pregnancy). Therefore, there were 18 samples with exposure to maternal GDM and 18 controls without exposure to GDM in the GSE102177 dataset [23].\",\n",
      "            \"dataset/redundancy\": \"Little information on redundancy reduction methods for the data splits in the text.\\n\\nLikely based on the text, the test and training were kept separate.\",\n",
      "            \"dataset/splits\": \"Authors randomly separated the samples from GSE88929 into the training set and testing set, containing 66 samples.\\n\\nTable S3 provided in the supplementary data contains the sample information of the training set and testing set in the GSE88929 datasets.\\n\\nData points:\\n-Test: 66 samples.\\n-Training: 66 samples.\\n\\nThe samples from GSE102177 were instead used as an independent validation set. This contained: 18 samples.\",\n",
      "            \"publication/authors\": \"Yan Liu, Hui Geng, Bide Duan, Xiuzhi Yang, Airong Ma, and Xiaoyan Ding\",\n",
      "            \"publication/journal\": \"BioMed Research International\",\n",
      "            \"publication/title\": \"Identification of Diagnostic CpG Signatures in Patients with Gestational Diabetes Mellitus via Epigenome-Wide Association Study Integrated with Machine Learning\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6634f1d6ded6e7820f74a18b\",\n",
      "        \"shortid\": \"fbkgc98sns\",\n",
      "        \"uuid\": \"56d33311-36d5-4be6-9a3f-2b732a2b4c63\",\n",
      "        \"created\": \"2024-05-03T14:16:54.445Z\",\n",
      "        \"updated\": \"2024-05-03T14:16:54.445Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"33532838\",\n",
      "            \"authors\": \"Fergus Imrie, Anthony R Bradley, Charlotte M Deane \",\n",
      "            \"journal\": \"Bioinformatics\",\n",
      "            \"title\": \"Generating property-matched decoy molecules using deep learning\",\n",
      "            \"doi\": \"10.1093/bioinformatics/btab080\",\n",
      "            \"year\": \"2021 \"\n",
      "        },\n",
      "        \"score\": 0.52,\n",
      "        \"matches\": {\n",
      "            \"evaluation/confidence\": \"Yes, confidence intervals are reported. The generated decoys by the model improved the Deviation from Optimal Embedding (DOE) score by an average of 81% and 66%, respectively, decreasing from 0.166 to 0.032 for DUD-E and from 0.109 to 0.038 for DEKOIS 2.0.\",\n",
      "            \"evaluation/measure\": \"The reported performance metrics include the DOE (deviation from optimal embedding) score, doppelganger score, and AUC ROC from predictive models and virtual screening performance.\",\n",
      "            \"evaluation/method\": \"The model was evaluated on independent SBVS datasets DUD-E and DEKOIS 2.0.\",\n",
      "            \"optimization/algorithm\": \"It is deep learning method using graph neural networks.\\nIt is not a novel algorithm.\",\n",
      "            \"optimization/encoding\": \"The data were encoded as graphs representing molecules. The model was trained using pairs of molecules, framing decoy generation as a multimodal graph-to-graph translation problem.\",\n",
      "            \"optimization/meta\": \"It is not a meta-predictor.\",\n",
      "            \"model/interpretability\": \"No mention was made on interpretability. The model appears to be a black box.\",\n",
      "            \"model/output\": \"It is a generative model.\",\n",
      "            \"dataset/provenance\": \"The source of the data is 250,000 randomly selected molecules from ZINC\\nThis subset was already used by Go\\u00b4mez-Bombarelli et al. (2018).\\nPairs of molecules were constructed to satisfy the following criteria: \\n(i) identical heavy atom count and counts of specific heavy atoms (C, N, O, S, Cl, F)\\n(ii) high similarity in property-space\\n(iii) low structural similarity\",\n",
      "            \"dataset/redundancy\": \"Test sets are independent from the training data.\",\n",
      "            \"dataset/splits\": \"Authors used two different test sets, DUD-E with 102 targets and DEKOIS 2.0 with 80 targets, and prepared different size training sets accordingly.\\nThis resulted in a training set of 131 199 pairs for DUD-E and 103 170 for DEKOIS 2.0.\\nAuthors selected 1000 pairs for model validation and used the remainder to train the model.\",\n",
      "            \"publication/authors\": \"Fergus Imrie, Anthony R Bradley, Charlotte M Deane \",\n",
      "            \"publication/title\": \"Generating property-matched decoy molecules using deep learning\",\n",
      "            \"publication/year\": \"2021 \"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6634f443ded6e7820f74a1ac\",\n",
      "        \"shortid\": \"l5alam5gs2\",\n",
      "        \"uuid\": \"2a384a79-d63e-4e6d-9930-10b3a40c2718\",\n",
      "        \"created\": \"2024-05-03T14:27:15.320Z\",\n",
      "        \"updated\": \"2024-05-03T14:27:15.320Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"36414666\",\n",
      "            \"authors\": \"Fenglei Li, Qiaoyu Hu, Xianglei Zhang, Renhong Sun, Zhuanghua Liu, Sanan Wu, Siyuan Tian, Xinyue Ma, Zhizhuo Dai, Xiaobao Yang, Shenghua Gao & Fang Bai\",\n",
      "            \"journal\": \"Nature Communications\",\n",
      "            \"title\": \"DeepPROTACs is a deep learning-based targeted degradation predictor for PROTACs\",\n",
      "            \"doi\": \"10.1038/s41467-022-34807-3\",\n",
      "            \"year\": \"2022\"\n",
      "        },\n",
      "        \"score\": 0.86,\n",
      "        \"matches\": {\n",
      "            \"evaluation/comparison\": \"Only comparison to SVM and RF models (developed by authors) was done.\",\n",
      "            \"evaluation/measure\": \"Average accuracy and AUROC are the reported performance metrics.\",\n",
      "            \"evaluation/method\": \"The model was eventually evaluated on a test set, after optimization on a validation set in another experiment beforehand.\\nAuthors further validated the model by using a batch recently reported PROTACs.\",\n",
      "            \"optimization/algorithm\": \"The algorithm is a Multi Layer Perceptron (Neural Networks).\\nAuthors compared the algorithm with SVM and RF, and they got better results with Neural Networks.\",\n",
      "            \"optimization/config\": \"They used a validation set to optimize hyperparameters. The source code of DeepPROTACs and associated data preparation scripts are available at github (https://github.com/fenglei104/ DeepPROTACs) 98. The final DeepPROTACs model is also provided.\",\n",
      "            \"optimization/encoding\": \"Authors analyzed each PROTAC molecule from through 5 aspects: POI Pocket, E3 Pocket, Warhead, E3 ligand, and Linker. The first 4 are preprocessed and encoded by Graph Convolution and Max Pooling layers. As mentioned,  to process the data regarding the SMILES format of the \\\"linker\\\" part in PROTAC molecules, they used embeddings followed by bidirectional LSTM and a fully connected layer.\",\n",
      "            \"optimization/features\": \"For each aspect of the PROTAC molecule (5), 64 features were extracted to be fed into the main neural networks at the end.\\nNo mention was made on feature selection\",\n",
      "            \"optimization/fitting\": \"The number of reported parameters is not bigger than training points. Authors used over-sampling method, compared to normal sampling and under-sampling, to address the imbalance in the data.\",\n",
      "            \"optimization/meta\": \"As a part of data encoding, to process the data regarding the SMILES format of the \\\"linker\\\" part in PROTAC molecules, they used embeddings followed by bidirectional LSTM and a fully connected layer.\",\n",
      "            \"optimization/parameters\": \"Overall 17 parameters were reported by Authors.\\nParameters were optimized on validation set.\",\n",
      "            \"optimization/regularization\": \"Authors used over-sampling method, compared to normal sampling and under-sampling, to address the imbalance in the data.\",\n",
      "            \"model/availability\": \"They used a validation set to optimize hyperparameters. The source code of DeepPROTACs and associated data preparation scripts are available at github (https://github.com/fenglei104/ DeepPROTACs) 98. The final DeepPROTACs model is also provided.\",\n",
      "            \"model/interpretability\": \"No mention on interpretability of the model was made. Due to many layers of input encoding and using neural networks, the model appears to be a black box.\",\n",
      "            \"model/output\": \"It is a binary classifier.\",\n",
      "            \"dataset/availability\": \"The PROTACs data used in this study are available in the public database of PROTAC-DB (http://cadd.zju.edu.cn/protacdb/).\",\n",
      "            \"dataset/provenance\": \"The source of the data is PROTAC molecules that are either present on PROTACS-DB, an online database, or gathered from \\\"other public sources\\\".\\nThe size of the whole dataset used is 2832.\\nIt was further labeled as 988 positive and 1844 samples.\",\n",
      "            \"dataset/redundancy\": \"Data was split randomly and no mention on redundancy reduction was made.\\nThe whole dataset is considered to be small in size and, to my knowledge, no previous ML dataset does exist for this purpose.\",\n",
      "            \"dataset/splits\": \"For optimization purpose, they randomly split the data into the training set, validation set, and test set at a ratio of 8:1:1.\\nAfter optimization, they used a 8:2 ratio for training:test.\\nData was split randomly and no mention was made on the distribution of the negatives/positives different divisions.\",\n",
      "            \"publication/authors\": \"Fenglei Li, Qiaoyu Hu, Xianglei Zhang, Renhong Sun, Zhuanghua Liu, Sanan Wu, Siyuan Tian, Xinyue Ma, Zhizhuo Dai, Xiaobao Yang, Shenghua Gao & Fang Bai\",\n",
      "            \"publication/journal\": \"Nature Communications\",\n",
      "            \"publication/title\": \"DeepPROTACs is a deep learning-based targeted degradation predictor for PROTACs\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6634f526ded6e7820f74a1b8\",\n",
      "        \"shortid\": \"skg7vifrfy\",\n",
      "        \"uuid\": \"242800d0-70de-4409-9b2f-bff40afacc32\",\n",
      "        \"created\": \"2024-05-03T14:31:02.390Z\",\n",
      "        \"updated\": \"2024-05-03T14:31:02.390Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"No\",\n",
      "            \"authors\": \"Hannes St\\u00e4rk, Octavian-Eugen Ganea, Lagnajit Pattanaik, Regina Barzilay, Tommi Jaakkola\",\n",
      "            \"journal\": \"arXiv\",\n",
      "            \"title\": \"EQUIBIND: Geometric Deep Learning for Drug Binding Structure Prediction\",\n",
      "            \"doi\": \"https://doi.org/10.48550/arXiv.2202.05146\",\n",
      "            \"year\": \"2022\"\n",
      "        },\n",
      "        \"score\": 1,\n",
      "        \"matches\": {\n",
      "            \"evaluation/availability\": \"Code to reproduce results with the provided model weights is available at https://github.com/HannesStark/ EquiBind.\",\n",
      "            \"evaluation/comparison\": \"The model was compared to similar software and methods including QVINA, GNINA, SMINA, and GLIDE.\\nAlso the combinations of the model with SMINA and QVINA was included in the benchmark.\",\n",
      "            \"evaluation/confidence\": \"MEAN, MED, 25TH, 50TH, 75TH, % below 5 and 2 A\\u02da was reported for the mentioned evaluation metrics. While the standard model performs relatively well, in most metrics the best results are obtained when EQUIBIND is combined with SMINA for fine-tuning.\",\n",
      "            \"evaluation/measure\": \"Authos used the ligand root mean square deviation (L-RMSD), the centroid distance, and the KabschRMSD as evaluation metics.\",\n",
      "            \"evaluation/method\": \"The evaluation was carried out on an independent test set in two experiments: 1. Flexible blind self-docking and 2. Blind re-docking\",\n",
      "            \"optimization/algorithm\": \"It is a geometric deep learning model.\",\n",
      "            \"optimization/config\": \"Code to reproduce results or perform fast docking with the provided model weights is available at https://github.com/HannesStark/ EquiBind.\",\n",
      "            \"optimization/encoding\": \"Both input molecules (ligand & receptor) are represented to the model as spatial k-nearest neighbor (k-NN) graphs.\",\n",
      "            \"optimization/features\": \"For the \\u03b1-carbons in the receptor graph, authors used the residue type as a feature. The edges have two attributes.\\n\\nIn the ligand, the edges have features that are encoded in the same fashion as for the receptor. Meanwhile, the atoms have the following features: atomic number; chirality; degree; formal charge; implicit valence; the number of connected hydrogens; the number of radical electrons; hybridization type; whether or not it is in an aromatic ring; in how many rings it is; and finally, 6 features for whether or not it is in a ring of size 3, 4, 5, 6, 7, or 8.\",\n",
      "            \"optimization/fitting\": \"p is not larger than the number of training points. \",\n",
      "            \"optimization/meta\": \"The model combines Graph Matching Networks and E(3)-Equivariant Graph Neural Networks.\",\n",
      "            \"optimization/parameters\": \"Overall 15 parameters were reported.\\nAuthors used search space strategy to obtain a strong performance on the validation set.\",\n",
      "            \"optimization/regularization\": \"Authors optimized the model using \\\"Adam\\\" and did early stopping with patience of 150 epochs based on the percentage of predicted validation set complexes with an RMSD better than 2 A.\",\n",
      "            \"model/availability\": \"The model and its source code is available at https://github.com/HannesStark/ EquiBind.\",\n",
      "            \"model/duration\": \"In \\\"Flexible blind self-docking\\\" experiment, Standard EQUIBIND takes on average 0.16 second on 16 CPU cores and 0.04 second on a 6GB GTX 1060 GPU to process a task.\",\n",
      "            \"model/interpretability\": \"No mention was made on the interoperability of the model. However, due to the complexity of the model, it appears to be a black box.\",\n",
      "            \"model/output\": \"The model is close to a regression model by predicting the coordinates of the ligand-protein binding site alongside the bond angles and lengths of the ligand molecule.\",\n",
      "            \"dataset/availability\": \"The data and associated scripts available at https://github.com/HannesStark/EquiBind.\",\n",
      "            \"dataset/provenance\": \"Authors used protein-ligand complexes from PDBBind in a time split manner.\\nThe newest version, PDBBind v2020, contains 19,443 protein-ligand complexes with 3,890 unique receptors and 15,193 unique ligands.\\n\",\n",
      "            \"dataset/redundancy\": \"A time split strategy was adopted by the authors.\",\n",
      "            \"dataset/splits\": \"Of the 19 119 preprocessed complexes, 1512 were discovered in 2019 or later. From these, they randomly sampled 125 unique proteins and collected all new complexes containing them (363) to create the final test set.\\nFrom the remaining complexes that are older than 2019, we remove those with ligands contained in the test set, giving 17,347 complexes for training and validation. These are divided into 968 validation complexes, which share no ligands with the remaining 16,379 train complexes.\",\n",
      "            \"publication/authors\": \"Hannes St\\u00e4rk, Octavian-Eugen Ganea, Lagnajit Pattanaik, Regina Barzilay, Tommi Jaakkola\",\n",
      "            \"publication/title\": \"EQUIBIND: Geometric Deep Learning for Drug Binding Structure Prediction\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6638a38fb30933003cc215c1\",\n",
      "        \"shortid\": \"63a7xx35gw\",\n",
      "        \"uuid\": \"c4675347-1a80-45e3-b55c-1e43e2e94e91\",\n",
      "        \"created\": \"2024-05-06T09:31:59.998Z\",\n",
      "        \"updated\": \"2024-05-06T09:31:59.998Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"35489069\",\n",
      "            \"authors\": \"Vineet Thumuluri, Jos\\u00e9 Juan Almagro Armenteros, Alexander Rosenberg Johansen, Henrik Nielsen, Ole Winther\",\n",
      "            \"journal\": \"Nucleic Acids Research\",\n",
      "            \"title\": \"DeepLoc 2.0: multi-label subcellular localization prediction using protein language models\",\n",
      "            \"doi\": \"10.1093/nar/gkac278\",\n",
      "            \"year\": \"2022\"\n",
      "        },\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"evaluation/comparison\": \"The model was compared to other similar methods including YLoc+, DeepLoc 1.0,  Fuel-mLoc, and LAProtT5\",\n",
      "            \"evaluation/confidence\": \"Standard deviations are reported.\",\n",
      "            \"evaluation/measure\": \"Metrics for quantifying the performance in prediction of subcellular localization:\\nNumber of predicted labels, Accuracy, Jaccard, MicroF1, MacroF1, Matthews Correlation Coefficient\\n\\nFor quantifying the relevance of attention to the sorting signals:\\nImportance in signal: Total attention mass present within the signal.\\nSignal over background: The average attention value within the signal over the average value outside the signal.\\nMetric Entropy: The entropy of the attention normalized by the information length of the protein. \\nKL-Divergence: Distributional dissimilarity between the signal and attention\",\n",
      "            \"evaluation/method\": \"An independent dataset (3) was used for the evaluation purpose.\",\n",
      "            \"optimization/algorithm\": \"The prediction stage consists of two multi-layer perceptron (MLP) classifier heads.\\nThe first head is trained along with the learnable vector from the attention step for the ten-class multi-label subcellular localization task.\\nA second head is trained after freezing the rest of the parameters for the nineclass sorting signal prediction task\",\n",
      "            \"optimization/encoding\": \"Then using an interpretable attention pooling mechanism a sequence representation is produced. The two prediction heads then utilize this representation to predict multiple labels for both the 10-type subcellular localization and 9-type sorting signal prediction tasks.\",\n",
      "            \"optimization/fitting\": \"Discrete-Cosine Transform was used to regularize the attention-pooling layer.\",\n",
      "            \"optimization/meta\": \"DeepLoc 2.0 uses a transformer-based protein language model to encode the input amino acid sequence.\\nFor this purpose, they evaluated three publicly available transformer models:\\nThe 12-layer ESM model with 84M parameters\\nThe 33-layer ESM model with 650M parameters\\nThe 3B parameter ProtT5-XL-UniRef50model\",\n",
      "            \"model/availability\": \"It is available through a webserver: https://services.healthtech.dtu.dk/services/DeepLoc-2.0/\",\n",
      "            \"model/duration\": \"Based on the language model used, webserver estimated time per sequence are as follows:\\n\\nShort sequences (Average length: 104) for ESM1b and ProtT5 respectively:\\nModel load time (s) 11.07 and 26.80 \\nPrediction time (s / seq) 0.83 3.93\\nPlot time (s / seq) 2.38 2.57\\n\\nLong sequences (Average length: 400) for ESM1b and ProtT5 respectively:\\nModel load time (s) 11.09 26.09\\nPrediction time (s / seq) 3.29 7.33\\nPlot time (s / seq) 7.94 7.97\",\n",
      "            \"model/interpretability\": \"After encoding the sequences with protein language models, an interpretable attention pooling mechanism is used to produce sequence representations.\",\n",
      "            \"model/output\": \"The model is a multi-label classification model.\",\n",
      "            \"dataset/availability\": \"The data used for training and testing are available at https://services.healthtech.dtu.dk/service.php?DeepLoc-2.0\",\n",
      "            \"dataset/provenance\": \"The authors used 3 different datasets for different purposes.\\n1. Localization dataset for training purpose, obtained from SwissProt:\\nCytoplasm =  9870 \\nNucleus =  9720\\nExtracellular =  3301 \\nMitochondrion =  2590 \\nCell membrane =  4187 \\nEndoplasmic reticulum (ER) =  2180 \\nPlastid =  1047 \\nGolgi apparatus =  1279 \\nLysosome/Vacuole =  1496 \\nPeroxisome =  304\\n\\n2. Localization dataset for testing purpose, obtained from The Human Protein Atlas:\\nNucleus =  893\\nCytoplasm =  562\\nCell membrane =  287\\nMitochondrion =  196\\nGolgi apparatus =  86\\nEndoplasmic reticulum (ER)  =  77\\n\\n3. Sorting signals dataset, curated from literature:\\nSignal Peptides (SP)  =  1011\\nTransmembrane domains (TM)  =  260 \\nMitochondrial transit peptide (MT)  =  242 \\nChloroplast transit peptide (CH)  =  90 \\nThylakoidal lumen composite transit peptide (TH) 42 \\nNuclear localization signal (NLS) 148 \\nNuclear export signal (NES) 100 \\nPeroxisome targeting signal (PTS) 127\",\n",
      "            \"dataset/redundancy\": \"Authors ensured that each pair of train and test fold does not share sequences that have global sequence identity greater than 30%.\\n\",\n",
      "            \"dataset/splits\": \"1 and 3 datasets are used in a 5-fold cross-validation after homology based partitioning.  \\ndataset 2 is completely used for evaluation purpose.\",\n",
      "            \"publication/authors\": \"Vineet Thumuluri, Jos\\u00e9 Juan Almagro Armenteros, Alexander Rosenberg Johansen, Henrik Nielsen, Ole Winther\",\n",
      "            \"publication/journal\": \"Nucleic Acids Research\",\n",
      "            \"publication/title\": \"DeepLoc 2.0: multi-label subcellular localization prediction using protein language models\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6638a437b30933003cc215cd\",\n",
      "        \"shortid\": \"3a79km88l8\",\n",
      "        \"uuid\": \"fa0099b4-d7bf-44c1-bee9-04ac2176a4d9\",\n",
      "        \"created\": \"2024-05-06T09:34:47.725Z\",\n",
      "        \"updated\": \"2024-05-06T09:34:47.725Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"35896542\",\n",
      "            \"authors\": \"Noelia Ferruz, Steffen Schmidt, Birte H\\u00f6cker\",\n",
      "            \"journal\": \"nature communications\",\n",
      "            \"title\": \"ProtGPT2 is a deep unsupervised language model for protein design\",\n",
      "            \"doi\": \"10.1038/s41467-022-32007-7\",\n",
      "            \"year\": \"2022\"\n",
      "        },\n",
      "        \"score\": 0.9,\n",
      "        \"matches\": {\n",
      "            \"evaluation/comparison\": \"The model was not compared to similar methods as it is quite novel.\\nAt one point, the generations by the model were compared to randomly generated sequences as the simplest baseline.\",\n",
      "            \"evaluation/confidence\": \"Only MD calculations for measuring structure stability have confidence intervals.\",\n",
      "            \"evaluation/measure\": \"The generations made by the model were compared to a randomly selected natural dataset of 10,000 data points (sequences) in terms of following measures:\\n1) globular domains % \\n2) Ordered content % \\n3) Alpha-helical content %\\n4) Beta-sheet content and %\\n5) Coil content \\n6) Structure stability using MD calculations\",\n",
      "            \"evaluation/method\": \"The model was evaluated based on the comparison of the model's generations to random naturally occurring samples in terms of sequence and structural properties.\",\n",
      "            \"optimization/algorithm\": \"The model is an autoregressive Transformer.\\nThe model is not novel.\",\n",
      "            \"optimization/config\": \"The model weights are publicly available in the HuggingFace repository: https://huggingface.co/nferruz/ProtGPT2 and Zenodo: https://doi.org/10.5281/zenodo.6796843 [https://zenodo.org/record/ 6796843#.YswB9XbMIVA]\",\n",
      "            \"optimization/encoding\": \"BPE tokenizer was used to train the vocabulary of the dataset. BPE is a sub-word tokenization algorithm.\",\n",
      "            \"optimization/features\": \"The results shown in this work correspond to a model trained with a block size of 512 tokens.\\nNo feature selection step was involved.\",\n",
      "            \"optimization/fitting\": \"p is much larger than f. The model was fit in a way that the generations most resemble the ones that naturally occur. \",\n",
      "            \"optimization/meta\": \"The model is not a meta-predictor.\",\n",
      "            \"optimization/parameters\": \"The final model is a decoder-only architecture of 36 layers and 738 million parameters.\\nThe architecture matches that of the previously released GPT2-large Transformer.\",\n",
      "            \"model/availability\": \"The model is freely available and the code and documentation are available here: https:// huggingface.co/docs/transformers/main_classes/trainer\",\n",
      "            \"model/duration\": \"\\\"ProtGPT2 generates sequences in a matter of seconds\\\".\",\n",
      "            \"model/interpretability\": \"The model is a black box due to sheer number of 738 million parameters.\",\n",
      "            \"model/output\": \"It is a generative model.\",\n",
      "            \"dataset/availability\": \"The used dataset is publicly available through the URL: https://huggingface.co/datasets/nferruz/UR50_2021_04\\nNo information on licence was reported.\",\n",
      "            \"dataset/provenance\": \"The model was trained and evaluated on UniRef50 database (version 2021_04) with 49,874,565 data points.\\nThe dataset has been previously used in many other studies.\",\n",
      "            \"dataset/redundancy\": \"The split has been done randomly.\\nThe evaluation set is a 10% independent exclusion from UniRef50. The rest 90% was used for training.\\nUniRef50 is a 50% identity clustered database of UniProt KB. \",\n",
      "            \"dataset/splits\": \"They have used a 90 - 10 (44.9 million and 4.9 million) split corresponding to training and evaluation set respectively.\\nNo feature has been reported to be taken into account for splitting the data. \",\n",
      "            \"publication/authors\": \"Noelia Ferruz, Steffen Schmidt, Birte H\\u00f6cker\",\n",
      "            \"publication/journal\": \"nature communications\",\n",
      "            \"publication/title\": \"ProtGPT2 is a deep unsupervised language model for protein design\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"667203b937ea6fa797a6c2ef\",\n",
      "        \"shortid\": \"x9vqohdvu0\",\n",
      "        \"uuid\": \"7a30fa4d-704a-4379-b242-310bf0bf9d57\",\n",
      "        \"created\": \"2024-06-18T22:01:29.043Z\",\n",
      "        \"updated\": \"2024-06-18T22:01:29.043Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"36525447\",\n",
      "            \"authors\": \"Xiaohui Zou, Marcus Nguyen, Jamie Overbeek, Bin Cao,  and James J. Davis\",\n",
      "            \"journal\": \"PLOS One\",\n",
      "            \"title\": \"Classification of bacterial plasmid and chromosome derived sequences using machine learning\",\n",
      "            \"doi\": \"10.1371/journal.pone.0279280\",\n",
      "            \"year\": \"2022\"\n",
      "        },\n",
      "        \"score\": 0.95,\n",
      "        \"matches\": {\n",
      "            \"evaluation/availability\": \"No - the evaluation is not clearly available based on GitHub repository content or linked from text.\",\n",
      "            \"evaluation/comparison\": \"The different models cross-compared for the classification task could be considered baselines from lower (eg: logistic regression) to higher complexity (eg: neural network) models.\\n\\nFurther, the text does compare the models to existing classification methods described in previous publications:\\n-PlasClass\\n-PlasFlow\\nThese were evaluated on the same datasets used in this study.\",\n",
      "            \"evaluation/confidence\": \"Confidence intervals are reported for the models performances throughout the text. \",\n",
      "            \"evaluation/measure\": \"For classifying plasmid and chromosome sequences using 6-mers as features, the following model metrics were reported in the text:\\n\\n-Accuracy\\n-F1 score\\n-Precision \\n-Recall \",\n",
      "            \"evaluation/method\": \"10-fold cross-validation was employed for model evaluation.\\n\",\n",
      "            \"optimization/algorithm\": \"4x model types were noted to have been used for the model generations based on text:\\n\\n1. Logistic regression \\n2. Random forest   \\n3. eXtreme Gradient Boosting - XGBoost   \\n4. Neural network\\n\\nNone of these models are novel\",\n",
      "            \"optimization/config\": \"Hyperparameters detailed in the text. The model GitHub linked may include more configuration information but unclear.  \",\n",
      "            \"optimization/encoding\": \"The data encoding was through k-merisation which involved creating numerical representations of the categorical data (DNA sequences) for the machine learning models.  Likely one-hot encoding but hard to determine from text as not explictily written..\",\n",
      "            \"optimization/features\": \"Features are somewhat described in the text but exact feature figures not explicitly included in relation the the 4x model types used. However, some of these can be inferred based on the text.\\n\\nSome more information can be extrapolated from the text based on the features below:\\n-K-mer size: the text mentions using k-mers of size 6 (6-mers) for feature extraction.\\n-Subsequence length: the model used two subsequence lengths - 2kb and 5kb.\\n\\n4x nucleotides (A, T, G, C) means a 6-mer can have 4^6 = 4096 possible combinations.\\nThe text notes they only considered the \\\"canonical\\\" k-mer - the lexicographically highest version (e.g., \\\"AAAAAA\\\" instead of \\\"TTTTTT\\\"). This reduces the number of features by half (assuming even distribution of nucleotides).\\n\\nTherefore, the model features for 6-mers could be inferred as (4^6 / 2) = 2048. However, given the exact numbers are not stated for the models in text this may not be true.\",\n",
      "            \"optimization/fitting\": \"Unclear model fittings - there is not a lot of information in the text on the precise number of parameters or features used to generate the 4x models.\",\n",
      "            \"optimization/parameters\": \"Exact parameters for the 4x models are not clearly stated in the text. \\n\\n1. Logistic regression = unkown, but uses a single weight vector with a dimension equal to the number of features.\\n\\n2. Random forest   = 200 (based on 200 decision trees noted in the final model.)\\n\\n3. eXtreme Gradient Boosting - XGBoost  = unkown, little information in text\\n\\n4. Neural network = unkown, not explicitly stated in text\\n-However, information for the neural network parameters can be inferred to be large as it has 7 layers with specific numbers of neurons.\\n-Text notes text number of neurons in each layer (256, 256, 128, 128, 32, 10, and 1).\\n-Hyperparameter tuning & computational Resources seem to have been considered for parameter selection.\\n\",\n",
      "            \"optimization/regularization\": \"10-fold cross-validation was one of the key approaches technique used to prevent overfitting. For the neural network specifically two other approaches were mentioned in the text to avoid overfitting: drop-out layers (these were applied to the first 4x layers to prevent co-adaptation and encourage generalisable features.) and L2 weight regularisation (model used a value of 0.0001 to penalise large weights to prevent overfitting.).\",\n",
      "            \"model/availability\": \"Github containing model source code available: https://github.com/BV-BRC-dependencies/zou-plasmid-prediction. Python code primarily, no interactive notebooks. No docker/container deployment linked or clearly available. Repository license not clear.\",\n",
      "            \"model/duration\": \"Clear equations for helping with the estimation of neural network memory usage are present. However, no exact compute requirements for model training or time to do so. Additionally, no run time info for use on datasets.\\n\\nText notes GPUs plural for model needs - it could be presumed more than one GPU is needed. 2x GPUs are mentioned at another point in the text and improved performance in relation to this.\",\n",
      "            \"model/interpretability\": \"Moderately interpretable - but variable by the 4x model types which makes this harder to discern interpretability. Low information on exact parameters and features in the text and somewhat confusing as there is mutliple models. However, the GitHub with data is available and model source code. Although no containers/environment control tooling/code provided. The simpler model types (e.g. random forest) are more interpretable but the more complex ones (e.g. neural network) are somewhat more complex. The authors did a decent job for describing the various DOME areas.\",\n",
      "            \"dataset/availability\": \"Datasets used for training & test available on the GitHub repository within labelled CSV files. GitHub: https://github.com/BV-BRC-dependencies/zou-plasmid-prediction.\\n\\nThe original data sourced from BV-BRC (https://www.bv-brc.org/) should also still be avaialble provided no changes have occured to the data since the original study publication.\",\n",
      "            \"dataset/provenance\": \"Data source is from the database: PAThosystems Resource Integration Center (PATRIC).\\n-Note: this database is now called the Bacterial and Viral Bioinformatic Resource Center (BV-BRC).\\n\\nThe data type is DNA, plasmids and chromosomes.\\n\\nThe study classed its data as follows:\\n\\u201cplasmid\\u201d as positive class, Npos = 10,654 \\n\\u201cchromosome\\u201d as the negative class, Nneg = 10,584\\n\\nNovel dataset was compiled from publicly available data - this dataset is not community recognised/re-used but the overall database content would be. \",\n",
      "            \"dataset/redundancy\": \"The dataset (exempting the holdout set) was split 7:2:1 ratio for model training, testing, and validation, respectively.\\n\\nYes - independent training and test as noted from use of hold out set.\",\n",
      "            \"dataset/splits\": \"10,654 plasmid genomes with lengths greater than 2kb.\\n-plasmid dataset contained a total of 1,258 species and 485 genera\\n10,584 bacterial chromosomes with lengths greater than 10kb. \\n-chromosomal dataset contained 2,212 species and 906 genera. \\n\\nPrior to building models: 1,000 plasmid and 1,000 chromosomal sequences were separated from the dataset to create a holdout set.\",\n",
      "            \"publication/authors\": \"Xiaohui Zou, Marcus Nguyen, Jamie Overbeek, Bin Cao,  and James J. Davis\",\n",
      "            \"publication/journal\": \"PLOS One\",\n",
      "            \"publication/title\": \"Classification of bacterial plasmid and chromosome derived sequences using machine learning\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63a25db2e8edf6ce46f6e84b\",\n",
      "        \"uuid\": \"8c0c94cd-3172-4f65-92b0-b997742324e0\",\n",
      "        \"created\": \"2022-12-21T01:13:22.874Z\",\n",
      "        \"updated\": \"2022-12-21T01:38:36.717Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"authors\": \"Ang Guo, Zhiyu Chen, Fang Li, and Qian Luo\",\n",
      "            \"doi\": \"10.1093/gigascience/giad021\",\n",
      "            \"journal\": \"GigaScience\",\n",
      "            \"pmid\": \"37039115\",\n",
      "            \"title\": \"Delineating Regions-of-interest for Mass Spectrometry Imaging by Multimodally Corroborated Spatial Segmentation\",\n",
      "            \"year\": \"2023\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"shortid\": \"ck60ijuxvo\",\n",
      "        \"score\": 0.9,\n",
      "        \"matches\": {\n",
      "            \"evaluation/comparison\": \"Yes, our method was compared with two internal validation measures: (1) segmentation was evaluated by how closely it resembled the low-dimension overview of the high\\u2010dimensional molecular content of MSI data obtained by nonlinear dimension reduction techniques (here we used UMAP). The resemblance between the UMAP image and the segmentation maps was measured by applying a Canny edge detector to both and computing their edge correlation.  (2) the Davies\\u2013Bouldin index (DBI) was used to find the optimal segmentation for MSI data. DBI measures the ratio of within-cluster distances (the measure of intra-cluster compactness) to between-cluster distances (the measure of inter-cluster separation), so a smaller DBI indicates better-defined clusters and thus supposedly better segmentation. \",\n",
      "            \"evaluation/confidence\": \"not applicable \",\n",
      "            \"evaluation/measure\": \"Cohen's kappa score between MSI- and Histology-segmentation results\",\n",
      "            \"evaluation/method\": \"A multimodal fusion-based method was proposed in our manuscript. Visual evaluation by an expert was also performed.\",\n",
      "            \"optimization/algorithm\": \"Spectral Clustering algorithm with  n_clusters=3 to 8, affinity='cosine' or 'nearest neighbors', n_components=5, assign_labels='kmeans'\",\n",
      "            \"optimization/config\": \"Not applicable \",\n",
      "            \"optimization/encoding\": \"An inner layer (conv5-block32-concat) of DenseNet 201 was used as our extractor of choice to encode the stain color and morphology of a 2D H&E image tile into a set of informative histomorphological features (HF). To stay in keeping with ImageNet, our input tiles had to be resized to [224, 224, 3] through bilinear interpolation and each color channel had to be centered to zero . Eventually, the output arrays after the concatenation operation at the conv5_block32 layer of DenseNet201 were 2-D globally average-pooled, Min-Max scaled, and reshaped as a \\\"histomorphological feature (HF) spectrum\\\" of 1,920 variables.\",\n",
      "            \"optimization/features\": \"HF data cube had 1920 histomorphological features. For the MSI data of whole kidney, the number of m/z variables was 87. For the tumor data, the number of m/z variables was 89. Feature selection was performed to include only the ions that had a stronger signal in the foreground tissue areas than the background glass substrates.\",\n",
      "            \"optimization/parameters\": \"n_clusters were selected objectively by a multimodal fusion method proposed in our manuscript, the affinity and n_components were empirically configured to produce visually less fragmented regions \",\n",
      "            \"optimization/regularization\": \"Not applicable \",\n",
      "            \"model/availability\": \"Yes, available at https://github.com/guoang4github/ROIforMSI/ (Licence: GPL-3)\",\n",
      "            \"model/duration\": \"less than 1 min\",\n",
      "            \"model/interpretability\": \"Not applicable\",\n",
      "            \"model/output\": \"Clustering \",\n",
      "            \"dataset/availability\": \"Yes, The MSI data have been deposited to the ProteomeXchange Consortium (http://proteomecentral.proteomexchange.org) via the iProX partner repository with the dataset identifier PXD038876.\",\n",
      "            \"dataset/provenance\": \"DESI-MSI experiments of whole mouse kidney and renal tumor specimens. Two MSI datasets and their corresponding H&E microscopy images.  The MSI data have been deposited to the ProteomeXchange Consortium (http://proteomecentral.proteomexchange.org) via the iProX partner repository with the dataset identifier PXD038876.\",\n",
      "            \"dataset/redundancy\": \"Not applicable \",\n",
      "            \"dataset/splits\": \"Not applicable \",\n",
      "            \"publication/authors\": \"Ang Guo, Zhiyu Chen, Fang Li, and Qian Luo\",\n",
      "            \"publication/title\": \"Delineating Regions-of-interest for Mass Spectrometry Imaging by Multimodally Corroborated Spatial Segmentation\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"645aa34160bf612a3caabc1b\",\n",
      "        \"uuid\": \"9b42e80b-19bd-49d8-b06e-3b8302ceb152\",\n",
      "        \"created\": \"2023-05-09T19:47:13.177Z\",\n",
      "        \"updated\": \"2023-05-09T19:48:29.691Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"authors\": \"Zhenjiang Fan, Kate F. Kernan, Aditya Sriram, Panayiotis V. Benos, Scott W. Canna, Joseph A. Carcillo, Soyeon Kim, and Hyun Jung Park\",\n",
      "            \"doi\": \"https://doi.org/10.1101/2021.07.17.452800\",\n",
      "            \"journal\": \"GigaScience\",\n",
      "            \"pmid\": \"Not yet assigned\",\n",
      "            \"title\": \"Deep neural networks with knockoff features identify nonlinear causal relations and estimate effect sizes in complex biological systems.\",\n",
      "            \"year\": \"2023\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"shortid\": \"ngjci1cyqx\",\n",
      "        \"score\": 0.86,\n",
      "        \"matches\": {\n",
      "            \"evaluation/comparison\": \"We compared our method to threeexisting methods, causalMGM, DAG-GNN, and NOTEAR.\",\n",
      "            \"evaluation/confidence\": \"better timing and accuracy\",\n",
      "            \"evaluation/measure\": \"Sensivitity and specificity\",\n",
      "            \"evaluation/method\": \"10-fold cross validation\",\n",
      "            \"optimization/algorithm\": \"The initial weights for the hidden layer are generated using the Glorot normal initializer, which uses \\ud835\\udc3f1\\u2212\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc54\\ud835\\udc62\\ud835\\udc59\\ud835\\udc4e\\ud835\\udc5f\\ud835\\udc56\\ud835\\udc67\\ud835\\udc4e\\ud835\\udc61\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b with the regularization parameter set to O(\\u221a(2logp/n)). To train this model, mean of squares of errors (MSE) is used to calculate the loss in comparison with the response on the output layer. To train the model\\u2019s parameters with respect to the loss function, we used a stochastic gradient descent method called \\u201cAdam optimization\\u201d. \",\n",
      "            \"optimization/encoding\": \"All the inputs have been normalized into the range [-1, 1] for fairness.\",\n",
      "            \"optimization/features\": \"We used a simulation data set, two public data, and one access-controlled data. Our simulation data are downloadable from our project website (https://github.com/ZhenjiangFan/DAG-deepVASE). TCGA breast invasive carcinoma (BRCA) data were downloaded from https://tcga.xenahubs.net, available under BRCA cohort, under gene expression RNAseq section, on IlluminaHiSeq (n=1,218) TCGA Hub. It consists of the gene expression RNAseq dataset (dataset ID: TCGA.BRCA.sampleMap/HiSeqV2) and the clinical phenotype dataset (dataset ID: TCGA.BRCA.sampleMap/BRCA_clinicalMatrix). To investigate the dietary effect of the human gut microbiome, we downloaded a cross-sectional data of 98 healthy volunteers from https://noble.gs.washington.edu/proj/DeepPINK/ that preprocessed the data set.\",\n",
      "            \"optimization/fitting\": \"We used linear fit.\",\n",
      "            \"optimization/parameters\": \"Parameters\\tValue\\nActivation function\\tRectified linear unit (ReLU)\\nInitial weight values\\tGlorot normal intializer\\nRegularization\\t\\ud835\\udc3f1\\u2212\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc54\\ud835\\udc62\\ud835\\udc59\\ud835\\udc4e\\ud835\\udc5f\\ud835\\udc56\\ud835\\udc67\\ud835\\udc4e\\ud835\\udc61\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b\\nOptimization\\tAdam optimization\\nLoss function\\tMean of squares of errors (MSE)\\nFDR control rate\\t0.05\\n\",\n",
      "            \"optimization/regularization\": \"We used \\ud835\\udc3f1\\u2212\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc54\\ud835\\udc62\\ud835\\udc59\\ud835\\udc4e\\ud835\\udc5f\\ud835\\udc56\\ud835\\udc67\\ud835\\udc4e\\ud835\\udc61\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b with the regularization parameter set to O(\\u221a(2logp/n)).\",\n",
      "            \"model/duration\": \"Within 6 hours for mid-sized samples.\",\n",
      "            \"model/interpretability\": \"we developed the first computational method that explicitly learns nonlinear causal relations and estimates the effect size using a deep-neural network approach coupled with the knockoff framework.\",\n",
      "            \"model/output\": \"Model classification.\",\n",
      "            \"dataset/provenance\": \"We used a simulation data set, two public data, and one access-controlled data. Our simulation data are downloadable from our project website (https://github.com/ZhenjiangFan/DAG-deepVASE). TCGA breast invasive carcinoma (BRCA) data were downloaded from https://tcga.xenahubs.net, available under BRCA cohort, under gene expression RNAseq section, on IlluminaHiSeq (n=1,218) TCGA Hub. It consists of the gene expression RNAseq dataset (dataset ID: TCGA.BRCA.sampleMap/HiSeqV2) and the clinical phenotype dataset (dataset ID: TCGA.BRCA.sampleMap/BRCA_clinicalMatrix). To investigate the dietary effect of the human gut microbiome, we downloaded a cross-sectional data of 98 healthy volunteers from https://noble.gs.washington.edu/proj/DeepPINK/ that preprocessed the data set.\",\n",
      "            \"dataset/redundancy\": \"all datasets are without overlap, kept coincident for each trial of the algorithms.\",\n",
      "            \"dataset/splits\": \"We used 10 fold cross validation in all the data sets. \",\n",
      "            \"publication/authors\": \"Zhenjiang Fan, Kate F. Kernan, Aditya Sriram, Panayiotis V. Benos, Scott W. Canna, Joseph A. Carcillo, Soyeon Kim, and Hyun Jung Park\",\n",
      "            \"publication/pmid\": \"Not yet assigned\",\n",
      "            \"publication/title\": \"Deep neural networks with knockoff features identify nonlinear causal relations and estimate effect sizes in complex biological systems.\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6634f4c2ded6e7820f74a1b4\",\n",
      "        \"shortid\": \"nsqtgf6bjv\",\n",
      "        \"uuid\": \"a80c9c2f-d151-4ef4-8aaf-28dfedcf8b7c\",\n",
      "        \"created\": \"2024-05-03T14:29:22.628Z\",\n",
      "        \"updated\": \"2024-05-03T14:29:22.628Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"37996753\",\n",
      "            \"authors\": \"Minkyung Baek, Ryan McHugh, Ivan Anishchenko, Hanlun Jiang, David Baker, Frank DiMaio\",\n",
      "            \"journal\": \"nature methods\",\n",
      "            \"title\": \"Accurate prediction of protein-nucleic acid complexes using RoseTTAFoldNA\",\n",
      "            \"doi\": \"10.1038/s41592-023-02086-5\",\n",
      "            \"year\": \"2023\"\n",
      "        },\n",
      "        \"score\": 0.9,\n",
      "        \"matches\": {\n",
      "            \"evaluation/comparison\": \"The predictions of the model were compared to AlphaFold (protein structure prediction method), Hdock (protein\\u2013DNA docking method), and methods for RNA prediction such as DeepFoldRNA, FARFAR2, and AIchemy_RNA.\",\n",
      "            \"evaluation/confidence\": \"Confidence metrics were used and reported tailored to different tasks.\",\n",
      "            \"evaluation/measure\": \"Local Distance Difference Test (lDDT),  fraction of native contacts (FNAT), mean interface predicted aligned error (PAE), CAPRI metrics, RMS, and plDDT.\",\n",
      "            \"evaluation/method\": \"The model was evaluated on an independent test set.\",\n",
      "            \"optimization/algorithm\": \"The model is a neural network-based approach adopted from RoseTTAFold.\",\n",
      "            \"optimization/config\": \"Source code and a link to the training weights have been made available at https://github.com/uw-ipd/RoseTTAFold2NA.\",\n",
      "            \"optimization/encoding\": \"The data is encoded as sequence (1D), residue pair (2D) and structural (3D) representations of protein\\u2013nucleic acid complexes. This makes it compatible with the three-track architecture of RoseTTAFoldNA.\",\n",
      "            \"optimization/features\": \"The model simultaneously refines three representations of a biomolecular system: sequence (1D), residue-pair distances (2D) and cartesian coordinates (3D).\",\n",
      "            \"optimization/fitting\": \"p is much larger than the number of training points.\",\n",
      "            \"optimization/meta\": \"It is not a meta-predictor.\",\n",
      "            \"optimization/parameters\": \"The model has \\u223c67\\u2009M parameters and made up of 36 total layers.\",\n",
      "            \"optimization/regularization\": \"To improve generalizability of protein\\u2013DNA interactions, authors added a few ways of \\u2018randomizing\\u2019 inputs during training. They also performed negative training.\",\n",
      "            \"model/availability\": \"Source code and a link to the training weights have been made available at https://github.com/uw-ipd/RoseTTAFold2NA. The model can be used through a conda environment.\",\n",
      "            \"model/interpretability\": \"The model appears to be a black box as a deep neural network with 67M parameteres.\",\n",
      "            \"model/output\": \"It is a structure prediction model that has some resemblance to a regressor in the sense that it predicts the spatial arrangement of atoms.\",\n",
      "            \"dataset/availability\": \"All data used for training and evaluation is publicly available through the PDB (https://www.rcsb.org/). \",\n",
      "            \"dataset/provenance\": \"Protein Data Bank was used as the source data for training, validation, and test.\",\n",
      "            \"dataset/redundancy\": \"Authors adopted a time split strategy to create an independent test set.\\nThe data was clustered using a 1\\u2009\\u00d7\\u200910\\u22123 hhblits E-value for proteins and 80% sequence identity for RNA molecules.\",\n",
      "            \"dataset/splits\": \"For training and validation sets, A dataset was constructed considering all PDB structures published at or before 30 April 2020, consisted of 7,396 RNA chains and 23,583 Protein-NA complexes.\\nFor Test set, all structures published to the PDB from May 2020 or later, consisted of 91 complexes with one protein molecule plus a single RNA chain or DNA duplex, 43 cases with a single RNA chain and 106 cases with more than one protein chain or more than a single RNA chain or DNA duplex.\",\n",
      "            \"publication/authors\": \"Minkyung Baek, Ryan McHugh, Ivan Anishchenko, Hanlun Jiang, David Baker, Frank DiMaio\",\n",
      "            \"publication/journal\": \"nature methods\",\n",
      "            \"publication/title\": \"Accurate prediction of protein-nucleic acid complexes using RoseTTAFoldNA\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6638a35eb30933003cc215bd\",\n",
      "        \"shortid\": \"nfj5rdqggm\",\n",
      "        \"uuid\": \"5231538c-a267-4ece-a6dd-484c57f5f1d8\",\n",
      "        \"created\": \"2024-05-06T09:31:10.078Z\",\n",
      "        \"updated\": \"2024-05-06T09:31:10.078Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"38114456\",\n",
      "            \"authors\": \"Andy M Lau, Shaun M Kandathil, David T Jones\",\n",
      "            \"journal\": \"10.1038/s41467-023-43934-4\",\n",
      "            \"title\": \"Merizo: a rapid and accurate protein domain segmentation method using invariant point attention\",\n",
      "            \"doi\": \"10.1038/s41467-023-43934-4\",\n",
      "            \"year\": \"2023\"\n",
      "        },\n",
      "        \"score\": 0.9,\n",
      "        \"matches\": {\n",
      "            \"evaluation/comparison\": \"The benchmark compares the accuracy of domain assignments by Merizo against those produced by four recently published methods including DeepDom, a CNN-based method from Eguchi et al (referred to as Eguchi-CNN), SWORD and UniDoc.\\nThey also included four baseline measures, including scoring ECOD assignments against CATH (where ECOD assignments are treated as a prediction result), and three random assignment methods prefixed with\\u2019Random\\u2019, where the domain count is estimated according to the Domain Guess by Size method.\",\n",
      "            \"evaluation/confidence\": \"Yes, confidence intervals are reported. Merizo is the most performant method on the CATH-663 set when scoring by IoU. It is followed closely by UniDoc, which has a wider distribution.\",\n",
      "            \"evaluation/measure\": \"They scored predictions based on (1) how well the residues in a predicted domain overlap with a true domain, measured via the intersect-over-union (IoU) between residues in the predicted and\\nground-truth domain, and (2) how precise the predicted domain boundaries are, when assessed using the Matthews Correlation Coefficient (MCC).\",\n",
      "            \"evaluation/method\": \"They evaluated the model on a test split which did not overlap at the CATH homologous superfamily (H) level with the training set.\\nNo mention was made of cross-validation.\",\n",
      "            \"optimization/algorithm\": \"The model is a deep neural network.\\nIt is not a novel algorithm.\",\n",
      "            \"optimization/config\": \"The model is accessible through https://github.com/psipred/Merizo\",\n",
      "            \"optimization/encoding\": \"The model takes three inputs: a single representation, pairwise representation and backbone frames. The single representation is produced by one-hot encoding the primary sequence into 20 amino acid classes and then projected into 512 feature dimensions. For the pairwise representation, authors used the pairwise distance map derived from alpha carbons, directly embedded into 32 feature dimensions as continuous values using a linear layer. Finally, the Euclidean backbone frames are calculated from each residue \\u201cframe\\u201d (N-CA-C atoms) via Gram-Schmidt orthogonalization.\",\n",
      "            \"optimization/features\": \"The model takes 3 inputs with varying feature dimensions.\",\n",
      "            \"optimization/fitting\": \"P is much larger than the number of training points. The authors devised a training-test split which did not overlap at the CATH homologous superfamily (H) level  to better gauge performance on folds that the network has not seen before.\",\n",
      "            \"optimization/meta\": \"It is not a meta-predictor.\",\n",
      "            \"optimization/parameters\": \"The model is a small encoder-decoder network with approximately 37 M parameters (20.4 M in the encoder and 16.8 M in the decoder).\",\n",
      "            \"model/availability\": \"It will be incorporated into the PSIPRED workbench at http://bioinf.cs.ucl.ac.uk/psipred/\",\n",
      "            \"model/duration\": \"Average time per target (second) on GPU: 0.112\",\n",
      "            \"model/interpretability\": \"The model is a deep neural network with 37 M parameters, rendering it a black box.\",\n",
      "            \"model/output\": \"The model has elements of both classification and regression tasks.\",\n",
      "            \"dataset/availability\": \"The code and network weights of Merizo are available at https://github.com/psipred/Merizo\",\n",
      "            \"dataset/provenance\": \"The PDB chains and domain annotations used for training were accessed from version 4.3 of the CATH database.\\nThe final training and testing set contained 17,287 and 663 chains respectively.\\nTo fine-tune the model, 7502 and 1195 AFDB-human models were used for the training and testing sets, respectively\",\n",
      "            \"dataset/redundancy\": \"Further redundancy filtering with CD-HIT39 was performed to cluster targets which had a sequence identity of greater than 99%.\",\n",
      "            \"dataset/splits\": \"The authors devised a training-test split which did not overlap at the CATH homologous superfamily (H) level  to better gauge performance on folds that the network has not seen before.\",\n",
      "            \"publication/authors\": \"Andy M Lau, Shaun M Kandathil, David T Jones\",\n",
      "            \"publication/title\": \"Merizo: a rapid and accurate protein domain segmentation method using invariant point attention\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6638a3d4b30933003cc215c5\",\n",
      "        \"shortid\": \"u122uk9z7j\",\n",
      "        \"uuid\": \"2a48fdcb-6313-45be-a84a-d0c8a9843cb5\",\n",
      "        \"created\": \"2024-05-06T09:33:08.069Z\",\n",
      "        \"updated\": \"2024-05-06T09:33:08.069Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"36420989\",\n",
      "            \"authors\": \"Manon R\\u00e9au, Nicolas Renaud, Li C. Xue, Alexandre M. J. J. Bonvin \",\n",
      "            \"journal\": \"Bioinformatics\",\n",
      "            \"title\": \"DeepRank-GNN: a graph neural network framework to learn patterns in protein\\u2013protein interfaces\",\n",
      "            \"doi\": \"10.1093/bioinformatics/btac759\",\n",
      "            \"year\": \"2023\"\n",
      "        },\n",
      "        \"score\": 0.76,\n",
      "        \"matches\": {\n",
      "            \"evaluation/comparison\": \"in both applications, the model was compared and benchmarked to other software, including their own previous model.\",\n",
      "            \"evaluation/confidence\": \"Confidence intervals are reported for AUC's.\",\n",
      "            \"evaluation/measure\": \"Area under the ROC Curve (AUC), MSE, R2, Accuracy, TP rate, and TN rate were reported in Application 1.\\nAccuracy, Specificity, Sensitivity, and Precision metrics were reported in Application 2.\",\n",
      "            \"evaluation/method\": \"Application 1: The model was trained with cross-validation on BM5 dataset and tested on CAPRI dataset.\\nApplication 2: The model was trained on MANY dataset without cross-validation, and tested on DC dataset.\",\n",
      "            \"optimization/algorithm\": \"The model is a Graph Neural Network.\\nIt is not a novel model.\",\n",
      "            \"optimization/config\": \"Available on GitHub: https://github.com/DeepRank/Deeprank-GNN\",\n",
      "            \"optimization/encoding\": \"The graph representation of a PPI is split into two sub-graphs, i.e. the internal graph connecting atoms from the same protein and the external graph connecting atoms from distinct proteins. The two sub-graphs are sequentially passed to two consecutive convolution/activation/pooling layers. The two final graph representations are flattened using the mean value of each feature and merged before applying two fully connected layers.\",\n",
      "            \"optimization/features\": \"48 features.\\nNo mention on feature selection.\",\n",
      "            \"model/availability\": \"DeepRank-GNN can be installed using PyPi package manager after installation of dependencies. The source code is available on GitHub: https://github.com/DeepRank/Deeprank-GNN\",\n",
      "            \"model/duration\": \"Average time of graph generation step per model (second) = 0,65\\nAverage scoring time per model (second) = 2,8E-02 \",\n",
      "            \"model/interpretability\": \"Due to the complexity of data pre-processing and the model itself, it appears be a black box or hardly interpretable at least.\",\n",
      "            \"model/output\": \"The model can be used in both classification and regression tasks. \",\n",
      "            \"dataset/availability\": \"All datasets are available from the SBGrid data repository https://data.sbgrid.org/dataset/843/\",\n",
      "            \"dataset/provenance\": \"4 different datasets were used in two different applications of the model, all of them obtained from other publications.\\n\\nApplication 1: scoring of docking models \\nBM5 = 3,592,600 models generated from 142 dimers using HADDOCK\\nCAPRI = 16,666 models generated from 13 protein dimers by over 40 different research teams using a variety of software\\n\\nApplication 2: binary classification of biological and crystal dimers in 50/50 proportions \\nMANY = 5739 dimers\\nDC = 161 dimers\",\n",
      "            \"dataset/redundancy\": \"The splits have been done randomly by sklearn StratifiedKFold tool in an independent way.\\nNo mention on redundancy reduction by pairwise identity.\",\n",
      "            \"dataset/splits\": \"BM5 = 10% test, 90% training and evaluation in a 10-fold cross validation that each fold is splitted 80-20 for training and evaluation, respectively.\\nCAPRI  = completely used to benchmark the trained model on BM5 with other software\\nMANY = 80-20 for training and evaluation respectively\\nDC = completely used for test purpose from the best model trained on MANY\",\n",
      "            \"publication/authors\": \"Manon R\\u00e9au, Nicolas Renaud, Li C. Xue, Alexandre M. J. J. Bonvin \",\n",
      "            \"publication/title\": \"DeepRank-GNN: a graph neural network framework to learn patterns in protein\\u2013protein interfaces\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"664234d0b30933003cc21777\",\n",
      "        \"shortid\": \"nit3xkdwep\",\n",
      "        \"uuid\": \"74d82093-c2cb-4840-8d8a-dc23995f7c82\",\n",
      "        \"created\": \"2024-05-13T15:42:08.260Z\",\n",
      "        \"updated\": \"2024-05-13T15:42:08.260Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"37204193\",\n",
      "            \"authors\": \"Yidong Song, Qianmu Yuan, Sheng Chen, Ken Chen, Yaoqi Zhou and Yuedong Yang\",\n",
      "            \"journal\": \"Briefings in Bioinformatics\",\n",
      "            \"title\": \"Fast and accurate protein intrinsic disorder prediction by using a pretrained language model\",\n",
      "            \"doi\": \"10.1093/bib/bbad173\",\n",
      "            \"year\": \"2023\"\n",
      "        },\n",
      "        \"score\": 0.9,\n",
      "        \"matches\": {\n",
      "            \"evaluation/comparison\": \"The model was compared with seven single-sequence-based methods (ESpritz-N, ESpritz-D, ESpritz-X, IUPred2A-short, IUPred2A-long and Spot-Disorder-Single) on DM1229 and SL329. \\nIn addition, it was compared to NetSurfP-3.0, which is based on ESM-1b language model. \",\n",
      "            \"evaluation/measure\": \"Authors employed the area under the receiver operating characteristic curve (AUCROC), precision (Pr), sensitivity (Se), specificity (Sp), the area under the precision-recall curve (AUCPR), Matthews correlation coefficient (MCC), and the weighted score Sw (Sw = sensitivity + specificity \\u2013 1) to evaluate the performance of the model.\",\n",
      "            \"evaluation/method\": \"Authors evaluated the model on a testing set of 1229 proteins (DM1229), in addition to four independent test datasets SL329, DisProt228,\\nMobi9230 and DisProt452.\",\n",
      "            \"optimization/algorithm\": \"The model is comprised of transformer networks and a fully connected layer (ANN).\\nIt is not a novel algorithm.\",\n",
      "            \"optimization/config\": \"The datasets, the source codes and the trained model are available on https://github.com/biomed-AI/LMDisorder.\",\n",
      "            \"optimization/encoding\": \"First, the protein sequence is inputted into the pretrained language model ProtTrans to yield the sequence embedding, which is augmented by Gaussian noise to avoid overfitting.\",\n",
      "            \"optimization/features\": \"Authors extracted the hidden states from the last layer of the ProtTrans encoder as sequence features, which is an n \\u00d7 1024 matrix (n is the sequence length).\",\n",
      "            \"optimization/fitting\": \"The exact number of total parameters not reported. To rule out overfitting, early stopping was used with validation set and additionally, a dropout rate of 0.3 was applied.\",\n",
      "            \"optimization/meta\": \"Yes, the model uses embeddings generated by unsupervised pretrained language models, namely ProtTrans (ProtT5-XL-U50) and ESM-1b.\",\n",
      "            \"optimization/parameters\": \"The number of total parameters is not explicitly stated but authors reported following parameters:\\n2-layer transformer network\\n128 hidden units\\nHyperparameters: h = 4, \\u03b5 = 0.05\\nBatch size: 12\\nDropout rate: 0.3\\nAdam optimizer with learning rate of 3 \\u00d7 10^(-4)\\nBinary cross-entropy loss function\\nImplemented with PyTorch 1.7.1\\n\\np was selected through searching all hyperparameters through a grid search.\",\n",
      "            \"optimization/regularization\": \" Yes, early stopping was used with validation set. Additionally, a dropout rate of 0.3 was applied.\",\n",
      "            \"model/availability\": \"The datasets, the source codes and the trained model are available on https://github.com/biomed-AI/LMDisorder.\",\n",
      "            \"model/duration\": \"For a protein with 500 residues it takes 1 second on an Nvidia GeForce RTX 3090 GPU.\",\n",
      "            \"model/interpretability\": \"No mention was made on interpretability. The model appears to be a black box due to its complexity.\",\n",
      "            \"model/output\": \"It is a binary classifier model.\",\n",
      "            \"dataset/availability\": \"The datasets, the source codes and the trained model are available on https://github.com/biomed-AI/LMDisorder.\",\n",
      "            \"dataset/provenance\": \"The dataset comprises 4229 protein sequences (DM4229), with 72 fully disordered chains from DisProt v5.0 and 4157 high-resolution X-ray crystallography structures from PDB.\\nAdditionally, there are also four independent test datasets: SL329, DisProt228, Mobi9230, and DisProt452,\",\n",
      "            \"dataset/redundancy\": \"The datasets were split into training, validation, and testing sets randomly.\\nTo ensure independence between training and test sets, redundancy reduction was enforced by using a sequence similarity cutoff of <25%, as determined by BLASTClust.\",\n",
      "            \"dataset/splits\": \"The training set consists of 2700 proteins, the validation set 300 proteins, and the testing set 1229 proteins (DM1229).\\nThere are also four independent test datasets: SL329, DisProt228, Mobi9230, and DisProt452.\",\n",
      "            \"publication/authors\": \"Yidong Song, Qianmu Yuan, Sheng Chen, Ken Chen, Yaoqi Zhou and Yuedong Yang\",\n",
      "            \"publication/journal\": \"Briefings in Bioinformatics\",\n",
      "            \"publication/title\": \"Fast and accurate protein intrinsic disorder prediction by using a pretrained language model\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"666ca94f37ea6fa797a6c1f9\",\n",
      "        \"shortid\": \"31tebn1dq4\",\n",
      "        \"uuid\": \"5f5a87ee-e6b1-441d-a425-0abbc75bb322\",\n",
      "        \"created\": \"2024-06-14T20:34:23.344Z\",\n",
      "        \"updated\": \"2024-06-14T20:34:23.344Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"38015968\",\n",
      "            \"authors\": \"Heidi J. Imker, Kenneth E. Schackart III, Ana-Maria Istrate & Charles E. Cook\",\n",
      "            \"journal\": \"PLOS ONE\",\n",
      "            \"title\": \"A machine learning-enabled open biodata resource inventory from the scientific literature\",\n",
      "            \"doi\": \"10.1371/journal.pone.0294812\",\n",
      "            \"year\": \"2023\"\n",
      "        },\n",
      "        \"score\": 1,\n",
      "        \"matches\": {\n",
      "            \"evaluation/availability\": \"Yes - several supplmentary files well detail the evaluation. Code: https://zenodo.org/records/10105162 / \",\n",
      "            \"evaluation/comparison\": \"Yes, a camparison to manually curated database regisrties was undertaken as deatailed in section 2.9.2 'Comparison with existing registries.' This utilised data from re3data.org and FAIRsharing regsitries using their APIs. Limitations of the benchmark datasets noted in the text.\\n\\nThis was not a simpler ML model baseline as this work was novel, but instead against manually curated datasets containing the same fields the model was extracting with NER.\\n\\nThe authors initially expected greater overlap with re3data.org and FAIRSharing, but only 536/3112 (17.2%) inventory resources were identified in these two registries; similarly, the majority of life science resources within both re3data (975/1189, 80.5%) and FAIRsharing (1161/1640, 70.8%) are not found in their inventory.\",\n",
      "            \"evaluation/confidence\": \"Confidence scores used but not confidence interval ranges. The use of the models was novel and no comparable  method was deployed in the past to draw direct comparison to these ML methods. However, manual curator validation was used as a baseline as described in text: to determine a threshold probability of < 0.978 as \\u201clow-scoring,\\u201d where 0.978 was the average probability for names determined by a curator to have been correctly predicted in the 10% random sample of the 468 articles that were manually reviewed.\",\n",
      "            \"evaluation/measure\": \"Both the perfomance of the article classification task and that of the NER task were measured to ensure best model performance.\\n\\nPre-trained BERT model selection for article classification: \\n-Performance measured to selected best BERT model for the NLP tasks. \\n-15 total evaluated and noted in table 3 (and cited)\\n-'S(upplementary)5 Table. Article classification' measures BERT model performance and documents this in relation to F1-score, Precision & Recall. \\n\\nPre-trained BERT model selection for NER model performance:\\n-Performance measured to selected best BERT model for the NER tasks.\\n-15 total evaluated and noted in table 3 (and cited)\\n-'S(upplementary)6 Table. NER model performance.' measure BERT model performance and documents this in relation to F1-score, Precision & Recall. \\n\\nMid way evaluation undertaken also to manually assess precision on a 10% random sample (n = 468) of the NER tasks. \",\n",
      "            \"evaluation/method\": \"Independent dataset used for validation. 15% of whole dataset held out to validate the model performance.\",\n",
      "            \"optimization/algorithm\": \"Two machine learning models described in the text were fine-tuned to automate the process of: \\n-1: classifying research articles \\n-2: extracting mentions of biodata resources from those predicted to describe a biodata resource\\n\\nThese were based on pre-trained BERT (Bidirectional Encoder Representations from Transformers) models.\\n\\nPre-trained BERT models leverage deep learning transformer architectures - neural networks utilised for NLP tasks. Not novel algorithm.\",\n",
      "            \"optimization/config\": \"Hyperparameters detailed in 'S4 Table. Hyperparameters used for model fine-tuning for article classification and NER tasks.' - Zenodo PDF: https://doi.org/10.1371/journal.pone.0294812.s008\",\n",
      "            \"optimization/encoding\": \"Data was preprocessed for use by the pre-trained BERT models independently by two curators. Article titles and abstracts were reviewed to classify them as either describing a biodata resource (pos) or not describing a biodata resource(neg). Text strings were tokenized for BERT models using specific BERT tokenizers described in text.\",\n",
      "            \"optimization/features\": \"Not applicable as pre-trained BERT models were used. These do not use a single set of features that you directly extract and feed into the model like traditional machine learning methods. BERT learns features based on the pre-training it was subject to. \\n\\nRelated info on tokenization described above with regards to BERT model input features during the model fine tuning and training for its two tasks NER and classification.\",\n",
      "            \"optimization/fitting\": \"Exact p and f unkown and not detailed in text due to pre-trained BERT models in used. However, the authors used early stopping, a validation set, pre-trained BERT models with cross-comparison across 15 of these, and reported good performance on unseen test data. This in total contributes to a strong likelihood that the authors effectively addressed both overfitting and underfitting concerns. \",\n",
      "            \"optimization/meta\": \"No - data is sourced from direct Europe PMC API query of data as detailed in text, and is not inputting meta-predictions to the models.\",\n",
      "            \"optimization/parameters\": \"Number of parameters (p) are used in the model?: \\n-Not directly mentioned but findable based on the BERT model types being well detailed. \\n-Pre-trained BERT models were used, so model parameters not directly detailed in text as a result but can be found from: Hugging Face Library (https://huggingface.co/docs/transformers/en/index) where you can find the number of parameters for a pre-trained model by using the model.config.num_parameters() function.\\n\\nHyperparameters detailed in 'S4 Table. Hyperparameters used for model fine-tuning for article classification and NER tasks.'\",\n",
      "            \"optimization/regularization\": \"Yes - overfitting prevention techniques were employed.  Early stopping was undertaken using a validation set. Max of 10 epochs but early stopping and use of highest precision.\",\n",
      "            \"model/availability\": \"Source code available: Yes - https://zenodo.org/records/10105162. Algorithms and models can be run using the 2x Snakemake reusable pipelines and also an iPython notebook (ipynb) file is available for use Google Colab/other notebook deployment platforms. \",\n",
      "            \"model/duration\": \"The text directly references computational need for a GPU to re-run the model training. They do not make exact/estimate statements referring to execution times but explictly state a Google Colab instance with a GPU utlising their iPython notebooks (ipynb) provided would be sufficient. This would indicate a desktop equipped with a GPU would suffice rather than there being a requirement for access to HPC resources and several GPUs. To run  \\n\\nPotentially this information is more explicitly noted in the well documented supplementary materials code release: https://zenodo.org/records/10105162.\",\n",
      "            \"model/interpretability\": \"Highly interpretable - the authors made expert efforts to avoid having a black box model publication. For example all code and data & configs, etc are all available on Zenodo repository and expertly documented for ease of interpretability: https://zenodo.org/records/10105162. All test and training data available and clear, linked from text to relevant repositories. Explicit study design noted in text to have been created with open science and reproducibility in mind.\",\n",
      "            \"model/output\": \"Classification model \",\n",
      "            \"dataset/availability\": \"Yes, all the data in the dataset that was used has been documented in the Zenodo repository. The original source literature dataset remains available in the Europe PMC database. Biodata Resource Inventory Code Release: https://zenodo.org/records/10105162\\n\\nEPMC database: https://europepmc.org/\\n\\nEPMC licensing policy: https://plus.europepmc.org/user-guide#Licensing_policies\",\n",
      "            \"dataset/provenance\": \"Data source: Europe PMC - a database for depositing life science literature was the primary data source for the study.  \\n\\nThe life science literature used was: titles and correpsonding abstracts.\\n\\nDataset community recognition: this was not an established dataset but created for the purpose of this study using a subset of literature data available in Europe PMC.\\n\\nNpos/Nneg info: the study kept the entries where two curators agreed on the article classification label \\n-Total positive or negative, n = 1,587\\n-Total positive: 478\\n-Total negative: 1,109\",\n",
      "            \"dataset/redundancy\": \"Test and training sets were independent.\\n\\nDistribution of whole data set: 70% training, 15% validation, 15% test. This aligns to general reccomended redundancy splits for ML model training, fine tuning and evaluation uses.\\n\",\n",
      "            \"dataset/splits\": \"Whole data set:\\n1634 literature records total. This was reduced to 1,587 (data points were kept from origianl 1,634 where 2x curators agreed on classification of pos/neg)\\nThese were dsitributed into: 70% training, 15% validation, 15% test (hold-out).\\n\\nData points - breakdown of the initial 1,587 items of literature data collected:\\n-Training set: 1,110 data points\\n-Test set: 239 data points (+ 238 validation data points)\\n\\nWas a separate validation set used, and if yes, how large was it?: yes, validation set used = 238 data points\\n\\nAre the distributions of data types in both training and test sets plotted?: no - but data cleaning done through curator validation on all npos/nneg idenitfied.\\n\\nThe above information on the data splits can be viewed in an overview table in the paper: Table 1. Training dataset splits for the article classification task - https://doi.org/10.1371/journal.pone.0294812.t001\",\n",
      "            \"publication/authors\": \"Heidi J. Imker, Kenneth E. Schackart III, Ana-Maria Istrate & Charles E. Cook\",\n",
      "            \"publication/journal\": \"PLOS ONE\",\n",
      "            \"publication/title\": \"A machine learning-enabled open biodata resource inventory from the scientific literature\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"666f4a9e37ea6fa797a6c20d\",\n",
      "        \"shortid\": \"hipgaatgji\",\n",
      "        \"uuid\": \"e9d0a4a1-31d9-4782-937b-885197f55f14\",\n",
      "        \"created\": \"2024-06-16T20:27:10.713Z\",\n",
      "        \"updated\": \"2024-06-16T20:27:10.713Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"37126495\",\n",
      "            \"authors\": \"Olga Mineeva, Daniel Danciu, Bernhard Sch\\u00f6lkopf, Ruth E. Ley, Gunnar R\\u00e4tsch, and Nicholas D. Youngblut\",\n",
      "            \"journal\": \"PLOS Computational Biology\",\n",
      "            \"title\": \"ResMiCo: Increasing the quality of metagenome-assembled genomes with deep learning\",\n",
      "            \"doi\": \"https://doi.org/10.1371/journal.pcbi.1011001\",\n",
      "            \"year\": \"2023\"\n",
      "        },\n",
      "        \"score\": 0.95,\n",
      "        \"matches\": {\n",
      "            \"evaluation/availability\": \"Large degree of the evaluation is noted throughout the text & figures or in S1 - Supplementary Material ResMiCo: increasing the quality of metagenome-assembled genomes with deep learning (https://journals.plos.org/ploscompbiol/article/file?type=supplementary&id=10.1371/journal.pcbi.1011001.s001). Statistical code for evaluation not clearly avaialble linked from text or within shared GitHub repository.\",\n",
      "            \"evaluation/comparison\": \"The model was compared to other state of the art models for this prediction task:\\n-metaMIC  \\n-DeepMAsED  \\n-ALE \\n\\nThe model was also compared to various benchmark datasets:\\n-CAMI datasets (gut, oral, skin)\\n-Mock communities (BMock12, MBARC-26)\",\n",
      "            \"evaluation/confidence\": \"Confidence intervals are not explictly mentioned in the text. If taking the other models as the baseline for camparison the reported AUPRC & AUROC are noted to outperform these throughout the text. More information for the confidence would be useful beyond comparisons already noted for the datasets and other models.\",\n",
      "            \"evaluation/measure\": \"Various model performances measure metrics were reported in the text eg:\\n-Area Under the Precision-Recall Curve (AUPRC)\\n-Area Under the ROC Curve (AUROC)\\n-Precision and Recall\",\n",
      "            \"evaluation/method\": \"Independent datasets were used to evalaute the model. \\nFor example the text notes that two CAMI datasets that simulate non-human biomes: CAMI-marine and CAMI-plant-associated were used to evaluate the model and corresponding AUPRC & AUROC shared.\",\n",
      "            \"optimization/algorithm\": \"Deep Residual Neural Network (ResNet) \\n-Not a new algorithm \",\n",
      "            \"optimization/config\": \"The list of optimised hyperparameters and the attempted values are provided in Table B in S1 Text. (https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011001#pcbi.1011001.s001). Unclear if further information available and this is unlikely based on the GitHub which is functionally in place to share reuse of the model vs considerations of sharing precise configuration information.  \",\n",
      "            \"optimization/encoding\": \"Data encoding (0-1) detailed in supplemetary data 'Table A. The full list of positional features computed by ResMiCo pipeline'. The fifth column states preprocessing applied to the features of the table as used for the data encoding for the model: standardisation (Std), normalisation (Nrm), and one-hot encoding (Onh).\",\n",
      "            \"optimization/features\": \"14 features as noted in 'Fig 3. Feature ranked by their importance.'.\\n\\nFeature selection was performed and noted in a dedicated paper subsection. \",\n",
      "            \"optimization/fitting\": \"Yes, p much larger than number of training points. Trainable Parameters (559,441) vs. Features (14).\",\n",
      "            \"optimization/parameters\": \"ResMiCo model has 562,573 parameters, of which 559,441 are trainable.\",\n",
      "            \"optimization/regularization\": \"Early stopping likely used based on text information but not explicitly written in the text. Class imbalance handling and data augmentation approaches also noted in the text which can help prevent overfitting a model.\",\n",
      "            \"model/availability\": \"Main ResMiCo GitHub (python package and snakemake pipeline): https://github.com/leylabmpi/ResMiCo - MIT license. Dataset simulation pipeline used available in Snakemake: https://doi.org/10.1093/bioinformatics/bts480 . Dockerfiles noted in the repo but no VMs/web server. Direct pip install possible from a command line and information in GitHub software repo but limitations noted for incompatibility with apple Mac machines due to chipset.  \",\n",
      "            \"model/duration\": \"There is a section dedicated to benchmarking the ResMiCo model resource requirements in the materials and methods.\\n-Using the CAMI gut dataset, ResMiCo ran > 2x faster with a GPU versus a CPU (108 \\u00b1 0.7 versus 38.7 \\u00b1 10.3 contigs per second).\\n-They further note the reccomendation to use multiple GPUs for training the model on larger datasets.\\n-While it is feasible to run the model with a CPU, this is at a much slower rate: 140,000 contigs in 1 hour with a single CPU.\",\n",
      "            \"model/interpretability\": \"Moderately interpretable. GitHub available with model code & datasets hosted online. Important info detailed in paper but not precisely straight forward on all aspects. Tutorials available which are helpful to reuse the model: https://github.com/leylabmpi/ResMiCo/wiki/ResMiCo-SM-tutorial. However, this is a lightweight tutorial page and more information could be provided given the complex nature of the model used. More clarity around the large number of datasets mentioned in the evaluation would be helpful.\",\n",
      "            \"dataset/availability\": \"Yes - data available: http://ftp.tue.mpg.de/ebio/projects/ResMiCo/\\nThis is on the: MPI for Biology FTP server, author noted choice due to size of datasets.\",\n",
      "            \"dataset/provenance\": \"An existing database was the primary source of the data - Release 202 of the Genome Taxonomy Database (GTDB).\\n-18,000 reference genomes from the database were selected for further use.\\n-From this database the authors created a synthetic dataset comprised of bacterial and archaeal genomes with the simulation software 'Metagenome read simulation of multiple synthetic communities' (https://github.com/nick-youngblut/MGSIM).\\n-Illumina ART read simulator was used to generate paired-end Illumina reads of length 100 or 150 using either the default \\u201cIllumina HiSeq 2500\\u201d error profile or the \\u201cHiSeq2500L150R1/2\\u201d error profile used in CAMISIM.\\n-Information detailed with parameters of the simulation in 'Table 1. Parameter values used in the simulation pipeline.'\",\n",
      "            \"dataset/redundancy\": \"The sets were split from the original 18,000 using a family taxonomic level split to divide these into training and test.\\n\\nFor redundancy reduction, max 50 genomes per species were included to avoid overfitting.\\n\\nRandom genome selection was used to divide the test and training in alignment with the 50 genomes max per species. \\n\\n\",\n",
      "            \"dataset/splits\": \"18,000 total reference genomes selected from GTDB. Of these:\\n-Test: 9000 reference genomes used \\n-Training: 9000 reference genomes used\\n\\n10% of the training dataset was used as a validation set for the model selection.\",\n",
      "            \"publication/authors\": \"Olga Mineeva, Daniel Danciu, Bernhard Sch\\u00f6lkopf, Ruth E. Ley, Gunnar R\\u00e4tsch, and Nicholas D. Youngblut\",\n",
      "            \"publication/journal\": \"PLOS Computational Biology\",\n",
      "            \"publication/title\": \"ResMiCo: Increasing the quality of metagenome-assembled genomes with deep learning\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6670865737ea6fa797a6c28a\",\n",
      "        \"shortid\": \"3cfsqm95ys\",\n",
      "        \"uuid\": \"3badf5a7-cfb0-4138-813b-299c482e3bf4\",\n",
      "        \"created\": \"2024-06-17T18:54:15.621Z\",\n",
      "        \"updated\": \"2024-06-17T18:54:15.621Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"37971967\",\n",
      "            \"authors\": \"Ananthan Nambiar, Veronika Dubinkina, Simon Liu, and Sergei Maslov\",\n",
      "            \"journal\": \"PLOS Computational Biology\",\n",
      "            \"title\": \"FUN-PROSE: A deep learning approach to predict condition-specific gene expression in fungi\",\n",
      "            \"doi\": \"10.1371/journal.pcbi.1011563\",\n",
      "            \"year\": \"2023\"\n",
      "        },\n",
      "        \"score\": 0.9,\n",
      "        \"matches\": {\n",
      "            \"evaluation/availability\": \"Not available based on text, evaluation not heavily focused on in text.\",\n",
      "            \"evaluation/comparison\": \"The evaluation of the model performance seems to be against that of the 3x distinct datasets used for the study to create the model.\\n-S. cerevisiae dataset (noted under data section)\\n-N. crassa dataset (noted under data section)\\n-I. orientalis dataset (noted under data section)\\n\\nNo other models cross compared or simpler baseline to evaluate the model. Poorly described evaluation.\",\n",
      "            \"evaluation/measure\": \"Pearson correlation coefficient reported for model use across the 3x datasets used:\\n-0.85 for S. cerevisiae\\n-0.72 for N. crassa\\n-0.81 for I. orientalis\\n\\nNot many other performance measures in the text/supplementary files. \",\n",
      "            \"evaluation/method\": \"Independent data sets used to evaluate FUN-PROSE model.\\n\\nThe authors noted use of several previously published RNA-seq datasets for different fungal species to evaluate the model. Although, this is contradictory as it seems these 3x datasets were used to create the model in the first place. Somewhat unclear the barriers between create the model and datasets used to evaluate the model.\",\n",
      "            \"optimization/algorithm\": \"Convolutional neural network (CNN) - not a new algorithm.\\n-Composed of two convolutional layers\",\n",
      "            \"optimization/config\": \"Hyperparameters described directly in a subsection of the paper: 'Hyperparameter optimization and model training'. This does not have exact hyperparameter configurations, optimization schedule, model files, and optimization parameters reported. However, certain GitHub files in the code repo seem to contain further hyperparameter information such as 'hyperparameter-search.py' (https://github.com/maslov-group/FUN-PROSE/blob/main/hyperparameter-search.py) \",\n",
      "            \"optimization/encoding\": \"Data sources and preprocessing subsection includes info on the utisation of log-transformed RNA-seq expression levels and also the use of one-hot encoded promoter sequences later in other sections.\",\n",
      "            \"optimization/features\": \"Not explicitly noted in the text.\\n\\n256 convolutional filters noted, therefore likely hundreds/thousands of features in the model as there is potential for multiple features to be extracted per filter.\",\n",
      "            \"optimization/fitting\": \"Fitting poorly described. Unknown parameters vs features from text - cannot determine exact figures for these. Fitting not touched on in the text at all. Only comparisons of pearson correlations across use in different datasets.\",\n",
      "            \"optimization/parameters\": \"Specific CNN layer parameters are noted to be described in table 1 - but primarily hyperparameters instead are actually in the table.\\n-Titled 'Table 1.  Configuration search space for hyperparameter optimization and best hyperparameters identified in the space.'\\n-Parameters of the model partially described and it does not seem as if the weights/biases etc are included in one of the many figures/tables clearly. Cannot determine accurate number from text or their selection. \",\n",
      "            \"optimization/regularization\": \"Early stopping was performed: 60 epochs and training was stopped early if the validation correlation coefficient did not improve for 5 epochs in a row.\",\n",
      "            \"model/availability\": \"GitHub repository: https://github.com/maslov-group/FUN-PROSE. Primarily in python and jupyter notebooks. No containers present in the repo or other run method support/variations. \",\n",
      "            \"model/duration\": \"Text notes models were trained on an NVIDIA V100 GPU with 16GB of RAM using automatic mixed-precision training. \\nAlso further notes that there was model training on a NVIDIA GeForce GTX 1080 Ti GPU.\\n\\nExecution time metrics not stated in text.\",\n",
      "            \"model/interpretability\": \"Not very interpretable - comes across as a black box from the text and formatting. The datasets used are confusing and poorly described eg: hosted in Google drive, and from cited publications. Three different fungi species were used for creating the model and not very accessible without combing trhough the text to understand the underlying RNA-seq data within each of these or their splits/data points. No clear tables to detail the splits of test/training/validation although some percents provided. Almost 20 figures in the paper when including supplementary data and very divided information points across the whole paper.  Parameters and features of the model poorly described and very little info on the fitting/evalution of the model.\",\n",
      "            \"dataset/availability\": \"Preprocessed data linked in a Google drive: https://drive.google.com/drive/folders/19K5DxFVpjozpd1rKnBvZZzDmnPp1-Ldw & also off of the main GitHub (https://github.com/maslov-group/FUN-PROSE/blob/main/README.md).\",\n",
      "            \"dataset/provenance\": \"3x RNA-seq datasets used:\\n1. RNA-seq data on N. crassa (wild type and gene-deletion mutants) growing on different carbon sources [44]\\n2. S. cerevisiae RNA-seq data for 28 analog sensitive kinase alleles across 12 different conditions (stresses and different media) [45]\\n3. I. orientalis RNA-seq data for growth in different media conditions (YPD+glucose and lignocellulosic extracts) [45]\\n\\nCorresponding datasets from publications cited in the text:\\n[44.] Wu VW, Thieme N, Huberman LB, Dietschmann A, Kowbel DJ, Lee J, et al. The regulatory and transcriptional landscape associated with carbon utilization in a filamentous fungus. Proceedings of the National Academy of Sciences. 2020;117(11):6003\\u20136013.\\n\\n[45.] Mace K, Krakowiak J, El-Samad H, Pincus D. Multi-kinase control of environmental stress responsive transcription. PloS one. 2020;15(3):e0230246. pmid:32160258\\nView ArticlePubMed/NCBIGoogle Scholar\",\n",
      "            \"dataset/redundancy\": \"Gene condition splits for each of the 3x different data sets corresponding to each of the fungi species are noted as:\\n-70 % training\\n-10% validation \\n-20% test  \\n\\nModel seems to have been trained on each of the 3x corresponding data sets which contains RNA-seq expression data under different conditions. \",\n",
      "            \"dataset/splits\": \"Three different datasets divided into train/test set splits for use in creating the model, each described in supplementary figures 1-3:\\n1. S1 Fig. Vizualizing the Saccharomyces cerevisiae dataset.\\n2. S2 Fig. Vizualizing the Neurospora crassa dataset.\\n3. S3 Fig. Vizualizing the Issatchenkia orientalis dataset.\\n\\nAuthor's first split the gene-condition data into train, validation and test sets by randomly withholding 10% of the elements for the validation set and 20% for the test set.\\n\\nDifficult to discern exact training and test set data points from the text and figures relating to the publication. It appears that relating to each dataset there are:\\nS. cerevisiae = 6645 genes\\nN. crassa = 9725 genes\\nI. orientalis = 4925 genes \\nHowever, it is not very clear.\",\n",
      "            \"publication/authors\": \"Ananthan Nambiar, Veronika Dubinkina, Simon Liu, and Sergei Maslov\",\n",
      "            \"publication/journal\": \"PLOS Computational Biology\",\n",
      "            \"publication/title\": \"FUN-PROSE: A deep learning approach to predict condition-specific gene expression in fungi\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e363261d57eb8bca695a3\",\n",
      "        \"shortid\": \"bgldxl71jp\",\n",
      "        \"uuid\": \"8ac43578-356a-49dc-a0a1-f2bfd3a887e0\",\n",
      "        \"created\": \"2024-10-15T09:30:26.463Z\",\n",
      "        \"updated\": \"2024-10-15T09:30:26.463Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"title\": \"MuLan-Methyl\\u2014multiple transformer-based language models for accurate DNA methylation prediction\",\n",
      "            \"authors\": \"Wenhuan Zeng, Anupam Gautam, Daniel H Huson\",\n",
      "            \"journal\": \"GigaScience\",\n",
      "            \"year\": \"2023\",\n",
      "            \"pmid\": \"37489753\",\n",
      "            \"doi\": \"https://doi.org/10.1093/gigascience/giad054\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 6\n",
      "        },\n",
      "        \"score\": 0.78,\n",
      "        \"matches\": {\n",
      "            \"evaluation/method\": \"We evaluated MuLan-Methyl on the iDNA-MS independent test dataset.\",\n",
      "            \"evaluation/measure\": \"MuLan-Methyl is evaluated by the following evaluation metrics: AUC, Accuracy, F1-score, Recall, and AUPR.\\n\",\n",
      "            \"evaluation/comparison\": \"Yes, MuLan-Methyl is compared with iDNA-ABF and iDNA-ABT on the iDNA-MS independent dataset, MuLan-Methyl outperforms 13 out of 17 sub-dataset.\",\n",
      "            \"evaluation/confidence\": \"Performance metrics of our study doesn't have confidence intervals.\",\n",
      "            \"evaluation/availability\": \"Yes, it's available in the MuLan-Methyl manuscript and its supplementary files.\",\n",
      "            \"optimization/algorithm\": \"MuLan-Methyl is an ensemble framework consists of five transformer-based language models.\\n\",\n",
      "            \"optimization/meta\": \"The model doesn't use data from other ML algorithms as input.\",\n",
      "            \"optimization/config\": \"Yes, all the hyper-parameters are reported in MuLan-Methyl manuscript and its corresponding Github repository(https://github.com/husonlab/mulan-methyl).\",\n",
      "            \"optimization/encoding\": \"The input of MuLan-Methyl is processed by converting each sample' DNA sequences and its taxonomic lineages into a description. Each processed sample is further encoded by tokenizer of each language models.\",\n",
      "            \"optimization/features\": \"Two features of each sample are used as input, one is sample's DNA sequence, another is its taxonomic lineage. No feature selection is performed.\",\n",
      "            \"optimization/fitting\": \"p is much larger than f, Overfitting is ruled out since the loss value of both training process and validation process has similar changing trends.\",\n",
      "            \"optimization/parameters\": \"Here is the models' parameter:\\nModel Number of parameters\\nMuLan-Methyl-BERT 105,242,882\\nMuLan-Methyl-DistilBERT 62,714,114\\nMuLan-Methyl-ALBERT 11,045,122\\nMuLan-Methyl-XLNet 111,934,466\\nMuLan-Methyl-ELECTRA 29,336,578\",\n",
      "            \"optimization/regularization\": \"Yes, early stopping on validation dataset is conducted for preventing overfitting.\",\n",
      "            \"model/interpretability\": \"MuLan-Methyl is interpretable by utilizing the self-attention mechanism of transformer architecture. For example, attention score assigned to each tokens of each sample which predicted positive are used to discover methylation motifs.\",\n",
      "            \"model/output\": \"It's classification model.\",\n",
      "            \"model/duration\": \"In average one second.\",\n",
      "            \"model/availability\": \"The source code is released (https://github.com/husonlab/mulan-methyl). A web server implementing the MuLan-Methyl approach is freely accessible at http://ab.cs.uni-tuebingen.de/software/mulan-methyl/.\",\n",
      "            \"dataset/provenance\": \"Data source: iDNA-MS (Lv, Hao, et al. \\\"iDNA-MS: an integrated computational tool for detecting DNA modification sites in multiple genomes.\\\" Iscience 23.4 (2020): 100991.)\\nData are in classes,the data statistics for positive samples and negative samples in both training dataset and test dataset can be found in supplementary file of published paper.\\n\",\n",
      "            \"dataset/splits\": \"The ratio of training and test set is 1:1.\\nValidation set is generated by sampling 20% training dataset.\\nThe distribution of data types in the training and test sets is same.\",\n",
      "            \"dataset/redundancy\": \"The training and test set are split by iDNA-MS, they are independent.\\n\",\n",
      "            \"dataset/availability\": \"Data are public, can be obtained from iDNA-MS(http://lin-group.cn/server/iDNA-MS/), as well as MuLan-Methyl(https://github.com/husonlab/mulan-methyl).\",\n",
      "            \"publication/title\": \"MuLan-Methyl\\u2014multiple transformer-based language models for accurate DNA methylation prediction\",\n",
      "            \"publication/authors\": \"Wenhuan Zeng, Anupam Gautam, Daniel H Huson\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e389461d57eb8bca695c1\",\n",
      "        \"shortid\": \"zg83kd0vmv\",\n",
      "        \"uuid\": \"3cd05870-401b-496e-9b88-edc18d906026\",\n",
      "        \"created\": \"2024-10-15T09:40:36.120Z\",\n",
      "        \"updated\": \"2024-10-15T09:40:36.120Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"title\": \"KGML-xDTD: a knowledge graph\\u2013based machine learning framework for drug treatment prediction and mechanism description \",\n",
      "            \"authors\": \"Chunyu Ma, Zhihan Zhou, Han Liu, David Koslicki\",\n",
      "            \"journal\": \"GigaScience\",\n",
      "            \"year\": \"2023\",\n",
      "            \"pmid\": \"37602759\",\n",
      "            \"doi\": \"10.1093/gigascience/giad057\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 6\n",
      "        },\n",
      "        \"score\": 0.78,\n",
      "        \"matches\": {\n",
      "            \"evaluation/method\": \"The model is evaluated based on an independent test set.\",\n",
      "            \"evaluation/measure\": \"The accuracy, Macro F1 score, MRR, Hit@K are reported as performance metrics, They are all common evaluation metrics used for the goal of drug repurposing prediction based on the biomedical knowledge graph.\",\n",
      "            \"evaluation/comparison\": \"The KGML-xDTD has been compared with the comprehensive start-of-the-art ML/DL models based on the same dataset we collected from four public datasets mentioned in the Data Chapter.\",\n",
      "            \"evaluation/confidence\": \"For the ranking metrics (e.g., MRR and Hit@K), we generate 10 sets of random drug-disease pairs (each with 1,000 pairs) independently and calculate the mean and standard deviation of the ranking-based metrics outcomes, which are superior to other baselines. \",\n",
      "            \"evaluation/availability\": \"If you follow the evaluation instruction on Github: https://github.com/chunyuma/KGML-xDTD, you can easily reproduce the evaluation results reported in the paper.\",\n",
      "            \"optimization/algorithm\": \"The KGML-xDTD model framework of two modules: a drug repurposing prediction (DRP) module that combines the advantages of GraphSAGE and a Random Forest model, and a Mechanism of Action (MOA) prediction module that utilizes an adversarial actor-critic reinforcement learning (RL) model. \\n\\nThis model framework combines the existing start-of-the-art models with the biologically meaningful \\\"demonstration paths\\\", and achieves better performance than the known alternatives.\",\n",
      "            \"optimization/meta\": \"No, the model uses the training data that are collected by ourselves. The training data is independent of the test data.\",\n",
      "            \"optimization/config\": \"Yes, they are reported in the supplemenatary material in the paper.\",\n",
      "            \"optimization/encoding\": \"Each node in the biomedical knowledge graph is encoded into 512 numeric embedding through the PubMedBERT model and GraphSage. For each drug-disease pair, their embeddings are concatenated and used as input for a Random Forest model to predict drug repurposing.\",\n",
      "            \"optimization/features\": \"The knowledge graph node features are generated via the PubMedBERT model and GraphSage. The dimension of each node feature embedding is 512. There is no manual feature selection needed for this case. The random forest model selects the features by itself. Yes, the model selection via random forest is performed using the training set only.\",\n",
      "            \"optimization/fitting\": \"The training data is larger than p but the underfitting problem was ruled out via the setting of using maximum depth of 35 and the number of tress of 200 in the random forest.\",\n",
      "            \"optimization/parameters\": \"There are 9 hyper-parameters used in unsupervised GraphSAGE embedding training which are selected manually while 2 hyper-parameters are used in the random forest which are selected via grid search algorithm.  The remaining hyper-parameters are set to default values.\",\n",
      "            \"optimization/regularization\": \"There are a few overfitting prevention techniques used in the KGML-xDTD model which includes subsampling and feature selection by the random forest model, early stopping using a validation set in the reinforcement learning model.\",\n",
      "            \"model/interpretability\": \"The model itself is a black box but we utilize a novel knowledge-graph path-based method to explain the drug repurposing prediction result.\",\n",
      "            \"model/output\": \"The model is classification.\",\n",
      "            \"model/duration\": \"A single representative prediction ran on a desktop PC needs only 409 ms.\",\n",
      "            \"model/availability\": \"Yes, the source code released on Github: https://github.com/chunyuma/KGML-xDTD with the MIT license. Please follow the instruction on the GitHub to download and run the executable model.\",\n",
      "            \"dataset/provenance\": \"The data (drug-disease pairs) used for training our KGML-xDTD model were collected from four high-quality and NLP-derived data sources: MyChem Data, SemMedDB Data, NDF-RT Data, and RepoDB Data. All of these are public datasets; please see a more detailed description in our paper \\\"KGML-xDTD: A Knowledge Graph-based Machine Learning Framework for Drug Treatment Prediction and Mechanism Description\\\".\\n\\nThe data are categorized into classes, with 21,437 positive cases and 33,189 negative cases.\\n\\nThe data are in classes\\n  \",\n",
      "            \"dataset/splits\": \"They are 26,552 negative cases and 17,149 positive cases in the training set.\\nThere are 3,318 negative cases and 2,143 positive cases in the validation set.\\nThere are 3,319 negative cases and 2,145 positive cases in the validation set.\\n\\nThe drug class distribution in the training set and test set are similar. We plotted their distribution in Figure 7. in the paper.\",\n",
      "            \"dataset/redundancy\": \"We split the data into training, validation, and test sets where the drug-disease pairs of each unique drug are randomly split according to a ratio of 8:1:1. For example, let\\u2019s say drugA has 10 known diseases that it treats (e.g., drugA-disease1, . . . , drugA-disease10), 8 pairs are randomly split into the training set, 1 pair is to the validation set, 1 pair to the test set. \\n\\nThe drug-disease pairs in the training set and test set are independent, with no overlap. \\n\\nThere is no such drug class distribution analysis reported in the previous dataset that is similar to ours.\\n\\n\\n\",\n",
      "            \"dataset/availability\": \"These data are released in the Zenodo public repository: https://zenodo.org/record/7582233 with a license CC0 1.0.\",\n",
      "            \"publication/title\": \"KGML-xDTD: a knowledge graph\\u2013based machine learning framework for drug treatment prediction and mechanism description \",\n",
      "            \"publication/authors\": \"Chunyu Ma, Zhihan Zhou, Han Liu, David Koslicki\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e39e161d57eb8bca695c5\",\n",
      "        \"shortid\": \"1scfw6g7s4\",\n",
      "        \"uuid\": \"4a182f3e-96e9-4a16-9429-878ae0565956\",\n",
      "        \"created\": \"2024-10-15T09:46:09.031Z\",\n",
      "        \"updated\": \"2024-10-15T09:46:09.031Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"title\": \"Confound-leakage: confound removal in machine learning leads to leakage\",\n",
      "            \"authors\": \"Sami Hamdan, Bradley C Love, Georg G von Polier, Susanne Weis, Holger Schwender, Simon B Eickhoff, Kaustubh R Patil\",\n",
      "            \"journal\": \"GigaScience\",\n",
      "            \"year\": \"2023\",\n",
      "            \"pmid\": \"37776368\",\n",
      "            \"doi\": \"10.1093/gigascience/giad071\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 6\n",
      "        },\n",
      "        \"score\": 0.78,\n",
      "        \"matches\": {\n",
      "            \"evaluation/method\": \"We employed nested cross validation scheme. Train/test split (or simulating new out-of-sample data) was performed only in simulated data or examples and was used to aid understanding of the concepts and results presented in the paper.\",\n",
      "            \"evaluation/measure\": \"We report predictive r\\u00b2 for regression tasks and AUCROC for classification tasks. They are representative of what is common and reommended in the literature.\",\n",
      "            \"evaluation/comparison\": \"We compare the performance of each ML algorithm with and without confound removal. We do not make any claims of performing better on the data than other algorithms. Still, we included a baseline model (dummy classifier/regressor) to evaluate performance not informed by the feature target relationship.\",\n",
      "            \"evaluation/confidence\": \"We report statistically meaningful results using the Bayesian ROPE approach. We also add standard deviations over repeats which could convey similar information as confidence intervals.\",\n",
      "            \"evaluation/availability\": \"The code is available here: https://github.com/juaml/ConfoundLeakage under GNU Affero General Public License v3.0\",\n",
      "            \"optimization/algorithm\": \"We only used the following standard ML algorithms. \\n1) Linear/Logistic Regression \\n2) Support Vector Machine with RBF kernel\\n3) Support Vector Machine with linear kernel\\n4) Decision Tree\\n5) Random Forests\\n6) Multi Layer Perceptron\\n7) Dummy/Baseline Model\\n\",\n",
      "            \"optimization/meta\": \"The input to our models is only the available features and no meta-predictions were used.\",\n",
      "            \"optimization/config\": \"URL: https://github.com/juaml/ConfoundLeakage/blob/main/leakconfound/leakconfound/experiments/helper_func.py. License: GNU Affero General Public License v3.0\",\n",
      "            \"optimization/encoding\": \"Categorical features were one-hot encoded.  All continuous features were z-score standardized. Depending on the experimental condition we performed confound removal using confound regression with or without shuffling the features. All preprocessing steps were cross-validation consistent to avoid any data leakage.\",\n",
      "            \"optimization/features\": \"No feature selection was used. \\nFor the restricted data we followed instructions given by von Polier to follow best practices described in von Polier et al. 2021.\\nList of Feature numbers:\\n1) Income (Adult) f=14\\n2) Bank Marketing f=20\\n3) Heart f=13\\n4) Blood Transfusion f=4\\n5) Breast Cancer f=10\\n6) Student Performance f=30\\n7) Abalone  f=8\\n8) Concrete Compressive Strength f=8\\n9) Residential Building f=107\\n10) Real Estate f=6\\n11) real-world clinical dataset f=616\",\n",
      "            \"optimization/fitting\": \"We observe the same behavior for different datasets with different n/p reatios. Only the real world clinical dataset had p>n. Still we observe the same behaviour over different models as in the other datasets. We explicitly focused in CV for generalization estimates and did not analyse over- or under-fitting.\",\n",
      "            \"optimization/parameters\": \"The parameters of the models were according the corresponding model class as defined in sci-kit learn library.\\nThe hyperparameters were selected using a grid-search within a nested cross-validation scheme. \\nHere is a list of hyperparameters to chose from given the used ML algorithm: \\n1) Logistic Regression : max_iter=100000, c=np.geomspace(1e-2, 1e2, 25)\\n2) RBF Support Vector Machine : c=np.geomspace(1e-2, 1e2, 25)\\n3) Linear Support Vector Machine:c=np.geomspace(1e-2, 1e2, 25), max_iter = 1000\\n4) Decision Tree: None\\n5) Random Forest : n_estimators=500\\n6) Multi Layered Perceptron : hidden_layer_size= [[32], [64], [128], [256]] (max_iter = 100000 for classification)\\n7) Dummy/Baseline Model: strategy='mean' for regression and strategy='prior' for classification\",\n",
      "            \"optimization/regularization\": \"As we used nested cross-validation we can rule out overoptimistic final results with a reasonable confidence. \",\n",
      "            \"model/interpretability\": \"The models used were all standatd models with some degree of interpretability, e.g. we visualized decision trees in Figure 1 and 3. Furthermore, we looked into feature importance of a random forest model in Figure 4.\",\n",
      "            \"model/output\": \"We used both classification and regression given the different datasets.\",\n",
      "            \"model/duration\": \"Prediction on new data takes less than a second on a standard deskop PC.\",\n",
      "            \"model/availability\": \"The code is available under the GNU Affero General Public License v3.0 on GitHub: https://github.com/juaml/ConfoundLeakage\",\n",
      "            \"dataset/provenance\": \"We used two sources of data: I) The widely used and recognized UCI Machine Learning Repository, and II) a real-world clinical dataset. \\nI) UCI data: For classification dataset we subsampled the data to have balanced classes (the corresponding n after subsampling shown in parenthesis) :\\n1) Income (Adult) n=32561 (15682,  equal Npos and Nneg)\\n2) Bank Marketing n=41188 (9280,  equal Npos and Nneg)\\n3) Heart n=297 (274,  equal Npos and Nneg)\\n4) Blood Transfusion n=748 (356,  equal Npos and Nneg)\\n5) Breast Cancer n=569 (424,  equal Npos and Nneg)\\n6) Student Performance n=649 | used for regression\\n7) Abalone n=4177 | used for regression\\n8) Concrete Compressive Strength n=1030 | used for regression\\n9) Residential Building n=372 | used for regression\\n10) Real Estate n=414 | used for regression\\n\\nII) real-world clinical dataset is restricted, but was already used by von Polier at al. 2021\\nn=1045 (126, equal Npos and Nneg)\",\n",
      "            \"dataset/splits\": \"All data splits for the main analyses were performed using repeated k-fold cross-validation (k=5, repeats=10). In case of classification we used a stratified folds to preserve distributions of the data in training and test sets. If hyperparameter tuning was needed, we uses a nested cross-validation with the outer loop used for model assessment as described above and an inner 5-fold CV was used for model selection. We did not plot each of these distributions for our 11 datasets.\",\n",
      "            \"dataset/redundancy\": \"As we used a (nested) cross-validation and thus the training and test sets are independent of each other. To account for the dependence structure across CV repeats when comparing CV outcomes of two ML models, we used the Bayesian ROPE approach which is specifically designed for this purpose.  \",\n",
      "            \"dataset/availability\": \"All UCI datasets are available via https://archive.ics.uci.edu/. \\nWe also provide a clear instruction together with our supporting material such as code on the following GitHub repository: https://github.com/juaml/ConfoundLeakage/tree/main.\\nThe clinical data can be obtained upon request from the original authors as described in the supporting material.\\nOur repo uses the GNU Affero General Public License v3.0. \\n\\nThe sensitive real-world clinical dataset is restricted and can only be requesting it from PeakProfiling GmbH with certain restrictions. See paper for more details.\",\n",
      "            \"publication/title\": \"Confound-leakage: confound removal in machine learning leads to leakage\",\n",
      "            \"publication/authors\": \"Sami Hamdan, Bradley C Love, Georg G von Polier, Susanne Weis, Holger Schwender, Simon B Eickhoff, Kaustubh R Patil\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e3b6e61d57eb8bca695c9\",\n",
      "        \"shortid\": \"d9uiis9a39\",\n",
      "        \"uuid\": \"127575b1-dda0-4c00-9f22-520eb402fc63\",\n",
      "        \"created\": \"2024-10-15T09:52:46.103Z\",\n",
      "        \"updated\": \"2024-10-15T09:52:46.103Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"title\": \"SpheroScan: a user-friendly deep learning tool for spheroid image analysis\",\n",
      "            \"authors\": \"Akshay Akshay, Mitali Katoch, Masoud Abedi, Navid Shekarchizadeh, Mustafa Besic, Fiona C Burkhard, Alex Bigger-Allen, Rosalyn M Adam, Katia Monastyrskaya, Ali Hashemi Gheinani\",\n",
      "            \"journal\": \"GigaScience\",\n",
      "            \"year\": \"2023\",\n",
      "            \"pmid\": \"37889008\",\n",
      "            \"doi\": \"10.1093/gigascience/giad082\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 6\n",
      "        },\n",
      "        \"score\": 0.63,\n",
      "        \"matches\": {\n",
      "            \"evaluation/method\": \"The evaluation method employed for Mask R-CNN involved assessing the model's performance based on object detection accuracy and instance segmentation quality using Intersection over Union (IoU).\",\n",
      "            \"evaluation/measure\": \"To evaluate the performance of the trained models on spheroid segmentation, we used the Average Precision (AP) evaluation metric. \",\n",
      "            \"optimization/algorithm\": \"For spheroid detection and segmentation, we employed a state-of-the-art deep learning model known as Mask Regions with Convolutional Neural Networks (R-CNN).\",\n",
      "            \"optimization/meta\": \"No, our model does not utilize data from other algorithms.\",\n",
      "            \"optimization/config\": \"In this study, we used the Mask R-CNN model for instance segmentation and tuned several of its parameters to fit the specific problem and the dataset we were working with. The backbone of the model was a ResNet-50 feature pyramid network, and we initialised the model with weights from a pre-trained COCO instance segmentation model. The batch size for training was set to 4, and the base learning rate was set to 0.00025. The RoIHead batch size was 256, and we used a single output class (for spheroids). We trained the model for a total of 1000 iterations. In addition to these specified parameters, we used the default values for all other parameters of the Mask R-CNN model.\",\n",
      "            \"optimization/encoding\": \"An experienced researcher in the spheroid assay manually annotated the images from Incucyte and microscopes using the VGG Image Annotator. \",\n",
      "            \"optimization/features\": \"Not applicable.\",\n",
      "            \"optimization/fitting\": \"Not applicable.\",\n",
      "            \"optimization/parameters\": \"In this study, we used the Mask R-CNN model for instance segmentation and tuned several of its parameters to fit the specific problem and the dataset we were working with. The backbone of the model was a ResNet-50 feature pyramid network, and we initialised the model with weights from a pre-trained COCO instance segmentation model. The batch size for training was set to 4, and the base learning rate was set to 0.00025. The RoIHead batch size was 256, and we used a single output class (for spheroids). We trained the model for a total of 1000 iterations. In addition to these specified parameters, we used the default values for all other parameters of the Mask R-CNN model.\",\n",
      "            \"model/interpretability\": \"We utilized the Mask R-CNN model, which is recognized as a black box model itself.\",\n",
      "            \"model/output\": \"No. Mask RCNN is a object detection and semantic segmentation model.\",\n",
      "            \"model/duration\": \"The prediction module exhibits linear runtime complexity, taking approximately 1 second per image to mask the spheroids. The run-time performance evaluation was conducted on a Red Hat server equipped with 16 Central Processing Unit (CPU) cores and 64 GB of Random-Access Memory (RAM).\",\n",
      "            \"model/availability\": \"The source code for SpheroScan is available at https://github.com/FunctionalUrology/SpheroScan with GNU GENERAL PUBLIC LICENSE.\",\n",
      "            \"dataset/provenance\": \"To generate the image datasets required for a DL model, we conducted a spheroid gel contraction assay using 5000 Smooth Muscle Cells (SMCs) and Human Embryonic Kidney (HEK) cells per collagen spheroid. After the collagen droplet had polymerized, we changed the medium and transferred the plates to an Incucyte Live-Cell Analysis System, which captured images of the spheroids every hour for a duration of 24 hours. Additionally, we employed a ZEISS Axio Vert.A1 Inverted Microscope to manually capture images of the spheroids at specific time points. By utilizing both methods, we were able to collect a diverse range of spheroid images, resulting in a robust dataset for our DL model. We obtained a total of 530 images from the Incucyte system and 432 images from the microscope.\",\n",
      "            \"dataset/splits\": \"<!DOCTYPE html>\\n<html>\\n<head>\\n  <title>Dataset Information</title>\\n</head>\\n<body>\\n  \\n  <h4>Incucyte System Dataset:</h4>\\n  <ul>\\n    <li>Training dataset: 336 images</li>\\n    <li>Validation dataset: 144 images</li>\\n    <li>Test dataset: 50 images</li>\\n  </ul>\\n\\n  <h4>Microscope Dataset:</h4>\\n  <ul>\\n    <li>Training dataset: 265 images</li>\\n    <li>Validation dataset: 117 images</li>\\n    <li>Test dataset: 50 images</li>\\n  </ul>\\n</body>\\n</html>\",\n",
      "            \"dataset/redundancy\": \"The training, validation, and test sets are independent of each other. Furthermore, the spheroids in the test dataset underwent different treatment compared to those in the training and validation datasets. For the test dataset, the spheroids were cultured in smooth muscle cell medium and Dulbecco's Modified Eagle Medium (DMEM) with 0.5% and 1% FBS. \",\n",
      "            \"dataset/availability\": \"All the images used for training, validation, and testing are available at Zenodo with the DOI: https://doi.org/10.5281/zenodo.7555467 (Creative Commons \\u2014 CC0 license).\",\n",
      "            \"publication/title\": \"SpheroScan: a user-friendly deep learning tool for spheroid image analysis\",\n",
      "            \"publication/authors\": \"Akshay Akshay, Mitali Katoch, Masoud Abedi, Navid Shekarchizadeh, Mustafa Besic, Fiona C Burkhard, Alex Bigger-Allen, Rosalyn M Adam, Katia Monastyrskaya, Ali Hashemi Gheinani\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e3c5061d57eb8bca695ce\",\n",
      "        \"shortid\": \"16cyggfthl\",\n",
      "        \"uuid\": \"3572dc07-ae4e-497f-b7b7-dc66981fbe02\",\n",
      "        \"created\": \"2024-10-15T09:56:32.676Z\",\n",
      "        \"updated\": \"2024-10-15T09:56:32.676Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"title\": \"Machine learning\\u2013based feature selection to search stable microbial biomarkers: application to inflammatory bowel disease\",\n",
      "            \"authors\": \"Youngro Lee, Marco Cappellato, Barbara Di Camillo\",\n",
      "            \"journal\": \"GigaScience\",\n",
      "            \"year\": \"2023\",\n",
      "            \"pmid\": \"37882604\",\n",
      "            \"doi\": \"10.1093/gigascience/giad083\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 6\n",
      "        },\n",
      "        \"score\": 0.78,\n",
      "        \"matches\": {\n",
      "            \"evaluation/method\": \"As illustrated in Fig.1, we divided the entire dataset into Ensemble Dataset 1 and Ensemble Dataset 2. And each ensemble dataset was divided to training set and test set. With this pipeline, we are able to evaluate the entire pipeline in two independent separate dataset. \",\n",
      "            \"evaluation/measure\": \"To validate the evaluation, we check various performance indexes (MCC, AUC, accuracy, PPV, NPV, sensitivity, specificity) and stability indexes (rank based stability measurement-number of common features, Pearson Correlation, Canberra Distance, Bray-Curtis Dissimilarity). Evaluation is done by test dataset obtained from following process: merging benchmark datasets and splitting into training dataset and test dataset by random sort(bootstrapping). \",\n",
      "            \"evaluation/comparison\": \"To validate the performance improvement/consistence, we compare with public, simple algorithm which is Linear SVM based RFE without any special preprocessing method. \",\n",
      "            \"evaluation/confidence\": \"To prove the low variability of performance, the standard deviation of performance is written together with average in Supplementary Tables. Variability is rounded to two decimal places. \",\n",
      "            \"evaluation/availability\": \"The source code containing evaluation files is open to the public at https://gitlab.com/sysbiobig/mlonmicrobiome with GNU General Public License. \",\n",
      "            \"optimization/algorithm\": \"Eight different types of prediction algorithms, namely logistic regression, linear SVM, random forest, XGBoost, Perceptron, and Multi-Layer Perceptron (MLP) with 1, 2 or 3 hidden layers, were used to classify samples in IBD vs. healthy using the features selected within the RFE phase. There was no new ML algorithm. \",\n",
      "            \"optimization/meta\": \"Before applying the eight different types of prediction algorithms, Recursive Feature Elimination (RFE) by Linear SVM was used. RFE stage was done solely by training dataset, and test dataset was used only for evaluating the performance of eight different prediction algorithms.\",\n",
      "            \"optimization/config\": \"We reported how hyperparameters were tuned in 2.5 Classification Model Algorithms, and reported the code at https://gitlab.com/sysbiobig/mlonmicrobiome with GNU General Public License. \",\n",
      "            \"optimization/encoding\": \"As explained in Section 2.1 Data, we divided the abundance profiles by the geometric mean in each data source and took the log (base 2) of the ratios, and then min-max scaler was applied.\",\n",
      "            \"optimization/features\": \"We selected a core set of features with 283 taxa at the species level and 220 at the genus level. Feature selection was done by RFE, which is a core part of our paper. RFE was done only by training dataset. \",\n",
      "            \"optimization/fitting\": \"In this experiment, f was large so that overfitting should be considered (f>100). In this aspect, we propose stable feature selection method to prevent overfitting. \",\n",
      "            \"optimization/parameters\": \"Grid search is used to tune major parameters (learning rate, regularization parameter). Grid search is done solely on the training dataset in cross validation. As all models are built from scikit-learn library 1.0.2, definitions of parameters are all released in the library page and also summarized in Methods. (This part is described at Section 2.2 and 2.5.1)\",\n",
      "            \"optimization/regularization\": \"We applied RFE with mapping transformation to prevent overfitting. Also, regularization parameter was tuned for applicable machine learning algorithm(logistic regression, linear SVM, XGBoost, MLP regressor).\",\n",
      "            \"model/interpretability\": \"We reported interpretation of model in Figure 5 by SHapley Additive exPlanations (SHAP). \",\n",
      "            \"model/output\": \"We used regressor to predict between healthy and IBD samples. \",\n",
      "            \"model/duration\": \"The major execution time was consumed by RFE stage, and we recorded the execution time in the source code. In each bootstrap, RFE with mapping by Bray-curtis similarity matrix required around 3~4 minutes. \",\n",
      "            \"model/availability\": \"The source code is open to the public at https://gitlab.com/sysbiobig/mlonmicrobiome with GNU General Public License. \",\n",
      "            \"dataset/provenance\": \"Dataset is originated from four different public datasets in Qiita. Each dataset is open to the public from references: 1. Lloyd-Price et al (published 2019, citation#=1233), 2. Flores et al. (published 2014, citation #=377), 3. Halfvarsona et al. (published 2017, citation #=825), 4. McDonald et al. (published 2018, citation #=476). A Total of 2140 samples are used for the experiment. (citation # is referred at 2022/12/22) (This part is described at Section 2.1)\\nAmong 1569 samples which have class state, 702 samples are positive and the rest are negative. Number of positives and negatives is similar, and various performance indexes are calculated to avoid class imbalance problems. (This part is described at Section 2)\",\n",
      "            \"dataset/splits\": \"The ratio between training and test set was 80:20. Separate validation set was not used. To maintain the distribution of data types, bootstrapping was used. \",\n",
      "            \"dataset/redundancy\": \"Partitioning is done by splitting the training and the independent test (never used for preprocessing, feature selection, parameter tuning) and, internally to the training set, by bootstrapping to maintain the class balance and random sorting. (This part is described at Section 2)\",\n",
      "            \"dataset/availability\": \"Raw data and preprocessed data are all accessible at https://gitlab.com/sysbiobig/mlonmicrobiome . You can check raw data in the folder-original_data, and preprocessed data by each step in the folder-Count_Preprocessing and folder-Preprocessing. (This part is described at Section 2 and Code Availability Statement)\",\n",
      "            \"publication/title\": \"Machine learning\\u2013based feature selection to search stable microbial biomarkers: application to inflammatory bowel disease\",\n",
      "            \"publication/authors\": \"Youngro Lee, Marco Cappellato, Barbara Di Camillo\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e3d9261d57eb8bca695d2\",\n",
      "        \"shortid\": \"aqtrrhz75x\",\n",
      "        \"uuid\": \"a404e9b9-96f0-411a-b390-a893a6c59651\",\n",
      "        \"created\": \"2024-10-15T10:01:54.363Z\",\n",
      "        \"updated\": \"2024-10-15T10:01:54.363Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"title\": \"Imputation method for single-cell RNA-seq data using neural topic model\",\n",
      "            \"authors\": \"Yueyang Qi, Shuangkai Han, Lin Tang, Lin Liu\",\n",
      "            \"journal\": \"GigaScience\",\n",
      "            \"year\": \"2023\",\n",
      "            \"pmid\": \"38000911\",\n",
      "            \"doi\": \"10.1093/gigascience/giad098\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 6\n",
      "        },\n",
      "        \"score\": 0.7,\n",
      "        \"matches\": {\n",
      "            \"evaluation/method\": \" Independent dataset\",\n",
      "            \"evaluation/measure\": \"ARI-Adjusted Rand Index, RI-Rand Index, NMI-Normalized Mutual Information, MI-Mutual Information and so on.\",\n",
      "            \"evaluation/comparison\": \"Compare with other algorithms\",\n",
      "            \"evaluation/confidence\": \"Not able to use indicator confidence intervals\",\n",
      "            \"evaluation/availability\": \"Yes.We will publish it on GitHub\",\n",
      "            \"optimization/meta\": \"No other data were used as inputs\",\n",
      "            \"optimization/config\": \"Yes.We will publish it on GitHub\",\n",
      "            \"optimization/encoding\": \"Normalization processing\",\n",
      "            \"optimization/features\": \"The expression of each gene in a single cell\",\n",
      "            \"optimization/parameters\": \"Around 200\",\n",
      "            \"model/interpretability\": \"Transparent.Neural Topic inherit the advantages of the topic model and is highly interpretable\",\n",
      "            \"model/duration\": \"Transfer learning of models is linearly correlated with the number of genes\",\n",
      "            \"model/availability\": \"Links can be provided separately\",\n",
      "            \"dataset/provenance\": \"Human Pancreatic Islet data and Mouse Pancreatic Islet data;Human brain scRNA-seq data.All datasets have been used in other published journals and are available in public dataset repositories\",\n",
      "            \"dataset/splits\": \"No data splitting was done\",\n",
      "            \"dataset/redundancy\": \"Data does not overlap\",\n",
      "            \"dataset/availability\": \"Most of the data are in the NCBI Public Dataset.\",\n",
      "            \"publication/title\": \"Imputation method for single-cell RNA-seq data using neural topic model\",\n",
      "            \"publication/authors\": \"Yueyang Qi, Shuangkai Han, Lin Tang, Lin Liu\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e60fa61d57eb8bca695f6\",\n",
      "        \"shortid\": \"x0nks31fro\",\n",
      "        \"uuid\": \"2f8fe6a8-a0b4-40aa-93a9-3a83e53fde3f\",\n",
      "        \"created\": \"2024-10-15T12:32:58.438Z\",\n",
      "        \"updated\": \"2024-10-15T12:32:58.438Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"title\": \"Euler characteristic curves and profiles: a stable shape invariant for big data problems\",\n",
      "            \"authors\": \"Pawe\\u0142 D\\u0142otko, Davide Gurnari\",\n",
      "            \"journal\": \"GigaScience\",\n",
      "            \"year\": \"2023\",\n",
      "            \"pmid\": \"37966428\",\n",
      "            \"doi\": \"10.1093/gigascience/giad094\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 6\n",
      "        },\n",
      "        \"score\": 0.74,\n",
      "        \"matches\": {\n",
      "            \"evaluation/measure\": \"Average accuracy on the test set.\",\n",
      "            \"evaluation/comparison\": \"we compare our results to the one in the original article by Vipond et al.\",\n",
      "            \"evaluation/confidence\": \"confidence intervals are not present in Vipond et al. , we provide ours in our GitHUb. Our results are statistically significant.\",\n",
      "            \"evaluation/availability\": \"https://github.com/dioscuri-tda/ecp_experiments MIT license\",\n",
      "            \"optimization/algorithm\": \"We repeated the procedure outlined in the original paper, described in section 3D of the supplementary materials.\\nVipond et al. \\\"Multiparameter persistent homology landscapes identify immune cell spatial patterns in tumors\\\" https://doi.org/10.1073/pnas.2102166118 \\n\\nQuoting from the above source:\\n\\nWe test the ability of the MPH-landscape to distinguish the cell types in each tumor. For each pair of cell types we make a randomized 80/20 training/test split, and evaluate the classification accuracy of 3 classifiers (Linear Discriminant Analysis, LDA, Regularised Linear Discriminant Analysis, rLDA, and regularised Quadratic Discriminant Analysis, rQDA) on the test data. Repeating this process 100 times we attain average pairwise classification accuracies.\",\n",
      "            \"optimization/config\": \"https://github.com/dioscuri-tda/ecp_experiments/tree/main/immune_cells MIT license\",\n",
      "            \"optimization/encoding\": \"We used the Vipond et al.'s code to re-generate the same Vietoris-Rips and bifiltered Vietoris-Rips complexes from the provided pointclouds. We then computed ECC (radius only) and ECP (radius and codensity) for each complex and used them as input for the same LDA, rLDA and rQDA classifiers using the same train-test split procedure.\",\n",
      "            \"optimization/features\": \"Both ECCs and ECPs where converted to vectors of lenght 51 by sampling them on a grid.\",\n",
      "            \"optimization/fitting\": \"By comparing train and test accuracies \",\n",
      "            \"optimization/parameters\": \" Default hyperparameters from the scikit-learn implementations, as in the original study.\",\n",
      "            \"model/interpretability\": \"The model is interpretable, but interpretation goes beyond the scope of this work.\",\n",
      "            \"model/duration\": \"Seconds on a consumer-grade laptop.\",\n",
      "            \"model/availability\": \"https://github.com/dioscuri-tda/ecp_experiments MIT license\",\n",
      "            \"dataset/provenance\": \"Anonymized point cloud data from Vipond et al. \\\"Multiparameter persistent homology landscapes identify immune cell spatial patterns in tumors\\\" https://doi.org/10.1073/pnas.2102166118 .\\n\",\n",
      "            \"dataset/splits\": \"We repeated the procedure outlined in the original paper, described in section 3D of the supplementary materials.\\n\\nThere is a total of 1574 data points belonging to 3 different cell types. No separate validation set is provided.\",\n",
      "            \"dataset/redundancy\": \"We repeated the procedure outlined in the original paper, described in sectin 3D of the supplementary materials. \\n\\nFor each pair of cell type we make a randomized 80/20 training/test split with stratification. The process was repeated 100 time\",\n",
      "            \"dataset/availability\": \"Yes. The anonymized point cloud data are available from Vipond et al. \\\"Multiparameter persistent homology landscapes identify immune cell spatial patterns in tumors\\\" https://doi.org/10.1073/pnas.2102166118 \\n\\nhttps://github.com/MultiparameterTDAHistology/SpatialPatterningOfImmuneCells\\n\\nour pipeline is available at\\nhttps://github.com/dioscuri-tda/ecp_experiments/tree/main/immune_cells\\n\\n\",\n",
      "            \"publication/title\": \"Euler characteristic curves and profiles: a stable shape invariant for big data problems\",\n",
      "            \"publication/authors\": \"Pawe\\u0142 D\\u0142otko, Davide Gurnari\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e64f661d57eb8bca695fa\",\n",
      "        \"shortid\": \"vdqf1t5lyj\",\n",
      "        \"uuid\": \"e8f2de3b-25bc-4a43-9af4-fc31a7f05d40\",\n",
      "        \"created\": \"2024-10-15T12:49:58.625Z\",\n",
      "        \"updated\": \"2024-10-15T12:49:58.625Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"title\": \"MLcps: machine learning cumulative performance score for classification problems\",\n",
      "            \"authors\": \"Akshay Akshay, Masoud Abedi, Navid Shekarchizadeh, Fiona C Burkhard, Mitali Katoch, Alex Bigger-Allen,Rosalyn M Adam, Katia Monastyrskaya, Ali Hashemi Gheinani\",\n",
      "            \"journal\": \"GigaScience\",\n",
      "            \"year\": \"2023\",\n",
      "            \"pmid\": \"38091508\",\n",
      "            \"doi\": \"10.1093/gigascience/giad108\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 6\n",
      "        },\n",
      "        \"score\": 0.7,\n",
      "        \"matches\": {\n",
      "            \"evaluation/method\": \"We consistently maintained an independent test set for TCGA dataset to evaluate the model's performance and identify potential issues of overfitting or underfitting. To mitigate the risk of overfitting in the CLL and cervical datasets, we utilized the Repeated Stratified K-fold Cross-Validation method.\",\n",
      "            \"evaluation/measure\": \"We computed 7 evaluation metrics, including precision, recall, F1 score, and area under the curve (AUC), for each trained model across all datasets.This comprehensive approach enabled us to gain a thorough understanding of the model's performance from multiple angles and perspectives. \",\n",
      "            \"evaluation/comparison\": \"We compared the performance of our trained models with a dummy classifier, which is a classifier that makes random predictions. Typically, it is expected that the trained models will outperform the dummy classifier. This serves as a baseline comparison to assess the effectiveness and superiority of our trained models. By comparing the performance metrics of our models against the random predictions of the dummy classifier, we can evaluate the added value and efficacy of our trained models in making accurate predictions.\",\n",
      "            \"evaluation/availability\": \"Not applicable.\",\n",
      "            \"optimization/algorithm\": \"We have utilized 8 classification algorithms for each dataset in order to classify the classes within each dataset.\",\n",
      "            \"optimization/meta\": \"No. \",\n",
      "            \"optimization/config\": \"We did not perform any hyperparameter tuning for the trained models. \",\n",
      "            \"optimization/encoding\": \"For the CLL patients dataset, we specifically utilized the top 5,000 most variable mRNAs, excluding genes from the Y chromosome, as input for the machine learning pipeline. In the case of the BRCA mRNA dataset, our focus was solely on differentially expressed genes identified by edgeR, using a threshold of FDR \\u2264 0.001 and logFC > \\u00b1 2. As for the cervical cancer dataset, we utilized it in its original form without making any modifications.\",\n",
      "            \"optimization/features\": \"No feature selection was performed on any of the datasets.\",\n",
      "            \"optimization/fitting\": \"We consistently maintained an independent test set for TCGA dataset to evaluate the model's performance and identify potential issues of overfitting or underfitting. To mitigate the risk of overfitting in the CLL and cervical datasets, we utilized the Repeated Stratified K-fold Cross-Validation method.\",\n",
      "            \"optimization/parameters\": \"The majority of the trained models were utilized with their default parameters.\",\n",
      "            \"model/interpretability\": \" We have used multiple ML classification algorithms, most of which are black box models. For example, SVM (Support Vector Machine) is considered a black box model, but features like support vectors and feature importance can offer some interpretability.\",\n",
      "            \"model/output\": \" Classification.\",\n",
      "            \"model/duration\": \" It is not applicable to current project.\",\n",
      "            \"model/availability\": \"The source code for MLcps is available at https://github.com/FunctionalUrology/MLcps with GNU GENERAL PUBLIC LICENSE.\",\n",
      "            \"dataset/provenance\": \"\\nIn this project, we utilized four different publicly available datasets that are well recognized in the domain. The first dataset consisted of mRNA data obtained from a study on Chronic Lymphocytic Leukemia (CLL) patients, measuring their transcriptome profiles. The second dataset was collected from a cervical cancer study that analyzed the expression levels of 714 miRNAs in human samples. The third and fourth datasets were obtained from The Cancer Genome Atlas (TCGA) and included mRNA and miRNA sequencing data from patients with Breast Invasive Carcinoma (BRCA). \\n  \\n<!DOCTYPE html>\\n<html>\\n<head>\\n<style>\\ntable {\\n  text-align: center;\\n}\\nth {\\n  text-align: center;\\n}\\n</style>\\n</head>\\n<body>\\n\\n<table>\\n\\n  <tr>\\n    <th>Dataset</th>\\n    <th>Data type</th>\\n    <th>Number of Samples</th>\\n    <th>Number of Features</th>\\n    <th>Target Class ratio</th>\\n  </tr>\\n  <tr>\\n    <td>CLL</td>\\n    <td>mRNA</td>\\n    <td>136</td>\\n    <td>5000</td>\\n    <td>Male (n=82): Female (n=54)</td>\\n  </tr>\\n  <tr>\\n    <td>Cervical cancer</td>\\n    <td>miRNA</td>\\n    <td>58</td>\\n    <td>714</td>\\n    <td>Normal (n=29): Tumor (n=29)</td>\\n  </tr>\\n  <tr>\\n    <td>TCGA-BRCA</td>\\n    <td>miRNA</td>\\n    <td>1207</td>\\n    <td>1404</td>\\n    <td>Normal (n=104): Tumor (n=1104)</td>\\n  </tr>\\n  <tr>\\n    <td>TCGA-BRCA</td>\\n    <td>mRNA</td>\\n    <td>1219</td>\\n    <td>5520</td>\\n    <td>Normal (n=113): Tumor (n=1106)</td>\\n  </tr>\\n\\n</table>\\n\\n</body>\\n</html>\\n\\n\",\n",
      "            \"dataset/splits\": \"We maintained a distinct test/validation dataset to evaluate the model's performance on TCGA datasets. The original datasets were randomly split, ensuring that each class was proportionally represented within the dataset. Approximately 70% of the data was allocated to the training dataset, while the remaining 30% was assigned to the test dataset.\\n\\nTo assess the model's performance on the CLL and cervical cancer datasets, we employed the Repeated (10) Stratified K-fold (3) Cross-Validation method. This approach allowed us to thoroughly evaluate the model by repeatedly dividing the data into folds, ensuring that each fold maintained a balanced distribution of classes.\\n\",\n",
      "            \"dataset/redundancy\": \"We maintained a distinct test/validation dataset to evaluate the model's performance on TCGA datasets. The original datasets were randomly split, ensuring that each class was proportionally represented within the dataset. Approximately 70% of the data was allocated to the training dataset, while the remaining 30% was assigned to the test dataset.\\n\\nTo assess the model's performance on the CLL and cervical cancer datasets, we employed the Repeated (10) Stratified K-fold (3) Cross-Validation method. This approach allowed us to thoroughly evaluate the model by repeatedly dividing the data into folds, ensuring that each fold maintained a balanced distribution of classes.\\n\",\n",
      "            \"dataset/availability\": \"The datasets we have utilized are publicly available datasets. All the relevant details can be found in the manuscript.\",\n",
      "            \"publication/title\": \"MLcps: machine learning cumulative performance score for classification problems\",\n",
      "            \"publication/authors\": \"Akshay Akshay, Masoud Abedi, Navid Shekarchizadeh, Fiona C Burkhard, Mitali Katoch, Alex Bigger-Allen,Rosalyn M Adam, Katia Monastyrskaya, Ali Hashemi Gheinani\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e65ee61d57eb8bca695fe\",\n",
      "        \"shortid\": \"9izph0m2we\",\n",
      "        \"uuid\": \"b2f6bf1e-bccb-4250-98a3-0b71335847dc\",\n",
      "        \"created\": \"2024-10-15T12:54:06.607Z\",\n",
      "        \"updated\": \"2024-10-15T12:54:06.607Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"title\": \"MMV_Im2Im: An Open Source Microscopy Machine Vision Toolbox for Image-to-Image Transformation\",\n",
      "            \"authors\": \"Justin Sonneck, Yu Zhou, Jianxu Chen\",\n",
      "            \"journal\": \"GigaScience\",\n",
      "            \"year\": \"2023\",\n",
      "            \"pmid\": \"38280188\",\n",
      "            \"doi\": \"10.1093/gigascience/giad120\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 6\n",
      "        },\n",
      "        \"score\": 0.67,\n",
      "        \"matches\": {\n",
      "            \"evaluation/method\": \"evaluated on hold-out sets\",\n",
      "            \"evaluation/measure\": \"The objective of this paper is to introduce a geneic machien learning tool, not for a specific scientific study. The evaluation metric varies from application to application. Please refer the \\\"Results\\\" section of the manuscript for details.\",\n",
      "            \"evaluation/availability\": \"All models are released https://zenodo.org/records/10034416, which can be used to reproduce raw outputs\",\n",
      "            \"optimization/algorithm\": \"Neural network. Four types of methods were used, conditional GAN, cycle GAN, FCN, and embedding based instance segmentation network.\",\n",
      "            \"optimization/config\": \"yes, https://github.com/MMV-Lab/mmv_im2im/tree/main/paper_configs\",\n",
      "            \"optimization/encoding\": \"Usually, the images need to go through intensity normalization before feeding into the neural network. Different experiments may use different intensity normalization methods.\",\n",
      "            \"optimization/features\": \"Inputs are images\",\n",
      "            \"optimization/fitting\": \"We demonstration examples of various regularization methods in different experiments, such as weigh decay and early stopping, etc.. The objective of this paper is to introduce a generic machine learning tool, not for a specific scientific question. Users can configure their own way to control overfitting and under fitting, depending on their own data.\",\n",
      "            \"optimization/parameters\": \"We used different neural networks for different applications. Please refer the \\\"Results\\\" section of the manuscript for details. The goal is not to show the best model. Instead, it is to highlight the flexibility of our tool, where users can test differnet models without changing any line of code. The objective of this paper is to introduce a generic machine learning tool, not for a specific scientific question.\",\n",
      "            \"optimization/regularization\": \"yes, we used weight decay in the optimizer and early stopping monitoring the validation loss. (Again, the objective of this paper is to introduce a generic machine learning tool, not for a specific scientific question. One highlight of this tool is that users can easily configure different regularization methods, e.g., different early stopping criteria, different optimizer, adding additional regularization term in the loss, etc.)\",\n",
      "            \"model/interpretability\": \"in general, deep neural networks are not fully interpretable\",\n",
      "            \"model/output\": \"The objective of this paper is to introduce a machine learning tool, not for a specific scientific question. The model can be regression or classification depending on specific image-to-image transformation application. For labelfree, denoising, modality transfer, synthetic image generation, the models are regression; for other segmentation tasks, the models are classification.\",\n",
      "            \"model/duration\": \"Generally about a few seconds, depending on the size of the image and the specific model and application.\",\n",
      "            \"model/availability\": \"yes, open source python package. https://github.com/MMV-Lab/mmv_im2im (MIT license)\",\n",
      "            \"dataset/provenance\": \"The data were all from public repositories released with previous publications. Please refer the \\\"Data Availability\\\" section of the manuscript for details.\",\n",
      "            \"dataset/splits\": \"There are over ten different experiments in this work. In general, K% of the data were held out for testing, while (100-K)% were used during training. Among this (100-K)%, 85%*(100-K)% were used in the training loops, while 15%*(100-K)% were used in the validation loops (e.g., for the purpose of early stoping determination). In most cases, K = 20. But in some cases, due to limited amount of public data, we can only hold out smaller amount of data; otherwise, the training set would be too small to be effective. There are also a few experiments, we just followed the original split from the published dataset. Please refer the \\\"Data Availability\\\" section of the manuscript for details.\",\n",
      "            \"dataset/redundancy\": \"When we do train/test split, all splits are random.\",\n",
      "            \"dataset/availability\": \"The data are all publicly available, as they were all released with previous publications. Please refer the \\\"Data Availability\\\" section of the manuscript for details.\",\n",
      "            \"publication/title\": \"MMV_Im2Im: An Open Source Microscopy Machine Vision Toolbox for Image-to-Image Transformation\",\n",
      "            \"publication/authors\": \"Justin Sonneck, Yu Zhou, Jianxu Chen\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"65d7e78d1502715bfe53c582\",\n",
      "        \"uuid\": \"00e4d4f8-2dd6-452a-b27c-72fe9296b09d\",\n",
      "        \"created\": \"2024-02-23T00:32:13.005Z\",\n",
      "        \"updated\": \"2024-02-23T00:35:32.655Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"title\": \"Discovering genotype-phenotype relationships with machine learning and the Visual Physiology Opsin Database (VPOD)\",\n",
      "            \"authors\": \"Seth A. Frazer, Mahdi Baghbanzadeh, Ali Rahnavard, Keith A. Crandall, Todd H. Oakley\",\n",
      "            \"journal\": \"GigaScience\",\n",
      "            \"year\": \"2024\",\n",
      "            \"pmid\": \"na\",\n",
      "            \"doi\": \"10.1101/2024.02.12.579993\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"shortid\": \"88n4lxv68p\",\n",
      "        \"score\": 0.9,\n",
      "        \"matches\": {\n",
      "            \"evaluation/method\": \"For model evaluation and comparison, deepBreaks by default uses a 10-fold cross-validation approach and ranks\\nthe models based on their average cross-validation score.\\nAs we described in the methods of the main text \\\"we created eleven data subsets with varying levels of taxonomic and gene family inclusivity (Table 1) to test which factors most impact the reliability/performance of ML methods. We used naming conventions that include versioning to improve reproducibility and reliability of individual datasets and models. For example, one subset combines ultraviolet and SWS opsins, which we named VPOD_uss_het_1.0. Our convention is to name the subset (in this case USS = \\u2018Ultraviolet and Short-wave Sensitive\\u2019 opsins); name the source of phenotype data (heterologous = het), and record the version number of the dataset (1.0). We also created subsets for medium- and long-wave sensitive opsins (VPOD_mls_het_1.0) and all rod (Rh1) and rod-like (Rh2) opsins (VPOD_rod_het_1.0). Other subsets use species taxonomy, one for vertebrates (VPOD_vert_het_1.0) and another for invertebrates (VPOD_inv_het_1.0). For taxonomic subsets, we considered all sequences from phylum Chordata as \\u2018vertebrates\\u2019 and the rest as 'invertebrates\\u2019. Another subset excludes all mutant opsin sequences, called \\u2018wild-types\\u2019 (VPOD_wt_het_1.0). A final named subset is the whole data set (VPOD_wds_het_1.0). \\nUsing various subsets of data, we performed a number of experiments to better understand the performance of ML models in predicting \\u03bbmax. First, to better understand how training data relate to model performance, R2 , and training data size, we gradually increased the size of training datasets, using the WDS, Vertebrate, WT, and Rod subsets separately, by adding between 15-50 randomly selected sequences at a time, repeating the process three times per data split (Table S1). We then analyzed the fit between the size of training data sets (x-axis) and model performance (y-axis), comparing six non-linear models with AIC to find the model that best explains the observed variation (Figure S2). Second, to understand if ML could predict known phenotypic changes due to experimental mutations, we queried the top performing WT model (which lacks data from artificially mutated sequences) using all experimentally mutated opsins to predict their phenotypes. We plotted these results using matplotlib [49] to visualize characteristics of poorly predicted outliers (e.g., taxonomic bias or sensitivity to mutations which caused large shifts in \\u03bbmax from the WT). Third, we examined the ability of our models to predict \\u03bbmax of thirty invertebrate opsins not in VPOD_1.0 because they are only known from physiological studies (Table S3, Figure S4). Here, we collected data both characterized by single-cell microspectrophotometry (MSP) or electroretinogram methods and with expression localized to cell-type by in-situ-hybridization (ISH), to link \\u03bbmax to a specific opsin (the sequences and metadata can be found in \\u2018msp_erg_raw.txt\\u2019 and \\u2018msp_erg_meta.tsv\\u2019, while the resulting predictions can be found under the \\u2018msp_tests\\u2019 folder on our GitHub repository). Finally, we directly compared predictive capabilities of models trained on different data subsets by randomly selecting and removing the same 25 wild-type ultraviolet or short-wave sensitive opsins from the training data of the WDS, Vertebrate, WT, and UVS/SWS models before training and querying the model with those same sequences following training (Table S3, Figure S5). \\\"\\n\",\n",
      "            \"evaluation/measure\": \"The default performance metrics for regression and classification that deepBreaks uses are Mean Absolute Error (MAE) and F-score. The default list of metrics that deepBreaks reports are provided in the documentation provide predefined custom metrics or a set of metrics from the scikit-learn library in python.\",\n",
      "            \"evaluation/comparison\": \"We didn't compare to an existing publicly available ML methods. However, we compared performance of ML models to phylogenetic imputation, which estimates phenotypes using phylogenetic information. Phylogenetic imputation uses maximum likelihood (we will not abbreviate maximum likelihood as ML to avoid confusion with machine learning), assuming Brownian Motion to predict missing phenotypes using a phylogenetic tree, assuming more closely related species or sequences have more similar phenotypes. We randomly removed 50 opsin sequences, and their corresponding \\u03bbmax values from each of the training datasets used to train our ML models (with the exception of the smaller MWS/LWS and invertebrate datasets, in which we only removed 15), then estimated the removed \\u03bbmax values using phylogenetic imputation. We used the phylogenetic imputation sub-module of the phytools R package for performing imputation. We compared imputed and actual \\u03bbmax using regression. \",\n",
      "            \"evaluation/availability\": \"Yes, this all available on our GitHub repository, (10.5281/zenodo.10667840 or https://github.com/VisualPhysiologyDB/visual-physiology-opsin-db/).\",\n",
      "            \"optimization/algorithm\": \"We then trained various ML models employing a custom version of deepBreaks, an ML tool designed for exploring genotype-phenotype associations. For continuous phenotypes, deepBreaks fit models using twelve different existing ML linear regression algorithms including, Ridge Regression, Lasso Regression, Bayesian Regression, Lasso Least Angle Regression, Huber Regressor, Extremely Randomized Trees (Extra Trees), Extreme Gradient Boosting (xgboost), Light Gradient Boosting Machine (lightgbm), Random Forest, Decision Tree, and AdaBoost. deepBreaks takes aligned genotype data (DNA, RNA, Amino Acid) and some measure(s) of corresponding continuous or categorical phenotype data as input to train ML models. \",\n",
      "            \"optimization/config\": \"Yes, they are likely available in the scikit-learn documentation. \",\n",
      "            \"optimization/encoding\": \"The deepBreaks pipeline for preprocessing starts with dropping columns in the dataset that contain missing values over a certain threshold. The default threshold is 80% of the number of samples.  Dropping the zero-entropy (constant) features from the dataset, is the next step.   deepBreaks uses one-hot encoding to convert amino acid sequences into numerical values. One consequence of this encoding is any amino acids at a given position in the alignment, which are not present at that position in any training data, will be treated equivalently as unseen. For example, cases of only A and V at a highly conserved site in the training set that are presented with a sequence with T at that site will be considered as no A and no V. The models cannot distinguish the input whether it's T or other unseen amino acids at that site.  \",\n",
      "            \"optimization/features\": \"The number of input features is variable depending on the length of the sequences following sequences alignment and the many preprocessing and feature selection steps. deepBreaks uses the Kruskal-Wallis tests (for continuous phenotypes)  to reduce the number of positions in the training data set and drop the redundant ones. This statistical test is used to assess the significance of each position by running tests on all the positions against the phenotype one by one. Those features where the p-value of their test against the phenotype is less than a threshold (default p-value = 0.25) will be dropped. A list of all features and their test p-values are provided a report to the user. Then, since deepBreaks considers each position in the sequences as a feature of our training dataset,  it checks for collinearity between our predictive variables, as it can cause issues for parameter estimation. To check for the relationship between\\n\",\n",
      "            \"optimization/fitting\": \"We did not focus on ruling out overfitting or underfitting, however these features may be present in the scikit-learn backend. \",\n",
      "            \"optimization/parameters\": \"For all of the above-mentioned models deepBreaks by default uses the default hyperparameters from the scikit-learn library in python and a grid search (expandable by user preference) parameter set that is provided in the documentation.\",\n",
      "            \"optimization/regularization\": \"We did not directly impliment any regularization measures, however I know certain models like the Light Gradient Boosted Machine and Xtreme Gradient Boosted Machine algorithms have regularization terms/parameters to limit overfitting.  That said, more information on this can be found in the scikit-learn documentation or in the corresponding literature for each machine learning algorithm type. \",\n",
      "            \"model/interpretability\": \"All models used are generally interpretable, primarily due to the nature of the feature selection process, treating each position on an amino acid sequence as a feature. \\nFor interpreting the contribution of sequence positions to the predictive models, we use the feature importance, coefficients, and weights as different algorithms have different kinds of\\noutput. For xgboost and lightgbm the reported feature importance represents the number of times a feature appears in a tree. For AdaBoost, random forest, decision tree, extra tree, and\\ngradient boosting the importance of a feature is its Gini importance which is computed as the\\nnormalized total reduction of the criterion brought by that feature.\",\n",
      "            \"model/output\": \"The models used for our paper were all regression, but deepBreaks provides the option to also train classification models in an identical manner. \",\n",
      "            \"model/duration\": \"A single representative prediction, all the way to several hundred predictions, takes only a matter of seconds to complete on a normal desktop PC.  Additionally, training the models can completed in a matter of minutes on a desktop PC as well.  \",\n",
      "            \"model/availability\": \"As mentioned earlier, all software, code and supporting data are available on our GitHub repository (10.5281/zenodo.10667840 or https://github.com/VisualPhysiologyDB/visual-physiology-opsin-db/). All data and code (software) is covered under a GNU General Public License (Version 3), in accordance with Open Source Initiative (OSI)-policies. \",\n",
      "            \"dataset/provenance\": \"The source of the data is from a database we compiled, the Visual Physiology Opsin Database (VPOD) (10.5281/zenodo.10667840 or https://github.com/VisualPhysiologyDB/visual-physiology-opsin-db/). VPOD_1.0 is a new database, available on GitHub, that currently includes all heterologously expressed animal opsins. We refer to a subset of the database with only heterologous data as VPOD_het_1.0, although for version 1.0, this is synonymous with the entire database. VPOD_het_1.0 relies on 68 publications, mainly primary sources, with dates ranging from the 1980\\u2019s to 2023. The database contains opsin sequences and phenotype data from 166 unique species (counting 35 reconstructed ancestors), including fishes, amphibians, reptiles, mammals, crustaceans, and bivalves. Altogether, VPOD_het_1.0 contains 864 unique opsin sequences and corresponding \\u03bbmax values.\",\n",
      "            \"dataset/splits\": \"For model training, a whole dataset it submitted to the algorithm training pipeline and it is randomly sampled to split the data such  that 80% is used for training, and 20% is used for model validation. The amount of data points in these splits/sets are dependent on the subset of data used to train the models. As mentioned earlier, VPOD_het_1.0 contains 864 unique opsin sequences and corresponding \\u03bbmax values. From this we created eleven data subsets with varying levels of taxonomic and gene family inclusivity to test which factors most impact the reliability/performance of ML methods.\",\n",
      "            \"dataset/redundancy\": \"We used naming conventions that include versioning to improve reproducibility and reliability of individual datasets and models. For example, one subset combines ultraviolet and SWS opsins, which we named VPOD_uss_het_1.0 (n=280). Our convention is to name the subset (in this case USS = \\u2018Ultraviolet and Short-wave Sensitive\\u2019 opsins); name the source of phenotype data (heterologous = het), and record the version number of the dataset (1.0). We also created subsets for medium- and long-wave sensitive opsins (VPOD_mls_het_1.0)(n=91) and all rod (Rh1) and rod-like (Rh2) opsins (VPOD_rod_het_1.0)(n=352). Other subsets use species taxonomy, one for vertebrates (VPOD_vert_het_1.0)(n=721) and another for invertebrates (VPOD_inv_het_1.0)(n=143). For taxonomic subsets, we considered all sequences from phylum Chordata as \\u2018vertebrates\\u2019 and the rest as 'invertebrates\\u2019. Another subset excludes all mutant opsin sequences, called \\u2018wild-types\\u2019 (VPOD_wt_het_1.0)(n=318). A final named subset is the whole data set (VPOD_wds_het_1.0)(n=864). \\nWe used naming conventions that include versioning to improve reproducibility and reliability of individual datasets and models. For example, one subset combines ultraviolet and SWS opsins, which we named VPOD_uss_het_1.0 (n=280). Our convention is to name the subset (in this case USS = \\u2018Ultraviolet and Short-wave Sensitive\\u2019 opsins); name the source of phenotype data (heterologous = het), and record the version number of the dataset (1.0). We also created subsets for medium- and long-wave sensitive opsins (VPOD_mls_het_1.0)(n=91) and all rod (Rh1) and rod-like (Rh2) opsins (VPOD_rod_het_1.0)(n=352). Other subsets use species taxonomy, one for vertebrates (VPOD_vert_het_1.0)(n=721) and another for invertebrates (VPOD_inv_het_1.0)(n=143). For taxonomic subsets, we considered all sequences from phylum Chordata as \\u2018vertebrates\\u2019 and the rest as 'invertebrates\\u2019. Another subset excludes all mutant opsin sequences, called \\u2018wild-types\\u2019 (VPOD_wt_het_1.0)(n=318). A final named subset is the whole data set (VPOD_wds_het_1.0)(n=864). \\n\",\n",
      "            \"dataset/availability\": \"The data set(s) supporting the results and all other code used in this article are available in the \\u2018Visual Physiology Opsin Database\\u2019 GitHub repository, (10.5281/zenodo.10667840 or https://github.com/VisualPhysiologyDB/visual-physiology-opsin-db/). All data and code is covered under a GNU General Public License (Version 3), in accordance with Open Source Initiative (OSI)-policies.  DOME-ML (Data, Optimisation, Model, and Evaluation in Machine Learning) annotation, supporting the current study, is available through DOME Wizard.\\n\",\n",
      "            \"publication/title\": \"Discovering genotype-phenotype relationships with machine learning and the Visual Physiology Opsin Database (VPOD)\",\n",
      "            \"publication/authors\": \"Seth A. Frazer, Mahdi Baghbanzadeh, Ali Rahnavard, Keith A. Crandall, Todd H. Oakley\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"65f598d51502715bfe53d2d8\",\n",
      "        \"uuid\": \"e2ca04b9-38fe-40d6-9fd9-5c8355f4402d\",\n",
      "        \"created\": \"2024-03-16T13:04:21.998Z\",\n",
      "        \"updated\": \"2024-03-16T13:04:21.998Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"pmid\": \"39172545\",\n",
      "            \"authors\": \"Guowei Chen, Jingzhe Jiang, and Yanni Sun\",\n",
      "            \"journal\": \"GigaScience\",\n",
      "            \"title\": \"VirHost: a machine learning-based method for predicting reservoir hosts of RNA viruses through viral genomes\",\n",
      "            \"doi\": \"10.1093/gigascience/giae059\",\n",
      "            \"year\": \"2024\"\n",
      "        },\n",
      "        \"shortid\": \"ta01kc1au8\",\n",
      "        \"score\": 0.95,\n",
      "        \"matches\": {\n",
      "            \"evaluation/availability\": \"They are availble in the GigaDB and supplementary information.\",\n",
      "            \"evaluation/comparison\": \"Yes, we set the alignment-based method, BLASTN, as the baseline model. We then further comared VirHost with various available learning-based methods and validated the outperforming accuracy of VirHost.\",\n",
      "            \"evaluation/confidence\": \"We evaluated all the benchmark models across virus orders by their accuracy distribution. VirHost outperformed any other models from the average accuracy. We also tested confidence of the superior accuracy by one-sided Wilcoxon test, which gave p-value smaller then 0.005\",\n",
      "            \"evaluation/measure\": \"We used accuracy, precision, and prediction rate and the performance metrics in this study. These metrics are widely used in previous studies, like DOI:10.1126/science.aap9072 and doi: 10.1093/bioinformatics/btab33 .\",\n",
      "            \"evaluation/method\": \"We extensively assessed the models by stratified 5-fold cross evaluation, leave-one-genus-out experiment, and recently-identified novel RNA viuses.\",\n",
      "            \"optimization/algorithm\": \"We designated XGBoost as the learning architecture out of its superiors accuracy and training efficiency. To validate our choice, we conducted an evaluation of several learning architectures, encompassing XGBoost, Gradient Boosting Decision Tree (GBDT), Random Forest (RF), Support Vector Machine with RBF kernel (SVM), Logistic Regression (LR), K-Nearest Neighbors (KNN), and Gaussian Naive Bayes (GNB). Using the scikit-learn and xgboost package, default parameters were employed to train these models, and their performance was assessed using accuracy as the evaluation metric.\",\n",
      "            \"optimization/config\": \"All of the model configuration can be easily access from the scikit-learn and xgboost documentation. If you wanna check the parameters of our models, you may load the models by pickle package and used the command \\\"model.get_xgb_params()\\\"\",\n",
      "            \"optimization/encoding\": \"We encode the query sequences by their genomic traits and sequence homology. Specifically, we encode the sequences into a (137+m) dimensional vector as the input to models, where m is the number of host labels in the corresponding virus order and model layer. The genomic traits is vectorized as a 137-dimensional vector. To encode the m feature, we first group the reference viruses by their host labels, and then align the query virus against the reference viruses. The highest similarity score against each group is kept to be the corresponding feature value.\",\n",
      "            \"optimization/features\": \"Two groups of feature are used as input, 137 genomic traits and the viral sequence homology. Although we did feature selection, we simply compared the feature contribution and model accuracy between the 137 genomic tratis and the codon pairs groups. This is done in the cross validation experiment. For a fair comparison, we removed all of the codon pair scores without using any relatively important ones, which will not result in the data leakage.\",\n",
      "            \"optimization/fitting\": \"We did not focus on ruling out overfitting or underfitting. However, it is worth noting that the parameter count of XGBoost is typically lower than that of neural networks. Additionally, XGBoost incorporates L2 regularization by default, which helps mitigate the risk of overfitting.\",\n",
      "            \"optimization/parameters\": \"For all of the above-mentioned models, we use the default hyperparameters from scikit-learn and xgboost library to train.\",\n",
      "            \"optimization/regularization\": \"XGBoost incorporates L2 regularization by default, which helps mitigate the risk of overfitting. Besides, we adopted the early stop strategy by evaluating the prediction probability of our models. We set probability cutoff for each model to distinguish predictions with low confidence.\",\n",
      "            \"model/availability\": \"It can be access by https://github.com/GreyGuoweiChen/VirHost\",\n",
      "            \"model/duration\": \"It takes around 5 seconds to run the test cases (3 viruses) on a normal desktop PC.\",\n",
      "            \"model/interpretability\": \"The models are black box models. But we provide the evidence and different confidence level of our predictions to users.\",\n",
      "            \"model/output\": \"We build hierarchical classification models for each virus order.\",\n",
      "            \"dataset/availability\": \"The data supporting the results and software in this article are available in the \\u2018VirHost\\u2019 GitHub repository, (https://github.com/GreyGuoweiChen/VirHost). All data and code is covered under a MIT License. The analytic code is accessible from the GigaDB.\",\n",
      "            \"dataset/provenance\": \"We collected 6,735 RNA viruses from Virus-Host Database and 126,417 records with host annotations from NCBI GenBank, both of which are widely used database. After the careful data preprocessings, including de-replication and removal of ambiguous host annotations, we finally got 14500 RNA viruses, spanning 30 virus orders and 12 host groups, including Invertebrate, Viridiplantae, Fungi, Bacteria, Primates, Rodentia, Artiodactyla, Carnivora, Other mammalia, Aves, Reptilia, and Fish. We also evaluated our method in a set of newly-identified RNA viruses, whose hosts are derived based on experimental evidence. The set includes 126 RNA viruses and were collected from various hosts, including Plant, Invertebrate, Fungi, and Fish. The dataset is complied from 20 publications.\",\n",
      "            \"dataset/redundancy\": \"We evalaute the model by cross-validation, leave-one-genus-out experiment and recently-identified viruses, which are not included in the training data. In all datasets, the training and test sets are independent. Before the evaluation, we remove the data redundancy to be less than 90% coverage and 80% identity. In leave-one-genus-out experiment and recently-identified viruses, the sequence identity between training and test set is even lower. \",\n",
      "            \"dataset/splits\": \"We first evalute the learning architecture by stratified 5-fold cross validation. The viruses in corresponding virus orders are stratified splited into 5 folds by their labels, with 4 folds as training set and 1 as test set. We evaluated the models on each fold and average the results. There is no duplicate samples between the training and test datasets. \\nBesides, we evaluated the models by conducting leave-one-genus-out experiments. Specifically, we used one genus as test set and viruses from other genuses as training set to assess the generalizability of the models. There are 448 virus genera in total. This experiment is a strong demonstration of the generality of the model; no viruses of the same genus are distributed in both the training and test data. \",\n",
      "            \"publication/authors\": \"Guowei Chen, Jingzhe Jiang, and Yanni Sun\",\n",
      "            \"publication/title\": \"VirHost: a machine learning-based method for predicting reservoir hosts of RNA viruses through viral genomes\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e670661d57eb8bca69602\",\n",
      "        \"shortid\": \"bxlfk5g20v\",\n",
      "        \"uuid\": \"bb9e3878-75dc-4120-88f4-0a98f0195ec1\",\n",
      "        \"created\": \"2024-10-15T12:58:46.423Z\",\n",
      "        \"updated\": \"2024-10-15T12:58:46.423Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"title\": \"Machine Learning Made Easy (MLme): a comprehensive toolkit for machine learning\\u2013driven data analysis\",\n",
      "            \"authors\": \"Akshay Akshay, Mitali Katoch, Navid Shekarchizadeh, Masoud Abedi, Ankush Sharma, Fiona C Burkhard, Rosalyn M Adam, Katia Monastyrskaya, Ali Hashemi Gheinani\",\n",
      "            \"journal\": \"GigaScience\",\n",
      "            \"year\": \"2024\",\n",
      "            \"pmid\": \"38206587\",\n",
      "            \"doi\": \"10.1093/gigascience/giad111\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 6\n",
      "        },\n",
      "        \"score\": 0.74,\n",
      "        \"matches\": {\n",
      "            \"evaluation/method\": \"We consistently maintained an independent test set for all datasets to evaluate the model performance accurately. In addition, we employed multiple model evaluation techniques such as repeated stratified k-fold cross-validation, nested cross-validation, and others. These techniques allow for robust and reliable assessment of the models, taking into account the variance and potential bias in the data. By utilizing such methods, we aimed to obtain a comprehensive understanding of the model's performance across different folds and iterations, enhancing the reliability of our results.\",\n",
      "            \"evaluation/measure\": \"We computed more than 10 evaluation metrics, including precision, recall, F1 score, and area under the curve (AUC), for each trained model across all datasets. This comprehensive approach enabled us to gain a thorough understanding of the model's performance from multiple angles and perspectives\",\n",
      "            \"evaluation/comparison\": \"We compared the performance of our trained models with a dummy classifier, which is a classifier that makes random predictions. Typically, it is expected that the trained models will outperform the dummy classifier. This serves as a baseline comparison to assess the effectiveness and superiority of our trained models. By comparing the performance metrics of our models against the random predictions of the dummy classifier, we can evaluate the added value and efficacy of our trained models in making accurate predictions.\",\n",
      "            \"evaluation/availability\": \"All the trained models and corresponding performance results are available on (https://doi.org/10.5281/zenodo.8073635) under the Creative Commons - CC0 license.\",\n",
      "            \"optimization/algorithm\": \"We have utilized over 15 classification algorithms for each dataset in order to classify the classes within each datasets.\",\n",
      "            \"optimization/meta\": \"The ML pipeline employed in this project incorporates several preprocessing steps, including data resampling and feature selection. These steps are followed by model training and evaluation. To prevent any potential data leakage, we perform data preparation within cross validation folds. Additionally, we maintain an independent test dataset to ensure accurate and unbiased evaluation.\",\n",
      "            \"optimization/config\": \"We did not perform any hyperparameter tuning for the trained models. However, all the trained models and corresponding performance results are available on Zenodo (https://doi.org/10.5281/zenodo.8073635) under the Creative Commons - CC0 license.\",\n",
      "            \"optimization/encoding\": \"For the CLL patients dataset, we exclusively utilized the top 5,000 most variable mRNAs, excluding genes from the Y chromosome, as input for ML pipeline. As for the BRCA mRNA dataset, we concentrated solely on differentially expressed genes identified by edgeR, with a threshold of FDR \\u2264 0.001 and logFC > \\u00b1 2.  For the PBMC dataset, we utilized only 500 highly variable genes across the three cell populations. For all other datasets, we employed them as they were originally available without any modifications.\",\n",
      "            \"optimization/features\": \"To evaluate MLme, we utilized datasets ranging from 10 features to 5000 features. Feature selection was performed on all the datasets, but we always maintained an independent dataset solely for evaluating the model's performance. It's important to note that this independent dataset was not used for any kind of preprocessing or model training.\",\n",
      "            \"optimization/fitting\": \"We consistently maintained an independent test set for all datasets in order to evaluate the model's performance and determine if there was any overfitting or underfitting. Additionally, we employed cross-validation methods and feature selection techniques to mitigate the risk of overfitting. These measures helped ensure a more reliable assessment of the model's generalization capabilities and minimize the influence of biased or noisy data.\",\n",
      "            \"optimization/parameters\": \"The majority of the trained models were utilized with their default parameters.\",\n",
      "            \"optimization/regularization\": \"We employed cross-validation methods and feature selection techniques to mitigate the risk of overfitting. These measures helped ensure a more reliable assessment of the model's generalization capabilities and minimize the influence of biased or noisy data.\",\n",
      "            \"model/interpretability\": \"We have used multiple ML classification algorithms, some of which are black box models. For example, SVM (Support Vector Machine) is considered a black box model, but features like support vectors and feature importance can offer some interpretability. In contrast, kNN (K-Nearest Neighbors) is generally interpretable as it relies on nearest neighbors and distance metrics.\",\n",
      "            \"model/duration\": \"It is not applicable to current project.\",\n",
      "            \"model/availability\": \"The source code for MLme is available at https://github.com/FunctionalUrology/MLme with GNU GENERAL PUBLIC LICENSE.\",\n",
      "            \"dataset/provenance\": \"\\nIn this project, we utilized six different publicly available datasets that are well recognized in the domain. The first dataset consisted of mRNA data obtained from a study on Chronic Lymphocytic Leukemia (CLL) patients, measuring their transcriptome profiles. The second dataset was collected from a cervical cancer study that analyzed the expression levels of 714 miRNAs in human samples. The third and fourth datasets were obtained from The Cancer Genome Atlas (TCGA) and included mRNA and miRNA sequencing data from patients with Breast Invasive Carcinoma (BRCA). \\n  <br>\\n  <br>\\n\\n\\nThe fifth dataset consists of scRNA-seq data obtained from peripheral blood mononuclear cells (PBMCs) that were sequenced using 10\\u00d7 chromium technology. Among all the cell populations described in this study, we specifically utilized the scRNA datasets of CD8+ na\\u00efve, CD14+, and CD16+ monocytes (n=1500) with the goal of identifying distinct markers for each of these cell populations. The sixth dataset used in this study was the widely recognized Glass Identification dataset obtained from the University of California Irvine (UCI) ML repository.\\n  \\n<!DOCTYPE html>\\n<html>\\n<head>\\n<style>\\ntable {\\n  text-align: center;\\n}\\nth {\\n  text-align: center;\\n}\\n</style>\\n</head>\\n<body>\\n\\n<table>\\n\\n  <tr>\\n    <th>Dataset</th>\\n    <th>Data type</th>\\n    <th>Number of Samples</th>\\n    <th>Number of Features</th>\\n    <th>Target Class ratio</th>\\n  </tr>\\n  <tr>\\n    <td>CLL</td>\\n    <td>mRNA</td>\\n    <td>136</td>\\n    <td>5000</td>\\n    <td>Male (n=82): Female (n=54)</td>\\n  </tr>\\n  <tr>\\n    <td>Cervical cancer</td>\\n    <td>miRNA</td>\\n    <td>58</td>\\n    <td>714</td>\\n    <td>Normal (n=29): Tumor (n=29)</td>\\n  </tr>\\n  <tr>\\n    <td>TCGA-BRCA</td>\\n    <td>miRNA</td>\\n    <td>1207</td>\\n    <td>1404</td>\\n    <td>Normal (n=104): Tumor (n=1104)</td>\\n  </tr>\\n  <tr>\\n    <td>TCGA-BRCA</td>\\n    <td>mRNA</td>\\n    <td>1219</td>\\n    <td>5520</td>\\n    <td>Normal (n=113): Tumor (n=1106)</td>\\n  </tr>\\n  <tr>\\n    <td> PBMC </td>\\n    <td> scRNA-seq </td>\\n    <td>1500</td>\\n    <td>500</td>\\n    <td> CD8 Naive (n=500 cells) : CD14 Monocytes (n=500 cells) : CD16 Monocytes (n=500 cells) )</td>\\n  </tr>\\n\\n  <tr>\\n    <td>Glass Identification</td>\\n    <td>Oxide content (i.e., Na, Fe, K, etc)</td>\\n    <td>214</td>\\n    <td>10</td>\\n    <td>Glass 1 (70), Glass 2 (76), Glass 3 (17), Glass 5 (12), Glass 6 (10), Glass 7 (29)</td>\\n  </tr>\\n</table>\\n\\n</body>\\n</html>\\n\\n\",\n",
      "            \"dataset/splits\": \"We kept a separate test/validation dataset to assess the model's performance on each dataset. The initial datasets were randomly divided, but in a way that preserved proportional representation of each class in the given dataset, with 70% assigned to the training and 30% assigned to the test dataset.\",\n",
      "            \"dataset/redundancy\": \"We retained an independent dataset to evaluate the performance of the model for each dataset. The original datasets were divided randomly but in a stratified manner, with 70% allocated to the training dataset and 30% allocated to the test dataset.\",\n",
      "            \"dataset/availability\": \"The datasets we have utilized are publicly available datasets. All the relevant details can be found in the manuscript.\",\n",
      "            \"publication/title\": \"Machine Learning Made Easy (MLme): a comprehensive toolkit for machine learning\\u2013driven data analysis\",\n",
      "            \"publication/authors\": \"Akshay Akshay, Mitali Katoch, Navid Shekarchizadeh, Masoud Abedi, Ankush Sharma, Fiona C Burkhard, Rosalyn M Adam, Katia Monastyrskaya, Ali Hashemi Gheinani\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e68a561d57eb8bca69606\",\n",
      "        \"shortid\": \"z5ym87wvmo\",\n",
      "        \"uuid\": \"567d717d-1210-4ce3-92f1-effeabb4d133\",\n",
      "        \"created\": \"2024-10-15T13:05:41.358Z\",\n",
      "        \"updated\": \"2024-10-15T13:05:41.358Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"title\": \"Julearn: an easy-to-use library for leakage-free evaluation and inspection of ML models\",\n",
      "            \"authors\": \"Sami Hamdan, Shammi More, Leonard Sasse, Vera Komeyer, Kaustubh R. Patil, Federico Raimondo\",\n",
      "            \"journal\": \"GigaScience\",\n",
      "            \"year\": \"2024\",\n",
      "            \"pmid\": \"38496213\",\n",
      "            \"doi\": \"10.46471/gigabyte.113\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 6\n",
      "        },\n",
      "        \"score\": 0.74,\n",
      "        \"matches\": {\n",
      "            \"evaluation/method\": \"We used nested cross-validation. Therefore cross-validation.\",\n",
      "            \"evaluation/measure\": \"We used common sets of metrics given the literature. Names of scores refer to the in julearn used names: \\nReplication 1:  [\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_squared_error\\\",\\n    \\\"r2\\\",\\n]\\n\\nReplication 2: Performed standard training, scoring with accuracy. Reported mean age of misclassified for corrected and uncorrected models\\n\\nReplication 3:  [\\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_squared_error\\\",\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_median_absolute_error\\\",\\n    \\\"r2\\\",\\n    \\\"r_corr\\\"]\",\n",
      "            \"evaluation/comparison\": \"We do not claim any improvements over previous methods. Therefore we only performed comparisons also performed in the replicated work. \",\n",
      "            \"evaluation/confidence\": \"The replication examples were able to replicate previous work. Where needed we also show significance and measurements of confidence, i.e. Replication 1 & 2\",\n",
      "            \"evaluation/availability\": \"All code is available here:  https://github.com/juaml/julearn_paper/ (Attribution-NonCommercial-ShareAlike 4.0 International licence). This includes information about what comparisons are made and how we got to the presented results. \",\n",
      "            \"optimization/algorithm\": \"We propose software compatible with scikit-learn standard. It allows users to use any ML algorithm class compatible with that standard. \\nFurthermore, we illustrated or software using multiple examples (including 3 replications).\\nHere we used the following algorithm classes: \\nSVM, RVR, Gaussian Models and unsupervised methods like: PCA & CBPM. \\n\\nThere are no newly proposed ML algorithms.\",\n",
      "            \"optimization/meta\": \"No meta-predictions were used.\",\n",
      "            \"optimization/config\": \"This information ist included in our GitHub repository under: https://github.com/juaml/julearn_paper/ with a Attribution-NonCommercial-ShareAlike 4.0 International licence\",\n",
      "            \"optimization/encoding\": \"PCA, Z-Scoring, Feature Selection, Confound Regression\",\n",
      "            \"optimization/features\": \"All preprocessing steps including feature selection were trained only on the training set in a CV consistent way.\\nVariance thresholding was used in Replication Example 1.\\nCBPM thresholds significantly correlated features with the target and was used in Example 3.\",\n",
      "            \"optimization/fitting\": \"Our analyses are replications of previous research following there setup as we only want to show that our software is able to reproduce previous research. Therefore we know that we at least fitted as well as previous research. Overfitting was ruled out by our regigorous nested cross-validation setupts. As mentioned before we used feature selection or PCA to reduce the number of features if needed to decrease the p. \",\n",
      "            \"optimization/parameters\": \"Using notation of Hyperparameter=ListOfParameters\\nCV -> Cross-Validation\\n\\nReplication Example 1:\\nRVR 1 - using CV: kernel=[\\\"linear\\\", \\\"poly\\\"], degree=[1, 2] and Model 2 using CV: kernel=[\\\"linear\\\", \\\"rbf\\\", \\\"poly\\\"], C=[0.01, 0.1]\\n\\nReplication Example 2: \\nSVM - using CV: C=np.arange(0.1, 4, 0.2)\\n\\nReplication Example 3: \\nCBPM - using manual combinations documented in open source code: \\ncorr_signs = [\\\"pos\\\", \\\"neg\\\", \\\"posneg\\\"]\\nsignificance_threshold = [0.01, 0.05, 0.10 p]\\n\",\n",
      "            \"optimization/regularization\": \"Maninly nested cross-validation.\",\n",
      "            \"model/interpretability\": \"Models used range in their interpretabilty, but all of them are reasonably interpretable using common methods like permutation importance. Some havea direct interpretation of weights such as gaussian models. As we do not aim to gain any new evidence interpretability of the models is not relevant for this work.\",\n",
      "            \"model/output\": \"Replication 1 Models are regression \\nReplication 2 Models are classification\\nReplication 3 Models are regression\",\n",
      "            \"model/availability\": \"Yes our examples are released here: https://github.com/juaml/julearn_paper/ (Attribution-NonCommercial-ShareAlike 4.0 International licence) and the actual software is released here https://github.com/juaml/julearn (GNU Affero General Public License)\",\n",
      "            \"dataset/provenance\": \"All data we use is recognized by the community and was used by it before. As we only do replication examples our analyses and data is by design recognized. \\n\\nReplication 1 Data:   562 data points\\nReplication 2 Data:  498 data points  (291 controls, 207 after balancing)\\nReplication 3 Data: 368 data points \",\n",
      "            \"dataset/splits\": \"Replication 1: Repeated K-Fold Cross-Validation with 5 repeats and 5 equal splits (80% training)\\nReplication 2: Repeated K-Fold Cross-Validation with 60 repeats and 2 splits (50% training) following the work to be replicated\\nReplication 3: Used different cross-validation schemas for different subexperiments out of the following options: \\nLeave-One-Out (1 data point for testing) or Repeated  K-Fold Cross-Validation with 10 repeats and 10 equal splits (90% training)\\n\\nWhen applying hyperparameter tuning training is spitted using another 5 Fold Cross-Validation.\",\n",
      "            \"dataset/redundancy\": \"The splits were created using K-Fold cross-validation. This makes training and test set independent on the level of each iteration. \",\n",
      "            \"dataset/availability\": \"The data splits are created using reproducible code you can find  in our GitHub repository under: https://github.com/juaml/julearn_paper/ with a Attribution-NonCommercial-ShareAlike 4.0 International licence.\",\n",
      "            \"publication/title\": \"Julearn: an easy-to-use library for leakage-free evaluation and inspection of ML models\",\n",
      "            \"publication/authors\": \"Sami Hamdan, Shammi More, Leonard Sasse, Vera Komeyer, Kaustubh R. Patil, Federico Raimondo\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e6a0961d57eb8bca6960a\",\n",
      "        \"shortid\": \"dfyn1yvtz3\",\n",
      "        \"uuid\": \"1261ec25-2b6d-4a8a-aca6-a50c235a4737\",\n",
      "        \"created\": \"2024-10-15T13:11:37.812Z\",\n",
      "        \"updated\": \"2024-10-15T13:11:37.812Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"title\": \"Large-scale Genomic Survey with Deep Learning-based Method Reveals Strain-Level Phage Specificity Determinants\",\n",
      "            \"authors\": \"Yiyan Yang, Keith Dufault-Thompson, Wei Yan, Tian Cai, Lei Xie, Xiaofang Jiang\",\n",
      "            \"journal\": \"GigaScience\",\n",
      "            \"year\": \"2024\",\n",
      "            \"pmid\": \"38649301\",\n",
      "            \"doi\": \"10.1093/gigascience/giae017\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 6\n",
      "        },\n",
      "        \"score\": 0.7,\n",
      "        \"matches\": {\n",
      "            \"evaluation/method\": \"It was evaluated by an independent test dataset.\",\n",
      "            \"evaluation/measure\": \"Evaluation of the model on the testing dataset demonstrated an F1-score of 0.994, precision of 0.991, recall of 0.996, specificity of 1.000, a Mathew\\u2019s correlation coefficient (MCC) of 0.994, and the area under the precision-recall curve of 0.994.\",\n",
      "            \"evaluation/availability\": \"Yes. The data is accessible via GigaDB and the supplemental material.\",\n",
      "            \"optimization/algorithm\": \"This is a deep-learning model that utilizes the pre-trained transformer protein language model ESM-2 (esm2_t33_650M_UR50D) as an embedding layer. This embedding layer is then linked to a neural network comprising three fully connected layers with 1280, 568, and 2 nodes, respectively. The output layer employs a softmax activation function to produce probabilities, indicating whether each sequence corresponds to a tailspike protein or not.\",\n",
      "            \"optimization/meta\": \"This model is not a meta-predictor.\",\n",
      "            \"optimization/config\": \"Yes. The deep-learning model trained in this study is provided at https://figshare.com/articles/online_resource/SpikeHunter_trained_model_pth_file/23577051.\",\n",
      "            \"optimization/encoding\": \"Phage protein sequences were tokenized and transformed into numerical vectors using the batch_converter function in the ESM Python package (https://github.com/facebookresearch/esm).\",\n",
      "            \"optimization/features\": \"Since the sequences are embedded as 1280-length representations using a pre-trained transformer protein language model ESM-2 during training, the number of input features before embedding varies depending on the lengths of protein sequences, while the number of features after the embedding is 1280. No feature selection strategy was performed.\",\n",
      "            \"optimization/fitting\": \"The model's parameter count is approximately eight times the number of training data points. Early stopping was adopted to stop training once the model performance was no longer improved on the validation dataset for three consecutive epochs to avoid overfitting.\",\n",
      "            \"optimization/regularization\": \"Early stopping was adopted to stop training once the model performance was no longer improved on the validation dataset for three consecutive epochs to avoid overfitting.\",\n",
      "            \"model/interpretability\": \"It is a black box.\",\n",
      "            \"model/output\": \"The model is a classification that outputs probabilities to indicate whether each sequence corresponds to a tailspike protein or not.\",\n",
      "            \"model/duration\": \"3 days with two NVIDIA v100x GPUs on a high-performance computing cluster.\",\n",
      "            \"model/availability\": \"Yes, the source code is released at https://github.com/nlm-irp-jianglab/SpikeHunter.\",\n",
      "            \"dataset/provenance\": \"The source of the dataset is INfrastructure for a PHAge REference Database (INPHARED) provided by https://github.com/RyanCook94/inphared on Aug 1st, 2022. There are 3,659 bacteriophage genomes in this dataset. We curated 1912 tailspike protein sequences and 200732 non-tailspike protein sequences from this dataset. This data has not been used in previous papers.\",\n",
      "            \"dataset/splits\": \"The dataset was divided into training, validation, and testing datasets in a ratio of 3:1:1. The training set includes 122,506 proteins (comprising 1,023 positive samples and 121,483 negative samples belonging to 12,170 clusters), a validation set 40,838 proteins (comprising 343 positive samples and 40,495 negative samples belonging to 4,054 clusters), and a test set 39,300 proteins (comprising 546 positive samples and 38,754 negative samples belonging to 4,050 clusters).\",\n",
      "            \"dataset/redundancy\": \"To train and validate the SpikeHunter the manually curated set of tailspike proteins was first clustered into 20,274 clusters at 30% identity using CD-HIT. The dataset was divided into training, validation, and testing datasets in a ratio of 3:1:1 using the StratifiedGroupKFold function in the Scikit-learn python package, with two key objectives in mind: 1) ensuring the absence of overlaps among protein clusters, and 2) maintaining consistent ratios of positive to negative samples across the splits. As a result of this process, the training, validation and test sets are independent.\",\n",
      "            \"dataset/availability\": \"The data is accessible via GigaDB and the supplemental material.\",\n",
      "            \"publication/title\": \"Large-scale Genomic Survey with Deep Learning-based Method Reveals Strain-Level Phage Specificity Determinants\",\n",
      "            \"publication/authors\": \"Yiyan Yang, Keith Dufault-Thompson, Wei Yan, Tian Cai, Lei Xie, Xiaofang Jiang\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e6eef61d57eb8bca6960e\",\n",
      "        \"shortid\": \"345ml05xtn\",\n",
      "        \"uuid\": \"dfddd412-f46b-447b-8ab6-a45bfeaf37c2\",\n",
      "        \"created\": \"2024-10-15T13:32:31.707Z\",\n",
      "        \"updated\": \"2024-10-15T13:32:31.707Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"title\": \"spatiAlign: an unsupervised contrastive learning model for data integration of spatially resolved transcriptomics\",\n",
      "            \"authors\": \"Chao Zhang, Lin Liu, Ying Zhang, Mei Li, Shuangsang Fang, Qiang Kang, Ao Chen, Xun Xu, Yong Zhang, Yuxiang Li\",\n",
      "            \"journal\": \"GigaScience\",\n",
      "            \"year\": \"2024\",\n",
      "            \"pmid\": \"39028588\",\n",
      "            \"doi\": \"10.1093/gigascience/giae042\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 6\n",
      "        },\n",
      "        \"score\": 0.59,\n",
      "        \"matches\": {\n",
      "            \"evaluation/method\": \"We use different dataset to evaluate our method, which include measured by different sequencing platforms, different time-series, different regions, et al.\",\n",
      "            \"evaluation/measure\": \"F1 score of local inverse Simpson's index, adjusted rand index, Moran's I index\\nDownstream bioinformation analysis, differential expression analysis, GO enrichment analysis, trajectory inference analysis, et al.\",\n",
      "            \"evaluation/comparison\": \"benchmarking method: PRECAST, GraphST, SCALEX, Harmony, Combat, BBKNN, Scanorama, MNN\",\n",
      "            \"optimization/algorithm\": \"We first implement a self-supervised contrastive learning architecture (Deep graph infomax framework) for dimensional reduction while simultaneously propagating neighbouring spatil context between spots/cells. And we employ an across-domain adaptation technique to align joint embeddings. \",\n",
      "            \"optimization/config\": \" No\",\n",
      "            \"optimization/encoding\": \"The collected datasets were be saved as '*.h5ad' format, and also includes two-dimensional spatial coordinates for each spot/cell. The dataformat can reference: https://anndata.readthedocs.io/en/latest/  In the preprocessing step, the raw gene expression matrices were first filtered according to criteria 'min_gene' smaller than 20 and 'min_cell' smaller than 20  for each data using SCANPY (version: 1.9.1), and followed by normalization and log transformation of individual spots.  In our algorithm, spatiAlign, we just set the 'is_norm_log' to True.\",\n",
      "            \"optimization/features\": \"base on input data list, we choose common genes as input\",\n",
      "            \"optimization/parameters\": \"There are 17 instantiated model parameters. Details as follows,\\n:param data_path: List of input dataset path.\\n:param min_genes: Minimum number of genes expressed required for a cell to pass filtering, default 20.\\n:param min_cells: Minimum number of cells expressed required for a gene to pass filtering, default 20.\\n:param batch_key: The batch annotation to :attr:`obs` using this key, default, 'batch'.\\n:param is_norm_log: Whether to perform 'sc.pp.normalize_total' and 'sc.pp.log1p' processing, default, True.\\n:param is_scale: Whether to perform 'sc.pp.scale' processing, default, False.\\n:param is_hvg: Whether to perform 'sc.pp.highly_variable_genes' processing, default, False.\\n:param is_reduce: Whether to perform PCA reduce dimensional processing, default, False.\\n:param n_pcs: PCA dimension reduction parameter, valid when 'is_reduce' is True, default, 100.\\n:param n_hvg: 'sc.pp.highly_variable_genes' parameter, valid when 'is_reduce' is True, default, 2000.\\n:param n_neigh: The number of neighbors selected when constructing a spatial neighbor graph. default, 15.\\n:param is_undirected: Whether the constructed spatial neighbor graph is undirected graph, default, True.\\n:param latent_dims: The number of embedding dimensions, default, 100.\\n:param is_verbose: Whether the detail information is print, default, True.\\n:param seed: Random seed.\\n:param gpu: Whether the GPU device is using to train spatialign.\\n:param save_path: The path of alignment dataset and saved spatialign.\\n\\nThere are 7 training model parameters. Details as follows,\\n:param lr: Learning rate, default, 1e-3.\\n:param max_epoch: The number of maximum epochs, default, 500.\\n:param alpha: The momentum parameter, default, 0.5\\n:param patient: Early stop parameter, default, 15.\\n:param tau1: Instance level and pseudo prototypical cluster level contrastive learning parameters, default, 0.2\\nparam tau2: Pseudo prototypical cluster entropy parameter, default, 1.\\n:param tau3: Cross-batch instance self-supervised learning parameter, default, 0.5\\n\",\n",
      "            \"optimization/regularization\": \"early stopping\",\n",
      "            \"model/interpretability\": \"early stopping\",\n",
      "            \"model/output\": \"No, our model output a latent embedding and reconstructed representation, respectively.\",\n",
      "            \"model/duration\": \"base on the input dataset\",\n",
      "            \"model/availability\": \"github1: https://github.com/zhangchao162/Spatialign.git github2: https://github.com/STOmics/Spatialign.git pypi: https://pypi.org/project/spatialign/ tutorial: https://spatialign-tutorials.readthedocs.io/en/latest/index.html\",\n",
      "            \"dataset/splits\": \"We did not split the data and used all datasets for model training and testing.\",\n",
      "            \"dataset/availability\": \"Yes\\n1. Mouse olfactory bulb: \\na. The 10x Geomics Visium dataset can be download from: https://www.10xgenomics.com/resources/datasets/adult-mouse-olfactory-bulb-1-standard-1\\nb. The Stereo-seq datasets can be download from: https://db.cngb.org/stomics/mosta/download/\\n2. Human dorsolateral prefrontal cortex (DLPFC): the 10x Geomics Visium dataset and annotation file can be download from: https://zenodo.org/record/6925603#.YuM5WXZBwuU\\n3. Mouse hippocampal dataset: the Slide-seq datasets can be download from: https://singlecell.broadinstitute.org/single_cell/study/SCP815/highly-sensitive-spatial-transcriptomics-at-near-cellular-resolution-with-slide-seqv2#study-summary, https://singlecell.broadinstitute.org/single_cell/study/SCP354/slide-seq-study#study-summary, and https://singlecell.broadinstitute.org/single_cell/study/SCP948/robust-decomposition-of-cell-type-mixtures-in-spatial-transcriptomics#study-summary, respectively.\\n4. Mouse embryonic brain: the Stereo-seq datasets can be download from: https://db.cngb.org/stomics/mosta/download/\",\n",
      "            \"publication/title\": \"spatiAlign: an unsupervised contrastive learning model for data integration of spatially resolved transcriptomics\",\n",
      "            \"publication/authors\": \"Chao Zhang, Lin Liu, Ying Zhang, Mei Li, Shuangsang Fang, Qiang Kang, Ao Chen, Xun Xu, Yong Zhang, Yuxiang Li\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e70a761d57eb8bca69612\",\n",
      "        \"shortid\": \"iv50u2ycn5\",\n",
      "        \"uuid\": \"49b4a023-592f-4a04-bad2-827e519896e0\",\n",
      "        \"created\": \"2024-10-15T13:39:51.375Z\",\n",
      "        \"updated\": \"2024-10-15T13:39:51.375Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"title\": \"Omada: robust clustering of transcriptomes through multiple testing\",\n",
      "            \"authors\": \"Sokratis Kariotis, Pei Fang Tan, Haiping Lu, Christopher J Rhodes, Martin R Wilkins, Allan Lawrie, Dennis Wang\",\n",
      "            \"journal\": \"GigaScience\",\n",
      "            \"year\": \"2024\",\n",
      "            \"pmid\": \"38991852\",\n",
      "            \"doi\": \"10.1093/gigascience/giae039\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 0\n",
      "        },\n",
      "        \"score\": 0.95,\n",
      "        \"matches\": {\n",
      "            \"evaluation/method\": \"Independent dataset.\",\n",
      "            \"evaluation/measure\": \"As this is unsupervised learning the performance was justified biologically.\",\n",
      "            \"evaluation/comparison\": \"There are no methods that address the same questions. \",\n",
      "            \"evaluation/confidence\": \"The statistical significance was calculated based on biological differences and not ML metrics. \",\n",
      "            \"evaluation/availability\": \"No, but the p-values of the biological validation can be found in https://www.nature.com/articles/s41467-021-27326-0.\",\n",
      "            \"optimization/algorithm\": \"Three (unsupervised) widely-used clustering algorithms were used: spectral, k-means and hierarchical. \",\n",
      "            \"optimization/meta\": \"The input does not consist of other ML algorithm results.\",\n",
      "            \"optimization/encoding\": \"The data were in numeric form representing gene counts (FPKM or TPM depeding on the dataset). The processing consists of arcise transformation.\",\n",
      "            \"optimization/features\": \"Each dataset used a different number of features ranging from 100 to 25,955. Feature selection was performed as a step of Omada using the average cluster stability for different feature subsets after they were ranked by expression variance.\",\n",
      "            \"optimization/fitting\": \"This was unsupervised learning.\",\n",
      "            \"optimization/parameters\": \"In this model, Spectral and k-means clustering allows one parameter (kernel) and hierarchical allows 2 parameters (distance measure and linkage). These parameters were selected to as they provide the most influence towards the clustering results.\",\n",
      "            \"optimization/regularization\": \"This was unsupervised learning.\",\n",
      "            \"model/interpretability\": \"Black box.\",\n",
      "            \"model/output\": \"Unsupervised clustering.\",\n",
      "            \"model/duration\": \"Under a minute for a dataset for few hundred datapoints/features.\",\n",
      "            \"model/availability\": \"The source code can be found: https://github.com/BioSok/omada and is also published as a package in https://www.bioconductor.org/packages/release/bioc/html/omada.html.\",\n",
      "            \"dataset/provenance\": \"Single-class simulated dataset: Simulated by using specific mean and standard deviation. This dataset only contains one class. The dataset hasn't been used before as it was generated from one of Omada's functions.\\n\\nMulti-class simulated dataset: Simulated by using specific means and standard deviations. This dataset contains five classes of almost identical sizes (72,72,72,72,71). The dataset hasn't been used before as it was generated from one of Omada's functions.\\n\\nPan-cancer dataset:  Sourced from https://pubmed.ncbi.nlm.nih.gov/32025007/ and contains 3 classes: Breast cancer found in https://www.cbioportal.org/study/summary?id=brca_tcga_pan_can_atlas_2018, Colorectal cancer found in https://www.cbioportal.org/study/summary?id=coadread_tcga_pan_can_atlas_2018 and Lung cancer found in https://www.cbioportal.org/study/summary?id=luad_tcga_pan_can_atlas_2018. These data have been used in several publications and are widely used for cancer studies.\\n\\nPAH dataset: The transcriptomic data can be found in the EGA (the European Genome-phenome Archive) database under accession code EGAS000010055326562 (https://ega-archive.org/studies/EGAS00001005532) . Restricted access, needs application. This dataset has no defined classes. It has been used by https://www.nature.com/articles/s41467-021-27326-0.\\n\\nGUSTO dataset: This dataset can be found in the GEO database with accession number GSE182409. There are no classes.\",\n",
      "            \"dataset/splits\": \"Single-class simulated dataset: The dataset contains 100 datapoints. No test set as this was used for unsupervised learning methods.\\n\\nMulti-class simulated dataset: The dataset contains 359 datapoints. No test set as this was used for unsupervised learning methods.\\n\\nPan-cancer dataset:  Each of the three classes have the following datapoints: breast (n=1084), lung (n=566) and colorectal (n=594). No test set as this was used for unsupervised learning methods.\\n\\nPAH dataset: The dataset contains 359 datapoints. No test set as this was used for unsupervised learning methods.\\n\\nGUSTO dataset: The dataset contains 238 datapoints. No test set as this was used for unsupervised learning methods.\",\n",
      "            \"dataset/redundancy\": \"No test sets for any dataset.\",\n",
      "            \"dataset/availability\": \"Single-class simulated dataset: Yes, published on https://github.com/BioSok/OmadaSimulatedDatasets. \\n\\nMulti-class simulated dataset: Yes, published on https://github.com/BioSok/OmadaSimulatedDatasets. \\n\\nPan-cancer dataset: These is public data and the Breast cancer found in https://www.cbioportal.org/study/summary?id=brca_tcga_pan_can_atlas_2018, Colorectal cancer found in https://www.cbioportal.org/study/summary?id=coadread_tcga_pan_can_atlas_2018 and Lung cancer found in https://www.cbioportal.org/study/summary?id=luad_tcga_pan_can_atlas_2018.\\n\\nPAH dataset: The data can be found in the EGA (the European Genome-phenome Archive) database under accession code EGAS000010055326562 (https://ega-archive.org/studies/EGAS00001005532) . Restricted access, needs application.\\n\\nGUSTO dataset: The data can be found in the GEO database with accession number GSE182409.\",\n",
      "            \"publication/title\": \"Omada: robust clustering of transcriptomes through multiple testing\",\n",
      "            \"publication/authors\": \"Sokratis Kariotis, Pei Fang Tan, Haiping Lu, Christopher J Rhodes, Martin R Wilkins, Allan Lawrie, Dennis Wang\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e716961d57eb8bca69616\",\n",
      "        \"shortid\": \"4y1myuozde\",\n",
      "        \"uuid\": \"bf403e75-6baf-4278-bf96-1469c78c65e0\",\n",
      "        \"created\": \"2024-10-15T13:43:05.591Z\",\n",
      "        \"updated\": \"2024-10-15T13:43:05.591Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"title\": \"MOBFinder: a tool for MOB typing for plasmid metagenomic fragments based on language model\",\n",
      "            \"authors\": \"Tao Feng, Shufang Wu, Hongwei Zhou, and Zhencheng Fang\",\n",
      "            \"journal\": \"GigaScience\",\n",
      "            \"year\": \"2024\",\n",
      "            \"pmid\": \"39101782\",\n",
      "            \"doi\": \"10.1093/gigascience/giae047\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 6\n",
      "        },\n",
      "        \"score\": 0.74,\n",
      "        \"matches\": {\n",
      "            \"evaluation/method\": \"Independent dataset.\",\n",
      "            \"evaluation/measure\": \"This tool uses F1 score, balanced accuracy, harmonic mean, and AUC to evaluate the model. These metrics are commonly used in other similar algorithms, such as PPR-Meta and PlasTrans.\",\n",
      "            \"evaluation/comparison\": \"As there are currently no benchmark datasets for metagenomic plasmid assembly fragments, this study constructed one from scratch and compared it with existing tools like MOB-suite and MOBscan.\",\n",
      "            \"evaluation/confidence\": \"The evaluation metrics used in this study range from 0 to 1, with 0 indicating the lowest performance and 1 indicating the highest. MOBFinder's performance surpasses existing tools significantly, with an overall accuracy at least 59% higher than MOB-suite and at least 61% higher than MOBscan.\",\n",
      "            \"evaluation/availability\": \" The evaluation script for this tool will be uploaded to the relevant database after the article is published. You can access the MOBFinder tool from Github: https://github.com/FengTaoSMU/MOBFinder.\",\n",
      "            \"optimization/algorithm\": \"The machine learning algorithms used in this study are the Skip-gram language model and Random Forest. Both of these methods are well-known in machine learning. Currently, methods used for MOB typing annotation rely on relaxase-based approaches such as MOB-suite and MOBscan. However, in metagenomic plasmid assembly fragments, relaxase sequences are often missing or incomplete. As a result, most plasmid assembly fragments are annotated as non-transferable plasmids. Due to differences in sequence features and host range among different MOB types, this study utilized the Skip-gram language model to digitally encode the biological patterns and features of metagenomic plasmid assembly fragments, resulting in significant performance improvements for MOBFinder. With a training dataset of up to 990,000 entries, Random Forest was used to prevent overfitting in training the MOB classification models. The combined use of these two algorithms effectively enhanced the performance of predicting MOB types in metagenomic plasmid assembly fragments. In some cases, F1 and AUC scores reached as high as 0.99, almost perfect.\",\n",
      "            \"optimization/config\": \"According to our test results, MOBFinder takes approximately 5 to 18 minutes to predict on the test set, depending on the length and quantity of input data.\",\n",
      "            \"optimization/encoding\": \"1. In word vector training, this study generated overlapping \\\"words\\\" of 4-mers from plasmid genomes and assigned a random numeric vector to each unique \\\"word\\\". These vectors were then inputted into a two-layer neural network for training, learning the probability of occurrence of 10 preceding and succeeding \\\"words\\\". The two-layer neural network consists of a hidden layer with 100 neurons. Finally, 100-dimensional word vectors corresponding to 256 DNA 4-mer \\\"words\\\" were outputted. 2. Training of the MOB classification model: This study utilized known relaxases of MOB types to perform MOB typing on plasmid genomes, selecting plasmid genomes with confirmed MOB types based on their scores to construct benchmark datasets. For each MOB type of plasmid genome, the training and testing sets were divided in a 7:3 ratio. The training set for each MOB type randomly generated 90,000 simulated metagenomic plasmid assembly fragments, while the testing set for each MOB type randomly generated 500 simulated metagenomic plasmid assembly fragments. All fragments were encoded using the generated 4-mer word vectors, with the average 100-dimensional word vector calculated as input for training the Random Forest model.\",\n",
      "            \"optimization/features\": \"This tool did not conduct feature selection; instead, it used 100 word vector features trained by the skip-gram model as input.\",\n",
      "            \"optimization/fitting\": \"The number of each MOB type in the training dataset is the same, and random forest was used to prevent overfitting.\",\n",
      "            \"optimization/parameters\": \"1. The skip-gram model consists of two layers of neural networks: a hidden layer and an output layer, with 100 neurons in the hidden layer. For each input 4-mer \\\"word\\\", it predicts the probability of occurrence of 10 preceding and succeeding words in its context.\\n2. The random forest model uses 500 trees.\",\n",
      "            \"optimization/regularization\": \"Random forest.\",\n",
      "            \"model/interpretability\": \"Black box.\",\n",
      "            \"model/duration\": \"According to our test results, MOBFinder takes approximately 5 to 18 minutes to predict on the test set, depending on the length and quantity of input data.\",\n",
      "            \"model/availability\": \"The source code of this tool will be uploaded to the corresponding database after the article is published. You can access the MOBFinder tool from Github: https://github.com/FengTaoSMU/MOBFinder.\",\n",
      "            \"dataset/provenance\": \"All plasmid genomes were downloaded from NCBI database.\",\n",
      "            \"dataset/splits\": \"When training plasmid DNA word vectors based on the Skip-gram language model, MOBFinder utilized a total of 37,139 plasmid genomes. For training the four MOB classification models, this study obtained the complete plasmid genomes from the NCBI database again and annotated them with MOB typing using the relaxase database. Subsequently, 67,925 plasmid genomes determined by MOB typing were used to simulate plasmid assembly fragments from metagenomic datasets for training the MOB classification models\",\n",
      "            \"dataset/redundancy\": \"When training the four MOB classification models suitable for different length ranges, the training and testing sets were randomly split in a 7:3 ratio. There was no overlap between the training and testing sets; they were independent of each other.\",\n",
      "            \"dataset/availability\": \"The training script and test data for this article will be uploaded to the website's database after publication. Currently, you can use and view the MOBFinder tool on Github: https://github.com/MOBFinder\",\n",
      "            \"publication/title\": \"MOBFinder: a tool for MOB typing for plasmid metagenomic fragments based on language model\",\n",
      "            \"publication/authors\": \"Tao Feng, Shufang Wu, Hongwei Zhou, and Zhencheng Fang\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e76ea61d57eb8bca6961b\",\n",
      "        \"shortid\": \"zn00kk9s7i\",\n",
      "        \"uuid\": \"440c11f3-f064-40d7-9b1d-5d29591896b4\",\n",
      "        \"created\": \"2024-10-15T14:06:34.688Z\",\n",
      "        \"updated\": \"2024-11-14T16:33:58.724Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"title\": \"Deepdefense: annotation of immune systems in prokaryotes using deep learning \",\n",
      "            \"authors\": \"Sven Hauns, Omer S Alkhnbashi, Rolf Backofen\",\n",
      "            \"journal\": \"GigaScience\",\n",
      "            \"year\": \"2024\",\n",
      "            \"pmid\": \"39388605\",\n",
      "            \"doi\": \"10.1093/gigascience/giae062\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 6,\n",
      "            \"created\": \"\"\n",
      "        },\n",
      "        \"score\": 0.78,\n",
      "        \"matches\": {\n",
      "            \"evaluation/method\": \"We use cross-validation and ensure the independence of our training/test dataset using BLAST.\",\n",
      "            \"evaluation/measure\": \"We supply representative metrics ROC-AUC and AUPRC togther with BLAST allignment scores, aswell as classification scores for single classes.\",\n",
      "            \"evaluation/comparison\": \"We compare our method to PADLOC on a set of phages, bacteria and archea.\",\n",
      "            \"evaluation/confidence\": \"The confidence of the class assignments is discussed in the publication. Additional wet-lab experiments will be needed to verify the quality.\",\n",
      "            \"evaluation/availability\": \"Additional evaluation files are part of the gigascience database.\",\n",
      "            \"optimization/algorithm\": \"To optimize our algorithm we choose BOHB (bayesian optimization with hyperband)*\\n\\n*Falkner S, Klein A, Hutter F. BOHB: Robust and Efficient Hyperparameter Optimization at Scale. CoRR 2018;abs/1807.01774.http://arxiv.org/abs/1807.01774.\",\n",
      "            \"optimization/meta\": \"does not use a meta-predictor\",\n",
      "            \"optimization/config\": \"Details of the optimization schedule and hyperparameter configurations can be found in the publication.\",\n",
      "            \"optimization/encoding\": \"data was encoded in a one-hot-vector fashion using the aminoacids of the protein\",\n",
      "            \"optimization/features\": \"The input consists primarily of the proteins, ecnoded in a one-hot fashion, additionally we supply information characterizing any proteins as used by a previous publication. No further feature selection was performed.\",\n",
      "            \"optimization/fitting\": \"Overfitting was controlled by using a validation set with an early stopping procedure. \",\n",
      "            \"optimization/parameters\": \"The current deeplearning model has roughly 11700000 learnable parameter. The size of the model was subject of the optimization processed and hence also optimized. \",\n",
      "            \"optimization/regularization\": \"We use early stopping using a validation set to prevent overfitting. Additionally a dropout rate was discovered using the described optimization mechanism. \",\n",
      "            \"model/interpretability\": \"The model is mostly a black box model. The output of the model is more interpretable than it would usually be the case, since we make use of methods to increase the model calibration.\",\n",
      "            \"model/duration\": \"On an older laptop (cpu run only, Intel(R) Core(TM) i5-8350U CPU @ 1.70GHz) after first loading the model a simple prediction can be made in 0.60 seconds.\",\n",
      "            \"model/availability\": \"The source code can be found in our github repro under the free MIT licence: https://github.com/SvenHauns/Deepdefense\",\n",
      "            \"dataset/provenance\": \"Our dataset consists of 21196 unique validated samples available due to a previous publication*. The dataset we used was imbalanced for types, consisting of 1263 Durantia samples, 3723 Gajiba samples,1529 Hachiman samples, 6882 Wadjet samples, 637 Lamassu samples, 2807 Septu samples, 647 Shedu samples, 1097 Thoeris samples, 745 Kiwa samples, 1866 Zorya samples. Hence there were only roughly one-tenth of the samples of Lamassu than for Wadjet.  \\n\\n* Doron S, Melamed S, Ofir G, Leavitt A, Lopatina A,Keren M, et al. Systematic discovery of antiphage defense systems in the microbial pangenome. Science 2018;359(6379):eaar4120. https://www.science.org/doi/abs/10.1126/science.aar4120.\",\n",
      "            \"dataset/splits\": \"We separate our dataset in a stratified training, test, and validation split, using a 10-fold CV split to ensure enough training data samples are available for subclasses with few samples.\",\n",
      "            \"dataset/redundancy\": \"Training and test set were insured to be independent, by controlling for sequence homology using BLAST.\",\n",
      "            \"dataset/availability\": \"The data is available following the original publication*. \\n\\n* Doron S, Melamed S, Ofir G, Leavitt A, Lopatina A,Keren M, et al. Systematic discovery of antiphage defense systems in the microbial pangenome. Science 2018;359(6379):eaar4120. https://www.science.org/doi/abs/10.1126/science.aar4120.\",\n",
      "            \"publication/title\": \"Deepdefense: annotation of immune systems in prokaryotes using deep learning \",\n",
      "            \"publication/authors\": \"Sven Hauns, Omer S Alkhnbashi, Rolf Backofen\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e781961d57eb8bca6961f\",\n",
      "        \"shortid\": \"2bpmmu8yav\",\n",
      "        \"uuid\": \"19954d39-0d13-4f99-9e5d-0624ccd5b638\",\n",
      "        \"created\": \"2024-10-15T14:11:37.681Z\",\n",
      "        \"updated\": \"2024-10-15T14:11:37.681Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"title\": \"Deep learning links localized digital pathology phenotypes with transcriptional subtype and patient outcome in glioblastoma\",\n",
      "            \"authors\": \"Thomas Roetzer-Pejrimovsky, Karl-Heinz Nenning, Barbara Kiesel, Johanna Klughammer, Martin Rajchl, Bernhard Baumann, Georg Langs, Adelheid Woehrer\",\n",
      "            \"journal\": \"GigaScience\",\n",
      "            \"year\": \"2024\",\n",
      "            \"pmid\": \"39185700\",\n",
      "            \"doi\": \"https://doi.org/10.1093/gigascience/giae057\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 6\n",
      "        },\n",
      "        \"score\": 0.78,\n",
      "        \"matches\": {\n",
      "            \"evaluation/method\": \"5-fold CV and independent external test dataset\",\n",
      "            \"evaluation/measure\": \"For prediction of the transcriptional subtype: accuracy, AUC.\\nFor prediction of the survival: median overall survial and logrank test after groupint into high-risk and low-risk groups.\",\n",
      "            \"evaluation/comparison\": \"NA / no benchmark datasets available.\",\n",
      "            \"evaluation/confidence\": \"NA / no other methods for comparison available\",\n",
      "            \"evaluation/availability\": \"Evaluation results are covered in the manuscript. the Model output for the external TCGA validation dataset is available via the github page: https://github.com/tovaroe/GBMatch_CNN (GPL 3.0)\",\n",
      "            \"optimization/algorithm\": \"We used a pre-trained Xception CNN as the backbone with an additional layer for TS/survival prediction and fine-tuning.\",\n",
      "            \"optimization/meta\": \"Not applicable\",\n",
      "            \"optimization/config\": \"Available via the github-page in the config.py (https://github.com/tovaroe/GBMatch_CNN)\",\n",
      "            \"optimization/encoding\": \"Image tiles were used as input for the ML algorithm, the preprocessing was performed according to the keras implementation of the Xception model.\",\n",
      "            \"optimization/features\": \"Image tiles (512x512 px) were used as input, no additional feature selection was performed.\",\n",
      "            \"optimization/fitting\": \"Overfitting/Underfitting was ruled out by keeping track of the validation set error in 5-fold-CV during hyperparameter selection; And by fixing the pre-trained model parameters and only fine-tuning the last few layers.\",\n",
      "            \"optimization/parameters\": \"No additional parameters werde set in the pre-trained Xception model. For prediction of survival, a 1-neuron layer was added as the ultimate layer, and for prediction of the transcriptional subtype, a 3-neuron layer was added.\",\n",
      "            \"optimization/regularization\": \"Dropout (0.25)\",\n",
      "            \"model/interpretability\": \"The model is semi-interpretable. While the prediction of single image tiles is a black box, the mapping of tile prediction onto the whole slide scans allows for interpretability (discussed extensively in the manuscript).\",\n",
      "            \"model/duration\": \"Depending on the slide scan size, a single prediction requires a few minutes on a workstation desktop PC.\",\n",
      "            \"model/availability\": \"The source code is released via github: https://github.com/tovaroe/GBMatch_CNN (GPL 3.0)\",\n",
      "            \"dataset/provenance\": \"The training data is derived from the publication \\\"The DNA methylation landscape of glioblastoma disease progression shows extensive heterogeneity in time and space\\\" (https://doi.org/10.1038/s41591-018-0156-x) and contains a total of 276 cases, 189 of which have information on the transcriptional subtype.\\n\\n\",\n",
      "            \"dataset/splits\": \"For model selection, the above mentioned 276 or 189 cases, respectively, were split into 5 equally sized fold for 5-fold CV, with similar distribution of transcriptional subtypes and survival, respectively.\\n\\nThe external validation data is derived from TCGA, consists of 178 cases and can be accessed via cBioPortal (https://www.cbioportal.org) and/or the GDC Data Portal (https://portal.gdc.cancer.gov). In contrast to the training dataset, the transcriptional subtypes were determined by RNAseq, but the overall distribution is similar, albeit with slightly more classical cases and fewer mesenchymal cases. Due to the strict selection critera for the study underlying the training dataset, the overall survival in the TCGA dataset was slightly lower.\",\n",
      "            \"dataset/redundancy\": \"The external validation set is completely independent, as it is derived from TCGA.\",\n",
      "            \"dataset/availability\": \"The splits for the training data are published in the corresponding github repository (https://github.com/tovaroe/GBMatch_CNN, GPL 3.0).\",\n",
      "            \"publication/title\": \"Deep learning links localized digital pathology phenotypes with transcriptional subtype and patient outcome in glioblastoma\",\n",
      "            \"publication/authors\": \"Thomas Roetzer-Pejrimovsky, Karl-Heinz Nenning, Barbara Kiesel, Johanna Klughammer, Martin Rajchl, Bernhard Baumann, Georg Langs, Adelheid Woehrer\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e790061d57eb8bca69627\",\n",
      "        \"shortid\": \"09r03h9clm\",\n",
      "        \"uuid\": \"d77983e0-5279-4379-b608-8032a2990b09\",\n",
      "        \"created\": \"2024-10-15T14:15:28.964Z\",\n",
      "        \"updated\": \"2024-10-15T14:15:28.964Z\",\n",
      "        \"public\": true,\n",
      "        \"publication\": {\n",
      "            \"title\": \"PhageGE: An interactive web-based R shiny application for exploratory analysis and visualisation of bacteriophage genomes\",\n",
      "            \"authors\": \"Jinxin Zhao1, 2 *, Jiru Han3, Yu-Wei Lin1, Yan Zhu1, 4, Michael Aichem5, Dimitar Garkov5, Phillip J. Bergen1, Sue C. Nang1, Jian-Zhong Ye6, 7, Tie-Li Zhou6, 7, Tony Velkov8, Jiang-Ning Song2, 9, Falk Schreiber5, 10, Jian Li1, 2*\",\n",
      "            \"journal\": \"GigaScience\",\n",
      "            \"year\": \"2024\",\n",
      "            \"pmid\": \"39320317\",\n",
      "            \"doi\": \"10.1093/gigascience/giae074\",\n",
      "            \"done\": 0,\n",
      "            \"skip\": 6\n",
      "        },\n",
      "        \"score\": 0.78,\n",
      "        \"matches\": {\n",
      "            \"evaluation/method\": \"Cross-validation, independent dataset\",\n",
      "            \"evaluation/measure\": \"Our manuscript include the comparison of the performance of PhageGE and other methods.\",\n",
      "            \"evaluation/comparison\": \"Our manuscript include the comparison of the performance of PhageGE and other methods.\",\n",
      "            \"evaluation/confidence\": \"We do provided classification accuracy of each compared method across both the training and test datasets. Based on the comparison, the performance of phageGE is superior to others. \",\n",
      "            \"evaluation/availability\": \"We shared the benchmark dataset in the phageGE github under the example data folder.\",\n",
      "            \"optimization/algorithm\": \"Random forest classifier \",\n",
      "            \"optimization/config\": \"Data and related files for the development of final model have been shared in phageGE github (https://github.com/JinxinMonash/PhageGE/tree/main/Example%20data)\",\n",
      "            \"optimization/encoding\": \"Conserved Domain Database (11/2023) for protein domains that mechanistically involved in lysogeny were collected and manually curated. In the meantime, each genome sequence in the training set, a list of all possible 6-frame translation sequences for all genomes were generated with rhmmer package. \",\n",
      "            \"optimization/features\": \"477 features (protein domains) were collected initially. Testing set was not used for feature selection, pre-processing steps or parameter tuning.\",\n",
      "            \"optimization/fitting\": \"We optimised the initial data collection (from CDD) strategy to limit the possibility of over-fitting. We also performed the comparison of the incorrect predictions of training and testing.\",\n",
      "            \"optimization/parameters\": \"\\u2018bootstrap\\u2019 (True, False), \\u2018class_weight\\u2019 (balanced, balanced_subsample), \\u2018min_samples_leaf\\u2019 , \\u2018n_estimators\\u2019 , and \\u2018max_depth\\u2019. \\nGridSearchCV were used to evaluate all possible parameters or their combinations.\\n\",\n",
      "            \"optimization/regularization\": \"We limited the amount of initial features (protein domains from CDD) from the data collection.\",\n",
      "            \"model/interpretability\": \"Black box \",\n",
      "            \"model/duration\": \"Seconds on HPC cluster\",\n",
      "            \"model/availability\": \"Yes, the source code is released in the PhageGE github page. And it has been incorporated in our phageGE webserver.\",\n",
      "            \"dataset/provenance\": \"The dataset was selected from Mavrich, T., Hatfull, G. Bacteriophage evolution differs by host, lifestyle and genome. Nat Microbiol 2, 17112 (2017). There are 604 positive (temperate) and 453 negative cases (lytic) for the whole dataset. \",\n",
      "            \"dataset/splits\": \"634 genomes were included in the training set while 423 genomes were included in the test set. We applied cross-validation to tune model hyper-parameters, where the training set was randomly split into individual training and validation sets.\",\n",
      "            \"dataset/redundancy\": \"The training and test sets are independent using a 60:40 split.\",\n",
      "            \"dataset/availability\": \"Yes, all the data are released in the PhageGE github example data (https://github.com/JinxinMonash/PhageGE/tree/main/Example%20data).\",\n",
      "            \"publication/title\": \"PhageGE: An interactive web-based R shiny application for exploratory analysis and visualisation of bacteriophage genomes\",\n",
      "            \"publication/authors\": \"Jinxin Zhao1, 2 *, Jiru Han3, Yu-Wei Lin1, Yan Zhu1, 4, Michael Aichem5, Dimitar Garkov5, Phillip J. Bergen1, Sue C. Nang1, Jian-Zhong Ye6, 7, Tie-Li Zhou6, 7, Tony Velkov8, Jiang-Ning Song2, 9, Falk Schreiber5, 10, Jian Li1, 2*\"\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# 2. Produce DOME Registry contents metadata .csv file and data visualisation\n",
    "import json\n",
    "\n",
    "# 2.1 Visualise and check the contents of the downloaded json file as print out\n",
    "\n",
    "# Function to read and pretty-print the JSON file sample entry\n",
    "def pretty_print_json(file_name):\n",
    "    try:\n",
    "        # Open and read the JSON file\n",
    "        with open(file_name, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # Pretty-print the JSON data\n",
    "        print(json.dumps(data, indent=4))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the JSON file: {e}\")\n",
    "\n",
    "# Call the function to pretty-print the JSON file\n",
    "pretty_print_json(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened JSON data saved to 'flattened_DOME_Registry_Contents.json'\n",
      "[\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b5c\",\n",
      "        \"publication_pmid\": \"16524483\",\n",
      "        \"publication_updated\": \"01/28/2022 00:13:56\",\n",
      "        \"publication_authors\": \"Wang H, Zheng H, Simpson D, Azuaje F\",\n",
      "        \"publication_journal\": \"BMC Bioinformatics\",\n",
      "        \"publication_title\": \"Machine learning approaches to supporting the identification of photoreceptor-enriched genes based on expression data.\",\n",
      "        \"publication_doi\": \"10.1186/1471-2105-7-116\",\n",
      "        \"publication_year\": \"2006\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"66a94333-8cd1-499c-86ef-0497a4c4dabc\",\n",
      "        \"shortid\": \"6i0xepuivt\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches_publication/updated\": \"01/28/2022 00:13:56\",\n",
      "        \"matches_publication/authors\": \"Wang H, Zheng H, Simpson D, Azuaje F\",\n",
      "        \"matches_publication/journal\": \"BMC Bioinformatics\",\n",
      "        \"matches_publication/title\": \"Machine learning approaches to supporting the identification of photoreceptor-enriched genes based on expression data.\",\n",
      "        \"matches_optimization/algorithm\": \"ensemble decision tree model\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/method\": \"five-fold cross-validation\",\n",
      "        \"matches_dataset/availability\": \"yes, https://www.nature.com/articles/s41467-019-12812-3#Sec24\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b93\",\n",
      "        \"publication_pmid\": \"17374164\",\n",
      "        \"publication_updated\": \"03/09/2022 10:14:51\",\n",
      "        \"publication_authors\": \"Al-Shahib A, Breitling R, Gilbert DR\",\n",
      "        \"publication_journal\": \"BMC Genomics\",\n",
      "        \"publication_title\": \"Predicting protein function by machine learning on amino acid sequences--a critical evaluation.\",\n",
      "        \"publication_doi\": \"10.1186/1471-2164-8-78\",\n",
      "        \"publication_year\": \"2007\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"147ddf2b-6b53-4335-b62f-87994d284310\",\n",
      "        \"shortid\": \"nlj5x3dld8\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches_publication/updated\": \"03/09/2022 10:14:51\",\n",
      "        \"matches_publication/authors\": \"Al-Shahib A, Breitling R, Gilbert DR\",\n",
      "        \"matches_publication/journal\": \"BMC Genomics\",\n",
      "        \"matches_publication/title\": \"Predicting protein function by machine learning on amino acid sequences--a critical evaluation.\",\n",
      "        \"matches_optimization/algorithm\": \"Two stage neural network approach\",\n",
      "        \"matches_optimization/features\": \"672 features\",\n",
      "        \"matches_optimization/fitting\": \"Newly crystallized proteins should avoid overfitting \",\n",
      "        \"matches_optimization/meta\": \"Yes, combination of different alignments  tested on independent datasets\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"Classification prediction of residue contact.\",\n",
      "        \"matches_evaluation/comparison\": \"Performance achieved with methods based on automatic multiple sequence alignment calculation\",\n",
      "        \"matches_evaluation/measure\": \"Precision as a function of effective aligned sequences\",\n",
      "        \"matches_evaluation/method\": \"Independent dataset form CASP11\",\n",
      "        \"matches_dataset/availability\": \"Casp 11 website (https://predictioncenter.org/casp11/index.cgi)\",\n",
      "        \"matches_dataset/redundancy\": \"Not assessed. In principle de novo protein structure prediction experiments should involve protein with no similarity with those in public available databases\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"66030aaa1502715bfe53d65c\",\n",
      "        \"uuid\": \"600b20de-7c70-41af-ad39-33121af090ef\",\n",
      "        \"created\": \"2024-03-26T17:49:30.048Z\",\n",
      "        \"updated\": \"2024-03-26T17:49:30.048Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"17888165\",\n",
      "        \"publication_authors\": \"Hui Lan, Rachel Carson , Nicholas J Provart and Anthony J Bonner\",\n",
      "        \"publication_journal\": \"BMC Bioinformatics\",\n",
      "        \"publication_title\": \"Combining classifiers to predict gene function in Arabidopsis thaliana using large-scale gene expression measurements\",\n",
      "        \"publication_doi\": \"10.1186/1471-2105-8-358\",\n",
      "        \"publication_year\": \"2007\",\n",
      "        \"shortid\": \"ysqyy92zyr\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches_evaluation/comparison\": \"no comparison with other approaches perfomed\",\n",
      "        \"matches_evaluation/confidence\": \"no confidence interval reported. No statistical significance over baselines has been computed\",\n",
      "        \"matches_evaluation/measure\": \"ROC curve\",\n",
      "        \"matches_evaluation/method\": \"cross validation\",\n",
      "        \"matches_optimization/algorithm\": \"Different supervised and unsupervised learning algorithms: logistic regression, linear discriminant analysis, quadratic discriminant analysis, naive Bayes, k-nearest neighbors, PCA. No new algorithm developed.\",\n",
      "        \"matches_optimization/encoding\": \"Gene expression data\",\n",
      "        \"matches_optimization/features\": \"290 features. no feature selection performed.\",\n",
      "        \"matches_optimization/fitting\": \"p is much lower than the number of features. Unclear how potential underfitting was handled\",\n",
      "        \"matches_optimization/parameters\": \"Unclear, approximately in the range of the number of features\",\n",
      "        \"matches_optimization/regularization\": \"Not adopted\",\n",
      "        \"matches_model/duration\": \"not stated\",\n",
      "        \"matches_model/interpretability\": \"Model is partially interpretable, since classifier paramenters can be used to assess how gene expression data related to gene response to stress.\",\n",
      "        \"matches_dataset/provenance\": \"Data are extracted from different databases (TAIR, AtGenExpress Consortium, NASCArrays). Data are in classes. Npos and Nneg are not reported.\",\n",
      "        \"matches_dataset/redundancy\": \"Random split has been adopted for cross-validation. No redundancy check performed.\",\n",
      "        \"matches_dataset/splits\": \"Training set: 11553 data points, No test nor validation sets have been used.  Performance is scored using cross-validation only.\",\n",
      "        \"matches_publication/authors\": \"Hui Lan, Rachel Carson , Nicholas J Provart and Anthony J Bonner\",\n",
      "        \"matches_publication/journal\": \"BMC Bioinformatics\",\n",
      "        \"matches_publication/title\": \"Combining classifiers to predict gene function in Arabidopsis thaliana using large-scale gene expression measurements\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"66041e5d1502715bfe53d70a\",\n",
      "        \"uuid\": \"b863eb51-d9ae-4fc0-bfd4-006db90d1631\",\n",
      "        \"created\": \"2024-03-27T13:25:49.790Z\",\n",
      "        \"updated\": \"2024-03-27T13:25:49.790Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"17570862\",\n",
      "        \"publication_authors\": \"Blaise Gassend, Charles W O'Donnell, William Thies, Andrew Lee, Marten van Dijk and Srinivas Devadas\",\n",
      "        \"publication_journal\": \"BMC Bioinformatics\",\n",
      "        \"publication_title\": \"Learning biophysically-motivated parameters for alpha helix prediction\",\n",
      "        \"publication_doi\": \"10.1186/1471-2105-8-S5-S3\",\n",
      "        \"publication_year\": \"2007\",\n",
      "        \"shortid\": \"qx3ex71jye\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_evaluation/availability\": \"Not available\",\n",
      "        \"matches_evaluation/comparison\": \"Cmparison with other approaches is missing. No baseline method is considered\",\n",
      "        \"matches_evaluation/confidence\": \"Not reported\",\n",
      "        \"matches_evaluation/measure\": \"accuracy and segment-overlap value for alpha helix (SOVa)\",\n",
      "        \"matches_evaluation/method\": \"Repeated random traing/test split\",\n",
      "        \"matches_optimization/algorithm\": \"support vector machine classifyer. The algorithm is not new.\",\n",
      "        \"matches_optimization/encoding\": \"Residue are encoded with different propensity scale for a residues to by in alpha-helix or coil\",\n",
      "        \"matches_optimization/features\": \"f=380. No feature selection performed. \",\n",
      "        \"matches_optimization/fitting\": \"p is much lower than number of training points. Not clear how potential undefitting has been ruled out\",\n",
      "        \"matches_optimization/regularization\": \"No regularization applied. Validation set not used.\",\n",
      "        \"matches_model/interpretability\": \"Model is interpreatable, since paramenters learning by the SVM corresponds to interpretable paramenters of an energy function\",\n",
      "        \"matches_model/output\": \"binary classification\",\n",
      "        \"matches_dataset/provenance\": \"Data is extracted from the PDB. Data are in classes (alpha-helix vs other), however, it is not clear ho many alpha-helix residues (positive example) are present within the 300 proteins in the dataset. Dataset previsouly used in other studies and recognized by the community (no logner available)\",\n",
      "        \"matches_dataset/redundancy\": \"All proteins in the dataset are non-homologous all-alpha proteins. Unclear how redundancy reduction is performed.\",\n",
      "        \"matches_dataset/splits\": \"Traning set: 150 proteins; Testing set: 150 proteins. Distributions of data classess in training and testing not shown. No validation set adopted. \",\n",
      "        \"matches_publication/authors\": \"Blaise Gassend, Charles W O'Donnell, William Thies, Andrew Lee, Marten van Dijk and Srinivas Devadas\",\n",
      "        \"matches_publication/journal\": \"BMC Bioinformatics\",\n",
      "        \"matches_publication/title\": \"Learning biophysically-motivated parameters for alpha helix prediction\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b1c\",\n",
      "        \"publication_pmid\": \"19091017\",\n",
      "        \"publication_updated\": \"03/25/2022 13:35:02\",\n",
      "        \"publication_authors\": \"Tsai RT, Dai HJ, Huang CH, Hsu WL\",\n",
      "        \"publication_journal\": \"BMC Bioinformatics\",\n",
      "        \"publication_title\": \"Semi-automatic conversion of BioProp semantic annotation to PASBio annotation.\",\n",
      "        \"publication_doi\": \"10.1186/1471-2105-9-S12-S18\",\n",
      "        \"publication_year\": \"2008\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"28fe7de1-ac05-4cf2-bfa8-d5ddd1ba32b8\",\n",
      "        \"shortid\": \"v536tc3b5t\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches_publication/updated\": \"03/25/2022 13:35:02\",\n",
      "        \"matches_publication/authors\": \"Tsai RT, Dai HJ, Huang CH, Hsu WL\",\n",
      "        \"matches_publication/journal\": \"BMC Bioinformatics\",\n",
      "        \"matches_publication/title\": \"Semi-automatic conversion of BioProp semantic annotation to PASBio annotation.\",\n",
      "        \"matches_optimization/algorithm\": \"A  non-linear, multi-layer convolutional Graph Neural Network (GNN) was trained to encode drug features, which were then fed to a Multi-Layer Perceptron (MLP) to output a probability distribution.  The probability distributions were passed to a SVM for the binary classification of nodes. The training was end-to-end.\",\n",
      "        \"matches_optimization/config\": \"Yes. Hyperparameter settings for every method are reported. For neural models, hyperparameter candidates can be found in Table 1, Characteristics of the neural network models architecture can be found in text.\",\n",
      "        \"matches_optimization/encoding\": \"Initially, each drug (or food molecule) is represented by a graph G of human PPI (with 15135 nodes and 177848 edges), with one binary feature per node (1 for anti-cancer, 0 for non anti-cancer).     A vector representation of the graph G is computed using a Graph Encoder, i.e. a GNN, which learns the systemic effect of drugs (or food molecules) on the PPI network.    \",\n",
      "        \"matches_optimization/features\": \"Initial f0) = number of genes x number of drugs (15135x2048).  After the GNN step, each drug has an associated feature vector, so that the number of features is reduced to f < f(0). \",\n",
      "        \"matches_optimization/fitting\": \"As far as one can tell, over-fitting could not be excluded (p >> N).  Indeed, regularization was performed.\",\n",
      "        \"matches_optimization/regularization\": \"Yes.   L2 regularization on weights of the neural network was performed.    Space search:  1.10^(\\u22125), 1.10^(\\u22124), 5.10^(\\u22124).  \",\n",
      "        \"matches_model/availability\": \"The code to reproduce the results can be downloaded from GitHub (https://github.com/ggonzalezp/hyperfoods)\",\n",
      "        \"matches_model/duration\": \"Training time is expressed as milliseconds per sample per epoch, to facilitate the estimation of the total training time the proposed neural models would need for a different dataset.\",\n",
      "        \"matches_model/interpretability\": \"Transparent : The attribution recall score for the best performing model is computed, to assess whether the model predicts drugs as anticancer preferentially based on the feature values in cancer-related genes, and found to be very high (85%). This means that the graph neural model classifies drugs as anticancer preferentially based on the value of the input features in cancer-related genes, which adds to the biological plausibility of the model. In addition, 6 use cases were invetigated. For all 6 drugs studied, over-represented pathways successfully recovered pathways described in the literature along with cancer-related\\n pathways. This means that the representations learned capture the mechanisms of action of drugs.\",\n",
      "        \"matches_model/output\": \"Regression is the output by neural networks, i.e. a probability distribution for anticancer/non-anticancer categories), which is taken in input by SVM for a binary classification output.\",\n",
      "        \"matches_evaluation/availability\": \"Yes. (https://github.com/ggonzalezp/hyperfoods)\",\n",
      "        \"matches_evaluation/comparison\": \"A baseline input is used, in which all drug targets are set to zero. To motivate the use of network propagation, versions of the baseline and proposed methods without network propagation were also evaluated (for comparison to the method used in https://doi.org/10.1038/s41598-019-45349-y, which did not use network propagation). F1 score and AUPR were significantly higher with the adopted models.\",\n",
      "        \"matches_evaluation/confidence\": \"Confidence intervals and statistical significance are reported. Statistically significant higher performance measures were obtained by the used model, relative to the baseline method and to the method without network propagation used in https://doi.org/10.1038/s41598-019-45349-y.\",\n",
      "        \"matches_evaluation/measure\": \"Balanced accuracy, F1 score, AUPR. The last two are used as parameters which better capture the performance of a classifier in the case of a highly-imbalanced dataset.\",\n",
      "        \"matches_evaluation/method\": \"Cross-validation. The model was also tested on an independent dataset of 7793 food molecules, for their classification as anti-cancer or not anti-cancer, available for future experimental tests. The model outputs a high anticancer likelihood for a given food molecule if said molecule acts on the interactome through similar mechanisms of action as those of FDA-approved anticancer drugs. Among the anticancer-predicted molecules, e.g. genistein and pterostilbene show the most promise as cancer preventing agents, as indicated by substantial experimental evidence, gained from the literature.\",\n",
      "        \"matches_dataset/availability\": \"Yes :  data to reproduce the results can be downloaded from GitHub (https://github.com/ggonzalezp/hyperfoods).  All data were extracted from publicly available databases.\",\n",
      "        \"matches_dataset/provenance\": \"\\\"Data were extracted from publicly available databases: UniProt, STRING STITCH; COSMIC, NCBI,  DrugBase, DrugCentral,  FooDB, KEGG, MSigDB.   The dataset contains 2048 drugs (training dataset).   The dataset had been previously used also in https://doi.org/10.1038/s41598-019-45349-y.     The procedure in [ https://doi.org/10.1038/s41598-019-45349-y ] was used to obtain classification labels for the cancer task (positive (anti-cancer drug)/negative (non anti-cancer drug): N_pos = 209 /N_neg = 1839 drugs).   \\n\",\n",
      "        \"matches_dataset/splits\": \"A 5-fold cross-validation was performed to assess model performance. In each split, 20% of the data is kept as the test set; from the remaining 80%, 10% is used as a validation set to perform early stopping. All splits were generated stratifying samples with respect to labels.  To balance the positive/negative classes (only 10.2% of drugs are anticancer), the contribution of each class was re-scaled to the loss function so that it is inversely proportional to class frequencies of each class during training.  \"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b1d\",\n",
      "        \"publication_pmid\": \"18586734\",\n",
      "        \"publication_updated\": \"04/18/2022 16:37:38\",\n",
      "        \"publication_authors\": \"Klammer AA, Reynolds SM, Bilmes JA, MacCoss MJ, Noble WS\",\n",
      "        \"publication_journal\": \"Bioinformatics\",\n",
      "        \"publication_title\": \"Modeling peptide fragmentation with dynamic Bayesian networks for peptide identification.\",\n",
      "        \"publication_doi\": \"10.1093/bioinformatics/btn189\",\n",
      "        \"publication_year\": \"2008\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"56505402-9ea8-41a0-9132-ea658a7eee7f\",\n",
      "        \"shortid\": \"5867a1dxop\",\n",
      "        \"score\": 0.9,\n",
      "        \"matches_publication/updated\": \"04/18/2022 16:37:38\",\n",
      "        \"matches_publication/authors\": \"Klammer AA, Reynolds SM, Bilmes JA, MacCoss MJ, Noble WS\",\n",
      "        \"matches_publication/title\": \"Modeling peptide fragmentation with dynamic Bayesian networks for peptide identification.\",\n",
      "        \"matches_optimization/algorithm\": \"Boosted decision tree\",\n",
      "        \"matches_optimization/config\": \"Authors state that BigML models will be shared without limitations.\",\n",
      "        \"matches_optimization/encoding\": \"Global features.\",\n",
      "        \"matches_optimization/features\": \"Apparently, 20 parameters from cytofluorometry and 4 parameters from standard biochemical laboratory data were used in input.    it is not mentioned whether some of the parameters related to primary diagnoses of other diseases, or related to age, ethnicity and sex were also used.   \",\n",
      "        \"matches_optimization/fitting\": \"According to the author's statement, the AUROC values of the training (0.98) and of the testing (0.99) sets were \\\"most likely over-fitting\\\" -- (AUROC of the independent validation set resulted 0.8).                                                                                \",\n",
      "        \"matches_optimization/parameters\": \"not reported. Most likely, however, the number of parameters was as in the software package by default.\",\n",
      "        \"matches_optimization/regularization\": \"Tools eventually applied to avoid overfitting are not mentioned.\",\n",
      "        \"matches_model/availability\": \"The materials, data, code and associated protocols are available to readers with application to the corresponding author and Waitemata privacy, security and governance group with a limited data sharing agreement.\",\n",
      "        \"matches_model/interpretability\": \"Black box. No information about the optimized parameters were reported.\",\n",
      "        \"matches_model/output\": \"Binary prediction of a positive or negative SARS-CoV-2 PCR result.\",\n",
      "        \"matches_evaluation/availability\": \"The materials, data, code and associated protocols are available to readers with application to the corresponding author and Waitemata privacy, security and governance group with a limited data sharing agreement.\",\n",
      "        \"matches_evaluation/comparison\": \"A comparison is reported between the boosted decision tree model and the highest univariate predictor for COVID-19 (highly fluorescent lymphocytes count % [HFLC%]).\",\n",
      "        \"matches_evaluation/confidence\": \"AUROC from ML model was 0.80, from univariate predictor was 0.77, but the small difference was not statistically significant, according to 95% Confidence Intervals.\",\n",
      "        \"matches_evaluation/measure\": \"AUROC (in spite of the much higher numerosity of negative versus positive samples in the datasets).\",\n",
      "        \"matches_evaluation/method\": \"Validation (most likely 5-fold cross-validation, even if it not mentioned explicitly) on training set and validation on an independent set. Independent set: new data collected from 9 June 2020 to 24 August 2020 during New Zealand\\u2019s second wave.\",\n",
      "        \"matches_dataset/availability\": \"The materials, data, code and associated protocols are available to readers with application to the corresponding author and Waitemata privacy, security and governance group with a limited data sharing agreement.     \",\n",
      "        \"matches_dataset/provenance\": \"Upon ethics approval obtained locally at Waitemata District Health Board (New Zealand), hematology raw hospital data were downloaded from the Information Process Unit (IPU) of the hospitals.  Data from 43,761 patients were collected between 1 July 2019 and 8 June 2020 from two hospital's flow cytometry analyzers.     A total of 2168 of SARS-CoV-2 PCR tests could be matched to patients with Full Blood Counts (FBC) data.   9 patients with 102 FBCs were SARS-CoV-2 positive, 2159 patients with 15,243 FBCs were SARS-CoV-2 negative.\",\n",
      "        \"matches_dataset/redundancy\": \"Since the 102 FBCs sample came from 9 positive patients only, independence seems doubtful. \",\n",
      "        \"matches_dataset/splits\": \"Models were trained, tested and then validated in an independent cohort. Due to the low number of COVID-19 PCR-positive cases, serial results for each positive case were used for descriptive statistics and in ML models, \\\"in the assumption that this would include the various stages of the disease and convalescence\\\".    A total of 102 (N_pos) instances (serial FBCs in 9 patients identified during New Zealand\\u2019s first lockdown) and 204 (N_pos) control FBCs in unique patients were used for model training and testing.   For independent validation:  11 FBCs from 3 patients with COVID-19 were used for validation with 6770 controls.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b94\",\n",
      "        \"publication_pmid\": \"18221567\",\n",
      "        \"publication_updated\": \"03/24/2022 13:09:43\",\n",
      "        \"publication_authors\": \"Zhao XM, Wang Y, Chen L, Aihara K\",\n",
      "        \"publication_journal\": \"BMC Bioinformatics\",\n",
      "        \"publication_title\": \"Gene function prediction using labeled and unlabeled data.\",\n",
      "        \"publication_doi\": \"10.1186/1471-2105-9-57\",\n",
      "        \"publication_year\": \"2008\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"9052c56d-022c-45d9-8b82-58312399f0dc\",\n",
      "        \"shortid\": \"ali2ohlvnk\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches_publication/updated\": \"03/24/2022 13:09:43\",\n",
      "        \"matches_publication/authors\": \"Zhao XM, Wang Y, Chen L, Aihara K\",\n",
      "        \"matches_publication/journal\": \"BMC Bioinformatics\",\n",
      "        \"matches_publication/title\": \"Gene function prediction using labeled and unlabeled data.\",\n",
      "        \"matches_optimization/algorithm\": \"Learning Gaussian Bayesian networks with interventions\",\n",
      "        \"matches_optimization/encoding\": \"Global features\",\n",
      "        \"matches_optimization/features\": \"Expression level of the genes under different conditions\",\n",
      "        \"matches_optimization/fitting\": \"Not assessed\",\n",
      "        \"matches_optimization/parameters\": \"Increases with the size of the network. They scale with the number of possible edges\",\n",
      "        \"matches_model/availability\": \"Matlab Code\\n http://www.plosone.org/article/fetchSingleRepresentation.action?uri=info:doi/10.1371/journal.pone.0150611.s002\",\n",
      "        \"matches_model/output\": \"Network reconstruction\",\n",
      "        \"matches_evaluation/comparison\": \"Comparison with state-of-the-art algorithms\",\n",
      "        \"matches_evaluation/measure\": \"AUROC and AUPR\",\n",
      "        \"matches_evaluation/method\": \"Evaluation of two datasets\",\n",
      "        \"matches_dataset/provenance\": \"In silico gene expression data from DREAM Challenge 4\",\n",
      "        \"matches_dataset/redundancy\": \"Not assessed\",\n",
      "        \"matches_dataset/splits\": \"Networks of different sets of genes for wt and perturbed networks\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"66040f611502715bfe53d6e7\",\n",
      "        \"uuid\": \"804c2b2b-e663-4d3a-8042-7d2a35ad2122\",\n",
      "        \"created\": \"2024-03-27T12:21:53.450Z\",\n",
      "        \"updated\": \"2024-03-27T12:21:53.450Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"18808707\",\n",
      "        \"publication_authors\": \"Iain Melvin, Jason Weston , Christina S Leslie and William S Noble\",\n",
      "        \"publication_journal\": \"BMC Bioinformatics\",\n",
      "        \"publication_title\": \"Combining classifiers for improved classification of proteins from sequence or structure\",\n",
      "        \"publication_doi\": \"10.1186/1471-2105-9-389\",\n",
      "        \"publication_year\": \"2008\",\n",
      "        \"shortid\": \"vwy8sti3pw\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches_evaluation/availability\": \"yes, through the author website\",\n",
      "        \"matches_evaluation/comparison\": \"Yes, with a single external tool (AutoSCOP)\",\n",
      "        \"matches_evaluation/confidence\": \"not reported\",\n",
      "        \"matches_evaluation/measure\": \"Per-class error rate\",\n",
      "        \"matches_evaluation/method\": \"cross-validation and independent test set\",\n",
      "        \"matches_optimization/algorithm\": \"Combined kNN and SVM. \",\n",
      "        \"matches_optimization/config\": \"yes, hardcoded into the source code\",\n",
      "        \"matches_optimization/encoding\": \"Protein primary sequence. Profile kernel is used for SVM\",\n",
      "        \"matches_optimization/fitting\": \"Cannot be determined\",\n",
      "        \"matches_optimization/parameters\": \"Not clearly declared.\",\n",
      "        \"matches_optimization/regularization\": \"No  \",\n",
      "        \"matches_model/availability\": \"yes, thrugh the author website\",\n",
      "        \"matches_model/duration\": \"not reported\",\n",
      "        \"matches_model/output\": \"multi-class classification\",\n",
      "        \"matches_dataset/availability\": \"yes (URL)\",\n",
      "        \"matches_dataset/provenance\": \"Data taken from SCOP database (release 1.69). Multi-class data where each class corresponds to a SCOP superfamily. Number of superfamilies is 74 and 1458 in in Set A  and Set B, respectively.  Number of proteins is 643 and 2182 in Set A and Set B, respectively.\",\n",
      "        \"matches_dataset/redundancy\": \"Testing set should be independent, given that split has been perfomed at the level of SCOP superfamilies\",\n",
      "        \"matches_dataset/splits\": \"Dataset A: N_train=543 (proteins), N_test=110 (proteins) ; Dataset B: N_train=1740 (proteins), N_test=442 (proteins)\",\n",
      "        \"matches_publication/authors\": \"Iain Melvin, Jason Weston , Christina S Leslie and William S Noble\",\n",
      "        \"matches_publication/journal\": \"BMC Bioinformatics\",\n",
      "        \"matches_publication/title\": \"Combining classifiers for improved classification of proteins from sequence or structure\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b3a\",\n",
      "        \"publication_pmid\": \"19154573\",\n",
      "        \"publication_updated\": \"02/23/2022 23:30:01\",\n",
      "        \"publication_authors\": \"Brown JB, Akutsu T\",\n",
      "        \"publication_journal\": \"BMC Bioinformatics\",\n",
      "        \"publication_title\": \"Identification of novel DNA repair proteins via primary sequence, secondary structure, and homology.\",\n",
      "        \"publication_doi\": \"10.1186/1471-2105-10-25\",\n",
      "        \"publication_year\": \"2009\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"1fe140b6-a570-49cf-bccb-e58aa1719bec\",\n",
      "        \"shortid\": \"2d714axh0n\",\n",
      "        \"score\": 0.86,\n",
      "        \"matches_publication/updated\": \"02/23/2022 23:30:01\",\n",
      "        \"matches_publication/authors\": \"Brown JB, Akutsu T\",\n",
      "        \"matches_publication/journal\": \"BMC Bioinformatics\",\n",
      "        \"matches_publication/title\": \"Identification of novel DNA repair proteins via primary sequence, secondary structure, and homology.\",\n",
      "        \"matches_optimization/algorithm\": \"The AdaBoost algorithm on a set of 80 Decision Trees was used, as implemented in the scikit learn package.             \",\n",
      "        \"matches_optimization/config\": \"A web server implementing the \\u201copen-source\\u201d model was developed and is freely available at http://chemosimserver.unice.fr/predisweet/. The 32 descriptors for the \\u201cDragon\\u201d model, and 51 descriptors for the \\u201copen source\\u201d model are also reported.\",\n",
      "        \"matches_optimization/encoding\": \"Drugs were encoded as a set of molecular descriptors.    Molecular descriptors were computed using the Dragonpackage ('Dragon\\\" descriptors), or RDKit, Mordred, and ChemoPy packages (\\u201copen-source\\u201d descriptors). \",\n",
      "        \"matches_optimization/features\": \"\\\"For each molecule, 635 molecular descriptors for the Dragon dataset, and 506 features for the \\u201copen-source\\u201d dataset were used in the model.   For each of these two descriptors sets, the initial number of features had been reduced by removing near-constant features (two or less unique values), features with a standard deviation below 0.001, and features with a correlation greater than 0.95.       During cross-validation, selection of descriptors was done by keeping a given percentile of the highest ranked descriptors based on their Mutual Information with the endpoint. The optimal percentile of features was tuned as a parameter of the Grid Search.   \\n\\\"\",\n",
      "        \"matches_optimization/fitting\": \"Optimization of the number of features used by the model\",\n",
      "        \"matches_optimization/parameters\": \"Default defined in sklearn package\",\n",
      "        \"matches_optimization/regularization\": \"Yes.  To avoid any model bias due to overfitting, the number of features used by the model is a hyperparameter that has been optimized. \",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"Regression (sweetness score)\",\n",
      "        \"matches_evaluation/comparison\": \"Several regression algorithms from the python package scikit-learn were evaluated: Random Forest, SVM, AdaBoost Tree, and k-Nearest Neighbors. Five-fold cross validation was performed with hyperparameter tuning using a grid search. The AdaBoost Tree model was selected as the best performing model, using 32 descriptors for the \\u201cDragon\\u201d model, and 51 descriptors for the \\u201copen source\\u201d model.\",\n",
      "        \"matches_evaluation/confidence\": \"Confidence intervals for coefficient of determination are shown in Fig. S2, but a statistical significance analysis among the different tested methods is not reported\",\n",
      "        \"matches_evaluation/measure\": \"Correlation Coefficient (R^2), cross-validated Correlation Coefficient (Q^2), coefficient of determination (|R^2-R0^2)/R^2), slope of regression line (k). The quality of each prediction is also assessed based on three metrics, namely the applicability, reliability, and decidability domains, typically used in the Quantitative Structure-Activity Relationships field.\",\n",
      "        \"matches_evaluation/method\": \"Cross-validation. Novel experiments: The virtual screening of a large database of natural compounds (4796) identified thousands of putative sweeteners, of which 3 were selected for in vitro functional assays of the human sweet taste receptor. Among them, arctiin, with a novel scaffold, was identified as a novel agonist of the T1R2/T1R3 sweet taste receptor.\",\n",
      "        \"matches_dataset/availability\": \"Yes.  Dataset available in the SweetenersDB database http://sebfiorucci.free.fr/SweetenersDB/sweetenersDB.html  \",\n",
      "        \"matches_dataset/provenance\": \"Dataset:  316 sugar/sweeteners compounds of known sweetness collected by the authors from literature sources in the SweetenersDB database . Already used previously by the same authors (in a less-updated version).   \",\n",
      "        \"matches_dataset/redundancy\": \"The dataset  was split in training and validation sets using a Sphere Exclusion clustering algorithm.     The chemical space was mapped using t-SNE and PCA.\",\n",
      "        \"matches_dataset/splits\": \"64 diverse compounds (20.3%) were selected for the validation set, leaving 252 compounds in the training set.     \"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b5d\",\n",
      "        \"publication_pmid\": \"19667082\",\n",
      "        \"publication_updated\": \"04/06/2022 03:38:12\",\n",
      "        \"publication_authors\": \"Wegrzyn JL, Lee JM, Liechty J, Neale DB\",\n",
      "        \"publication_journal\": \"Bioinformatics\",\n",
      "        \"publication_title\": \"PineSAP--sequence alignment and SNP identification pipeline.\",\n",
      "        \"publication_doi\": \"10.1093/bioinformatics/btp477\",\n",
      "        \"publication_year\": \"2009\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"3f2e8acd-75f4-4e37-b345-0b43034fdfd4\",\n",
      "        \"shortid\": \"zl2x79pdqc\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches_publication/updated\": \"04/06/2022 03:38:12\",\n",
      "        \"matches_publication/authors\": \"Wegrzyn JL, Lee JM, Liechty J, Neale DB\",\n",
      "        \"matches_publication/title\": \"PineSAP--sequence alignment and SNP identification pipeline.\",\n",
      "        \"matches_optimization/algorithm\": \"Ensemble of a deep Residual Convolutional Neural Networks.\\t\",\n",
      "        \"matches_optimization/encoding\": \"Each MHC allele was represented by a pseudo-sequence consisting of 34 amino acid residues in contact with the peptide.  All peptides sequences were padded on the right end to the same length, 30 for class I and 40 for class II, using a place-holder amino acid.     For each MHC- peptide pair, the MHC feature vector and the peptide feature matrix formed a final input matrix of size 1400 x 30 for class I MHC and 1400 x 40 for class II MHC. The difference between the peptide length L and the expected length L (9 for class I MHC and 15 for class II MHC) was encoded using a sigmoid function.\",\n",
      "        \"matches_optimization/features\": \"Number of initial features on the order of 1400 x 30\",\n",
      "        \"matches_optimization/fitting\": \"Possible redundancy in the sequences\",\n",
      "        \"matches_optimization/parameters\": \"The model weights from the epoch with the lowest validation loss were selected.\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"Regression: The PUFFIN method takes as input a MHC-peptide pair and predicts a probabilistic distribution of peptide-MHC binding affinity. For Classification: positive examples were defined as the ones with a binding affinity stronger than 500 nM.\",\n",
      "        \"matches_evaluation/comparison\": \"PUFFIN was compared to NetMHCpan, MHCflurry and MHCnuggets. Unlike those methods, PUFFIN provides uncertainty estimates for MHC-peptide affinity prediction. It is shown that PUFFIN\\u2019s uncertainty estimates are able to reflect the predictive error on unseen examples.\",\n",
      "        \"matches_evaluation/confidence\": \"Confidence intervals are not reported. As mentioned in the text, there were no significant performance differences among the different tested methods.\",\n",
      "        \"matches_evaluation/measure\": \"auROC, F1 score, mean-squared-error (MSE), R2, Spearman, correlation, and Point-Biserial correlation. For auROC, F1 score, and Point-Biserial correlation, positive examples were defined as the ones with a binding affinity stronger than 500 nM.\",\n",
      "        \"matches_evaluation/method\": \"Cross-validation on training set and independent set\",\n",
      "        \"matches_dataset/availability\": \"Class I MHC binding affinity data in IEDB\\nhttps://cbs.dtu.dk/services.NetMHCpan-3.0 (broken link)\\n\\nClass II MHC binding affinity data in IEDB\\nhttps://cbs.dtu.dk/services.NetMHCIIpan-3.2 (broken link)\\n\\nBenchmark dataset (used for comparison with other methods)\\nhttps://www.biorxiv.org/content/10.1101/154757v2  https://data.mendeley.com/datasets/jwhmrdx268/1\\nThe authors obtained data in the class I MHC-peptide binding affinity benchmark from personal correspondence with Bhattacharya et al. and they have deposited this dataset in Mendeley Data. The accession number for this data is Mendeley Data:\\nhttps://doi.org/10.17632/jwhmrdx268.1\\n\",\n",
      "        \"matches_dataset/provenance\": \"Regression data\\n\\nClass I MHC binding affinity data in IEDB\\nBroken link\\n\\nClass II MHC binding affinity data in IEDB\\nBroken link\\n\\nBenchmark dataset (used for comparison with other methods)\\nCurated class I MHC benchmark dataset (https://www.biorxiv.org/content/10.1101/154757v2 https://data.mendeley.com/datasets/jwhmrdx268/1)  \\nTraining 176,985\\nTesting  26,888\",\n",
      "        \"matches_dataset/redundancy\": \"Class I MHC binding affinity data in IEDB\\nFor analyses on class I MHC-peptide binding, the IEDB-based dataset of Nielsen et al (2016) was used, in which 5 cross-validation folds were created to ensure no peptide shares a 9-mer sequence with any peptide in a different fold. \\t\\n\\nClass II MHC binding affinity data in IEDB\\nFor analyses on class II MHC-peptide binding, the IEDB-based dataset of Jensen et al (2018) was used, in which 5 cross-validation folds were created in the same way as in Nielsen et al (2016).\\t\\n\\nBenchmark dataset (used for comparison with other methods)\\nThe dataset of Bhattacharya et al.(2017) was used, who constructed a benchmark in which no peptide in the test set has identical length and greater than 80% sequence identity to any peptide in the training Set.\",\n",
      "        \"matches_dataset/splits\": \"Class I MHC binding affinity data in IEDB\\nOnly MHC alleles (114)  with more than 100 examples were included to ensure the quality of training.   1/8 of the training set was held out as a validation set.\\t\\n\\nClass II MHC binding affinity data in IEDB\\nOnly MHC alleles (55) with more than 100 examples were included to ensure the quality of training.   1/8 of the training set was held out as a validation set.\\t\\n\\nBenchmark dataset (used for comparison with other methods)\\n51 class I MHC alleles are covered in this dataset.   \"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6613fe1f1502715bfe53d929\",\n",
      "        \"uuid\": \"b05d78bd-b870-43e2-8313-2c6e8cc7a91a\",\n",
      "        \"created\": \"2024-04-08T14:24:31.559Z\",\n",
      "        \"updated\": \"2024-04-08T14:24:31.559Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"19692556\",\n",
      "        \"publication_authors\": \"Bandyopadhyay S, Mitra R. \",\n",
      "        \"publication_journal\": \"Bioinformatics\",\n",
      "        \"publication_title\": \"TargetMiner: microRNA target prediction with systematic identification of tissue-specific negative examples\",\n",
      "        \"publication_doi\": \"10.1093/bioinformatics/btp503\",\n",
      "        \"publication_year\": \"2009\",\n",
      "        \"shortid\": \"vqpw9fqmuu\",\n",
      "        \"score\": 0.95,\n",
      "        \"matches_evaluation/availability\": \"I could not find them.\",\n",
      "        \"matches_evaluation/comparison\": \"Ten other methods (DIANA-microT, Micro Inspector, miRanda, MirTarget2, NBmiRTar, PicTar, PITA, RNA22, RNAhybrid, TargetScan) have been applied by the Authors to the same test data, reaching the conclusion that the better performance of their own method was probably due to the better negative training set they were able to individuate.\",\n",
      "        \"matches_evaluation/confidence\": \"No confidence intervals are reported for any performance measure.\",\n",
      "        \"matches_evaluation/measure\": \"Sensitivity, specificity (ROC curves), ACA (Average Classwise Accuracy) and MCC (Matthews Correlation Coefficient).\",\n",
      "        \"matches_evaluation/method\": \"Independent dataset, experimentally validated, composed of 246 miRNA\\u2013transcript pairs, of  which 187 were positive, 59 negative. \",\n",
      "        \"matches_optimization/algorithm\": \"Support Vector Machine (SVM). \",\n",
      "        \"matches_optimization/config\": \"TargetMiner is available as an online tool at https://www.isical.ac.in/~bioinfo_miu/targetminer20.htm.       The optimized parameter values for C and \\u03b3 are given in text.  Both the 90 and 30 feature sets are explicitly reported in the Supplementary Materials, together with the identification numbers of the 578 data points.  \",\n",
      "        \"matches_optimization/encoding\": \"kmer for seed region, base pairing frequencies in the nearby regions.\",\n",
      "        \"matches_optimization/features\": \"Two SVM models were build, based on the 90 and 30 (top 30 F-score) features, respectively. The two SVM classifiers are referred to as TargetMiner* and TargetMiner.  The selection of the 30 top features was based on an F-score, which indicated the discriminating power of a given feature between positive and negative examples. The F-score was calculated based on the training set only.\",\n",
      "        \"matches_optimization/fitting\": \"The number of features was less than 100, but not small (30 or 90), compared to the number of training points (n = 578). \",\n",
      "        \"matches_optimization/parameters\": \"The two standard RBF SVM hyperparameters C and \\u03b3 were determined by a grid search with a 10-fold cross-validation on the training dataset. \",\n",
      "        \"matches_optimization/regularization\": \"The parameter C was standardly used to control the tradeoff between training error and margin. \",\n",
      "        \"matches_model/availability\": \"SVM software is standard.  TargetMiner is available as an online tool at https://www.isical.ac.in/~bioinfo_miu/targetminer20.htm.     Executables are given .  Data files of test sets are available.\",\n",
      "        \"matches_model/duration\": \"Not reported\",\n",
      "        \"matches_model/interpretability\": \"SVM is generally considered black box. However, some ante hoc interpretability is manifested in the feature generation step, which was based on miRNA / 3'-UTR mRNA hybridization characteristics, such as seed length and identification, thermodynamic duplex stability, combinatorial effect of miRNAs and multiple target sites in the 3-UTRs of target mRNA, importance of miRNA\\u2019s outseed segment to determine the target specificity, analysis of evolutionary conserved target sites.  Post-hoc analysis of single features effectiveness was not performed.  Indeed, that is in agreement with the Author's statement, \\\"Since our objective in this article is to demonstrate the utility of systematically identifying the negative examples, we have kept the feature selection part simple. A more sophisticated approach is expected to improve the performance and will be considered in the future\\\".\",\n",
      "        \"matches_model/output\": \"Binary classification (target or non-target genes for miRNAs).\",\n",
      "        \"matches_dataset/availability\": \"Yes. Supporting Information.\",\n",
      "        \"matches_dataset/provenance\": \"Source of positive miRNAs: TarBase (Papadopoulos et al., 2009) and miRecords database (Xiao et al., 2009, Nucleic Acids Res., 37, D155\\u2013D158, Nucleic Acids Res., 37, D105\\u2013D110)  \\nA set of 289 miRNA transcript pairs (positive examples), and 289 negative examples were used as training dataset (total training data points npos + nneg =578).  \\nThe positive data had been used previously in other papers. The negative data are novel, and have been identified by the Authors by means of a complex analysis. A subset of the negative examples has been validated experimentally.\",\n",
      "        \"matches_dataset/redundancy\": \"Not reported\",\n",
      "        \"matches_dataset/splits\": \"The SVM model with RBF kernel was generated by a 10-fold cross-validation on the training dataset.  The distribution of + and - in each data split is not mentioned, but it can be deduced to have been half and half.\",\n",
      "        \"matches_publication/authors\": \"Bandyopadhyay S, Mitra R. \",\n",
      "        \"matches_publication/title\": \"TargetMiner: microRNA target prediction with systematic identification of tissue-specific negative examples\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b9d\",\n",
      "        \"publication_pmid\": \"20122221\",\n",
      "        \"publication_updated\": \"02/07/2022 18:57:16\",\n",
      "        \"publication_authors\": \"Yang Y, Zhao J, Morgan RL, Ma W, Jiang T\",\n",
      "        \"publication_journal\": \"BMC Bioinformatics\",\n",
      "        \"publication_title\": \"Computational prediction of type III secreted proteins from gram-negative bacteria.\",\n",
      "        \"publication_doi\": \"10.1186/1471-2105-11-S1-S47\",\n",
      "        \"publication_year\": \"2010\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"ed449019-062c-4769-99ec-83a325549f96\",\n",
      "        \"shortid\": \"hl7w8279ra\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches_publication/updated\": \"02/07/2022 18:57:16\",\n",
      "        \"matches_publication/authors\": \"Yang Y, Zhao J, Morgan RL, Ma W, Jiang T\",\n",
      "        \"matches_publication/journal\": \"BMC Bioinformatics\",\n",
      "        \"matches_publication/title\": \"Computational prediction of type III secreted proteins from gram-negative bacteria.\",\n",
      "        \"matches_optimization/algorithm\": \"Iterative Bayesian Model Averaging (BMA) algorithm.\",\n",
      "        \"matches_optimization/features\": \"f=3.   The feature selection method to distinguish benign from malignant samples consisted of two steps: a LIMMA linear model, and an iterative BMA algorithm.   The R package LIMMA was used  to  select  significantly  differentially  expressed  genes (fold-change cutoff of >=2 and a p-value<0.01). To minimize the number of signature genes, the iterative BMA R package was applied, which accounts for model uncertainty and the dependency between signature genes.    The BMA step was applied to further reduce the number of signature genes from 43 to 3, and thus the costs associated with microarrays and time-consuming data analysis.\",\n",
      "        \"matches_optimization/fitting\": \"\\nOver- or under- fit could probably be excluded a posteriori by the good predictive performance in independent test sets and novel experiments.\\n\",\n",
      "        \"matches_optimization/parameters\": \"The authors do not mention parameters numbers different from standard. \",\n",
      "        \"matches_model/availability\": \"Publicly available R packages.\",\n",
      "        \"matches_model/interpretability\": \"No statement about ante-hoc interpretability of the model is made by the authors. The model looks to me black box. Post-hoc interpretability for the ipeptidylprolyl peptidase 4 (DPP4) gene is supported e.g. by literature reports that this gene significant increases in differentiated carcinomas vs. normal or benign thyroid nodules at average 46 times. However, the low univariate rankings of 2 of the 3 genes indicated that it was the genes combination, that resulted in good predictive power, and no attempt was made to explain such joint effect.\",\n",
      "        \"matches_model/output\": \"Binary classification between benign and malignant thyroid tumors.\",\n",
      "        \"matches_evaluation/comparison\": \"Despite the small number of genes in the panel, the ability to predict different categories of thyroid nodules was similar to that of published data from over 100 genes.\",\n",
      "        \"matches_evaluation/confidence\": \"Confidence Intervals are reported, by which a performance similarity between the 3 genes panel and the 100 genes panel is claimed.\",\n",
      "        \"matches_evaluation/measure\": \"Sensitivity, specificity, accuracy.\",\n",
      "        \"matches_evaluation/method\": \"Independent datasets and novel experiment. Independent dataset: GSE33630, GSE27155 and GSE3678. Novel experiment: Thyroid tissue specimens excised intraoperatively from 70 patients undergoing primary thyroidectomies in Renji Hospital\",\n",
      "        \"matches_dataset/availability\": \"Yes.  https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE29315, vhttps://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE33630, vhttps://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE27155, vhttps://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE3678   \",\n",
      "        \"matches_dataset/provenance\": \"Source:   Four published datasets from the gene expression omnibus (GEO)  series  GSE29315, GSE33630,  GSE27155 and GSE3678.      N_pos=176 patients, N_neg=113 patients.   GSE29315 already used in (Finley et al, Ann Surg, 2004)  GSE27155 already used in (Giordano et al, Oncogene, 2005, and Giordano et al, Clin Cancer Res 2006).\",\n",
      "        \"matches_dataset/splits\": \"Training set, GSE29315: N_pos_train=31, N_neg_train=40.         Testing sets, GSE33630: N_pos_test=60, N_neg_test=45.    GSE27155: N_pos_test=78, N_neg_test=21.  GSE3678:  N_pos_test=7, N_neg_test=7.    43.7% positives on training set,   57.1% positives on testing set GSE33630 ,  78.8% positives on testing set GSE27155,  50.0% positives on testing set GSE3678.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bb6\",\n",
      "        \"publication_pmid\": \"19994907\",\n",
      "        \"publication_updated\": \"03/24/2022 13:42:10\",\n",
      "        \"publication_authors\": \"Eng K, Scouten-Ponticelli SK, Sutton M, Berdis A\",\n",
      "        \"publication_journal\": \"ACS Chem Biol\",\n",
      "        \"publication_title\": \"Selective inhibition of DNA replicase assembly by a non-natural nucleotide: exploiting the structural diversity of ATP-binding sites.\",\n",
      "        \"publication_doi\": \"10.1021/cb900218c\",\n",
      "        \"publication_year\": \"2010\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"8bb488cc-4a32-481c-8c5c-82e9d7990c0e\",\n",
      "        \"shortid\": \"3p7aj2vzii\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches_publication/updated\": \"03/24/2022 13:42:10\",\n",
      "        \"matches_publication/authors\": \"Eng K, Scouten-Ponticelli SK, Sutton M, Berdis A\",\n",
      "        \"matches_publication/journal\": \"ACS Chem Biol\",\n",
      "        \"matches_publication/title\": \"Selective inhibition of DNA replicase assembly by a non-natural nucleotide: exploiting the structural diversity of ATP-binding sites.\",\n",
      "        \"matches_optimization/encoding\": \"the protein interaction data, gene expression profiles and protein\\ncomplex data for yeast genes are integrated into one functional linkage graph\",\n",
      "        \"matches_optimization/features\": \"SVD technique was employed to reduce the dimensionality and remove noise. 13 features.\",\n",
      "        \"matches_optimization/fitting\": \"to evaluate the functional similarity between a pair of genes, the Czekanowski-Dice distance was employed. After that, the functional similarity between any pair of genes was represented as a real value between 0 and 1\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/comparison\": \"The AGPS algorithm is different from existing methods, which have inappropriate assumptions about those genes that have no target annotation.\",\n",
      "        \"matches_evaluation/measure\": \"precision, recall and F1\",\n",
      "        \"matches_evaluation/method\": \"cross-validation and independent dataset\",\n",
      "        \"matches_dataset/availability\": \"DOI: 10.1093/nar/gkh894, DOI: 10.1093/nar/gkj109, \",\n",
      "        \"matches_dataset/provenance\": \"FunCat dataset used by DOI: 10.1093/nar/30.1.31, BioGRID database, SMD, MIPS\",\n",
      "        \"matches_dataset/splits\": \"1) 13 general functional classes were selected, and 4049 genes have been annotated in total.\\n2) 82,633 pairs of interactions among 5,299 yeast genes, of which 4049 genes are annotated by the 13 functional classes. \\n3) 5,132 genes with 278 real value features for\\ngene expression data.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b3b\",\n",
      "        \"publication_pmid\": \"22913485\",\n",
      "        \"publication_updated\": \"02/11/2022 16:40:03\",\n",
      "        \"publication_authors\": \"Akella LM, Norton CN, Miller H\",\n",
      "        \"publication_journal\": \"BMC Bioinformatics\",\n",
      "        \"publication_title\": \"NetiNeti: discovery of scientific names from text using machine learning methods.\",\n",
      "        \"publication_doi\": \"10.1186/1471-2105-13-211\",\n",
      "        \"publication_year\": \"2012\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"b879f61f-b41d-4e82-ad6e-fd33b4e669f1\",\n",
      "        \"shortid\": \"ku9smf88dv\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches_publication/updated\": \"02/11/2022 16:40:03\",\n",
      "        \"matches_publication/authors\": \"Akella LM, Norton CN, Miller H\",\n",
      "        \"matches_publication/journal\": \"BMC Bioinformatics\",\n",
      "        \"matches_publication/title\": \"NetiNeti: discovery of scientific names from text using machine learning methods.\",\n",
      "        \"matches_optimization/algorithm\": \"Logistic regression.\",\n",
      "        \"matches_optimization/features\": \"Only 5 predictors available, no selection applied in this work.  The 5 predictors were the result of a selection applied in a previous work (PMID: 21136905), by quantifying differentially expressed proteins in urine proteomes.\",\n",
      "        \"matches_optimization/fitting\": \"Bootstrap cross-validation was used for the internal validation to ensure that overfitting is avoided. Following that, elastic net was used for the regularisation of the coefficients to obtain the final model.  \",\n",
      "        \"matches_optimization/parameters\": \"The authors do not mention parameters numbers different from standard. \",\n",
      "        \"matches_optimization/regularization\": \"Yes, use of elastic net.\",\n",
      "        \"matches_model/availability\": \"Logistic regression: The \\u201cglmnet\\u201d package from R was used with elastic net regularisation. NN: Python packages tensorflow, keras, and scikit-learn. RF: The \\u201cparty\\u201d package from R. SVM: The \\u201csvmLinear\\u201d method from the \\u201ccaret\\u201d package in R was used. NF: The r-algorithm developed by Shor was used with a precision \\u03b5 = 0.001. Software implementation of this approach was developed within the Visual Studio 2013 environment.\",\n",
      "        \"matches_model/interpretability\": \"Logistic Regression is generally considered transparent. In a previous work (PMID: 26240291) the authors examined the good predicting power of each of the 3 urine biomarkers (LYVE1, REG1A, and TFF1) taken separately. However, an explaination of the joint effect of the variables has not been attempted.\",\n",
      "        \"matches_model/output\": \"Binary classification (high PDAC risk or not).\",\n",
      "        \"matches_evaluation/comparison\": \"Logistic regression was compared to neural network (NN), neuro-fuzzy technology (NF), random forest (RF) and support vector machine (SVM). None of those additional approaches significantly outperformed logistic regression.\",\n",
      "        \"matches_evaluation/confidence\": \"Inference for the ROC curves was based on cluster-robust standard errors that accounted for the serially correlated nature of the samples. It was not possible to create ROC curves and therefore AUC for RF and SVM since the outcome was not continuous. McNemar\\u2019s exact test was used to assess the significance of difference in SN at fixed SP and DeLong\\u2019s test was used to assess the significance of differences in AUC between approaches. Confidence intervals (CI 95%) for AUCs were derived based on the DeLong\\u2019s method to evaluate the uncertainty of an AUC; SN and SP 95% CI were derived using bootstrap replicates. To allow for multiple testing, both types of tests were adjusted using the Bonferroni correction.\",\n",
      "        \"matches_evaluation/measure\": \"AUROC (except for RF and SVM) and sensitivity at clinically relevant specificity.\",\n",
      "        \"matches_evaluation/method\": \"Independent dataset.\",\n",
      "        \"matches_dataset/availability\": \"Data available on request from the corresponding author.\",\n",
      "        \"matches_dataset/provenance\": \"Specimens collected at the Royal London Hospital, University College London Hospital, Liverpool University and the CNIO Madrid, Spain, plus further samples obtained from Pancreas Tissue Bank (https://www. bartspancreastissuebank.org.uk).  N_pos = 199 ( pancreatic ductal adenocarcinoma (PDAC) patients), N_neg = 180 (healthy patients). No previously used.\",\n",
      "        \"matches_dataset/splits\": \"Random division in a 1:1 ratio for train and test.   N_pos_train = 96, N_neg_train = 95,  N_pos_test = 103, N_neg_test = 85.    50.3% positives on training set.   54.8% positives on test set.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b3c\",\n",
      "        \"publication_pmid\": \"22532634\",\n",
      "        \"publication_updated\": \"05/20/2022 15:57:36\",\n",
      "        \"publication_authors\": \"Pratt AG, Swan DC, Richardson S, Wilson G, Hilkens CM, Young DA, Isaacs JD\",\n",
      "        \"publication_journal\": \"Ann Rheum Dis\",\n",
      "        \"publication_title\": \"A CD4 T cell gene signature for early rheumatoid arthritis implicates interleukin 6-mediated STAT3 signalling, particularly in anti-citrullinated peptide antibody-negative disease.\",\n",
      "        \"publication_doi\": \"10.1136/annrheumdis-2011-200968\",\n",
      "        \"publication_year\": \"2012\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"74f23aa2-985c-49d2-9a0d-0d7b3e0f4bda\",\n",
      "        \"shortid\": \"p00ybazkxy\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches_publication/updated\": \"05/20/2022 15:57:36\",\n",
      "        \"matches_publication/authors\": \"Pratt AG, Swan DC, Richardson S, Wilson G, Hilkens CM, Young DA, Isaacs JD\",\n",
      "        \"matches_publication/journal\": \"Ann Rheum Dis\",\n",
      "        \"matches_publication/title\": \"A CD4 T cell gene signature for early rheumatoid arthritis implicates interleukin 6-mediated STAT3 signalling, particularly in anti-citrullinated peptide antibody-negative disease.\",\n",
      "        \"matches_optimization/algorithm\": \"LightGBM (a gradient boosting framework using tree based learning algorithms) is stated in the Supplementary to have been the algorithm of choice.\",\n",
      "        \"matches_optimization/encoding\": \"For character data field (like sex, pathogenesis), the LabelEncoder method in Python was used (categorical features encoded as a one-hot numeric array).\",\n",
      "        \"matches_optimization/features\": \"Starting from 24 features (clinical measurements commons to the 4 hospitals), 9 features were selected for training, by means of LASSO regression and filter methods (the latter being variance threshold, Pearson Correlation Coefficient, chi-square test and mutual information).\",\n",
      "        \"matches_optimization/fitting\": \"The LightGBM algorithm is stated in its documentation likely to be over-fitting if not used with the appropriate parameters. \",\n",
      "        \"matches_optimization/parameters\": \"The number of parameters was the standard for Python implementation of LightGBM.  Parameters were tuned to get good results by means of grid search, random search and the Python library Hyperopt.\",\n",
      "        \"matches_optimization/regularization\": \"Yes.  The authors state that, \\\"to prevent overfitting, the index of colsample_bytree was set to 0.9\\\".    Other parameters tuning for over-fitting prevention is not mentioned. \",\n",
      "        \"matches_model/availability\": \"The ML algorithms were implemented using Python 3.7.\",\n",
      "        \"matches_model/duration\": \"The run time of FibroBox is mentioned in the Discussion to be only a few seconds.\",\n",
      "        \"matches_model/interpretability\": \"No statement about ante-hoc interpretability of the model is made by the authors. This LightGBM model looks to me complex enough to result rather black box. Post-hoc analysis showed e.g. that the contribute of the Transient Elastography (TE) feature to the good predictability was very relevant, which is meaningful. An explaination for an eventual joint effect of the 9 features was not adressed.\",\n",
      "        \"matches_model/output\": \"Classification. Case A: positive and negative samples are non-significant fibrosis vs. significant fibrosis. Case B: positive and negative samples are non-cirrhosis vs. cirrhosis.\",\n",
      "        \"matches_evaluation/comparison\": \"FibroBox was compared to 3 other pre-existing predicting methods: TE (Transient Elastography), APRI (Aspartate transaminase-to-platelet ratio index), FIB-4 (fibrosis-4 index), the letter two being serum biomarkers. The LightGBM algorithm was coompared to Logistic regression and XGBoost.\",\n",
      "        \"matches_evaluation/confidence\": \"Confidence intervals at 95% for AUROC, statistical significance confirmed for the difference between FibroBox and each of TE, APRI, FIB-4 methods, both for fibrosis and for cyrrhosis predictions.\",\n",
      "        \"matches_evaluation/measure\": \"Precision, recall, F1-score, accuracy, AUROC. The latter was used for feature selection, and for comparison with other models.\",\n",
      "        \"matches_evaluation/method\": \"5-fold cross-validation during training-testing. Two independent datasets were used as evaluation sets: the Anhui cohort (n = 408), and the Beijing cohort (n=332).\",\n",
      "        \"matches_dataset/availability\": \"According to the author's statement, the data are not available because of patients\\u2019 privacy.\",\n",
      "        \"matches_dataset/provenance\": \"Clinical data from 4 different hospitals in China (4 different cities) about piatients with chronic B virus hepatitis. N = 1289 (patients from 4 different cities).  N_pos (fibrosis) = 815, N_neg (fibrosis) = 474 ;    N_pos (cirrhosis) = 290, N_neg (cirrhosis) = 999.   Data not used by previous authors.\",\n",
      "        \"matches_dataset/splits\": \"Training set:   N = 549  (patients from 2 different cities, joined together).  N_pos (fibrosis) = 382 / N_neg (fibrosis) = 167 ;    N_pos (cirrhosis) = 157 // N_neg (cirrhosis) = 392.   Test set Anhui:   N = 408 (independent patients dataset from Anhui city).  N_pos (fibrosis) = 254 // N_neg (fibrosis) = 154 ;    N_pos (cirrhosis) = 59 // N_neg (cirrhosis) = 359.     Test set Beijing:   N = 332 (independent patients dataset from Beijing city).  N_pos (fibrosis) = 179 // N_neg (fibrosis) = 153 ;    N_pos (cirrhosis) = 74 // N_neg (cirrhosis) = 258.        69.6% positives (fibrosis), 28.6% positives (cirrhosis) on training set.   62.3% positives (fibrosis), 14.5% positives (cirrhosis) on Anhui test set.  53.9% positives (fibrosis), 22.3% positives (cirrhosis) on Beijing test set.  \"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b84\",\n",
      "        \"publication_pmid\": \"22408447\",\n",
      "        \"publication_updated\": \"01/31/2022 11:13:16\",\n",
      "        \"publication_authors\": \"Zhao X, Ma Z, Yin M\",\n",
      "        \"publication_journal\": \"Int J Mol Sci\",\n",
      "        \"publication_title\": \"Using support vector machine and evolutionary profiles to predict antifreeze protein sequences.\",\n",
      "        \"publication_doi\": \"10.3390/ijms13022196\",\n",
      "        \"publication_year\": \"2012\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"052c537c-d355-4d83-9a5b-2587a9451a4d\",\n",
      "        \"shortid\": \"0zaakstjvr\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches_publication/updated\": \"01/31/2022 11:13:16\",\n",
      "        \"matches_publication/authors\": \"Zhao X, Ma Z, Yin M\",\n",
      "        \"matches_publication/journal\": \"Int J Mol Sci\",\n",
      "        \"matches_publication/title\": \"Using support vector machine and evolutionary profiles to predict antifreeze protein sequences.\",\n",
      "        \"matches_optimization/algorithm\": \"Four approaches were compared: logistic regression (LR), multivariate adaptive regression splines (MARS), artificial neural networks (ANN), random forest (RF). \",\n",
      "        \"matches_optimization/features\": \"Exploratory data analyses resulted in removal of correlated predictors (\\u00b10.90).   In the end, 7 predictors were used (i.e. 7 types of environmental data -- air temperature, relative humidity, etc).  The \\u201cvarImp\\u201d function contained in the caret package was used to determine the relative predictor importance for each model. Each model was run using 3, 4, 5, 6, and 7 predictors. The most important variables were selected for the development of the final model.\",\n",
      "        \"matches_optimization/fitting\": \"Over-fitting in MARS and ANN was discussed and prevented.   In LR and RF, over-fitting should not have been an issue.  Possible underfitting was probabiy there for LR, which, with a kappa of 0.16, indicated a low degree of similarity, between observed and predicted, beyond random chance.\",\n",
      "        \"matches_optimization/parameters\": \"For LR, MARS, RF, the authors do not mention parameters numbers different from standard.   For ANN, weights can be deduced to have been in the range of 100. Their number depended on the number of nodes in the hidden layer, which was optimized using 10-fold cross-validation and the AUROC curve for model assessment.\",\n",
      "        \"matches_optimization/regularization\": \"For MARS, the forward stepwise algorithm leads to an overfitted model which is then run through a backward stepwise algorithm where basis functions that contribute the least are removed (Friedman1991).   For RF,  to reduce overfitting, the tree was often pruned, resulting in a smaller tree with fewer splits. This was accomplished using the Gini index, which is a measure of variance across all classes\\u2014smaller values mean a more accurate prediction at that node.\",\n",
      "        \"matches_model/availability\": \"Standard algorithms were used.\",\n",
      "        \"matches_model/interpretability\": \"No statement about ante-hoc interpretability of the models is made by the authors. LR and MARS are generally considered interpretable models, while ANN and RF are generally considered not interpretable. Post-hoc feature importance analysis indicated as the most important ones soil moisture, precipitation, and air temperature (LR model), or soil temperature, soil moisture, and solar radiation (MARS, ANN, RF models) -- all of them in line with conclusions found in experimental literature.\",\n",
      "        \"matches_model/output\": \"Classification (binary prediction). The continuous output of the LR, MARS, ANN was assigned as 'close to 1' or 'close to 0'.\",\n",
      "        \"matches_evaluation/comparison\": \"Four approaches were compared: LR, MARS, ANN, RF. Model performance was compared based on the AUROC, kappa-metrics, and Brier score. The best measures were those of RF.\",\n",
      "        \"matches_evaluation/confidence\": \"Model performance was compared based on the AUROC, kappa metrics, and Brier score. The AUROC of the RF model was highest at 0.74, significantly higher than LR (with a value of 0.57) but not significantly different from the ANN or MARS models. LR had a very low kappa value (0.16), while RF had kappa values between 0.43 and 0.57, higher than ANN and MARS values of between 0.35 and 0.5 and, therefore, has the best prediction potential among the four models tested in this study based on the kappa metric.\",\n",
      "        \"matches_evaluation/measure\": \"Accuracy, sensitivity, specificity, AUROC.\",\n",
      "        \"matches_dataset/provenance\": \"Total dataset composed of 535 in-field observations, N_pos = 84  (presence of spore-realising apothecia) and N_neg = 352 (absence of spore-realising apothecia).  Dataset not previously used.\",\n",
      "        \"matches_dataset/splits\": \"The dataset was randomly split into training (70%) and testing (30%) using the \\u201ccreateDataPartition\\u201d function part of the caret package in R (version 3.2.4 for iOS).  Each model was trained with 10-fold cross-validation.    The random splitting of the data, model training, and assessment on the test set were performed 100 times to ascertain the variance of each model due to the random data splitting.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bad\",\n",
      "        \"publication_pmid\": \"22558141\",\n",
      "        \"publication_updated\": \"03/24/2022 11:24:39\",\n",
      "        \"publication_authors\": \"Wrzodek C, B\\u00fcchel F, Hinselmann G, Eichner J, Mittag F, Zell A\",\n",
      "        \"publication_journal\": \"PLoS One\",\n",
      "        \"publication_title\": \"Linking the epigenome to the genome: correlation of different features to DNA methylation of CpG islands.\",\n",
      "        \"publication_doi\": \"10.1371/journal.pone.0035327\",\n",
      "        \"publication_year\": \"2012\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"c3ffe65b-e1f7-4326-a75c-44891ea42eb2\",\n",
      "        \"shortid\": \"y6rde1aew5\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches_publication/updated\": \"03/24/2022 11:24:39\",\n",
      "        \"matches_publication/authors\": \"Wrzodek C, B\\u00fcchel F, Hinselmann G, Eichner J, Mittag F, Zell A\",\n",
      "        \"matches_publication/journal\": \"PLoS One\",\n",
      "        \"matches_publication/title\": \"Linking the epigenome to the genome: correlation of different features to DNA methylation of CpG islands.\",\n",
      "        \"matches_optimization/features\": \"f = 12.   Starting from 16,205 genes, 12 genes were at the end selected as differentially expressed in RA versus non-RA patients.  Differential expression was defined as a fold-change cut-off of 1.2, combined with a significance level cut-off of p<0.05 (Welch\\u2019s t-test), corrected for multiple testing using the false-discovery-rate method of Benjamini.\",\n",
      "        \"matches_optimization/parameters\": \"\\nThe authors do not mention parameters numbers different from standard. \\n\",\n",
      "        \"matches_model/availability\": \"Standard algorithms are used.\",\n",
      "        \"matches_model/interpretability\": \"No statement about ante-hoc interpretability of the model is made by the authors. SVM is generally considered black box. Post-hoc analysis indicates that PB CD4 T cells in early RA are characterised by a predominant upregulation of biological pathways involved in cell cycle progression (ACPA-positive) and survival, death and apoptosis (ACPA-negative). ( ACPA = anti-citrullinated peptide antibodies)\",\n",
      "        \"matches_model/output\": \"Binary prediction: RA or non-RA.\",\n",
      "        \"matches_evaluation/comparison\": \"A transcriptional \\u2018risk metrics\\u2019 for ACPA-negative patients was bild, and the AUROC curve of the 12-gene signature was compared to the existing \\u2018Leiden prediction rule\\u2019 as a predictor of RA in the test set. No difference in the performance was seen in this case. However, by combining all features of the Leiden prediction rule with the 12-gene risk metric, and applying it to the ACPA-negative UA cohort (test set), the AUROC curve value improved from 0.74, SEM=0.08 (original Leiden prediction rule) to 0.84; SEM=0.06 (modified metric incorporating gene signature).\",\n",
      "        \"matches_evaluation/confidence\": \"AUROC curve (original Leiden prediction rule)=0.74; SEM=0.08 versus area under ROC curve (modified metric incorporating gene signature)=0.84; SEM=0.06; p<0.001 in both cases.\",\n",
      "        \"matches_evaluation/measure\": \"Sensitivity, specificity, positive and negative likelihood ratio.\",\n",
      "        \"matches_evaluation/method\": \"Test set (independent dataset).\",\n",
      "        \"matches_dataset/availability\": \"Yes.    Raw and processed microarray data used in this study is available via Gene Expression Omnibus at: http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?token=bviftkociimgsnk&acc=GSE20098\",\n",
      "        \"matches_dataset/provenance\": \"CD4 T-cell transcriptomes from 173 UK patients, of which N_pos = 72  (RA, i.e. outcome Rheumatoid Arthritis), N_neg =101 (outcome Non-RA).  Not used in previous papers.\",\n",
      "        \"matches_dataset/splits\": \"111 patients in training set, of which N_pos_train = 47  (RA), N_neg_train = 64 (Non-RA).    62 patients in testing set, of which N_pos_test = 25  (RA), N_neg_test = 37 (Non-RA).   42.3% positives on training set.   40.3% positives on test set.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b3d\",\n",
      "        \"publication_pmid\": \"23102953\",\n",
      "        \"publication_updated\": \"03/08/2022 14:59:55\",\n",
      "        \"publication_authors\": \"Gonz\\u00e1lez-Recio O, Jim\\u00e9nez-Montero JA, Alenda R\",\n",
      "        \"publication_journal\": \"J Dairy Sci\",\n",
      "        \"publication_title\": \"The gradient boosting algorithm and random boosting for genome-assisted evaluation in large data sets.\",\n",
      "        \"publication_doi\": \"10.3168/jds.2012-5630\",\n",
      "        \"publication_year\": \"2013\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"7f0eb63d-7a88-4b70-82f9-857b0399a39f\",\n",
      "        \"shortid\": \"9hqbg4dzys\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches_publication/updated\": \"03/08/2022 14:59:55\",\n",
      "        \"matches_publication/authors\": \"Gonz\\u00e1lez-Recio O, Jim\\u00e9nez-Montero JA, Alenda R\",\n",
      "        \"matches_publication/journal\": \"J Dairy Sci\",\n",
      "        \"matches_publication/title\": \"The gradient boosting algorithm and random boosting for genome-assisted evaluation in large data sets.\",\n",
      "        \"matches_optimization/algorithm\": \"SVM and RF.\",\n",
      "        \"matches_optimization/features\": \"The study focused on 412 proteins (of the 1296 identified proteins in each proteome) quantified in more than 80% of urine samples, with missing values filled by local least squares imputation.  From those 412 proteins, 5 proteins (ACP2, CTSA, GM2A, MUC1, and SPARCL1) were selected as significant by an AUC-based random forest method. \",\n",
      "        \"matches_optimization/fitting\": \"The authors do not mention overfitting issues, although their multivariate AUROCs showed very high values.\",\n",
      "        \"matches_optimization/parameters\": \"The authors do not mention parameters numbers different from standard.  They mention the value of some parameters, without mentioning how they were chosen. \",\n",
      "        \"matches_model/availability\": \"Data were analyzed using the publicly available RStudio (version 1.1.456) including R (version 3.6.0).\",\n",
      "        \"matches_model/interpretability\": \"No statement about ante-hoc interpretability of the models is made by the authors. The RF and SVM are generally considered black box. Post-hoc analysis resulted somewhat interpretable, since the 5 selected features correspond to 5 urinary proteins that are considered likely to be related to DKD. However, their eventual joint effect remains not interpretable.\",\n",
      "        \"matches_model/output\": \"Binary classification (PPG or GPG). The binary results of RF and SVM models were also transformed in disease prediction scores, which ranged from 0 to 1.\",\n",
      "        \"matches_evaluation/comparison\": \"The performances of the SVM and RF models were compared to the predicting performance of the albumin-to-creatinine ratio, a simple biomarker for DKD which has been widely used so far.\",\n",
      "        \"matches_evaluation/confidence\": \"The authors state that the AUROC of the two classifiers (SVM and RF) differed significantly from albumin-to-creatinine ratio (likelihood ratio test: p-value < 0.05). However, for the RF AUROC (value = 1.0) no confidence intervals are reported, and the confidence intervals for SVM AUROC are not further specified.\",\n",
      "        \"matches_evaluation/measure\": \"AUROC. Comparison of disease prediction scores.\",\n",
      "        \"matches_evaluation/method\": \"Cross-validation. Since the authors were unable to find a benchmarking study in the discovery of urine protein biomarkers, they evaluated the models with mRNA expression in the kidney. The SVM and RF models consisting of 5 urine proteins were applied to 4 publicly available GEO datasets: GSE99339, GSE47185, GSE30122, and GSE96804. However, the predictions on such datasets were not statistically significant.\",\n",
      "        \"matches_dataset/availability\": \"Yes. Supporting Information.\",\n",
      "        \"matches_dataset/provenance\": \"Proteomes of urine samples from 54 T2D (Type 2 Diabetes) patients from Pusan National University Hospital, South Korea. N_pos = 19 (poor prognosis group (PPG) due to DKD (Diabetic Kidney Disease), N_neg = 35 (good prognosis group (GPG), i.e. no DKD).   Not used in previous papers.\",\n",
      "        \"matches_dataset/splits\": \"SVM model with linear kernel was generated by a 10 fold repeated three-fold cross validation.  The RF model was generated by a 3-fold cross validation method repeated 100 times.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bb2\",\n",
      "        \"publication_pmid\": \"25404408\",\n",
      "        \"publication_updated\": \"03/28/2022 23:06:53\",\n",
      "        \"publication_authors\": \"Ultsch A, L\\u00f6tsch J\",\n",
      "        \"publication_journal\": \"BMC Genomics\",\n",
      "        \"publication_title\": \"What do all the (human) micro-RNAs do?\",\n",
      "        \"publication_doi\": \"10.1186/1471-2164-15-976\",\n",
      "        \"publication_year\": \"2014\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"98d8027e-41f2-4b54-8fd6-20c9b51e7bdf\",\n",
      "        \"shortid\": \"w5mge5bmyl\",\n",
      "        \"score\": 0.52,\n",
      "        \"matches_publication/updated\": \"03/28/2022 23:06:53\",\n",
      "        \"matches_publication/authors\": \"Ultsch A, L\\u00f6tsch J\",\n",
      "        \"matches_publication/journal\": \"BMC Genomics\",\n",
      "        \"matches_publication/title\": \"What do all the (human) micro-RNAs do?\",\n",
      "        \"matches_optimization/algorithm\": \"J48 Algorithm For Decision Tree (WEKA)   Decision tree J48 is the implementation of algorithm ID3 (Iterative Dichotomiser 3) developed by the WEKA project team. \",\n",
      "        \"matches_optimization/encoding\": \"Global features\",\n",
      "        \"matches_optimization/features\": \"Sequence-based statistics were derived through a customized feature extraction program and fed as a vector for each polymorphism to the J48 classification tree available in the WEKA classifier package.  9 features were used to enhance polymorphism prediction accuracy (as reported in https://nealelab.ucdavis.edu/adept2-overview/pinesap/).\",\n",
      "        \"matches_model/availability\": \"Broken link (http://dendrome.ucdavis.edu/adept2/\\n resequencing.html). The customized pipeline for feature extraction is reported in a new link: https://nealelab.ucdavis.edu/adept2-overview/pinesap/\",\n",
      "        \"matches_model/interpretability\": \"Input features are transparent (Sequence Depth, Local Average Quality, Alignment Quality) while their combination is not interpretable (Black box).\",\n",
      "        \"matches_model/output\": \"Binary classifier (SNP predictions accepted or rejected).\",\n",
      "        \"matches_evaluation/comparison\": \"Polyphred, Polybayes. Used for generating the features.\",\n",
      "        \"matches_evaluation/measure\": \"Accuracy, sensitivity, specificity\",\n",
      "        \"matches_evaluation/method\": \"Independent dataset of 120 unique sequences with 563 manually validated SNPs. Validation = All SNP calls were identified as based on visual inspection of Polyphred and Polybayes predictions in Consed.\",\n",
      "        \"matches_dataset/provenance\": \"Source: Pinus taeda resequencing data, not further specified.  Training set is composed of a total of 300 validated sequences.  Test set is composed of 120 independent sequences, with 563 manually validated SNPs.\",\n",
      "        \"matches_dataset/splits\": \"\\nTesting: 120 Sequences 563 manually validated SNPs\\n\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bb4\",\n",
      "        \"publication_pmid\": \"24675637\",\n",
      "        \"publication_updated\": \"03/08/2022 13:05:23\",\n",
      "        \"publication_authors\": \"Mahony S, Edwards MD, Mazzoni EO, Sherwood RI, Kakumanu A, Morrison CA, Wichterle H, Gifford DK\",\n",
      "        \"publication_journal\": \"PLoS Comput Biol\",\n",
      "        \"publication_title\": \"An integrated model of multiple-condition ChIP-Seq data reveals predeterminants of Cdx2 binding.\",\n",
      "        \"publication_doi\": \"10.1371/journal.pcbi.1003501\",\n",
      "        \"publication_year\": \"2014\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"8067befa-adce-4b5a-9da3-d16a3566a794\",\n",
      "        \"shortid\": \"36d464edpz\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches_publication/updated\": \"03/08/2022 13:05:23\",\n",
      "        \"matches_publication/authors\": \"Mahony S, Edwards MD, Mazzoni EO, Sherwood RI, Kakumanu A, Morrison CA, Wichterle H, Gifford DK\",\n",
      "        \"matches_publication/journal\": \"PLoS Comput Biol\",\n",
      "        \"matches_publication/title\": \"An integrated model of multiple-condition ChIP-Seq data reveals predeterminants of Cdx2 binding.\",\n",
      "        \"matches_optimization/algorithm\": \"\\\"Hybrid dynamic Bayesian network (DBN) / support\\nvector machine (SVM)\\\"\",\n",
      "        \"matches_optimization/encoding\": \"\\\"Pre-processing: Input data obtained from MS/MS data, an aqueous soluble protein sample from E.coli lysate was reduced, carbamidomethylated and digested with trypsin.\\\"\",\n",
      "        \"matches_optimization/features\": \"\\\"99-dimensional feature vectors generated by Riptide (Bayesian part)\\\"\",\n",
      "        \"matches_optimization/parameters\": \"For the SVM, we use a Gaussian kernel, and hyperparameters C (soft margin penalty) and sigma (low case, width of the Gaussian). Hyperparameters are selected using five-fold nested cross-validation, where the parameter with the largest area under the ROC curve is selected.\",\n",
      "        \"matches_model/availability\": \"Upon request (but did not try to get it, there is a link to a tar file with, it says, C++ and Python for the Riptide part, I did not examine the files)\",\n",
      "        \"matches_evaluation/comparison\": \"SEQUEST, Percolator\",\n",
      "        \"matches_evaluation/confidence\": \"\\\"q value, which is defined as the minimal false discovery rate threshold at which the\\n PSM is deemed significant\\\"\",\n",
      "        \"matches_evaluation/measure\": \"Kind of discussed but did not see values\",\n",
      "        \"matches_evaluation/method\": \"\\\"Comparison against SEQUEST (Riptide with the static SVM outperforms SEQUEST by 10.8% at a 1% false discovery rate) and Percolator\\\"\",\n",
      "        \"matches_dataset/availability\": \"PSMs at http://noble.gs.washington.edu/proj/intense (also stated that availability is upon request but the URL indeed has links to the data)\",\n",
      "        \"matches_dataset/provenance\": \"1208 peptide spectrum matches (PSMs) and 18149 mass spectra for validation\",\n",
      "        \"matches_dataset/splits\": \"Positive and negative points for the Bayesian network are mentioned but no further info provided\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bb5\",\n",
      "        \"publication_pmid\": \"24977146\",\n",
      "        \"publication_updated\": \"03/15/2022 11:52:26\",\n",
      "        \"publication_authors\": \"Xu R, Zhou J, Liu B, Yao L, He Y, Zou Q, Wang X\",\n",
      "        \"publication_journal\": \"Biomed Res Int\",\n",
      "        \"publication_title\": \"enDNA-Prot: identification of DNA-binding proteins by applying ensemble learning.\",\n",
      "        \"publication_doi\": \"10.1155/2014/294279\",\n",
      "        \"publication_year\": \"2014\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"37b6eb38-2c74-40e9-9f75-95d27907ae41\",\n",
      "        \"shortid\": \"qto6tkwcli\",\n",
      "        \"score\": 0.48,\n",
      "        \"matches_publication/updated\": \"03/15/2022 11:52:26\",\n",
      "        \"matches_publication/authors\": \"Xu R, Zhou J, Liu B, Yao L, He Y, Zou Q, Wang X\",\n",
      "        \"matches_publication/journal\": \"Biomed Res Int\",\n",
      "        \"matches_publication/title\": \"enDNA-Prot: identification of DNA-binding proteins by applying ensemble learning.\",\n",
      "        \"matches_optimization/algorithm\": \"The semantic role labeling (SRL) system BIOSMILE, which is based on Maximum entropy. \\n\\nNovel rule-based converter based on verb-by-verb conversion rules which describe under which conditions each mapping is valid.The algorithm used by the rule-generator compares corresponding framesets for a given verb sense, checks each argument in its PASBio frameset, and tries to find an argument in its BioProp frameset that has the same semantic role under a set of conditions. When a match is found, the algorithm maps a link between the two frameset arguments, which includes a description of required conditions, named entities (NEs) and keywords.\\n\",\n",
      "        \"matches_optimization/encoding\": \"1)\\tTagging of 5 names entities (NEs), protein, Dnot reported, Rnot reported, cell line, and cell type, with NERBio recognition software. A dictionary was used to find other NE types, such as exon and intron.\\n2)\\tIdentification of the PAS objects of each sentence followed by classification of the semantic roles of the arguments according to BioProp format, using BIOSMILE SRL system.\\n3)\\tRule-based conversion from BioProp to PASBio annotation, using the novel rule-based converter.\\n\",\n",
      "        \"matches_optimization/features\": \"Semantic roles of PAS objects following PASBio annotation\",\n",
      "        \"matches_optimization/meta\": \"Yes. Combination of BIOSMILE SRL system output with novel rule-based converter. Independency not reported.\",\n",
      "        \"matches_model/output\": \"Multi-label predictions\",\n",
      "        \"matches_evaluation/comparison\": \"Comparison with ML-based SRL systems of other specific domains based on F-score performance\",\n",
      "        \"matches_evaluation/measure\": \"Precision, recall, F-score\",\n",
      "        \"matches_evaluation/method\": \"3-fold cross-validation\",\n",
      "        \"matches_dataset/provenance\": \"Manually re-annotated 313 sentences, containing 2304 predicate-argument structures (PAS) annotated for 49 biomedical verbs.\",\n",
      "        \"matches_dataset/splits\": \"Separation of dataset into 3 subsets. Ntrain = 2 subsets. Ntest = 1 subset. The process is repeated three times, with each of the test sets being used exactly once (3-fold cross-validation).\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"66732d6237ea6fa797a6c33c\",\n",
      "        \"shortid\": \"ats2zi61i5\",\n",
      "        \"uuid\": \"1dcb40c7-3c20-484d-9f45-bcf91cfd4d17\",\n",
      "        \"created\": \"2024-06-19T19:11:30.981Z\",\n",
      "        \"updated\": \"2024-06-19T19:11:30.981Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"24498380\",\n",
      "        \"publication_authors\": \"Daniel Beck, James A. Foster\",\n",
      "        \"publication_journal\": \"PLOS One\",\n",
      "        \"publication_title\": \"Machine Learning Techniques Accurately Classify Microbial Communities by Bacterial Vaginosis Characteristics\",\n",
      "        \"publication_doi\": \"10.1371/journal.pone.0087830\",\n",
      "        \"publication_year\": \"2014\",\n",
      "        \"score\": 0.95,\n",
      "        \"matches_evaluation/availability\": \"No availability of evaluation files, code, etc.\",\n",
      "        \"matches_evaluation/comparison\": \"No comparison was made to any publicly available methods.\\n\\nNo benchmark datasets used or against simpler baselines compared to unless considering the complexity variances between the 3x models to be a simpler baseline varying by model complexity.\",\n",
      "        \"matches_evaluation/confidence\": \"No confidence intervals or values noted in the text. \",\n",
      "        \"matches_evaluation/measure\": \"The performance measures used to evaluate the accuracy of the 3x models were:\\n-The accuracy of the 3x models at performing the correct classification (above 90% for Nugent score BV + above 80% for Amsel criteria BV.)\\n-The receiver operator curves (ROCs) of the 3x models in 'Figure 2. A comparison of the classification accuracies for each machine learning technique'\",\n",
      "        \"matches_evaluation/method\": \"10-fold cross-validation was noted as the primary evaluation method used in the text.\\n\\nAdditionally, the authors compare the 3x models on two datasets but these seem to be the same ones used to train the models. No clarity on splits or redundancy of the model data for the evalutaion vs training.\",\n",
      "        \"matches_optimization/algorithm\": \"Text notes used of three machine learning algorithm types.\\n\\nML algorithms: \\n1. Gaussian process classifier\\n2. Random forests\\n3. Logistic regression \\n\\nNot new algorithms.\\n\\nChose these types as some are more efficient than others at the classification needed.\",\n",
      "        \"matches_optimization/config\": \"No - not reported in text and no links to configurations.\",\n",
      "        \"matches_optimization/encoding\": \"Not explicitly noted in text. Data will likely have been encoded for Microbial Taxa & BV status.\",\n",
      "        \"matches_optimization/features\": \"Features noted to be algorithm specific across each of the 3x models created.\\n\\nTable 1. This table shows the fifteen most important features identified by the different classifiers.\\n-Based on this it can be inferred that the models had at least 15x features but does not list all or the total number.\\n\\nFeature selection seems to have been done as the author notes that they ranked the features by their apparent importance to each model.\",\n",
      "        \"matches_optimization/fitting\": \"Potentially models were overfit. No exact p or f numbers to help determination. There are low dataset sizes noted in text (396 and 220). However, the text notes some overfitting prevention methods such as cross-validation and model complexity penalties.\",\n",
      "        \"matches_optimization/parameters\": \"For the gaussian process classifier, Table 2. lists the parameter values used.\\n-6x parameters noted in the table and corresponding values.\\n\\nFor the random forest model,  the author notes use of R package 'randomForest' on default parameters. \\n\\nFor the logistic regression model, the author notes use of R package 'glmnet' on default parameters. \",\n",
      "        \"matches_optimization/regularization\": \"Ten-fold cross validation was the primary technique employed to prevent overfitting.\",\n",
      "        \"matches_model/availability\": \"No - no clear links to a code repository or GitHub from the publication.\",\n",
      "        \"matches_model/duration\": \"The different classification techniques varied widely in computational time: \\n\\n-Logistic regression + random forests were noted as relatively quick to run, usually completing in less than an hour on a single laptop. \\n\\n-Gaussian process classifier is noted to have taken several hours longer to run.\",\n",
      "        \"matches_model/interpretability\": \"Black box - missing a lot of key information. No GitHub linked for model code and no links to training/test data. Very poor use of the DOME related info breakdowns and 3x models poorly described overall in text making the interpretability black box like.\",\n",
      "        \"matches_dataset/availability\": \"Only publications listed - by searching these publications the data only seems to be available for one of the two and linked from its text as supplementary data files (Ravel et al. in 2011 [8]:). Data splits not available. No licenses or URL.\",\n",
      "        \"matches_dataset/provenance\": \"Data source: publications\\n\\nData type: 16S rRNA seq data (for understanding microbial communities - microbiome)\\n\\nThe data used consists of two different datasets drawn from studies published by:\\n-Ravel et al. in 2011 [8]:\\nRavel J, Gajer P, Abdo Z, Schneider GM, Koenig SSK, et al. (2011) Vaginal microbiome of reproductive-age women. Proceedings of the National Academy of Science USA 108: 4680\\u20134687.\\n\\n-Srinivasan et al. in 2012 [9]:\\nSrinivasan S, Hoffman NG, Morgan MT, Matsen FA, Fiedler TL, et al. (2012) Bacterial communities in women with bacterial vaginosis: high resolution phylogenetic analysis reveal relationships of microbiota to clinical criteria. PLoS One 7: 6.\",\n",
      "        \"matches_dataset/redundancy\": \"No information relating to the redundancy between data splits evident in the text.\",\n",
      "        \"matches_dataset/splits\": \"Data splits are not mentioned in the text.\\n\\nDataset sizes & data within:\\n-Ravel et al. dataset: 396 samples - included only asymptomatic participants\\n-Srinivasan et al. dataset: 220 samples - included women with and without a BV diagnosis.\",\n",
      "        \"matches_publication/authors\": \"Daniel Beck, James A. Foster\",\n",
      "        \"matches_publication/journal\": \"PLOS One\",\n",
      "        \"matches_publication/title\": \"Machine Learning Techniques Accurately Classify Microbial Communities by Bacterial Vaginosis Characteristics\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b73\",\n",
      "        \"publication_pmid\": \"26834994\",\n",
      "        \"publication_updated\": \"03/09/2022 11:07:20\",\n",
      "        \"publication_authors\": \"Ekins S, Freundlich JS, Clark AM, Anantpadma M, Davey RA, Madrid P\",\n",
      "        \"publication_journal\": \"F1000Res\",\n",
      "        \"publication_title\": \"Machine learning models identify molecules active against the Ebola virus <i>in vitro</i>.\",\n",
      "        \"publication_doi\": \"10.12688/f1000research.7217.3\",\n",
      "        \"publication_year\": \"2015\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"874bbd17-26ef-4992-9473-d3a4a22d9280\",\n",
      "        \"shortid\": \"p9igs00nw2\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches_publication/updated\": \"03/09/2022 11:07:20\",\n",
      "        \"matches_publication/authors\": \"Ekins S, Freundlich JS, Clark AM, Anantpadma M, Davey RA, Madrid P\",\n",
      "        \"matches_publication/title\": \"Machine learning models identify molecules active against the Ebola virus <i>in vitro</i>.\",\n",
      "        \"matches_optimization/algorithm\": \"Novel semi-supervised algorthm called AMVML (Adaptive Multi-View Multi-Label). No reason stated for not having published it before.\",\n",
      "        \"matches_optimization/encoding\": \"Not transformed\",\n",
      "        \"matches_optimization/features\": \"not reported, but could be inferred from the text.\",\n",
      "        \"matches_optimization/parameters\": \"not reported, maybe could be inferred from the paper.\",\n",
      "        \"matches_model/availability\": \"Yes for one specific case: https://github.com/alcs417/AMVML\",\n",
      "        \"matches_model/interpretability\": \"Trasparent. Prediction based on similarity between different miRNAs and different diseases. If a given miRNA is associated to a given disease D, it might be associated only with diseases similar to D\",\n",
      "        \"matches_model/output\": \"Regression (association probability with a disease)\",\n",
      "        \"matches_evaluation/comparison\": \"Compared with other 4 methods for predicting miRNA-disease association. Statistical significance is given as proof for performance.\",\n",
      "        \"matches_evaluation/confidence\": \"The performarce difference is statistically significant compared to other 4 algorithms\",\n",
      "        \"matches_evaluation/measure\": \"Area Under Curve (AUC)\",\n",
      "        \"matches_evaluation/method\": \"Leave-one-out validation and 5-fold cross-validation on Dataset 1\\n 5-fold cross validation on Dataset 3\",\n",
      "        \"matches_dataset/availability\": \"Dataset 1: No.\\n\\nDataset 2: No.\\n\\nDataset 3. Yes. URL: https://portal.gdc.cancer.gov/projects/TCGA-THCA\",\n",
      "        \"matches_dataset/provenance\": \"They use different datasets in the paper.\\n\\nDataset 1: obtained composing data from different databases. miRnot reported-disease association data were retrived from the database HMDD v2.0. They added miRnot reported information using data from the miRBase database and added disease information using MeSH descriptors. The final dataset was used to compose a matrix where miRnot reported associated to a disease was labeled 1 and 0 otherwise. N, N_pos, and N_neg not reported, but could be inferred from the text. \\n\\nDataset 2: miRnot reported-disease association data from HMDD v1.0\\n\\nDataset3: miRnot reported expression data associated with Tyroid cancer, retrived from The Cancer Genome Atlas (Project TCGA-THCA).\\n\\nDataset 1 not used in previous papers. Datasets 2 and 3 used in the community.\",\n",
      "        \"matches_dataset/splits\": \"not reported, but could be inferred from the text.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b7e\",\n",
      "        \"publication_pmid\": \"25878156\",\n",
      "        \"publication_updated\": \"01/24/2022 17:28:42\",\n",
      "        \"publication_authors\": \"Connolly AT, Jensen AL, Baker KB, Vitek JL, Johnson MD\",\n",
      "        \"publication_journal\": \"J Neurophysiol\",\n",
      "        \"publication_title\": \"Classification of pallidal oscillations with increasing parkinsonian severity.\",\n",
      "        \"publication_doi\": \"10.1152/jn.00840.2014\",\n",
      "        \"publication_year\": \"2015\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"c3dde50f-83db-4289-96ec-dbfdca27594b\",\n",
      "        \"shortid\": \"duas5qkjag\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches_publication/updated\": \"01/24/2022 17:28:42\",\n",
      "        \"matches_publication/authors\": \"Connolly AT, Jensen AL, Baker KB, Vitek JL, Johnson MD\",\n",
      "        \"matches_publication/journal\": \"J Neurophysiol\",\n",
      "        \"matches_publication/title\": \"Classification of pallidal oscillations with increasing parkinsonian severity.\",\n",
      "        \"matches_optimization/config\": \"All analysis scripts are available on GitHub: https://github.com/umutcaglar/ecoli_multiple_growth_conditions (permanent archived version available via zenodo: 10.5281/zenodo.1294110)\",\n",
      "        \"matches_optimization/encoding\": \"level of transcripts/proteins expression\",\n",
      "        \"matches_optimization/features\": \"Number of transcripts/proteins in E.coli unspecified. Feature selection performed on training data with PCA: 10 features retained\",\n",
      "        \"matches_optimization/fitting\": \"f = 10, N_train \\u2248 90 - Low dimensional SVM\",\n",
      "        \"matches_optimization/parameters\": \"Kernel selected with a grid search and performance evaluation on the validation set\",\n",
      "        \"matches_model/availability\": \"Allanalysis scripts are available on GitHub: https://github.com/umutcaglar/ecoli_multiple_growth_conditions (permanent archived version available via zenodo: 10.5281/zenodo.1294110)\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/comparison\": \"Different kernels are used. Random forests are used.\",\n",
      "        \"matches_evaluation/confidence\": \"Distributions over the samples are reported, but no statistical evaluation is computed.\",\n",
      "        \"matches_evaluation/measure\": \"F1 score\",\n",
      "        \"matches_evaluation/method\": \"Independent test set + externa test set\",\n",
      "        \"matches_dataset/availability\": \"All processed data are available on GitHub: https://github.com/umutcaglar/ecoli_multiple_growth_conditions (permanent archived version available via zenodo: 10.5281/zenodo.1294110)\",\n",
      "        \"matches_dataset/provenance\": \"Previous publication: 155 E. coli samples (102 have both mRnot reported and protein abundance data; 50 have only mRnot reported abundance data; 3 have only protein abundance data). \\nExternal validation performed on 5 samples from a different publication.\",\n",
      "        \"matches_dataset/redundancy\": \"No measure of independence provided\",\n",
      "        \"matches_dataset/splits\": \"Diffent conditions are considered: carbon sources (glucose, glycerol, gluconate, and lactate),  sodium concentrations (base and high), and magnesium concentrations (low, base, and high). Different splits are therefore adopted.\\nSplitting: training/validation set:test set=80:20. Training:validation=75:25 (x 10 independent runs).\\nSemi-random split preserving the ratios of different conditions between the training/validation and the test subsets. \"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b96\",\n",
      "        \"publication_pmid\": \"25849257\",\n",
      "        \"publication_updated\": \"03/21/2022 11:49:08\",\n",
      "        \"publication_authors\": \"Gigu\\u00e8re S, Laviolette F, Marchand M, Tremblay D, Moineau S, Liang X, Biron \\u00c9, Corbeil J\",\n",
      "        \"publication_journal\": \"PLoS Comput Biol\",\n",
      "        \"publication_title\": \"Machine learning assisted design of highly active peptides for drug discovery.\",\n",
      "        \"publication_doi\": \"10.1371/journal.pcbi.1004074\",\n",
      "        \"publication_year\": \"2015\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"1212cc08-554d-44ca-a4b8-1544c008b3ce\",\n",
      "        \"shortid\": \"nlsxj0478u\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"03/21/2022 11:49:08\",\n",
      "        \"matches_publication/authors\": \"Gigu\\u00e8re S, Laviolette F, Marchand M, Tremblay D, Moineau S, Liang X, Biron \\u00c9, Corbeil J\",\n",
      "        \"matches_publication/journal\": \"PLoS Comput Biol\",\n",
      "        \"matches_publication/title\": \"Machine learning assisted design of highly active peptides for drug discovery.\",\n",
      "        \"matches_optimization/algorithm\": \"Random Forest\",\n",
      "        \"matches_optimization/encoding\": \"random sample of (number of descriptors) ^(1/2) until the tree can no longer grow\",\n",
      "        \"matches_optimization/features\": \"existing protein-ligand scoring function RF-Score and\\na new accessibility-like algorithm called CavSeek to compute structurally-based binding descriptors and descriptors pertaining to the composition and flexibility of the clefts.\",\n",
      "        \"matches_model/interpretability\": \"transparent since there is a methodological feature selection.\",\n",
      "        \"matches_evaluation/confidence\": \"Statistical confidence. The times assigned to each class are given so as to express the approximate level of confidence with which a class has been assigned from 100 repeats.\",\n",
      "        \"matches_evaluation/measure\": \"Gini importance measure, RF-score and CavSeek\",\n",
      "        \"matches_evaluation/method\": \"out-of-bag set and independent test set\",\n",
      "        \"matches_dataset/provenance\": \"data were primarily collected from the online Allosteric Database (ASD)\",\n",
      "        \"matches_dataset/redundancy\": \"selection of negative and positive for balanced datasets\",\n",
      "        \"matches_dataset/splits\": \"allosteric sites (59), regular sites (99), orthosteric sited (159)\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b97\",\n",
      "        \"publication_pmid\": \"26495028\",\n",
      "        \"publication_updated\": \"03/29/2022 21:41:26\",\n",
      "        \"publication_authors\": \"Rodr\\u00edguez-Escobedo JG, Garc\\u00eda-Sep\\u00falveda CA, Cuevas-Tello JC\",\n",
      "        \"publication_journal\": \"Comput Math Methods Med\",\n",
      "        \"publication_title\": \"KIR Genes and Patterns Given by the A Priori Algorithm: Immunity for Haematological Malignancies.\",\n",
      "        \"publication_doi\": \"10.1155/2015/141363\",\n",
      "        \"publication_year\": \"2015\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"cfb3eddf-4a2d-4640-9d9e-8650193f3286\",\n",
      "        \"shortid\": \"r7jsdtsoxh\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches_publication/updated\": \"03/29/2022 21:41:26\",\n",
      "        \"matches_publication/authors\": \"Rodr\\u00edguez-Escobedo JG, Garc\\u00eda-Sep\\u00falveda CA, Cuevas-Tello JC\",\n",
      "        \"matches_publication/journal\": \"Comput Math Methods Med\",\n",
      "        \"matches_publication/title\": \"KIR Genes and Patterns Given by the A Priori Algorithm: Immunity for Haematological Malignancies.\",\n",
      "        \"matches_optimization/algorithm\": \"Deep Transfer Learning (type of Deep Neural Network)\",\n",
      "        \"matches_optimization/regularization\": \"leave-one-compound-out cross-validation (LOOCV)\",\n",
      "        \"matches_model/duration\": \"500 min\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/measure\": \"Accuracy, confusion matrices\",\n",
      "        \"matches_dataset/availability\": \"https://bbbc.broadinstitute.org/ accession BBBC021\",\n",
      "        \"matches_dataset/splits\": \"148649 cells. 1/2 source and 1/2 target\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b9c\",\n",
      "        \"publication_pmid\": \"25175491\",\n",
      "        \"publication_updated\": \"05/20/2022 17:45:46\",\n",
      "        \"publication_authors\": \"Zheng B, Liu J, Gu J, Lu Y, Zhang W, Li M, Lu H\",\n",
      "        \"publication_journal\": \"Int J Cancer\",\n",
      "        \"publication_title\": \"A three-gene panel that distinguishes benign from malignant thyroid nodules.\",\n",
      "        \"publication_doi\": \"10.1002/ijc.29172\",\n",
      "        \"publication_year\": \"2015\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"b96ff1c7-58ce-47a8-8d72-140992f72b1c\",\n",
      "        \"shortid\": \"0mlbkqclbr\",\n",
      "        \"score\": 0.43,\n",
      "        \"matches_publication/updated\": \"05/20/2022 17:45:46\",\n",
      "        \"matches_publication/authors\": \"Zheng B, Liu J, Gu J, Lu Y, Zhang W, Li M, Lu H\",\n",
      "        \"matches_publication/journal\": \"Int J Cancer\",\n",
      "        \"matches_publication/title\": \"A three-gene panel that distinguishes benign from malignant thyroid nodules.\",\n",
      "        \"matches_optimization/algorithm\": \"Many algorithms compared: Decision Trees, Support Vector Machine, Neural Network (multilayer perceptron), Naive Bayes, Decision Rule\",\n",
      "        \"matches_optimization/encoding\": \"Not clearly stated. They just mention the elimination of non valid attributes (e.g. missing or NaN value for some features) and the selection of attributes through Chi Square Evaluation.\",\n",
      "        \"matches_optimization/features\": \"Not clearly stated (they say \\\"around 100\\\")\",\n",
      "        \"matches_model/interpretability\": \"Both transparent (e.g. Decision Trees) and black box algorithms (e.g. Neural Networks) were used.\",\n",
      "        \"matches_evaluation/comparison\": \"Comparison was made among the methods used, based on the ROC Area\",\n",
      "        \"matches_evaluation/measure\": \"ROC Area\",\n",
      "        \"matches_evaluation/method\": \"Experimental Validation\",\n",
      "        \"matches_dataset/provenance\": \"Dataset generated by the authors. Total number of instances not clearly stated (they state \\\"around 250\\\"), but could be inferred from Supplementary Informations. N_pos or N_neg not reported Dataset not used in previous papers.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b9e\",\n",
      "        \"publication_pmid\": \"26068103\",\n",
      "        \"publication_updated\": \"03/06/2022 17:08:06\",\n",
      "        \"publication_authors\": \"Blondel M, Onogi A, Iwata H, Ueda N\",\n",
      "        \"publication_journal\": \"PLoS One\",\n",
      "        \"publication_title\": \"A Ranking Approach to Genomic Selection.\",\n",
      "        \"publication_doi\": \"10.1371/journal.pone.0128570\",\n",
      "        \"publication_year\": \"2015\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"e92f4f40-8f6b-4688-9bf5-24409e3eb9bb\",\n",
      "        \"shortid\": \"4ecj3a4lnj\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"03/06/2022 17:08:06\",\n",
      "        \"matches_publication/authors\": \"Blondel M, Onogi A, Iwata H, Ueda N\",\n",
      "        \"matches_publication/journal\": \"PLoS One\",\n",
      "        \"matches_publication/title\": \"A Ranking Approach to Genomic Selection.\",\n",
      "        \"matches_optimization/algorithm\": \"J48 Algorithm, A Priori Algorithm\",\n",
      "        \"matches_model/duration\": \"no, the authors only described the machine, \\\"Weka software using a personal computer with a processor IntelCore i7with 2.3Ghz speed and 3 Gb memory.\\\"\",\n",
      "        \"matches_model/interpretability\": \"transparent, the authors provided biological explanation some of scenarios\",\n",
      "        \"matches_evaluation/measure\": \"\\ud835\\udc5d value, \\ud835\\udf122\",\n",
      "        \"matches_evaluation/method\": \"statisctical evaluation\",\n",
      "        \"matches_dataset/provenance\": \"300 healthy individuals (Mexican Reference Genomic Dnot reported Collection (MGDC-REF),)\\n43 patients with haematological malignancies (Haematology Department of Hospital Central \\u201cDr. Ignacio Morones Prieto\\u201d)\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b9f\",\n",
      "        \"publication_pmid\": \"26495028\",\n",
      "        \"publication_updated\": \"03/08/2022 10:53:29\",\n",
      "        \"publication_authors\": \"Rodr\\u00edguez-Escobedo JG, Garc\\u00eda-Sep\\u00falveda CA, Cuevas-Tello JC\",\n",
      "        \"publication_journal\": \"Comput Math Methods Med\",\n",
      "        \"publication_title\": \"KIR Genes and Patterns Given by the A Priori Algorithm: Immunity for Haematological Malignancies.\",\n",
      "        \"publication_doi\": \"10.1155/2015/141363\",\n",
      "        \"publication_year\": \"2015\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"432f82cf-b140-411c-917b-b6c655b11e1f\",\n",
      "        \"shortid\": \"r3o9d6vk1p\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"03/08/2022 10:53:29\",\n",
      "        \"matches_publication/authors\": \"Rodr\\u00edguez-Escobedo JG, Garc\\u00eda-Sep\\u00falveda CA, Cuevas-Tello JC\",\n",
      "        \"matches_publication/journal\": \"Comput Math Methods Med\",\n",
      "        \"matches_publication/title\": \"KIR Genes and Patterns Given by the A Priori Algorithm: Immunity for Haematological Malignancies.\",\n",
      "        \"matches_optimization/algorithm\": \"Novel, graph theory based approach to learn Generic String kernel (G\",\n",
      "        \"matches_optimization/encoding\": \"Sequence to binding affinities and IC50\",\n",
      "        \"matches_optimization/features\": \"Sequence (GS kernel), Synthetic data used.\",\n",
      "        \"matches_optimization/fitting\": \"not a binary classification problem, hence positive negative training data not used.\",\n",
      "        \"matches_optimization/parameters\": \"position-specific weight matrix (PSWM)\",\n",
      "        \"matches_model/availability\": \"link given https://graal.ift.ulaval.ca/peptide-design/, but page not found\",\n",
      "        \"matches_model/interpretability\": \"Transparent, graph model\",\n",
      "        \"matches_model/output\": \"Predict a string of amino acids with antimicrobial properties.\",\n",
      "        \"matches_evaluation/availability\": \"No, URL isn't working.\",\n",
      "        \"matches_evaluation/comparison\": \"Pearson correlation of prediction with values in databases)\",\n",
      "        \"matches_evaluation/confidence\": \"Correlation coefficient of 0.90 and 0.93 were reported for two different datasets used.\",\n",
      "        \"matches_evaluation/measure\": \"Pearson correlation coefficient ( correlation of prediction with values in databases)\",\n",
      "        \"matches_evaluation/method\": \"kernel ridge regression with training used for validation. Also performed lab experiments.\",\n",
      "        \"matches_dataset/provenance\": \"Data taken from Wade 2002 (101 data points), Ufkes 1982 (31 data points),  its quantitative continuous data - peptide sequence and anti-microbial activity (binding affinity, IC50), hence no positive negative, \",\n",
      "        \"matches_dataset/redundancy\": \"Synthetic data used\",\n",
      "        \"matches_dataset/splits\": \"Data is peptide sequence and anti-microbial activity (binding affinity, IC50),  hence no pos and negative control,  first built a model to generate synthetic data and used 1000 of such data for training.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305ba0\",\n",
      "        \"publication_pmid\": \"26422234\",\n",
      "        \"publication_updated\": \"03/09/2022 10:11:09\",\n",
      "        \"publication_authors\": \"S\\u00f8ndergaard D, Pedersen CN\",\n",
      "        \"publication_journal\": \"PLoS One\",\n",
      "        \"publication_title\": \"PATBox: A Toolbox for Classification and Analysis of P-Type ATPases.\",\n",
      "        \"publication_doi\": \"10.1371/journal.pone.0139571\",\n",
      "        \"publication_year\": \"2015\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"d6ffe3b1-8da7-40dd-ae1e-a31ebb7c757c\",\n",
      "        \"shortid\": \"5i5yt6gjy3\",\n",
      "        \"score\": 0.33,\n",
      "        \"matches_publication/updated\": \"03/09/2022 10:11:09\",\n",
      "        \"matches_publication/authors\": \"S\\u00f8ndergaard D, Pedersen CN\",\n",
      "        \"matches_publication/journal\": \"PLoS One\",\n",
      "        \"matches_publication/title\": \"PATBox: A Toolbox for Classification and Analysis of P-Type ATPases.\",\n",
      "        \"matches_optimization/algorithm\": \"Novel approach\",\n",
      "        \"matches_model/availability\": \"Supplementary data of the article\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/comparison\": \"stochastic simulations\",\n",
      "        \"matches_dataset/availability\": \"Yes, the Drosophila Bicoid data used in this study is available from the FlyEx database, http://urchin.spbcas.ru/flyex/\\n\",\n",
      "        \"matches_dataset/provenance\": \"syntetic data and one public dataset\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305ba8\",\n",
      "        \"publication_pmid\": \"26495028\",\n",
      "        \"publication_updated\": \"02/08/2022 15:10:18\",\n",
      "        \"publication_authors\": \"Rodr\\u00edguez-Escobedo JG, Garc\\u00eda-Sep\\u00falveda CA, Cuevas-Tello JC\",\n",
      "        \"publication_journal\": \"Comput Math Methods Med\",\n",
      "        \"publication_title\": \"KIR Genes and Patterns Given by the A Priori Algorithm: Immunity for Haematological Malignancies.\",\n",
      "        \"publication_doi\": \"10.1155/2015/141363\",\n",
      "        \"publication_year\": \"2015\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"0f4944df-a1cc-4bf4-a6da-bb1ce13b71df\",\n",
      "        \"shortid\": \"74z8knxsmc\",\n",
      "        \"score\": 0.38,\n",
      "        \"matches_publication/updated\": \"02/08/2022 15:10:18\",\n",
      "        \"matches_publication/authors\": \"Rodr\\u00edguez-Escobedo JG, Garc\\u00eda-Sep\\u00falveda CA, Cuevas-Tello JC\",\n",
      "        \"matches_publication/journal\": \"Comput Math Methods Med\",\n",
      "        \"matches_publication/title\": \"KIR Genes and Patterns Given by the A Priori Algorithm: Immunity for Haematological Malignancies.\",\n",
      "        \"matches_optimization/algorithm\": \"TargetScan - non-ML algorithm\",\n",
      "        \"matches_optimization/parameters\": \"params provided in additional info\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"probability score\",\n",
      "        \"matches_dataset/availability\": \"Yes, website URL\",\n",
      "        \"matches_dataset/provenance\": \"Dataset links provided in Table 1\",\n",
      "        \"matches_dataset/splits\": \"Some details provided in Additional information\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305ba9\",\n",
      "        \"publication_pmid\": \"25783485\",\n",
      "        \"publication_updated\": \"02/28/2022 13:11:53\",\n",
      "        \"publication_authors\": \"Engchuan W, Dhindsa K, Lionel AC, Scherer SW, Chan JH, Merico D\",\n",
      "        \"publication_journal\": \"BMC Med Genomics\",\n",
      "        \"publication_title\": \"Performance of case-control rare copy number variation annotation in classification of autism.\",\n",
      "        \"publication_doi\": \"10.1186/1755-8794-8-S1-S7\",\n",
      "        \"publication_year\": \"2015\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"35b090fd-315b-4d28-93d7-b2c94ae39deb\",\n",
      "        \"shortid\": \"0jrk3ke80f\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches_publication/updated\": \"02/28/2022 13:11:53\",\n",
      "        \"matches_publication/authors\": \"Engchuan W, Dhindsa K, Lionel AC, Scherer SW, Chan JH, Merico D\",\n",
      "        \"matches_publication/journal\": \"BMC Med Genomics\",\n",
      "        \"matches_publication/title\": \"Performance of case-control rare copy number variation annotation in classification of autism.\",\n",
      "        \"matches_optimization/algorithm\": \"SOMs and kNNs\",\n",
      "        \"matches_optimization/parameters\": \"k = 5 neighbors;  Euclidean distance d(x1,x2), of 2, and a distance weight w(i),p of 2\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/comparison\": \"We decided to apply SOM and kNN for the Corg models, as previous methods such as the derivation of Corg stocks from classified vegetation types or the derivation via quantiles in a classification and regression tree (CART) approach had only \\n limited success.\",\n",
      "        \"matches_evaluation/confidence\": \"ML training metrics\",\n",
      "        \"matches_evaluation/measure\": \"bias and the root mean square error (RMSE)\",\n",
      "        \"matches_dataset/provenance\": \"RapidEye data were used as the high spatial resolution reflects the spatial heterogeneity of carbon  https://doi.org/10.1016/j.actaastro.2009.06.008\",\n",
      "        \"matches_dataset/splits\": \"104 in situ inventory plots\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305baa\",\n",
      "        \"publication_pmid\": \"25646976\",\n",
      "        \"publication_updated\": \"03/03/2022 14:47:08\",\n",
      "        \"publication_authors\": \"Jorda J, Liu Y, Bobik TA, Yeates TO\",\n",
      "        \"publication_journal\": \"PLoS Comput Biol\",\n",
      "        \"publication_title\": \"Exploring bacterial organelle interactomes: a model of the protein-protein interaction network in the Pdu microcompartment.\",\n",
      "        \"publication_doi\": \"10.1371/journal.pcbi.1004067\",\n",
      "        \"publication_year\": \"2015\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"6fbdbce3-56b4-4ceb-853f-9b5c4604cd2c\",\n",
      "        \"shortid\": \"7hxvmu9cij\",\n",
      "        \"score\": 0.95,\n",
      "        \"matches_publication/updated\": \"03/03/2022 14:47:08\",\n",
      "        \"matches_publication/authors\": \"Jorda J, Liu Y, Bobik TA, Yeates TO\",\n",
      "        \"matches_publication/journal\": \"PLoS Comput Biol\",\n",
      "        \"matches_publication/title\": \"Exploring bacterial organelle interactomes: a model of the protein-protein interaction network in the Pdu microcompartment.\",\n",
      "        \"matches_optimization/algorithm\": \"Heterogeneous ensemble classifier baed on adaboost (but for unbalanced data), with 20 different based classifiers  including rule-based, SVM, tree-based and KNN-based classifiers.\",\n",
      "        \"matches_optimization/config\": \"Not available, but there is a platform for the tool\",\n",
      "        \"matches_optimization/encoding\": \"188 feature vector for each protein sequence with information on composition, distribution and physiochemical properties\",\n",
      "        \"matches_optimization/features\": \"188 features per sequence. No feature selection appears to be performed.\",\n",
      "        \"matches_optimization/fitting\": \"Nothing reported except for the claim that their method of selecting negative cases in function of their difficulty leads to less over-fitting.  No feature selection was performed, no cross-validation\",\n",
      "        \"matches_optimization/meta\": \"There is not sufficient information.  They calculate a 188 feature vector with properties about the sequence composition, distribution and physiochemical properties, but they not provide details on whether these are predictions or actual calculations.\",\n",
      "        \"matches_optimization/parameters\": \"Details on the parameters of each independent learner  in the ensemble are not reported. Their ensemble method uses a weight for each negative sample in the training set to tune the sampling of the negative instances\",\n",
      "        \"matches_optimization/regularization\": \"not really\",\n",
      "        \"matches_model/availability\": \"platform : http://bliulab.net/Ensemble-DNA-Prot/index.jsp\",\n",
      "        \"matches_model/interpretability\": \"no interpretation provided, only performance assessment. Remains black box as it is based on 20 different learners.\",\n",
      "        \"matches_model/output\": \"binary (I assume based on the pseudocode provided)\",\n",
      "        \"matches_evaluation/comparison\": \"Compared to other methods : DNAbinder, DNA-prot, iDNA-prot They were all reimplemented in house on the same data sets.\",\n",
      "        \"matches_evaluation/confidence\": \"value comparison, no statistical tests\",\n",
      "        \"matches_evaluation/measure\": \"ACC, MCC, SE, SP and F1\",\n",
      "        \"matches_evaluation/method\": \"independent data sets only\",\n",
      "        \"matches_dataset/availability\": \"all data is made available via Supplementary information\",\n",
      "        \"matches_dataset/provenance\": \"four datasets are used, two for training and two for testing. The first set consist of 146 positive and 250 negative cases.  They were obtained from two earlier publications on the same topic.  The second set is an expansion of the first, adding more negative instances. Te negative set is increases to 2125 instances. The third set is obtained from another publication, consisting of 92 positive and 100 negative instances.  The last set contains 823 positive and 823 negative instances, also extracted from another publication. \",\n",
      "        \"matches_dataset/redundancy\": \"With the data sets, sequences with a pairwise identity larger or equal to 25% were removed.  All sequences in the test sets that had a pairwise sequence identity larger or equal to 40% were removed from the test sets (using CD-HIT).  \",\n",
      "        \"matches_dataset/splits\": \"Data set 1 and.2 are used for training, dataset 3 and 4 for testing. \"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bae\",\n",
      "        \"publication_pmid\": \"25878156\",\n",
      "        \"publication_updated\": \"01/21/2022 17:00:14\",\n",
      "        \"publication_authors\": \"Connolly AT, Jensen AL, Baker KB, Vitek JL, Johnson MD\",\n",
      "        \"publication_journal\": \"J Neurophysiol\",\n",
      "        \"publication_title\": \"Classification of pallidal oscillations with increasing parkinsonian severity.\",\n",
      "        \"publication_doi\": \"10.1152/jn.00840.2014\",\n",
      "        \"publication_year\": \"2015\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"868e7e5a-159e-47dc-9571-2700b8d3541b\",\n",
      "        \"shortid\": \"f4zymru581\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches_publication/updated\": \"01/21/2022 17:00:14\",\n",
      "        \"matches_publication/authors\": \"Connolly AT, Jensen AL, Baker KB, Vitek JL, Johnson MD\",\n",
      "        \"matches_publication/journal\": \"J Neurophysiol\",\n",
      "        \"matches_publication/title\": \"Classification of pallidal oscillations with increasing parkinsonian severity.\",\n",
      "        \"matches_optimization/algorithm\": \"decision trees, naive Bayes,  k-nearest neighbor, K*, random decision forest and support vector machines with Gaussian radial basis function and linear kernel\",\n",
      "        \"matches_optimization/features\": \"948 features from 15 categories but each training included a subset of them\",\n",
      "        \"matches_model/availability\": \"http://www.cogsys.\\n cs.uni-tuebingen.de/software/dna-methylation/.\",\n",
      "        \"matches_model/interpretability\": \"the algorithms were used in order to show the predictive performance of each feature and thus outline the correlation between features and classification\",\n",
      "        \"matches_model/output\": \"binary classification\",\n",
      "        \"matches_evaluation/comparison\": \"direct comparison is challenging since there are a lot of factors contributing in the final results. Some comparison is indeed presented from other publications.\",\n",
      "        \"matches_evaluation/confidence\": \"To ensure a fair comparison, all analyses have been repeated ten times with a ten-fold cross-validation so the mean and standard deviation for each experiment are presented.\",\n",
      "        \"matches_evaluation/measure\": \"accuracy, Matthews correlation coefficient (MCC) and the area under the receiver operating\\n characteristics curve (AUC), average absolute error (AAE)\",\n",
      "        \"matches_evaluation/method\": \"Cross-validation and independent dataset\",\n",
      "        \"matches_dataset/availability\": \" http://www.cogsys.cs.uni-tuebingen.de/software/dna-methylation/.\",\n",
      "        \"matches_dataset/provenance\": \"not reportedME21 consortium, ENCODE consortium,  whole-genome catalogue of Dnot reported methylation in human, DOI: 10.1371/journal.pgen.1000438\",\n",
      "        \"matches_dataset/splits\": \"56 methylated (112 unmethylated) instances for leukocytes, 73\\nmethylated (117 unmethylated) instances for HEK293, 44 methylated (142 unmethylated) instances for HEPG2, 43 methylated (142 unmethylated) instances for fibroblasts, and 32\\nmethylated (137 unmethylated) instances for trisomic fibroblasts\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b5e\",\n",
      "        \"publication_pmid\": \"27127534\",\n",
      "        \"publication_updated\": \"03/30/2022 16:22:15\",\n",
      "        \"publication_authors\": \"Wang MY, Li P, Qiao PL\",\n",
      "        \"publication_journal\": \"Comput Math Methods Med\",\n",
      "        \"publication_title\": \"The Virtual Screening of the Drug Protein with a Few Crystal Structures Based on the Adaboost-SVM.\",\n",
      "        \"publication_doi\": \"10.1155/2016/4809831\",\n",
      "        \"publication_year\": \"2016\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"10e71e8f-f4e5-4904-9a7b-9428370d1e99\",\n",
      "        \"shortid\": \"2t5i3s7g3y\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches_publication/updated\": \"03/30/2022 16:22:15\",\n",
      "        \"matches_publication/authors\": \"Wang MY, Li P, Qiao PL\",\n",
      "        \"matches_publication/journal\": \"Comput Math Methods Med\",\n",
      "        \"matches_publication/title\": \"The Virtual Screening of the Drug Protein with a Few Crystal Structures Based on the Adaboost-SVM.\",\n",
      "        \"matches_optimization/algorithm\": \"Multiple Linear Regression (MLR) \",\n",
      "        \"matches_optimization/config\": \"Coefficients Estimates and Standard Errors of the predictors are reported.\",\n",
      "        \"matches_optimization/encoding\": \"Global features\",\n",
      "        \"matches_optimization/features\": \"The 110 numeric fields included in the platform were considered as the possible predictors with a backward elimination method. From the screening of every model, the authors selected the most significant ones (5 predictors) according to the F statistics of the ChiSquare coefficients.  From the text it appears that the feature elimination procedure was applied on the whole dataset.  \",\n",
      "        \"matches_optimization/fitting\": \"Apparently both over-fitting and under-fitting can be excluded (p<N, f =5).  \",\n",
      "        \"matches_optimization/parameters\": \"7 MLR parameters:  5 feature parameters, 1 intercept, 1 error term.\",\n",
      "        \"matches_model/interpretability\": \"Transparent. All 5 features are clinical parameters known to be related to the AKU illness.\",\n",
      "        \"matches_model/output\": \"Regression: prediction of patients PTI (Protein Thiolation Index) values, given the patients clinical information.\",\n",
      "        \"matches_evaluation/confidence\": \"Significance of the model by F statistics.\",\n",
      "        \"matches_evaluation/measure\": \"Adjusted coefficient of determination, Mean Standard Error, Maximum Absolute Difference Predicted vs Experimental\",\n",
      "        \"matches_evaluation/method\": \"Independent validation set.\",\n",
      "        \"matches_dataset/availability\": \"The database, hosting the dataset, is accessible via registration request:    http://www.bio.unisi.it/aku-db/\",\n",
      "        \"matches_dataset/provenance\": \"Source:  AKU-related dataset, 203 patients in total.  Not used previously.\",\n",
      "        \"matches_dataset/splits\": \"Training set: 181 patients, Validation set: 22 patients\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b5f\",\n",
      "        \"publication_pmid\": \"26930205\",\n",
      "        \"publication_updated\": \"06/23/2022 04:51:07\",\n",
      "        \"publication_authors\": \"Cho H, Berger B, Peng J\",\n",
      "        \"publication_journal\": \"PLoS One\",\n",
      "        \"publication_title\": \"Reconstructing Causal Biological Networks through Active Learning.\",\n",
      "        \"publication_doi\": \"10.1371/journal.pone.0150611\",\n",
      "        \"publication_year\": \"2016\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"55301cf1-e2b8-4e59-86d5-6502872104d6\",\n",
      "        \"shortid\": \"ftglxzast4\",\n",
      "        \"score\": 0.57,\n",
      "        \"matches_publication/updated\": \"06/23/2022 04:51:07\",\n",
      "        \"matches_publication/authors\": \"Cho H, Berger B, Peng J\",\n",
      "        \"matches_publication/journal\": \"PLoS One\",\n",
      "        \"matches_publication/title\": \"Reconstructing Causal Biological Networks through Active Learning.\",\n",
      "        \"matches_optimization/encoding\": \"Yes, e.g. voxel resolution\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"Binary classification\",\n",
      "        \"matches_evaluation/measure\": \"ROC curve\",\n",
      "        \"matches_evaluation/method\": \"Cross validation\",\n",
      "        \"matches_dataset/provenance\": \" distinguish 32 patients from 30 healthy control\",\n",
      "        \"matches_dataset/splits\": \" distinguish 32 patients from 30 healthy control\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b60\",\n",
      "        \"publication_pmid\": \"26205532\",\n",
      "        \"publication_updated\": \"06/23/2022 05:29:46\",\n",
      "        \"publication_authors\": \"Kosciolek T, Jones DT\",\n",
      "        \"publication_journal\": \"Proteins\",\n",
      "        \"publication_title\": \"Accurate contact predictions using covariation techniques and machine learning.\",\n",
      "        \"publication_doi\": \"10.1002/prot.24863\",\n",
      "        \"publication_year\": \"2016\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"92789330-e8c7-4761-a47b-6758bb151af7\",\n",
      "        \"shortid\": \"m8bml54z62\",\n",
      "        \"score\": 0.9,\n",
      "        \"matches_publication/updated\": \"06/23/2022 05:29:46\",\n",
      "        \"matches_publication/authors\": \"Kosciolek T, Jones DT\",\n",
      "        \"matches_publication/title\": \"Accurate contact predictions using covariation techniques and machine learning.\",\n",
      "        \"matches_optimization/algorithm\": \"AdaBoost, Gradient boosting, Gaussian process, K-nearest neighbors, logistic regression, naive Bayes, Random forest, SVM (RBF)\",\n",
      "        \"matches_optimization/config\": \"Yes, supporting information\",\n",
      "        \"matches_optimization/encoding\": \"Mean imputation for missing values, normalization of continuous valued features to zero mean and unit variance.\",\n",
      "        \"matches_optimization/features\": \"36 clinical attributes per patient per time-point\",\n",
      "        \"matches_optimization/fitting\": \"Second feature selection process as part of the hyper-parameter tuning process, referred to as \\u201cautomated feature selection\\u201d in Fig 1. The automated method is based on the mutual information between each individual feature and sepsis class (case or control) to select top n features, 11 features selected for CPOnly DS, 35 (all) for CP+Clinical dataset.\",\n",
      "        \"matches_optimization/parameters\": \"Ada boost: 3, Gradient Boosting: 2, kNN: 2, Logistic Regression: 1, Random Forest: 3, SVM: 2\",\n",
      "        \"matches_optimization/regularization\": \"Nested k-fold cross-validation\",\n",
      "        \"matches_model/availability\": \"https://github.com/chop-dbhi/sepsis_01, Data is in S3, unclear if project can be fully bootstrapped.\",\n",
      "        \"matches_model/interpretability\": \"Transparent, names of models and parameters are provided\",\n",
      "        \"matches_model/output\": \"probability score, classification into positive case if p > 0.5\",\n",
      "        \"matches_evaluation/availability\": \"Yes, Supporting information, https://github.com/chop-dbhi/sepsis_01, MIT license (code)\",\n",
      "        \"matches_evaluation/comparison\": \"Ada boost, Gradient Boosting, kNN, Logistic Regression, Random Forest, SVM\",\n",
      "        \"matches_evaluation/confidence\": \"NA (The null hypothesis of equal inter-model distributions was rejected by the Friedman rank sum test with p-values of <0.001 for both the CPOnly and CP+Clinical datasets.)\",\n",
      "        \"matches_evaluation/measure\": \"AUC, Specificity, PPV, NPV\",\n",
      "        \"matches_evaluation/method\": \"k-fold cross validation, negative control dataset\",\n",
      "        \"matches_dataset/availability\": \"Yes, Supporting information.\",\n",
      "        \"matches_dataset/provenance\": \"Neonatal Intensive Care Unit (NICU) at the Children\\u2019s Hospital of Philadelphia, hospizalized infants with sepsis evaluation (culture positive, clinically positive)\",\n",
      "        \"matches_dataset/redundancy\": \"not reported (there were pre-selection criteria for inclusion)\",\n",
      "        \"matches_dataset/splits\": \"618 infants with 1188 sepsis evaluations, 110 culture positive, 265 clinically positive, 492 negative\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b7a\",\n",
      "        \"publication_pmid\": \"27191382\",\n",
      "        \"publication_updated\": \"03/07/2022 10:49:51\",\n",
      "        \"publication_authors\": \"Putin E, Mamoshina P, Aliper A, Korzinkin M, Moskalev A, Kolosov A, Ostrovskiy A, Cantor C, Vijg J, Zhavoronkov A\",\n",
      "        \"publication_journal\": \"Aging (Albany NY)\",\n",
      "        \"publication_title\": \"Deep biomarkers of human aging: Application of deep neural networks to biomarker development.\",\n",
      "        \"publication_doi\": \"10.18632/aging.100968\",\n",
      "        \"publication_year\": \"2016\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"fd5713cd-748e-4a55-889a-9ed418021731\",\n",
      "        \"shortid\": \"0qudu672ba\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches_publication/updated\": \"03/07/2022 10:49:51\",\n",
      "        \"matches_publication/authors\": \"Putin E, Mamoshina P, Aliper A, Korzinkin M, Moskalev A, Kolosov A, Ostrovskiy A, Cantor C, Vijg J, Zhavoronkov A\",\n",
      "        \"matches_publication/journal\": \"Aging (Albany NY)\",\n",
      "        \"matches_publication/title\": \"Deep biomarkers of human aging: Application of deep neural networks to biomarker development.\",\n",
      "        \"matches_optimization/algorithm\": \"neural network\",\n",
      "        \"matches_optimization/encoding\": \"BioFSharp framework (available at: https://github.com/CSBiology/BioFSharp) and converted into a feature vector with 45 entries.\",\n",
      "        \"matches_optimization/features\": \"The networks were trained using a minibatch size of 3 for 10 epoch.\",\n",
      "        \"matches_optimization/parameters\": \"five dense layers with 128 nodes each\",\n",
      "        \"matches_optimization/regularization\": \"Yes, \\u201cdropout\\u201d technique \",\n",
      "        \"matches_model/availability\": \"webservice: (http://csbweb.bio.uni-kl.de/)\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/comparison\": \"ChemScore (Parker, 2002) \\n PeptideSieve (Mallick et al., 2007),\\n PeptideRank (Qeli et al., 2014),\\n CONSequence (Eyers et al., 2011), \\n ESPPredictor (Fusaro et al., 2009).\",\n",
      "        \"matches_evaluation/confidence\": \"no statistical significance declared.\",\n",
      "        \"matches_evaluation/measure\": \"normalized discounted cumulative gain (nDCG) metric\",\n",
      "        \"matches_evaluation/method\": \"randomly selected 20% of the proteins in each assembly to use them as validation-data-sets, \\n 32 peptides from a QconCAT protein was experimentally validated\",\n",
      "        \"matches_dataset/availability\": \"at the suplementary files  https://www.frontiersin.org/articles/10.3389/fpls.2018.01559/full#supplementary-material\\n\\n\",\n",
      "        \"matches_dataset/provenance\": \"Yeast data set:  from the PRIDE repository \\nC. reinhardtii data set:  previous proteome-wide studies\\neach dataset filtered for single occurrence of all proteins\\n\\n\",\n",
      "        \"matches_dataset/splits\": \"training datasets consisting of 2,652 yeast and 2,732 C. reinhardtii proteins\\ntwo validation datasets consisting of 664 yeast and 685 C. reinhardtii proteins\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b7b\",\n",
      "        \"publication_pmid\": \"27592011\",\n",
      "        \"publication_updated\": \"03/13/2022 19:09:08\",\n",
      "        \"publication_authors\": \"Sunseri J, Ragoza M, Collins J, Koes DR\",\n",
      "        \"publication_journal\": \"J Comput Aided Mol Des\",\n",
      "        \"publication_title\": \"A D3R prospective evaluation of machine learning for protein-ligand scoring.\",\n",
      "        \"publication_doi\": \"10.1007/s10822-016-9960-x\",\n",
      "        \"publication_year\": \"2016\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"4a3c8c15-7e55-4033-a570-4dd9364e7be4\",\n",
      "        \"shortid\": \"2imglukj27\",\n",
      "        \"score\": 0.52,\n",
      "        \"matches_publication/updated\": \"03/13/2022 19:09:08\",\n",
      "        \"matches_publication/authors\": \"Sunseri J, Ragoza M, Collins J, Koes DR\",\n",
      "        \"matches_publication/journal\": \"J Comput Aided Mol Des\",\n",
      "        \"matches_publication/title\": \"A D3R prospective evaluation of machine learning for protein-ligand scoring.\",\n",
      "        \"matches_optimization/encoding\": \"The probes corresponding to the same gene were averaged. The gene expression data was preprocessed with quantile normalization\",\n",
      "        \"matches_model/interpretability\": \"transparent, listed in the The CIN-associated gene selection section in Methods\",\n",
      "        \"matches_evaluation/availability\": \"yes, Figure 1\",\n",
      "        \"matches_evaluation/measure\": \"Accuracy, sensitivity, specificity, mcc\",\n",
      "        \"matches_dataset/availability\": \"yes, GEO GSE39582\",\n",
      "        \"matches_dataset/provenance\": \"GEO GSE39582\",\n",
      "        \"matches_dataset/splits\": \"Within the 585 colon patients, there were 369 CIN+ and 112 CIN-, 93 CIMP+ and 420 CIMP-, 77 dMMR and 459 pMMR\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b7c\",\n",
      "        \"publication_pmid\": \"26746583\",\n",
      "        \"publication_updated\": \"03/17/2022 23:10:43\",\n",
      "        \"publication_authors\": \"Kandaswamy C, Silva LM, Alexandre LA, Santos JM\",\n",
      "        \"publication_journal\": \"J Biomol Screen\",\n",
      "        \"publication_title\": \"High-Content Analysis of Breast Cancer Using Single-Cell Deep Transfer Learning.\",\n",
      "        \"publication_doi\": \"10.1177/1087057115623451\",\n",
      "        \"publication_year\": \"2016\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"bad7ff2b-45e0-4386-ba20-6ff517bf0db5\",\n",
      "        \"shortid\": \"wd9oesbckf\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"03/17/2022 23:10:43\",\n",
      "        \"matches_publication/authors\": \"Kandaswamy C, Silva LM, Alexandre LA, Santos JM\",\n",
      "        \"matches_publication/journal\": \"J Biomol Screen\",\n",
      "        \"matches_publication/title\": \"High-Content Analysis of Breast Cancer Using Single-Cell Deep Transfer Learning.\",\n",
      "        \"matches_optimization/algorithm\": \" random forest and gradient boosting. Also ensemble method from different classifiers, Two separate values were used for the creation of each ensemble model \\u2013 scores sij and\\npredictions pij where i represents model number and j transcript.  The four ensemble\\napproaches included both algebraic combiners and voting methods as non-trainable methods, and a stacking generalizer as a meta-learner.\",\n",
      "        \"matches_optimization/encoding\": \"Diamond alignment in SwissProt database\",\n",
      "        \"matches_optimization/features\": \"9 features were extracted using a combination of custom Python scripts and known software CPAT, Diamond, RepeatMasker.\",\n",
      "        \"matches_optimization/parameters\": \" gradient boosting parameters :  learning_rate, max_depth, subsample, n_estimators. \\nRandom forest parameters: only change from default parameters being n_estimators and min_samples_leaf.\",\n",
      "        \"matches_model/duration\": \"measured in minutes\",\n",
      "        \"matches_model/output\": \"classification binary if a transcript was or was not predicted as a lncRNA and stacking with\\n logistic regression for ensemble method\",\n",
      "        \"matches_evaluation/comparison\": \"compared to GreeNC (uses a transcript filtering method, rather than a machine learning approaches).\",\n",
      "        \"matches_evaluation/confidence\": \"(qualitative explanation) An important consideration of this tool is that it is not constrained by preconceived rules that may or may not appropriately classify lncRNA properties and the stacking generalizer model based on gradient boosting models will facilitate lncRNA identification without imposing arbitrary rules for lncRNA detection.\",\n",
      "        \"matches_evaluation/measure\": \"accuracy, sensitivity, specificity and AUC values\",\n",
      "        \"matches_evaluation/method\": \"10-fold cross-validation\",\n",
      "        \"matches_dataset/availability\": \"(http://lncrnadb.org), (http://www.cuilab.cn/lncrnadisease), (http://www.ensembl.org), (https://araport-dev.tacc.utexas.edu)\",\n",
      "        \"matches_dataset/provenance\": \"positive: lncRnot reporteddb v2.0, lncRnot reporteddisease , total of 436 unique, validated lncRnot reported sequences // negative: Ensembl, Araportv11 \",\n",
      "        \"matches_dataset/redundancy\": \"variety of training datasets was used to maximize model diversity and samples were equally and randomly selected to get a balanced training\",\n",
      "        \"matches_dataset/splits\": \" 8 different combinations of negative data from multiple species\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b7d\",\n",
      "        \"publication_pmid\": \"27491922\",\n",
      "        \"publication_updated\": \"03/23/2022 12:35:43\",\n",
      "        \"publication_authors\": \"Chen AS, Westwood NJ, Brear P, Rogers GW, Mavridis L, Mitchell JB\",\n",
      "        \"publication_journal\": \"Mol Inform\",\n",
      "        \"publication_title\": \"A Random Forest Model for Predicting Allosteric and Functional Sites on Proteins.\",\n",
      "        \"publication_doi\": \"10.1002/minf.201500108\",\n",
      "        \"publication_year\": \"2016\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"c0279a1e-2bf3-4fe2-8d40-9c9cc040608d\",\n",
      "        \"shortid\": \"o94lxlja8t\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches_publication/updated\": \"03/23/2022 12:35:43\",\n",
      "        \"matches_publication/authors\": \"Chen AS, Westwood NJ, Brear P, Rogers GW, Mavridis L, Mitchell JB\",\n",
      "        \"matches_publication/journal\": \"Mol Inform\",\n",
      "        \"matches_publication/title\": \"A Random Forest Model for Predicting Allosteric and Functional Sites on Proteins.\",\n",
      "        \"matches_optimization/algorithm\": \"Random Forest \",\n",
      "        \"matches_optimization/features\": \"Number of features not reported\\n\\nThe feature selection was actually the main topic of the paper. The feature selection method is carefully described. In brief, features were selected passing through different steps: 1. initial filtering 2. Random Logistic Regression 3. Feature importance of Random Forest 4. evaluating the LogLoss of the prediction performed using different combination of the selected features.\",\n",
      "        \"matches_model/availability\": \"Yes, the code is available at URL: https://github.com/bioinformatics-IBCH/logloss-beraf\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/comparison\": \"Compared with other classification models, all based on logistic regression.\",\n",
      "        \"matches_evaluation/confidence\": \"No confidence intervals. No static significance claimed\",\n",
      "        \"matches_evaluation/measure\": \"Precision, Recall, F1-score, Area Under Curve (AUC)\",\n",
      "        \"matches_evaluation/method\": \"Independent Datasets (test sets)\",\n",
      "        \"matches_dataset/availability\": \"Yes. \\n\\n-- Datasets for prostate cancer --\\nDataset 1 URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE74013\\nDataset 2 URL: https://portal.gdc.cancer.gov/projects/TCGA-PRAD\\nDataset 3 URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE55479\\nDataset 4 URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE38240\\nDataset 5 URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE73549\\n\\n-- Datasets for bladder cancer --\\nDataset 6 URL: https://portal.gdc.cancer.gov/projects/TCGA-BLCA\\n\\n-- Datasets for colorectal cancer --\\nDataset 7 URL: https://portal.gdc.cancer.gov/projects/TCGA-COAD\\nDataset 8 URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE74013\\n\\n-- Datasets for renal clear cells cancer --\\nDataset 9 URL: https://wiki.cancerimagingarchive.net/display/Public/TCGA-KIRC\\n\\n-- Datasets for renal papillary cell carcinoma --\\nDataset 10 URL: https://www.google.com/search?channel=trow5&client=firefox-b-d&q=TCGA+KIRP\",\n",
      "        \"matches_dataset/provenance\": \"All the datasets are public. For all datasetes, pos refer to tumor sample, neg to non-tumor sample.\\n\\n-- Datasets for prostate cancer --\\nDataset 1: GEO dataset GSE74013 (N_pos = 21; N_neg = 27)\\nDataset 2: TCGA-PRAD (N_pos = 293; N_neg = 23)\\nDataset 3: GEO dataset GSE55479 (N_pos = 143; N_neg = 0)\\nDataset 4: GEO dataset GSE38240 (N_pos = 8; N_neg = 4)\\nDataset 5: GEO dataset GSE73549 (N_pos = 77; N_neg = 15)\\n\\n-- Datasets for bladder cancer --\\nDataset 6: TCGA-BLCA (N_pos = 335; N_neg = 23)\\n\\n-- Datasets for colorectal cancer --\\nDataset 7: TCGA-COAD (N_pos = 333; N_neg = 37)\\nDataset 8: GEO dataset GSE74013 (N_pos = 14; N_neg = 20)\\n\\n-- Datasets for renal clear cells cancer --\\nDataset 9: TGCA-KIRC (N_pos = 290; N_neg = 130)\\n\\n-- Datasets for renal papillary cell carcinoma --\\nDataset 10: TGCA-KIRP (N_pos = 252; N_neg = 167)\",\n",
      "        \"matches_dataset/redundancy\": \"No redundancy stated for dataset splits. All the datasets are independent from each other\",\n",
      "        \"matches_dataset/splits\": \"In all cases, the training dataset is used also for validation.\\n\\n-- Datasets for prostate cancer --\\nDataset 1: Splitted in Training (N_pos = 8; N_neg = 11) and Test set (N_pos = 13; N_neg = 16)\\nDataset 2: Splitted in Training (N_pos = 117; N_neg = 15) and Test set (N_pos = 176; N_neg = 23)\\nDataset 3: Used as test set (N_pos = 143; N_neg = 0)\\nDataset 4: Used as test set (N_pos = 8; N_neg = 4)\\nDataset 5: Used as test set (N_pos = 77; N_neg = 15)\\n\\n-- Datasets for bladder cancer --\\nDataset 6: Splitted in training (N_pos = 134; N_neg = 9) and test set (N_pos = 201; N_neg = 14)\\n\\n-- Datasets for colorectal cancer --\\nDataset 7: Splitted in training (N_pos = 133; N_neg = 15) and test set (N_pos = 200; N_neg = 22)\\nDataset 8: Splitted in training (N_pos = 6; N_neg = 9) and test set (N_pos = 8; N_neg = 11)\\n\\n-- Datasets for renal clear cells cancer --\\nDataset 9: Splitted in training (N_pos = 116; N_neg = 52) and test set (N_pos = 174; N_neg = 78)\\n\\n-- Datasets for renal papillary cell carcinoma --\\nDataset 10: Splitted in training (N_pos = 101; N_neg = 63) and test set (N_pos = 151; N_neg = 104)\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b85\",\n",
      "        \"publication_pmid\": \"27488918\",\n",
      "        \"publication_updated\": \"02/09/2022 10:22:18\",\n",
      "        \"publication_authors\": \"Liu HC, Goldenberg A, Chen Y, Lun C, Wu W, Bush KT, Balac N, Rodriguez P, Abagyan R, Nigam SK\",\n",
      "        \"publication_journal\": \"J Pharmacol Exp Ther\",\n",
      "        \"publication_title\": \"Molecular Properties of Drugs Interacting with SLC22 Transporters OAT1, OAT3, OCT1, and OCT2: A Machine-Learning Approach.\",\n",
      "        \"publication_doi\": \"10.1124/jpet.116.232660\",\n",
      "        \"publication_year\": \"2016\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"e9716212-a945-4dc9-b615-7fc1704b6dbf\",\n",
      "        \"shortid\": \"3htxdzl6gy\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches_publication/updated\": \"02/09/2022 10:22:18\",\n",
      "        \"matches_publication/authors\": \"Liu HC, Goldenberg A, Chen Y, Lun C, Wu W, Bush KT, Balac N, Rodriguez P, Abagyan R, Nigam SK\",\n",
      "        \"matches_publication/journal\": \"J Pharmacol Exp Ther\",\n",
      "        \"matches_publication/title\": \"Molecular Properties of Drugs Interacting with SLC22 Transporters OAT1, OAT3, OCT1, and OCT2: A Machine-Learning Approach.\",\n",
      "        \"matches_optimization/algorithm\": \"Elastic net regression, SVM  and deep autoencoder\",\n",
      "        \"matches_optimization/encoding\": \"selected features from the deep learning autoencoder\",\n",
      "        \"matches_optimization/features\": \"selected features from the deep learning autoencoder: \\\"Matlab code for training a deep autoencoder as described by Hinton and Salakhutdinov was obtained from Hinton's website (http://www.cs.toronto.edu/$hinton/MatlabForSciencePaper.html)\\\"\",\n",
      "        \"matches_optimization/regularization\": \"Yes, variance-based mixture-fitting feature selection scheme\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/comparison\": \"they mentioned two similar studies: 10.1126/science.1127647 and 10.1038/nature12831\",\n",
      "        \"matches_evaluation/measure\": \"lastic net models: average sensitivity 0.75, average specificity 0.78, AUROC 0.81\\n SVM models: average sensitivity 0.59, average specificity 0.56, AUROC 0.55\",\n",
      "        \"matches_evaluation/method\": \"25-fold cross-validation\",\n",
      "        \"matches_dataset/provenance\": \"source of data:  large pharmacogenomics studies: Genomics of Drug Sensitivity in Cancer Project (GDSC), and the Cancer Cell Line Encyclopedia (CCLE),\\nafter filtering, they created a single array of data containing information on 3577 features in 624 cell lines\",\n",
      "        \"matches_dataset/splits\": \"for training a deep autoencoder: randomly split into training and testing datasets of 520 and 104 samples, respectively\\n\\nfor drug-sensitivity prediction: 25-fold cross-validation\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b86\",\n",
      "        \"publication_pmid\": \"27832081\",\n",
      "        \"publication_updated\": \"02/21/2022 23:04:51\",\n",
      "        \"publication_authors\": \"Willett DS, George J, Willett NS, Stelinski LL, Lapointe SL\",\n",
      "        \"publication_journal\": \"PLoS Comput Biol\",\n",
      "        \"publication_title\": \"Machine Learning for Characterization of Insect Vector Feeding.\",\n",
      "        \"publication_doi\": \"10.1371/journal.pcbi.1005158\",\n",
      "        \"publication_year\": \"2016\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"5de83145-b739-43f7-a0cf-8c223ddf45f9\",\n",
      "        \"shortid\": \"8ockqu6jl9\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches_publication/updated\": \"02/21/2022 23:04:51\",\n",
      "        \"matches_publication/authors\": \"Willett DS, George J, Willett NS, Stelinski LL, Lapointe SL\",\n",
      "        \"matches_publication/journal\": \"PLoS Comput Biol\",\n",
      "        \"matches_publication/title\": \"Machine Learning for Characterization of Insect Vector Feeding.\",\n",
      "        \"matches_optimization/config\": \"yes, in \\\"savedmodels\\\" folder in https://github.com/KlugerLab/deepcytof.git.\",\n",
      "        \"matches_optimization/encoding\": \"sample denoising, calibration between target samples and a single reference source sample\\nand finally cell classification. We implement each of these tasks using the following three neural nets: (i) a denoising autoencoder (DAE) for handling missing data; (ii) an MMD-ResNet for calibrating between the target samples and a reference source sample; (iii) a\\ndepth-4 feed-forward neural net for classifying/gating cell types trained on a reference source sample.\",\n",
      "        \"matches_optimization/parameters\": \"depth-4 feed-forward neural nets\",\n",
      "        \"matches_optimization/regularization\": \"logarithmic transform, followed by rescaling\",\n",
      "        \"matches_model/availability\": \"https://github.com/\\n KlugerLab/deepcytof.git.\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"cell classification\",\n",
      "        \"matches_evaluation/confidence\": \"comparison with manually performed task\",\n",
      "        \"matches_evaluation/measure\": \"F-measure statistic (the harmonic mean of precision\\n and recall)\",\n",
      "        \"matches_evaluation/method\": \"independent dataset\",\n",
      "        \"matches_dataset/provenance\": \" three CyTOF datasets consisting of 56, 136 and 16 PBMC samples\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b87\",\n",
      "        \"publication_pmid\": \"27855170\",\n",
      "        \"publication_updated\": \"02/23/2022 17:15:55\",\n",
      "        \"publication_authors\": \"Crisman TJ, Zelaya I, Laks DR, Zhao Y, Kawaguchi R, Gao F, Kornblum HI, Coppola G\",\n",
      "        \"publication_journal\": \"PLoS One\",\n",
      "        \"publication_title\": \"Identification of an Efficient Gene Expression Panel for Glioblastoma Classification.\",\n",
      "        \"publication_doi\": \"10.1371/journal.pone.0164649\",\n",
      "        \"publication_year\": \"2016\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"ae4b3d28-aac1-4f6c-87b5-cd0f72a69674\",\n",
      "        \"shortid\": \"xyv3h983ib\",\n",
      "        \"score\": 0.38,\n",
      "        \"matches_publication/updated\": \"02/23/2022 17:15:55\",\n",
      "        \"matches_publication/authors\": \"Crisman TJ, Zelaya I, Laks DR, Zhao Y, Kawaguchi R, Gao F, Kornblum HI, Coppola G\",\n",
      "        \"matches_publication/journal\": \"PLoS One\",\n",
      "        \"matches_publication/title\": \"Identification of an Efficient Gene Expression Panel for Glioblastoma Classification.\",\n",
      "        \"matches_optimization/meta\": \"Yes. Protein structures/Protein sequences\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/measure\": \"ROC Curve\",\n",
      "        \"matches_evaluation/method\": \"Independent dataset\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b95\",\n",
      "        \"publication_pmid\": \"27222432\",\n",
      "        \"publication_updated\": \"03/16/2022 17:02:02\",\n",
      "        \"publication_authors\": \"Schnoerr D, Grima R, Sanguinetti G\",\n",
      "        \"publication_journal\": \"Nat Commun\",\n",
      "        \"publication_title\": \"Cox process representation and inference for stochastic reaction-diffusion processes.\",\n",
      "        \"publication_doi\": \"10.1038/ncomms11729\",\n",
      "        \"publication_year\": \"2016\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"2882dbba-6819-442d-b027-50598cd5a0a6\",\n",
      "        \"shortid\": \"yirxngqbuc\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"03/16/2022 17:02:02\",\n",
      "        \"matches_publication/authors\": \"Schnoerr D, Grima R, Sanguinetti G\",\n",
      "        \"matches_publication/journal\": \"Nat Commun\",\n",
      "        \"matches_publication/title\": \"Cox process representation and inference for stochastic reaction-diffusion processes.\",\n",
      "        \"matches_optimization/algorithm\": \"Ensemble, incl. Adaboost Random Forrest, and SVM\",\n",
      "        \"matches_optimization/fitting\": \"Class imbalance is compensated\",\n",
      "        \"matches_optimization/parameters\": \"Protocol is clear\",\n",
      "        \"matches_optimization/regularization\": \"No but kernel: RBF\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"Binary classification but evaluated a ranker: ROC\",\n",
      "        \"matches_evaluation/measure\": \"ROC curve\",\n",
      "        \"matches_evaluation/method\": \"Cross validation\",\n",
      "        \"matches_dataset/splits\": \"100 pos, 2000 neg\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"665a01aa37ea6fa797a6bd7d\",\n",
      "        \"shortid\": \"23rrtkglve\",\n",
      "        \"uuid\": \"4871c35e-fd51-4036-abbc-783f8f4ca99a\",\n",
      "        \"created\": \"2024-05-31T16:58:18.981Z\",\n",
      "        \"updated\": \"2024-05-31T16:58:18.981Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"27875980\",\n",
      "        \"publication_authors\": \"Guido Cordoni, Martin J. Woodward, Huihai Wu, Mishaal Alanazi, Tim Wallis and Roberto M. La Ragione\",\n",
      "        \"publication_journal\": \"BMC Genomics\",\n",
      "        \"publication_title\": \"Comparative genomics of European avian pathogenic E. Coli (APEC)\",\n",
      "        \"publication_doi\": \"10.1186/s12864-016-3289-7\",\n",
      "        \"publication_year\": \"2016\",\n",
      "        \"score\": 0.95,\n",
      "        \"matches_evaluation/comparison\": \"No \",\n",
      "        \"matches_evaluation/confidence\": \"No cross compaarison to other methods. From the text: Strong factor associations were reported (confidence 0.99):  1). ompT (protease) ==\\u2009>\\u2009hylP (haemolysin) 2). IroN (siderophore)\\u2009+\\u2009ompT (proteases) ==\\u2009>\\u2009hlyp (haemolysin) 3). ompT (proteases)\\u2009+\\u2009sitA (cell adhesion\\u2013metal ions binding==\\u2009>\\u2009hlyp (haemolysisn).  Significant factor associations were reported (confidence above 0.95): 4). IroN (siderophore)\\u2009+\\u2009sitA (cell adhesion\\u2013metal ions binding) ==\\u2009>\\u2009hlyP (haemolysisn conf:(0.96) 5). cva/cvi (bacteriocin immunity) ==\\u2009>\\u2009hlyP (haemolysisn) conf:(0.96) 6). hlyP (haemolysisn)\\u2009+\\u2009sitA (cell adhesion metal ions binding) ==\\u2009>\\u2009iron (siderophore) conf:(0.95) 7). hlyp(haemolysisn)\\u2009=\\u20091 sitA (cell adhesion\\u2013metal ions binding) ==\\u2009>\\u2009ompT (proteases) conf:(0.95).\",\n",
      "        \"matches_evaluation/measure\": \"Apriori is an unsupervised learning algorithm, the concept of performance measures in the traditional sense (like accuracy or precision) doesn't directly apply. \",\n",
      "        \"matches_evaluation/method\": \"The Apriori ML algorithm itself doesn't directly benefit from techniques like cross-validation typically used in supervised learning. \\n\\nThe 22 equally weighted factors covering virulence genes, R-type and phylogroup predicted factor associations were used in a standard ML Apriori algorithm implementation. This is a novel dataset.\",\n",
      "        \"matches_optimization/algorithm\": \"To determine virulence factor associations the in the PCR isolates data they used machine learning and data mining software WEKA. Within WEKA the Apriori ML algorithm was applied to the data.\\n\\nThis Apriori ML algorithm is not new, first proposed in 1994.\",\n",
      "        \"matches_optimization/config\": \"Apriori ML algorithm in WEKA software was used, leaving all the parameters on the default settings. \",\n",
      "        \"matches_optimization/encoding\": \"No clear preprocessing was undertaken beyond standard data structuring for use in the ML alogrithm. 22 equally weighted factors covering virulence genes, R-type and phylogroup were checked for their presence in each of the 272 isolates. These DNA data virulence factors are available in spreadsheet like tables in the paper.\",\n",
      "        \"matches_optimization/features\": \"None - not applicable to Apriori ML model. They use transactional datasets, in this case the 22 PCR virulence factors are the constituents of the transactional dataset in relation to each of the 272 isolates.\",\n",
      "        \"matches_optimization/fitting\": \"No - unsupervised ML method, used to classify and no fitting is used for this. \",\n",
      "        \"matches_optimization/meta\": \"No - Apriori ML alogrithm does not use meta-predictions as an input. \\n\\nWhile Apriori doesn't use meta-predictors, other algorithms for association rule learning might leverage them:\\nSEuqential Miner (SEQUOIA)or Constraint-based association rule learning.\",\n",
      "        \"matches_optimization/parameters\": \"Provided a standard Apriori ML algorithm was implemented as indicated in the text, here are some of the key parameters that would be used:\\nMinimum Support \\nMinimum Confidence \\n\\nAlso sometimes used by the Apriori ML algorithm are:\\nMaximum Length \\nLift\\n\",\n",
      "        \"matches_optimization/regularization\": \"No - not applicable for this unsupervised ML method. No regularistaion is used.\",\n",
      "        \"matches_model/availability\": \"No, it seems no novel code was produced or shared if it was produced for the analysis. No GitHub or code repository linked. The primary ML related software used for the analysis is identified as the 'machine learning and data mining software WEKA' which is referenced in the text. (https://dl.acm.org/doi/10.1145/1656274.1656278)\",\n",
      "        \"matches_model/duration\": \"Information not provided for the text on the ML section. It is unlikely a HPC machine was needed to run the analysis as the software was released in the early 2000s and uses a user friendly graphical user interface.  \",\n",
      "        \"matches_model/interpretability\": \"Information and tutorials are available on the Apriori ML algorithm of the Weka software in online tutorials e.g. https://www.tutorialspoint.com/weka/weka_association.htm . As the default parameters were used, it is not a complete black box. However, the exact availability of the Weka tool's underlying code is not clear or easily available from the paper, e.g. no GitHub link. \",\n",
      "        \"matches_model/output\": \"Classification model.\",\n",
      "        \"matches_dataset/availability\": \"Data relevant to the ML methods:\\nThe PCR data was the determination of the presence of 22 equally weighted genetic factors covering virulence genes, R-type and phylogroup across 272 isolates. This data such as gene names, amplicon size in bp length and sequence 5\\u2032\\u20133\\u2032 are available in tables in the text - Tables 1, 2 and 3. \\n\\nData not relevant to the ML methods:\\nThe WGS sequences can be found on European Nucleotide Archive (EMBL-EBI) with project accession number PRJEB11876 (ERP013295) and on the NCBI database.\\nENA: http://www.ebi.ac.uk/ena/data/view/PRJEB11876\\nNCBI: https://www.ncbi.nlm.nih.gov/bioproject/PRJEB11876/  \",\n",
      "        \"matches_dataset/provenance\": \"Avian pathogenic Escherichia coli (APEC) isolates were the primary data source and were collected through direct experimentation. \\n\\n272 APEC isolates were collected from the  UK (173), Germany (69) and Italy (30). These 272 isolates were then genetically characterised using multiplex polymerase chain reactions (PCRs) targeting 22 equally weighted factors covering virulence genes, R-type and phylogroup. This data was used for their ML approaches. \\n\\n95 of the 272 isolates were further analysed using Whole Genome Sequencing (WGS) to create whole genomes. This data was not used for their ML appraoches.\",\n",
      "        \"matches_dataset/redundancy\": \"Data was not split. No training data used due to unsupervised classification ML model used.\",\n",
      "        \"matches_dataset/splits\": \"No - no data split as unsupervised classification method used without labelled data included. \",\n",
      "        \"matches_publication/authors\": \"Guido Cordoni, Martin J. Woodward, Huihai Wu, Mishaal Alanazi, Tim Wallis and Roberto M. La Ragione\",\n",
      "        \"matches_publication/journal\": \"BMC Genomics\",\n",
      "        \"matches_publication/title\": \"Comparative genomics of European avian pathogenic E. Coli (APEC)\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b39\",\n",
      "        \"publication_pmid\": \"26957000\",\n",
      "        \"publication_updated\": \"02/23/2022 16:01:54\",\n",
      "        \"publication_authors\": \"Jia CZ, He WY, Yao YH\",\n",
      "        \"publication_journal\": \"J Biomol Struct Dyn\",\n",
      "        \"publication_title\": \"OH-PRED: prediction of protein hydroxylation sites by incorporating adapted normal distribution bi-profile Bayes feature extraction and physicochemical properties of amino acids.\",\n",
      "        \"publication_doi\": \"10.1080/07391102.2016.1163294\",\n",
      "        \"publication_year\": \"2017\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"36e9870f-9db6-4673-90a4-ad00c967c0bd\",\n",
      "        \"shortid\": \"ie0f3buyr4\",\n",
      "        \"score\": 0.52,\n",
      "        \"matches_publication/updated\": \"02/23/2022 16:01:54\",\n",
      "        \"matches_publication/authors\": \"Jia CZ, He WY, Yao YH\",\n",
      "        \"matches_publication/journal\": \"J Biomol Struct Dyn\",\n",
      "        \"matches_publication/title\": \"OH-PRED: prediction of protein hydroxylation sites by incorporating adapted normal distribution bi-profile Bayes feature extraction and physicochemical properties of amino acids.\",\n",
      "        \"matches_optimization/algorithm\": \"Random forest\",\n",
      "        \"matches_optimization/encoding\": \"global features\",\n",
      "        \"matches_optimization/features\": \"100. Iterative feature selection removing features with Pearson\\u2019s correlation coefficient > 0.8. Performed on all data.\",\n",
      "        \"matches_optimization/parameters\": \"Number of parameters not specificed. Hyperparameter tuning was performed using randomised search with K-fold cross-validation to optimise the model parameters \",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/measure\": \"F1 score of 0.98\",\n",
      "        \"matches_dataset/availability\": \"The features table dataset has not been made available. Authors made available the imaging data at https://www.ebi.ac.uk/biostudies/ with accession number S-BIAD161. Authors also report that features were extracted from images with CellProfiler 3.1.8 and provide the list of morphological and contextual measurements extracted to generate the features table (Table B of http://journals.plos.org/ploscompbiol/article/asset?unique&id=info:doi/10.1371/journal.pcbi.1009193.s002http://journals.plos.org/ploscompbiol/article/asset?unique&id=info:doi/10.1371/journal.pcbi.1009193.s002 )\",\n",
      "        \"matches_dataset/provenance\": \"Imaging data produced by the same authors. 826 cells classified in 3 classes (no negative/positive binary classification).\",\n",
      "        \"matches_dataset/splits\": \"90% training set 10% test set\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b3e\",\n",
      "        \"publication_pmid\": \"28696170\",\n",
      "        \"publication_updated\": \"05/20/2022 17:19:51\",\n",
      "        \"publication_authors\": \"Harteveld DOC, Grant MR, Pscheidt JW, Peever TL\",\n",
      "        \"publication_journal\": \"Phytopathology\",\n",
      "        \"publication_title\": \"Predicting Ascospore Release of Monilinia vaccinii-corymbosi of Blueberry with Machine Learning.\",\n",
      "        \"publication_doi\": \"10.1094/PHYTO-04-17-0162-R\",\n",
      "        \"publication_year\": \"2017\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"d1a1ce81-ead9-4970-ba09-10e679dcfc03\",\n",
      "        \"shortid\": \"lrlwou3dt7\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches_publication/updated\": \"05/20/2022 17:19:51\",\n",
      "        \"matches_publication/authors\": \"Harteveld DOC, Grant MR, Pscheidt JW, Peever TL\",\n",
      "        \"matches_publication/title\": \"Predicting Ascospore Release of Monilinia vaccinii-corymbosi of Blueberry with Machine Learning.\",\n",
      "        \"matches_optimization/algorithm\": \"Statistical analysis and clustering (K-means)\",\n",
      "        \"matches_optimization/encoding\": \"Trimming and segmentation over sequences\",\n",
      "        \"matches_optimization/parameters\": \"Clusters number treated as a tuning parameter. Cross-validation approach to choose optimal K (looks like it was 5000 clusters)\",\n",
      "        \"matches_model/availability\": \"https://github.com/zji90/SCATE and release used at https://doi.org/10.5281/zenodo.3711558\",\n",
      "        \"matches_model/duration\": \"1-2 days. running SCATE to reconstruct regulome approximately takes 5 minutes per cell cluster on a computer with 10 computing cores (2.5 GHz CPU/core) and a total of 20GB RAM.\",\n",
      "        \"matches_evaluation/comparison\": \"Across benchmarking datasets\",\n",
      "        \"matches_evaluation/confidence\": \"p and q values\",\n",
      "        \"matches_evaluation/method\": \"Benchmarking over 3 datasets with scATAC-seq data\",\n",
      "        \"matches_dataset/provenance\": \"Provenance stated via references\",\n",
      "        \"matches_dataset/redundancy\": \"Not applicable (it is a cluster approach)\",\n",
      "        \"matches_dataset/splits\": \"Not applicable (it is a cluster approach)\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b61\",\n",
      "        \"publication_pmid\": \"27362985\",\n",
      "        \"publication_updated\": \"01/26/2022 11:27:05\",\n",
      "        \"publication_authors\": \"Adl AA, Lee HS, Qian X\",\n",
      "        \"publication_journal\": \"IEEE/ACM Trans Comput Biol Bioinform\",\n",
      "        \"publication_title\": \"Detecting Pairwise Interactive Effects of Continuous Random Variables for Biomarker Identification with Small Sample Size.\",\n",
      "        \"publication_doi\": \"10.1109/TCBB.2016.2586042\",\n",
      "        \"publication_year\": \"2017\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"006ff363-6c34-4593-86af-0aa3b8af83d1\",\n",
      "        \"shortid\": \"2so9xiaxer\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches_publication/updated\": \"01/26/2022 11:27:05\",\n",
      "        \"matches_publication/authors\": \"Adl AA, Lee HS, Qian X\",\n",
      "        \"matches_publication/journal\": \"IEEE/ACM Trans Comput Biol Bioinform\",\n",
      "        \"matches_publication/title\": \"Detecting Pairwise Interactive Effects of Continuous Random Variables for Biomarker Identification with Small Sample Size.\",\n",
      "        \"matches_optimization/algorithm\": \"neural network\",\n",
      "        \"matches_optimization/encoding\": \"pECG signal features:\\n(A) QRS duration, \\n(B) QT interval, \\n(C) ST deviation, \\n(D) T wave duration, \\n(E) QRS amplitude \\n(F) T wave amplitude\",\n",
      "        \"matches_optimization/parameters\": \" multiple setup was tested, selected with : 5 hidden layers and 7 hidden neurons per layer,\\n\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/measure\": \"sensitivity, PPV, F1-score\",\n",
      "        \"matches_evaluation/method\": \"10-fold cross-validation\",\n",
      "        \"matches_dataset/provenance\": \" 6132 pECG beats was used for training in three class: Control, Mild, Severe\",\n",
      "        \"matches_dataset/splits\": \"10-fold cross-validation\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b62\",\n",
      "        \"publication_pmid\": \"29263361\",\n",
      "        \"publication_updated\": \"01/28/2022 12:34:45\",\n",
      "        \"publication_authors\": \"Nicola W, Clopath C\",\n",
      "        \"publication_journal\": \"Nat Commun\",\n",
      "        \"publication_title\": \"Supervised learning in spiking neural networks with FORCE training.\",\n",
      "        \"publication_doi\": \"10.1038/s41467-017-01827-3\",\n",
      "        \"publication_year\": \"2017\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"964f49d7-ae30-4db1-8d54-ca667d7e64d5\",\n",
      "        \"shortid\": \"84zp8aovt4\",\n",
      "        \"score\": 0.57,\n",
      "        \"matches_publication/updated\": \"01/28/2022 12:34:45\",\n",
      "        \"matches_publication/authors\": \"Nicola W, Clopath C\",\n",
      "        \"matches_publication/journal\": \"Nat Commun\",\n",
      "        \"matches_publication/title\": \"Supervised learning in spiking neural networks with FORCE training.\",\n",
      "        \"matches_optimization/encoding\": \"six blood parameters (C-reactive protein, white cell count, bilirubin, creatinine, ALT and alkaline phosphatase)\",\n",
      "        \"matches_optimization/fitting\": \"Removal of outliers, Synthetic Minority Over-Sampling Technique was used\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/comparison\": \"no direct comparision\",\n",
      "        \"matches_evaluation/measure\": \"ROC AUC 0.84\\n 92% sensitivity, 94%specificity\",\n",
      "        \"matches_evaluation/method\": \"10-fold cross-validation\",\n",
      "        \"matches_dataset/availability\": \"Yes,  upon reasonable request from the corresponding author\",\n",
      "        \"matches_dataset/provenance\": \"six available blood parameters (C-reactive protein, white cell count, bilirubin, creatinine, ALT and alkaline phosphatase) from 160203 individuals.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b63\",\n",
      "        \"publication_pmid\": \"28678787\",\n",
      "        \"publication_updated\": \"01/31/2022 08:45:48\",\n",
      "        \"publication_authors\": \"Zwierzyna M, Overington JP\",\n",
      "        \"publication_journal\": \"PLoS Comput Biol\",\n",
      "        \"publication_title\": \"Classification and analysis of a large collection of in vivo bioassay descriptions.\",\n",
      "        \"publication_doi\": \"10.1371/journal.pcbi.1005641\",\n",
      "        \"publication_year\": \"2017\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"f11b2731-c298-4706-b5fb-70d1068217da\",\n",
      "        \"shortid\": \"b171clx1jy\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"01/31/2022 08:45:48\",\n",
      "        \"matches_publication/authors\": \"Zwierzyna M, Overington JP\",\n",
      "        \"matches_publication/journal\": \"PLoS Comput Biol\",\n",
      "        \"matches_publication/title\": \"Classification and analysis of a large collection of in vivo bioassay descriptions.\",\n",
      "        \"matches_optimization/config\": \"Yes, Supporting information\",\n",
      "        \"matches_optimization/features\": \"34 featuress mapped to genes altered in sample cohort (one of the three datasets). See Supplementary Material 1for details.\",\n",
      "        \"matches_optimization/parameters\": \"nu (all kernels), gamma (radial, sigmoid, polynomial kernels), degree (polynomial kernel). 10000 iterations of three-fold cross validation, random split of training set into 2/3 train, 1/3 test set. Sensitivity is used to select the least varying model from top 5 models for each kernel. (more details in Supplementary Material 1)\",\n",
      "        \"matches_optimization/regularization\": \"best model selection takes into account all previous cross-validation iterations every n (100) cross validations, random reordering of cross validation iterations (5x)\",\n",
      "        \"matches_model/availability\": \"https://github.com/ciccalab/sysSVM, License not defined\",\n",
      "        \"matches_evaluation/availability\": \"Supporting information and GitHub / R Project https://github.com/ciccalab/sysSVM\",\n",
      "        \"matches_evaluation/comparison\": \"No comparison to other methods. Identified helper genes show similar properties to known cancer genes. Estimation based on pathway enrichment of identified novel genes (helpers) vs known cancer genes (drivers) based on functional association\",\n",
      "        \"matches_evaluation/method\": \"Cross validation & independent datasets\",\n",
      "        \"matches_dataset/availability\": \"Yes, supporting information, https://ega-archive.org/datasets/EGAD00001004775, https://ega-archive.org/datasets/EGAD00001004776, esophageal adenocarcinoma samples from OCCAM consortium / part of ICGC\",\n",
      "        \"matches_dataset/provenance\": \"Data are EAC (esophageal adenocarcinoma) genes from 1) ICGC (261), TCGA (86), Other Study (21)\",\n",
      "        \"matches_dataset/redundancy\": \"Training and validation are completely separate. Parameter optimization was based on training data with grid search using 10,000 iterations and three fold cross-validation on four different SVM classifiers using a linear, radial, sigmoid and polynomial kernel.\",\n",
      "        \"matches_dataset/splits\": \"Training and validation data were completely independent (ICGC/Occam data for training, TCGA and additionaly study data for testing of robustness and validation)\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b64\",\n",
      "        \"publication_pmid\": \"28624633\",\n",
      "        \"publication_updated\": \"02/02/2022 10:08:47\",\n",
      "        \"publication_authors\": \"S\\u00e1nchez-Rodr\\u00edguez A, P\\u00e9rez-Castillo Y, Sch\\u00fcrer SC, Nicolotti O, Mangiatordi GF, Borges F, Cordeiro MNDS, Tejera E, Medina-Franco JL, Cruz-Monteagudo M\",\n",
      "        \"publication_journal\": \"Drug Discov Today\",\n",
      "        \"publication_title\": \"From flamingo dance to (desirable) drug discovery: a nature-inspired approach.\",\n",
      "        \"publication_doi\": \"10.1016/j.drudis.2017.05.008\",\n",
      "        \"publication_year\": \"2017\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"02cbd7a6-f8b7-425b-8d94-ec6d79a8aebc\",\n",
      "        \"shortid\": \"5a9ger6xi3\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches_publication/updated\": \"02/02/2022 10:08:47\",\n",
      "        \"matches_publication/authors\": \"S\\u00e1nchez-Rodr\\u00edguez A, P\\u00e9rez-Castillo Y, Sch\\u00fcrer SC, Nicolotti O, Mangiatordi GF, Borges F, Cordeiro MNDS, Tejera E, Medina-Franco JL, Cruz-Monteagudo M\",\n",
      "        \"matches_publication/journal\": \"Drug Discov Today\",\n",
      "        \"matches_publication/title\": \"From flamingo dance to (desirable) drug discovery: a nature-inspired approach.\",\n",
      "        \"matches_optimization/algorithm\": \"Diffusion (propagation) methods, Purer ML-based methods and naive baseline methods\",\n",
      "        \"matches_optimization/encoding\": \"Associations were binarised\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"regression: ranking of genes in terms of their association scores to the disease\",\n",
      "        \"matches_evaluation/comparison\": \"network topology, basic GBA approach\",\n",
      "        \"matches_evaluation/confidence\": \"The rankings produced by the different algorithms were qualitatively compared using Spearman\\u2019s footrule\",\n",
      "        \"matches_evaluation/measure\": \"20 hits, AUPRC, AUROC\",\n",
      "        \"matches_dataset/provenance\": \"Open Targets platform,  at least 1,000 Open Targets associations. 22 diseases were considered\",\n",
      "        \"matches_dataset/splits\": \"genetic association with disease. Based on given score some  associations were considered positive.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b65\",\n",
      "        \"publication_pmid\": \"28600868\",\n",
      "        \"publication_updated\": \"02/08/2022 23:45:07\",\n",
      "        \"publication_authors\": \"Sundaram L, Bhat RR, Viswanath V, Li X\",\n",
      "        \"publication_journal\": \"Hum Mutat\",\n",
      "        \"publication_title\": \"DeepBipolar: Identifying genomic mutations for bipolar disorder via deep learning.\",\n",
      "        \"publication_doi\": \"10.1002/humu.23272\",\n",
      "        \"publication_year\": \"2017\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"30e2b822-a203-454f-9cb8-41623505bcda\",\n",
      "        \"shortid\": \"ek6yatpcos\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches_publication/updated\": \"02/08/2022 23:45:07\",\n",
      "        \"matches_publication/authors\": \"Sundaram L, Bhat RR, Viswanath V, Li X\",\n",
      "        \"matches_publication/journal\": \"Hum Mutat\",\n",
      "        \"matches_publication/title\": \"DeepBipolar: Identifying genomic mutations for bipolar disorder via deep learning.\",\n",
      "        \"matches_optimization/algorithm\": \"K-means clustering, hierarchal clustering (HC), partitioning around medoids (PAM),\\nLSTM based on variational autoencoder (VAE)\\ndeep convolutional embedded clustering (DCEC)\\n\",\n",
      "        \"matches_optimization/config\": \"platform: Intel Xeon Processor E5-2643 v4, 128 GB RAM and NVIDIA Quadro M4000 GPU.\\n K-means and HC: Python scikit-learn \\n PAM: R \\u2018cluster\\u2019 package\\n LSTM-VAE: https://github.com/bilalmirza8519/LSTM-VAE\\n DCEC: https://github.com/XifengGuo/DCEC\",\n",
      "        \"matches_optimization/parameters\": \"K-means, HC, PAM: K = 6 based on prior biological knowledge\\n\\nLSTM-VAE: \\nthe input layer of dimension 7 \\u00d7 1\\nfirst layer generated 7 \\u00d7 n\\nsecond layer 7 \\u00d7 1\\n\\nDCEC: used as DOI: 10.1007/978-3-319-70096-0_39\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/comparison\": \"Comparison only betweeen models created by the authors\",\n",
      "        \"matches_evaluation/measure\": \"pathway enrichment analysis using Reactome knowledgebase\",\n",
      "        \"matches_dataset/provenance\": \"datasets are based on mouse strains generated by the lab itself\\nThe aggerated dataset has complete time-series (7 timepoints) data for 3479 proteins and 513 metabolites.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b66\",\n",
      "        \"publication_pmid\": \"28065610\",\n",
      "        \"publication_updated\": \"02/15/2022 17:17:01\",\n",
      "        \"publication_authors\": \"Real E, Asari H, Gollisch T, Meister M\",\n",
      "        \"publication_journal\": \"Curr Biol\",\n",
      "        \"publication_title\": \"Neural Circuit Inference from Function to Structure.\",\n",
      "        \"publication_doi\": \"10.1016/j.cub.2016.11.040\",\n",
      "        \"publication_year\": \"2017\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"8fbaaea0-bcec-4aaf-a34b-86f7471a84cc\",\n",
      "        \"shortid\": \"909naoy87e\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches_publication/updated\": \"02/15/2022 17:17:01\",\n",
      "        \"matches_publication/authors\": \"Real E, Asari H, Gollisch T, Meister M\",\n",
      "        \"matches_publication/journal\": \"Curr Biol\",\n",
      "        \"matches_publication/title\": \"Neural Circuit Inference from Function to Structure.\",\n",
      "        \"matches_optimization/algorithm\": \"Lasso regression\",\n",
      "        \"matches_optimization/config\": \"Only values for alpha are provided\",\n",
      "        \"matches_optimization/features\": \"24994 genomic transcripts, 1000 metabolites, four agronomic traits, CV on transcripts > 0.2 and PD > 1 (90th% - 10th%), 5467 genomic transcripts after CV filter\",\n",
      "        \"matches_optimization/parameters\": \"Modified lasso regression, alpha (first layer), beta (second layer), gamma (third layer), 10-fold CV for all parameters, successively\",\n",
      "        \"matches_optimization/regularization\": \"10-fold CV\",\n",
      "        \"matches_model/interpretability\": \"Model is not available for evaluation\",\n",
      "        \"matches_model/output\": \"Regression, outputs \\\"predictability\\\"\",\n",
      "        \"matches_evaluation/availability\": \"Yes (not all parameters, evaluation based on \\\"Predictability\\\"), Supporting information\",\n",
      "        \"matches_evaluation/comparison\": \"Lasso regression\",\n",
      "        \"matches_dataset/availability\": \"Stated to use previously reported data, but no explicit reference provided. \",\n",
      "        \"matches_dataset/provenance\": \"Previously reported data, 210 lines, 1619 bins (synthetic markers), 24994 genes transcripts, 1000 metabolites and four agronomic traits\",\n",
      "        \"matches_dataset/redundancy\": \"Random choice from Cross-Validation\",\n",
      "        \"matches_dataset/splits\": \"10-fold Cross-Validation\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b67\",\n",
      "        \"publication_pmid\": \"29219069\",\n",
      "        \"publication_updated\": \"03/02/2022 17:27:58\",\n",
      "        \"publication_authors\": \"Tang Y, Liu D, Wang Z, Wen T, Deng L\",\n",
      "        \"publication_journal\": \"BMC Bioinformatics\",\n",
      "        \"publication_title\": \"A boosting approach for prediction of protein-RNA binding residues.\",\n",
      "        \"publication_doi\": \"10.1186/s12859-017-1879-2\",\n",
      "        \"publication_year\": \"2017\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"e104aa68-ff85-4fed-bc9f-06f1cdc39835\",\n",
      "        \"shortid\": \"acyudepk6j\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches_publication/updated\": \"03/02/2022 17:27:58\",\n",
      "        \"matches_publication/authors\": \"Tang Y, Liu D, Wang Z, Wen T, Deng L\",\n",
      "        \"matches_publication/journal\": \"BMC Bioinformatics\",\n",
      "        \"matches_publication/title\": \"A boosting approach for prediction of protein-RNA binding residues.\",\n",
      "        \"matches_optimization/algorithm\": \"Random forest\",\n",
      "        \"matches_optimization/config\": \"Yes, in Jupyter notebooks available on GitHub (https://github.com/knightlab-analyses/crossmodel_prediction).\",\n",
      "        \"matches_optimization/encoding\": \"1)\\t16S rRnot reported raw amplicon sequencing data were processed and converted to sub-operational taxonomic unit (sOTU) abundance per sample (BIOM format) using the Deblur workflow. Taxonomies for sOTUs were assigned using the sklearn-based taxonomy classifier trained on the Greengenes 13_8 99% OTUs in QIIME 2. The sOTU table was rarefied to a depth of 2,000 sequences/sample to control for sequencing effort. A phylogeny was inferred using SAT\\u00e9-enabled phylogenetic placement, which was used to insert 16S Deblur sOTUs into Greengenes 13_8 at a 99% phylogeny.\\n2)\\tRaw LC-MS/MS data sets were converted to m/z extensible markup language (mzXML) in centroid mode using MSConvert. All mzXML files were cropped with an m/z range of 75.00 to 1,000.00 Da. Feature extraction was performed in MZmine2 with a signal intensity threshold of 2.0e5 and minimum peak width of 0.3 s. The maximum allowed mass and retention time tolerances were 10 ppm and 10 s, respectively. A local minimum search algorithm with a minimum relative peak height of 1% was used for chromatographic deconvolution; the maximum peak width was set to 1 min. The detected peaks were aligned across all samples using the above-mentioned retention time and mass tolerances, producing the final feature table used in these analyses. \\nMolecular networking in GNPS was performed to putatively identify molecular features using MS/MS-based spectral library matches.\\n\",\n",
      "        \"matches_optimization/features\": \"1)\\tFirst data layer.16S rRnot reported amplicon sequencing-derived abundances of microbial taxonomies.\\n2)\\tSecond data layer. Quantified LC-MS/MS peaks of detected metabolites following preprocessing.\\n\",\n",
      "        \"matches_optimization/fitting\": \"Cross-validation with all the samples from the same mouse appearing only in either training or validation data but not both, to avoid overoptimistic cross-validation accuracy scores because of the classifier learning idiosyncrasies of the individual itself rather than the treatment.\",\n",
      "        \"matches_model/availability\": \"Yes, in Jupyter notebooks available on GitHub (https://github.com/knightlab-analyses/crossmodel_prediction).\",\n",
      "        \"matches_model/interpretability\": \"Transparent. The abundance of each feature, 16S sequence and metabolite, was used as the score to plot the ROC curve and compute the AUC score. Features that can single-handedly distinguish IHH-exposed samples on ROC plots were highlighted.\",\n",
      "        \"matches_model/output\": \"1) Binary predictions of IHH-exposed samples (positive) or air-exposed samples (negative) using total Ldlr-/- and ApoE-/- data as training and testing dataset, and vice versa.\\n 2) For longitudinal binary predictions of IHH-exposed samples (positive) or air-exposed samples (negative), using Ldlr-/- or ApoE-/- data per time point as training and testing dataset, and vice versa.\",\n",
      "        \"matches_evaluation/availability\": \"Yes. Supplementary information.\",\n",
      "        \"matches_evaluation/measure\": \"ROC curves, AUC score.\",\n",
      "        \"matches_evaluation/method\": \"Cross-validation. Details not specified.\",\n",
      "        \"matches_dataset/availability\": \"Yes, online under the following accession numbers: for metabolomics data, MSV000081482 (Ldlr knockout animal) at ftp://massive.ucsd.edu/MSV000081482, MSV000082813 (ApoE knockout animal) at ftp://massive.ucsd.edu/MSV000082813, and MSV000081853 (commercial standards) at ftp://massive.ucsd.edu/MSV000081853, and for microbiome data, ERP106495 (Ldlr knockout animals; EBI database) and ERP110592 (ApoE knockout animals).\",\n",
      "        \"matches_dataset/provenance\": \"16S rRnot reported sequencing and untargeted liquid chromatography-tandem mass spectrometry (LC-MS/MS) data from fecal samples of atherosclerosis-prone, 10-week-old, male mice on a\\nC57BL/6J background. 24 knockout mice for ApoE (ApoE-/-) and 16 knockout mice for Ldlr (Ldlr-/-). Fecal samples were collected at baseline and twice each week. 6 weeks, 12 time points and 192 samples, for Ldlr-/- mice. 10 weeks, 20 time points and 480 samples, for ApoE-/- mice.\\n\",\n",
      "        \"matches_dataset/redundancy\": \"Analytical standards for bile acids of interest were used with the same LC-MS/MS to ensure feature annotation.\\nData set stratification by genotypes and effect size calculation of each of the covariates within each mouse model to untangle the effect of genotype.\\n\",\n",
      "        \"matches_dataset/splits\": \"1)\\tNpos=96 samples for 8 Ldlr-/- mice exposed to intermittent hypoxia and hypercapnia (IHH). Nneg=96 samples for 8 Ldlr-/- mice exposed to air. Ntrain=192 for Ldlr-/- mice. Ntest=480 for ApoE-/- mice.\\n2)\\tNpos=12 ApoE-/- mice exposed to intermittent hypoxia and hypercapnia (IHH). Nneg=12 ApoE-/- mice exposed to air. Ntrain=480 for ApoE-/- mice. Ntest=192 for Ldlr-/- mice.\\n\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b68\",\n",
      "        \"publication_pmid\": \"28624633\",\n",
      "        \"publication_updated\": \"03/08/2022 10:24:58\",\n",
      "        \"publication_authors\": \"S\\u00e1nchez-Rodr\\u00edguez A, P\\u00e9rez-Castillo Y, Sch\\u00fcrer SC, Nicolotti O, Mangiatordi GF, Borges F, Cordeiro MNDS, Tejera E, Medina-Franco JL, Cruz-Monteagudo M\",\n",
      "        \"publication_journal\": \"Drug Discov Today\",\n",
      "        \"publication_title\": \"From flamingo dance to (desirable) drug discovery: a nature-inspired approach.\",\n",
      "        \"publication_doi\": \"10.1016/j.drudis.2017.05.008\",\n",
      "        \"publication_year\": \"2017\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"f04fcb26-53d5-4ac0-8458-c45183b92b0c\",\n",
      "        \"shortid\": \"8ltvqe2m93\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches_publication/updated\": \"03/08/2022 10:24:58\",\n",
      "        \"matches_publication/authors\": \"S\\u00e1nchez-Rodr\\u00edguez A, P\\u00e9rez-Castillo Y, Sch\\u00fcrer SC, Nicolotti O, Mangiatordi GF, Borges F, Cordeiro MNDS, Tejera E, Medina-Franco JL, Cruz-Monteagudo M\",\n",
      "        \"matches_publication/journal\": \"Drug Discov Today\",\n",
      "        \"matches_publication/title\": \"From flamingo dance to (desirable) drug discovery: a nature-inspired approach.\",\n",
      "        \"matches_optimization/encoding\": \"processing of signals and the resulting values are converted to quantile rank.\",\n",
      "        \"matches_optimization/features\": \"defaults classification labels lists or can be provided by the user\",\n",
      "        \"matches_optimization/meta\": \"authors recommend to choose the model with the highest F1-score\",\n",
      "        \"matches_optimization/parameters\": \"not clearly  stated\",\n",
      "        \"matches_model/interpretability\": \"various methods to directly determine class of genes\",\n",
      "        \"matches_evaluation/confidence\": \"qualitative description of the advantages of the presented pipeline\",\n",
      "        \"matches_evaluation/measure\": \"precision and recall\",\n",
      "        \"matches_evaluation/method\": \"Cross-validation and independent dataset\",\n",
      "        \"matches_dataset/redundancy\": \"In order to avoid excessive numbers of false\\npositive calls due to this imbalance, we trained the\\nmodels to optimize the metric Kappa rather than accuracy, as Kappa accounts for imbalanced number of genes\\nbelonging to each class in training data\",\n",
      "        \"matches_dataset/splits\": \"253 MAE genes and 1127 BAE genes\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b69\",\n",
      "        \"publication_pmid\": \"28807860\",\n",
      "        \"publication_updated\": \"03/08/2022 13:39:24\",\n",
      "        \"publication_authors\": \"Llanos F, Xie Z, Chandrasekaran B\",\n",
      "        \"publication_journal\": \"J Neurosci Methods\",\n",
      "        \"publication_title\": \"Hidden Markov modeling of frequency-following responses to Mandarin lexical tones.\",\n",
      "        \"publication_doi\": \"10.1016/j.jneumeth.2017.08.010\",\n",
      "        \"publication_year\": \"2017\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"d4ddd51f-3d4c-4c5d-8269-38a65992f2da\",\n",
      "        \"shortid\": \"0yzdxjimwz\",\n",
      "        \"score\": 0.43,\n",
      "        \"matches_publication/updated\": \"03/08/2022 13:39:24\",\n",
      "        \"matches_publication/authors\": \"Llanos F, Xie Z, Chandrasekaran B\",\n",
      "        \"matches_publication/journal\": \"J Neurosci Methods\",\n",
      "        \"matches_publication/title\": \"Hidden Markov modeling of frequency-following responses to Mandarin lexical tones.\",\n",
      "        \"matches_optimization/algorithm\": \"regularized logistic regression and random forest\",\n",
      "        \"matches_optimization/encoding\": \"Gene expression data, clinical variables.\",\n",
      "        \"matches_optimization/features\": \"f=10 ?\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"Binary classification\",\n",
      "        \"matches_evaluation/measure\": \"Balanced accuracy and ROC-AUC\",\n",
      "        \"matches_evaluation/method\": \"10-fold nested cross-validation. No independent validation data\",\n",
      "        \"matches_dataset/provenance\": \"Patient data from the  Rheumatoid Arthritis Medication Study (RAMS). N_pos=42, N_neg=43. Not previuolsy used. \",\n",
      "        \"matches_dataset/splits\": \"Nested cross-validation split. N_pos, N_neg not available\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b6a\",\n",
      "        \"publication_pmid\": \"28747397\",\n",
      "        \"publication_updated\": \"03/08/2022 18:05:03\",\n",
      "        \"publication_authors\": \"Gao H, Aderhold A, Mangion K, Luo X, Husmeier D, Berry C\",\n",
      "        \"publication_journal\": \"J R Soc Interface\",\n",
      "        \"publication_title\": \"Changes and classification in myocardial contractile function in the left ventricle following acute myocardial infarction.\",\n",
      "        \"publication_doi\": \"10.1098/rsif.2017.0203\",\n",
      "        \"publication_year\": \"2017\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"4427eadc-dc28-4afb-8ae5-dcaf51935306\",\n",
      "        \"shortid\": \"oi6cru1897\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"03/08/2022 18:05:03\",\n",
      "        \"matches_publication/authors\": \"Gao H, Aderhold A, Mangion K, Luo X, Husmeier D, Berry C\",\n",
      "        \"matches_publication/journal\": \"J R Soc Interface\",\n",
      "        \"matches_publication/title\": \"Changes and classification in myocardial contractile function in the left ventricle following acute myocardial infarction.\",\n",
      "        \"matches_optimization/algorithm\": \"Yes: SVM\",\n",
      "        \"matches_optimization/encoding\": \"Yes: sequence features (NVM, g-gap, TPC) and composition properties (CTD, pseAAC) \",\n",
      "        \"matches_optimization/features\": \"Yes: 5 types of features (NVM, g-gap, TPC, CTD, pseAAC). Feature selection using ANOVA for g-gap and pseAAC, binomial distribution for TPC and Incremental feature selection.\\nand size of vectors (21, 60, 81, 400, 8000 depending on the feature extraction method...)\",\n",
      "        \"matches_optimization/parameters\": \"Yes: parameters C and g, optimised by grid search space\",\n",
      "        \"matches_optimization/regularization\": \"Yes: Parameter C, optimised by grid search space\",\n",
      "        \"matches_model/availability\": \"No, only a prediction web service\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/comparison\": \"Yes: Comparison with other classifiers: J48, Bagging, Random Forest, Naive Bayes\\n Comparison with other published methods: HBPred, iGHBP, HBPred2.0\",\n",
      "        \"matches_evaluation/confidence\": \"No: only comparing difference between performance measures\",\n",
      "        \"matches_evaluation/measure\": \"Yes: Sensitivity, Specificity, Accuracy, Matthew correlation coefficient, AUC\",\n",
      "        \"matches_evaluation/method\": \"Yes: on 5-fold training dataset and also on independent dataset\",\n",
      "        \"matches_dataset/availability\": \"Yes: website url (http://lin-group.cn/server/HBPred2.0/download.html)\",\n",
      "        \"matches_dataset/provenance\": \"Yes: previous paper\",\n",
      "        \"matches_dataset/redundancy\": \"Yes: exclusion of identical sequences between testing and training datasets. Reduced redundancy within testing dataset (sequence identity >60% CD-HIT).\",\n",
      "        \"matches_dataset/splits\": \"Yes, size of training and test set, including distribution N_pos N_neg\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b74\",\n",
      "        \"publication_pmid\": \"28881974\",\n",
      "        \"publication_updated\": \"03/17/2022 23:25:21\",\n",
      "        \"publication_authors\": \"Michel M, Men\\u00e9ndez Hurtado D, Uziela K, Elofsson A\",\n",
      "        \"publication_journal\": \"Bioinformatics\",\n",
      "        \"publication_title\": \"Large-scale structure prediction by improved contact predictions and model quality assessment.\",\n",
      "        \"publication_doi\": \"10.1093/bioinformatics/btx239\",\n",
      "        \"publication_year\": \"2017\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"23c26bad-c7ec-455d-aec5-edc6cea9e204\",\n",
      "        \"shortid\": \"28yy20yr51\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches_publication/updated\": \"03/17/2022 23:25:21\",\n",
      "        \"matches_publication/authors\": \"Michel M, Men\\u00e9ndez Hurtado D, Uziela K, Elofsson A\",\n",
      "        \"matches_publication/title\": \"Large-scale structure prediction by improved contact predictions and model quality assessment.\",\n",
      "        \"matches_optimization/algorithm\": \"Algorithm 1 (TripletRes): neural network\\n\\nAlgorithm 2 (ResTriplet): neural network\",\n",
      "        \"matches_optimization/encoding\": \"For each sequence a multiple sequence alignment (MSA) was performed.\",\n",
      "        \"matches_optimization/features\": \"For each sequence three matrix features are generated: Covariance matrix, Precision Matrix, coupling parameters of the Potts model.\",\n",
      "        \"matches_optimization/meta\": \"Algorithm 1: No.\\n\\nAlgorithm 2: Yes. The network is actually composed of two subnetworks (called Stage 1 and Stage 2 in the paper), the first giving the inputs to the second. \",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"The model produces a prediction of the contact map for each residue pair in the sequence alignment.\",\n",
      "        \"matches_evaluation/comparison\": \"Not clear. They compare Algorithm 1 and Algorithm 2.\",\n",
      "        \"matches_evaluation/confidence\": \"They claim statistical significance in the different performances of Algorithm 1 and Algorithm 2.\",\n",
      "        \"matches_evaluation/measure\": \"Prediction accuracy (performed by CASP13 assesors)\",\n",
      "        \"matches_evaluation/method\": \"Independent dataset (Dataset 2, i.e. CASP13)\",\n",
      "        \"matches_dataset/availability\": \"Yes. \\n\\nDataset 1: URL: http://scop.berkeley.edu/\\n\\nDataset 2: URL: https://predictioncenter.org/casp13/\",\n",
      "        \"matches_dataset/provenance\": \"Dataset 1: Protein sequences retrived from SCOPe 2.07 database. N = 7,671. Used in other papers. Dataset used for training.\\n\\nDataset 2: CASP13. Used in other papers. Dataset used for test. N = 122.\\n\\nThe paper is about the prediction of contact maps in the protein sequence, so data are not in classes and N_pos and N_neg do not apply (not reported from now on)\",\n",
      "        \"matches_dataset/redundancy\": \"Dataset 1 (used for training) and Dataset 2 (used for test) are independent.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b76\",\n",
      "        \"publication_pmid\": \"29036374\",\n",
      "        \"publication_updated\": \"03/23/2022 13:41:44\",\n",
      "        \"publication_authors\": \"Li H, Shaham U, Stanton KP, Yao Y, Montgomery RR, Kluger Y\",\n",
      "        \"publication_journal\": \"Bioinformatics\",\n",
      "        \"publication_title\": \"Gating mass cytometry data by deep learning.\",\n",
      "        \"publication_doi\": \"10.1093/bioinformatics/btx448\",\n",
      "        \"publication_year\": \"2017\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"d7de0b56-fc2d-4ad5-a3d8-d33f721d5f36\",\n",
      "        \"shortid\": \"nzflw09djs\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches_publication/updated\": \"03/23/2022 13:41:44\",\n",
      "        \"matches_publication/authors\": \"Li H, Shaham U, Stanton KP, Yao Y, Montgomery RR, Kluger Y\",\n",
      "        \"matches_publication/title\": \"Gating mass cytometry data by deep learning.\",\n",
      "        \"matches_optimization/algorithm\": \"Algorithm 1: they use a novel machine learning method for feature extraction, called Gaussian interaction profile kernel and autoencoder (GIPAE). \\n\\nAlgorithm 2: they use Random Forest for classification.\",\n",
      "        \"matches_optimization/encoding\": \"Input information is transformed by GIPAE, in order to extract new features from data. The transformed data are then used for training a Random Forest algorithm.\",\n",
      "        \"matches_model/availability\": \"The repository of the code exists at https://github.com/HanJingJiang/GIPAE but the actual code has been removed.\",\n",
      "        \"matches_model/interpretability\": \"Algorithm 1: Transparent. Input features regarding diseases and drugs are transform to provide a sort of similarity measure between different drugs and different diseases. These information are then used to train Algorithm 2.\\n Algorithm 2: black box.\",\n",
      "        \"matches_evaluation/comparison\": \"Compared with other predictors of drug-disease association: DrugNet, HGBI, KBMF, MBiRW, DRRS.\",\n",
      "        \"matches_evaluation/confidence\": \"No confidence intervals or statistical significance stated.\",\n",
      "        \"matches_evaluation/measure\": \"Sensitivity, Specificity, F1-score, and accuracy.\",\n",
      "        \"matches_evaluation/method\": \"10-fold cross vaildation\",\n",
      "        \"matches_dataset/availability\": \"Yes. Made available by the authors at: https://github.com/HanJingJiang/GIPAE. No License stated.\",\n",
      "        \"matches_dataset/provenance\": \"Dataset 1: Cdataset (N_pos = 2532; N_neg = 2532); Used in previous papers.\\n\\nDataset 2: Fdataset (N_pos: 1933; N_neg = 1933); Used in previous papers.\\n\\nBoth databases contain established drug-disease interactions, that they used as positive cases. Negative cases generated randomly pairing diseases and drugs available in the databases. The number of negative cases generated is always equal to the number of positive cases. Both the dataset are integrated with information coming from other databases (PubChem, MeSH).\",\n",
      "        \"matches_dataset/redundancy\": \"Dataset 1 and 2 are independent. No redundancies stated in 10-fold cross validation.\",\n",
      "        \"matches_dataset/splits\": \"Both databases used as training and validation set using 10-fold cross-validation.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"660304301502715bfe53d658\",\n",
      "        \"uuid\": \"2783c6b5-d21f-4ac6-a776-4235d6631552\",\n",
      "        \"created\": \"2024-03-26T17:21:51.940Z\",\n",
      "        \"updated\": \"2024-03-26T17:21:51.940Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"28369334\",\n",
      "        \"publication_authors\": \"He, B., Mortuza, S. M., Wang, Y., Shen, H. B., & Zhang, Y.\",\n",
      "        \"publication_journal\": \"Bioinformatics\",\n",
      "        \"publication_title\": \"NeBcon: Protein contact map prediction using neural network training coupled with na\\u00efve Bayes classifiers\",\n",
      "        \"publication_doi\": \"10.1093/bioinformatics/btx164\",\n",
      "        \"publication_year\": \"2017\",\n",
      "        \"shortid\": \"6jexahy331\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches_evaluation/comparison\": \"Comparison has been perfomed using the test introduced in this study. No baseline approaches tested\",\n",
      "        \"matches_evaluation/measure\": \"accuracy in contact prediction at different distance ranges (short, medium and long range contacts)\",\n",
      "        \"matches_evaluation/method\": \"independent dataset\",\n",
      "        \"matches_optimization/algorithm\": \"Naive Bayes combined with neural networks. The algorithm is not new.\",\n",
      "        \"matches_optimization/config\": \"Not available\",\n",
      "        \"matches_optimization/encoding\": \"Overall 717 sequence-based features are adopted, including MSA-derived, secondary structure (predicted), solvation (predicted), sequence separation between pairs of residues.\",\n",
      "        \"matches_optimization/features\": \"517 features. no feature selection apparently performed.\",\n",
      "        \"matches_optimization/fitting\": \"number of parameters, though not precisely estimated, is much lower than number of data points. Unclear how potential underfitting has been handled.\",\n",
      "        \"matches_optimization/meta\": \"Yes, it adopts predictions obtained by other contact map prediction methods. It is not clear whether training data used for initial predictor are independent from test data of the meta predictor.\",\n",
      "        \"matches_model/availability\": \"Source code and stanalone version available at the tool website.  License is not specified\",\n",
      "        \"matches_model/duration\": \"not reported\",\n",
      "        \"matches_model/interpretability\": \"model is black box\",\n",
      "        \"matches_dataset/availability\": \"Yes, available at the tool website. No licence specified \",\n",
      "        \"matches_dataset/provenance\": \"Data for training and testing were extracted from Protein Data Bank (PDB). Npos = 20636/26798/87200 (short/medium/long range residue contacts). Nneg = NA. Dataset firstly introduced in this study.\",\n",
      "        \"matches_dataset/redundancy\": \"Redundancy between training and testing set is set to at most 25% pairswise sequence identity. \",\n",
      "        \"matches_dataset/splits\": \"Training set: 517 proteins. Test set: 98 proteins. No validation set has been used. \",\n",
      "        \"matches_publication/authors\": \"He, B., Mortuza, S. M., Wang, Y., Shen, H. B., & Zhang, Y.\",\n",
      "        \"matches_publication/title\": \"NeBcon: Protein contact map prediction using neural network training coupled with na\\u00efve Bayes classifiers\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"66735a8837ea6fa797a6c341\",\n",
      "        \"shortid\": \"otyepo566r\",\n",
      "        \"uuid\": \"297b4cc8-9937-41b5-bfb3-7469fedc1fbe\",\n",
      "        \"created\": \"2024-06-19T22:24:08.516Z\",\n",
      "        \"updated\": \"2024-06-19T22:24:08.516Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"29181236\",\n",
      "        \"publication_authors\": \"Yashik Singh\",\n",
      "        \"publication_journal\": \"Healthcare Informatics Research \",\n",
      "        \"publication_title\": \"Machine Learning to Improve the Effectiveness of ANRS in Predicting HIV Drug Resistance\",\n",
      "        \"publication_doi\": \"10.4258/hir.2017.23.4.271 \",\n",
      "        \"publication_year\": \"2017\",\n",
      "        \"score\": 0.95,\n",
      "        \"matches_evaluation/availability\": \"Not available.\",\n",
      "        \"matches_evaluation/comparison\": \"Comparison not undertaken.\",\n",
      "        \"matches_evaluation/confidence\": \"No confidence intervals reported. '88% \\u00b1 7.1% improvement' is noted but unclear if specific confidence metrics.\",\n",
      "        \"matches_evaluation/measure\": \"Some performance metrics of the model are reported. However, these are not compared to the literature or other previously published models.\\n\\n1. Accuracy percentages: provide an overall measure of how well the model performs by detailing the percentage of correct predictions.\\n\\n2. Positive Predictive Value (PPV) and Negative Predictive Value (NPV): metrics for these were reported and indicate the probability of a positive/negative prediction being correct.\\n\\n3. Statistical Significance (aZ-score): aZ-score greater than 1.98 reported. This would indicate a p-value less than 0.05 and a statistically significant result. \",\n",
      "        \"matches_evaluation/method\": \" 5-fold cross-validation performed for model evaluation.\",\n",
      "        \"matches_optimization/algorithm\": \"The algorithm used is a supervised machine learning algorithm for classification.\\n-However, the exact model type not mentioned or clear.\\n-Text refers to the model used as 'ANRS', a computer based interpretation algorithm was built by the French ANRS (Agence Nationale de Recherches sur le SIDA; National Agency for AIDS Research). ANRS classifies ARV resistance according to three levels: susceptible, intermediate, and resistant. \\u2018Susceptible\\u2019 indicates that a particular ARV drug will be effective against HIV; \\u2018intermediate\\u2019 indicates that the ARV drug is partially effective; and if the ARV is not effective at all, it is classified \\u2018resistant\\u2019.\\n-Further online searches do not clearly yield information on this model.\",\n",
      "        \"matches_optimization/config\": \"Configuration not available.\",\n",
      "        \"matches_optimization/encoding\": \"No information in text on how the genotype seqs or phenotype data was encoded for the model.\",\n",
      "        \"matches_optimization/features\": \"Unclear from text - not explicitly stated. Text suggests after feature selection the top 10 features were selected for the model.\\n\\nYes - feature selection was performed and noted in text. The text mentions using ReliefF, MODTree filtering, FCBF filtering, and CFS filtering. These feature selection methods were used to identify the most relevant features (gene mutations) from the data for the ML task of predicting HIV drug resistance.\",\n",
      "        \"matches_optimization/fitting\": \"Overfitting less likely due to 5-fold cross-validation and limited features in use. Underfitting may be possible but low info in text not clear to determine the fit likelihood. Parameter numbers unknown.\",\n",
      "        \"matches_optimization/parameters\": \"Not mentioned in text - difficult to infer/extrapolate as model type is also not specified.\",\n",
      "        \"matches_optimization/regularization\": \"5-fold cross-validation technique was in use to help prevent overfitting. No others clearly noted in text.\",\n",
      "        \"matches_model/availability\": \"None available or linked. No GitHub, code repository available.\",\n",
      "        \"matches_model/duration\": \"No information on execution time or compute requirements.\",\n",
      "        \"matches_model/interpretability\": \"Black box. Next to no required information for model interpretation available. No datasets, no code, no parameters, features, data splits. Even the exact model algorithm in use is unclear beyond the fact it is a supervised machine learning model that performs classification.\",\n",
      "        \"matches_dataset/availability\": \"Data was sourced from the Stanford HIV drug resistance database (http://hivdb.stanford.edu/).\\nHowever, the exact sequences and phenotype/genotype data used is not listed or avaialble in text/supplementary data. So the data used is not available nor the splits.\",\n",
      "        \"matches_dataset/provenance\": \"Database - Stanford HIV drug resistance database (http://hivdb.stanford.edu/).\\n\\nThe data used is de-identified genotype-phenotype datasets: 23,000 protease gene sequences and 23,000 reverse transcriptase gene sequences.\",\n",
      "        \"matches_dataset/redundancy\": \"Some information in text on the splits.\\n\\nData is split by 5-fold cross-validation, this uses four folds for training and the remaining unseen fold for testing in each iteration.\\n\\nHowever, the level of redundacy reduction (if any performed) is not clear in the text.\",\n",
      "        \"matches_dataset/splits\": \"Unclear if whole dataset points = \\n-46,000 total (23,000 protease seqs & 23,000 reverse transcriptase seqs) \\nor \\n-23,000 total (containing a mix of protease seqs and reverse transcriptase seqs.)\\nThe former is stated at first but the splits noted later in the text align with the latter.\\n\\nText notes for the data splits:\\n-Training dataset: 18,400 protease seqs and reverse transcriptase seqs\\n-Testing dataset: 4,600 protease seqs and reverse transcriptase seqs\\nUnclear the distibution of these.\\n\\nDistibutions unclear from text and not available in any figure/tables/files.\",\n",
      "        \"matches_publication/authors\": \"Yashik Singh\",\n",
      "        \"matches_publication/journal\": \"Healthcare Informatics Research \",\n",
      "        \"matches_publication/title\": \"Machine Learning to Improve the Effectiveness of ANRS in Predicting HIV Drug Resistance\",\n",
      "        \"matches_publication/doi\": \"10.4258/hir.2017.23.4.271 \"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b3f\",\n",
      "        \"publication_pmid\": \"29790392\",\n",
      "        \"publication_updated\": \"01/25/2022 16:07:48\",\n",
      "        \"publication_authors\": \"Privratsky JR, Zhang J, Lu X, Rudemiller N, Wei Q, Yu YR, Gunn MD, Crowley SD\",\n",
      "        \"publication_journal\": \"Am J Physiol Renal Physiol\",\n",
      "        \"publication_title\": \"Interleukin 1 receptor (IL-1R1) activation exacerbates toxin-induced acute kidney injury.\",\n",
      "        \"publication_doi\": \"10.1152/ajprenal.00104.2018\",\n",
      "        \"publication_year\": \"2018\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"21016d93-6e18-4e47-83ec-458e3a565ffe\",\n",
      "        \"shortid\": \"3ggc5le2qz\",\n",
      "        \"score\": 0.52,\n",
      "        \"matches_publication/updated\": \"01/25/2022 16:07:48\",\n",
      "        \"matches_publication/authors\": \"Privratsky JR, Zhang J, Lu X, Rudemiller N, Wei Q, Yu YR, Gunn MD, Crowley SD\",\n",
      "        \"matches_publication/journal\": \"Am J Physiol Renal Physiol\",\n",
      "        \"matches_publication/title\": \"Interleukin 1 receptor (IL-1R1) activation exacerbates toxin-induced acute kidney injury.\",\n",
      "        \"matches_optimization/algorithm\": \"Coarse decision trees and five-fold cross-validation.\",\n",
      "        \"matches_optimization/encoding\": \"3D segmentation on MRI exams, enhancement maps calculated. Data reduced to fixed bin number of 16 greys levels. Combat harmonisation to reduce centre effect\",\n",
      "        \"matches_optimization/features\": \"Features computed from 2D directional matrix and average over 2D directions and slices. \",\n",
      "        \"matches_optimization/parameters\": \"102 texture parameters in 6 categories\",\n",
      "        \"matches_model/output\": \"Classification (pCR or no pCR). HER2 expression levels wrt IHC and FISH\",\n",
      "        \"matches_evaluation/comparison\": \"Comparison of different configurations. Spearman correlation\",\n",
      "        \"matches_evaluation/measure\": \"Percentile, specificity, sensitivity, positive predict value, negative predict value, accuracy\",\n",
      "        \"matches_dataset/provenance\": \"311 patients chosen out of 445 available records. \",\n",
      "        \"matches_dataset/splits\": \"\\\"Split 80:20. Random splitting of the data resulted in 249 cases (150 pCR, 99 no pCR) in the training set and 62 cases (38 pCR, 24 no pCR) in the test set.\\\"\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b40\",\n",
      "        \"publication_pmid\": \"30046299\",\n",
      "        \"publication_updated\": \"01/26/2022 14:34:16\",\n",
      "        \"publication_authors\": \"Tian HY, Li SJ, Wu TQ, Yao M\",\n",
      "        \"publication_journal\": \"Comput Intell Neurosci\",\n",
      "        \"publication_title\": \"An Extreme Learning Machine Based on Artificial Immune System.\",\n",
      "        \"publication_doi\": \"10.1155/2018/3635845\",\n",
      "        \"publication_year\": \"2018\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"d6d6562d-8254-45bc-88b2-6a88827e9cf8\",\n",
      "        \"shortid\": \"mewdwg9y4z\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches_publication/updated\": \"01/26/2022 14:34:16\",\n",
      "        \"matches_publication/authors\": \"Tian HY, Li SJ, Wu TQ, Yao M\",\n",
      "        \"matches_publication/journal\": \"Comput Intell Neurosci\",\n",
      "        \"matches_publication/title\": \"An Extreme Learning Machine Based on Artificial Immune System.\",\n",
      "        \"matches_optimization/algorithm\": \"Random forest\",\n",
      "        \"matches_optimization/encoding\": \"Global features\",\n",
      "        \"matches_optimization/features\": \"Intra-stable miRnot reporteds (fourth quartile of ICCs; Q100) from the discovery cohort were used as a set of input features. Feature selection protocol identified the expression of 7 miRnot reported which maximize the performance of the method tested in cross-validation on the training set.\",\n",
      "        \"matches_optimization/fitting\": \"Number of features ~ N_pos + N_neg and Number of parameters > N_pos + N_neg\",\n",
      "        \"matches_optimization/parameters\": \"Random forest (mtry and ntree) optimized by grid search using 5-fold cross-validation with 10 randomized replicates. Predictive model built with randomForestSRC (v2.4.2) for R.\",\n",
      "        \"matches_optimization/regularization\": \"Yes. miRnot reported normalization with NanoStringNorm (v1.1.20).\",\n",
      "        \"matches_model/interpretability\": \"Black box. No information about the optimized parameters were reported.\",\n",
      "        \"matches_model/output\": \"Binary classifier (high- and low-risk groups)\",\n",
      "        \"matches_evaluation/confidence\": \"Confidence interval shows overlap between the performance on training and validation sets\",\n",
      "        \"matches_evaluation/method\": \"cross-validation on training set and validation on an independent set\",\n",
      "        \"matches_dataset/availability\": \"Raw data were deposited into the Gene Expression Omnibus (GSE86474, https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE86474).\",\n",
      "        \"matches_dataset/provenance\": \"miRnot reported samples were extracted from prostate cancer patients cohorts, and profiling obtained.  The dataset was composed of N_pos = 61, N_neg = 78. Data not used previously.    An additional 'discovery' cohort was composed of 10 patients (all negatives) .  (Positive: high-risk patients, i.e. GS (Gleason grade) > 7. low-risk patients (GS = 6).\",\n",
      "        \"matches_dataset/splits\": \"Training set: N_pos = 50, N_neg = 49.  Testing set: N_pos = 11, N_neg = 29.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b41\",\n",
      "        \"publication_pmid\": \"30295871\",\n",
      "        \"publication_updated\": \"02/08/2022 16:25:04\",\n",
      "        \"publication_authors\": \"Rappoport N, Shamir R\",\n",
      "        \"publication_journal\": \"Nucleic Acids Res\",\n",
      "        \"publication_title\": \"Multi-omic and multi-view clustering algorithms: review and cancer benchmark.\",\n",
      "        \"publication_doi\": \"10.1093/nar/gky889\",\n",
      "        \"publication_year\": \"2018\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"805d6ac8-7e63-41b2-a36b-427fbcf4b64c\",\n",
      "        \"shortid\": \"q3f9qsuitm\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches_publication/updated\": \"02/08/2022 16:25:04\",\n",
      "        \"matches_publication/authors\": \"Rappoport N, Shamir R\",\n",
      "        \"matches_publication/journal\": \"Nucleic Acids Res\",\n",
      "        \"matches_publication/title\": \"Multi-omic and multi-view clustering algorithms: review and cancer benchmark.\",\n",
      "        \"matches_optimization/algorithm\": \"SVM (RBF kernel), Logistic regression\",\n",
      "        \"matches_optimization/encoding\": \"Log-transform, auto-scaling\",\n",
      "        \"matches_optimization/features\": \"Correlation-based feature selection, LASSO, step-wise variable selection\",\n",
      "        \"matches_model/availability\": \"NA (MetaboLights accession is private)\",\n",
      "        \"matches_model/interpretability\": \"NA (missing or inaccessible model data and source code)\",\n",
      "        \"matches_evaluation/availability\": \"Supporting information, potentially in MetaboLights repository under private accession MTBLS1695\",\n",
      "        \"matches_evaluation/comparison\": \"SVM, logistic regression\",\n",
      "        \"matches_evaluation/confidence\": \"p-values, CI (95%) for AUCs\",\n",
      "        \"matches_evaluation/measure\": \"AUC, sensitivity, specificity\",\n",
      "        \"matches_evaluation/method\": \"10-fold Cross-validation\",\n",
      "        \"matches_dataset/availability\": \"MTBLS1695, study still private\",\n",
      "        \"matches_dataset/provenance\": \"20 Alzheimer's Disease patients (AD), 10 Mild cognitive impairment (MCI) and 29 control patients. Metabolomics samples measured with HNMR and DI LC-MS/MS, identification of 142 metabolites with HNMR and 51 with DI LC-MS/MS, demographic information (age and gender)\",\n",
      "        \"matches_dataset/redundancy\": \"Average of concentrations of overlapping metabolites between HNMR and DI LC-MS/MS. PCA to screen for and remove subjects outside of 95% percentile. Student\\u2019s t-test was performed to determine if there were any significantly different metabolites between AD, MCI, and age-matched controls (p < 0.05) when compared pairwise. Non-normally distributed data were analyzed using a Mann\\u2212Whitney U test and a Bonferroni correction was applied to account for multiple comparisons. To determine if sample demographics were statistically significantly different, a one-way analysis of variance analysis (ANOVA) was conducted using the IBM SPSS Statistics toolbox (v. 24.0).\",\n",
      "        \"matches_dataset/splits\": \"20, 10, 29 (see provenance) * 142 metabolites, \"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b42\",\n",
      "        \"publication_pmid\": \"29720103\",\n",
      "        \"publication_updated\": \"03/01/2022 19:41:49\",\n",
      "        \"publication_authors\": \"Simopoulos CMA, Weretilnyk EA, Golding GB\",\n",
      "        \"publication_journal\": \"BMC Genomics\",\n",
      "        \"publication_title\": \"Prediction of plant lncRNA by ensemble machine learning classifiers.\",\n",
      "        \"publication_doi\": \"10.1186/s12864-018-4665-2\",\n",
      "        \"publication_year\": \"2018\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"051b93a6-4e37-4b9c-8cc9-05f531317aea\",\n",
      "        \"shortid\": \"ixx5zlqxpf\",\n",
      "        \"score\": 0.57,\n",
      "        \"matches_publication/updated\": \"03/01/2022 19:41:49\",\n",
      "        \"matches_publication/authors\": \"Simopoulos CMA, Weretilnyk EA, Golding GB\",\n",
      "        \"matches_publication/journal\": \"BMC Genomics\",\n",
      "        \"matches_publication/title\": \"Prediction of plant lncRNA by ensemble machine learning classifiers.\",\n",
      "        \"matches_optimization/algorithm\": \"Logistic regression, SVM with linear or Gaussian kernels, and random forest were used to conduct supervised machine learning\",\n",
      "        \"matches_optimization/features\": \"Due to the high dimensionality of the image features and relatively small sample size, overfitting of the data is likely; therefore, before building classification models, we performed feature selection to avoid the overfitting problem. Feature dimensionality was reduced by the mRMR algorithm42 using R package mRMRe. mRMR has been shown to be a robust feature selection algorithm in various tasks43,44,45. The mRMR algorithm was applied to all image features with regard to the class label of sample (i.e., TFE3-RCC or ccRCC) to select an informative and non-redundant set of features.\",\n",
      "        \"matches_optimization/fitting\": \"See Features\",\n",
      "        \"matches_optimization/regularization\": \"Yes, see Features\",\n",
      "        \"matches_evaluation/measure\": \"AUC and confidence intervals were computed with the R package pROC.\",\n",
      "        \"matches_evaluation/method\": \"In dataset 1, five-fold cross-validation was used. To further validate our method using an external validation set, classification models were trained using dataset 1 and evaluated using dataset 2\",\n",
      "        \"matches_dataset/availability\": \"yes, processed, not raw\",\n",
      "        \"matches_dataset/provenance\": \"The quantitative image features extracted from H&E stained whole-slide images are available from GitHub. No access to raw data provided\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b43\",\n",
      "        \"publication_pmid\": \"29849042\",\n",
      "        \"publication_updated\": \"03/04/2022 12:54:32\",\n",
      "        \"publication_authors\": \"Han X, Chen S, Flynn E, Wu S, Wintner D, Shen Y\",\n",
      "        \"publication_journal\": \"Nat Commun\",\n",
      "        \"publication_title\": \"Distinct epigenomic patterns are associated with haploinsufficiency and predict risk genes of developmental disorders.\",\n",
      "        \"publication_doi\": \"10.1038/s41467-018-04552-7\",\n",
      "        \"publication_year\": \"2018\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"c61651cd-193f-4b5e-aa19-77eed7eb2649\",\n",
      "        \"shortid\": \"217brrych3\",\n",
      "        \"score\": 0.86,\n",
      "        \"matches_publication/updated\": \"03/04/2022 12:54:32\",\n",
      "        \"matches_publication/authors\": \"Han X, Chen S, Flynn E, Wu S, Wintner D, Shen Y\",\n",
      "        \"matches_publication/journal\": \"Nat Commun\",\n",
      "        \"matches_publication/title\": \"Distinct epigenomic patterns are associated with haploinsufficiency and predict risk genes of developmental disorders.\",\n",
      "        \"matches_optimization/algorithm\": \"deep learning, novel approach\",\n",
      "        \"matches_optimization/config\": \"implemented with PyTorch [38] using an Nvidia TITAN Xp GPU.\",\n",
      "        \"matches_optimization/encoding\": \"datasets, all images are first resized to 224 \\u00d7 224 in axial plane,\",\n",
      "        \"matches_optimization/parameters\": \"Batch Normalization\\n\\n\\n\",\n",
      "        \"matches_model/interpretability\": \"color maps using Grad-CAM\",\n",
      "        \"matches_evaluation/comparison\": \"firstly comparision to COVID-Net method https://doi.org/10.1038/s41598-020-76550-z (Scientific Reports) by ROC AUC\\n further comparisions by p-value:\\n  - Series-Adapter https://scholar.google.com/scholar?as_q=Learning+multiple+visual+domains+with+residual+adapters&as_occt=title&hl=en&as_sdt=0%2C31 \\n  - Parallel-Adapter https://ieeexplore.ieee.org/document/8578945\\n  - MS-Net https://doi.org/10.1038/s41598-020-76550-z\",\n",
      "        \"matches_evaluation/confidence\": \"outperforming the original\\n COVID-Net trained on each dataset by 12.16% and 14.23%\\n in AUC respectively,\",\n",
      "        \"matches_evaluation/measure\": \"Accuracy, F1 score, Sensitivity, Precision, AUC\",\n",
      "        \"matches_evaluation/method\": \"four-fold cross-validation\",\n",
      "        \"matches_dataset/availability\": \"preprocessed data: https://drive.google.com/file/d/1JBp9RH9-yBEdtkNYDi6wWL79o62JD5Td/view   \\n\\n\",\n",
      "        \"matches_dataset/provenance\": \"two public COVID-19 CT datasets: \\n -   https://www.medrxiv.org/content/10.1101/2020.04.24.20078584v3\\n2482 CT images from 120 patients,  N_pos 1252, N_neg 1230\\n\\n -   http://arxiv.org/abs/2003.13865\\nN_pos 349 CT images from 216 patients, \\nN_neg 397 CT images from 171 patients\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b44\",\n",
      "        \"publication_pmid\": \"30388153\",\n",
      "        \"publication_updated\": \"03/06/2022 19:15:35\",\n",
      "        \"publication_authors\": \"Caglar MU, Hockenberry AJ, Wilke CO\",\n",
      "        \"publication_journal\": \"PLoS One\",\n",
      "        \"publication_title\": \"Predicting bacterial growth conditions from mRNA and protein abundances.\",\n",
      "        \"publication_doi\": \"10.1371/journal.pone.0206634\",\n",
      "        \"publication_year\": \"2018\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"706c0f3d-b856-473d-9864-c48e3733bceb\",\n",
      "        \"shortid\": \"vecnt31t10\",\n",
      "        \"score\": 0.52,\n",
      "        \"matches_publication/updated\": \"03/06/2022 19:15:35\",\n",
      "        \"matches_publication/authors\": \"Caglar MU, Hockenberry AJ, Wilke CO\",\n",
      "        \"matches_publication/journal\": \"PLoS One\",\n",
      "        \"matches_publication/title\": \"Predicting bacterial growth conditions from mRNA and protein abundances.\",\n",
      "        \"matches_optimization/algorithm\": \"Coarse decision trees\",\n",
      "        \"matches_optimization/encoding\": \"Following ROC and correlation analysis, Breast MRIs were assessed according to the American College of Radiology (ACR) Breast Imaging Reporting and Data System (BI-RADS) lexicon.\\n\\nManual, expert review on the MRI exams and performed 3D segmentations of the whole tumour in the first post-contrast non-subtracted sequence using ITK-Snot reportedP software.\\n\\nSusceptibility artefacts related to post-biopsy changes, when\\npresent, were excluded from segmentation and only the largest\\nlesion was segmented in multifocal tumours. \\n\\nEnhancement maps were calculated as the percentage increase in signal from the pre-contrast image to the first post-contrast image. Radiomics and statistical analysis were performed using MATLAB and publicly available CERR (Computational Environment for Radiological Research) software.\\n\\nFurthermore, data was reduced to a fixed bin number of 16 grey levels and only an interpixel distance of one was considered. CERR analysis resulted in 102 texture parameters sub-divided into six categories - 22 first order statistics, 26 statistics based on grey level cooccurrence matrices, 16 statistics based on run length matrices, 16 statistics based on size zone matrices, 17 statistics based on neighborhood grey level dependence matrices, and finally five statistics based on neighborhood grey tone difference matrices.\\n\\nFeatures were computed for each 2D directional matrix and averaged over 2D directions and slices, since data was not isotropic. As patients were scanned at different sites, Combat harmonisation was performed to remove the centre effect (local vs. foreign scans) while retaining the pathophysiologic information (either HER2 expression or pathologic response). The harmonisation employed Bayes estimates to account for both additive and multiplicative scanner effects.\\n\\nUnivariate analysis was performed to identify significant parameters. Continuous variables were described as mean, standard deviation (SD), and range. The two-tailed Mann-Whitney U test for two independent samples was used to determine significant differences between groups. Correlation analysis was then employed to remove redundant parameters from advancement to model development. If a highly positive (> 0.9) or highly negative (< -0.9) correlation was noted, the parameter with the lowest area under the receiver operating curve (AUROC) was removed.\\n\",\n",
      "        \"matches_optimization/features\": \"1)\\tThe final model to predict HER2 intratumour expression levels (IHC vs. FISH) utilized three MRI features. Lesion type and multifocality (clinical features) and large zone emphasis (radiomic feature).\\n2)\\tThe model to predict pCR status included six MRI parameters. Lesion type and size (clinical parameters) and variance, first order entropy, 90th percentile and zone length variance (radiomic parameters).\\n\",\n",
      "        \"matches_optimization/parameters\": \"Coarse decision tree modelling was implemented in MATLAB, with the maximum number of splits set at four and utilizing Gini\\u2019s diversity index as the splitting criterion.\",\n",
      "        \"matches_model/interpretability\": \"Transparent. Assessing the presence of statistically significant differences, using Mann-Whitney U-test and Chi-squared test, across clinical and MRI features of 1) IHC vs FISH and 2) pCR vs non-pCR groups, before including them to the final model.\",\n",
      "        \"matches_model/output\": \"1) Binary predictions of IHC (positive) or FISH (negative) samples.\\n 2) Binary predictions of pCR (positive) or non-pCR (negative) samples.\",\n",
      "        \"matches_evaluation/measure\": \"Sensitivity, specificity, diagnostic accuracy\",\n",
      "        \"matches_evaluation/method\": \"5-fold cross validation\",\n",
      "        \"matches_dataset/provenance\": \"Breast magnetic resonance imaging (MRI) and clinical data from 311 HER2 overexpressing breast cancer patients. \\n1)        Patients were classified into two groups based on HER2 expression level. Npos=279 patients with tumours that showed HER2 protein overexpression on immunohistochemistry (IHC 3+; IHC group). Nneg=32 patients with tumours that showed HER2 gene amplification detected by FISH in the absence of protein overexpression on IHC (IHC 2+ or 1+ to 2+; FISH group).\\n2)        Npos=188 patients with pathologic complete response (pCR), which was defined as no residual invasive carcinoma in the breast or axillary lymph nodes (ypT0/isN0) at surgical resection. Nneg=123 patients that are non-pCR.\\n\",\n",
      "        \"matches_dataset/redundancy\": \"Inclusion criteria for this study were HER2 overexpressing breast cancer patients who underwent not reportedC and pretreatment state-of-the-art contrast-enhanced breast MRI. 70 were excluded because they did not have pretreatment breast MRI and 64 patients with outside images were excluded because of poor image quality.\",\n",
      "        \"matches_dataset/splits\": \"For the prediction of pathological complete response, the data was split into training and test sets at a ratio of 4:1 (80% training and 20% test), with feature selection performed purely on the training set. Npos,train=150 patients with pCR. Npos,test=38 patients with pCR. Nneg,train=99 patients with non-pCR. Nneg,test=24 patients with non-pCR. \\nDue to the low number of cases in the minority class, this was not feasible for the comparison between the IHC and FISH groups.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b45\",\n",
      "        \"publication_pmid\": \"30388122\",\n",
      "        \"publication_updated\": \"03/08/2022 14:37:33\",\n",
      "        \"publication_authors\": \"Babalyan K, Sultanov R, Generozov E, Sharova E, Kostryukova E, Larin A, Kanygina A, Govorun V, Arapidi G\",\n",
      "        \"publication_journal\": \"PLoS One\",\n",
      "        \"publication_title\": \"LogLoss-BERAF: An ensemble-based machine learning model for constructing highly accurate diagnostic sets of methylation sites accounting for heterogeneity in prostate cancer.\",\n",
      "        \"publication_doi\": \"10.1371/journal.pone.0204371\",\n",
      "        \"publication_year\": \"2018\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"f792fa0e-c332-4321-9ab0-a504c495e7c3\",\n",
      "        \"shortid\": \"qxfdrs4tuj\",\n",
      "        \"score\": 0.57,\n",
      "        \"matches_publication/updated\": \"03/08/2022 14:37:33\",\n",
      "        \"matches_publication/authors\": \"Babalyan K, Sultanov R, Generozov E, Sharova E, Kostryukova E, Larin A, Kanygina A, Govorun V, Arapidi G\",\n",
      "        \"matches_publication/journal\": \"PLoS One\",\n",
      "        \"matches_publication/title\": \"LogLoss-BERAF: An ensemble-based machine learning model for constructing highly accurate diagnostic sets of methylation sites accounting for heterogeneity in prostate cancer.\",\n",
      "        \"matches_optimization/algorithm\": \"Na\\u00efve Bayes, logistic regression, random forest, and artificial neural network models\",\n",
      "        \"matches_optimization/features\": \"performed feature selection using the caret R package. from 89 initial features, redundant features were removed, attributes with an absolute correlation coefficient of 0.5 or greater were also removed. Last, specific features were selected using the recursive feature elimination (RFE) method. 20 features were finally selected. \",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/confidence\": \"ML algorithms metrics\",\n",
      "        \"matches_evaluation/measure\": \"precision, recall, accuracy\",\n",
      "        \"matches_dataset/availability\": \"yes in Supporting information section\",\n",
      "        \"matches_dataset/provenance\": \"made their own dataset\",\n",
      "        \"matches_dataset/splits\": \"Among 222 patients, 126 developed postinduction hypotension\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b46\",\n",
      "        \"publication_pmid\": \"29720103\",\n",
      "        \"publication_updated\": \"03/22/2022 13:13:16\",\n",
      "        \"publication_authors\": \"Simopoulos CMA, Weretilnyk EA, Golding GB\",\n",
      "        \"publication_journal\": \"BMC Genomics\",\n",
      "        \"publication_title\": \"Prediction of plant lncRNA by ensemble machine learning classifiers.\",\n",
      "        \"publication_doi\": \"10.1186/s12864-018-4665-2\",\n",
      "        \"publication_year\": \"2018\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"2ab96eb2-c809-4f94-9729-9573ca70ad20\",\n",
      "        \"shortid\": \"od7rdaz7w7\",\n",
      "        \"score\": 0.86,\n",
      "        \"matches_publication/updated\": \"03/22/2022 13:13:16\",\n",
      "        \"matches_publication/authors\": \"Simopoulos CMA, Weretilnyk EA, Golding GB\",\n",
      "        \"matches_publication/journal\": \"BMC Genomics\",\n",
      "        \"matches_publication/title\": \"Prediction of plant lncRNA by ensemble machine learning classifiers.\",\n",
      "        \"matches_optimization/algorithm\": \"Random Forest, Support Vector Machine (SVM), Adaptative Boosting with a Decision Tree base estimator (AdaBoost Tree), and k-Nearest Neighbors. AdaBoost Tree was selected\",\n",
      "        \"matches_optimization/encoding\": \"Every compound in the datasets were collected as SMILES strings and sanitized with RDKit. The resulting datasets consisted of 635 descriptors for the Dragon dataset, and 506 features for the \\u201copen-source\\u201d dataset. \",\n",
      "        \"matches_optimization/features\": \"Five-fold cross validation was performed with hyperparameter tuning using a grid search.  The optimal percentile of features was tuned as a parameter of the Grid Search.\\n32 descriptors for the \\u201cDragon\\u201d model, and 51descriptors for the \\u201copen source\\u201d model\",\n",
      "        \"matches_optimization/fitting\": \"To avoid any model bias due to overfitting, the number of features used by the model is a hyperparameter that has been optimized.\",\n",
      "        \"matches_optimization/regularization\": \"Structures were standardized using the \\u201cstandardizer\\u201d from Python.\",\n",
      "        \"matches_model/interpretability\": \"direct correlation between compound and sweetness\",\n",
      "        \"matches_model/output\": \"regression to predict the logSw (relative sweetness)\",\n",
      "        \"matches_evaluation/comparison\": \"e-Sweet platform (Zheng et al., 2019) is based on a consensus model of various\\n machine learning protocols. The performance of BitterSweet is comparable to\\n e-Sweet and Predisweet (R2 of 0.72 on our test set) but the protocol is still unpublished, and seven molecules of the test set has not been\\n considered as sweet.\",\n",
      "        \"matches_evaluation/confidence\": \"statistical metrics\",\n",
      "        \"matches_evaluation/measure\": \"predictive performance was evaluated based on criteria previously defined by: https://doi.org/10.1016/S1093-3263(01)00123-1.\\n correlation coefficient, coefficient of determination, slopes of the regression lines through the origin for the observed vs. predicted and predicted vs. observed values respectively, corresponding coefficients of determination, root mean squared error, mean absolute error\",\n",
      "        \"matches_evaluation/method\": \"independent dataset\",\n",
      "        \"matches_dataset/provenance\": \"316 sweet compounds from SweetenersDB dataset.\\nhttps://doi.org/10.1016/j.foodchem.2016.10.145\",\n",
      "        \"matches_dataset/redundancy\": \"The updated SweetenersDB was split in training and test sets using a Sphere Exclusion clustering algorithm. \",\n",
      "        \"matches_dataset/splits\": \"64 diverse compounds (20.3%) were selected for the test set, leaving 252 compounds in the training set\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b47\",\n",
      "        \"publication_pmid\": \"30008861\",\n",
      "        \"publication_updated\": \"03/28/2022 23:21:09\",\n",
      "        \"publication_authors\": \"Zhang TM, Huang T, Wang RF\",\n",
      "        \"publication_journal\": \"Oncol Lett\",\n",
      "        \"publication_title\": \"Cross talk of chromosome instability, CpG island methylator phenotype and mismatch repair in colorectal cancer.\",\n",
      "        \"publication_doi\": \"10.3892/ol.2018.8860\",\n",
      "        \"publication_year\": \"2018\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"39fb8263-4ce3-4283-87ed-5ceba5717b62\",\n",
      "        \"shortid\": \"9m31lscgpm\",\n",
      "        \"score\": 0.86,\n",
      "        \"matches_publication/updated\": \"03/28/2022 23:21:09\",\n",
      "        \"matches_publication/authors\": \"Zhang TM, Huang T, Wang RF\",\n",
      "        \"matches_publication/journal\": \"Oncol Lett\",\n",
      "        \"matches_publication/title\": \"Cross talk of chromosome instability, CpG island methylator phenotype and mismatch repair in colorectal cancer.\",\n",
      "        \"matches_optimization/algorithm\": \"A series of classification methods, all from scimitar learn ; including SVM (best performance), RF and NB. \",\n",
      "        \"matches_optimization/encoding\": \"The paper proposed sequence image normalisation for encoding.  yet very poorly explained and thus difficult to understand\",\n",
      "        \"matches_optimization/features\": \"RGB matrices encoding sequences, yet unclear how this works exactly.\",\n",
      "        \"matches_optimization/fitting\": \"many more features, if one considers that every RGB value as a feature.  \",\n",
      "        \"matches_optimization/meta\": \"not features coming from other predictors, all raw data \",\n",
      "        \"matches_optimization/parameters\": \"ML parameters are optmized, e.g.  regularization parameter c for SVM and number of trees for RF.  Not all parameters are systematically mentioned \",\n",
      "        \"matches_optimization/regularization\": \"Cross-validation approaches\",\n",
      "        \"matches_model/availability\": \"yes via GitHub\",\n",
      "        \"matches_model/interpretability\": \"no obvious interpretation\",\n",
      "        \"matches_model/output\": \"binary classification\",\n",
      "        \"matches_evaluation/availability\": \"might be part of the githuv rep\",\n",
      "        \"matches_evaluation/comparison\": \"method in ref [32], which has significantly worse performance.\",\n",
      "        \"matches_evaluation/measure\": \"Accuracy, AUC, presicion and recall\",\n",
      "        \"matches_dataset/availability\": \"from other papers, and requests can be made to the senior author. Data also available via GitHub link\",\n",
      "        \"matches_dataset/provenance\": \"Comes from two of other publications [13] and [8]. Note that the purpose of this article is to show a new data representation for classification. First data set consist of 365 NGS samples, 108 are recently infected hosts and 257 are chronically infected hosts. The second set consists of 335 infected persons, 142 correspond to outbreaks with more than one person and 193 are isolated cases. the latter is used for clustering, so not further considered here\",\n",
      "        \"matches_dataset/redundancy\": \"No stratification explicitly discussed, yet leave-one-outbreak out aims to resolve overlaps between the folds used for training and testing.\",\n",
      "        \"matches_dataset/splits\": \"no separate validation set. Cross-validation is used, both classic 10-fold and \\\"leave-one-outbreak-out\\\", also under sampling of the larger set (chronically affected) is tested.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b48\",\n",
      "        \"publication_pmid\": \"30483279\",\n",
      "        \"publication_updated\": \"03/28/2022 23:57:02\",\n",
      "        \"publication_authors\": \"Zimmer D, Schneider K, Sommer F, Schroda M, M\\u00fchlhaus T\",\n",
      "        \"publication_journal\": \"Front Plant Sci\",\n",
      "        \"publication_title\": \"Artificial Intelligence Understands Peptide Observability and Assists With Absolute Protein Quantification.\",\n",
      "        \"publication_doi\": \"10.3389/fpls.2018.01559\",\n",
      "        \"publication_year\": \"2018\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"81c5e03c-ebb1-44ac-b252-0b787354659d\",\n",
      "        \"shortid\": \"v1vwcbzzui\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"03/28/2022 23:57:02\",\n",
      "        \"matches_publication/authors\": \"Zimmer D, Schneider K, Sommer F, Schroda M, M\\u00fchlhaus T\",\n",
      "        \"matches_publication/journal\": \"Front Plant Sci\",\n",
      "        \"matches_publication/title\": \"Artificial Intelligence Understands Peptide Observability and Assists With Absolute Protein Quantification.\",\n",
      "        \"matches_optimization/algorithm\": \"Yes: SVM (compared to KNN, adaboost, random forest, decision tree, logistic regression and XGBoost)\",\n",
      "        \"matches_optimization/encoding\": \"Yes: sequence features (KNF/NC, KSNPF, PSNP, KSPSDP, PseDNC, CPD)\",\n",
      "        \"matches_optimization/features\": \"Yes: 6 f. Wrapper method (sequence forward selection). ten-fold cross-validation on training dataset.\",\n",
      "        \"matches_optimization/parameters\": \"Yes: box constraint and kernel scale, optimised by a grid search\",\n",
      "        \"matches_optimization/regularization\": \"Yes:  box constraint parameter\",\n",
      "        \"matches_model/availability\": \"No. Link to project (https://zhulab.ahu.edu.cn/m5CPred-SVM/) is broken\",\n",
      "        \"matches_model/interpretability\": \"~Yes: Results for different feature selections\",\n",
      "        \"matches_evaluation/comparison\": \"Yes: RNAm5Cfinder, iRNA-m5C, iRNAm5C-PseDNC, RNAm5CPred, PEA-m5C\",\n",
      "        \"matches_evaluation/confidence\": \"No. Justification based only on evaluation values difference (acc, sn, sp, pre, mcc, f1, AUROC)\",\n",
      "        \"matches_evaluation/measure\": \"accuracy, sensitivity, specificity, precision, Matthews correlation coefficient and F1-score, AUROC\",\n",
      "        \"matches_evaluation/method\": \"independent datasets\",\n",
      "        \"matches_dataset/availability\": \"Yes: Supp data of referenced publication,  and GEO query\",\n",
      "        \"matches_dataset/provenance\": \"Yes: used by previous papers. N_pos and N_neg are given.\",\n",
      "        \"matches_dataset/redundancy\": \"Yes: random selection with redundancy removal in pos and neg sets (>70% sequence identity CD-HIT)\",\n",
      "        \"matches_dataset/splits\": \"Yes: Size of N_pos and N_neg for training and test sets.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b75\",\n",
      "        \"publication_pmid\": \"29133589\",\n",
      "        \"publication_updated\": \"03/28/2022 00:12:23\",\n",
      "        \"publication_authors\": \"Ding MQ, Chen L, Cooper GF, Young JD, Lu X\",\n",
      "        \"publication_journal\": \"Mol Cancer Res\",\n",
      "        \"publication_title\": \"Precision Oncology beyond Targeted Therapy: Combining Omics Data with Machine Learning Matches the Majority of Cancer Cells to Effective Therapeutics.\",\n",
      "        \"publication_doi\": \"10.1158/1541-7786.MCR-17-0378\",\n",
      "        \"publication_year\": \"2018\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"54b0bca4-f5c2-48bb-81d3-2aa6f88cbafc\",\n",
      "        \"shortid\": \"c80vqcn356\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"03/28/2022 00:12:23\",\n",
      "        \"matches_publication/authors\": \"Ding MQ, Chen L, Cooper GF, Young JD, Lu X\",\n",
      "        \"matches_publication/journal\": \"Mol Cancer Res\",\n",
      "        \"matches_publication/title\": \"Precision Oncology beyond Targeted Therapy: Combining Omics Data with Machine Learning Matches the Majority of Cancer Cells to Effective Therapeutics.\",\n",
      "        \"matches_optimization/algorithm\": \"Least absolute shrinkage and selection operator (LASSO).\",\n",
      "        \"matches_optimization/config\": \"The code and the parameters used are available at: https://github.com/sailalithabollepalli/EpiSmokEr. No license specified.\",\n",
      "        \"matches_optimization/encoding\": \"Training dataset are quantile-normalized before training.\",\n",
      "        \"matches_optimization/features\": \"Number of f = 122.\",\n",
      "        \"matches_optimization/parameters\": \"Number of p not reported, but could be inferred from the context.\",\n",
      "        \"matches_optimization/regularization\": \"Introduction of a parameter \\\"lambda\\\" in the penalized log likelihood procedure for selecting the \\\"trainable\\\" parameter. Selection of the \\\"lambda\\\" parameter through cross-validation.\",\n",
      "        \"matches_model/availability\": \"Code is available at: https://github.com/sailalithabollepalli/EpiSmokEr. No License provided.\",\n",
      "        \"matches_model/interpretability\": \"Black box.\",\n",
      "        \"matches_model/output\": \"Regression (probability scores of being Smoker, Former Smoker or Never Smoker)\",\n",
      "        \"matches_evaluation/comparison\": \"Comparison with non-ML methods provided. An extensive comparison was not performed due to differences in the methods.\",\n",
      "        \"matches_evaluation/measure\": \"Sensitivity and Specificity\",\n",
      "        \"matches_evaluation/method\": \"Using independent dataset.\",\n",
      "        \"matches_dataset/availability\": \"Dataset 1: yes. Dataset ID: EGAD00001000200; URL: https://ega-archive.org/datasets/EGAD00001000200; license: stated with specific Data Use Ontology (DUO) codes: DUO:0000005, DUO:0000026, DUO:0000027, DUO:0000029, DUO:0000019, DUO:0000028.\\n\\nDataset 2: no (available upon request at: https://thl.fi/en/web/thl-biobank/for-researchers/sample-collections/twin-study)\\n\\nDataset 3: yes. Dataset id: GSE42861; URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=gse42861; license: not reported\\n\\nDataset 4: yes. Dataset id: GSE50660; URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE50660; license: not reported\",\n",
      "        \"matches_dataset/provenance\": \"For each dataset 3 categories are considered: Smokers (S), Former Smokers (FS), and Never Smokers (NS). For each dataset N_S, N_FS, and N_NS will be used for the number of Smokers, Former Smokers, and Never Smokers respectively. For each dataset only data related to Dnot reported methilation.\\n\\nDataset 1: data from 474 individuals from the Dietary, Lifestyle and Genetic determinants of Obesity and Metabolic syndrome (DILGOM). N_S = 113, N_FS = 118, N_NS = 243. Used in other papers.\\n\\nDstaset 2: data from 408 individuals from the Finnish Twin Cohort (FTC). N_S = 67; N_FS = 141; N_NS = 200. Used in other papers.\\n\\nDataset 3: data from 687 individuals from the GSE42861 in Gene Expression Omnibus (GEO). N_S = 266; N_FS = 228; N_NS = 193. Used in other papers.\\n\\nDataset 4: data from 464 individuals from the GSE50660 in Gene Expression Omnibus (GEO). N_S = 22; N_FS = 263, N_NS = 179.\",\n",
      "        \"matches_dataset/redundancy\": \"Dataset 1, 2, 3 and 4 are independent from each other.\",\n",
      "        \"matches_dataset/splits\": \"Dataset 1: Used as training test. Used for cross-validation randomly subdividing data in 90% training and 10% test data. Distribution of S, FS, and NS after random subdivisions is not reported\\n\\nDataset 2: used as independent set to verify generalization capability of the classifier. Distribution of S, FS, and NS stated above.\\n\\nDataset 3: used as independent set to verify generalization capability of the classifier. Distribution of S, FS, and NS stated above.\\n\\nDataset 4: used as independent set to verify generalization capability of the classifier. Distribution of S, FS, and NS stated above.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"65e843f41502715bfe53cd1e\",\n",
      "        \"uuid\": \"9bd31f10-4479-4940-810c-3e6a4bcfb1e3\",\n",
      "        \"created\": \"2024-03-06T10:22:44.950Z\",\n",
      "        \"updated\": \"2024-03-06T10:35:57.616Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_title\": \"P2Rank: machine learning based tool for rapid and accurate prediction of ligand binding sites from protein structure\",\n",
      "        \"publication_authors\": \"Radoslav Kriv\\u00e1k, David Hoksza\",\n",
      "        \"publication_journal\": \"Journal of cheminformatics\",\n",
      "        \"publication_year\": \"2018\",\n",
      "        \"publication_pmid\": \"30109435\",\n",
      "        \"publication_doi\": \"10.1186/s13321-018-0285-8\",\n",
      "        \"publication_done\": 6,\n",
      "        \"publication_skip\": 0,\n",
      "        \"shortid\": \"iblymem5cf\",\n",
      "        \"score\": 0.96,\n",
      "        \"matches_evaluation/method\": \"The model was evaluated on two independent datasets. Disjunct with data points present in training and validation set.\",\n",
      "        \"matches_evaluation/measure\": \"Instead of the conventional performance metrics, 3 reported metrics are as follows:\\n1. Identification success rate [%] measured by DCCcriterion (distance from pocket center to closest ligand atom) with 4 \\u00c5 threshold.\\n2. Average total number of binding sites predicted per protein by on a given dataset.\\n3. Average time required for prediction on a single protein.\",\n",
      "        \"matches_evaluation/comparison\": \"The method was compared to other publicly available methods in the 3 mentioned metrics.\",\n",
      "        \"matches_evaluation/confidence\": \"The confidence intervals are only reported for \\\"Average prediction time per protein\\\".\\nWhile the method is reported to perform best in the first 2 mentioned metrics, which is not the case in terms of prediction time, the difference is not substantial.\",\n",
      "        \"matches_optimization/algorithm\": \"The used algorithm is a Random Forest Regression model.\\nThe model is not novel.\",\n",
      "        \"matches_optimization/meta\": \"The algorithm is not a meta-predictor.\",\n",
      "        \"matches_optimization/config\": \"The model is accessible through the URL of the GitHub repository.\",\n",
      "        \"matches_optimization/encoding\": \"The model takes vectors of 35 numerical features as input.\",\n",
      "        \"matches_optimization/features\": \"Every vector is composed of 35 numerical features.\\nNo mention on feature selection.\",\n",
      "        \"matches_optimization/fitting\": \"The clear number of parameters is not mentioned.\\nNo assessment on over/under fitting was mentioned.\",\n",
      "        \"matches_optimization/parameters\": \"Beside the hyper-parameters of Random Forest, the algorithm uses other parameters and \\\"cut-of's\\\", \\\"thresholds\\\", \\\"protrusion radius\\\", are explicitly mentioned.\\nIt is mentioned that only hyper-parameters are optimized on a separate dataset from training set.\\nThe method of optimization is not mentioned.\",\n",
      "        \"matches_optimization/regularization\": \"A validation set was used to optimize the parameters before training on the training set.\",\n",
      "        \"matches_model/interpretability\": \"The model has 200 trees, each grown with no depth limit using 6 features, this makes it challenging to interpret due to the sheer number of trees and their depth.\\nHowever, it is still possible to obtain feature importance scores.\",\n",
      "        \"matches_model/output\": \"It is a regression model outputting numbers between 0 and 1.\",\n",
      "        \"matches_model/duration\": \"It is mentioned that it requires under 1 s for prediction on one protein.\",\n",
      "        \"matches_model/availability\": \"The software and the source code is publicly available through the provided link to the GitHub repository of the software.\\nIt is a stand-alone executable software, they currently have a web server, but at the time of publication the web server was under development.\\nURL: https://github.com/rdk/p2rank\\nLicence: MIT \",\n",
      "        \"matches_dataset/provenance\": \"Training: CHEN11\\u2014a dataset of 251 proteins harboring 476 ligands introduced in LBS prediction benchmarking study.\\n\\nOptimization and validation: JOINED\\u2014consists of structures from several smaller datasets used in previous studies (B48/U48, B210, DT198, ASTEX) joined into one larger dataset. you can find the details below:\\nB48/U48\\u2014Datasets that contain a set of 48 proteins in a bound and unbound state.\\nB210\\u2014a benchmarking dataset of 210 proteins in bound state.\\nDT198\\u2014a dataset of 198 drug-target complexes.\\nASTEX\\u2014Astex Diverse set is a collection of 85 proteins that was introduced as a benchmarking dataset for molecular docking methods.\",\n",
      "        \"matches_dataset/splits\": \"2 data splits were utilized:\\nTraining: CHEN11 dataset composed of 251 data points.\\nOptimization and validation: JOINED dataset composed of an overall  541 data points.\\nAll the data points are positive examples of protein-ligand complexes.\",\n",
      "        \"matches_dataset/redundancy\": \"Datasets for training and validation purposes are selected arbitrarily.\\nTesting dataset is not mentioned.\\nOnly training set is mentioned to be non-redundant without explicit mention on the cutout identity percentage.\",\n",
      "        \"matches_dataset/availability\": \"All the mentioned datasets are selected from previous studies and are publicly available.\\nDatasets are both mentioned through referencing to other studies and accessible through the URL: https://github.com/rdk/p2rank-datasets\",\n",
      "        \"matches_publication/title\": \"P2Rank: machine learning based tool for rapid and accurate prediction of ligand binding sites from protein structure\",\n",
      "        \"matches_publication/authors\": \"Radoslav Kriv\\u00e1k, David Hoksza\",\n",
      "        \"matches_publication/journal\": \"Journal of cheminformatics\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6634f285ded6e7820f74a19a\",\n",
      "        \"shortid\": \"rejm27trh8\",\n",
      "        \"uuid\": \"a2eb5814-8cb1-4c0d-a2aa-96fda79bcc2d\",\n",
      "        \"created\": \"2024-05-03T14:19:49.660Z\",\n",
      "        \"updated\": \"2024-05-03T14:19:49.660Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"29679026\",\n",
      "        \"publication_authors\": \"Jingxue Wang, Huali Cao, John Z. H. Zhang & Yifei Qi \",\n",
      "        \"publication_journal\": \"Scientific Reports\",\n",
      "        \"publication_title\": \"Computational Protein Design with Deep Learning Neural Networks\",\n",
      "        \"publication_doi\": \"10.1038/s41598-018-24760-x\",\n",
      "        \"publication_year\": \"2018\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches_evaluation/comparison\": \"The model was compared to a similar method called SPIN.\",\n",
      "        \"matches_evaluation/confidence\": \"Standard deviation was reported. The results are not significantly better than the only method that was compared to (SPIN) with 3% improvement.\",\n",
      "        \"matches_evaluation/measure\": \"The authors used the accuracy of top-k predictions from the model as the evaluation metric.\\nTop-K accuracy: if the native amino acid is within the top-K predictions (K amino acids that have the highest probabilities), the prediction is considered correct.\",\n",
      "        \"matches_evaluation/method\": \"1. The model was solely evaluated on 3 proteins that are as follows:\\nAn all-\\u03b1 protein (PDB ID 2B8I60), an all-\\u03b2 protein (PDB ID 1HOE61), and a mixed \\u03b1\\u03b2 protein (PDB ID 2IGD).\\n2. The model was evaluated and compared to another method on a data set of 50 proteins.\",\n",
      "        \"matches_optimization/algorithm\": \"The algorithm used is a classic neural network. \",\n",
      "        \"matches_optimization/encoding\": \"Data was encoded by extracting features from protein residues and their N closest neighboring residues.\",\n",
      "        \"matches_optimization/features\": \"The following input features were reported:\\n1. Cos and sin values of backbone dihedrals\\n2. Total solvent accessible surface area (SASA) of backbone atoms\\n3. Three-type secondary structure\\n4. C\\u03b1-C\\u03b1 distance to the central residue.\\n5. Unit vectors from the central residue to the neighbor residues\\n6. Number of backbone-backbone hydrogen bonds.\",\n",
      "        \"matches_optimization/meta\": \"It is not a meta-predictor.\",\n",
      "        \"matches_optimization/parameters\": \"The following parameters were reported:\\n1. Activation function: ReLU for all layers.\\n2. Loss function: Categorical cross entropy.\\n3. Optimization: SGD with Nesterov momentum (0.9) and learning rate of 0.01.\\n4. Batch size: 40,000.\\n5. Sample weighting: Adjusted based on residue type abundance\\n6. Epochs: 1000\",\n",
      "        \"matches_model/interpretability\": \"No mention on interpretability was made. The model appears to be a black box.\",\n",
      "        \"matches_model/output\": \"Ultimately, it is a classifier method that outputs the potential residue types at a target position based on the probability of 20 amino acids for that specific position.\",\n",
      "        \"matches_dataset/availability\": \"Available from the corresponding author on \\\"reasonable request\\\".\",\n",
      "        \"matches_dataset/provenance\": \"The authors used structures in PDB as the main data source.\\nThey clustered the structures based on different sequence identity thresholds. The resulted structure dataset consists of:\\n10173 (30% sequence identity), 14064 (50% sequence identity), and 17607 structures (90% sequence identity).\",\n",
      "        \"matches_dataset/redundancy\": \"The authors trained their model on 3 redundancy-reduced datasets with 3 different sequence identity thresholds (30%, 50%, and 90%).\",\n",
      "        \"matches_dataset/splits\": \"For training the model, the authors used a random split 5-fold cross-validation.\\nThe proportion of training and test data points used in cross-validation was not reported.\",\n",
      "        \"matches_publication/authors\": \"Jingxue Wang, Huali Cao, John Z. H. Zhang & Yifei Qi \",\n",
      "        \"matches_publication/journal\": \"Scientific Reports\",\n",
      "        \"matches_publication/title\": \"Computational Protein Design with Deep Learning Neural Networks\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6634f47fded6e7820f74a1b0\",\n",
      "        \"shortid\": \"6qvzmhfton\",\n",
      "        \"uuid\": \"8106fd96-ea13-4cb8-84f9-4ac85aba9559\",\n",
      "        \"created\": \"2024-05-03T14:28:15.854Z\",\n",
      "        \"updated\": \"2024-05-03T14:28:15.854Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"30538725\",\n",
      "        \"publication_authors\": \"Qiwan Hu, Mudong Feng, Luhua Lai, Jianfeng Pei\\n\",\n",
      "        \"publication_journal\": \"Frontiers in Genetics\",\n",
      "        \"publication_title\": \"Prediction of Drug-Likeness Using Deep Autoencoder Neural Networks\",\n",
      "        \"publication_doi\": \"10.3389/fgene.2018.00585\",\n",
      "        \"publication_year\": \"2018\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches_evaluation/comparison\": \"Accuracy was compared to a SVM model built by Li et al (Li et al., 2007).\",\n",
      "        \"matches_evaluation/measure\": \"All models were evaluated by five indexes. The Accuracy, Specificity, Sensitivity, Matthews correlation coefficient (MCC), and area under the receiver operating characteristic curve (AUC).\",\n",
      "        \"matches_evaluation/method\": \"They used a 5 fold cross-validation.\\nThe evaluation was not performed on an independent set.\\n\",\n",
      "        \"matches_optimization/algorithm\": \"Algorithm is an autoencoder neural network.\",\n",
      "        \"matches_optimization/encoding\": \"Authors used 2D descriptors to encode the molecules. Molecules after preprocessing were calculated by MOLD2 (Hong et al., 2008), resulting a descriptor matrix of \\u223c700 descriptors per molecule.\",\n",
      "        \"matches_optimization/features\": \"\\u223c700 descriptors per molecule.\",\n",
      "        \"matches_optimization/fitting\": \"The exact number of parameters not reported. As a strategy against overfitting, authors tried to optimized the weight of the positive and negative sample loss of the logarithmic likelihood loss function.\",\n",
      "        \"matches_optimization/meta\": \"It is not a meta-predictor.\",\n",
      "        \"matches_optimization/parameters\": \"Reported table of the hyperparameters:\\nInitializer = TruncatedNormal\\nNumber of hidden layers = 1\\nNumber of hidden layer nodes = 512\\nL2 Normalization term = 1e-4\\nDropout rate = 0.14\\nActivation = Relu\\nBatch size = 128\\nOptimizer = Adam\\nLoss = mse for AE, binary crossentropy for classifier\",\n",
      "        \"matches_optimization/regularization\": \"As a strategy against overfitting, authors tried to optimized the weight of the positive and negative sample loss of the logarithmic likelihood loss function. They also used early stopping based on classification ACC on the \\\"test\\\" set.\",\n",
      "        \"matches_model/interpretability\": \"No mention on interoperability. It appears to be a black box.\",\n",
      "        \"matches_model/output\": \"It is a classifier model.\",\n",
      "        \"matches_dataset/provenance\": \"3 manually built dataset pairs were used by authors to construct prediction models for drug-likeness.\\nDataset pair | Number of positive | Number of negative | Total\\nWDI/ACD | 38,260 | 288,540 | 326,800\\nMDDR/ZINC | 171,850 | 199,220 | 371,070\\nWORLDDRUG/ZINC | 3,380 | 199,220 | 202,600\\n\\nMDDR (MACCS-II Drug Data Report [MDDR], 2004), WDI (Li et al., 2007), ACD (Li et al., 2007), ZINC (Irwin et al., 2012; Sterling and Irwin, 2015), ZINC WORLD DRUG (Sterling and Irwin, 2015)\",\n",
      "        \"matches_dataset/redundancy\": \"Authors randomly split the datasets.\\nThe training and test sets are not independent.\\nThey removed the duplicates appearing in both sets.\\n\",\n",
      "        \"matches_dataset/splits\": \"Authors randomly split the datasets on the proportion of 9:1 as training set and \\\"validation\\\" (apparently used as the test set).\\nNo mention on stratified sampling to ensure the same distribution of positive and negative classes in the splits.\",\n",
      "        \"matches_publication/authors\": \"Qiwan Hu, Mudong Feng, Luhua Lai, Jianfeng Pei\\n\",\n",
      "        \"matches_publication/journal\": \"Frontiers in Genetics\",\n",
      "        \"matches_publication/title\": \"Prediction of Drug-Likeness Using Deep Autoencoder Neural Networks\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6638a2f7b30933003cc215b9\",\n",
      "        \"shortid\": \"toe45v1h7a\",\n",
      "        \"uuid\": \"71898e53-9df0-464d-9e78-bb95274221ec\",\n",
      "        \"created\": \"2024-05-06T09:29:27.218Z\",\n",
      "        \"updated\": \"2024-05-06T09:29:27.218Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"30109435\",\n",
      "        \"publication_authors\": \"Radoslav Kriv\\u00e1k, David Hoksza\",\n",
      "        \"publication_journal\": \"Journal of cheminformatics\",\n",
      "        \"publication_title\": \"P2Rank: machine learning based tool for rapid and accurate prediction of ligand binding sites from protein structure\",\n",
      "        \"publication_doi\": \"10.1186/s13321-018-0285-8\",\n",
      "        \"publication_year\": \"2018\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_optimization/algorithm\": \"The used algorithm is a Random Forest Regression model.\\nThe model is not novel.\",\n",
      "        \"matches_optimization/config\": \"URL: https://github.com/rdk/p2rank. Licence: MIT\",\n",
      "        \"matches_optimization/encoding\": \"The model takes vectors of 35 numerical features as input.\",\n",
      "        \"matches_optimization/features\": \"Every vector is composed of 35 numerical features.\\nNo mention on feature selection.\",\n",
      "        \"matches_optimization/fitting\": \"The clear number of parameters is not mentioned. No assessment on over/under fitting was mentioned.\",\n",
      "        \"matches_optimization/meta\": \"The algorithm is not a meta-predictor.\",\n",
      "        \"matches_optimization/parameters\": \"Beside the hyper-parameters of Random Forest, the algorithm uses other parameters and \\\"cut-of's\\\", thresholds\\\", \\\"protrusion radius\\\", are explicitly mentioned.\\nIt is mentioned that only hyper-parameters are optimized on a separate dataset from training set.\\nThe method of optimization is not mentioned.\",\n",
      "        \"matches_optimization/regularization\": \"A validation set was used to optimize the parameters before training on the training set.\",\n",
      "        \"matches_model/availability\": \"The software and the source code is publicly available through the provided link to the GitHub repository of the software. It is a stand-alone executable software, they currently have a web server, but at the time of publication the web server was under development. URL: https://github.com/rdk/p2rank. Licence: MIT\",\n",
      "        \"matches_model/duration\": \"It is mentioned that it requires under 1 s for prediction on one protein.\",\n",
      "        \"matches_model/interpretability\": \"The model has 200 trees, each grown with no depth limit using 6 features, this makes it challenging to interpret due to the sheer number of trees and their depth. However, it is still possible to obtain feature importance scores.\",\n",
      "        \"matches_model/output\": \"It is a regression model outputting numbers between 0 and 1.\",\n",
      "        \"matches_dataset/availability\": \"All the mentioned datasets are selected from previous studies and are publicly available.\\nDatasets are both mentioned through referencing to other studies and accessible through the URL: https://github.com/rdk/p2rank-datasets\",\n",
      "        \"matches_dataset/provenance\": \"Training:  CHEN11\\u2014a dataset of 251 proteins harboring 476 ligands introduced in LBS prediction benchmarking study.\\nOptimization and validation: JOINED\\u2014consists of structures from several smaller datasets used in previous studies (B48/U48, B210, DT198, ASTEX) joined into one larger dataset. you can find the details below:\\nB48/U48\\u2014Datasets that contain a set of 48 proteins in a bound and unbound state.\\nB210\\u2014a benchmarking dataset of 210 proteins in bound state.\\nDT198\\u2014a dataset of 198 drug-target complexes.\\nASTEX\\u2014Astex Diverse set is a collection of 85 proteins that was introduced as a benchmarking dataset for molecular docking methods.\",\n",
      "        \"matches_dataset/redundancy\": \"Datasets for training and validation purposes are selected arbitrarily.\\nTesting dataset is not mentioned.\\nOnly training set is mentioned to be non-redundant without explicit mention on the cutout identity percentage.\",\n",
      "        \"matches_dataset/splits\": \"2 data splits were utilized:\\nTraining: CHEN11 dataset composed of 251 data points.\\nOptimization and validation: JOINED dataset composed of an overall  541 data points.\\nAll the data points are positive examples of protein-ligand complexes.\",\n",
      "        \"matches_publication/authors\": \"Radoslav Kriv\\u00e1k, David Hoksza\",\n",
      "        \"matches_publication/journal\": \"Journal of cheminformatics\",\n",
      "        \"matches_publication/title\": \"P2Rank: machine learning based tool for rapid and accurate prediction of ligand binding sites from protein structure\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"664b2a75b30933003cc2184b\",\n",
      "        \"shortid\": \"2g7fzlkala\",\n",
      "        \"uuid\": \"4fb79024-ab54-4e22-889b-73335801c3bc\",\n",
      "        \"created\": \"2024-05-20T10:48:21.402Z\",\n",
      "        \"updated\": \"2024-05-20T10:48:21.402Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"28527154\",\n",
      "        \"publication_authors\": \"Jain S, Grandits M, Richter L, Ecker GF. \",\n",
      "        \"publication_journal\": \"Journal of Computer-Aided Molecular Design\",\n",
      "        \"publication_title\": \"Structure based classification for bile salt export pump (BSEP) inhibitors using comparative structural modeling of human BSEP\",\n",
      "        \"publication_doi\": \"10.1007/s10822-017-0021-x\",\n",
      "        \"publication_year\": \"2018\",\n",
      "        \"score\": 1,\n",
      "        \"matches_evaluation/availability\": \"Not available.\",\n",
      "        \"matches_evaluation/comparison\": \"A comparison between the present structure-based models to a previous published method, by the same research group, that applied ligand-based models, was performed.  A comparison to a model, obtained using the scoring probability functions only, was performed. \",\n",
      "        \"matches_evaluation/confidence\": \"No confidence intervals of performance metrics are given.\",\n",
      "        \"matches_evaluation/measure\": \"Sensitivity, specificity, accuracy, G-mean, Matthews Correlation Coefficient, AUC-ROC.\",\n",
      "        \"matches_evaluation/method\": \"Two independent test sets were used, containing 166 compounds (44 inhibitors and 122 noninhibitors), and 638 compounds (248 inhibitors and 390 non-inhibitors), respectively.  The first set was taken from the work of Pedersen JM, et al (2013) Toxicol Sci 136:328\\u2013343.  The second dataset (unpublished) was provided by AstraZeneca within the framework of the IMI project eTOX. (http://www.etoxproject.eu). Both studies provide in vitro inhibition data on human BSEP.\",\n",
      "        \"matches_optimization/algorithm\": \"The open source software WEKA (version 3.7.10) was used for building binary classification models. The standard machine learning classifiers, J48, Random Forest, REPTree, LibSVM, and Naive Bayes, were used with the default parameters along with tenfold internal cross-validation.\",\n",
      "        \"matches_optimization/config\": \"Not available.\",\n",
      "        \"matches_optimization/encoding\": \"The initial dataset was curated according to the following steps: (1) removal of inorganic compounds using Instant JChem v.5.3, 2010, ChemAxon (http://www.chemaxon.com); (2) analysis and removal of mixtures formed by two or more large molecules; (3) deletion of organometallic compounds using MOE 2011.10 15; (4) identification and removal of compounds containing special atoms such as selenium or tellurium by means of an in-house MOE SVL script; (5) normalization of chemotypes using the ChemAxon\\u2019s Standardizer with the following settings: clean 2D, aromatize, mesomerize, neutralize, tautomerize and all transform options; (6) identification and elimination of nonunique structures using MOE; (7) deletion of compounds having permanent charges.    Different docking runs (using the docking software GOLD) and docking fitness functions were applied to the preprocessed training set.  Prior probability distributions for the inhibitor and non-inhibitor classes were calculated.\",\n",
      "        \"matches_optimization/features\": \"The input for the set of the 5 ML models was a combination of the Xscore(ChemScore) scoring function, obtained by the GOLD docking runs, combined with physicochemical properties as descriptors for the training set. The physicochemical properties were MW (Molecular Weight) and log(P) (where P is the octanol-water partition coefficient of the compound).   No feature selection is mentioned.\",\n",
      "        \"matches_optimization/fitting\": \"The standard number of parameters in the applied classifiers was much lower than the training points.  The possibility of under-fitting was not mentioned.\",\n",
      "        \"matches_optimization/parameters\": \"The standard parameters in WEKA for the 5 chosen classifiers were used.  Their number is in the order of less than a dozen for each classifier. \",\n",
      "        \"matches_optimization/regularization\": \"Not mentioned in text.\",\n",
      "        \"matches_model/availability\": \"The open source software WEKA (version 3.7.10) was used.\",\n",
      "        \"matches_model/duration\": \"Not reported.\\n\",\n",
      "        \"matches_model/interpretability\": \"The input features were relatively transparent, being based on the quality of the docking poses and on two main reasonable physicochemical properties of the compounds.  The addition of the latters did improve the performance, which was in agreement with expectation.\",\n",
      "        \"matches_model/output\": \"Binary classification (BSEP inhibitor or non-inhibitor).  \",\n",
      "        \"matches_dataset/availability\": \"The training dataset has been taken from a cited publication (Warner DJ, et al (2012) Drug Metab Dispos Biol Fate Chem 40:2332\\u20132341), which however was not accessible without a fee.  One of the test sets in published, in the unprocessed form, in Pedersen JM, et al (2013) Toxicol Sci 136:328\\u2013343.\",\n",
      "        \"matches_dataset/provenance\": \"The training dataset comprised 408 compounds:113 BSEP (bile salt export pump) inhibitors and 295 non-inhibitors, derived from a previous publication (Warner DJ, et al (2012) Drug Metab Dispos Biol Fate Chem 40:2332\\u20132341\",\n",
      "        \"matches_dataset/redundancy\": \"A chemical space network (CSN) was constructed and analyzed in order to assess the structural similarity shared by the compounds of the inhibitor and non-inhibitor groups.  The majority of the nodes did not have a connection, indicating a high structural diversity in the training dataset.  A similar analysis showed a high structural diversity also for one of the test sets.\",\n",
      "        \"matches_dataset/splits\": \"For all model, tenfold internal cross-validation was applied.  Distribution of data point in the splits is not reported.\",\n",
      "        \"matches_publication/authors\": \"Jain S, Grandits M, Richter L, Ecker GF. \",\n",
      "        \"matches_publication/journal\": \"Journal of Computer-Aided Molecular Design\",\n",
      "        \"matches_publication/title\": \"Structure based classification for bile salt export pump (BSEP) inhibitors using comparative structural modeling of human BSEP\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b1e\",\n",
      "        \"publication_pmid\": \"31137222\",\n",
      "        \"publication_updated\": \"03/18/2022 14:48:58\",\n",
      "        \"publication_authors\": \"Tan JX, Li SH, Zhang ZM, Chen CX, Chen W, Tang H, Lin H\",\n",
      "        \"publication_journal\": \"Math Biosci Eng\",\n",
      "        \"publication_title\": \"Identification of hormone binding proteins based on machine learning methods.\",\n",
      "        \"publication_doi\": \"10.3934/mbe.2019123\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"79228609-a725-4ad4-a390-21d4cfe00670\",\n",
      "        \"shortid\": \"rggiypqqgz\",\n",
      "        \"score\": 0.57,\n",
      "        \"matches_publication/updated\": \"03/18/2022 14:48:58\",\n",
      "        \"matches_publication/authors\": \"Tan JX, Li SH, Zhang ZM, Chen CX, Chen W, Tang H, Lin H\",\n",
      "        \"matches_publication/journal\": \"Math Biosci Eng\",\n",
      "        \"matches_publication/title\": \"Identification of hormone binding proteins based on machine learning methods.\",\n",
      "        \"matches_optimization/algorithm\": \"Support vector machine (SVM) \",\n",
      "        \"matches_optimization/encoding\": \"Global features. Gene Expression Profile\",\n",
      "        \"matches_optimization/features\": \"The optimized method uses expression from 66 selected genes. The expression profile genes (genes nr = 16032) were first ranked by feature importance (gene expression) via the minimum redundancy maximum relevancy (mRMR) method, getting down to 500 genes. Subsequently, a SVM classifier was used to screen the optimal feature genes by the incremental feature selection (IFS) method. Optimal genes were selected maximizing the the MCC obtained with a Leave-One-Out Cross-Validation procedure on training set.\",\n",
      "        \"matches_optimization/fitting\": \"not reported   The number of features were reduced to 66 by the feature selection algorithms, which however could have induce over-fitting by themselves.\",\n",
      "        \"matches_optimization/regularization\": \"No. not reported how the regularization parameter in SVM was tuned.\",\n",
      "        \"matches_model/interpretability\": \"Black box. PCA and GO-Term enrichment analysis on 66 selected genes shows an association with ribosomal protein-encoding, viral protein translation, and protein-membrane location.\",\n",
      "        \"matches_model/output\": \"Classification (Covid swab positive or negative)\",\n",
      "        \"matches_evaluation/method\": \"Leave-One-Out Cross-validation\",\n",
      "        \"matches_dataset/availability\": \"Yes (GEO: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE152075)\",\n",
      "        \"matches_dataset/provenance\": \"Data source:  Gene expression profiles from NCBI/GEO GSE152075.  Data points: 484 individuals.  N_pos (swabs Covid positive)= 430, N_neg (swabs Covid negative)= 34.  Used by at least one previous paper (PMID: 32898168).   \",\n",
      "        \"matches_dataset/splits\": \"Due to sample imbalance, the python package imblearn was used to amplify the number of small samples to the same as that of large samples.  \"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b1f\",\n",
      "        \"publication_pmid\": \"30615300\",\n",
      "        \"publication_updated\": \"03/21/2022 10:33:58\",\n",
      "        \"publication_authors\": \"Plant D, Maciejewski M, Smith S, Nair N, Maximising Therapeutic Utility in Rheumatoid Arthritis Consortium, the RAMS Study Group., Hyrich K, Ziemek D, Barton A, Verstappen S\",\n",
      "        \"publication_journal\": \"Arthritis Rheumatol\",\n",
      "        \"publication_title\": \"Profiling of Gene Expression Biomarkers as a Classifier of Methotrexate Nonresponse in Patients With Rheumatoid Arthritis.\",\n",
      "        \"publication_doi\": \"10.1002/art.40810\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"1b20e970-8ffe-4825-aebd-9e1d924a6d06\",\n",
      "        \"shortid\": \"r4ntb0iqha\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches_publication/updated\": \"03/21/2022 10:33:58\",\n",
      "        \"matches_publication/authors\": \"Plant D, Maciejewski M, Smith S, Nair N, Maximising Therapeutic Utility in Rheumatoid Arthritis Consortium, the RAMS Study Group., Hyrich K, Ziemek D, Barton A, Verstappen S\",\n",
      "        \"matches_publication/journal\": \"Arthritis Rheumatol\",\n",
      "        \"matches_publication/title\": \"Profiling of Gene Expression Biomarkers as a Classifier of Methotrexate Nonresponse in Patients With Rheumatoid Arthritis.\",\n",
      "        \"matches_optimization/algorithm\": \"composite model  with several stepp with different classification algorithms (hclust, K-means, mclust, Random Forest)\",\n",
      "        \"matches_optimization/encoding\": \"global features (Rnot reported-Seq, Flow cytometry)\",\n",
      "        \"matches_optimization/features\": \"features selection by Boruta algorithm ( 10.18637/jss.v036.i11 )\",\n",
      "        \"matches_optimization/parameters\": \"Molecular subgroups discovery:\\n - Step 1: Unsupervised gene selection,\\n - Step 2: Robust consensus clustering (hclust, K-means, mclust)\\n - Step 3: Identification of molecular signature (one-way ANOVA and Random Forest),\\n - Step 4: Robustness classification\\n - Step 5: Classification of discordant patients\\n-> definition of 4 cluster\\n\\nComposite model for cluster prediction:\\n#1 xgboost-tree: predict C4 vs all\\n#2 multi-classification:  C1, C2, or C3\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/measure\": \"Accuracy (94.81% for the C4 prediction model, and 96.72% for the multi-classification model.)\",\n",
      "        \"matches_evaluation/method\": \"independent dataset\",\n",
      "        \"matches_dataset/availability\": \"All data included in this study is available upon request at ELIXIR Luxemburg ( https://doi.org/10.17881/th9v-xt85 )\",\n",
      "        \"matches_dataset/provenance\": \"Clinical data collected by the authors\\nN_neg 330, N_pos 304\",\n",
      "        \"matches_dataset/splits\": \"N_pos:\\nDiscovery 227 and Validation 77\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b20\",\n",
      "        \"publication_pmid\": \"30819107\",\n",
      "        \"publication_updated\": \"03/23/2022 10:25:57\",\n",
      "        \"publication_authors\": \"Vinogradova S, Saksena SD, Ward HN, Vigneau S, Gimelbrant AA\",\n",
      "        \"publication_journal\": \"BMC Bioinformatics\",\n",
      "        \"publication_title\": \"MaGIC: a machine learning tool set and web application for monoallelic gene inference from chromatin.\",\n",
      "        \"publication_doi\": \"10.1186/s12859-019-2679-7\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"d70f673b-b310-4054-9672-a93679f1d817\",\n",
      "        \"shortid\": \"htsvoi90ft\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"03/23/2022 10:25:57\",\n",
      "        \"matches_publication/authors\": \"Vinogradova S, Saksena SD, Ward HN, Vigneau S, Gimelbrant AA\",\n",
      "        \"matches_publication/journal\": \"BMC Bioinformatics\",\n",
      "        \"matches_publication/title\": \"MaGIC: a machine learning tool set and web application for monoallelic gene inference from chromatin.\",\n",
      "        \"matches_optimization/algorithm\": \"the models included lasso and ridge based on linear relationships [14], support vector machine using kernel methods [15], tree-based random forest [16], and Xgboost\",\n",
      "        \"matches_optimization/config\": \"yes, SI\",\n",
      "        \"matches_optimization/encoding\": \"Dimension reduction was performed to avoid the \\u201ccurse of dimensionality\\u201d caused by a large number of variables compared with the size of the data. \",\n",
      "        \"matches_optimization/features\": \"Among the 64 variables, we selected variables that are frequently encountered in clinical practice for prescription of biologics and excluded variables that are not referenced when prescribing biologics. As a result, 15 variables known to be of clinical importance were preselected (i.e., sex, age, baseline DAS28-ESR, methotrexate dose, steroid dose, erythrocyte sedimentation rate [ESR], C-reactive protein [CRP], rheumatoid factor [RF], anti-cyclic citrullinated peptide antibody [ACPA], anti-nuclear antibody [Anot reported], and five comorbidities). Subsequently, 20 variables that were highly correlated with the drug response (remission) of each bDMARD were selected. After selecting variables based on data, we created a prediction model by training with a fixed set of 35 variables. Missing data for variables (Additional file: Table S3) were replaced with the median value for each variable. With a similar logic, binary variables such as comorbidities were coded as 1 if \\u201cyes\\u201d and 0 if \\u201cno\\u201d or \\u201cno test\\u201d because \\u201cno\\u201d was the most common value.\",\n",
      "        \"matches_optimization/fitting\": \"To avoid overfitting problems, the training and test sets were divided in a 7:3 ratio, and the models were trained with the training set; then, the prediction results were verified using the test set. For the training dataset, a 5-fold cross validation was performed to tune the hyperparameters determined as outside models (Additional file: Table S1 and Table S2). In this procedure, a grid search was conducted to evaluate all possible combinations of the hyperparameters. The grid search found optimal hyperparameters with the objective function of determining the area under the receiver operating characteristics (AUROC) in each model. Bootstrapping (random sampling with replacement) was also performed to obtain a median value for the AUROC curve and to determine the accuracy for reducing measurement variances caused by small samples when dividing between the training and test sets.\",\n",
      "        \"matches_optimization/parameters\": \"a grid search was conducted to evaluate all possible combinations of the hyperparameters. The grid search found optimal hyperparameters with the objective function of determining the area under the receiver operating characteristics (AUROC) in each model\",\n",
      "        \"matches_evaluation/comparison\": \"The no information rate, which is the largest proportion of the observed classes, was used as a baseline to determine the overall distribution of the classification and to compare with those of the machine learning models\",\n",
      "        \"matches_evaluation/measure\": \"Bootstrapping (random sampling with replacement) was also performed to obtain a median value for the AUROC curve and to determine the accuracy for reducing measurement variances caused by small samples when dividing between the training and test sets.\",\n",
      "        \"matches_dataset/availability\": \"Yes, Data are available from the Clinical Research Committee of KOBIO under the Korean College of Rheumatology for researchers who meet the criteria for access to confidential data\",\n",
      "        \"matches_dataset/provenance\": \"This study used data from the KOBIO registry, which is a nationwide multicenter cohort in Korea that was established to evaluate the effectiveness and side effects of biologic therapies in patients with RA [13]. Patients in the registry were recruited from 38 hospitals since 2012, and their demographics, medications, comorbidities, extra-articular manifestations, disease activities, radiographic findings, and laboratory findings performed within 4 weeks prior to the patient\\u2019s visit were recorded with the date. The data from patients who were followed up annually were recorded on the KOBIO website (http://www.kobio.or.kr/kobio/), and these patients provided informed consent prior to registration. Ethical approval of the KOBIO-RA was obtained from the institutional review boards of all 38 participating institutions, including the Institutional Review Board of Inje University Seoul Paik Hospital (PAIK 2018-11-005).\",\n",
      "        \"matches_dataset/splits\": \" the training and test sets were divided in a 7:3 ratio, and the models were trained with the training set\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b21\",\n",
      "        \"publication_pmid\": \"31058230\",\n",
      "        \"publication_updated\": \"03/27/2022 14:51:24\",\n",
      "        \"publication_authors\": \"Tripathi A, Xu ZZ, Xue J, Poulsen O, Gonzalez A, Humphrey G, Meehan MJ, Melnik AV, Ackermann G, Zhou D, Malhotra A, Haddad GG, Dorrestein PC, Knight R\",\n",
      "        \"publication_journal\": \"mSystems\",\n",
      "        \"publication_title\": \"Intermittent Hypoxia and Hypercapnia Reproducibly Change the Gut Microbiome and Metabolome across Rodent Model Systems.\",\n",
      "        \"publication_doi\": \"10.1128/mSystems.00058-19\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"dd72ec96-8461-42d7-887c-700c90446755\",\n",
      "        \"shortid\": \"hk4hhg2svs\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches_publication/updated\": \"03/27/2022 14:51:24\",\n",
      "        \"matches_publication/authors\": \"Tripathi A, Xu ZZ, Xue J, Poulsen O, Gonzalez A, Humphrey G, Meehan MJ, Melnik AV, Ackermann G, Zhou D, Malhotra A, Haddad GG, Dorrestein PC, Knight R\",\n",
      "        \"matches_publication/title\": \"Intermittent Hypoxia and Hypercapnia Reproducibly Change the Gut Microbiome and Metabolome across Rodent Model Systems.\",\n",
      "        \"matches_optimization/algorithm\": \"Linear Support Vector Classification\",\n",
      "        \"matches_optimization/config\": \"Supplementary Information\",\n",
      "        \"matches_optimization/encoding\": \"One-hot encoding as vectors\",\n",
      "        \"matches_optimization/features\": \"Not defined, 1396 * number of genotypes\",\n",
      "        \"matches_optimization/parameters\": \"not reported, multiple supervised ML methods were used with scikit-learn\",\n",
      "        \"matches_model/availability\": \"https://github.com/jlanga/smsk_popoolation, MIT License\",\n",
      "        \"matches_evaluation/availability\": \"Supporting information\",\n",
      "        \"matches_evaluation/comparison\": \"Multiple supervised methods were compared, best method selection based on average accuracy.\",\n",
      "        \"matches_dataset/availability\": \"Additional file 1, https://www.ncbi.nlm.nih.gov/sra/?term=PRJnot reported666033\",\n",
      "        \"matches_dataset/provenance\": \"Custom sampling of 22 populations of honey bee in Europe and adjacent regions, total 2145 samples leading to 1.6 billion paired-end fragments. 1998 remained after removal of 62 outliers.\",\n",
      "        \"matches_dataset/redundancy\": \"Selection of SNPs (Single Nucleotide Polymorphisms), originally 4400 selected, 4165 after QC check. 4094 SNPs were genotyped (71 failed base calling).\",\n",
      "        \"matches_dataset/splits\": \"Training: 1391 samples (70% of 1998),  597 (30% of 1998) and 2505 independent samples (out-of-sample with known bee subspecies classification) for validation.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b22\",\n",
      "        \"publication_pmid\": \"30853547\",\n",
      "        \"publication_updated\": \"03/28/2022 11:30:10\",\n",
      "        \"publication_authors\": \"Chung NC, Mirza B, Choi H, Wang J, Wang D, Ping P, Wang W\",\n",
      "        \"publication_journal\": \"Methods\",\n",
      "        \"publication_title\": \"Unsupervised classification of multi-omics data during cardiac remodeling using deep learning.\",\n",
      "        \"publication_doi\": \"10.1016/j.ymeth.2019.03.004\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"84fcc9b6-a284-4d43-8940-fee068877b2f\",\n",
      "        \"shortid\": \"3hsc5woplt\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches_publication/updated\": \"03/28/2022 11:30:10\",\n",
      "        \"matches_publication/authors\": \"Chung NC, Mirza B, Choi H, Wang J, Wang D, Ping P, Wang W\",\n",
      "        \"matches_publication/title\": \"Unsupervised classification of multi-omics data during cardiac remodeling using deep learning.\",\n",
      "        \"matches_optimization/algorithm\": \"gradient boosted decision trees and random forests\",\n",
      "        \"matches_optimization/parameters\": \"Python version 3.6.8,\\ngradient boosted decision trees: LightGBM v2.2.3\\nRF: scikit-learn v0.20.2\",\n",
      "        \"matches_optimization/regularization\": \"\\\"The models were not retrained using SRM data to avoid overfitting and overestimating test performance. In addition, within the training set, cross-validation was used to develop the models to avoid overfitting to the training set.\\\"\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/availability\": \"yes, https://github.com/stanfordmlgroup/influenza-qtof/tree/master/data\",\n",
      "        \"matches_evaluation/comparison\": \"costeffective comare to PCR tests and could be performed at the point-of-care comapre to RT-PCR test, no other methods for direct omparisonc\",\n",
      "        \"matches_evaluation/measure\": \"AUC, sensitivity, specificity\",\n",
      "        \"matches_evaluation/method\": \"novel experiments.\",\n",
      "        \"matches_dataset/availability\": \"Conatact (hoganca@stanford.edu) is provided right the beggining of the \\\"Methods\\\" section of the papaer for further information and requests.\\n\\nThe data and code generated during this study were made available at https://github.com/stanfordmlgroup/influenza-qtof.\",\n",
      "        \"matches_dataset/provenance\": \"samples from Stanford Health Care and Stanford Children\\u2019s Health,\\n1:1 ratio of positive to age and sex-matched negative controls.\\n\\nData collection was performed after the reference test (RT-PCR) and before the index test (metabolomics).\\nDiscovery cohort (from April 23 2015 to October 13 2019):  118 samples, N_neg 118 samples\\nvalidation cohort (December 21 2019 to February 18 2020): N_pos 48 samples, N_neg 48 samples\",\n",
      "        \"matches_dataset/splits\": \"The final analysis included for discovery cohort:\\ntraining set:  94 positive, 92 negative\\ntest set: 24 positive, 26 negative\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b2c\",\n",
      "        \"publication_pmid\": \"31407406\",\n",
      "        \"publication_updated\": \"02/10/2022 16:35:16\",\n",
      "        \"publication_authors\": \"Li Y, Zhang C, Bell EW, Yu DJ, Zhang Y\",\n",
      "        \"publication_journal\": \"Proteins\",\n",
      "        \"publication_title\": \"Ensembling multiple raw coevolutionary features with deep residual neural networks for contact-map prediction in CASP13.\",\n",
      "        \"publication_doi\": \"10.1002/prot.25798\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"14a845e7-557b-486b-8b10-d636b8a1c8f2\",\n",
      "        \"shortid\": \"0zyckt3df0\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches_publication/updated\": \"02/10/2022 16:35:16\",\n",
      "        \"matches_publication/authors\": \"Li Y, Zhang C, Bell EW, Yu DJ, Zhang Y\",\n",
      "        \"matches_publication/title\": \"Ensembling multiple raw coevolutionary features with deep residual neural networks for contact-map prediction in CASP13.\",\n",
      "        \"matches_optimization/algorithm\": \"Weka platform used,  naive bases, logistic regression and random forests.  Only the latter is shown given its better performance. \",\n",
      "        \"matches_optimization/encoding\": \"Not discussed explicitly.  metabolic data per patient was used,\",\n",
      "        \"matches_optimization/features\": \"mass spectrum data is used.   Either focussing on a specific subset fo know compounds or the full VOC data (requiring extensive feature selection , see Fig2 of paper)\",\n",
      "        \"matches_optimization/meta\": \"no \",\n",
      "        \"matches_optimization/parameters\": \"Not detailed what the parameters were for the random forest. \",\n",
      "        \"matches_optimization/regularization\": \"Thorough feature selection procedure (wrapper based) and two step cross-validation (10-fol)\",\n",
      "        \"matches_model/interpretability\": \"No analysis provided\",\n",
      "        \"matches_model/output\": \"classification (Ca+ vs HC, CA- vs HC and Ca+ vs Ca-)\",\n",
      "        \"matches_evaluation/comparison\": \"focus on RF as performance of others is low (obvious for NB and regression)\",\n",
      "        \"matches_evaluation/measure\": \"AUC and accuracry\",\n",
      "        \"matches_dataset/availability\": \"previous publication gives some data but not the raw data\",\n",
      "        \"matches_dataset/provenance\": \"Data comes from a previous paper : Koureas, Michalis, et al. \\\"Target analysis of volatile organic compounds in exhaled breath for lung cancer discrimination from other pulmonary diseases and healthy persons.\\\" Metabolites 10.8 (2020): 317. 85 patients (49Ca+ and 36 Ca-) and 52 control group individuals.\",\n",
      "        \"matches_dataset/redundancy\": \"No mentioned how stratification is done in the cross-validation procedure.  Feature elimination is performed\",\n",
      "        \"matches_dataset/splits\": \"No split in training/test /validation.  The splitting is done within a 10-fold cross-validation procedure. Three classes are possible, and predictors are designed for pairs of classes. \"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b2d\",\n",
      "        \"publication_pmid\": \"31462106\",\n",
      "        \"publication_updated\": \"04/06/2022 18:58:39\",\n",
      "        \"publication_authors\": \"Cicaloni V, Spiga O, Dimitri GM, Maiocchi R, Millucci L, Giustarini D, Bernardini G, Bernini A, Marzocchi B, Braconi D, Santucci A\",\n",
      "        \"publication_journal\": \"FASEB J\",\n",
      "        \"publication_title\": \"Interactive alkaptonuria database: investigating clinical data to improve patient care in a rare disease.\",\n",
      "        \"publication_doi\": \"10.1096/fj.201901529R\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"488264e6-f952-472e-add0-e6d8fd6f5d1d\",\n",
      "        \"shortid\": \"2ee7tbw9bc\",\n",
      "        \"score\": 0.9,\n",
      "        \"matches_publication/updated\": \"04/06/2022 18:58:39\",\n",
      "        \"matches_publication/authors\": \"Cicaloni V, Spiga O, Dimitri GM, Maiocchi R, Millucci L, Giustarini D, Bernardini G, Bernini A, Marzocchi B, Braconi D, Santucci A\",\n",
      "        \"matches_publication/journal\": \"FASEB J\",\n",
      "        \"matches_publication/title\": \"Interactive alkaptonuria database: investigating clinical data to improve patient care in a rare disease.\",\n",
      "        \"matches_optimization/algorithm\": \"CNN, explained in Methods and figure in SI. Predicts a value between 0 and 1 for each of the three classes: inclusion, exclusion and unchanged. Aim is to predict splicing size changes (including no change) after BPN15477 treatment.\",\n",
      "        \"matches_optimization/config\": \"Code is available on GitHub (haven't checked it)\",\n",
      "        \"matches_optimization/encoding\": \"Onehot encoding of concatenated triplets of 3 exons (details see paper)\",\n",
      "        \"matches_optimization/features\": \"400x4 matrix for each exon triplet. No feature selection performed\",\n",
      "        \"matches_optimization/fitting\": \"used L-1 regularisation to avoid overfitting (coefficient =0.6) in the convolutional layer and dropout strategy im the hidden layer\",\n",
      "        \"matches_optimization/meta\": \"No data from other predictors is used\",\n",
      "        \"matches_optimization/parameters\": \"Huge number of network parameters (2.5 million trainable parameters as mentioned by the authors). \",\n",
      "        \"matches_optimization/regularization\": \"Overfitting limited through limitation on number of training epochs (12th epoch).  Comparison to 1000 other models with same structure using different random initialisations.  Evaluations done on separate validation and test sets\",\n",
      "        \"matches_model/availability\": \"via GitHub\",\n",
      "        \"matches_model/interpretability\": \"Method is black box but they provide an exhaustive evaluation of the predictions (compared to 1000 other models) and performed an analysis of the data, through other methods and experiments.\",\n",
      "        \"matches_model/output\": \"classification (values between 0 and 1 for each class)\",\n",
      "        \"matches_evaluation/comparison\": \"not relevant for this work,\",\n",
      "        \"matches_evaluation/confidence\": \"Provided in detail (see statistical analysis section)\",\n",
      "        \"matches_evaluation/measure\": \"AUC and precision recall\",\n",
      "        \"matches_evaluation/method\": \"Data split in training, validation and testing. Experimental verification of predictions.\",\n",
      "        \"matches_dataset/availability\": \"Data is provided as supplementary information (supplementary data 1) and via GEO\",\n",
      "        \"matches_dataset/provenance\": \"Rnot reported-seq data produced by the authors. The set includes 934 exon triplets responding to a BPN15477b treatment. 245 with increased exon inclusion and 680 with increased exclusion. They added 382 exon triplets which did not trigger a response (negative set). Data is used for a three-class predictor. \",\n",
      "        \"matches_dataset/redundancy\": \"No stratification wa reported\",\n",
      "        \"matches_dataset/splits\": \"Data divided in training (178 inclusion responded, 478 exclusion responded and 268 unchanged), validation (51inclusion responded, 136 exclusion responded and 76 unchanged) and test set (25 inclusion responded, 68 exclusion responded and 38 unchanged). the data is split randomly over these 3 sets. \"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b2e\",\n",
      "        \"publication_pmid\": \"31176619\",\n",
      "        \"publication_updated\": \"06/23/2022 03:07:23\",\n",
      "        \"publication_authors\": \"Zeng H, Gifford DK\",\n",
      "        \"publication_journal\": \"Cell Syst\",\n",
      "        \"publication_title\": \"Quantification of Uncertainty in Peptide-MHC Binding Prediction Improves High-Affinity Peptide Selection for Therapeutic Design.\",\n",
      "        \"publication_doi\": \"10.1016/j.cels.2019.05.004\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"9f2653e6-d8fb-455a-ac07-31ffd86fbf52\",\n",
      "        \"shortid\": \"1de6o2bxxv\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches_publication/updated\": \"06/23/2022 03:07:23\",\n",
      "        \"matches_publication/authors\": \"Zeng H, Gifford DK\",\n",
      "        \"matches_publication/journal\": \"Cell Syst\",\n",
      "        \"matches_publication/title\": \"Quantification of Uncertainty in Peptide-MHC Binding Prediction Improves High-Affinity Peptide Selection for Therapeutic Design.\",\n",
      "        \"matches_optimization/algorithm\": \"\\\"44 different types of ML classification algorithms available in WEKA (v3.8.2)\\\"\",\n",
      "        \"matches_optimization/config\": \"Partially in the supplement: http://14.139.62.220/covidprognosis/supple.php\",\n",
      "        \"matches_optimization/encoding\": \"global features\",\n",
      "        \"matches_optimization/parameters\": \"no details provided, but p varies based on the models\",\n",
      "        \"matches_optimization/regularization\": \"no details provided\",\n",
      "        \"matches_model/availability\": \"only on the web: http://14.139.62.220/covidprognosis/\",\n",
      "        \"matches_model/interpretability\": \"transparent: identification of proteins associated with labels based on feature selection methods in WEKA\",\n",
      "        \"matches_model/output\": \"possibly both depending on the model\",\n",
      "        \"matches_evaluation/availability\": \"Confusion matrices in the supplement: http://14.139.62.220/covidprognosis/supple.php\",\n",
      "        \"matches_evaluation/comparison\": \"None, only the 44 different models used in the study were compared\",\n",
      "        \"matches_evaluation/measure\": \"MCC, Accuracy, Sensitivity, Specificity, area under ROC\",\n",
      "        \"matches_dataset/availability\": \"yes: https://www.olink.com/application/mgh-covid-19-study/ upon request\",\n",
      "        \"matches_dataset/provenance\": \"clinical and normalized protein expression profile data for 306 COVID-19 patients and 78 other patients (control) from the Olink website; 42 pos and 264 neg\",\n",
      "        \"matches_dataset/redundancy\": \"Not commented\",\n",
      "        \"matches_dataset/splits\": \"only LOOCV was used\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b49\",\n",
      "        \"publication_pmid\": \"31132080\",\n",
      "        \"publication_updated\": \"01/20/2022 15:22:27\",\n",
      "        \"publication_authors\": \"Bernacki DT, Bryce SM, Bemis JC, Dertinger SD\",\n",
      "        \"publication_journal\": \"Toxicol Sci\",\n",
      "        \"publication_title\": \"Aneugen Molecular Mechanism Assay: Proof-of-Concept With 27 Reference Chemicals.\",\n",
      "        \"publication_doi\": \"10.1093/toxsci/kfz123\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"f0595a6e-043d-4fb6-8569-dbdf82e84558\",\n",
      "        \"shortid\": \"l0wznwpm1x\",\n",
      "        \"score\": 0.33,\n",
      "        \"matches_publication/updated\": \"01/20/2022 15:22:27\",\n",
      "        \"matches_publication/authors\": \"Bernacki DT, Bryce SM, Bemis JC, Dertinger SD\",\n",
      "        \"matches_publication/journal\": \"Toxicol Sci\",\n",
      "        \"matches_publication/title\": \"Aneugen Molecular Mechanism Assay: Proof-of-Concept With 27 Reference Chemicals.\",\n",
      "        \"matches_optimization/algorithm\": \"Classification and Regression Tree\",\n",
      "        \"matches_optimization/features\": \"12 markers\",\n",
      "        \"matches_model/interpretability\": \"Transparent - Lipid peroxidation was the most important predictor of the changes in LDL levels\",\n",
      "        \"matches_dataset/provenance\": \"109 patients\",\n",
      "        \"matches_dataset/splits\": \"60% training 40% validation\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b4a\",\n",
      "        \"publication_pmid\": \"31871774\",\n",
      "        \"publication_updated\": \"01/25/2022 14:56:54\",\n",
      "        \"publication_authors\": \"Xu W, Xu M, Wang L, Zhou W, Xiang R, Shi Y, Zhang Y, Piao Y\",\n",
      "        \"publication_journal\": \"Signal Transduct Target Ther\",\n",
      "        \"publication_title\": \"Integrative analysis of DNA methylation and gene expression identified cervical cancer-specific diagnostic biomarkers.\",\n",
      "        \"publication_doi\": \"10.1038/s41392-019-0081-6\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"80e739c4-91d8-49a9-8620-1f876215ff63\",\n",
      "        \"shortid\": \"cqy67zmg5o\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches_publication/updated\": \"01/25/2022 14:56:54\",\n",
      "        \"matches_publication/authors\": \"Xu W, Xu M, Wang L, Zhou W, Xiang R, Shi Y, Zhang Y, Piao Y\",\n",
      "        \"matches_publication/journal\": \"Signal Transduct Target Ther\",\n",
      "        \"matches_publication/title\": \"Integrative analysis of DNA methylation and gene expression identified cervical cancer-specific diagnostic biomarkers.\",\n",
      "        \"matches_optimization/algorithm\": \"Random forest\",\n",
      "        \"matches_optimization/encoding\": \"K-mer featurization (k=3,4,5) scheme for 5'-UTR, CDS and 3'-UTR.\",\n",
      "        \"matches_optimization/fitting\": \"Risk of underfitting, since p=64 << N_total=2928.\",\n",
      "        \"matches_optimization/parameters\": \"p=sqrt(f)=64, where f is the number of features. \",\n",
      "        \"matches_model/availability\": \"Yes, GitHub https://github.com/wukevin/rnagps\",\n",
      "        \"matches_model/interpretability\": \"Interpretable. Interpretation performed via RF feature importance\",\n",
      "        \"matches_model/output\": \"Multi-class classification\",\n",
      "        \"matches_evaluation/comparison\": \"Basset (Kelley et al., 2016), RNATracker (Yan et al.,. 2019). Baselines implemented with other tree-based approaches (e.g XGBoost), neural networks, convolutional networks, recurrent networks (long-short term memory, gated recurrent units).\",\n",
      "        \"matches_evaluation/measure\": \"Accuracy, AUROC, AUPRC\",\n",
      "        \"matches_evaluation/method\": \"10-fold cross-validation. Independent dataset\",\n",
      "        \"matches_dataset/availability\": \"Raw APEX-seq data available at Gene Expression Omnibus (GEO) under accession GSE116008\",\n",
      "        \"matches_dataset/provenance\": \"Training data: Rnot reported localization data from  APEX-seq results available in literature (Fazal et al., 2019). Eight localization classes: N_c1=1223,N_c2=768,N_c3=301,N_c4=208,N_c5=1361,N_c6=823,N_c7=159,N_c8=739.  Independent test data: ENCODE Project Consortium 2012, cell line HeLa-S3: N=7641, cell line K562: N=6359. Individual class abundance in independent data is unknown\",\n",
      "        \"matches_dataset/redundancy\": \"Not handled\",\n",
      "        \"matches_dataset/splits\": \"N_train=80%,N_test=10%,N_val=10%. ENCODE data used for testing\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b4b\",\n",
      "        \"publication_pmid\": \"30448611\",\n",
      "        \"publication_updated\": \"01/26/2022 17:25:36\",\n",
      "        \"publication_authors\": \"Sun H, Paixao L, Oliva JT, Goparaju B, Carvalho DZ, van Leeuwen KG, Akeju O, Thomas RJ, Cash SS, Bianchi MT, Westover MB\",\n",
      "        \"publication_journal\": \"Neurobiol Aging\",\n",
      "        \"publication_title\": \"Brain age from the electroencephalogram of sleep.\",\n",
      "        \"publication_doi\": \"10.1016/j.neurobiolaging.2018.10.016\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"7ff7eafe-6d4e-4b8e-b924-ee81c0e447ff\",\n",
      "        \"shortid\": \"7rqpjvvf0w\",\n",
      "        \"score\": 0.48,\n",
      "        \"matches_publication/updated\": \"01/26/2022 17:25:36\",\n",
      "        \"matches_publication/authors\": \"Sun H, Paixao L, Oliva JT, Goparaju B, Carvalho DZ, van Leeuwen KG, Akeju O, Thomas RJ, Cash SS, Bianchi MT, Westover MB\",\n",
      "        \"matches_publication/journal\": \"Neurobiol Aging\",\n",
      "        \"matches_publication/title\": \"Brain age from the electroencephalogram of sleep.\",\n",
      "        \"matches_optimization/algorithm\": \"Random forest\",\n",
      "        \"matches_optimization/encoding\": \"MRI scans parceled into non-overlapping patches of V voxels. Patches represent nodes of a brain network, and the absolute values of Pearson\\u2019s correlation between patch pairs were considered the links between the node. Given N, the number of network nodes, 8N features for each subject\",\n",
      "        \"matches_optimization/features\": \"f=?. Feature selection by Random Forest\",\n",
      "        \"matches_model/interpretability\": \"Black box. Random forest used for feature seleciton\",\n",
      "        \"matches_model/output\": \"Binary classification\",\n",
      "        \"matches_evaluation/comparison\": \"Comparison with a standard baseline method based on Region-Of-Interest (ROI) segmentation\",\n",
      "        \"matches_evaluation/measure\": \"Sensitivity, Specificity, Accuracy, ROC-AUC\",\n",
      "        \"matches_evaluation/method\": \"Repeated 80%-20% cross-validation. No indipendent datasets\",\n",
      "        \"matches_dataset/provenance\": \"MRI scans of Traumatic Brain Injury (TBI) subjects recruited in EpiBioS4Rx. Npos=16, Nneg=37. Not previously used in literature.\",\n",
      "        \"matches_dataset/splits\": \"N_pos,train=13, N_neg_train=30, N_pos,test=3, N_neg_test=7. Not separate validation set.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b4c\",\n",
      "        \"publication_pmid\": \"30933970\",\n",
      "        \"publication_updated\": \"02/11/2022 10:17:27\",\n",
      "        \"publication_authors\": \"Liang C, Yu S, Luo J\",\n",
      "        \"publication_journal\": \"PLoS Comput Biol\",\n",
      "        \"publication_title\": \"Adaptive multi-view multi-label learning for identifying disease-associated candidate miRNAs.\",\n",
      "        \"publication_doi\": \"10.1371/journal.pcbi.1006931\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"3cb70f9b-d503-4330-9b57-4a893f11f3b0\",\n",
      "        \"shortid\": \"p75y9vrkgn\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches_publication/updated\": \"02/11/2022 10:17:27\",\n",
      "        \"matches_publication/authors\": \"Liang C, Yu S, Luo J\",\n",
      "        \"matches_publication/journal\": \"PLoS Comput Biol\",\n",
      "        \"matches_publication/title\": \"Adaptive multi-view multi-label learning for identifying disease-associated candidate miRNAs.\",\n",
      "        \"matches_optimization/algorithm\": \"SVM, Adaboost with decision trees, Ensemble KNN, Random forest\",\n",
      "        \"matches_optimization/encoding\": \"some data were transformed either by binning or one-hot encoding .  \",\n",
      "        \"matches_optimization/features\": \"It's is unclear which features are exactly used. There is no clear summary table.  They used clinical test and patient data next to protein concentration information (HMGB1, NFL, p-181-tau).  Missing values were filled up with K-NN imputation.  They examine always 7 models (in terms of the feature set used), M1 is only clinical data the others use M1 plus a subset of the 3 proteins.\",\n",
      "        \"matches_optimization/fitting\": \"number if features is smaller than number of samples. Cross-validation (I assume with random splits) to avoid over-fitting.\",\n",
      "        \"matches_optimization/meta\": \"No, all raw data\",\n",
      "        \"matches_optimization/parameters\": \"They are not reported (number of KNN in the ensemble, RF settings, adaboost)\",\n",
      "        \"matches_optimization/regularization\": \"no validation set used.\",\n",
      "        \"matches_model/interpretability\": \"They performed a feature importance analysis for the best models (M3 and M4) and showed partial dependency plots between classification and a series ofd features. No details on how this was produced.\",\n",
      "        \"matches_model/output\": \"classification in two classes (impaired versus normal)\",\n",
      "        \"matches_evaluation/comparison\": \"4 different methods were compared. No comparison with other method on their data.\",\n",
      "        \"matches_evaluation/confidence\": \"paired t-test with p<0.05\",\n",
      "        \"matches_evaluation/measure\": \"area under the curve\",\n",
      "        \"matches_evaluation/method\": \"cross validation\",\n",
      "        \"matches_dataset/availability\": \"data is not reported.\",\n",
      "        \"matches_dataset/provenance\": \"In house produce experimental and clinical data (neurophysiological tests, age, education, ethnicity.  20 normal  and 40 neurologically impaired patients. New data not used in other studies.\",\n",
      "        \"matches_dataset/redundancy\": \"not reported, although they claim that data leakage (which I assume is bad stratification) between folds was precluded.  No details on how.  I assume random fold separation, hence the 10 times repetition.\",\n",
      "        \"matches_dataset/splits\": \"They employed 6-fold cross-validation (repeated 10 times), not needing split between training and test set.  they did not provide a validation set.  Pos=40, Neg=20 patients.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b4d\",\n",
      "        \"publication_pmid\": \"30769139\",\n",
      "        \"publication_updated\": \"03/09/2022 09:50:58\",\n",
      "        \"publication_authors\": \"Kargarfard F, Sami A, Hemmatzadeh F, Ebrahimie E\",\n",
      "        \"publication_journal\": \"Gene\",\n",
      "        \"publication_title\": \"Identifying mutation positions in all segments of influenza genome enables better differentiation between pandemic and seasonal strains.\",\n",
      "        \"publication_doi\": \"10.1016/j.gene.2019.01.014\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"5d549370-43e5-4163-977c-59e9d5cadf79\",\n",
      "        \"shortid\": \"iugmhjifoe\",\n",
      "        \"score\": 0.52,\n",
      "        \"matches_publication/updated\": \"03/09/2022 09:50:58\",\n",
      "        \"matches_publication/authors\": \"Kargarfard F, Sami A, Hemmatzadeh F, Ebrahimie E\",\n",
      "        \"matches_publication/title\": \"Identifying mutation positions in all segments of influenza genome enables better differentiation between pandemic and seasonal strains.\",\n",
      "        \"matches_optimization/algorithm\": \"Novel approach called BioConceptVec. The paper explains why they used a novel approach\",\n",
      "        \"matches_optimization/config\": \"Yes, available at URL: https://github.com/ncbi/BioConceptVec\",\n",
      "        \"matches_model/availability\": \"Yes, available at URL: https://github.com/ncbi/BioConceptVec\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/comparison\": \"Compared with other methods (BioAgvWord and \\\"Yu et al.\\\")\",\n",
      "        \"matches_evaluation/confidence\": \"No confidence interval\",\n",
      "        \"matches_evaluation/measure\": \"Precision, Recall, F1-score, Area Under Curve (AUC)\",\n",
      "        \"matches_evaluation/method\": \"Intrinsic and Extrinsic evaluation from 9 independent datasets\",\n",
      "        \"matches_dataset/availability\": \"Yes. Dataset available at URL: https://github.com/ncbi/BioConceptVec\",\n",
      "        \"matches_dataset/provenance\": \"Only one dataset employed, created using all PubMed abastracts \"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b4e\",\n",
      "        \"publication_pmid\": \"31404081\",\n",
      "        \"publication_updated\": \"03/29/2022 01:42:53\",\n",
      "        \"publication_authors\": \"Ledezma CA, Zhou X, Rodr\\u00edguez B, Tan PJ, D\\u00edaz-Zuccarini V\",\n",
      "        \"publication_journal\": \"PLoS One\",\n",
      "        \"publication_title\": \"A modeling and machine learning approach to ECG feature engineering for the detection of ischemia using pseudo-ECG.\",\n",
      "        \"publication_doi\": \"10.1371/journal.pone.0220294\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"f2fcb740-5dca-4b4c-b5e1-8ea073ecc3e0\",\n",
      "        \"shortid\": \"lohsb5kzme\",\n",
      "        \"score\": 0.9,\n",
      "        \"matches_publication/updated\": \"03/29/2022 01:42:53\",\n",
      "        \"matches_publication/authors\": \"Ledezma CA, Zhou X, Rodr\\u00edguez B, Tan PJ, D\\u00edaz-Zuccarini V\",\n",
      "        \"matches_publication/journal\": \"PLoS One\",\n",
      "        \"matches_publication/title\": \"A modeling and machine learning approach to ECG feature engineering for the detection of ischemia using pseudo-ECG.\",\n",
      "        \"matches_optimization/algorithm\": \" SVM, RF, XGBoost for feature ranking\",\n",
      "        \"matches_optimization/config\": \"yes: https://github.com/taigangliu/HMMPred\",\n",
      "        \"matches_optimization/encoding\": \"global features were derived from sequece-based features by averaging over protein length\",\n",
      "        \"matches_optimization/features\": \"a range from 420 to 4020 was tested; 2000 in the final model\",\n",
      "        \"matches_optimization/fitting\": \"a range of feature numbers was tested based on CVs; XGBoost feature ranking\",\n",
      "        \"matches_optimization/parameters\": \"p = f+3 for SVM,  \",\n",
      "        \"matches_optimization/regularization\": \"included in SVM (margin maximisation)\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"binary classification\",\n",
      "        \"matches_evaluation/availability\": \"no raw evaluation files\",\n",
      "        \"matches_evaluation/comparison\": \"comparisons with some existing predictors on the same datasets: DNAbinder, DNA-Prot, iDNA-Prot, iDNA-Prot|dis, Kmer1+ACC, iDNAPro-PseAAC, PseDNA-Pro, Local-DPP, HMMBinder\",\n",
      "        \"matches_evaluation/measure\": \"Accuracy, sensitivity, specificity, MCC, AUC\",\n",
      "        \"matches_evaluation/method\": \"Cross-validation, independent dataset\",\n",
      "        \"matches_dataset/availability\": \"yes, https://github.com/taigangliu/HMMPred\",\n",
      "        \"matches_dataset/provenance\": \"Two published datasets from literature: PDB1075 (525 pos and 550 neg) and PDB186 (93 pos and 93 neg)\",\n",
      "        \"matches_dataset/redundancy\": \"sequences with more than 25% sequence similarity were removed\",\n",
      "        \"matches_dataset/splits\": \"training: 525 pos / 550 neg; validation: 10-fold CV and jackknife CV; testing: 93 pos / 93 neg\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b56\",\n",
      "        \"publication_pmid\": \"31362694\",\n",
      "        \"publication_updated\": \"03/13/2022 11:00:59\",\n",
      "        \"publication_authors\": \"Wang J, Gribskov M\",\n",
      "        \"publication_journal\": \"BMC Bioinformatics\",\n",
      "        \"publication_title\": \"IRESpy: an XGBoost model for prediction of internal ribosome entry sites.\",\n",
      "        \"publication_doi\": \"10.1186/s12859-019-2999-7\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"17ff2958-4461-4d8f-9c75-f7e3992a9bde\",\n",
      "        \"shortid\": \"i4p484v6d2\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches_publication/updated\": \"03/13/2022 11:00:59\",\n",
      "        \"matches_publication/authors\": \"Wang J, Gribskov M\",\n",
      "        \"matches_publication/journal\": \"BMC Bioinformatics\",\n",
      "        \"matches_publication/title\": \"IRESpy: an XGBoost model for prediction of internal ribosome entry sites.\",\n",
      "        \"matches_optimization/algorithm\": \"One class logistic regression. \",\n",
      "        \"matches_optimization/encoding\": \"Cox regression analysis, least absolute shrinkage and selection operator (lasso), and Akaike information criterion (AIC) were used to identify the relevant genes to train the logistic regression model.\",\n",
      "        \"matches_optimization/features\": \"8 input features selected using Cox regression analysis, least absolute shrinkage and selection operator (lasso), and Akaike information criterion (AIC)\",\n",
      "        \"matches_optimization/fitting\": \"Not clearly stated, but could be inferred from the text that p is smaller than N. \",\n",
      "        \"matches_optimization/parameters\": \"Not clearly stated, could be inferred from the text.\",\n",
      "        \"matches_model/interpretability\": \"Transparent. The model generates a risk score according to the expression of the 8 selected genes.\",\n",
      "        \"matches_evaluation/comparison\": \"The method was not compared to others.\",\n",
      "        \"matches_evaluation/measure\": \"area under curve (AUC)\",\n",
      "        \"matches_evaluation/method\": \"Independent dataset (using Dataset 2)\",\n",
      "        \"matches_dataset/availability\": \"Dataset 1: Yes. URL: https://portal.gdc.cancer.gov/projects/TCGA-HNSC\\n\\nDataset 2: Yes. URL: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE41613 \",\n",
      "        \"matches_dataset/provenance\": \"Dataset 1: Rnot reported-Seq data from The Cancer Genome Atlas for Head and Neck Squamous Cell Carcinoma (TGCA-HNSCC). N = 544; N_pos (survived patients) = 211, N_neg (not survived patients) = 280. Used in the community.\\n\\nDataset 2: GSE41613 from the Gene Expression Omnibus (GEO). N = 97; N_pos (survived patients) = 46, N_neg (not survived patients) = 50. Used in the community.\",\n",
      "        \"matches_dataset/redundancy\": \"Dataset 1 and Dataset 2 are independent\",\n",
      "        \"matches_dataset/splits\": \"Dataset 1: splitted in 50% for training and 50% for test. Split was conducted randomly. N_pos and N_neg for each subset not reported\\n\\nDataset 2: entirely used for test.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b6b\",\n",
      "        \"publication_pmid\": \"31466478\",\n",
      "        \"publication_updated\": \"01/28/2022 21:38:37\",\n",
      "        \"publication_authors\": \"Bollepalli S, Korhonen T, Kaprio J, Anders S, Ollikainen M\",\n",
      "        \"publication_journal\": \"Epigenomics\",\n",
      "        \"publication_title\": \"EpiSmokEr: a robust classifier to determine smoking status from DNA methylation data.\",\n",
      "        \"publication_doi\": \"10.2217/epi-2019-0206\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"62a0f5bf-1440-4bce-855f-1beedf6af6f5\",\n",
      "        \"shortid\": \"dnrghw65xy\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches_publication/updated\": \"01/28/2022 21:38:37\",\n",
      "        \"matches_publication/authors\": \"Bollepalli S, Korhonen T, Kaprio J, Anders S, Ollikainen M\",\n",
      "        \"matches_publication/title\": \"EpiSmokEr: a robust classifier to determine smoking status from DNA methylation data.\",\n",
      "        \"matches_optimization/config\": \"Hyperparameter values reported in the paper. Model available in bitbucket (https://bitbucket.org/alexeyg-com/irespredictor/src/v2/)\",\n",
      "        \"matches_optimization/encoding\": \"340 global kmer features + 5440 local kmer features\",\n",
      "        \"matches_optimization/features\": \"The final model includes 1281 individual trees and each tree incorporates 340 features. Features selected by XGBoost feature importance\",\n",
      "        \"matches_optimization/parameters\": \"The final model includes 1281 individual trees and each tree incorporates 340 features. The\\nmaximum depth of each tree is set to be 6\",\n",
      "        \"matches_model/availability\": \"Model available on bitbucket (https://bitbucket.org/alexeyg-com/irespredictor/src/v2/)\",\n",
      "        \"matches_model/interpretability\": \"Feature interpreted by XGBoost feature importance\",\n",
      "        \"matches_evaluation/comparison\": \"Compared with IRESpred\",\n",
      "        \"matches_evaluation/measure\": \"Accuracy, sensitivity, specificity, precision, Matthews correlation\",\n",
      "        \"matches_evaluation/method\": \"Independent set\",\n",
      "        \"matches_dataset/availability\": \"Bitbucket available (https://bitbucket.org/alexeyg-com/irespredictor/src). Datasets non clearly labelled\",\n",
      "        \"matches_dataset/provenance\": \"Training dataset (dataset 2): high throughput experimental data (doi: 10.1126/science.aad4939), filtered and annotated as in (doi:10.1371/journal.pcbi.1005734) describing an available predictor. \\n20872 examples: 2129 positive, 18743 negative.\\nTesting dataset (dataset 1): low throughput experimental data extracted from a public database (https://doi. org/10.1093/nar/gkp981).\\n167 examples: 116 positive, 51 negative.\",\n",
      "        \"matches_dataset/redundancy\": \"Random split. Overall similarity in the dataset 2 was checked: 7.56% sequences have more\\nthan 80% identity, 15.3% sequences have more than 50% identity, and 17.02% sequences have more than 30% identity. There are no sequences with 100% identity-\\nSimilarity between dataset 1 and dataset 2 is not reported\",\n",
      "        \"matches_dataset/splits\": \"Random split of dataset 2 in 90% training and 10% testing.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b6c\",\n",
      "        \"publication_pmid\": \"30970017\",\n",
      "        \"publication_updated\": \"03/04/2022 17:32:12\",\n",
      "        \"publication_authors\": \"Conti S, Karplus M\",\n",
      "        \"publication_journal\": \"PLoS Comput Biol\",\n",
      "        \"publication_title\": \"Estimation of the breadth of CD4bs targeting HIV antibodies by molecular modeling and machine learning.\",\n",
      "        \"publication_doi\": \"10.1371/journal.pcbi.1006954\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"036db907-b055-40cb-b38e-3b1ef226ba31\",\n",
      "        \"shortid\": \"nfh7iw73hz\",\n",
      "        \"score\": 0.57,\n",
      "        \"matches_publication/updated\": \"03/04/2022 17:32:12\",\n",
      "        \"matches_publication/authors\": \"Conti S, Karplus M\",\n",
      "        \"matches_publication/journal\": \"PLoS Comput Biol\",\n",
      "        \"matches_publication/title\": \"Estimation of the breadth of CD4bs targeting HIV antibodies by molecular modeling and machine learning.\",\n",
      "        \"matches_optimization/algorithm\": \"DT, CBA, Ripper\",\n",
      "        \"matches_optimization/encoding\": \"global features (multiple sequence alignment)\",\n",
      "        \"matches_optimization/features\": \"f = protein sequence length (200-900)\",\n",
      "        \"matches_model/interpretability\": \"transparent: biological interpretation of identified rules (mutations)\",\n",
      "        \"matches_model/output\": \"probability score\",\n",
      "        \"matches_evaluation/confidence\": \"None for evaluation\",\n",
      "        \"matches_evaluation/method\": \"mysterious \\\"test set\\\" mentioned only once\",\n",
      "        \"matches_dataset/availability\": \"yes: supporting information\",\n",
      "        \"matches_dataset/provenance\": \"new database search in Influenza Research Database; 10 protein datasets with 4240-5373 data points (around 2/3 are pos and 1/3 are neg in each dataset) \",\n",
      "        \"matches_dataset/redundancy\": \"none reported\",\n",
      "        \"matches_dataset/splits\": \"There is a mysterious \\\"test data\\\" set mentioned only once without any additional information.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b6d\",\n",
      "        \"publication_pmid\": \"30857591\",\n",
      "        \"publication_updated\": \"03/08/2022 17:16:35\",\n",
      "        \"publication_authors\": \"Tubiana J, Cocco S, Monasson R\",\n",
      "        \"publication_journal\": \"Elife\",\n",
      "        \"publication_title\": \"Learning protein constitutive motifs from sequence data.\",\n",
      "        \"publication_doi\": \"10.7554/eLife.39397\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"0e3da6d0-101b-4136-926f-f122310fb98c\",\n",
      "        \"shortid\": \"v9brv84km1\",\n",
      "        \"score\": 0.86,\n",
      "        \"matches_publication/updated\": \"03/08/2022 17:16:35\",\n",
      "        \"matches_publication/authors\": \"Tubiana J, Cocco S, Monasson R\",\n",
      "        \"matches_publication/title\": \"Learning protein constitutive motifs from sequence data.\",\n",
      "        \"matches_optimization/algorithm\": \"Restricted Boltzmann Machines\",\n",
      "        \"matches_optimization/config\": \"yes: https://github.com/jertubiana/ProteinMotifRBM\",\n",
      "        \"matches_optimization/encoding\": \"aligned sequences\",\n",
      "        \"matches_optimization/features\": \"MxNx21 where M is length and N is width of an MSA\",\n",
      "        \"matches_optimization/fitting\": \"regularisation and model selection used\",\n",
      "        \"matches_optimization/parameters\": \"not given explicitly, a different number of hidden units (1-400) were tested\",\n",
      "        \"matches_optimization/regularization\": \"L2 and L2/L1\",\n",
      "        \"matches_model/availability\": \"yes: https://github.com/jertubiana/ProteinMotifRBM\",\n",
      "        \"matches_model/duration\": \"in the order of 1\\u20132 days on an Intel Xeon Phi processor with 2 \\u00d7 28 cores\",\n",
      "        \"matches_model/interpretability\": \"yes: weights are interrelated for various case studies\",\n",
      "        \"matches_model/output\": \"probability score\",\n",
      "        \"matches_evaluation/comparison\": \"performance was compared to direct coupling-based methods, namely the Pseudo-Likelihood Method (plmDCA) and Boltzmann Machine (BM)\",\n",
      "        \"matches_evaluation/measure\": \"PPV, accuracy (contact prediction task)\",\n",
      "        \"matches_evaluation/method\": \"independent test (20% of initial data)\",\n",
      "        \"matches_dataset/availability\": \"yes: https://github.com/jertubiana/ProteinMotifRBM\",\n",
      "        \"matches_dataset/provenance\": \"supervised (contact prediction): 18 sets of multiple sequence alignments from pfam database + contact maps based on pdbs; \",\n",
      "        \"matches_dataset/redundancy\": \"Reweighting procedure is applied: each sequence is assigned a weight equal to the inverse of the number of sequences with more than 90% identity\",\n",
      "        \"matches_dataset/splits\": \"train/test: 80%/20% at random \"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b6e\",\n",
      "        \"publication_pmid\": \"31479437\",\n",
      "        \"publication_updated\": \"03/28/2022 12:30:56\",\n",
      "        \"publication_authors\": \"Picart-Armada S, Barrett SJ, Will\\u00e9 DR, Perera-Lluna A, Gutteridge A, Dessailly BH\",\n",
      "        \"publication_journal\": \"PLoS Comput Biol\",\n",
      "        \"publication_title\": \"Benchmarking network propagation methods for disease gene identification.\",\n",
      "        \"publication_doi\": \"10.1371/journal.pcbi.1007276\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"73502b02-ed6c-48e0-9ab6-148d33d45944\",\n",
      "        \"shortid\": \"imwu5xtkc9\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"03/28/2022 12:30:56\",\n",
      "        \"matches_publication/authors\": \"Picart-Armada S, Barrett SJ, Will\\u00e9 DR, Perera-Lluna A, Gutteridge A, Dessailly BH\",\n",
      "        \"matches_publication/journal\": \"PLoS Comput Biol\",\n",
      "        \"matches_publication/title\": \"Benchmarking network propagation methods for disease gene identification.\",\n",
      "        \"matches_optimization/algorithm\": \"Kernel maximum mean discrepancy to select features + RF\",\n",
      "        \"matches_optimization/encoding\": \"global features\",\n",
      "        \"matches_optimization/features\": \" expression data of 23368 genes\",\n",
      "        \"matches_optimization/parameters\": \"non-parametric method (it seems)\",\n",
      "        \"matches_optimization/regularization\": \"None mentioned\",\n",
      "        \"matches_model/availability\": \"Barely: https://github.com/Zhixun-Zhao/GeneMarker\",\n",
      "        \"matches_model/interpretability\": \"transparent: identification of marker genes for lung cancer\",\n",
      "        \"matches_evaluation/availability\": \"yes: supporting information\",\n",
      "        \"matches_evaluation/comparison\": \"comparison with conventional t-test and fold change methods\",\n",
      "        \"matches_evaluation/measure\": \"Recall, F1, Accuracy, MCC\",\n",
      "        \"matches_evaluation/method\": \"10-fold CV\",\n",
      "        \"matches_dataset/availability\": \"NCBI Gene Expression Om-nibus (https://www.ncbi.nlm.nih.gov/geo/): GSE86354 and GSE62944\",\n",
      "        \"matches_dataset/provenance\": \"Three classes are three gene expression datasets collected before: 373 normal, 59 normal adjacent to tumour, and 541 tumour patients\",\n",
      "        \"matches_dataset/redundancy\": \"None checked\",\n",
      "        \"matches_dataset/splits\": \"10-fold CV\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b88\",\n",
      "        \"publication_pmid\": \"31874628\",\n",
      "        \"publication_updated\": \"02/23/2022 14:14:06\",\n",
      "        \"publication_authors\": \"Kim T, Lo K, Geddes TA, Kim HJ, Yang JYH, Yang P\",\n",
      "        \"publication_journal\": \"BMC Genomics\",\n",
      "        \"publication_title\": \"scReClassify: post hoc cell type classification of single-cell rNA-seq data.\",\n",
      "        \"publication_doi\": \"10.1186/s12864-019-6305-x\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"96990d27-f206-43f3-ac18-2c14125e545c\",\n",
      "        \"shortid\": \"kbejtqvi3h\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches_publication/updated\": \"02/23/2022 14:14:06\",\n",
      "        \"matches_publication/authors\": \"Kim T, Lo K, Geddes TA, Kim HJ, Yang JYH, Yang P\",\n",
      "        \"matches_publication/journal\": \"BMC Genomics\",\n",
      "        \"matches_publication/title\": \"scReClassify: post hoc cell type classification of single-cell rNA-seq data.\",\n",
      "        \"matches_optimization/algorithm\": \"Bayesian, Support Vector Machine and Recursive Partitioning Forest\",\n",
      "        \"matches_optimization/config\": \"Configuration avalailble in the supplementary material. models available http://molsync.com/ebola/ (link not working)\",\n",
      "        \"matches_optimization/encoding\": \"Molecular descriptors: molecular function class fingerprints of maximum diameter 6 (FCFP_6), AlogP, molecular weight, number of rotatable bonds, number of rings, number of aromatic rings, number of hydrogen bond acceptors, number of hydrogen bond donors, and molecular fractional polar surface area\",\n",
      "        \"matches_optimization/fitting\": \"Number of training examples is at least twice p_svm. Reduced risk of over- and under-fitting\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"Binary classification\",\n",
      "        \"matches_evaluation/availability\": \"Partially available in supplementary material\",\n",
      "        \"matches_evaluation/measure\": \"ROC-AUC, Confusion matrix, Sensitivity, Specificty\",\n",
      "        \"matches_evaluation/method\": \"5-fold Cross-validation and Leave out 50% \\u00d7 100 fold cross validation. No independent test.\",\n",
      "        \"matches_dataset/availability\": \"Yes, http://molsync.com/ebola/ (link not working)\",\n",
      "        \"matches_dataset/provenance\": \"Dataset from literature (Madrid et al., 2013; Madrid et al., 2015). N_pos=41, N_neg=653\",\n",
      "        \"matches_dataset/splits\": \"5-Fold Cross-validation split: N_pos_train ~= 33, N_neg_train ~= 522, N_pos_test ~= 8, N_neg_test ~= 131. Leave out 50% \\u00d7 100 fold cross validation: N_pos_train ~= 20, N_neg_train ~= 327, N_pos_test ~= 20, N_neg_test ~= 327\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b89\",\n",
      "        \"publication_pmid\": \"31856830\",\n",
      "        \"publication_updated\": \"03/08/2022 14:15:46\",\n",
      "        \"publication_authors\": \"Zhao Z, Peng H, Zhang X, Zheng Y, Chen F, Fang L, Li J\",\n",
      "        \"publication_journal\": \"BMC Med Genomics\",\n",
      "        \"publication_title\": \"Identification of lung cancer gene markers through kernel maximum mean discrepancy and information entropy.\",\n",
      "        \"publication_doi\": \"10.1186/s12920-019-0630-4\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"0f6385d3-bd3b-4257-b8e8-3289261b719f\",\n",
      "        \"shortid\": \"b9ln75l2jr\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"03/08/2022 14:15:46\",\n",
      "        \"matches_publication/authors\": \"Zhao Z, Peng H, Zhang X, Zheng Y, Chen F, Fang L, Li J\",\n",
      "        \"matches_publication/journal\": \"BMC Med Genomics\",\n",
      "        \"matches_publication/title\": \"Identification of lung cancer gene markers through kernel maximum mean discrepancy and information entropy.\",\n",
      "        \"matches_optimization/algorithm\": \"Logistic regression, KNN, LDA, DT, RF, Gaussian processes (GP-ARD)\",\n",
      "        \"matches_optimization/config\": \"partially: supplement\",\n",
      "        \"matches_optimization/encoding\": \"global features\",\n",
      "        \"matches_optimization/fitting\": \"a range of different model types was tested\",\n",
      "        \"matches_optimization/parameters\": \"various but equal to f in most cases\",\n",
      "        \"matches_optimization/regularization\": \"for some predictors, e.g. Lasso for logistic regression\",\n",
      "        \"matches_model/interpretability\": \"transparent: identification of the main biomarkers\",\n",
      "        \"matches_model/output\": \"both, depending on the model used\",\n",
      "        \"matches_evaluation/comparison\": \"only among the models in the paper\",\n",
      "        \"matches_evaluation/measure\": \"sensitivity, specificity, accuracy, AUROC\",\n",
      "        \"matches_dataset/availability\": \"No, only ClinicalTrials.gov identifier: NCT01717573\",\n",
      "        \"matches_dataset/provenance\": \"clinical trials, 11 pos and 27 neg\",\n",
      "        \"matches_dataset/splits\": \"LOOCV for testing and internal LOOCV or 5-fold CV for validation\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b8a\",\n",
      "        \"publication_pmid\": \"31308377\",\n",
      "        \"publication_updated\": \"03/28/2022 20:10:36\",\n",
      "        \"publication_authors\": \"Mourikis TP, Benedetti L, Foxall E, Temelkovski D, Nulsen J, Perner J, Cereda M, Lagergren J, Howell M, Yau C, Fitzgerald RC, Scaffidi P, Oesophageal Cancer Clinical and Molecular Stratification (OCCAMS) Consortium., Ciccarelli FD\",\n",
      "        \"publication_journal\": \"Nat Commun\",\n",
      "        \"publication_title\": \"Patient-specific cancer genes contribute to recurrently perturbed pathways and establish therapeutic vulnerabilities in esophageal adenocarcinoma.\",\n",
      "        \"publication_doi\": \"10.1038/s41467-019-10898-3\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"2c4e1331-5d62-4abc-a990-d4cea1bea700\",\n",
      "        \"shortid\": \"1r4k25lx15\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches_publication/updated\": \"03/28/2022 20:10:36\",\n",
      "        \"matches_publication/authors\": \"Mourikis TP, Benedetti L, Foxall E, Temelkovski D, Nulsen J, Perner J, Cereda M, Lagergren J, Howell M, Yau C, Fitzgerald RC, Scaffidi P, Oesophageal Cancer Clinical and Molecular Stratification (OCCAMS) Consortium., Ciccarelli FD\",\n",
      "        \"matches_publication/journal\": \"Nat Commun\",\n",
      "        \"matches_publication/title\": \"Patient-specific cancer genes contribute to recurrently perturbed pathways and establish therapeutic vulnerabilities in esophageal adenocarcinoma.\",\n",
      "        \"matches_optimization/algorithm\": \"hidden Markov models were trained for each class\",\n",
      "        \"matches_optimization/encoding\": \"moving average window\",\n",
      "        \"matches_optimization/features\": \"22 discrete intervals\",\n",
      "        \"matches_optimization/fitting\": \"testing various sizes of the moving average window\",\n",
      "        \"matches_optimization/parameters\": \"not clear\",\n",
      "        \"matches_model/availability\": \"partially in the supplement\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"probability scores\",\n",
      "        \"matches_evaluation/confidence\": \"Yes: SDs are given for each accuracy estimates\",\n",
      "        \"matches_dataset/provenance\": \"Recorded FFRs to 4 Mandarin tones from 28 people\",\n",
      "        \"matches_dataset/redundancy\": \"\\\"To avoid stimulus artifact bias, training and testing subsets alternated the same number of trials with opposite stimulus polarity\\\"\",\n",
      "        \"matches_dataset/splits\": \"K-fold CV of varying K for each tone separately (a version of unsupervised learning)\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b8b\",\n",
      "        \"publication_pmid\": \"31148311\",\n",
      "        \"publication_updated\": \"03/30/2022 16:46:29\",\n",
      "        \"publication_authors\": \"Jing R, Li P, Ding Z, Lin X, Zhao R, Shi L, Yan H, Liao J, Zhuo C, Lu L, Fan Y\",\n",
      "        \"publication_journal\": \"Hum Brain Mapp\",\n",
      "        \"publication_title\": \"Machine learning identifies unaffected first-degree relatives with functional network patterns and cognitive impairment similar to those of schizophrenia patients.\",\n",
      "        \"publication_doi\": \"10.1002/hbm.24678\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"fcd15280-77b1-4526-b2fc-1a1b8987db42\",\n",
      "        \"shortid\": \"nl91j0uju5\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches_publication/updated\": \"03/30/2022 16:46:29\",\n",
      "        \"matches_publication/authors\": \"Jing R, Li P, Ding Z, Lin X, Zhao R, Shi L, Yan H, Liao J, Zhuo C, Lu L, Fan Y\",\n",
      "        \"matches_publication/journal\": \"Hum Brain Mapp\",\n",
      "        \"matches_publication/title\": \"Machine learning identifies unaffected first-degree relatives with functional network patterns and cognitive impairment similar to those of schizophrenia patients.\",\n",
      "        \"matches_optimization/algorithm\": \"SVM with RBF kernel\",\n",
      "        \"matches_optimization/features\": \"Yes, SMILES Chem structures with 250 fragments selected by MI\",\n",
      "        \"matches_optimization/regularization\": \"Yes - intrinsic to SVM\",\n",
      "        \"matches_model/interpretability\": \"Black box but voting schema is applied\",\n",
      "        \"matches_evaluation/comparison\": \"Local baseline\",\n",
      "        \"matches_evaluation/method\": \"Cross validation\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b98\",\n",
      "        \"publication_pmid\": \"31534955\",\n",
      "        \"publication_updated\": \"01/28/2022 14:49:16\",\n",
      "        \"publication_authors\": \"Jiang HJ, Huang YA, You ZH\",\n",
      "        \"publication_journal\": \"Biomed Res Int\",\n",
      "        \"publication_title\": \"Predicting Drug-Disease Associations via Using Gaussian Interaction Profile and Kernel-Based Autoencoder.\",\n",
      "        \"publication_doi\": \"10.1155/2019/2426958\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"4fa6c779-0e82-43a8-8a08-65a2feaa0bad\",\n",
      "        \"shortid\": \"9t9rwycfgl\",\n",
      "        \"score\": 0.86,\n",
      "        \"matches_publication/updated\": \"01/28/2022 14:49:16\",\n",
      "        \"matches_publication/authors\": \"Jiang HJ, Huang YA, You ZH\",\n",
      "        \"matches_publication/journal\": \"Biomed Res Int\",\n",
      "        \"matches_publication/title\": \"Predicting Drug-Disease Associations via Using Gaussian Interaction Profile and Kernel-Based Autoencoder.\",\n",
      "        \"matches_optimization/algorithm\": \"1) Elastic net linear model for affinity prediction, 2) linear regression models (linear and logistic) and neural network for pose prediction (active versus decoy).  The linear model was submitted for D3R\",\n",
      "        \"matches_optimization/encoding\": \"1) training data is transformed into Boolean fingerprints, 2) training data for classifier is translated into numerical vectors\",\n",
      "        \"matches_optimization/features\": \"no feature selection was performed. 2) classifier has 61 features and 1) size of bit pattern defines number of features in the regressor (2048 or more)\",\n",
      "        \"matches_optimization/fitting\": \"classifier has less parameters than samples.  \",\n",
      "        \"matches_optimization/meta\": \"They use a number of other methods to infer the feature that are used by the regressor and classification algorithm.  Not clerk what the overlap is.\",\n",
      "        \"matches_optimization/parameters\": \"1) two parameters alpha and rho. 2) 1 for regressor and 20 hidden node/2 output node NN.decay and momentum parameters for training the network.\",\n",
      "        \"matches_optimization/regularization\": \"Cross-validation performed to determine the generalisation of the predictions.\",\n",
      "        \"matches_model/duration\": \"not mentioned but linear regression is fast\",\n",
      "        \"matches_model/interpretability\": \"the weights of the regressor explain the importance of the features. The NN is black box\",\n",
      "        \"matches_evaluation/comparison\": \"they compare only their own approaches\",\n",
      "        \"matches_evaluation/confidence\": \"confidence bars given in bart plots. Significance is mentioned but no p-values are provided\",\n",
      "        \"matches_evaluation/measure\": \"only AUC\",\n",
      "        \"matches_evaluation/method\": \"Cross-validation when training the classifiers and the test set is independent as it is provided by the D3R challenge\",\n",
      "        \"matches_dataset/availability\": \"they do not provide themselves the data they used in their regressor and classifier.\",\n",
      "        \"matches_dataset/provenance\": \"1) regression data : 355 compounds from ChEMBL bioactivity database for training the regressor, 2) classification data : DUD-E dataset (102 target proteins, 20000 active molecules and more than a million decoy molecules); classes active/decoy. The validation/testing of the predictive methods is done on the D3R data form HSP90 and MAP4K4. They generate 29K poses for the former to test their predictors and 5329 poses for the latter. No mention of which ones are active fits and which ones are decoys. \",\n",
      "        \"matches_dataset/redundancy\": \"The DUD-E set consists of a HSP90 target.  the authors make an independent set with this information, I assume to checkt the influence of the presence of this information own the classification.\",\n",
      "        \"matches_dataset/splits\": \"The training and test set are completely separate (see explanations above).  Note imbalance in dataset for the classifier, which they overcome by also creating a balanced dataset for training. In the HSP90 test set there were 136 active and 44 inactive compounds (threshold set by authors on affinity).\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b99\",\n",
      "        \"publication_pmid\": \"31659164\",\n",
      "        \"publication_updated\": \"06/26/2022 22:26:24\",\n",
      "        \"publication_authors\": \"Akerberg BN, Gu F, VanDusen NJ, Zhang X, Dong R, Li K, Zhang B, Zhou B, Sethi I, Ma Q, Wasson L, Wen T, Liu J, Dong K, Conlon FL, Zhou J, Yuan GC, Zhou P, Pu WT\",\n",
      "        \"publication_journal\": \"Nat Commun\",\n",
      "        \"publication_title\": \"A reference map of murine cardiac transcription factor chromatin occupancy identifies dynamic and conserved enhancers.\",\n",
      "        \"publication_doi\": \"10.1038/s41467-019-12812-3\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"2d650333-5e1b-4cc3-a7bb-512a00abfce0\",\n",
      "        \"shortid\": \"m6t40hhxhx\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches_publication/updated\": \"06/26/2022 22:26:24\",\n",
      "        \"matches_publication/authors\": \"Akerberg BN, Gu F, VanDusen NJ, Zhang X, Dong R, Li K, Zhang B, Zhou B, Sethi I, Ma Q, Wasson L, Wen T, Liu J, Dong K, Conlon FL, Zhou J, Yuan GC, Zhou P, Pu WT\",\n",
      "        \"matches_publication/journal\": \"Nat Commun\",\n",
      "        \"matches_publication/title\": \"A reference map of murine cardiac transcription factor chromatin occupancy identifies dynamic and conserved enhancers.\",\n",
      "        \"matches_optimization/algorithm\": \"21 DNNs + Elastic net as stacking model; GBoost; RF; DT; LR; kNN; Elastic net; SVM\",\n",
      "        \"matches_optimization/config\": \"Only the summary for the DNNs architectures\",\n",
      "        \"matches_optimization/encoding\": \"global features\",\n",
      "        \"matches_optimization/fitting\": \"DNNs outperform baseline ML approaches\",\n",
      "        \"matches_optimization/parameters\": \"around 5M\",\n",
      "        \"matches_optimization/regularization\": \"Yes: dropout (p=0.2) after each layer, and L2 weight decay\",\n",
      "        \"matches_model/availability\": \"http://www.aging.ai/ - looks proprietary\",\n",
      "        \"matches_model/interpretability\": \"transparent: marker importance based on Permutation Feature Importance; discussion of top 10 features\",\n",
      "        \"matches_model/output\": \"continuous labels\",\n",
      "        \"matches_evaluation/comparison\": \"only a set of baseline models, based on R2 and accuracy\",\n",
      "        \"matches_evaluation/measure\": \"epsilon-prediction accuracy (epsilon=10); R2; Pearson correlation (not reported); MAE (not reported)\",\n",
      "        \"matches_evaluation/method\": \"seemingly independent test set\",\n",
      "        \"matches_dataset/provenance\": \"62419 anonymized blood biochemistry records from Invitro Laboratory, Ltd.; continuous labels; dataset not used before\",\n",
      "        \"matches_dataset/splits\": \"random 90/10 train-test split; 10-fold CV mentioned only in a figure\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305ba1\",\n",
      "        \"publication_pmid\": \"30891794\",\n",
      "        \"publication_updated\": \"03/03/2022 13:08:10\",\n",
      "        \"publication_authors\": \"Cui S, Luo Y, Tseng HH, Ten Haken RK, El Naqa I\",\n",
      "        \"publication_journal\": \"Med Phys\",\n",
      "        \"publication_title\": \"Combining handcrafted features with latent variables in machine learning for prediction of radiation-induced lung damage.\",\n",
      "        \"publication_doi\": \"10.1002/mp.13497\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"01f23578-67f2-4b8c-ab9e-121a1b840b39\",\n",
      "        \"shortid\": \"zwmdye1tg8\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"03/03/2022 13:08:10\",\n",
      "        \"matches_publication/authors\": \"Cui S, Luo Y, Tseng HH, Ten Haken RK, El Naqa I\",\n",
      "        \"matches_publication/journal\": \"Med Phys\",\n",
      "        \"matches_publication/title\": \"Combining handcrafted features with latent variables in machine learning for prediction of radiation-induced lung damage.\",\n",
      "        \"matches_optimization/config\": \"Yes: text\",\n",
      "        \"matches_optimization/encoding\": \"global features: distances are calculated by BLAST\",\n",
      "        \"matches_optimization/features\": \"variable sequence lengths of around 1000 AAs\",\n",
      "        \"matches_optimization/fitting\": \"a range of K values tested (1-50), 2 different CV protocols, weighted KNN\",\n",
      "        \"matches_model/availability\": \"https://services.birc.au.dk/patbox/ - not available as of 09/03/2022\",\n",
      "        \"matches_model/interpretability\": \"transparent: k=1 was selected, which is basically the sequence similarity method\",\n",
      "        \"matches_model/output\": \"binary predictions\",\n",
      "        \"matches_evaluation/comparison\": \"one other method based on ANN is mentioned in the text\",\n",
      "        \"matches_evaluation/confidence\": \"standard deviation is reported in a figure based on 20*5 values\",\n",
      "        \"matches_evaluation/method\": \"5-fold and 2-fold CV\",\n",
      "        \"matches_dataset/provenance\": \"a dataset of 515 sequences annotated with experimentally verified subtypes; 11 classes\",\n",
      "        \"matches_dataset/redundancy\": \"the dataset was also clustered at similarity thresholds of 30%, 50%, 75%, and 90%\",\n",
      "        \"matches_dataset/splits\": \"20 runs of non-stratified 5-fold CVs and 2-fold CVs\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305ba2\",\n",
      "        \"publication_pmid\": \"30794638\",\n",
      "        \"publication_updated\": \"03/29/2022 09:39:03\",\n",
      "        \"publication_authors\": \"Masino AJ, Harris MC, Forsyth D, Ostapenko S, Srinivasan L, Bonafide CP, Balamuth F, Schmatz M, Grundmeier RW\",\n",
      "        \"publication_journal\": \"PLoS One\",\n",
      "        \"publication_title\": \"Machine learning models for early sepsis recognition in the neonatal intensive care unit using readily available electronic health record data.\",\n",
      "        \"publication_doi\": \"10.1371/journal.pone.0212665\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"5574a8f7-41dd-4803-b335-00c1cbb28c34\",\n",
      "        \"shortid\": \"hwprilha6h\",\n",
      "        \"score\": 0.52,\n",
      "        \"matches_publication/updated\": \"03/29/2022 09:39:03\",\n",
      "        \"matches_publication/authors\": \"Masino AJ, Harris MC, Forsyth D, Ostapenko S, Srinivasan L, Bonafide CP, Balamuth F, Schmatz M, Grundmeier RW\",\n",
      "        \"matches_publication/journal\": \"PLoS One\",\n",
      "        \"matches_publication/title\": \"Machine learning models for early sepsis recognition in the neonatal intensive care unit using readily available electronic health record data.\",\n",
      "        \"matches_optimization/algorithm\": \"Decision tree (C4.5)\",\n",
      "        \"matches_model/interpretability\": \"Black box (~large decision-tree)\",\n",
      "        \"matches_model/output\": \"Statistical analysis: association between features and disease\",\n",
      "        \"matches_evaluation/measure\": \"P-value of association\",\n",
      "        \"matches_dataset/splits\": \"Control & clinical sets (300 healthy individuals and 43 patients)\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bab\",\n",
      "        \"publication_pmid\": \"30590545\",\n",
      "        \"publication_updated\": \"03/29/2022 00:49:10\",\n",
      "        \"publication_authors\": \"Rawson TM, Hernandez B, Moore LSP, Blandy O, Herrero P, Gilchrist M, Gordon A, Toumazou C, Sriskandan S, Georgiou P, Holmes AH\",\n",
      "        \"publication_journal\": \"J Antimicrob Chemother\",\n",
      "        \"publication_title\": \"Supervised machine learning for the prediction of infection on admission to hospital: a prospective observational cohort study.\",\n",
      "        \"publication_doi\": \"10.1093/jac/dky514\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"783e858f-5f8f-4b82-afb8-d61eaf60be03\",\n",
      "        \"shortid\": \"ek1c4fvz6e\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches_publication/updated\": \"03/29/2022 00:49:10\",\n",
      "        \"matches_publication/authors\": \"Rawson TM, Hernandez B, Moore LSP, Blandy O, Herrero P, Gilchrist M, Gordon A, Toumazou C, Sriskandan S, Georgiou P, Holmes AH\",\n",
      "        \"matches_publication/journal\": \"J Antimicrob Chemother\",\n",
      "        \"matches_publication/title\": \"Supervised machine learning for the prediction of infection on admission to hospital: a prospective observational cohort study.\",\n",
      "        \"matches_optimization/encoding\": \"global features (k-mers)\",\n",
      "        \"matches_optimization/features\": \"not clear: in one place they mention 55-dimensional vectors, but also 4-mer frequencies (256) and 3 additional features.\",\n",
      "        \"matches_optimization/parameters\": \"p = f\",\n",
      "        \"matches_model/availability\": \"Not available for SVM, but the focus of the study was a non ML-based tool: https://github.com/seqcode/multigps\",\n",
      "        \"matches_model/interpretability\": \"transparent: discriminative motif discovery touched upon\",\n",
      "        \"matches_model/output\": \"binary classification\",\n",
      "        \"matches_evaluation/confidence\": \"Not explicitly given but 20 replicates are shown in the ROC graphs\",\n",
      "        \"matches_evaluation/method\": \"20 random replicates of train/test splits\",\n",
      "        \"matches_dataset/provenance\": \"55 mouse ES ChIP-seq and DNaseI-seq experiments from a variety of sources, each with up to 4000 pos and 10000 negs.\",\n",
      "        \"matches_dataset/redundancy\": \"mot checked\",\n",
      "        \"matches_dataset/splits\": \"20 repetitions of random selection of 100 data points for testing\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bac\",\n",
      "        \"publication_pmid\": \"30950198\",\n",
      "        \"publication_updated\": \"03/27/2022 20:48:59\",\n",
      "        \"publication_authors\": \"Hu X, Xie W, Wu C, Xu S\",\n",
      "        \"publication_journal\": \"Plant Biotechnol J\",\n",
      "        \"publication_title\": \"A directed learning strategy integrating multiple omic data improves genomic prediction.\",\n",
      "        \"publication_doi\": \"10.1111/pbi.13117\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"f0944313-d0c6-4160-94cb-b073fe88e4bd\",\n",
      "        \"shortid\": \"v1rge4dd87\",\n",
      "        \"score\": 0.52,\n",
      "        \"matches_publication/updated\": \"03/27/2022 20:48:59\",\n",
      "        \"matches_publication/authors\": \"Hu X, Xie W, Wu C, Xu S\",\n",
      "        \"matches_publication/journal\": \"Plant Biotechnol J\",\n",
      "        \"matches_publication/title\": \"A directed learning strategy integrating multiple omic data improves genomic prediction.\",\n",
      "        \"matches_optimization/algorithm\": \"gradient boosting algorithm using 2 different weak learner models: OLS and RKHS regression; modification -> random boosting\",\n",
      "        \"matches_optimization/encoding\": \"global features\",\n",
      "        \"matches_optimization/features\": \"only 39714 SNPs mentioned\",\n",
      "        \"matches_model/interpretability\": \"transparent: gene identification\",\n",
      "        \"matches_evaluation/measure\": \"Pearson correlation, Estimated prediction bias (=\\\"average difference between predicted and observed responses in standard deviation units\\\")\",\n",
      "        \"matches_evaluation/method\": \"independent test set\",\n",
      "        \"matches_dataset/provenance\": \"1859 data points from another publication, continuous lables\",\n",
      "        \"matches_dataset/redundancy\": \"data were split by the year of birth (before 2005 -> train, after -> test)\",\n",
      "        \"matches_dataset/splits\": \"train/test: 1601/258 or 1574/235 (depending on the label type); 10-fold CV\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bb7\",\n",
      "        \"publication_pmid\": \"30877925\",\n",
      "        \"publication_updated\": \"03/02/2022 16:41:47\",\n",
      "        \"publication_authors\": \"Andersen SL, Briggs FBS, Winnike JH, Natanzon Y, Maichle S, Knagge KJ, Newby LK, Gregory SG\",\n",
      "        \"publication_journal\": \"Mult Scler Relat Disord\",\n",
      "        \"publication_title\": \"Metabolome-based signature of disease pathology in MS.\",\n",
      "        \"publication_doi\": \"10.1016/j.msard.2019.03.006\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"a6fa00a2-c4cf-4004-b63f-2abb8ffd46bf\",\n",
      "        \"shortid\": \"vs7yv4y6i5\",\n",
      "        \"score\": 0.57,\n",
      "        \"matches_publication/updated\": \"03/02/2022 16:41:47\",\n",
      "        \"matches_publication/authors\": \"Andersen SL, Briggs FBS, Winnike JH, Natanzon Y, Maichle S, Knagge KJ, Newby LK, Gregory SG\",\n",
      "        \"matches_publication/journal\": \"Mult Scler Relat Disord\",\n",
      "        \"matches_publication/title\": \"Metabolome-based signature of disease pathology in MS.\",\n",
      "        \"matches_optimization/algorithm\": \"Support Vector Machines\",\n",
      "        \"matches_optimization/config\": \"Configuration and hyper-parameter configuration available in the main text\",\n",
      "        \"matches_optimization/encoding\": \"Global features encoding frequency and total number of each amino acid, as well as of certain sets of amino acids (e.g. hydrophobic, charged, polar). Protein subdivided into four equally sized fragments and calculated the same feature values for each fragment and combination of fragments. Predicted the secondary structure using Prof, position of putative transmembrane helices using TMHMM and of disordered regions using DisEMBL (predicted features are processed using the above fragmentation strategy). \",\n",
      "        \"matches_optimization/features\": \"f=2579. Feature selection performed using Wilcoxon signed-rank test\",\n",
      "        \"matches_optimization/meta\": \"Yes, for computing some feature. No handling of potential dataset redundancy.\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"Multi-class classification\",\n",
      "        \"matches_evaluation/method\": \"Repeated training/testing split (five times). No indipendent datasets\",\n",
      "        \"matches_dataset/provenance\": \"Los Alamos National Laboratory Bioscience Division STD Sequence Databases. N_pos and N_neg for each functional class are unknown.\",\n",
      "        \"matches_dataset/redundancy\": \"Redundancy between traiing/testing reduced with PSI-BLAST (e-value threshold set to 0.001)\",\n",
      "        \"matches_dataset/splits\": \"Five independent training/testing splits with ratio 4:1. N_pos, N_neg for each training/testing is unknown. No separate validation set.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6638a402b30933003cc215c9\",\n",
      "        \"shortid\": \"3iham0l32l\",\n",
      "        \"uuid\": \"34249f84-1197-4a65-8ab2-a298da42e32a\",\n",
      "        \"created\": \"2024-05-06T09:33:54.347Z\",\n",
      "        \"updated\": \"2024-05-06T09:33:54.347Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"31877719\",\n",
      "        \"publication_authors\": \"Floriane Montanari, Lara Kuhnke, Antonius Ter Laak, Djork-Arn\\u00e9 Clevert\",\n",
      "        \"publication_journal\": \"Molecules\",\n",
      "        \"publication_title\": \"Modeling Physico-Chemical ADMET Endpoints with Multitask Graph Convolutional Networks\\n\",\n",
      "        \"publication_doi\": \"10.3390/molecules25010044\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches_evaluation/comparison\": \"The model was compared to simpler models developed by authors, including:\\nRandom Forest\\nFully-Connected Single Task Network\\nFully-Connected Multitask Network\\nSingle Task Graph Convultional Network\",\n",
      "        \"matches_evaluation/confidence\": \"Standard deviations are reported in supplementary materials.\",\n",
      "        \"matches_evaluation/measure\": \"The performance of such regression models is evaluated by the coefficient of determination r2 (which measures the concordance between predicted and experimental values) and the Spearman correlation coefficient rho (which measures the ranking capabilities of the models).\",\n",
      "        \"matches_evaluation/method\": \"The model was evaluated a in cross-validation fashion for random and cluster split strategies.\\nIn time split method, the model that was trained on earlier measurements is evaluated on recent measurements.\",\n",
      "        \"matches_optimization/algorithm\": \"Multiple models were used and compared, but the main model that was focused by the authors is a Multitask Graph Convolutional Neural Network\",\n",
      "        \"matches_optimization/config\": \"The code to train multitask graph convolutional networks is available on github: https://github.com/fmonta/mtnngc_admet\",\n",
      "        \"matches_optimization/encoding\": \"The authors used molecular graphs and 75 simple atomic descriptors as initial node features.\",\n",
      "        \"matches_optimization/features\": \"75 atomic features for each atom in a molecule.\\nNo explanation on feature selection.\",\n",
      "        \"matches_optimization/meta\": \"The model is not a meta-predictor\",\n",
      "        \"matches_optimization/parameters\": \"The authors used the implementation of the Duvenaud algorithm in DeepChem v.1.2.1 and kept the architecture and hyperparameters suggested by the authors for ADMET predictions.\\n(Duvenaud, D.; Maclaurin, D.; Aguilera-Iparraguirre, J.; G\\u00f3mez-Bombarelli, R.; Hirzel, T.; Aspuru-Guzik, A.; Adams, R.P. Convolutional Networks on Graphs for Learning Molecular Fingerprints. In Proceedings of the Advances in Neural Information Processing Systems 28 (NIPS 2015), Montreal, QC, Canada, 7\\u201312 December 2015)\",\n",
      "        \"matches_optimization/regularization\": \"cross validation was performed for random splits and cluster splits.\",\n",
      "        \"matches_model/availability\": \"The code to train multitask graph convolutional networks is available on github: https://github.com/fmonta/mtnngc_admet\",\n",
      "        \"matches_model/interpretability\": \"The model is a black box.\",\n",
      "        \"matches_model/output\": \"The model is a regression model for predicting 7 ADMET endpoints.\",\n",
      "        \"matches_dataset/provenance\": \"The authors used in-house (Bayer) datasets related to 10 ADMET endpoints\\n1. LogD (pH7.5) (LOD) = 76,548 \\n2. LogD (pH2.3) (LOA) = 236,280\\n3. Membrane affinity (LOM) = 64,506 \\n4. Human serum albumin binding (LOH) = 61,398 \\n5. Melting point (LMP) = 90,589 \\n6. Solubility (DMSO)  (LOO) = 38,841 \\n7. Solubility (powder) (LOP) = 2334 \\n8. Solubility (nephelometry) (LON )= 88,301 \\n9. Solubility (DMSO not fully dissolved) (LOX) = 7392 \\n10. Solubility (no assay annotation) (LOQ) = 50,016\",\n",
      "        \"matches_dataset/redundancy\": \"Models were evaluated in both a cross-validation and a separate test set fashion.\\nDifferent splitting strategies were used that includes:\\n1. Cluster split using k-means to cluster the compounds (K = 10)\\n2. Random splits ensuring that each fold contains representatives from each task\\n3. Time splits with no cross-validation based on measurement dates, in which later measurements used as test sets\",\n",
      "        \"matches_dataset/splits\": \"Different splitting strategies were used independently and only the test size for time split dataset is reported:\\nLOD = 32,794\\nLOA = 46,481\\nLOM = 197\\nLOH = 614\\nLMP = 55\\nLOO = 22,803\\nLOP = 935\",\n",
      "        \"matches_publication/authors\": \"Floriane Montanari, Lara Kuhnke, Antonius Ter Laak, Djork-Arn\\u00e9 Clevert\",\n",
      "        \"matches_publication/title\": \"Modeling Physico-Chemical ADMET Endpoints with Multitask Graph Convolutional Networks\\n\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"665d0af137ea6fa797a6bda1\",\n",
      "        \"shortid\": \"5bz7gjjsah\",\n",
      "        \"uuid\": \"ffea624d-972d-4b3e-85bb-4708bb5c26a1\",\n",
      "        \"created\": \"2024-06-03T00:14:41.897Z\",\n",
      "        \"updated\": \"2024-06-03T00:14:41.897Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"31199787\",\n",
      "        \"publication_authors\": \"Kymberleigh A. Pagel, Danny Antaki, AoJie Lian, Matthew Mort, David N. Cooper, Jonathan Sebat, Lilia M. Iakoucheva, Sean D. Mooney, and Predrag Radivojac\",\n",
      "        \"publication_journal\": \"PLOS Computational Biology\",\n",
      "        \"publication_title\": \"Pathogenicity and functional impact of non-frameshifting insertion/deletion variation in the human genome\",\n",
      "        \"publication_doi\": \"10.1371/journal.pcbi.1007112\",\n",
      "        \"publication_year\": \"2019\",\n",
      "        \"score\": 0.95,\n",
      "        \"matches_evaluation/availability\": \"No - no link/files /statistical code relating to the raw evaluation beyond text details.\",\n",
      "        \"matches_evaluation/comparison\": \"Yes, the evaluation of MutPred-Indel included comparisons to both simpler baselines and publicly available methods.\\n\\nSimpler baseline: authors compared MutPred-Indel to MutPred2. They achieved this by simulating deletions and insertions using MutPred2 and showed that MutPred-Indel outperformed MutPred2 in this scenario (AUC of 0.903 vs 0.797)\\n\\nComparison to publicly available methods: authors also compared MutPred-Indel to other indel prediction methods like VEST-Indel and DDIG. MutPred-Indel achieved the highest AUC (0.897) compared to VEST-Indel (0.875) and DDIG-in (0.869). \",\n",
      "        \"matches_evaluation/confidence\": \"Confidence intervals are not explicitly mentioned in the text. No clear indication of t-tests/other approaches to determine statistically significant method improvements beyond the direct AUC comparisons.\",\n",
      "        \"matches_evaluation/measure\": \"The area under the receiver operating characteristic (ROC) curve is detailed and plotted in the evalaution section.\\n\\nThe paper notes the model: 'shows strong performance in cross-validation with the area under the ROC curve (AUC) of 0.908'. Figure 5 details the performance ROC curves under various comparisons such as against other prediction models such as 'CADD'.\",\n",
      "        \"matches_evaluation/method\": \"Various evaluation methods were employed such as:\\n10-fold cross-validation, per-protein and per-cluster cross-validation and comparison of models with different feature sets.\",\n",
      "        \"matches_optimization/algorithm\": \"The ML algorithm used in the paper is an ensemble of bagged two-layer feed-forward neural networks.\",\n",
      "        \"matches_optimization/config\": \"No, not clearly available from the text or software website. Regarding parameters reporting, the text does note: 'Each pathogenicity predictor was developed with the Matlab 2016b Neural Network Toolbox as an ensemble of one hundred bagged two-layer feed-forward neural networks, where the following training parameters were not varied between alternative models'.\",\n",
      "        \"matches_optimization/encoding\": \"Preprocessing was undertaken via Two-sample t-test and principal component analysis (PCA). Encoding used and detailed under feature engineering section such as numerical encoding.\",\n",
      "        \"matches_optimization/features\": \"Precise number of input features not explicitly stated in main publication text. The structural and functional features of protein sequences are detailed in Table 3 of the text and fall into 5x categories with approximately 57 noted across these categories. \",\n",
      "        \"matches_optimization/fitting\": \"Provided that the feature information and inferred parameter infromation (not easy to discern from text), the risk of overfitting is not very likely due to N >> p and the validation set. For underfitting this is mitigated by minimal feature reduction and 10-fold cross-validation employed, but this is dependent on significance of the features and risk grows if the features used are not significant enough. \",\n",
      "        \"matches_optimization/parameters\": \"Without the precise feature count the number of parameters cannot be exactly determined. However, if to use the estimated number of features from Table 3 in the text (57 features from total of 5x categories), it could be inferred that with a network architecture of a two-layer feed-forward neural network with 10 hidden units would be 591.\",\n",
      "        \"matches_optimization/regularization\": \"Yes, as the text mentions using a validation set, specifically retaining 25% of the training data being set aside for validation.\",\n",
      "        \"matches_model/availability\": \"Source code GitHub repository for MutPred2: https://github.com/vpejaver/mutpred2 - MIT License. Primary resource website of the software (http://mutpred.mutdb.org/) offers  live web service for analyses and downloadable executable.\",\n",
      "        \"matches_model/duration\": \"The standalone model executable can be used for genome-scale data sets. To install and run MutPred2, you will need about 50 GB of hard disk space and at least 4 GB RAM. No further information avaialble regarding prediction run times beyond this.\",\n",
      "        \"matches_model/interpretability\": \"Somewhat of a black box from the text alone. In the text there are reasonable descriptions of the model but given the lack of publicly available model & code (eg: in Huggingface/other model hosting/no GitHub) and exact training & test datasets. It is somewhat of a blackbox if attempting to reproduce and interpret the exacts of the model given its complex ML algorithm nature being that of an ensemble of neural networks from the text alone. However, there is a GitHub online that can be found for the model and related datasets so this helps greatly with the model interpretability in conjunction with the text. However, it should be explictly linked for readers. The Matlab related files and info also not available on GitHub due to licensing.\",\n",
      "        \"matches_model/output\": \"Classification - used to predict pathogenicity of indels\",\n",
      "        \"matches_dataset/availability\": \"Training data:\\n-Positive class, disease causing indel variant data was sourced from the Human Gene Mutation Database (HGMD), professional version 2017. http://www.hgmd.cf.ac.uk\\n\\n-Negative class, putatively neutral indel variant data was sourced from the Genome Aggregation Database (gnomAD) databases. https://gnomad.broadinstitute.org/\\n\\nTest data:\\n-1. Somatic test set: Catalogue Of Somatic Mutations In Cancer (COSMIC) genome-wide screen data set (v85) & DataBase of Cancer Driver InDels (dbCID). \\n\\n-2. De novo test set: REACH Project & Simons Simplex Collection.\\n\\nThe publicly available data of the study derived from the above databases are available at http://mutpred.mutdb.org/ - training data: http://mutpred.mutdb.org/wo_exclusive_hgmd_mp2_training_data.txt\\n\\nAlso references in the text to other publications regarding some of the data sources. \",\n",
      "        \"matches_dataset/provenance\": \"Data source: from databases - both pay to access (HGMD professional) and publicly available ones (COSMIC/gnomAD/+). \\n\\nData type: DNA - genetic variants, grouped as standard insertions and deletions (indels) and complex indels.\\nClass positive: disease causing sequence-retaining insertion, deletion, and complex indel variants. Unclear but likely: 1,296.\\nClass negative: putatively neutral insertion/deletion variants. Unclear but likely: 2,392.\\n\\nDetermination of exact number of training and test data points is difficult to ascertain due to poor alignment with numeric figures provided in the text to that of Table 2 which contains this information. The Table 2 itself is also difficult to interpret due to a second set of bracketed numbers beside each initial figure provided. Neither sets of numbers align exactly to the text and no clear key/description provided. \\n\\nDataset reuse/community recognised: data used is a subset of avilable data from reputable international databases. Large variety of databases leveraged and combined for training and test data.\",\n",
      "        \"matches_dataset/redundancy\": \"How were the sets split?: \\nFor the training data:\\n-Validation set (25%): A quarter of the training data is used to fine-tune the model during training (resilient propagation method).\\n-Cross-validation (10-fold): The training data is divided into 10 folds. The model is trained on 9 folds and tested on the remaining one, repeated 10 times, to assess generalisability (AUC-ROC).\\n\\nAre the training and test sets independent?: \\nYes, indpendent test and training sets used.\\n\\nHow does the distribution compare to previously published ML datasets?:\\nMutPred-Indel is compared to three existing methods: DDIG-in, VEST-Indel, and CADD  but it uses the training data from the current study, not entirely independent datasets. The paper notes a 'paucity' of such data.\",\n",
      "        \"matches_dataset/splits\": \"Training data set comprised of:\\n-5606 single residue deletions\\n-1033 single residue insertions\\n-2427 multi-residue insertions\\n-3052 multi-residue deletions\\n-1253 complex indel variants\\n\\nTest data sets: \\n2x test data sets were used to test the models classification efficacy.\\n1. Somatic mutation test sets: consisting of two sets of putatively damaging cancer causing somatic variants derived from information in COSMIC AND dbCID databases. Text seems to indicate 576 test data points based on the final sentence '(n = 576)' but not clear or explictly stated/documented in text.  \\n\\n2. De novo mutation test sets: consisting of non-frameshifting insertion/deletion variants curated from families affected by Autism Spectrum Disorder (ASD). Data sourced from REACH Project (2650 families) and the Simons Simplex Collection (SSC). Final test set after filtering is performed is composed of 1217 candidate de novo indels in 827 offspring (506 cases, 321 controls).\\n\\nSeparate validation set used, and if yes, how large was it?: \\nThe model training utilised the resilient propagation method and 25% of training data set aside for the validation.\",\n",
      "        \"matches_publication/authors\": \"Kymberleigh A. Pagel, Danny Antaki, AoJie Lian, Matthew Mort, David N. Cooper, Jonathan Sebat, Lilia M. Iakoucheva, Sean D. Mooney, and Predrag Radivojac\",\n",
      "        \"matches_publication/journal\": \"PLOS Computational Biology\",\n",
      "        \"matches_publication/title\": \"Pathogenicity and functional impact of non-frameshifting insertion/deletion variation in the human genome\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b1b\",\n",
      "        \"publication_pmid\": \"32344344\",\n",
      "        \"publication_updated\": \"03/22/2022 11:54:11\",\n",
      "        \"publication_authors\": \"Bouysset C, Belloir C, Antonczak S, Briand L, Fiorucci S\",\n",
      "        \"publication_journal\": \"Food Chem\",\n",
      "        \"publication_title\": \"Novel scaffold of natural compound eliciting sweet taste revealed by machine learning.\",\n",
      "        \"publication_doi\": \"10.1016/j.foodchem.2020.126864\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"8becb7c4-2b09-4c8a-b48f-eb340481376d\",\n",
      "        \"shortid\": \"fozqqtqf2d\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches_publication/updated\": \"03/22/2022 11:54:11\",\n",
      "        \"matches_publication/authors\": \"Bouysset C, Belloir C, Antonczak S, Briand L, Fiorucci S\",\n",
      "        \"matches_publication/journal\": \"Food Chem\",\n",
      "        \"matches_publication/title\": \"Novel scaffold of natural compound eliciting sweet taste revealed by machine learning.\",\n",
      "        \"matches_optimization/algorithm\": \"SVM classification method.\",\n",
      "        \"matches_optimization/encoding\": \"The feature vectors are encoded in a bi-profile manner. This approach is explained in the paper (2.2.2. Adapted normal distribution bi-profile Bayes (ANBPB)).\",\n",
      "        \"matches_optimization/features\": \"For feature extraction a modified version of classical bi-profile Bayes was used. Thirteen physicochemical features were selected. They used the jackknife test to select important features and optimize all parameters.\",\n",
      "        \"matches_optimization/parameters\": \"2 parameters ( c = 4, \\u03b3 = 0.25 for the hydroxyproline prediction and\\nc = 4, \\u03b3 = 0.125 for the hydroxylysine prediction). Parameters were downloaded from http://www.matlabsky.com and optimized by the SVMcgForClass program. \",\n",
      "        \"matches_model/availability\": \"The MATLAB package of OH-PRED is available as Supplementary files.\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/comparison\": \"iHyd-PseAAC (Xu, 2014) and PredHydroxy (Shi, 2015). Performance measures are compared.\",\n",
      "        \"matches_evaluation/measure\": \"Sensitivity, specificity, accuracy.\",\n",
      "        \"matches_evaluation/method\": \"Independent test dataset.\",\n",
      "        \"matches_dataset/provenance\": \"265 candidate proteins containing hydroxylated prolines and 34 candidate proteins\\ncontaining hydroxylated lysines were collected from the UniProtKB/Swiss-Prot database (version 2014_1, www.uniprot.org). Sequence segments around the hydroxylation sites\\nand non-hydroxylation sites were extracted as positive and negative training datasets,\\nrespectively. \",\n",
      "        \"matches_dataset/splits\": \"After removing the identical sequence, the original datasets contain 659\\npositive sites and 3855 negative sites for hydroxyproline from 112 proteins, and 97\\npositive sites and 855 negative sites for hydroxylysine from 25 proteins. The size of\\nthe negative datasets is much larger (approximate ratio of 1:6) than that of the positive training datasets. After addressing this problem, ratios of 1:1 and 1:3 of the number of positive samples and the number of negative samples were used to construct the negative training set. (Reduction of the negative set). \\nTest set is not described.\\nValidation set:  randomly split 10% of the samples from the dataset as an independent test dataset, and the remaining 90% of the samples as a training dataset.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b23\",\n",
      "        \"publication_pmid\": \"32220894\",\n",
      "        \"publication_updated\": \"03/15/2022 15:36:27\",\n",
      "        \"publication_authors\": \"Wu KE, Parker KR, Fazal FM, Chang HY, Zou J\",\n",
      "        \"publication_journal\": \"RNA\",\n",
      "        \"publication_title\": \"RNA-GPS predicts high-resolution RNA subcellular localization and highlights the role of splicing.\",\n",
      "        \"publication_doi\": \"10.1261/rna.074161.119\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"282ed2ca-7c65-4eb6-9c7d-8c69881d722c\",\n",
      "        \"shortid\": \"039id1a4pi\",\n",
      "        \"score\": 0.57,\n",
      "        \"matches_publication/updated\": \"03/15/2022 15:36:27\",\n",
      "        \"matches_publication/authors\": \"Wu KE, Parker KR, Fazal FM, Chang HY, Zou J\",\n",
      "        \"matches_publication/title\": \"RNA-GPS predicts high-resolution RNA subcellular localization and highlights the role of splicing.\",\n",
      "        \"matches_optimization/algorithm\": \"Spathial, Random forest, LASSO\",\n",
      "        \"matches_optimization/parameters\": \"R package randomForestSRC: \\\"The training was running with \\u201cimportance = TRUE,\\nblock size = 1\\u201d and set with all other parameters set to\\ndefaul\\\"\",\n",
      "        \"matches_evaluation/measure\": \"AUCs for 2-, 3-, and 5-year OS were 0.527, 0.596 and 0.671, respectively\",\n",
      "        \"matches_evaluation/method\": \"10-fold cross validation\",\n",
      "        \"matches_dataset/availability\": \"no, they claim: \\\"Publicly available datasets were analyzed in this study. This data can be found here: The datasets collected in the current study are available in the TCGA3 and GEO repository.\\\"\\n\",\n",
      "        \"matches_dataset/provenance\": \"public databases: 901 samples from The Cancer Genome Atlas cohort (TCGA-LUAD) and gene expression omnibus (GEO) database\",\n",
      "        \"matches_dataset/splits\": \"10-fold cross validation\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b24\",\n",
      "        \"publication_pmid\": \"31161221\",\n",
      "        \"publication_updated\": \"04/06/2022 16:25:21\",\n",
      "        \"publication_authors\": \"Jeon J, Olkhov-Mitsel E, Xie H, Yao CQ, Zhao F, Jahangiri S, Cuizon C, Scarcello S, Jeyapala R, Watson JD, Fraser M, Ray J, Commisso K, Loblaw A, Fleshner NE, Bristow RG, Downes M, Vesprini D, Liu S, Bapat B, Boutros PC\",\n",
      "        \"publication_journal\": \"J Natl Cancer Inst\",\n",
      "        \"publication_title\": \"Temporal Stability and Prognostic Biomarker Potential of the Prostate Cancer Urine miRNA Transcriptome.\",\n",
      "        \"publication_doi\": \"10.1093/jnci/djz112\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"f0936cfb-e3a1-44a1-b760-3897fce5b861\",\n",
      "        \"shortid\": \"nhcfgr8oi1\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches_publication/updated\": \"04/06/2022 16:25:21\",\n",
      "        \"matches_publication/authors\": \"Jeon J, Olkhov-Mitsel E, Xie H, Yao CQ, Zhao F, Jahangiri S, Cuizon C, Scarcello S, Jeyapala R, Watson JD, Fraser M, Ray J, Commisso K, Loblaw A, Fleshner NE, Bristow RG, Downes M, Vesprini D, Liu S, Bapat B, Boutros PC\",\n",
      "        \"matches_publication/journal\": \"J Natl Cancer Inst\",\n",
      "        \"matches_publication/title\": \"Temporal Stability and Prognostic Biomarker Potential of the Prostate Cancer Urine miRNA Transcriptome.\",\n",
      "        \"matches_optimization/algorithm\": \"Recursive feature elimination with cross-validation (RFECV) from sklearn. Random forest was used as the estimator.\",\n",
      "        \"matches_optimization/config\": \"Data is available from authors upon request.\",\n",
      "        \"matches_optimization/encoding\": \"1)\\tTo allow comparison between samples, all data were normalized to the internal standard in each chromatogram. The raw data consisting of 175 metabolites measured across 70 participants was normalized using min/max scaling. \\n2)\\tData imputation with IterativeImputer of sklearn was utilized to handle missing data. The trained imputer was tested by removing the data of one metabolite feature column and imputing the data afterward. The performance of the imputer was measured for each of the metabolites using R^2 metric. Metabolite columns with R^2 < 0.3 and more than 5% of missing values across all patients were removed.\\n3)\\tData standardization to zero mean and unit variance for each metabolite feature column. \\nData pre-processing step reduced the feature columns to 75 metabolites. \\n\",\n",
      "        \"matches_optimization/features\": \"Metabolic profiles of 45 metabolites following data preprocessing. Recursive feature elimination with cross-validation (RFECV), using random forest, reduced the number of features to 15 metabolites.\",\n",
      "        \"matches_model/availability\": \"Data is available from authors upon request.\",\n",
      "        \"matches_model/interpretability\": \"Transparent. 15 selected metabolites following feature elimination, including stearic acid and ornithine, leading to best model performance. Unpaired t-test to identify metabolites with differences between CMD and non-CMD.\",\n",
      "        \"matches_model/output\": \"The binary predictions of \\u201cCMD\\u201d and \\u201cnon-CMD\\u201d, with the latter combining both CAD and control group samples.\",\n",
      "        \"matches_evaluation/availability\": \"Data is available from authors upon request.\",\n",
      "        \"matches_evaluation/comparison\": \"1) One-way-ANOVA model and chi-squared analysis were fitted to test the statistical significance of clinical differences between different participant groups, followed by Tukey\\u2019s post hoc test. p < 0.05 was considered significant.\\n 2) Z-scores were calculated for each metabolite. An unpaired t-test was performed to identify metabolites that are different between each participant group.\",\n",
      "        \"matches_evaluation/measure\": \"Receiver operating curves (ROC), precision\\u2013recall (PR) curves, AUC score, F1 score\",\n",
      "        \"matches_evaluation/method\": \"5-fold cross-validation\",\n",
      "        \"matches_dataset/availability\": \"Data is available from authors upon request.\",\n",
      "        \"matches_dataset/provenance\": \"Profiles of 150 metabolites based on gas chromatography mass spectrometry (GC/MS) analysis of plasma samples from 70 postmenopausal women.\",\n",
      "        \"matches_dataset/redundancy\": \"During GC/MS analysis tentative substances were not reported All known artificial peaks were identified and removed before data mining. The metabolic feature columns, which had more than 40% of data missing, were eliminated.\",\n",
      "        \"matches_dataset/splits\": \"Npos=23 patients with coronary microvascular disease (CMD). Nneg=47 participants, including 21 patients with coronary artery disease (CAD) and 26 healthy participants as control group.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b25\",\n",
      "        \"publication_pmid\": \"33039708\",\n",
      "        \"publication_updated\": \"04/18/2022 16:33:16\",\n",
      "        \"publication_authors\": \"Bitencourt AGV, Gibbs P, Rossi Saccarelli C, Daimiel I, Lo Gullo R, Fox MJ, Thakur S, Pinker K, Morris EA, Morrow M, Jochelson MS\",\n",
      "        \"publication_journal\": \"EBioMedicine\",\n",
      "        \"publication_title\": \"MRI-based machine learning radiomics can predict HER2 expression level and pathologic response after neoadjuvant therapy in HER2 overexpressing breast cancer.\",\n",
      "        \"publication_doi\": \"10.1016/j.ebiom.2020.103042\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"1ac93280-f1b7-4064-8b5e-5e1553dbd65f\",\n",
      "        \"shortid\": \"9regsp7l7u\",\n",
      "        \"score\": 0.52,\n",
      "        \"matches_publication/updated\": \"04/18/2022 16:33:16\",\n",
      "        \"matches_publication/authors\": \"Bitencourt AGV, Gibbs P, Rossi Saccarelli C, Daimiel I, Lo Gullo R, Fox MJ, Thakur S, Pinker K, Morris EA, Morrow M, Jochelson MS\",\n",
      "        \"matches_publication/title\": \"MRI-based machine learning radiomics can predict HER2 expression level and pathologic response after neoadjuvant therapy in HER2 overexpressing breast cancer.\",\n",
      "        \"matches_optimization/algorithm\": \"Naive Bayes, SVM, Random Forests\",\n",
      "        \"matches_optimization/encoding\": \"sliding window on sequence\",\n",
      "        \"matches_optimization/features\": \"Fast Correlation Based Filter  and  Scatter Search  were used\",\n",
      "        \"matches_model/availability\": \"yes, GitLab https://gitlab.com/mgarciat/genome-wide-prediction-of-topoisomerase-iibeta-binding\",\n",
      "        \"matches_evaluation/measure\": \"ROC curves and AUC values\",\n",
      "        \"matches_evaluation/method\": \"5-fold cross validation\",\n",
      "        \"matches_dataset/availability\": \"yes, described at S1 table: https://deposition.proteinensemble.org/job/25e45232-2c53-409f-b734-bbc1710609a2\\n\\nall models and dataset at https://gitlab.com/mgarciat/genome-wide-prediction-of-topoisomerase-iibeta-binding\",\n",
      "        \"matches_dataset/provenance\": \"yes, N_pos: 13128  N_neg: 32766\",\n",
      "        \"matches_dataset/redundancy\": \"Correlation Feature Selection is used.\",\n",
      "        \"matches_dataset/splits\": \"5-fold cross-validation\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b26\",\n",
      "        \"publication_pmid\": \"32620137\",\n",
      "        \"publication_updated\": \"04/18/2022 16:44:10\",\n",
      "        \"publication_authors\": \"Ji Z, Zhou W, Hou W, Ji H\",\n",
      "        \"publication_journal\": \"Genome Biol\",\n",
      "        \"publication_title\": \"Single-cell ATAC-seq signal extraction and enhancement with SCATE.\",\n",
      "        \"publication_doi\": \"10.1186/s13059-020-02075-3\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"42bd8a6e-bec6-4f31-b0b6-e19be5f8c86f\",\n",
      "        \"shortid\": \"x35e8g9f2z\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches_publication/updated\": \"04/18/2022 16:44:10\",\n",
      "        \"matches_publication/authors\": \"Ji Z, Zhou W, Hou W, Ji H\",\n",
      "        \"matches_publication/journal\": \"Genome Biol\",\n",
      "        \"matches_publication/title\": \"Single-cell ATAC-seq signal extraction and enhancement with SCATE.\",\n",
      "        \"matches_optimization/algorithm\": \"SVM and Convolutional Neural Network (ImageNet architecture)\",\n",
      "        \"matches_optimization/config\": \"Some hyperparameters specified in the main text\",\n",
      "        \"matches_optimization/encoding\": \"150x150 pixel images (CNN). Image descrptors for SVM\",\n",
      "        \"matches_optimization/features\": \"f=3 (pixel intensities) for CNN. f=3 for SVM (descriptors selected after PCA-based feature selection)\",\n",
      "        \"matches_optimization/fitting\": \"Early stopping used to prevent overfitting (CNN)\",\n",
      "        \"matches_model/availability\": \"Yes https://github.com/gkanfer/AI-PS\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"Binary classification\",\n",
      "        \"matches_evaluation/confidence\": \"No confidence reported\",\n",
      "        \"matches_evaluation/measure\": \"Accuracy, AUPRC\",\n",
      "        \"matches_evaluation/method\": \"Independent testing\",\n",
      "        \"matches_dataset/availability\": \"Yes, https://github.com/ gkanfer/AI-PS/tree/master/facs\",\n",
      "        \"matches_dataset/provenance\": \"Parking and GFP-TFEB images generated in the same study\",\n",
      "        \"matches_dataset/splits\": \"Training 80%, validation 15%, 5% Independent test data. N_pos and N_neg unknown for training data. For independent data: N_pos=5401, N_neg=4948.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b27\",\n",
      "        \"publication_pmid\": \"33005419\",\n",
      "        \"publication_updated\": \"05/20/2022 15:26:30\",\n",
      "        \"publication_authors\": \"Lu XJ, Yang XJ, Sun JY, Zhang X, Yuan ZX, Li XH\",\n",
      "        \"publication_journal\": \"Biomark Res\",\n",
      "        \"publication_title\": \"FibroBox: a novel noninvasive tool for predicting significant liver fibrosis and cirrhosis in HBV infected patients.\",\n",
      "        \"publication_doi\": \"10.1186/s40364-020-00215-2\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"db022eae-23a7-444b-b7ad-0e845a5ec029\",\n",
      "        \"shortid\": \"sfncop89n7\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches_publication/updated\": \"05/20/2022 15:26:30\",\n",
      "        \"matches_publication/authors\": \"Lu XJ, Yang XJ, Sun JY, Zhang X, Yuan ZX, Li XH\",\n",
      "        \"matches_publication/journal\": \"Biomark Res\",\n",
      "        \"matches_publication/title\": \"FibroBox: a novel noninvasive tool for predicting significant liver fibrosis and cirrhosis in HBV infected patients.\",\n",
      "        \"matches_optimization/encoding\": \"data normalised, missing data inputed using median value, data standardised using z-scores. \",\n",
      "        \"matches_optimization/features\": \"10 clinical features, eight cancer biomarkers 29-gene NGS panel for mutations, 30 methylation-correlated blocks (feature-selected from 697 MCBs). \",\n",
      "        \"matches_optimization/fitting\": \"parameter smaller than samples, features larger but still smaller than samples pin the training set, but univariate analysis reduced then number of features.\",\n",
      "        \"matches_optimization/meta\": \"Features are coming from experimental data.  Four different predictors using different data are grouped in a stacked ensemble classifier, using Naive Bayes. \",\n",
      "        \"matches_optimization/parameters\": \"linear kernel used in SVMs for each independent predictor.  Naive bayes sued to determine the optimal combination of these predictors.\",\n",
      "        \"matches_optimization/regularization\": \"Cross-validations procedures and feature selection are used to reduce chances for over-fitting.  Evaluation based on independent validation set.\",\n",
      "        \"matches_model/interpretability\": \"partially interpretable but no apart from feature analysis on the baseline predictors, nothing else reported\",\n",
      "        \"matches_model/output\": \"classification in benign or malignant\",\n",
      "        \"matches_evaluation/comparison\": \"no other methods are compared\",\n",
      "        \"matches_evaluation/measure\": \"AUC. sensitivity and specificity\",\n",
      "        \"matches_evaluation/method\": \"cross validation and independent set\",\n",
      "        \"matches_dataset/availability\": \"patient clinical information available in SI, as well as the protein biomarker data cfDnot reported mutation and cfDnot reported methylation features. Link to raw data also provided (or via author)\",\n",
      "        \"matches_dataset/provenance\": \"Data is experimentally derived from 125 patients. Training data divided over 84 positive and 41 negative instances. An independent validation set \",\n",
      "        \"matches_dataset/splits\": \"Data is split into 96 for training and 29 for validation. The training set consisted of 69 positive and 27 negative, whereas the validation set is divided into 14 negative and 15 positive cases.  \"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b28\",\n",
      "        \"publication_pmid\": \"31857725\",\n",
      "        \"publication_updated\": \"05/20/2022 16:23:02\",\n",
      "        \"publication_authors\": \"Blyuss O, Zaikin A, Cherepanova V, Munblit D, Kiseleva EM, Prytomanova OM, Duffy SW, Crnogorac-Jurcevic T\",\n",
      "        \"publication_journal\": \"Br J Cancer\",\n",
      "        \"publication_title\": \"Development of PancRISK, a urine biomarker-based risk score for stratified screening of pancreatic cancer patients.\",\n",
      "        \"publication_doi\": \"10.1038/s41416-019-0694-0\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"c9c5b90f-7cb6-4c2e-9fd0-85cb16728ff1\",\n",
      "        \"shortid\": \"6ed6jt5sbi\",\n",
      "        \"score\": 0.38,\n",
      "        \"matches_publication/updated\": \"05/20/2022 16:23:02\",\n",
      "        \"matches_publication/authors\": \"Blyuss O, Zaikin A, Cherepanova V, Munblit D, Kiseleva EM, Prytomanova OM, Duffy SW, Crnogorac-Jurcevic T\",\n",
      "        \"matches_publication/journal\": \"Br J Cancer\",\n",
      "        \"matches_publication/title\": \"Development of PancRISK, a urine biomarker-based risk score for stratified screening of pancreatic cancer patients.\",\n",
      "        \"matches_optimization/algorithm\": \"Yes: SVM\",\n",
      "        \"matches_optimization/encoding\": \"Yes: images features (fractal dimension, 2D wavelet coefficients, percolation score)\",\n",
      "        \"matches_model/interpretability\": \"~Yes: comparison between different features\",\n",
      "        \"matches_evaluation/measure\": \"Yes: accuracy = R-square and RMSE\",\n",
      "        \"matches_evaluation/method\": \"independent dataset\",\n",
      "        \"matches_dataset/provenance\": \"Yes: dataset generated by own experiment\",\n",
      "        \"matches_dataset/splits\": \"~Yes but not very clear: 12 pos and 12 neg images, duplicated (image divided into four quadrant)->48 images pos and 48 images neg. divided: 80% cross-validation training set and 20% testing set.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b29\",\n",
      "        \"publication_pmid\": \"32344344\",\n",
      "        \"publication_updated\": \"06/23/2022 03:30:18\",\n",
      "        \"publication_authors\": \"Bouysset C, Belloir C, Antonczak S, Briand L, Fiorucci S\",\n",
      "        \"publication_journal\": \"Food Chem\",\n",
      "        \"publication_title\": \"Novel scaffold of natural compound eliciting sweet taste revealed by machine learning.\",\n",
      "        \"publication_doi\": \"10.1016/j.foodchem.2020.126864\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"4fd5e711-86f0-4064-a357-31d2f610128b\",\n",
      "        \"shortid\": \"l9ylxpirie\",\n",
      "        \"score\": 0.43,\n",
      "        \"matches_publication/updated\": \"06/23/2022 03:30:18\",\n",
      "        \"matches_publication/authors\": \"Bouysset C, Belloir C, Antonczak S, Briand L, Fiorucci S\",\n",
      "        \"matches_publication/journal\": \"Food Chem\",\n",
      "        \"matches_publication/title\": \"Novel scaffold of natural compound eliciting sweet taste revealed by machine learning.\",\n",
      "        \"matches_optimization/algorithm\": \"Novel approach (Preferential Subspace IDentification)\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/comparison\": \"neural dynamic mod- eling (NDM) e representational modeling (RM)\",\n",
      "        \"matches_evaluation/measure\": \"cross-validated CC between the true and predicted behavior\",\n",
      "        \"matches_dataset/availability\": \"Yes, Upon reasonable request from the corresponding author\",\n",
      "        \"matches_dataset/provenance\": \"Two monkeys!\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b2f\",\n",
      "        \"publication_pmid\": \"32826857\",\n",
      "        \"publication_updated\": \"01/26/2022 11:41:26\",\n",
      "        \"publication_authors\": \"Takahashi Y, Ueki M, Tamiya G, Ogishima S, Kinoshita K, Hozawa A, Minegishi N, Nagami F, Fukumoto K, Otsuka K, Tanno K, Sakata K, Shimizu A, Sasaki M, Sobue K, Kure S, Yamamoto M, Tomita H\",\n",
      "        \"publication_journal\": \"Transl Psychiatry\",\n",
      "        \"publication_title\": \"Machine learning for effectively avoiding overfitting is a crucial strategy for the genetic prediction of polygenic psychiatric phenotypes.\",\n",
      "        \"publication_doi\": \"10.1038/s41398-020-00957-5\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"0e4a9a17-a5bf-41d9-84a8-1eb49a8f35e5\",\n",
      "        \"shortid\": \"3qzygb13ir\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches_publication/updated\": \"01/26/2022 11:41:26\",\n",
      "        \"matches_publication/authors\": \"Takahashi Y, Ueki M, Tamiya G, Ogishima S, Kinoshita K, Hozawa A, Minegishi N, Nagami F, Fukumoto K, Otsuka K, Tanno K, Sakata K, Shimizu A, Sasaki M, Sobue K, Kure S, Yamamoto M, Tomita H\",\n",
      "        \"matches_publication/journal\": \"Transl Psychiatry\",\n",
      "        \"matches_publication/title\": \"Machine learning for effectively avoiding overfitting is a crucial strategy for the genetic prediction of polygenic psychiatric phenotypes.\",\n",
      "        \"matches_optimization/algorithm\": \"Deep neural network, end-to-end learning\",\n",
      "        \"matches_optimization/config\": \"The overall architecture is available in supporting information and released in github (https://github.com/fusong-ju/ProFOLD). Webserver is indicated but not functional (http://protein.ict.ac.cn/ProFOLD)\",\n",
      "        \"matches_optimization/encoding\": \"Multiple sequence alignment\",\n",
      "        \"matches_optimization/features\": \"Given the MSA, for each pair target-homologous sequences, each position is encoded with a 41-valued vector. Total encoding = Sequence length x Number of homologous sequences in MSA (Max 1000) x 41. No feature selection applied.\",\n",
      "        \"matches_optimization/fitting\": \"MSA sampling and distance matrix cropping in training process is adopted to avoid potential overfitting as well\",\n",
      "        \"matches_optimization/parameters\": \"6.46 M to 16.46 M parameters. Performance evaluated on the validation set.\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"classification (interresidue contacts) and regression (interresidue distance)\",\n",
      "        \"matches_evaluation/comparison\": \"RaptorX, AlphaFold, trRosetta\",\n",
      "        \"matches_evaluation/confidence\": \"No confidence intervals nor statistical significance reported\",\n",
      "        \"matches_evaluation/measure\": \"Precision of contact predictions at different thresholds\",\n",
      "        \"matches_evaluation/method\": \"Independent test set\",\n",
      "        \"matches_dataset/availability\": \"Yes, but the server is not working: http://protein.ict.ac.cn/ProFOLD\",\n",
      "        \"matches_dataset/provenance\": \"PDB, CATH, CASP13. \\n31,247 non-redundant domains + 104 domains from CASP13 (test).\\nThe number of contacts (positive) and non contacts (negative) is not reported\",\n",
      "        \"matches_dataset/redundancy\": \"Training/Validation: 35% sequence similarity cluster representatives of CATH (Mar 16, 2018). Test set released after 2018. Similarity with Training/Validation unclear\",\n",
      "        \"matches_dataset/splits\": \"Training: 29,247 domains; Validation: 1,820 domains; Test: 104 domains. Number of positive and negative not reported\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b30\",\n",
      "        \"publication_pmid\": \"32300371\",\n",
      "        \"publication_updated\": \"03/08/2022 12:38:13\",\n",
      "        \"publication_authors\": \"Sang X, Xiao W, Zheng H, Yang Y, Liu T\",\n",
      "        \"publication_journal\": \"Comput Math Methods Med\",\n",
      "        \"publication_title\": \"HMMPred: Accurate Prediction of DNA-Binding Proteins Based on HMM Profiles and XGBoost Feature Selection.\",\n",
      "        \"publication_doi\": \"10.1155/2020/1384749\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"bd99b02c-4c88-4e85-b466-4a97ef729643\",\n",
      "        \"shortid\": \"ij8nvrxx7j\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches_publication/updated\": \"03/08/2022 12:38:13\",\n",
      "        \"matches_publication/authors\": \"Sang X, Xiao W, Zheng H, Yang Y, Liu T\",\n",
      "        \"matches_publication/journal\": \"Comput Math Methods Med\",\n",
      "        \"matches_publication/title\": \"HMMPred: Accurate Prediction of DNA-Binding Proteins Based on HMM Profiles and XGBoost Feature Selection.\",\n",
      "        \"matches_optimization/algorithm\": \"Transfer learning with DL to extract features trained with stochastic gradient descent, SVM (linear kernel) for final classification into benign and malignant.\",\n",
      "        \"matches_optimization/encoding\": \"Five preprocessing steps to prepare mammography images (identification of ROI, image and size normalisation, and data augmentation (flipping and rotations). Image size was  224x224x3 \",\n",
      "        \"matches_optimization/features\": \"Handcrafted (455), clinical (5) and DL-based features (1024-dimensional vector) are used in the final classifier. MRMR is used for feature selection, reducing the number of features to 30 Hcr and 27 DL features, next to the clinical ones.\",\n",
      "        \"matches_optimization/fitting\": \"There are 7x744 datapoints for training, yet this seems still limited given the complexity of the DL network to extract features. Not considering the DL, and only the SVM, things look better as the feature set is reduced to 62 features in total, so f > p.\",\n",
      "        \"matches_optimization/meta\": \"Yes, for the DL feature extraction the VGG16 image-net trained network was used in combination with the Inception-V3 network into a fusion network.\",\n",
      "        \"matches_optimization/parameters\": \"The DL has its weights and layers next to the epoch, learning rate, momentum and weight decay parameters.  All parameters for the fusion network were transferred rom VGG16 and Inception V3 into a DL fusion network.  They added three additional FC layers.\",\n",
      "        \"matches_optimization/regularization\": \"SVM hyperparameters were tuned with grid-search and 10-fold cross-validation.  Tests were performed in an independent set and verified in an independent validation set.  Yet no stratification seems to be done.\",\n",
      "        \"matches_model/interpretability\": \"black box due to DL, but relatively transparent in the final classification step with SVM. The question is how interpretable the DL features are.\",\n",
      "        \"matches_model/output\": \"Benign or malignant mass.\",\n",
      "        \"matches_evaluation/comparison\": \"No comparison made with other approaches.\",\n",
      "        \"matches_evaluation/confidence\": \"yes, Dejong's test\",\n",
      "        \"matches_evaluation/measure\": \"Confusion matrix, calculating AUC, accuracy, sensitivity, precision, and F-score. Statistical significance with Delong's test (P<0.05 was considered significant).\",\n",
      "        \"matches_evaluation/method\": \"test set and independent validations set. Cross-validation when determining the optimal configuration of the SVM.\",\n",
      "        \"matches_dataset/availability\": \"No download information provided, but article contains statement that \\\"the data will  be made available without undue reservation\\\"\",\n",
      "        \"matches_dataset/provenance\": \"New cohort of 524 enrolled patients, 988 mammography images divided in 494 malignant and 494 benign masses.Data was preprocessed to be useful for DL work.  An additional validation set from another hospital is also used (58 patients). Not used before\",\n",
      "        \"matches_dataset/redundancy\": \"No stratification effort\",\n",
      "        \"matches_dataset/splits\": \"Data split 744 (training) and 244 (test) in a random manner. No details in Pos/Neg split but assumed to be equal.  \"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b32\",\n",
      "        \"publication_pmid\": \"32298292\",\n",
      "        \"publication_updated\": \"03/23/2022 11:05:15\",\n",
      "        \"publication_authors\": \"Kang AR, Lee J, Jung W, Lee M, Park SY, Woo J, Kim SH\",\n",
      "        \"publication_journal\": \"PLoS One\",\n",
      "        \"publication_title\": \"Development of a prediction model for hypotension after induction of anesthesia using machine learning.\",\n",
      "        \"publication_doi\": \"10.1371/journal.pone.0231172\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"31990540-50aa-4378-b78d-4ee10a62bdda\",\n",
      "        \"shortid\": \"7kuh4ta7dl\",\n",
      "        \"score\": 0.48,\n",
      "        \"matches_publication/updated\": \"03/23/2022 11:05:15\",\n",
      "        \"matches_publication/authors\": \"Kang AR, Lee J, Jung W, Lee M, Park SY, Woo J, Kim SH\",\n",
      "        \"matches_publication/journal\": \"PLoS One\",\n",
      "        \"matches_publication/title\": \"Development of a prediction model for hypotension after induction of anesthesia using machine learning.\",\n",
      "        \"matches_optimization/algorithm\": \"support vector machine (SVM) for which a linear C-SVM algorithm was applied, ii) decision trees, for which a Java open source implementation of the C4.5 algorithm (the J48 algorithm) was used and iii) the Naive Bayes (NB) classifier.\",\n",
      "        \"matches_optimization/features\": \"Features based on cortical thickness (CTH) and hippocampal volumes (HCV) extracted\\nfrom brain scans were used to train the learning algorithms.\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/comparison\": \"Direct, Direct VOI, STAND-score, Atlas, COMPARE, CTH-SVM, CTH-J48, \\n CTH-NB, NTI, ROI, Feature Vector, HCV-SVM, HCV-J48, HCV-NB, Volume- SPM5,\\n Volume-FreeSurfer, Shape. These are machine learning techniques used for mild cognitive\\n impairment patients classification. Accuracy is compared in Table 1 of the paper.\",\n",
      "        \"matches_dataset/availability\": \"Alzheimer \\u2019s Disease Neuroimaging Initiative (ADNI) (http://www.adni-info.org)\",\n",
      "        \"matches_dataset/provenance\": \"Alzheimer \\u2019s Disease Neuroimaging Initiative (ADNI), online database.\\nDataset size: 994. Split into 2 dataset: CTH, n= 650 and HCV, n= 299.\",\n",
      "        \"matches_dataset/splits\": \"CTH test set, n=167, training set n=483. HCV test set n=120, training set n=179.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b33\",\n",
      "        \"publication_pmid\": \"32878308\",\n",
      "        \"publication_updated\": \"03/29/2022 09:10:15\",\n",
      "        \"publication_authors\": \"Yilmaz A, Ugur Z, Bisgin H, Akyol S, Bahado-Singh R, Wilson G, Imam K, Maddens ME, Graham SF\",\n",
      "        \"publication_journal\": \"Metabolites\",\n",
      "        \"publication_title\": \"Targeted Metabolic Profiling of Urine Highlights a Potential Biomarker Panel for the Diagnosis of Alzheimer's Disease and Mild Cognitive Impairment: A Pilot Study.\",\n",
      "        \"publication_doi\": \"10.3390/metabo10090357\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"e2d3109d-c453-483d-8eb9-5fe17cc3bf50\",\n",
      "        \"shortid\": \"tgx5ifo7mb\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"03/29/2022 09:10:15\",\n",
      "        \"matches_publication/authors\": \"Yilmaz A, Ugur Z, Bisgin H, Akyol S, Bahado-Singh R, Wilson G, Imam K, Maddens ME, Graham SF\",\n",
      "        \"matches_publication/title\": \"Targeted Metabolic Profiling of Urine Highlights a Potential Biomarker Panel for the Diagnosis of Alzheimer's Disease and Mild Cognitive Impairment: A Pilot Study.\",\n",
      "        \"matches_optimization/algorithm\": \"5 algorithms used, LR, SVM, ANN, RF and XGBoost \",\n",
      "        \"matches_optimization/encoding\": \"mRnot reported data for 17 out 48 relevant molecules was used. The values expressed the difference in expression between the cancer and corresponding adjacent tissue.\",\n",
      "        \"matches_optimization/features\": \"17 features corresponding to the most relevant molecules, which were obtained from literature and an additional network analysis based on String. They tested with each ML algorithm all 2^17-1 (131071) feature combinations to see which ones lead to the best predictions. Selection was done on training set (I assume)\",\n",
      "        \"matches_optimization/fitting\": \"No information about parameters of the model and the model implementation.\",\n",
      "        \"matches_optimization/meta\": \"No data is used from other predictors, but the 5 predictors are used together as an ensemble to identify the most predictive features, i.e. the molecules useful for separating cases with good prognosis from bas ones\",\n",
      "        \"matches_optimization/parameters\": \"No details provided about the ML algorithm parameters\",\n",
      "        \"matches_optimization/regularization\": \"not clear.  They claim to have uses cross-validation but it is not explained in detail.\",\n",
      "        \"matches_model/interpretability\": \"both, they used LR as well as ANN.\",\n",
      "        \"matches_model/output\": \"Classification that is used to determine the most relevant set of features out of all 2^17-1 combinations.\",\n",
      "        \"matches_evaluation/comparison\": \"No comparison is made, as this is not the main point of this paper.\",\n",
      "        \"matches_evaluation/measure\": \"Only AUC was reported for the classifier, which is not the most suitable measure.\",\n",
      "        \"matches_evaluation/method\": \"They claim to have used crossvalidation but it is not explained. They use independent sets to test their findings and to relate the survival of patients to these findings.\",\n",
      "        \"matches_dataset/availability\": \"GEO and TCGA data is available. The 86 clinical cases are not reported, neither is the code provided for the ML part of the paper\",\n",
      "        \"matches_dataset/provenance\": \"Pubmed for relevant molecules (48 mol based on 38 articles), GEO (GSE53625 179 data points), TCGA (TCGA-ESCC 82 data points, 37 used for validation) and own clinical samples (86 samples)\",\n",
      "        \"matches_dataset/redundancy\": \"No mention made. Separation appears to be done randomly for the GEO set.  All the rest was used as validation.  No mention about the overlap between the sets.\",\n",
      "        \"matches_dataset/splits\": \"179 split into 134 training and 45 testing ESCC cases (randomly), 17 out of 48 moulecues were used as features for the classification.  ESCC cases with survival times more than 3 years were labelled 1 and the others were labelled 0, no information about the number in each set.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b4f\",\n",
      "        \"publication_pmid\": \"32933477\",\n",
      "        \"publication_updated\": \"01/18/2022 17:50:21\",\n",
      "        \"publication_authors\": \"Klosa J, Simon N, Westermark PO, Liebscher V, Wittenburg D\",\n",
      "        \"publication_journal\": \"BMC Bioinformatics\",\n",
      "        \"publication_title\": \"Seagull: lasso, group lasso and sparse-group lasso regularization for linear regression models via proximal gradient descent.\",\n",
      "        \"publication_doi\": \"10.1186/s12859-020-03725-w\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"e9544652-63df-4961-abc7-af965754adc8\",\n",
      "        \"shortid\": \"25pxfm641i\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"01/18/2022 17:50:21\",\n",
      "        \"matches_publication/authors\": \"Klosa J, Simon N, Westermark PO, Liebscher V, Wittenburg D\",\n",
      "        \"matches_publication/journal\": \"BMC Bioinformatics\",\n",
      "        \"matches_publication/title\": \"Seagull: lasso, group lasso and sparse-group lasso regularization for linear regression models via proximal gradient descent.\",\n",
      "        \"matches_optimization/algorithm\": \"SVM with RBF kernel\",\n",
      "        \"matches_optimization/config\": \"partially - only some hyper-parameters are given in the text\",\n",
      "        \"matches_optimization/encoding\": \"global features\",\n",
      "        \"matches_optimization/features\": \"originally over 433; 39 after \\\"parameter optimisation\\\"; further reduced to 21 by max-relevance-max-distance algorithm\",\n",
      "        \"matches_optimization/parameters\": \"39 or 21 (after dimension reduction using max-relevance-max-distance)\",\n",
      "        \"matches_optimization/regularization\": \"yes, L2 regularisation\",\n",
      "        \"matches_model/duration\": \"not given but should be instant\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"binary classification\",\n",
      "        \"matches_evaluation/availability\": \"no raw evaluation files; confusion matrix is in the text\",\n",
      "        \"matches_evaluation/measure\": \"Recall, Precision, Accuracy, MCC\",\n",
      "        \"matches_evaluation/method\": \"5-fold CV; independent test set\",\n",
      "        \"matches_dataset/availability\": \"yes, https://github.com/taozhy/identifying-vesicle-transport-proteins\",\n",
      "        \"matches_dataset/provenance\": \"based on UniProt search; dataset published in 2019; 2533 pos and 9086 neg\",\n",
      "        \"matches_dataset/redundancy\": \"The original data was processed by BLAST to get the sequence similarity to less than 30%; the test set was used before.\",\n",
      "        \"matches_dataset/splits\": \"Train: 2214 (pos) and 2214 (neg) -> 5-fold CV; test 319 (pos) 1513 (neg);\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b50\",\n",
      "        \"publication_pmid\": \"33329703\",\n",
      "        \"publication_updated\": \"02/16/2022 09:43:09\",\n",
      "        \"publication_authors\": \"Tian Y, Wang J, Qin C, Zhu G, Chen X, Chen Z, Qin Y, Wei M, Li Z, Zhang X, Lv Y, Cai G\",\n",
      "        \"publication_journal\": \"Front Genet\",\n",
      "        \"publication_title\": \"Identifying 8-mRNAsi Based Signature for Predicting Survival in Patients With Head and Neck Squamous Cell Carcinoma via Machine Learning.\",\n",
      "        \"publication_doi\": \"10.3389/fgene.2020.566159\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"3785a62f-b82d-40db-9c45-88dbe0b8582f\",\n",
      "        \"shortid\": \"hlpvh7cgmc\",\n",
      "        \"score\": 0.48,\n",
      "        \"matches_publication/updated\": \"02/16/2022 09:43:09\",\n",
      "        \"matches_publication/authors\": \"Tian Y, Wang J, Qin C, Zhu G, Chen X, Chen Z, Qin Y, Wei M, Li Z, Zhang X, Lv Y, Cai G\",\n",
      "        \"matches_publication/journal\": \"Front Genet\",\n",
      "        \"matches_publication/title\": \"Identifying 8-mRNAsi Based Signature for Predicting Survival in Patients With Head and Neck Squamous Cell Carcinoma via Machine Learning.\",\n",
      "        \"matches_optimization/algorithm\": \"Variant of random forest regression\",\n",
      "        \"matches_optimization/config\": \"Hyperparameters reported in the paper\",\n",
      "        \"matches_optimization/encoding\": \"Counts of all possible 3- to 8-letter-long sequence motifs present in the 5= and 3= UTRs\",\n",
      "        \"matches_optimization/features\": \"200,000 features for UTR sequence motif analysis / using a random subset of features to identify the best candidate feature for splitting at each node\",\n",
      "        \"matches_model/interpretability\": \"Transparent, T rich UTRs provide stability\",\n",
      "        \"matches_dataset/availability\": \"Yes, https://www.ncbi.nlm.nih.gov/sra/SRP130967 (Sequences) https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE109174 (transcripts half-life)\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b51\",\n",
      "        \"publication_pmid\": \"33324147\",\n",
      "        \"publication_updated\": \"03/01/2022 14:21:27\",\n",
      "        \"publication_authors\": \"Liu W, Zhang X, Qiao Y, Cai Y, Yin H, Zheng M, Zhu Y, Wang H\",\n",
      "        \"publication_journal\": \"Front Neurosci\",\n",
      "        \"publication_title\": \"Functional Connectivity Combined With a Machine Learning Algorithm Can Classify High-Risk First-Degree Relatives of Patients With Schizophrenia and Identify Correlates of Cognitive Impairments.\",\n",
      "        \"publication_doi\": \"10.3389/fnins.2020.577568\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"0f17c012-ed0e-4766-801b-39bb206b5767\",\n",
      "        \"shortid\": \"caz69j3bqb\",\n",
      "        \"score\": 0.52,\n",
      "        \"matches_publication/updated\": \"03/01/2022 14:21:27\",\n",
      "        \"matches_publication/authors\": \"Liu W, Zhang X, Qiao Y, Cai Y, Yin H, Zheng M, Zhu Y, Wang H\",\n",
      "        \"matches_publication/journal\": \"Front Neurosci\",\n",
      "        \"matches_publication/title\": \"Functional Connectivity Combined With a Machine Learning Algorithm Can Classify High-Risk First-Degree Relatives of Patients With Schizophrenia and Identify Correlates of Cognitive Impairments.\",\n",
      "        \"matches_optimization/algorithm\": \"Random Forest + Network Embedding  + Network Similarity\",\n",
      "        \"matches_optimization/parameters\": \"3, Random Forest\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/comparison\": \"DeepWalk, Line, Node2Vec, GraRep, GF, Lap, lle (all Network Embedding methods)\",\n",
      "        \"matches_evaluation/measure\": \"ROC-AUC, PR_AUC, Precision, Accuracy, F1, Recall\",\n",
      "        \"matches_evaluation/method\": \"Cross validation\",\n",
      "        \"matches_dataset/provenance\": \"Database HMDD3.0 (http://www.cuilab.cn/hmdde)\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b52\",\n",
      "        \"publication_pmid\": \"33133228\",\n",
      "        \"publication_updated\": \"03/07/2022 10:25:36\",\n",
      "        \"publication_authors\": \"Tao Z, Li Y, Teng Z, Zhao Y\",\n",
      "        \"publication_journal\": \"Comput Math Methods Med\",\n",
      "        \"publication_title\": \"A Method for Identifying Vesicle Transport Proteins Based on LibSVM and MRMD.\",\n",
      "        \"publication_doi\": \"10.1155/2020/8926750\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"827777a1-d886-4bc3-b9c3-91083dffda4f\",\n",
      "        \"shortid\": \"43nakaafp9\",\n",
      "        \"score\": 0.38,\n",
      "        \"matches_publication/updated\": \"03/07/2022 10:25:36\",\n",
      "        \"matches_publication/authors\": \"Tao Z, Li Y, Teng Z, Zhao Y\",\n",
      "        \"matches_publication/journal\": \"Comput Math Methods Med\",\n",
      "        \"matches_publication/title\": \"A Method for Identifying Vesicle Transport Proteins Based on LibSVM and MRMD.\",\n",
      "        \"matches_optimization/features\": \"584, SVM-recursive feature elimination used for feature selection on training data only.\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"Binary predictions\",\n",
      "        \"matches_evaluation/measure\": \"sensitivity, specificity, AUC-ROC curve\",\n",
      "        \"matches_evaluation/method\": \"Independent dataset\",\n",
      "        \"matches_dataset/provenance\": \"CT images from a total of 739 patients with gastric cancer. \",\n",
      "        \"matches_dataset/splits\": \"286 training - 453 validation No info on N_pos and N_neg immediately available \"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b53\",\n",
      "        \"publication_pmid\": \"32324731\",\n",
      "        \"publication_updated\": \"03/08/2022 15:42:05\",\n",
      "        \"publication_authors\": \"Chen Q, Lee K, Yan S, Kim S, Wei CH, Lu Z\",\n",
      "        \"publication_journal\": \"PLoS Comput Biol\",\n",
      "        \"publication_title\": \"BioConceptVec: Creating and evaluating literature-based biomedical concept embeddings on a large scale.\",\n",
      "        \"publication_doi\": \"10.1371/journal.pcbi.1007617\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"35561cc1-0576-4757-b30f-5bcd7b65ce52\",\n",
      "        \"shortid\": \"yuk8w6yxtm\",\n",
      "        \"score\": 0.48,\n",
      "        \"matches_publication/updated\": \"03/08/2022 15:42:05\",\n",
      "        \"matches_publication/authors\": \"Chen Q, Lee K, Yan S, Kim S, Wei CH, Lu Z\",\n",
      "        \"matches_publication/journal\": \"PLoS Comput Biol\",\n",
      "        \"matches_publication/title\": \"BioConceptVec: Creating and evaluating literature-based biomedical concept embeddings on a large scale.\",\n",
      "        \"matches_optimization/algorithm\": \"Random Forests\",\n",
      "        \"matches_optimization/encoding\": \"Rnot reported-Seq expression values in transcripts per million (TPM) were log2-transformed and normalized. \\nEstimation of relative immune cell relative infiltration and abundance  by using the method single\\u2011sample gene set enrichment analysis (ssGSEA) which identified gene sets from the Molecular Signatures Database that were enriched in TNBC Rnot reported-Seq data. 28 heterogeneous immune cells were classified according to gene sets. The degree of immune cell infiltration was determined by the ssGSEA scores. The immune signature was clustered into 3 populations, namely high\\u2011, medium\\u2011 and low\\u2011infiltration.\",\n",
      "        \"matches_optimization/features\": \"Hundreds of variants, TMB data, were employed as input parameters, including the relative infiltration of the 28 types of heterogenous immune cells, somatic mutation counts, 78 immune\\u2011related molecules, and 50 signaling pathways from the HALLMARK collection. In total 782 features were used to assess cytolytic activity (CYT).\",\n",
      "        \"matches_model/interpretability\": \"Feature importance score, relative contribution of each factor to the resulting immune response, for determining the most important features for CYT.\",\n",
      "        \"matches_model/output\": \"Multi-label predictions\",\n",
      "        \"matches_evaluation/comparison\": \"Factors that were associated with immune response in this analysis were consistent with established knowledge on antitumor immunity.\",\n",
      "        \"matches_evaluation/confidence\": \"OOB samples providing estimates of model error rate for the decision trees.\",\n",
      "        \"matches_evaluation/measure\": \"Out of bag (OOB) scores\",\n",
      "        \"matches_dataset/availability\": \"The datasets generated and/or analyzed during the present\\nstudy are available in the TCGA database.\",\n",
      "        \"matches_dataset/provenance\": \"Rnot reported-Seq expression values of immune regulatory molecules, including CTLA\\u20114, IDO1, LAG3, PDCD1, PDL1 and TIM3 across four types of breast cancer (HER2, luminal A, luminal B and TNBC) from The Cancer Genome Atlas (TCGA) database.\\nData for tumor mutation burden (TMB) from TCGA database.\\n\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b54\",\n",
      "        \"publication_pmid\": \"33328863\",\n",
      "        \"publication_updated\": \"03/15/2022 11:03:41\",\n",
      "        \"publication_authors\": \"La Rocca M, Garner R, Amoroso N, Lutkenhoff ES, Monti MM, Vespa P, Toga AW, Duncan D\",\n",
      "        \"publication_journal\": \"Front Neurosci\",\n",
      "        \"publication_title\": \"Multiplex Networks to Characterize Seizure Development in Traumatic Brain Injury Patients.\",\n",
      "        \"publication_doi\": \"10.3389/fnins.2020.591662\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"5a5db1d1-8e51-4dca-aee1-ec8f06e46300\",\n",
      "        \"shortid\": \"5iyltalim1\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches_publication/updated\": \"03/15/2022 11:03:41\",\n",
      "        \"matches_publication/authors\": \"La Rocca M, Garner R, Amoroso N, Lutkenhoff ES, Monti MM, Vespa P, Toga AW, Duncan D\",\n",
      "        \"matches_publication/journal\": \"Front Neurosci\",\n",
      "        \"matches_publication/title\": \"Multiplex Networks to Characterize Seizure Development in Traumatic Brain Injury Patients.\",\n",
      "        \"matches_optimization/algorithm\": \"Support Vector Machine with Linear kernel (Linear SVM)\",\n",
      "        \"matches_optimization/encoding\": \"The subjects\\u2019 brains were parcellated into 200 regions of interest (ROIs) using the Craddock atlas. \\u03a4he RS-fMRI data were preprocessed to calculate FC measures between each pair of ROIs. \\nFriston-24 parameters were used to regress out the effects of head motion. To further reduce the effects of nuisance factors, signals from cerebrospinal fluid and white matter were also regressed out. \\nDARTEL toolbox was used to normalize the data and the resulting images were finally smoothed with a 6-mm full width at half maximum (FWHM) Gaussian kernel.\\nThe time series within each ROI were first band-pass filtered (0.01\\u20130.08 Hz) and then averaged. For each participant, FC was calculated between each ROI using Pearson\\u2019s correlation coefficients, resulting in 19900-dimensional FC feature vectors for each subject.\\nPatients with SCZ were labeled as 1, and HCs were labeled as -1.\\n\",\n",
      "        \"matches_optimization/features\": \"FC measurements between each pair of the 200 brain ROIs were used as classification features. Feature selection was performed for data dimension reduction using F-score for feature ranking. The 644 highest-ranked FC features were used to build the classifier.\",\n",
      "        \"matches_optimization/parameters\": \"Linear SVM was implemented using the LIBSVM toolbox with the parameter C set to the default value of 1.\",\n",
      "        \"matches_optimization/regularization\": \"Yes. Linear SVM with C=1 and feature selection for data dimension reduction were selected to avoid overfitting.\",\n",
      "        \"matches_model/interpretability\": \"Feature weight extraction from the Linear SVM model and feature selection for data dimension reduction, using F-score for feature ranking, were performed to interpret feature importance. This allowed for the identification of the 18 ROIs having weights that were at least 1 standard deviation greater than the average of the weights of all regions, thus making the greatest contribution to the model.\",\n",
      "        \"matches_model/output\": \"1) Binary predictions.\\n 2) Classification score, which is the average of the 76 prediction labels. From a range of -1 to 1, a positive score indicates a SCZ pattern, and a negative score indicates a HC pattern. Binary predictions.\",\n",
      "        \"matches_evaluation/confidence\": \"1) Permutation statistical testing.\\n 2) Semantic fluency test (animal version) was administered to evaluate the executive function and the semantic memory, which are severely affected in SCZ. The performance was analyzed using the number of correct words within 1 min. Statistical testing of the correlation between classification score and semantic fluency scores of FDR participants.\",\n",
      "        \"matches_evaluation/measure\": \"Accuracy, sensitivity, specificity, ROC curve, AUC score.\",\n",
      "        \"matches_evaluation/method\": \"Leave one-out cross-validation (LOOCV).\\n Independent dataset of 142 features obtained by masking DMN, FP, auditory, and sensorimotor brain networks. Similar training of a Linear SVM classifier and evaluation of the resulting metrics.\",\n",
      "        \"matches_dataset/availability\": \"Declared availability upon request.\",\n",
      "        \"matches_dataset/provenance\": \"Functional connectivity (FC) patterns obtained from resting-state functional magnetic resonance imaging (RS-fMRI).\\n1)\\tNpos=38 Schizophrenia (SCZ) patients and Nneg=38 healthy controls (HC)\\n2)\\tThe produced classifier was applied to Ntest=38 high-risk first-degree relatives (FDRs) to predict their cognitive performance.\\n\",\n",
      "        \"matches_dataset/splits\": \"Leave one- out cross-validation, with Ntrain=37 and Ntest=1 for each iteration.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b55\",\n",
      "        \"publication_pmid\": \"32915751\",\n",
      "        \"publication_updated\": \"03/28/2022 12:23:43\",\n",
      "        \"publication_authors\": \"Wang Z, Liu Q, Dou Q\",\n",
      "        \"publication_journal\": \"IEEE J Biomed Health Inform\",\n",
      "        \"publication_title\": \"Contrastive Cross-Site Learning With Redesigned Net for COVID-19 CT Classification.\",\n",
      "        \"publication_doi\": \"10.1109/JBHI.2020.3023246\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"2598df6d-6714-4983-8db6-20a2fe1309b4\",\n",
      "        \"shortid\": \"opx6a1juph\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"03/28/2022 12:23:43\",\n",
      "        \"matches_publication/authors\": \"Wang Z, Liu Q, Dou Q\",\n",
      "        \"matches_publication/journal\": \"IEEE J Biomed Health Inform\",\n",
      "        \"matches_publication/title\": \"Contrastive Cross-Site Learning With Redesigned Net for COVID-19 CT Classification.\",\n",
      "        \"matches_optimization/algorithm\": \"a version of Lasso-penalized Cox regression\",\n",
      "        \"matches_optimization/encoding\": \"filtering of data points and features (SNPs)\",\n",
      "        \"matches_optimization/features\": \"f = 533 000 SNPs; SNPs in linkage disequilibrium were removed, using a correlation threshold of 0.1 and resulting in 108 254 features (not clear if this was done only based on the training data). \",\n",
      "        \"matches_optimization/parameters\": \"not reported explicitly; should be at least n+n^2 for n=108 254\",\n",
      "        \"matches_optimization/regularization\": \"Yes: lasso + selecting only the SNPs involved in the top 1000 one-way and all the SNPs from the top 1000 two-way interactions models based on 2-fold CV.\",\n",
      "        \"matches_model/interpretability\": \"transparent: identification of genes\",\n",
      "        \"matches_evaluation/comparison\": \"Only comparison against previous state-of-the-art method, Survival MDR (Surv-MDR)\",\n",
      "        \"matches_evaluation/confidence\": \"None for the model for the real data; two simulation studies were created to estimate the 5% type I error and power; the significance of the selected models (intermediate step) was evaluated by a 10000-fold permutation test.\",\n",
      "        \"matches_evaluation/measure\": \"time-dependent ROC and its AUC\",\n",
      "        \"matches_evaluation/method\": \"2-fold cross validation + independent test set.\",\n",
      "        \"matches_dataset/availability\": \"Only unfiltered data: NCBI dbGaP repository phs001273.v3.p2, https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs001273.v3.p2.\",\n",
      "        \"matches_dataset/provenance\": \"Originally, there were 533,631 SNPs from 57,775 individuals in the OncoArray-TRICL Consortium population-based study. The filtered data had 27722 individuals (14935 positive and 12787 negative cases). Two simulated datasets were also used to evaluate the type I error rate and power. \",\n",
      "        \"matches_dataset/redundancy\": \"None between the splits, but participants who were close relatives (second degree relatives or closer) and duplicate individuals were filtered out from the beginning.\",\n",
      "        \"matches_dataset/splits\": \"random sampling: 2/3 into a training set and 1/3 into the testing set; 2-fold cross-validation\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b6f\",\n",
      "        \"publication_pmid\": \"33240258\",\n",
      "        \"publication_updated\": \"02/09/2022 15:02:29\",\n",
      "        \"publication_authors\": \"Jia J, Wang M, Ma Y, Teng J, Shi H, Liu H, Sun Y, Su Y, Meng J, Chi H, Chen X, Cheng X, Ye J, Liu T, Wang Z, Wan L, Zhou Z, Wang F, Yang C, Hu Q\",\n",
      "        \"publication_journal\": \"Front Immunol\",\n",
      "        \"publication_title\": \"Circulating Neutrophil Extracellular Traps Signature for Identifying Organ Involvement and Response to Glucocorticoid in Adult-Onset Still's Disease: A Machine Learning Study.\",\n",
      "        \"publication_doi\": \"10.3389/fimmu.2020.563335\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"59ef281d-0bee-4188-a2b4-10dd495bb666\",\n",
      "        \"shortid\": \"f66mtky2wk\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches_publication/updated\": \"02/09/2022 15:02:29\",\n",
      "        \"matches_publication/authors\": \"Jia J, Wang M, Ma Y, Teng J, Shi H, Liu H, Sun Y, Su Y, Meng J, Chi H, Chen X, Cheng X, Ye J, Liu T, Wang Z, Wan L, Zhou Z, Wang F, Yang C, Hu Q\",\n",
      "        \"matches_publication/journal\": \"Front Immunol\",\n",
      "        \"matches_publication/title\": \"Circulating Neutrophil Extracellular Traps Signature for Identifying Organ Involvement and Response to Glucocorticoid in Adult-Onset Still's Disease: A Machine Learning Study.\",\n",
      "        \"matches_optimization/algorithm\": \"Multi-Layer Perceptron \",\n",
      "        \"matches_optimization/regularization\": \"No, high ratio between the number of experimental values in the training and number of parameters in the model \",\n",
      "        \"matches_model/availability\": \"Supplementary information\",\n",
      "        \"matches_model/duration\": \"about 13 minutes\",\n",
      "        \"matches_model/interpretability\": \"Black Box\",\n",
      "        \"matches_evaluation/comparison\": \"Neural Network with two hidden layers, k-nearest neighbors, Random Forest, SVM\",\n",
      "        \"matches_evaluation/confidence\": \"Confidence intervals\",\n",
      "        \"matches_evaluation/measure\": \"Confusion matrix\",\n",
      "        \"matches_dataset/availability\": \"Support information files.\",\n",
      "        \"matches_dataset/provenance\": \"Database CATnot reportedP http://hiv.lanl.gov/catnap\",\n",
      "        \"matches_dataset/splits\": \"3864 exact IC50 values are split randomly in half into a training set and a validation set.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b70\",\n",
      "        \"publication_pmid\": \"32218835\",\n",
      "        \"publication_updated\": \"03/02/2022 11:14:34\",\n",
      "        \"publication_authors\": \"Cheng J, Ding X, Xu S, Zhu B, Jia Q\",\n",
      "        \"publication_journal\": \"Oncol Lett\",\n",
      "        \"publication_title\": \"Gene expression profiling identified TP53<sup>Mut</sup>PIK3CA<sup>Wild</sup> as a potential biomarker for patients with triple-negative breast cancer treated with immune checkpoint inhibitors.\",\n",
      "        \"publication_doi\": \"10.3892/ol.2020.11381\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"94f52be3-39fa-4f72-9fc2-9ab4ae112839\",\n",
      "        \"shortid\": \"st1jp9fgiv\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"03/02/2022 11:14:34\",\n",
      "        \"matches_publication/authors\": \"Cheng J, Ding X, Xu S, Zhu B, Jia Q\",\n",
      "        \"matches_publication/journal\": \"Oncol Lett\",\n",
      "        \"matches_publication/title\": \"Gene expression profiling identified TP53<sup>Mut</sup>PIK3CA<sup>Wild</sup> as a potential biomarker for patients with triple-negative breast cancer treated with immune checkpoint inhibitors.\",\n",
      "        \"matches_optimization/algorithm\": \"Several methods are tested to find the optimal feature subset for classification (see fig1 in the paper). Includes multi-layer perceptrons, random forest, SVM and a combination of a VAE with a MLP.\",\n",
      "        \"matches_optimization/config\": \"some parts yes, other parts no\",\n",
      "        \"matches_optimization/encoding\": \"not reported in this article (ref to earlier article)\",\n",
      "        \"matches_optimization/features\": \"230 features, wrapper method with cross-validation to find the optimal subset.  VAE extraction applied also to data to identify other features\",\n",
      "        \"matches_optimization/fitting\": \"double loop of cross validation (5-fold) and ,multiple runs to obtain statistically robust results. \",\n",
      "        \"matches_optimization/meta\": \"not meta-predictions, everything is performed on the raw data. \",\n",
      "        \"matches_optimization/parameters\": \"Not all details provided about the parameters for each model. RF optimised by verifying different depths (yet number of trees was not mentioned). No details about SVM. VAE and MLP are shown in figures\",\n",
      "        \"matches_model/interpretability\": \"dependent on the classification approach. Most relevant features are explained. An expert should be able to get some understanding from the remaining features, yet interpreting the latent variables produced by the VAE will be complicated.\",\n",
      "        \"matches_model/output\": \"binary prediction\",\n",
      "        \"matches_evaluation/comparison\": \"no other methods compared\",\n",
      "        \"matches_evaluation/confidence\": \"DeLong method to compare AUC's\",\n",
      "        \"matches_evaluation/measure\": \"average AUC\",\n",
      "        \"matches_evaluation/method\": \"double loop of cross-validations and multiple repeats to overcome the imbalance in the data set.\",\n",
      "        \"matches_dataset/availability\": \"no \",\n",
      "        \"matches_dataset/provenance\": \"106 patients with non small cell lung cancer, 22 positive (>=2) long radiation pneumotis and 84 (<2) negative patients. Each patient is annotated with 230 features. Patient data comes from another publication 28237401. Data does not seem to be downloadable.\",\n",
      "        \"matches_dataset/splits\": \"System of inner and outer cross validation (5-fold) with multiple repeats of both loops. Distributions across sets or stratifications were not reported\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b71\",\n",
      "        \"publication_pmid\": \"32753502\",\n",
      "        \"publication_updated\": \"03/04/2022 17:00:53\",\n",
      "        \"publication_authors\": \"Gordon GC, Cameron JC, Gupta STP, Engstrom MD, Reed JL, Pfleger BF\",\n",
      "        \"publication_journal\": \"mSystems\",\n",
      "        \"publication_title\": \"Genome-Wide Analysis of RNA Decay in the Cyanobacterium <i>Synechococcus</i> sp. Strain PCC 7002.\",\n",
      "        \"publication_doi\": \"10.1128/mSystems.00224-20\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"52d91d41-3b36-4240-bf74-f433787be438\",\n",
      "        \"shortid\": \"21vzta5ft2\",\n",
      "        \"score\": 0.33,\n",
      "        \"matches_publication/updated\": \"03/04/2022 17:00:53\",\n",
      "        \"matches_publication/authors\": \"Gordon GC, Cameron JC, Gupta STP, Engstrom MD, Reed JL, Pfleger BF\",\n",
      "        \"matches_publication/title\": \"Genome-Wide Analysis of RNA Decay in the Cyanobacterium <i>Synechococcus</i> sp. Strain PCC 7002.\",\n",
      "        \"matches_optimization/algorithm\": \"Random forest\",\n",
      "        \"matches_model/interpretability\": \"Transparent. 12 metabolites were determined to be informative for MS status\",\n",
      "        \"matches_evaluation/method\": \"Other experiments and literature.\",\n",
      "        \"matches_dataset/provenance\": \"Untargeted two-dimensional gas chromatography and time-of-flight mass spectrometry. 12_pos and 13_neg\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b72\",\n",
      "        \"publication_pmid\": \"33039708\",\n",
      "        \"publication_updated\": \"03/27/2022 23:10:49\",\n",
      "        \"publication_authors\": \"Bitencourt AGV, Gibbs P, Rossi Saccarelli C, Daimiel I, Lo Gullo R, Fox MJ, Thakur S, Pinker K, Morris EA, Morrow M, Jochelson MS\",\n",
      "        \"publication_journal\": \"EBioMedicine\",\n",
      "        \"publication_title\": \"MRI-based machine learning radiomics can predict HER2 expression level and pathologic response after neoadjuvant therapy in HER2 overexpressing breast cancer.\",\n",
      "        \"publication_doi\": \"10.1016/j.ebiom.2020.103042\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"d6512a82-bc58-4d38-a7de-a80eecdc7a16\",\n",
      "        \"shortid\": \"4zvfuyfezh\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches_publication/updated\": \"03/27/2022 23:10:49\",\n",
      "        \"matches_publication/authors\": \"Bitencourt AGV, Gibbs P, Rossi Saccarelli C, Daimiel I, Lo Gullo R, Fox MJ, Thakur S, Pinker K, Morris EA, Morrow M, Jochelson MS\",\n",
      "        \"matches_publication/title\": \"MRI-based machine learning radiomics can predict HER2 expression level and pathologic response after neoadjuvant therapy in HER2 overexpressing breast cancer.\",\n",
      "        \"matches_optimization/algorithm\": \"SVM, random forest, ensemble learning\",\n",
      "        \"matches_optimization/config\": \"Some hyperparameters are given in the text.\",\n",
      "        \"matches_optimization/encoding\": \"Global features\",\n",
      "        \"matches_optimization/features\": \"PCA to capture at least 70%, projected to the range of 10-20 features \",\n",
      "        \"matches_optimization/parameters\": \"Forced to be in the range of 10-20 + 4 (for SVM) by PCA to capture at least 70%\",\n",
      "        \"matches_model/availability\": \"https://github.com/SydneyBioX/scReClassify; https://bioconductor.org/packages/release/bioc/html/scReClassify.html; GPL-3 license\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"multi-class reclassification (error correction)\",\n",
      "        \"matches_evaluation/measure\": \"mean classification accuracy; adjusted Rand index\",\n",
      "        \"matches_evaluation/method\": \"Training data only\",\n",
      "        \"matches_dataset/availability\": \"yes for real-world data: https://www.ebi.ac.uk/arrayexpress/help/GEO_data.html (ids E-MTAB-3929, GSE87795, GSE60361, GSE82187)\",\n",
      "        \"matches_dataset/provenance\": \"Simulated and real-world experimental scRnot reported-seq datasets: the simulated sets had 100 points for each of 3, 5, 7, or 9 classes. The real-world sets were 4 from literature (1059 points with 3 classes, 367 points with 6 classes, 3005 points with 7 classes and 705 points for 10 classes). Some of the labels of all the datasets were artificially corrupted.\",\n",
      "        \"matches_dataset/splits\": \"multiple AdaSampling (self-supervision) \"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b7f\",\n",
      "        \"publication_pmid\": \"33126877\",\n",
      "        \"publication_updated\": \"02/23/2022 08:54:37\",\n",
      "        \"publication_authors\": \"Luyapan J, Ji X, Li S, Xiao X, Zhu D, Duell EJ, Christiani DC, Schabath MB, Arnold SM, Zienolddiny S, Brunnstr\\u00f6m H, Melander O, Thornquist MD, MacKenzie TA, Amos CI, Gui J\",\n",
      "        \"publication_journal\": \"BMC Med Genomics\",\n",
      "        \"publication_title\": \"A new efficient method to detect genetic interactions for lung cancer GWAS.\",\n",
      "        \"publication_doi\": \"10.1186/s12920-020-00807-9\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"82cf0bf2-90df-48f5-9e3f-8671010c3fc3\",\n",
      "        \"shortid\": \"58820ywq9x\",\n",
      "        \"score\": 0.86,\n",
      "        \"matches_publication/updated\": \"02/23/2022 08:54:37\",\n",
      "        \"matches_publication/authors\": \"Luyapan J, Ji X, Li S, Xiao X, Zhu D, Duell EJ, Christiani DC, Schabath MB, Arnold SM, Zienolddiny S, Brunnstr\\u00f6m H, Melander O, Thornquist MD, MacKenzie TA, Amos CI, Gui J\",\n",
      "        \"matches_publication/journal\": \"BMC Med Genomics\",\n",
      "        \"matches_publication/title\": \"A new efficient method to detect genetic interactions for lung cancer GWAS.\",\n",
      "        \"matches_optimization/algorithm\": \"Random forest, Support Vector Machine (SVM), and SVM with LASSO feature selection.\",\n",
      "        \"matches_optimization/config\": \"Yes. GitHub website. https://github.com/ShenLab/episcore\",\n",
      "        \"matches_optimization/encoding\": \"For promoter features (H2A.Z, H3K27me3, H3K4me3, and H3K9ac), GappedPeaks were used to allow for broad domains of ChIP-seq signal. The assignment of a GapppedPeak to a gene followed these steps in order: \\n1)\\tFor each gene, only TSS of Ensembl canonical transcripts were used.\\n2)\\tA GappedPeak was assigned to a TSS if the GappedPeak overlaps with the upstream 5 kb to downstream 1 kb region around the TSS. This definition of basal cis-regulatory region around promoter was according to GREAT tool. Assigning one GappedPeak to multiple TSS was allowed.\\n3)\\tFor TSS having more than 1 GappedPeak assigned, only the closest one was kept.\\n4)\\tFor genes with multiple TSS and hence multiple assigned GappedPeaks, only the longest GappedPeak was kept.\\nAfter these four steps, if one gene had been associated with a GappedPeak, then the width of the peak was used as an epigenomic feature in the following machine learning models. If a gene had no associated GappedPeak, then the peak width is 0.\\n\\nCoverage of H3K27ac, H3K27me3, H3K36me3, H3K4me1, H3K4me3, H3K9me3, DNase I, and Rnot reported-seq data was used as input for EpiTensor to infer interacting enhancers across distant genomic regions. This was done as balance between more input data types and more cell types included, as not every cell type has all these histone modifications characterized.\\n\",\n",
      "        \"matches_optimization/features\": \"The widths of called ChIP-seq peaks was used as promoter features. The counts of the interacting number of promoters and enhancers within pre-defined topologically associated domains (TADs) as enhancer features.\\nSpecifically, the results of peak width and number of interacting enhancers were consolidated into a matrix, with each row being a gene and each column representing a combination of a tissue and a data type, e.g. \\u201cH3K4me3 peak width in fetal heart\\u201d. One combination of a tissue and a data type was referred to as one epigenomic feature. This matrix was used as input for the machine learning models.\\n\",\n",
      "        \"matches_optimization/parameters\": \"Alpha parameter equal to 1 for Lasso regularization. No further parameters were specified.\",\n",
      "        \"matches_optimization/regularization\": \"Yes. LASSO regularization was used with SVM for overfitting prevention.\",\n",
      "        \"matches_model/availability\": \"Yes. GitHub website. https://github.com/ShenLab/episcore\",\n",
      "        \"matches_model/interpretability\": \"Epigenomic features critical for the prediction were determined by calculating a Spearman correlation coefficient between each epigenomic feature and Episcore (random forest model) prediction. \\n One epigenomic feature corresponds to a data type per certain tissue/cell type. To examine which data types are more important, these Spearman correlation coefficients were plotted by data type. \\n To examine what tissue/cell types are more important, the averaged z-score for each tissue/cell type was calculated by:\\n 1) Converting every Spearman correlation coefficient to a Z-score using mean and standard deviation specific to each data type and\\n 2) Average Z-scores from various data types for each tissue/cell type.\\n This analysis indicated that epigenomic features in stem cells, brain tissues, and fetal tissues contribute more to Episcore prediction than other features.\",\n",
      "        \"matches_model/output\": \"Binary predictions. All training genes used to train the best performing Random Forest model, and then estimate the probabilities of being positive (HIS) for all genes. The whole process was repeated 30 times and the arithmetic mean of the 30 sets of probabilities was used as result.\",\n",
      "        \"matches_evaluation/availability\": \"Yes. Supplementary Data.\",\n",
      "        \"matches_evaluation/comparison\": \"Random Forest model performed better than SVM and SVM with Lasso, and it was chosen for training the final model (Episcore).\\n Comparison of Episcore with pLI scores from ExAC, Shet values, and ranks of mouse heart expression level, using de novo likely-gene-disrupting (LGD) variants identified in:\\n 1) A previously published whole exome sequencing study DDD (Deciphering Developmental Disorders consortium) of 1365 trio families with congenital heart disease (CHD).\\n 2) A second CHD WES cohort of 2645 parent\\u2212offspring trios from the Pediatric Cardiac Genomics Consortium (PCGC).\\n LGD variants include frameshift, nonsense and canonical splice site\\n mutations. Episcore achieved better performance in prioritizing LGD de novo variants than the other methods.\",\n",
      "        \"matches_evaluation/confidence\": \"Permutation testing.\",\n",
      "        \"matches_evaluation/measure\": \"ROC curve, AUC score, sensitivity, specificity\",\n",
      "        \"matches_evaluation/method\": \"1) 100 randomized runs with Ntrain=90% and Ntest=10% for each run. 10-fold cross validation was applied.\\n 2) For the best performing model (Random Forest) all training data were used to train the final model.\",\n",
      "        \"matches_dataset/availability\": \"Yes. Supplementary Data.\",\n",
      "        \"matches_dataset/provenance\": \"ChIP-seq data, including uniformly processed peak calling results and peak width of promoter histone modifications from Roadmap and ENCODE projects for active (H3K4me3, H3K9ac, and H2A.Z) and repressive (H3K27me3) promoter modifications, and marks associated with enhancers (H3K4me1, H3K27ac, DNase I hypersensitivity sites). \\n\\nCurated haploinsufficient (HIS) genes, positive (Npos) training observations, were collected from haploinsufficient training genes used in previous studies and genes with haploinsufficient score of 3 in ClinGen Dosage Sensitivity Map.\\n\\nCurated haplosufficient (HS) genes, negative (Nneg) training observations, included genes deleted in two or more healthy people, based on CNVs detected in 2026 normal individuals.\\n\\nAll data were used in previous studies.\\n\",\n",
      "        \"matches_dataset/redundancy\": \"Only genes with half or more of its length covered by any deletion were considered \\u201cdeleted\\u201d (HS genes) in an individual.\\n\\nThe initial raw training may have included some false positive and false negative genes, as it contained results from automated literature mining that is known to give noisy output. To optimize the performance, the following pruning of the raw training set was performed: \\n\\n1)\\tOnly protein-coding genes in autosomes were kept, as non-protein coding genes or genes on sex chromosomes may be under different mechanism of epigenomic regulation.\\n2)\\tFrom the positive training set, genes with sufficient contradictory evidence were removed (ExAC pLI \\u2264 0.1 and expected loss-of-function variants >1011).\\n3)\\tFrom the negative training set, genes with sufficient contradictory evidence (pLI \\u2265 0.2 and expected loss-of-function variants>10) were removed.\\n\",\n",
      "        \"matches_dataset/splits\": \"Following pruning for the training set, Npos=287 curated haploinsufficient genes and Nneg=574 curated haplosufficient genes were considered for further analysis.\\n1)\\tNtrain=90%. Ntest=10%. 10-fold cross validation for training. 100 randomized runs.\\n2)\\tFinal training with all training data and estimation of probabilities.\\n\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b80\",\n",
      "        \"publication_pmid\": \"32681213\",\n",
      "        \"publication_updated\": \"03/12/2022 19:15:18\",\n",
      "        \"publication_authors\": \"Pulliam L, Liston M, Sun B, Narvid J\",\n",
      "        \"publication_journal\": \"J Neurovirol\",\n",
      "        \"publication_title\": \"Using neuronal extracellular vesicles and machine learning to predict cognitive deficits in HIV.\",\n",
      "        \"publication_doi\": \"10.1007/s13365-020-00877-6\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"29042d14-1d9f-444e-b046-b5ec3e731b15\",\n",
      "        \"shortid\": \"g23kv6pr5v\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches_publication/updated\": \"03/12/2022 19:15:18\",\n",
      "        \"matches_publication/authors\": \"Pulliam L, Liston M, Sun B, Narvid J\",\n",
      "        \"matches_publication/journal\": \"J Neurovirol\",\n",
      "        \"matches_publication/title\": \"Using neuronal extracellular vesicles and machine learning to predict cognitive deficits in HIV.\",\n",
      "        \"matches_optimization/algorithm\": \"Stochastic gradient boosting and random forests\",\n",
      "        \"matches_optimization/config\": \"Configuration and hyper-parameter configuration available in the main text (Table 2)\",\n",
      "        \"matches_optimization/encoding\": \"Eleven features for describing complete lncRnot reported sequence: mRnot reported length, ORF length, GC%, Fickett score, hexamer score, alignment identity in SwissProt database, length of alignment in SwissProt database, proportion of alignment length and mRnot reported length (alignment length:mRnot reported length), proportion of alignment length and ORF length (alignment length:ORF), presence of transposable element, and sequence percent divergence from transposable element.\",\n",
      "        \"matches_optimization/features\": \"f=11. Feature selection by Recursive feature elimination\",\n",
      "        \"matches_model/availability\": \"Code not available\",\n",
      "        \"matches_model/interpretability\": \"Transparent. Random forests provide feature importance\",\n",
      "        \"matches_evaluation/comparison\": \"GreeNC method (transcript filtering, no machine-learning), CPAT\",\n",
      "        \"matches_evaluation/confidence\": \"No confidence reported\",\n",
      "        \"matches_evaluation/measure\": \"Sensitivity, Specificity, Accuracy, ROC-AUC\",\n",
      "        \"matches_evaluation/method\": \"Cross-validation. No indipendent datasets\",\n",
      "        \"matches_dataset/availability\": \"Yes, supplementary material.\",\n",
      "        \"matches_dataset/provenance\": \"Positive data from lncRnot reporteddb v2, lncRnot reporteddisease. Negative data from Ensembl, Araport v11. Npos=436 lncRnot reported sequences. Nneg=? (total number of negative not known). Not previously used.\",\n",
      "        \"matches_dataset/splits\": \"Ten different indipendent 10-fold cross-validation performed. N_pos and N_neg for training and testing unknown. \"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b8c\",\n",
      "        \"publication_pmid\": \"33354569\",\n",
      "        \"publication_updated\": \"03/03/2022 17:42:56\",\n",
      "        \"publication_authors\": \"Li J, Liu Y, Zhang Z, Liu B, Wang Y\",\n",
      "        \"publication_journal\": \"Biomed Res Int\",\n",
      "        \"publication_title\": \"PmDNE: Prediction of miRNA-Disease Association Based on Network Embedding and Network Similarity Analysis.\",\n",
      "        \"publication_doi\": \"10.1155/2020/6248686\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"4f8760d4-406b-4faf-bfce-2e05bee0335c\",\n",
      "        \"shortid\": \"akj12z17yv\",\n",
      "        \"score\": 0.57,\n",
      "        \"matches_publication/updated\": \"03/03/2022 17:42:56\",\n",
      "        \"matches_publication/authors\": \"Li J, Liu Y, Zhang Z, Liu B, Wang Y\",\n",
      "        \"matches_publication/journal\": \"Biomed Res Int\",\n",
      "        \"matches_publication/title\": \"PmDNE: Prediction of miRNA-Disease Association Based on Network Embedding and Network Similarity Analysis.\",\n",
      "        \"matches_optimization/algorithm\": \"Gradient tree boosting\",\n",
      "        \"matches_optimization/encoding\": \"global features\",\n",
      "        \"matches_optimization/features\": \"63 + 63, Incremental Feature Selection\",\n",
      "        \"matches_model/availability\": \"http://dlab.org.cn/PredRBR/ (not working)\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"Binary predictions\",\n",
      "        \"matches_evaluation/comparison\": \"BindN, PPRint, BindN+, RNABindR2.0, RNABindRPlus, SNBRFinder\",\n",
      "        \"matches_evaluation/measure\": \"sensitivity, specificity, accuracy, precision, F-measure, MCC score\",\n",
      "        \"matches_evaluation/method\": \"Independent dataset\",\n",
      "        \"matches_dataset/availability\": \"http://dlab.org.cn/PredRBR/ (not working now)\",\n",
      "        \"matches_dataset/provenance\": \"Used by previous papers\",\n",
      "        \"matches_dataset/redundancy\": \" eliminating sequences more similar than 40%\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b8d\",\n",
      "        \"publication_pmid\": \"32545899\",\n",
      "        \"publication_updated\": \"05/20/2022 15:07:04\",\n",
      "        \"publication_authors\": \"Ahn HS, Kim JH, Jeong H, Yu J, Yeom J, Song SH, Kim SS, Kim IJ, Kim K\",\n",
      "        \"publication_journal\": \"Int J Mol Sci\",\n",
      "        \"publication_title\": \"Differential Urinary Proteome Analysis for Predicting Prognosis in Type 2 Diabetes Patients with and without Renal Dysfunction.\",\n",
      "        \"publication_doi\": \"10.3390/ijms21124236\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"e735e3a3-1291-4134-b91b-e7eed358f5e6\",\n",
      "        \"shortid\": \"ebmz3cuuuq\",\n",
      "        \"score\": 0.57,\n",
      "        \"matches_publication/updated\": \"05/20/2022 15:07:04\",\n",
      "        \"matches_publication/authors\": \"Ahn HS, Kim JH, Jeong H, Yu J, Yeom J, Song SH, Kim SS, Kim IJ, Kim K\",\n",
      "        \"matches_publication/journal\": \"Int J Mol Sci\",\n",
      "        \"matches_publication/title\": \"Differential Urinary Proteome Analysis for Predicting Prognosis in Type 2 Diabetes Patients with and without Renal Dysfunction.\",\n",
      "        \"matches_optimization/algorithm\": \"Single linear-nonlinear cascade models (LN), linear-nonlinear-sum-nonlinear (LNSN), linear-nonlinear-sum-nonlinear-feedback (LNSNF), linear-nonlinear-feedback-sum-\\nnonlinear-feedback (LNFSNF) and LNFDSNF models. (to predict firing rates of ganglion cells)\",\n",
      "        \"matches_optimization/fitting\": \"Fitting is performed but the fitting algorithm is not explained.\",\n",
      "        \"matches_optimization/parameters\": \"~100-150 parameters\",\n",
      "        \"matches_optimization/regularization\": \"yes. A \\\"fitting algorithm\\\" is mentioned but the technique is not explained.\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"The model gives as output the neuron's spike rate (time course of the firing rate).\",\n",
      "        \"matches_evaluation/comparison\": \"Comparison between models used in the paper.\",\n",
      "        \"matches_evaluation/confidence\": \"Median and variance of cells across models.\",\n",
      "        \"matches_dataset/provenance\": \"The data comes from a direct experiment. They consider firing rates of ~200 ganglion cells.\",\n",
      "        \"matches_dataset/splits\": \"Training set: ~80% of the data. Test set: ~20% of the data.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b92\",\n",
      "        \"publication_pmid\": \"33679869\",\n",
      "        \"publication_updated\": \"03/28/2022 00:44:11\",\n",
      "        \"publication_authors\": \"Sun S, Fei K, Zhang G, Wang J, Yang Y, Guo W, Yang Z, Wang J, Xue Q, Gao Y, He J\",\n",
      "        \"publication_journal\": \"Front Genet\",\n",
      "        \"publication_title\": \"Construction and Comprehensive Analyses of a METTL5-Associated Prognostic Signature With Immune Implication in Lung Adenocarcinomas.\",\n",
      "        \"publication_doi\": \"10.3389/fgene.2020.617174\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"1a0158e9-2f41-4c14-9b7e-4d7369584811\",\n",
      "        \"shortid\": \"3p5oxxtlts\",\n",
      "        \"score\": 1,\n",
      "        \"matches_publication/updated\": \"03/28/2022 00:44:11\",\n",
      "        \"matches_publication/authors\": \"Sun S, Fei K, Zhang G, Wang J, Yang Y, Guo W, Yang Z, Wang J, Xue Q, Gao Y, He J\",\n",
      "        \"matches_publication/journal\": \"Front Genet\",\n",
      "        \"matches_publication/title\": \"Construction and Comprehensive Analyses of a METTL5-Associated Prognostic Signature With Immune Implication in Lung Adenocarcinomas.\",\n",
      "        \"matches_optimization/algorithm\": \"1) various methods for classification and clustering. Both supervised and unsupervised.\\n2) first network-based feature ranking method for selection of top genes, then SVM for classification\",\n",
      "        \"matches_optimization/config\": \"1) No\\n 2) No\",\n",
      "        \"matches_optimization/encoding\": \"1) Not applicable\\n2) Not applicable\",\n",
      "        \"matches_optimization/features\": \"1)50 and 200 input variables.\\n2) 6,168 genes as input features for network-based feature ranking method, and then top T (1,5,10...,50)\",\n",
      "        \"matches_optimization/fitting\": \"1) average over a wide range of K to avoid overfitting for KNN-based methods\\n2) Not applicable\",\n",
      "        \"matches_optimization/meta\": \"1) yes. Some in similar ways. Some other vary from unsupervised to supervised learning.\\n2) No\",\n",
      "        \"matches_optimization/parameters\": \"1) based on the complexity of each pattern\\n2) p=2, with complexity parameter C = 100 and RBF kernel with \\u03c3 = 1\",\n",
      "        \"matches_optimization/regularization\": \"1) No\\n2) No\",\n",
      "        \"matches_model/availability\": \"1)No\\n 2) No\",\n",
      "        \"matches_model/duration\": \"1) a few seconds\\n 2) not applicable\",\n",
      "        \"matches_model/interpretability\": \"1) transparent since results are based on statistics.\\n 2) transparent since results are based on statistics.\",\n",
      "        \"matches_model/output\": \"1) regression\\n 2) classification\",\n",
      "        \"matches_evaluation/availability\": \"1) No\\n 2) No\",\n",
      "        \"matches_evaluation/comparison\": \"1) LASSO. The performance of LASSO is worse than all the other non-linear methods when we have relatively small numbers of samples.\\n 2) Not applicable\",\n",
      "        \"matches_evaluation/confidence\": \"1)All the measurements are based on the statistics estimated from data.\\n 2) p-values\",\n",
      "        \"matches_evaluation/measure\": \"1) AUC (area under ROC curve) values\\n 2) AUC and p-values\",\n",
      "        \"matches_evaluation/method\": \"1) Not applicable\\n 2) 10-fold cross-validation and independent Dataset\",\n",
      "        \"matches_dataset/availability\": \"1) No\\n2) No\",\n",
      "        \"matches_dataset/provenance\": \"1) We simulate random datasets by extending a casecontrol model adopted in https://doi.org/10.1186/1752-0509-2-10, for evaluation of all methods.\\n2)USA dataset for breast cancer metastasis\",\n",
      "        \"matches_dataset/redundancy\": \"1) Simulation of three different types of interaction patterns between two interacting variables xi, xj and the outcome y: \\u201csimple\\u201d, \\u201ccomplex\\u201d, and \\u201cvery complex\\u201d. Among six pairs of interacting variables, simulation of the data by including two pairs of each pattern. Depending on the outcome then they assigned a value drawn from an equally weighted Mixture-of-Gaussian with various Gaussian components for each pattern case.\\n2) not applicable\",\n",
      "        \"matches_dataset/splits\": \"1) Randomly assignment of outcome variable y uniformly distributed in {0, 1}. Generation of input variables: random generation of 50 input variables, randomly select six of them to simulate the individual effects and another six distinct pairs of other variables from all 1, 225 possible variable pairs to simulate significant interactive effects on disease outcome y.\\nCreation of 1,000 datasets for each one of the following sample sizes: 20, 40, 60, 80, 100, 120, and 140.\\n2) USA(train): n=286, 107 metastasis cases\\nNetherlands(test): n=295, 79  metastasis cases\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b9a\",\n",
      "        \"publication_pmid\": \"33349236\",\n",
      "        \"publication_updated\": \"03/19/2022 20:19:10\",\n",
      "        \"publication_authors\": \"Basodi S, Baykal PI, Zelikovsky A, Skums P, Pan Y\",\n",
      "        \"publication_journal\": \"BMC Genomics\",\n",
      "        \"publication_title\": \"Analysis of heterogeneous genomic samples using image normalization and machine learning.\",\n",
      "        \"publication_doi\": \"10.1186/s12864-020-6661-6\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"4f314982-05d0-429f-aa3f-d163dc7c0834\",\n",
      "        \"shortid\": \"l4cnu26i2o\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches_publication/updated\": \"03/19/2022 20:19:10\",\n",
      "        \"matches_publication/authors\": \"Basodi S, Baykal PI, Zelikovsky A, Skums P, Pan Y\",\n",
      "        \"matches_publication/journal\": \"BMC Genomics\",\n",
      "        \"matches_publication/title\": \"Analysis of heterogeneous genomic samples using image normalization and machine learning.\",\n",
      "        \"matches_optimization/algorithm\": \"random forest\",\n",
      "        \"matches_optimization/config\": \"Partially yes: in the text\",\n",
      "        \"matches_optimization/encoding\": \"global features\",\n",
      "        \"matches_optimization/features\": \"All datasets were combined and normalized using the R package limma, and batch effects were adjusted using ComBat. Then the optimal number of features (48 out of presumably 753) was selected using all datasets, potentially leading to contamination. Then subsets of 48 features were used to train models (based on dataset 1), and the best model was chosen (based on datasets 2-5 + genetic algorithm) and evaluated (based on dataset 6).\",\n",
      "        \"matches_model/interpretability\": \"Partially transparent: the features (genes) selected in the final model were scrutinized for other associations.\",\n",
      "        \"matches_model/output\": \"4-class classification\",\n",
      "        \"matches_evaluation/availability\": \"Only final accuracy values for training, test, and combined datasets in the supporting information.\",\n",
      "        \"matches_evaluation/comparison\": \"Baselines: VarSelRF and simple RFE as an alternative to their feature selection; benchmarking: ClaNC by Verhaak et al. (claimed to be the standard in the field).\",\n",
      "        \"matches_evaluation/confidence\": \"Only standard deviations for the accuracy values are provided\",\n",
      "        \"matches_evaluation/method\": \"Cross-validation, independent dataset\",\n",
      "        \"matches_dataset/provenance\": \"6 experimental datasets from the literature (803 = 171+296+46+27+35+228) and 4 classes. The raw data is not reported to evaluate the imbalances\",\n",
      "        \"matches_dataset/redundancy\": \"Not studied\",\n",
      "        \"matches_dataset/splits\": \"575 data points in the training and validation sets; 228 in the test set; the raw data is not reported to evaluate the imbalances\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b9b\",\n",
      "        \"publication_pmid\": \"32286325\",\n",
      "        \"publication_updated\": \"03/29/2022 07:28:13\",\n",
      "        \"publication_authors\": \"Cheng J, Han Z, Mehra R, Shao W, Cheng M, Feng Q, Ni D, Huang K, Cheng L, Zhang J\",\n",
      "        \"publication_journal\": \"Nat Commun\",\n",
      "        \"publication_title\": \"Computational analysis of pathological images enables a better diagnosis of TFE3 Xp11.2 translocation renal cell carcinoma.\",\n",
      "        \"publication_doi\": \"10.1038/s41467-020-15671-5\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"4df4e637-ba5a-4be5-83d3-aed3e3c4742c\",\n",
      "        \"shortid\": \"du3gc2b5fz\",\n",
      "        \"score\": 0.48,\n",
      "        \"matches_publication/updated\": \"03/29/2022 07:28:13\",\n",
      "        \"matches_publication/authors\": \"Cheng J, Han Z, Mehra R, Shao W, Cheng M, Feng Q, Ni D, Huang K, Cheng L, Zhang J\",\n",
      "        \"matches_publication/journal\": \"Nat Commun\",\n",
      "        \"matches_publication/title\": \"Computational analysis of pathological images enables a better diagnosis of TFE3 Xp11.2 translocation renal cell carcinoma.\",\n",
      "        \"matches_optimization/algorithm\": \"Random Forests Classification\",\n",
      "        \"matches_optimization/encoding\": \"EPG waveform recordings were manually classified into 6 feeding states: C, D, E1, E2, G, NP. Fast Fourier transform of EPG recordings. The 6 frequencies with the highest magnitudes, often harmonics, were extracted and used for further analysis.\",\n",
      "        \"matches_optimization/features\": \"Main periodic components of the time series\",\n",
      "        \"matches_model/output\": \"Multi-label predictions on 6 different feeding states. Binary predictions between phloem (E1 and E2) and non-phloem (C, D, NP, and G) feeding states.\",\n",
      "        \"matches_evaluation/confidence\": \"95% confidence intervals. Confusion matrices.\",\n",
      "        \"matches_evaluation/measure\": \"Average of: Accuracy, Sensitivity, Specificity, Positive Predictive value, Negative Predictive value, Prevalence, Detection Rate, Detection Prevalence, Balanced Accuracy.\",\n",
      "        \"matches_evaluation/method\": \"1) 3 repeats of 10-fold cross validation for each EPG recording.\\n 2) Leave-one-out cross-validation. 3 repeats of 10-fold cross validation for 5% of 26 EPG recordings (train). 1 EPG recording for testing.\",\n",
      "        \"matches_dataset/provenance\": \"27 electrical penetration graph (EPG) waveform recordings \\ntotaling 470 hours on nine different citrus varieties. Not previously used.\",\n",
      "        \"matches_dataset/redundancy\": \"1)\\tA classification model was trained and used for predictions on each EPG recording independently. \\n2)\\tRandom selection of 5% of 26 EPG recordings used as training and 1 EPG recording as testing. 27 repeats (Leave-one-out cross-validation). \",\n",
      "        \"matches_dataset/splits\": \"1)\\tData split for each EPG recording. Ntrain = 5%. Ntest = 95%. 3 splits.\\n2)\\tNtrain = 5% from each of 26 EPG recordings. Ntest = 100% from 1 EPG recording (27th). \"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305ba4\",\n",
      "        \"publication_pmid\": \"33425719\",\n",
      "        \"publication_updated\": \"03/02/2022 16:10:05\",\n",
      "        \"publication_authors\": \"Li J, Zhang C, Wei J, Zheng P, Zhang H, Xie Y, Bai J, Zhu Z, Zhou K, Liang X, Xie Y, Qin T\",\n",
      "        \"publication_journal\": \"Front Oncol\",\n",
      "        \"publication_title\": \"Intratumoral and Peritumoral Radiomics of Contrast-Enhanced CT for Prediction of Disease-Free Survival and Chemotherapy Response in Stage II/III Gastric Cancer.\",\n",
      "        \"publication_doi\": \"10.3389/fonc.2020.552270\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"961066cf-8ef7-40b4-9b4f-2659655f5c2f\",\n",
      "        \"shortid\": \"82s7pnn2t8\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches_publication/updated\": \"03/02/2022 16:10:05\",\n",
      "        \"matches_publication/authors\": \"Li J, Zhang C, Wei J, Zheng P, Zhang H, Xie Y, Bai J, Zhu Z, Zhou K, Liang X, Xie Y, Qin T\",\n",
      "        \"matches_publication/journal\": \"Front Oncol\",\n",
      "        \"matches_publication/title\": \"Intratumoral and Peritumoral Radiomics of Contrast-Enhanced CT for Prediction of Disease-Free Survival and Chemotherapy Response in Stage II/III Gastric Cancer.\",\n",
      "        \"matches_optimization/algorithm\": \"Random Forest classifier\",\n",
      "        \"matches_optimization/encoding\": \"For each ortholog group, its corresponding protein sequences were aligned with MUSCLE. The multiple sequence alignments were subsequently input in PhyML for the construction of phylogenetic trees using the Maximum Likelihood method. For amino acid and nucleotide-based tree construction in PhyML, the LG and HKY85 substitution matrices were used, respectively. Additionally, distance matrices were calculated for each tree, where the distance between two leaves corresponds to the sum of the branch lengths separating them. \\n\\nComparing two trees can be subject to artefacts and lead in some cases to spurious correlations if speciation events are not taken in account. For this reason, some of the co-evolution features also involve the Tree of Life (ToL) of the 34 genomes studied, which originated from submitting sequences of their respective 16S ribosomal Rnot reported to similar treatment. Since distances in the ToL are computed from a nucleotide-based substitution matrix, the distances in the ToL matrix were rescaled for proper comparison with the protein-based distance matrices.\\n\",\n",
      "        \"matches_optimization/features\": \"For each protein pair, 7 coevolution features measuring the pairwise tree similarities have been defined. \\nOf these, 4 features are based on pairwise comparison of the distance matrices, as defined in the mirrortree approach, and whose metrics correspond to the linear correlation coefficient between the two matrices in consideration. Let A and B be the two MCP ortholog groups, mA and mB their respective matrices, tA and tB their trees. The parameter mirrorAB is the correlation between mA and mB, mirrorA is between mA and ToL, and mirrorB is between mB and ToL. The fourth descriptor, mirrorAB-ToL, involves an adaptation of the mirror tree, also known as tol-mirror, which measures the correlation between mA and mB after removing the background similarity inherent to speciation events in the ToL.\\nThe remaining 3 topological features are derived from the Icong index, defined as the probability that the Maximum Agreement Subtree (MAST) between two trees is arising by chance. Along the same idea, topological similarities were computed between tree A and ToL, tree B and ToL, and finally A and B (topA, topB, topAB).\\n\",\n",
      "        \"matches_model/interpretability\": \"Not explicitly interpreted. Comparison of classification performance for fewer features and evaluation of their discriminatory power individually by ranking their accuracies in the context of an unsupervised analysis. Results support the importance of all features for optimal model performance.\",\n",
      "        \"matches_model/output\": \"Binary predictions of pos for an interacting protein group pair and neg for those not interacting. For prediction probability is less than 0.7 then the result is neg, and for equal or greater than 0.7 the result is pos (increased specificity).\",\n",
      "        \"matches_evaluation/availability\": \"Yes. Supporting information.\",\n",
      "        \"matches_evaluation/confidence\": \"High training accuracy for experimentally characterized PPIs, 15 of 16 correctly predicted as pos. Claiming support for the high specificity criterion.\",\n",
      "        \"matches_evaluation/measure\": \"ROC curve, AUC score\",\n",
      "        \"matches_evaluation/method\": \"10-fold cross-validation. Experimental confirmation of a predicted positive PPI from the testing dataset.\",\n",
      "        \"matches_dataset/availability\": \"Yes. Supporting information.\",\n",
      "        \"matches_dataset/provenance\": \"Training dataset of 40 pairs of Pdu protein sequences whose presence or absence of physical, protein-protein interactions (PPIs) could be experimentally validated via binding assays, complementation and expression studies or crystallographic data.\\n\\nTesting dataset of protein orthologs collected from 34 bacterial genomes in the KEGG database and collapsed among 22 orthologous protein groups, which represent types of bacterial microcompartment (MCP) proteins known to be associated with the propanediol utilizing (Pdu) system.\\n\",\n",
      "        \"matches_dataset/redundancy\": \"Incomplete or erroneous annotations of the Pdu gene products were corrected after sequence comparison with the Pdu operon from Salmonella enterica LT2, the best-characterized strain in terms of Pdu MCP.\",\n",
      "        \"matches_dataset/splits\": \"For the training set, Npos=16 interacting and Nneg=24 non-interacting protein pairs.\\nFor the testing set, pairwise combinations of the 22 orthologous protein groups resulted in 231 unique protein pairs that needed to be classified.\\n\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305ba5\",\n",
      "        \"publication_pmid\": \"32858131\",\n",
      "        \"publication_updated\": \"03/16/2022 15:35:06\",\n",
      "        \"publication_authors\": \"Grundler F, Mesnage R, Goutzourelas N, Tekos F, Makri S, Brack M, Kouretas D, Wilhelmi de Toledo F\",\n",
      "        \"publication_journal\": \"Food Chem Toxicol\",\n",
      "        \"publication_title\": \"Interplay between oxidative damage, the redox status, and metabolic biomarkers during long-term fasting.\",\n",
      "        \"publication_doi\": \"10.1016/j.fct.2020.111701\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"d692ec44-aeae-4a41-9383-a899977f51f3\",\n",
      "        \"shortid\": \"mhyzrdvtd1\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches_publication/updated\": \"03/16/2022 15:35:06\",\n",
      "        \"matches_publication/authors\": \"Grundler F, Mesnage R, Goutzourelas N, Tekos F, Makri S, Brack M, Kouretas D, Wilhelmi de Toledo F\",\n",
      "        \"matches_publication/journal\": \"Food Chem Toxicol\",\n",
      "        \"matches_publication/title\": \"Interplay between oxidative damage, the redox status, and metabolic biomarkers during long-term fasting.\",\n",
      "        \"matches_optimization/algorithm\": \"Random Forest (RF), Conditional Inference Forest (CF), SVM with Linear kernel, Neural network.\",\n",
      "        \"matches_optimization/encoding\": \"Clinical categorization of de novo and inherited CNVs as pathogenic, uncertain or benign following clinical annotation guidelines. Large and very rare CNVs were also classified as pathogenic. \\nGene annotations based on CNVs. Gene-set construction, based on CNV gene annotations.\",\n",
      "        \"matches_optimization/features\": \"Clinically categorized CNVs. CNV annotated genes. 20 curated gene-sets of neurobiological relevance. Total gene count.\",\n",
      "        \"matches_optimization/fitting\": \"Stratified 3-fold cross-validation was used to avoid overfitting. \\nThe absence of overfitting was further assessed by replacing real classification features with randomized features based on gene identity permutation. \\nFeature selection was based on the feature relevance metrics calculated on the data subset used for training, and performed independently for every training set, to avoid any overfitting issues.\\nAdditionally, all subsets presented a gender composition similar to the full dataset.\\n\",\n",
      "        \"matches_optimization/parameters\": \"For RF and CF default settings were used unless otherwise specified.\\nFor Linear SVM the cost parameter was kept at default as 1 and class weights were kept even. Each feature was independently normalized and rescaled to a 0-1 interval prior to being input into the classifier.\\nThe Neural Network was built with two middle layers of 100 and 50 nodes each, a learning rate of 0.005 with a 0.9 momentum. The network was trained through back-propagation, and without feature normalization or scaling.\\n\",\n",
      "        \"matches_model/interpretability\": \"Feature selection for RF based on Mean Decrease Accuracy (MDA) and Mean Decrease Gini. Feature selection for CF based on MDA was performed with and without step-wise decorrelation, and on MRMR (Minimum Redundancy Maximum Relevance Feature Selection). Reported in Additional information.\\n Black box for SVM with Linear kernel and Neural network.\",\n",
      "        \"matches_model/output\": \"Prediction probabilities. Binary predictions.\",\n",
      "        \"matches_evaluation/comparison\": \"Comparison and evaluation of algorithms\\u2019 performance by splitting data into: \\n 1) all subjects, \\n 2) subjects with de novo CNVs, and \\n 3) subjects with pathogenic CNVs\\n Moreover, evaluating algorithms\\u2019 performance by splitting observations (CNVs) into:\\n 1) Total CNVs, \\n 2) gain CNVs, and \\n 3) loss CNVs\\n Additionally, evaluating algorithms\\u2019 performance by separating features, following feature selection, into:\\n 1) top 20 ranking features\\n 2) top 15% ranking features\\n 1) top 40% ranking features\\n CF reported as an optimal classification approach based on comparisons with different algorithms and the respective AUC scores.\",\n",
      "        \"matches_evaluation/measure\": \"AUC score.\\n Percentage of correctly classified ASD subjects, which was calculated as the number of ASD subjects correctly predicted in at least 15 out of 20 iterations divided by the study total (Npos=1892).\",\n",
      "        \"matches_evaluation/method\": \"Stratified 3-fold cross-validation.\",\n",
      "        \"matches_dataset/availability\": \"Yes. Stage-1 CNV calls are available in dbGAP as phs000267.v3.p2. Stage-2 CNV calls are available in dbGAP as phs000267.v4.p2. Supplementary files for rare variants of ASD subjects and controls.\",\n",
      "        \"matches_dataset/provenance\": \"Rare Copy Number Variation (CNV) data and comprehensive gene annotations from Npos=1892 Autism Spectrum Disorder ASD subjects (1623 males and 270 females), and Nneg=2342 platform-matched controls (1093 males and 1250 females) with at least one rare CNV (frequency 1% or less). All subjects (Npos) are of European\\nancestry and Caucasian ethnicity.\\nData were collected from previous studies: Autism Genome Project (AGP), SAGE (Study of Addiction Genetics and Environment), Ontario Colorectal Cancer study, HABC (Health Aging and Body Composition).\\n\",\n",
      "        \"matches_dataset/redundancy\": \"Subjects with karyotypic abnormalities, Fragile X syndrome or other\\ngenetic syndromes causing congenital malformations were excluded from the analysis. Only samples meeting quality thresholds were used for CNV analysis. CNVs (of size 30 kb or greater) were detected using an analytical pipeline optimized for Illumina 1M arrays. All de novo CNVs were experimentally validated. Samples with copy number variation greater than 7.5 MB were excluded.\\n\",\n",
      "        \"matches_dataset/splits\": \"Only subjects harboring at least one rare genic CNV were used for classification, as features would be constantly zero for the other subjects, but all subjects were considered when reporting percentage \\u201cexplained\\u201d statistics. This resulted in a subset of Npos=1570 ASD subjects (80.8%) and Nneg=1916 controls (81.8%).\\nRandom division into 3 equal and stratified subsets. Ntrain = 2 subsets. Ntest=1 subset. This process was repeated 3 times without re-dividing the dataset.\\n\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bb3\",\n",
      "        \"publication_pmid\": \"33126851\",\n",
      "        \"publication_updated\": \"03/18/2022 11:23:23\",\n",
      "        \"publication_authors\": \"Chen X, Xiong Y, Liu Y, Chen Y, Bi S, Zhu X\",\n",
      "        \"publication_journal\": \"BMC Bioinformatics\",\n",
      "        \"publication_title\": \"m5CPred-SVM: a novel method for predicting m5C sites of RNA.\",\n",
      "        \"publication_doi\": \"10.1186/s12859-020-03828-4\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"10fa32b7-b2d7-4aeb-9de4-351d2c086bf9\",\n",
      "        \"shortid\": \"y6wfiqd2mt\",\n",
      "        \"score\": 0.86,\n",
      "        \"matches_publication/updated\": \"03/18/2022 11:23:23\",\n",
      "        \"matches_publication/authors\": \"Chen X, Xiong Y, Liu Y, Chen Y, Bi S, Zhu X\",\n",
      "        \"matches_publication/journal\": \"BMC Bioinformatics\",\n",
      "        \"matches_publication/title\": \"m5CPred-SVM: a novel method for predicting m5C sites of RNA.\",\n",
      "        \"matches_optimization/algorithm\": \"Support Vector Machine (SVM)\",\n",
      "        \"matches_optimization/encoding\": \"Different data processing methods for transforming input protein sequences:\\n1)\\tTripeptide (k=3) frequency in protein sequence: Considering all possible subsequences of length k in the query protein sequence and dividing the number of occurrences of each k-mer by the total number of possible k-mers.\\n2)\\tSecondary structure: For each protein in each dataset SSPro was used to obtain a secondary structure role for each amino acid in the protein in question.\\n3)\\tFrequency Priors: Scanning database of known Dnot reported repair proteins for the frequencies of each type of amino acid, and using this information to determine if a query protein not belonging to the known database has a similar percentage of each type of amino acid (vf+) or not (vf-).\\n4)\\tBLAST homology: Homology positive or negative assessment and return of value, vb+ or vb-, if BLAST e-value is lower or higher than a 0.001 threshold, respectively.\\n\",\n",
      "        \"matches_optimization/features\": \"1)\\tPrimary Sequence\\n2)\\tPrimary Sequence and Secondary Structure\\n3)\\tPrimary Sequence and Frequency Priors\\n4)\\tPrimary Sequence and Homology\\n5)\\tPrimary Structure, Secondary Structure, Homology\\n6)\\tBLAST Homology\\n\",\n",
      "        \"matches_optimization/meta\": \"Yes. Utilization of BLAST in protein sequences data encoding for homology features.\",\n",
      "        \"matches_optimization/regularization\": \"Yes, manually setting the gamma value of the radial basis function (RBF) similarity-metric.\",\n",
      "        \"matches_model/availability\": \"Yes. Web server: https://sunflower.kuicr.kyoto-u.ac.jp/~jbbrown/dnaRepairPrediction/v2/index.py\",\n",
      "        \"matches_model/duration\": \"Yes. Available report in Additional information.\",\n",
      "        \"matches_model/interpretability\": \"Comparing model performance following training on datasets with different features.\",\n",
      "        \"matches_model/output\": \"Binary predictions. SVM scores or BLAST e-value as outputs, and comparisons with thresholds to determine the prediction (DNA repair protein or Not)\",\n",
      "        \"matches_evaluation/availability\": \"Yes. Additional information.\",\n",
      "        \"matches_evaluation/comparison\": \"The transformation based SVM experimental results were compared with independent BLAST trials. A continuum of thresholds was used in order to obtain ROC curves and compare different techniques.\",\n",
      "        \"matches_evaluation/confidence\": \"Pairwise comparisons of classifiers using both the parametric t-test and non-parametric Wilcoxon Signed-Rank Test.\",\n",
      "        \"matches_evaluation/measure\": \"ROC curves, AUC scores\",\n",
      "        \"matches_evaluation/method\": \"1) 5-fold cross-validation\\n 2) One-versus-one-versus-rest cross-validation. This technique differs in that for k-fold validation, one portion is still set aside for evaluation, but instead of k - 1 portions of data for training, only a single portion is used for training, and the k - 2 remaining portions are used as a reference homology database for querying training and test data. The end goal this technique is to combine homology and sequence data in an unbiased way and obtain a realistic estimate of method performance.\",\n",
      "        \"matches_dataset/availability\": \"Yes. Additional information.\",\n",
      "        \"matches_dataset/provenance\": \"1)\\tFirst dataset of protein sequences for identification experiments of Dnot reported repair proteins. Gene Ontology (GO) annotated proteins from PDB. Npos=557 and Nneg=1443 total protein sequences. Npos=114 and Nneg=353 protein sequences with 90% sequence similarity. Npos=76 and Nneg=215 protein sequences with 50% sequence similarity.\\n2)\\tSecond dataset of protein sequences for identification experiments of Dnot reported repair proteins. Gene Ontology (GO) annotated proteins from Uniprot:\\n-\\tProtein sequences of \\u201cBase Excision Repair\\u201d, Npos=2624 and Nneg=4723 for total protein sequences, Npos=1721 and Nneg=2924 protein sequences with 90% sequence similarity, and Npos=630 and Nneg=1200 protein sequences with 50% sequence similarity.\\n-\\tProtein sequences of \\u201cDnot reported Dealyklation\\u201d, Npos=25 and Nneg=7322 for total protein sequences.\\n-\\tProtein sequences of \\u201cDnot reported synthesis during Dnot reported repair\\u201d, Npos=28 and Nneg=7319 for total protein sequences.\\n-\\tProtein sequences of \\u201cDouble Strand Break repair\\u201d, Npos=364 and Nneg=6983 for total protein sequences, Npos=266 and Nneg=4379 protein sequences with 90% sequence similarity and Npos=174 and Nneg=1656 protein sequences with 50% sequence similarity.\\n-\\tProtein sequences of \\u201cError-prone Dnot reported repair\\u201d, Npos=46 and Nneg=7301 for total protein sequences, Npos=36 and Nneg=4609 protein sequences with 90% sequence similarity.\\n-\\tProtein sequences of \\u201cMismatch repair\\u201d, Npos=1777 and Nneg=5570 for total protein sequences, Npos=1020 and Nneg=3625 protein sequences with 90% sequence similarity and Npos=468 and Nneg=1362 protein sequences with 50% sequence similarity.\\n-\\tProtein sequences of \\u201cNucleotide Excision Repair\\u201d, Npos=2106 and Nneg=5241 for total protein sequences, Npos=1325 and Nneg=3320 protein sequences with 90% sequence similarity and Npos=363 and Nneg=1467 protein sequences with 50% sequence similarity.\\n-\\tProtein sequences of \\u201cPostreplication repair\\u201d, Npos=28 and Nneg=7319 for total protein sequences.\\n-\\tProtein sequences of GO \\u201cRegulation of Dnot reported repair\\u201d, Npos=264 and Nneg=7083 for total protein sequences, Npos=174 and Nneg=4471 protein sequences with 90% sequence similarity, and Npos=114 and Nneg=1716 protein sequences with 50% sequence similarity.\\n-\\tProtein sequences of GO \\u201cSingle Strand Break repair\\u201d, Npos=40 and Nneg=4605 for total protein sequences, and Npos=25 and Nneg=1805 protein sequences with 90% sequence similarity.\\n3)\\t31 vertebrate genomes from ENSEMBL for identification of novel, Dnot reported repair-related proteins.\\n\",\n",
      "        \"matches_dataset/redundancy\": \"Overlaps between protein sequence datasets of 0%(unfiltered), 50% and 90% sequence similarity. Only Dnot reported repair pathways which were consisted of at least 25 proteins, were considered. Removed redundancy of protein sequences which belong to more than one pathway. Removed proteins which contain the following keywords in their GO descriptions: putative, similar, possible/possibly, probable/probably, theoretical, and hypothetical.\",\n",
      "        \"matches_dataset/splits\": \"5-fold and one-versus-one-versus-rest cross-validation. not reported further.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6603fdf31502715bfe53d6df\",\n",
      "        \"uuid\": \"7cb19427-d4cb-4038-8225-3fabb2f4f585\",\n",
      "        \"created\": \"2024-03-27T11:07:31.027Z\",\n",
      "        \"updated\": \"2024-03-27T11:07:31.027Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"33225896\",\n",
      "        \"publication_authors\": \"Xin Liu, Liang Wang, Jian Li, Junfeng Hu and Xiao Zhang\",\n",
      "        \"publication_journal\": \"BMC Genomics\",\n",
      "        \"publication_title\": \"Mal-Prec: computational prediction of protein Malonylation sites via machine learning based feature integration\",\n",
      "        \"publication_doi\": \"10.1186/s12864-020-07166-w\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"shortid\": \"2b9h7u472x\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches_evaluation/comparison\": \"comparison with other methods performed on the benchmark dataset introduced in this study. No baseline method included in the benchmark\",\n",
      "        \"matches_evaluation/measure\": \"standard mesures for classification: accuracy, sensitivity, specificity, F1 and MCC\",\n",
      "        \"matches_evaluation/method\": \"cross-validation and independent dataset\",\n",
      "        \"matches_optimization/algorithm\": \"Dimensionality reduction (PCA) followed by classifier (SVM). The algorithm is not new. \",\n",
      "        \"matches_optimization/encoding\": \"Peptides are represented using: spaced dipeptide composition, physicochemical featurs, one-hot encoding\",\n",
      "        \"matches_optimization/features\": \"f=614 before PCA, f=100 after PCA. \",\n",
      "        \"matches_optimization/fitting\": \"Npos+Nneg>p. No specific strategies to rule out underfitting\",\n",
      "        \"matches_optimization/parameters\": \"p=100 (SVM)\",\n",
      "        \"matches_optimization/regularization\": \"No overfitting prevention strategies seem to have been applied\",\n",
      "        \"matches_model/availability\": \"yes, source code is available at GitHub. No License is present.\",\n",
      "        \"matches_model/duration\": \"not reported\",\n",
      "        \"matches_model/interpretability\": \"model is black box\",\n",
      "        \"matches_dataset/availability\": \"Yes, data available at GitHub\",\n",
      "        \"matches_dataset/provenance\": \"Data taken from literature. Data are in classes. Npos=1735, Nneg=1735. Dataset not previuosly used for ML applications.\",\n",
      "        \"matches_dataset/redundancy\": \"Overall redundancy is set to 40% protein pairwise sequence identity at most. \",\n",
      "        \"matches_dataset/splits\": \"Training set: 2775 data points. Testing set: 695 data points. No separate validation set used. Distributions of data are consistent between training and testing.\",\n",
      "        \"matches_publication/authors\": \"Xin Liu, Liang Wang, Jian Li, Junfeng Hu and Xiao Zhang\",\n",
      "        \"matches_publication/journal\": \"BMC Genomics\",\n",
      "        \"matches_publication/title\": \"Mal-Prec: computational prediction of protein Malonylation sites via machine learning based feature integration\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6638eae3b30933003cc215e9\",\n",
      "        \"shortid\": \"dq30wdbow2\",\n",
      "        \"uuid\": \"321f38fb-6765-48e6-8db4-12e72da58b47\",\n",
      "        \"created\": \"2024-05-06T14:36:19.663Z\",\n",
      "        \"updated\": \"2024-05-06T14:36:19.663Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"33431047\",\n",
      "        \"publication_authors\": \"Bowen Tang, Skyler T Kramer, Meijuan Fang, Yingkun Qiu, Zhen Wu, Dong Xu\",\n",
      "        \"publication_journal\": \"Journal of Cheminformatics\",\n",
      "        \"publication_title\": \"A self-attention based message passing neural network for predicting molecular lipophilicity and aqueous solubility\",\n",
      "        \"publication_doi\": \"10.1186/s13321-020-0414-z\",\n",
      "        \"publication_year\": \"2020\",\n",
      "        \"score\": 0.95,\n",
      "        \"matches_evaluation/availability\": \"All data sets and code are available at GitHub: https://github.com/tbwxmu/ SAMPN.\",\n",
      "        \"matches_evaluation/comparison\": \"In each task, authors built RF, MPN, SAMPN, multiMPN and multi-SAMPN models to explore the relationship between the target property and the molecular structure. \",\n",
      "        \"matches_evaluation/confidence\": \"Standard deviations are reported for each of the used metrics.\",\n",
      "        \"matches_evaluation/measure\": \"Multiple metrics were used to evaluate the performance of the model: mean absolute error (MAE), root mean squared error (RMSE), mean squared error (MSE),\\ncoefcient of determination (R2) and Pearson correlation coefcient (PC).\",\n",
      "        \"matches_evaluation/method\": \"The model was evaluated through a 10-fold cross-validation that uses 10% of the data as the test set.\",\n",
      "        \"matches_optimization/algorithm\": \"In principle it is an explainable graph neural network. It is not a novel model and was mainly adopted from Deepchem MPN (message passing network).\",\n",
      "        \"matches_optimization/config\": \"All data sets and code are available at GitHub: https://github.com/tbwxmu/ SAMPN.\",\n",
      "        \"matches_optimization/encoding\": \"The SMILES representations of molecules are converted into directed graphs before training the model. The graphs consisted of nodes and edges, where the number of nodes equals the number of atoms, and edges are always double the number of bonds (bidirectional).\",\n",
      "        \"matches_optimization/features\": \"Following features for nodes and edges were reported by the authors:\\n\\nAttribute | Description | Dimension \\n**Node** \\nAtom type  | All currently known chemical elements | 118       \\nDegree | Number of heavy atom neighbors  | 6         \\nFormal charge  | Charge assigned to an atom (-2, -1, 0, 1, 2) | 5         \\nChirality label | R, S, unspecified, and unrecognized type of chirality | 4         \\nHybridization | sp, sp2, sp3, sp3d, or sp3d2 | 5         \\nAromaticity | Aromatic atom or not | 1         \\n\\n**Edge** \\nBond type | Single, double, triple, or aromatic | 4         \\nRing | Whether the bond is in a ring | 1         \\nBond stereo | Nature of the bond\\u2019s stereochemistry (none, any, Z, E, cis, or trans) | 6         \",\n",
      "        \"matches_optimization/fitting\": \"The used dataset is fairly small, considering that ANN is used as the model algorithm and it easily overfit on small datasets. Authors adopted a 10-fold cross validation strategy to improve generalization.\",\n",
      "        \"matches_optimization/meta\": \"It is not a meta-predictor.\",\n",
      "        \"matches_optimization/parameters\": \"Hyperparameters were tuned via grid search using the Hyperopt package (v0.1.2).\\nRMSE on the validation set guided the search for optimal hyperparameter combinations.\\n\\nFollowing parameters and their associated range were reported by the authors.\\nActivation function = Tanh, ELU, LeakyReLU, ReLU, PReLU, SELU\\nSteps of message passing = 2\\u20136 \\nGraph embedding size = 32\\u2013512 \\nDropout rate = 0.0\\u20130.4 \\nLayers of fully connected network = 1\\u20133\",\n",
      "        \"matches_optimization/regularization\": \"Authors adopted a 10-fold cross validation strategy to improve generalization.\",\n",
      "        \"matches_model/availability\": \"All data sets and code are available at GitHub: https://github.com/tbwxmu/ SAMPN.\",\n",
      "        \"matches_model/interpretability\": \"The attention mechanism of the model indicates the degree to which each atom of the molecule contributes to the property of interest, and these results are visualized. Hence, it is interpretable.\",\n",
      "        \"matches_model/output\": \"It is a regressor model.\",\n",
      "        \"matches_dataset/availability\": \"All data sets and code are available at GitHub: https://github.com/tbwxmu/SAMPN.\",\n",
      "        \"matches_dataset/provenance\": \"The lipophilicity data was obtained from CHEMBL3301361 by AstraZeneca, comprising 4200 molecules.\\nAqueous solubility data, sourced from the online chemical database and modeling environment (OCHEM), includes 1311 experimental records.\",\n",
      "        \"matches_dataset/redundancy\": \"The splits were performed randomly.\\nFor the initial data preprocessing, duplicate molecules were removed so that each chemical structure in the data was unique.\",\n",
      "        \"matches_dataset/splits\": \"The training set comprises 80% of the data, while the test set contains 10%.\\nAdditionally, a separate validation set, constituting 10% of the data, was employed for parameter selection.\\nDataset distributions are provided in supplementary material.\",\n",
      "        \"matches_publication/authors\": \"Bowen Tang, Skyler T Kramer, Meijuan Fang, Yingkun Qiu, Zhen Wu, Dong Xu\",\n",
      "        \"matches_publication/journal\": \"Journal of Cheminformatics\",\n",
      "        \"matches_publication/title\": \"A self-attention based message passing neural network for predicting molecular lipophilicity and aqueous solubility\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b2a\",\n",
      "        \"publication_pmid\": \"34297718\",\n",
      "        \"publication_updated\": \"01/18/2022 16:56:16\",\n",
      "        \"publication_authors\": \"Rozova VS, Anwer AG, Guller AE, Es HA, Khabir Z, Sokolova AI, Gavrilov MU, Goldys EM, Warkiani ME, Thiery JP, Zvyagin AV\",\n",
      "        \"publication_journal\": \"PLoS Comput Biol\",\n",
      "        \"publication_title\": \"Machine learning reveals mesenchymal breast carcinoma cell adaptation in response to matrix stiffness.\",\n",
      "        \"publication_doi\": \"10.1371/journal.pcbi.1009193\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"b11547a3-b7fc-4667-b0c8-24f256717893\",\n",
      "        \"shortid\": \"1nvj60arng\",\n",
      "        \"score\": 0.43,\n",
      "        \"matches_publication/updated\": \"01/18/2022 16:56:16\",\n",
      "        \"matches_publication/authors\": \"Rozova VS, Anwer AG, Guller AE, Es HA, Khabir Z, Sokolova AI, Gavrilov MU, Goldys EM, Warkiani ME, Thiery JP, Zvyagin AV\",\n",
      "        \"matches_publication/journal\": \"PLoS Comput Biol\",\n",
      "        \"matches_publication/title\": \"Machine learning reveals mesenchymal breast carcinoma cell adaptation in response to matrix stiffness.\",\n",
      "        \"matches_optimization/algorithm\": \"Novel approach (Regression Plane)\",\n",
      "        \"matches_optimization/config\": \"heuristic hyperparameter initialization methods\",\n",
      "        \"matches_optimization/encoding\": \"position and features of each cell to be analyzed\",\n",
      "        \"matches_evaluation/method\": \"cross validation and novel experiments\",\n",
      "        \"matches_dataset/availability\": \"Yes, https://data.broadinstitute.org/bbbc/image_sets.html https://doi.org/10.6084/m9.figshare.c.5067638.v1 http://www.mitocheck.org/mitotic_cell_atlas/downloads/v1.0.1/mitotic_cell_atlas_v1.0.1_fulldata.zip https://doi.org/10.6084/m9.figshare.c.5075093.v1\",\n",
      "        \"matches_dataset/provenance\": \"Synthetic dataset + 3 original datasets\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b2b\",\n",
      "        \"publication_pmid\": \"34168145\",\n",
      "        \"publication_updated\": \"02/08/2022 00:18:31\",\n",
      "        \"publication_authors\": \"Bertoni M, Duran-Frigola M, Badia-I-Mompel P, Pauls E, Orozco-Ruiz M, Guitart-Pla O, Alcalde V, Diaz VM, Berenguer-Llergo A, Brun-Heath I, Villegas N, de Herreros AG, Aloy P\",\n",
      "        \"publication_journal\": \"Nat Commun\",\n",
      "        \"publication_title\": \"Bioactivity descriptors for uncharacterized chemical compounds.\",\n",
      "        \"publication_doi\": \"10.1038/s41467-021-24150-4\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"91f62631-e353-48e7-b960-4aef0562c730\",\n",
      "        \"shortid\": \"r23jj6bm7u\",\n",
      "        \"score\": 0.43,\n",
      "        \"matches_publication/updated\": \"02/08/2022 00:18:31\",\n",
      "        \"matches_publication/authors\": \"Bertoni M, Duran-Frigola M, Badia-I-Mompel P, Pauls E, Orozco-Ruiz M, Guitart-Pla O, Alcalde V, Diaz VM, Berenguer-Llergo A, Brun-Heath I, Villegas N, de Herreros AG, Aloy P\",\n",
      "        \"matches_publication/journal\": \"Nat Commun\",\n",
      "        \"matches_publication/title\": \"Bioactivity descriptors for uncharacterized chemical compounds.\",\n",
      "        \"matches_optimization/algorithm\": \"Random Forest\",\n",
      "        \"matches_optimization/encoding\": \"Amplicon Sequence Variants (ASV) used as features in a relative abundance matrix\",\n",
      "        \"matches_optimization/features\": \"Depending on the dataset, from 50 to 5000\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_dataset/availability\": \"Yes. Original dataset: https://www.ncbi.nlm.nih.gov/bioproject/?term=PRJnot reported417767\",\n",
      "        \"matches_dataset/provenance\": \"4 datasets, 3 form previous papers and 1 original. \"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b31\",\n",
      "        \"publication_pmid\": \"34388102\",\n",
      "        \"publication_updated\": \"02/17/2022 09:36:07\",\n",
      "        \"publication_authors\": \"An J, Cai Q, Qu Z, Gao Z\",\n",
      "        \"publication_journal\": \"IEEE J Biomed Health Inform\",\n",
      "        \"publication_title\": \"COVID-19 Screening in Chest X-Ray Images Using Lung Region Priors.\",\n",
      "        \"publication_doi\": \"10.1109/JBHI.2021.3104629\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"628354fa-6ad5-4a13-9ba2-0c5e5b0fd8dc\",\n",
      "        \"shortid\": \"k4k0b6uu1l\",\n",
      "        \"score\": 0.81,\n",
      "        \"matches_publication/updated\": \"02/17/2022 09:36:07\",\n",
      "        \"matches_publication/authors\": \"An J, Cai Q, Qu Z, Gao Z\",\n",
      "        \"matches_publication/journal\": \"IEEE J Biomed Health Inform\",\n",
      "        \"matches_publication/title\": \"COVID-19 Screening in Chest X-Ray Images Using Lung Region Priors.\",\n",
      "        \"matches_optimization/algorithm\": \"Logistic Regression\",\n",
      "        \"matches_optimization/config\": \"Yes, the 6 parameters resulted from training are reported on the paper\",\n",
      "        \"matches_optimization/encoding\": \"Feature selection (operated on the training set finding the top 5 significant features)\\nImputation of missing data points through MICE\\nBalancing on the dataset (regarding pos and neg cases) through SMOTE\",\n",
      "        \"matches_optimization/features\": \"5 selected out of 18. The 5 more relevant feature were selected using chi-square test to identify the feature which significantly differ between the \\\"pos\\\" cases and the \\\"neg\\\" cases.\\n\\nIt is not clear whether the feature selection was performed just on training data. \",\n",
      "        \"matches_optimization/parameters\": \"6 (inferred from the context)\",\n",
      "        \"matches_model/availability\": \"Yes, the code is available at: https://github.com/tawsifur/Mortality-severity-prediction-using-blood-biomarkers\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"Regression (survival probability)\",\n",
      "        \"matches_evaluation/availability\": \"Yes, it is available at: https://github.com/tawsifur/Mortality-severity-prediction-using-blood-biomarkers\",\n",
      "        \"matches_evaluation/comparison\": \"Compared with Random Forest, Support Vector machine, K-nearest neighbor, XGBoost, and Extra-tree\",\n",
      "        \"matches_evaluation/confidence\": \"The performance metrics have confidence intervals. No statistical significance is claimed.\",\n",
      "        \"matches_evaluation/measure\": \"Accuracy, Precision, Sensitivity, F1-Score, Specificity, AUC\",\n",
      "        \"matches_evaluation/method\": \"Predictor evaluated on independent datasets\",\n",
      "        \"matches_dataset/availability\": \"Dataset 1: publicy available with the publication at doi: https://doi.org/10.1016/j.imu.2019.100275. Dataset splits not reported.\\n\\nDataset 2: publicy available with the publication at doi: https://doi.org/10.1101/2020.11.02.365536\",\n",
      "        \"matches_dataset/provenance\": \"Dataset 1: 387 patients labeled as \\\"survived\\\" (pos) (N_pos = 335) and \\\"dead\\\" (neg) (N_neg = 49).\\n\\nDataset 2: 375 patients labeled as \\\"survived\\\" (pos) (N_pos = 201) and \\\"dead\\\" (neg) (N_neg = 174).\\n\\nBoth datasets used in previous publications.\",\n",
      "        \"matches_dataset/redundancy\": \"No redundancy between the subsets.\",\n",
      "        \"matches_dataset/splits\": \"Dataset 1 was splitted in two subsets. 80% of the data used for training and validation; 20% of the data used for testing.\\n\\nDataset 2 was entirely used for testing\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b34\",\n",
      "        \"publication_pmid\": \"34372798\",\n",
      "        \"publication_updated\": \"02/21/2022 11:17:51\",\n",
      "        \"publication_authors\": \"Li MX, Sun XM, Cheng WG, Ruan HJ, Liu K, Chen P, Xu HJ, Gao SG, Feng XS, Qi YJ\",\n",
      "        \"publication_journal\": \"BMC Cancer\",\n",
      "        \"publication_title\": \"Using a machine learning approach to identify key prognostic molecules for esophageal squamous cell carcinoma.\",\n",
      "        \"publication_doi\": \"10.1186/s12885-021-08647-1\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"0ade3d57-3ebf-4c42-af9c-48b4b4fd2e54\",\n",
      "        \"shortid\": \"agwmu9cbwt\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"02/21/2022 11:17:51\",\n",
      "        \"matches_publication/authors\": \"Li MX, Sun XM, Cheng WG, Ruan HJ, Liu K, Chen P, Xu HJ, Gao SG, Feng XS, Qi YJ\",\n",
      "        \"matches_publication/journal\": \"BMC Cancer\",\n",
      "        \"matches_publication/title\": \"Using a machine learning approach to identify key prognostic molecules for esophageal squamous cell carcinoma.\",\n",
      "        \"matches_optimization/algorithm\": \"Random Forest\",\n",
      "        \"matches_optimization/config\": \"No, but full code is available.\",\n",
      "        \"matches_optimization/encoding\": \"No tranformation.\",\n",
      "        \"matches_optimization/features\": \"5 lncRnot reported sequences selected from 731. A ML algorithm based on random forest was used for feature selection. Feature selection was operated on training data only.\",\n",
      "        \"matches_optimization/meta\": \"Yes. Feature selection operated using ML. The set used for feature selection is the same used for the training of the classifier, but the validation for the classifier is operated on independent dataset (Dataset 2 and 3).\",\n",
      "        \"matches_model/availability\": \"Yes, code available at: https://github.com/guoqingbao/PanCancerLncRNA\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/availability\": \"Yes, the evaluation procedure and code is available at: https://github.com/guoqingbao/PanCancerLncRNA\",\n",
      "        \"matches_evaluation/comparison\": \"The model is not compared with others.\",\n",
      "        \"matches_evaluation/measure\": \"Area Under Curve (AUC)\",\n",
      "        \"matches_evaluation/method\": \"Test set derived from Dataset 1; Independent Datasets 2 and 3.\",\n",
      "        \"matches_dataset/availability\": \"Dataset 1: URL: https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga\\n\\nDataset 2: URL: https://ocg.cancer.gov/programs/target\\n\\nDataset 3: URL: https://proteomics.cancer.gov/programs/cptac\",\n",
      "        \"matches_dataset/provenance\": \"Dataset 1: Rnot reported-seq data from The Cancer Genome Atlas for different patients affected by different types of cancer. To the end of ML classification, patients where classified as \\\"High risk\\\" or \\\"Low risk\\\" based on the Overall Survival time. N = 2210; distribution of High risk and Low risk patients not reported Used in other papers.\\n\\nDataset 2: Rnot reported-seq data from Therapeutically Applicable Research to Generate Effective Treatments (TARGET) dataset (N = 1122). Used in other papers.\\n\\nDataset 3: Rnot reported-seq data from Clinical Proteomic Tumor Analysis Consortium (CPTAC) dataset (N=391). Used in other papers.\",\n",
      "        \"matches_dataset/redundancy\": \"Dataset splits for Dataset 1 do not overlap. \\n\\nDataset 1, 2 and 3 are independent from each other.\",\n",
      "        \"matches_dataset/splits\": \"Dataset 1 divided in training set (N = 1878) and test set (N = 332). Distribution of High and Low risk patients not reported\\n\\nDatasets 2 and 3 used as independent test set. Distribution of High and Low risk patients not reported\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b35\",\n",
      "        \"publication_pmid\": \"33169030\",\n",
      "        \"publication_updated\": \"03/16/2022 16:40:33\",\n",
      "        \"publication_authors\": \"Sani OG, Abbaspourazad H, Wong YT, Pesaran B, Shanechi MM\",\n",
      "        \"publication_journal\": \"Nat Neurosci\",\n",
      "        \"publication_title\": \"Modeling behaviorally relevant neural dynamics enabled by preferential subspace identification.\",\n",
      "        \"publication_doi\": \"10.1038/s41593-020-00733-0\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"b3b4561c-e904-4def-89cd-783ff01a3b12\",\n",
      "        \"shortid\": \"dmb4u51v5o\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"03/16/2022 16:40:33\",\n",
      "        \"matches_publication/authors\": \"Sani OG, Abbaspourazad H, Wong YT, Pesaran B, Shanechi MM\",\n",
      "        \"matches_publication/journal\": \"Nat Neurosci\",\n",
      "        \"matches_publication/title\": \"Modeling behaviorally relevant neural dynamics enabled by preferential subspace identification.\",\n",
      "        \"matches_optimization/encoding\": \"Aminoacid sequences enriched with physicochemical proprieties from AAindex (for each amino-acid)\",\n",
      "        \"matches_optimization/features\": \"3318. No feature selection strategy.\",\n",
      "        \"matches_optimization/fitting\": \"The number of features is huge, but no strategy for overfitting prevention was adopted.\",\n",
      "        \"matches_model/availability\": \"The classiffier is available at: https://pitgroup.org/bap/; the source code is not available.\",\n",
      "        \"matches_model/interpretability\": \"Transparent. The support vector machine linearly separates samples based on the physicochemical features of the aminoacids.\",\n",
      "        \"matches_model/output\": \"Classification (amyloidogenic or nonamyloidogenic)\",\n",
      "        \"matches_evaluation/comparison\": \"Compared with another algorithm, but the comparison is only based on the accuracy.\",\n",
      "        \"matches_evaluation/confidence\": \"No confidence intervals or statistical significance stated.\",\n",
      "        \"matches_evaluation/measure\": \"Accuracy, ROC curve, Area Under Curve (AUC)\",\n",
      "        \"matches_evaluation/method\": \"Prediction on the test set.\",\n",
      "        \"matches_dataset/availability\": \"Yes. URL for waltz database: http://waltzdb.switchlab.org/\",\n",
      "        \"matches_dataset/provenance\": \"Waltz database of hexapeptides, classified in amyloidogenic (pos) and nonamyloidogenic (neg). N_pos = 541; N_neg = 901. Dataset used in other papers. Dataset enriched with physicochemical proprieties of amino-acids derived from AAindex. \",\n",
      "        \"matches_dataset/redundancy\": \"The two dataset have no overlaps.\",\n",
      "        \"matches_dataset/splits\": \"Dataset splitted in test set (N_pos = 158; N_neg = 309) and training set (N_pos = 383; N_neg = 592)\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b36\",\n",
      "        \"publication_pmid\": \"33464298\",\n",
      "        \"publication_updated\": \"03/21/2022 08:46:51\",\n",
      "        \"publication_authors\": \"Kanfer G, Sarraf SA, Maman Y, Baldwin H, Dominguez-Martin E, Johnson KR, Ward ME, Kampmann M, Lippincott-Schwartz J, Youle RJ\",\n",
      "        \"publication_journal\": \"J Cell Biol\",\n",
      "        \"publication_title\": \"Image-based pooled whole-genome CRISPRi screening for subcellular phenotypes.\",\n",
      "        \"publication_doi\": \"10.1083/jcb.202006180\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"621ff42a-1daa-4b6d-b190-e35478b9af68\",\n",
      "        \"shortid\": \"kr8wmng69g\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches_publication/updated\": \"03/21/2022 08:46:51\",\n",
      "        \"matches_publication/authors\": \"Kanfer G, Sarraf SA, Maman Y, Baldwin H, Dominguez-Martin E, Johnson KR, Ward ME, Kampmann M, Lippincott-Schwartz J, Youle RJ\",\n",
      "        \"matches_publication/journal\": \"J Cell Biol\",\n",
      "        \"matches_publication/title\": \"Image-based pooled whole-genome CRISPRi screening for subcellular phenotypes.\",\n",
      "        \"matches_optimization/algorithm\": \"Combination of three DenseNet-121, the output of which was combined in a final fully connected layer. \",\n",
      "        \"matches_optimization/encoding\": \"The classifier input data are generated by an unsupervised ML algorithm (MS-AdaNet). No transformation is stated for the input data of MS-AdaNet.\",\n",
      "        \"matches_optimization/features\": \"The inputs of the algorithm are three images. The definition of the images is not reported\",\n",
      "        \"matches_optimization/meta\": \"Yes. The classifier input data are generated using an unsupervised ML algorithm extracting three image features from Chest X Rays scans. Such unsupervised ML algorithm is a convolutional adversarial network (they call that \\\"MS-AdaNet\\\").\\n\\nThey train and test MS-AdaNet on a independent dataset to prove its ability in extrating features. However they trained this algorithm also on the dataset use for classification when the MS-AdaNet is used as input for the classifier.\",\n",
      "        \"matches_optimization/regularization\": \"No overfitting prevention strategy is mentioned.\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/comparison\": \"Compared with other methods presented in literature.\",\n",
      "        \"matches_evaluation/confidence\": \"No confidence intervals or statistical significance provided.\",\n",
      "        \"matches_evaluation/measure\": \"Accuracy, F1 score, Recall, and Precision\",\n",
      "        \"matches_evaluation/method\": \"5-fold cross-validation\",\n",
      "        \"matches_dataset/availability\": \"Yes. They used a public dataset published in a previous paper. Paper doi: 10.1109/ACCESS.2020.3010287\",\n",
      "        \"matches_dataset/provenance\": \"Public dataset of Chest X Rays scans labeled for \\\"normal\\\", \\\"viral pneumonia\\\", and \\\"COVID-19\\\". N_normal = 1341; N_viral_pneumonia = 1345; N_covid19 = 219. Used in previous papers.\",\n",
      "        \"matches_dataset/redundancy\": \"Only one dataset is used. They used 5-fold cross-validation on the dataset for evaluation.\",\n",
      "        \"matches_dataset/splits\": \"No test or validation set used. They used 5-fold cross-validation on the dataset for evaluation. Distribution of the classes in the splits not reported\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b37\",\n",
      "        \"publication_pmid\": \"33953201\",\n",
      "        \"publication_updated\": \"03/06/2022 18:09:45\",\n",
      "        \"publication_authors\": \"Ju F, Zhu J, Shao B, Kong L, Liu TY, Zheng WM, Bu D\",\n",
      "        \"publication_journal\": \"Nat Commun\",\n",
      "        \"publication_title\": \"CopulaNet: Learning residue co-evolution directly from multiple sequence alignment for protein structure prediction.\",\n",
      "        \"publication_doi\": \"10.1038/s41467-021-22869-8\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"4d57e85d-7eba-478f-9400-c8f4acb9fdcc\",\n",
      "        \"shortid\": \"1bn52lke7u\",\n",
      "        \"score\": 0.57,\n",
      "        \"matches_publication/updated\": \"03/06/2022 18:09:45\",\n",
      "        \"matches_publication/authors\": \"Ju F, Zhu J, Shao B, Kong L, Liu TY, Zheng WM, Bu D\",\n",
      "        \"matches_publication/journal\": \"Nat Commun\",\n",
      "        \"matches_publication/title\": \"CopulaNet: Learning residue co-evolution directly from multiple sequence alignment for protein structure prediction.\",\n",
      "        \"matches_optimization/algorithm\": \"Neural network\",\n",
      "        \"matches_optimization/encoding\": \"n-dimensional vectors\",\n",
      "        \"matches_optimization/regularization\": \"Yes, Global orthogonal regularization (alpha = 1)\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_dataset/availability\": \"Yes, https://chemicalchecker.org/\",\n",
      "        \"matches_dataset/provenance\": \"Public database\",\n",
      "        \"matches_dataset/splits\": \"Size not reported 80:20 train-test split\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b38\",\n",
      "        \"publication_pmid\": \"34099697\",\n",
      "        \"publication_updated\": \"03/07/2022 21:14:17\",\n",
      "        \"publication_authors\": \"Gao D, Morini E, Salani M, Krauson AJ, Chekuri A, Sharma N, Ragavendran A, Erdin S, Logan EM, Li W, Dakka A, Narasimhan J, Zhao X, Naryshkin N, Trotta CR, Effenberger KA, Woll MG, Gabbeta V, Karp G, Yu Y, Johnson G, Paquette WD, Cutting GR, Talkowski ME, Slaugenhaupt SA\",\n",
      "        \"publication_journal\": \"Nat Commun\",\n",
      "        \"publication_title\": \"A deep learning approach to identify gene targets of a therapeutic for human splicing disorders.\",\n",
      "        \"publication_doi\": \"10.1038/s41467-021-23663-2\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.443Z\",\n",
      "        \"uuid\": \"9bbabc44-4041-4c29-aacc-649db0ba034b\",\n",
      "        \"shortid\": \"ix9p2rdt6k\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches_publication/updated\": \"03/07/2022 21:14:17\",\n",
      "        \"matches_publication/authors\": \"Gao D, Morini E, Salani M, Krauson AJ, Chekuri A, Sharma N, Ragavendran A, Erdin S, Logan EM, Li W, Dakka A, Narasimhan J, Zhao X, Naryshkin N, Trotta CR, Effenberger KA, Woll MG, Gabbeta V, Karp G, Yu Y, Johnson G, Paquette WD, Cutting GR, Talkowski ME, Slaugenhaupt SA\",\n",
      "        \"matches_publication/journal\": \"Nat Commun\",\n",
      "        \"matches_publication/title\": \"A deep learning approach to identify gene targets of a therapeutic for human splicing disorders.\",\n",
      "        \"matches_optimization/algorithm\": \"Generalized Linear models, SVM, NN, Random Forests and XGBoost,\",\n",
      "        \"matches_optimization/encoding\": \"Normalization according to an external reference Gut. 2014;63(11):1700\\u201310. https://doi.org/10.1136/gutjnl-2013-305806.\",\n",
      "        \"matches_optimization/features\": \"No description\",\n",
      "        \"matches_optimization/fitting\": \"No description\",\n",
      "        \"matches_optimization/parameters\": \"No description\",\n",
      "        \"matches_model/interpretability\": \"Linear models and ensemble methods\",\n",
      "        \"matches_model/output\": \"both regression and classification\",\n",
      "        \"matches_evaluation/comparison\": \"No comparison\",\n",
      "        \"matches_evaluation/confidence\": \"Unpaired or paired Student t-test and log-rank tests for Kaplan-Meier\",\n",
      "        \"matches_evaluation/method\": \"one training set, one test set and one validation set.\",\n",
      "        \"matches_dataset/availability\": \"No. However, raw data can be downloaded  as data sets can be of GSE53625 from GEO (https://www.ncbi.nlm.nih.gov/geo/) and 37 ESCC cases with Asian ancestry from TCGA (UCSC Xena, https://xena.ucsc.edu/).\",\n",
      "        \"matches_dataset/provenance\": \"Downloaded from public sources\",\n",
      "        \"matches_dataset/redundancy\": \"No similarity check\",\n",
      "        \"matches_dataset/splits\": \"Train set of 134 samples, test of 45 samples, and a validation sets consisting of 86 samples. No mention to N_pos or N_neg.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b57\",\n",
      "        \"publication_pmid\": \"33810341\",\n",
      "        \"publication_updated\": \"02/18/2022 08:57:44\",\n",
      "        \"publication_authors\": \"Keresztes L, Sz\\u00f6gi E, Varga B, Farkas V, Perczel A, Grolmusz V\",\n",
      "        \"publication_journal\": \"Biomolecules\",\n",
      "        \"publication_title\": \"The Budapest Amyloid Predictor and Its Applications.\",\n",
      "        \"publication_doi\": \"10.3390/biom11040500\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"396609c8-552f-4eed-9c3e-18a8c4238dd0\",\n",
      "        \"shortid\": \"bd02oq0dn5\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches_publication/updated\": \"02/18/2022 08:57:44\",\n",
      "        \"matches_publication/authors\": \"Keresztes L, Sz\\u00f6gi E, Varga B, Farkas V, Perczel A, Grolmusz V\",\n",
      "        \"matches_publication/title\": \"The Budapest Amyloid Predictor and Its Applications.\",\n",
      "        \"matches_optimization/encoding\": \"global features invlude various clinical characteristis of sampes.\",\n",
      "        \"matches_optimization/features\": \"4(Plasma samples were used to measure cell-free Dnot reported, NE-Dnot reported, MPO-Dnot reported,\\nand citH3-Dnot reported complexes from training and validation sets.)\",\n",
      "        \"matches_optimization/parameters\": \"Grid search and Gaussian radial basis function kernels were implemented for tuning parameters.\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"classification: binary predictions\",\n",
      "        \"matches_evaluation/comparison\": \"novel approach\",\n",
      "        \"matches_evaluation/confidence\": \"svms accuracy\",\n",
      "        \"matches_evaluation/measure\": \"ROC, AUC, sensitivity, specificity\",\n",
      "        \"matches_evaluation/method\": \"indipendent dataset\",\n",
      "        \"matches_dataset/availability\": \"in supplementary files\",\n",
      "        \"matches_dataset/provenance\": \"they created the dataset\",\n",
      "        \"matches_dataset/splits\": \"training set: 40 (23 active and 17 inactive) patients & 24 healthy, validation set: 26 (18 active and 8 inactive) patients & 16 healthy\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b58\",\n",
      "        \"publication_pmid\": \"32991297\",\n",
      "        \"publication_updated\": \"02/18/2022 09:58:28\",\n",
      "        \"publication_authors\": \"Bao G, Xu R, Wang X, Ji J, Wang L, Li W, Zhang Q, Huang B, Chen A, Zhang D, Kong B, Yang Q, Yuan C, Wang X, Wang J, Li X\",\n",
      "        \"publication_journal\": \"IEEE J Biomed Health Inform\",\n",
      "        \"publication_title\": \"Identification of lncRNA Signature Associated With Pan-Cancer Prognosis.\",\n",
      "        \"publication_doi\": \"10.1109/JBHI.2020.3027680\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"9d6ac10d-1ae3-42d0-bc30-3a9363a41b6f\",\n",
      "        \"shortid\": \"lmmde595pw\",\n",
      "        \"score\": 0.86,\n",
      "        \"matches_publication/updated\": \"02/18/2022 09:58:28\",\n",
      "        \"matches_publication/authors\": \"Bao G, Xu R, Wang X, Ji J, Wang L, Li W, Zhang Q, Huang B, Chen A, Zhang D, Kong B, Yang Q, Yuan C, Wang X, Wang J, Li X\",\n",
      "        \"matches_publication/journal\": \"IEEE J Biomed Health Inform\",\n",
      "        \"matches_publication/title\": \"Identification of lncRNA Signature Associated With Pan-Cancer Prognosis.\",\n",
      "        \"matches_optimization/algorithm\": \"SVM (FITCSVM)\",\n",
      "        \"matches_optimization/config\": \"No. URL given for model availability but link is broken (not sure what exact information was available in the URL)\",\n",
      "        \"matches_optimization/encoding\": \"Yes: specific sequence features\\n(k-nucleotide frequency (KNF), k-spaced nucleotide pair frequency (KSNPF), position-specific nucleotide propensity (PSNP), k-spaced position-specific dinucleotide propensity (KSPSDP), pseudo dinucleotide composition (PseDNC), Chemical property with density (CPD))\\n\",\n",
      "        \"matches_optimization/features\": \"Yes: number of features and feature selection on the ten-fold cross-validation dataset using sequential forward feature selection (SFS)\",\n",
      "        \"matches_optimization/fitting\": \"No exclusion mentioned\",\n",
      "        \"matches_optimization/parameters\": \"Yes: 2 (box constraint and kernel scale)\\nSelected through grid search on ten-fold cross-validation dataset\",\n",
      "        \"matches_optimization/regularization\": \"Yes (sequential forward feature selection (SFS) to reduce redundant features)\",\n",
      "        \"matches_model/availability\": \"Website URL (but link is broken)\",\n",
      "        \"matches_model/interpretability\": \"Transparent at the level of the feature selection (evaluation results for different combinations of features), put in connection with mean sequence difference between positive and negative sets\",\n",
      "        \"matches_evaluation/comparison\": \"Comparison of SVM with other classifiers (KNN, Adaboost, random forests, decision tree, logistic regression and XGBoost) on the same cross-validation dataset.\\n Comparison of their best method (SVM) with five other existing methods with webserver availability (RNAm5Cfinder, iRNA-m5C, iRNAm5C-PseDNC and RNAm5Cpred, PEA-m5C). Table presenting algorithm class and features used by these methods is presented.\",\n",
      "        \"matches_evaluation/confidence\": \"List of so-called \\u201csignificantly higher\\u201c performance metric values in favor of their method, but without confidence interval or explicit p-values or even name of test performed.\",\n",
      "        \"matches_evaluation/measure\": \"Accuracy, sensitivity, specificity, precision, Matthews correlation coefficient and F1-score.\\n Area under ROC and PRC\",\n",
      "        \"matches_evaluation/method\": \"Independent test set\",\n",
      "        \"matches_dataset/availability\": \"Yes, supposedly. Datasets are supposed to be available through URL (https://zhulab.ahu.edu.cn/m5CPred-SVM/) but link does not respond\",\n",
      "        \"matches_dataset/provenance\": \"Yes: source of data. Used by previous papers.\",\n",
      "        \"matches_dataset/redundancy\": \"Yes: procedure to remove sequences with similarity >70% is applied in negative and positive datasets\",\n",
      "        \"matches_dataset/splits\": \"Yes: size of training, validation and test sets as well as distribution of N_pos and N_neg are given.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b59\",\n",
      "        \"publication_pmid\": \"34070374\",\n",
      "        \"publication_updated\": \"03/26/2022 18:39:06\",\n",
      "        \"publication_authors\": \"Arredondo Eve A, Tunc E, Liu YJ, Agrawal S, Erbak Yilmaz H, Emren SV, Aky\\u0131ld\\u0131z Ak\\u00e7ay F, Mainzer L, \\u017durauskien\\u0117 J, Madak Erdogan Z\",\n",
      "        \"publication_journal\": \"Metabolites\",\n",
      "        \"publication_title\": \"Identification of Circulating Diagnostic Biomarkers for Coronary Microvascular Disease in Postmenopausal Women Using Machine-Learning Techniques.\",\n",
      "        \"publication_doi\": \"10.3390/metabo11060339\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"26486d2e-e909-4b8a-a883-ec4878c2a8e0\",\n",
      "        \"shortid\": \"65taxw9gs8\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"03/26/2022 18:39:06\",\n",
      "        \"matches_publication/authors\": \"Arredondo Eve A, Tunc E, Liu YJ, Agrawal S, Erbak Yilmaz H, Emren SV, Aky\\u0131ld\\u0131z Ak\\u00e7ay F, Mainzer L, \\u017durauskien\\u0117 J, Madak Erdogan Z\",\n",
      "        \"matches_publication/title\": \"Identification of Circulating Diagnostic Biomarkers for Coronary Microvascular Disease in Postmenopausal Women Using Machine-Learning Techniques.\",\n",
      "        \"matches_optimization/algorithm\": \"Novel prediction algorithm: Smooth-Threshold Multivariate Genetic Prediction (STMGP)\",\n",
      "        \"matches_optimization/features\": \"They prepared SNP data, phenotype data, and covariate data for both the training and test\\ndatasets for the input of the function (3 features).\",\n",
      "        \"matches_optimization/parameters\": \"2 tuning parameters.\",\n",
      "        \"matches_optimization/regularization\": \"Strategy to reduce overfitting: screening and building penalized regression models.\",\n",
      "        \"matches_model/availability\": \"The program code for STMGP (STMGP v1.0), including the function used in the study, is available via CRAN, the official R package archive.\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/comparison\": \"The performance of STMGP was evaluated in terms of prediction accuracy and\\n the degree of overfitting, and compared with that of other state-of-the-art methods, which included, in addition to PRS and GBLUP, summary-data-based best linear-unbiased prediction (SBLUP) , BayesR (a Bayesian hierarchical model for complex trait analysis) , and ridge regression (penalized regression model).\",\n",
      "        \"matches_evaluation/confidence\": \"STMGP showed the highest prediction accuracy with the lowest degree of overfitting, although there was no significant difference in prediction accuracy.\",\n",
      "        \"matches_evaluation/method\": \"The performance of STMGP was evaluated in terms of prediction accuracy and the degree of overfitting.\",\n",
      "        \"matches_dataset/provenance\": \"SNP data for a total of 9966 subjects: 4974 training cohort subjects living in Miyagi prefecture recruited by Tohoku University and 4992 validation cohort subjects living in Iwate prefecture recruited by Iwate Medical University. \",\n",
      "        \"matches_dataset/redundancy\": \"Training and test sets are independent. Subjects with a low call rate (<0.98, n = 2 in the training cohort and n = 3 in the validation cohort) were excluded.\\nThey detected 2156 close-relationship pairs (620 in the training cohort and 1536 in the validation cohort) using the identity-by-descent method in PLINK software among the training cohort, the validation cohort, or between these cohorts. Then, in each of these pairs, a subject with lower call rates was excluded. Variants with low call rates, low Hardy\\u2013Weinberg equilibrium exact-test P values, or low minor-allele frequencies were filtered out. Subjects without outcome or covariate information (n = 669 in the training cohort and n = 408 in the validation cohort) were excluded. Finally, 3685 subjects in the training cohort and 3048 subjects in the validation cohort with 615,386 variants were subjected to prediction analyses.\",\n",
      "        \"matches_dataset/splits\": \"After filtering, 3685 subjects in the training cohort and 3048 subjects in the validation cohort with 615,386 variants were subjected to prediction analyses.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b5a\",\n",
      "        \"publication_pmid\": \"34229736\",\n",
      "        \"publication_updated\": \"03/29/2022 22:22:24\",\n",
      "        \"publication_authors\": \"Koo BS, Eun S, Shin K, Yoon H, Hong C, Kim DH, Hong S, Kim YG, Lee CK, Yoo B, Oh JS\",\n",
      "        \"publication_journal\": \"Arthritis Res Ther\",\n",
      "        \"publication_title\": \"Machine learning model for identifying important clinical features for predicting remission in patients with rheumatoid arthritis treated with biologics.\",\n",
      "        \"publication_doi\": \"10.1186/s13075-021-02567-y\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"fff9d12e-3bb2-4353-9447-8540487d7c84\",\n",
      "        \"shortid\": \"h1b95pkq6c\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches_publication/updated\": \"03/29/2022 22:22:24\",\n",
      "        \"matches_publication/authors\": \"Koo BS, Eun S, Shin K, Yoon H, Hong C, Kim DH, Hong S, Kim YG, Lee CK, Yoo B, Oh JS\",\n",
      "        \"matches_publication/journal\": \"Arthritis Res Ther\",\n",
      "        \"matches_publication/title\": \"Machine learning model for identifying important clinical features for predicting remission in patients with rheumatoid arthritis treated with biologics.\",\n",
      "        \"matches_optimization/algorithm\": \"The VGG-16 network architecture (Simonyan & Zisserman, 2014) has been updated to replace the last block containing the softmax classification with a fully-connected layer\\n(FCL).\",\n",
      "        \"matches_optimization/encoding\": \"Data augmentation: blur (+ affine transform), contrast (+ affine transform), noise (+ affine transform). In total, for every image in the original dataset, additional 150 images have been generated through the presented augmentation process.\",\n",
      "        \"matches_optimization/features\": \"The extracted features are flattened: input feature vector [7*7*512].\",\n",
      "        \"matches_optimization/fitting\": \"They report overfitting and state that they will evaluate the performance of the network training against the overfitting in future research activity.\",\n",
      "        \"matches_optimization/parameters\": \"The weights of the VGG-16 network have been preserved from the pre-trained model. FCL layer network which consists of 2-layers. The first layer is activated by the ReLU function and consists of 256 nodes, followed by the second layer consisting of 16 nodes activated by softmax.\",\n",
      "        \"matches_model/duration\": \"The cloud-based deployment of the CPU-only Tensorflow with Keras library has resulted\\n in the computational time between 2 s to 2.99 s for the classification of the input image and provide a response to the mobile application.\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_dataset/provenance\": \"Data collection was conducted through samples aggregated from mango\\nplants. Data is composed of images. \\nThey perform 3 experimental scenarios: Dataset size (510, 46.500, 62.047).\",\n",
      "        \"matches_dataset/splits\": \"The overall original dataset has been divided into three subsets\\nnamely (i) training; (ii) validation and (iii) testing with 60%, 20% and\\n20% respectively.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b5b\",\n",
      "        \"publication_pmid\": \"34099048\",\n",
      "        \"publication_updated\": \"06/23/2022 03:51:32\",\n",
      "        \"publication_authors\": \"Gonzalez G, Gong S, Laponogov I, Bronstein M, Veselkov K\",\n",
      "        \"publication_journal\": \"Hum Genomics\",\n",
      "        \"publication_title\": \"Predicting anticancer hyperfoods with graph convolutional networks.\",\n",
      "        \"publication_doi\": \"10.1186/s40246-021-00333-4\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"d8f4a424-12a1-40cc-8bde-3f756df2316b\",\n",
      "        \"shortid\": \"v4efeulceq\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"06/23/2022 03:51:32\",\n",
      "        \"matches_publication/authors\": \"Gonzalez G, Gong S, Laponogov I, Bronstein M, Veselkov K\",\n",
      "        \"matches_publication/journal\": \"Hum Genomics\",\n",
      "        \"matches_publication/title\": \"Predicting anticancer hyperfoods with graph convolutional networks.\",\n",
      "        \"matches_optimization/algorithm\": \"accelerated generalized gradient descent. \",\n",
      "        \"matches_optimization/encoding\": \"SVD for groups' separation\",\n",
      "        \"matches_optimization/parameters\": \"p=6. penalty parameter \\u03bb,  \\u03b1 \\u2208 [0, 1] is the mixing parameter which convexly links the penalties, \\u03b5_rel relative accuracy,  groups from SVD, weights for each explanatory variable, proportion \\u03be \\u03bbmin = \\u03be\\u03bbmax.\",\n",
      "        \"matches_optimization/regularization\": \"Yes. Regularization paths for the lasso, group lasso, sparse-group lasso, and IPF-lasso for linear regression models\",\n",
      "        \"matches_model/availability\": \"yes in Additional files and https://github.com/jklosa/seagull\",\n",
      "        \"matches_model/duration\": \"20'-5h compared to 45h of previous methods\",\n",
      "        \"matches_model/output\": \"regression of methylation age of mice. Eventually, seagull provides a sequence of penalty parameters and calculates the corresponding path of solutions.\",\n",
      "        \"matches_evaluation/comparison\": \"comparison of the outcome of seagull to that of the established R package SGL 1.3\",\n",
      "        \"matches_evaluation/confidence\": \"the results of seagull and SGL were very similar (R^2 > 0.99)\",\n",
      "        \"matches_evaluation/measure\": \"MSE of predicted age based on methylation data, squared correlation coefficient R^2 between predicted and chronological age, the number\\n of features with an estimated effect different from zero, the execution\\n time needed to compute the entire regularization path.\",\n",
      "        \"matches_evaluation/method\": \"independent dataset\",\n",
      "        \"matches_dataset/availability\": \"Yes. https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE80672\",\n",
      "        \"matches_dataset/provenance\": \"The data set is publicly available\\nand described in detail in https://doi.org/10.1016/j.cmet.2017.03.016 \\n141 data points, problem of regression for predicting chronological age of mice based on their methylation profiles.\",\n",
      "        \"matches_dataset/redundancy\": \"\\u0391ll age classes appeared almost equally in both sets.\",\n",
      "        \"matches_dataset/splits\": \"training (n = 75) and validation(n = 66)\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b77\",\n",
      "        \"publication_pmid\": \"34603483\",\n",
      "        \"publication_updated\": \"04/06/2022 17:27:29\",\n",
      "        \"publication_authors\": \"Zhang S, Qu R, Wang P, Wang S\",\n",
      "        \"publication_journal\": \"Comput Math Methods Med\",\n",
      "        \"publication_title\": \"Identification of Novel COVID-19 Biomarkers by Multiple Feature Selection Strategies.\",\n",
      "        \"publication_doi\": \"10.1155/2021/2203636\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.444Z\",\n",
      "        \"uuid\": \"ea4a498a-ad09-4fe4-9fba-a01b495ea341\",\n",
      "        \"shortid\": \"6ykikkh959\",\n",
      "        \"score\": 0.71,\n",
      "        \"matches_publication/updated\": \"04/06/2022 17:27:29\",\n",
      "        \"matches_publication/authors\": \"Zhang S, Qu R, Wang P, Wang S\",\n",
      "        \"matches_publication/journal\": \"Comput Math Methods Med\",\n",
      "        \"matches_publication/title\": \"Identification of Novel COVID-19 Biomarkers by Multiple Feature Selection Strategies.\",\n",
      "        \"matches_optimization/algorithm\": \"Novel approach: They develop a machine learning model to predict BA based on 2 large sleep EEG data sets. The model is described in the paper.\",\n",
      "        \"matches_optimization/config\": \"yes, included in the paper.\",\n",
      "        \"matches_optimization/encoding\": \"EEG signals are notch-filtered at 60 Hz to reduce line noise, and bandpass filtered from 0.5 Hz to 20 Hz to reduce myogenic artifacts.\\nFor 30s-epochs, those with absolute amplitude larger than 500 m V are removed to minimize movement artifacts. Epochs containing flat EEG for more than 2 seconds are also removed. We also exclude EEGs contaminated by electrocardiogram, indicated by 1 Hz harmonic in the EEG spectrogram. To reduce interparticipant variance, the amplitude of each EEG channel is normalized to have zero median and unit interquartile range across the whole night. The total amount of data removed by these preprocessing procedures is\\n7% in the MGH data set and 9% in the SHHS data set.\",\n",
      "        \"matches_optimization/features\": \"They extract 102 features from each 30-second epoch covering both time and frequency domains. For each EEG recording, they average the features in each of the 5 sleep stages overtime, yielding 102 x 5 = 510 features per EEG.\",\n",
      "        \"matches_optimization/fitting\": \"One strength of the study is the use of large data sets. The number of EEGs involved in this study is large among relevant \\u201cBA\\u201d studies. The large size of the data sets helps to ensure the statistical power as well and to minimize selection bias. A large training set helps ensure that the trained model does not overfit to a particular data set, improving the ability togeneralize when applied beyond the training set. A large testing set allows accurate statistical measurement of how accurately the\\nmodel performs.\",\n",
      "        \"matches_optimization/parameters\": \"one. To determine the optimal hyperparameter, they randomly select 300 EEGs from the training set to serve as internal validation data.\",\n",
      "        \"matches_model/interpretability\": \"Transparent. The use of a parametric model, improves model interpretation by inspecting each EEG feature and comparing to the age norm for each feature explicitly. An example is provided in Figure 5 of the paper.\",\n",
      "        \"matches_evaluation/confidence\": \"The method reports statistical significant results.\",\n",
      "        \"matches_evaluation/method\": \"The model is validated on a longitudinal cohort from a subset of the SHHS data set without neurological or cardiovascular disease.\",\n",
      "        \"matches_dataset/provenance\": \"2 large sleep EEG data sets: the Massachusetts General Hospital (MGH) sleep lab\\ndata set (N = 2532; ages 18-80); and the Sleep Heart Health Study (SHHS, N =1974; ages 40-80)\",\n",
      "        \"matches_dataset/redundancy\": \"They maintain strict separation of training and testing participants.\",\n",
      "        \"matches_dataset/splits\": \"The MGH data set (N =2532) was partitioned into a healthy training set (N = 1343) used to train the model, and a testing set (N =1189) to evaluate model performance.\\n\\nAs validation, they used a subset of the SHHS data set where each participant underwent 2 study visits, referred as SHHS1 and SHHS2. The data set contains 987 adults for a total of 1974 nights of EEG recorded. They trained the model in 2 ways. First, they trained the model on 752 participants with paired EEGs (1504 EEGs) from both visits and tested on the held out 235 participants with paired EEGs (470 EEGs) in both visits. They trained the model on the 2365 EEGs from healthy participants in MGH data set. We then predicted BA on the 1974 paired EEGs in SHHS as the testing set.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b78\",\n",
      "        \"publication_pmid\": \"33535965\",\n",
      "        \"publication_updated\": \"03/28/2022 20:30:14\",\n",
      "        \"publication_authors\": \"Momeni J, Parejo M, Nielsen RO, Langa J, Montes I, Papoutsis L, Farajzadeh L, Bendixen C, C\\u0103uia E, Charri\\u00e8re JD, Coffey MF, Costa C, Dall'Olio R, De la R\\u00faa P, Drazic MM, Filipi J, Galea T, Golubovski M, Gregorc A, Grigoryan K, Hatjina F, Ilyasov R, Ivanova E, Janashia I, Kandemir I, Karatasou A, Kekecoglu M, Kezic N, Matray ES, Mifsud D, Moosbeckhofer R, Nikolenko AG, Papachristoforou A, Petrov P, Pinto MA, Poskryakov AV, Sharipov AY, Siceanu A, Soysal MI, Uzunov A, Zammit-Mangion M, Vingborg R, Bouga M, Kryger P, Meixner MD, Estonba A\",\n",
      "        \"publication_journal\": \"BMC Genomics\",\n",
      "        \"publication_title\": \"Authoritative subspecies diagnosis tool for European honey bees based on ancestry informative SNPs.\",\n",
      "        \"publication_doi\": \"10.1186/s12864-021-07379-7\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"bfdbba26-c83c-43c0-8067-6e78c75facb7\",\n",
      "        \"shortid\": \"m2bccoqnyy\",\n",
      "        \"score\": 0.57,\n",
      "        \"matches_publication/updated\": \"03/28/2022 20:30:14\",\n",
      "        \"matches_publication/authors\": \"Momeni J, Parejo M, Nielsen RO, Langa J, Montes I, Papoutsis L, Farajzadeh L, Bendixen C, C\\u0103uia E, Charri\\u00e8re JD, Coffey MF, Costa C, Dall'Olio R, De la R\\u00faa P, Drazic MM, Filipi J, Galea T, Golubovski M, Gregorc A, Grigoryan K, Hatjina F, Ilyasov R, Ivanova E, Janashia I, Kandemir I, Karatasou A, Kekecoglu M, Kezic N, Matray ES, Mifsud D, Moosbeckhofer R, Nikolenko AG, Papachristoforou A, Petrov P, Pinto MA, Poskryakov AV, Sharipov AY, Siceanu A, Soysal MI, Uzunov A, Zammit-Mangion M, Vingborg R, Bouga M, Kryger P, Meixner MD, Estonba A\",\n",
      "        \"matches_publication/journal\": \"BMC Genomics\",\n",
      "        \"matches_publication/title\": \"Authoritative subspecies diagnosis tool for European honey bees based on ancestry informative SNPs.\",\n",
      "        \"matches_optimization/algorithm\": \"Logistic regression model.\",\n",
      "        \"matches_optimization/encoding\": \"Feature selection.\",\n",
      "        \"matches_optimization/features\": \"Hybrid feature selection schema based on information gain and sequential backward\\nfeature selection (SBFS).\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/measure\": \"96.2% sensitivity and 95.2% specificity\",\n",
      "        \"matches_evaluation/method\": \"tenfold cross-validation\",\n",
      "        \"matches_dataset/availability\": \"Yes. Supplementary material of the paper.\",\n",
      "        \"matches_dataset/provenance\": \"307 cervical tumor samples from The Cancer Genome Atlas, 113 normal.\",\n",
      "        \"matches_dataset/splits\": \"The data were randomly divided into ten different sets. Nine sets were used for training, and the remaining set was used for validation.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b79\",\n",
      "        \"publication_pmid\": \"34254032\",\n",
      "        \"publication_updated\": \"06/23/2022 03:40:26\",\n",
      "        \"publication_authors\": \"Gladding PA, Ayar Z, Smith K, Patel P, Pearce J, Puwakdandawa S, Tarrant D, Atkinson J, McChlery E, Hanna M, Gow N, Bhally H, Read K, Jayathissa P, Wallace J, Norton S, Kasabov N, Calude CS, Steel D, Mckenzie C\",\n",
      "        \"publication_journal\": \"Future Sci OA\",\n",
      "        \"publication_title\": \"A machine learning PROGRAM to identify COVID-19 and other diseases from hematology data.\",\n",
      "        \"publication_doi\": \"10.2144/fsoa-2020-0207\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"1788b70c-e3a7-4a8f-96a4-95a8ea1f3f40\",\n",
      "        \"shortid\": \"9ydtb6du8j\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches_publication/updated\": \"06/23/2022 03:40:26\",\n",
      "        \"matches_publication/authors\": \"Gladding PA, Ayar Z, Smith K, Patel P, Pearce J, Puwakdandawa S, Tarrant D, Atkinson J, McChlery E, Hanna M, Gow N, Bhally H, Read K, Jayathissa P, Wallace J, Norton S, Kasabov N, Calude CS, Steel D, Mckenzie C\",\n",
      "        \"matches_publication/journal\": \"Future Sci OA\",\n",
      "        \"matches_publication/title\": \"A machine learning PROGRAM to identify COVID-19 and other diseases from hematology data.\",\n",
      "        \"matches_optimization/algorithm\": \"ML prediction algorithm was developed based on an artificial neural network (ANN; JMP software, v12.0.1).\",\n",
      "        \"matches_optimization/encoding\": \"Data were comprised of AUC values from each of the 26 cases.\",\n",
      "        \"matches_optimization/features\": \"2 factors.\",\n",
      "        \"matches_optimization/parameters\": \"3 hidden nodes.\",\n",
      "        \"matches_model/availability\": \"Model developed based on an artificial neural network (ANN; JMP software, v12.0.1). There is no executable file available.\",\n",
      "        \"matches_model/interpretability\": \"Transparent: classifies chemicals based on AUC parameters. Small dataset, few features and parameters considered.\",\n",
      "        \"matches_model/output\": \"Classification (4 classes).\",\n",
      "        \"matches_evaluation/comparison\": \"No comparison.\",\n",
      "        \"matches_evaluation/confidence\": \"25 of 26 cases correctly assigned. There is a table with the probability of each case to be correctly classified.\",\n",
      "        \"matches_evaluation/method\": \"Cross-validation, using a leave-one-out approach.\",\n",
      "        \"matches_dataset/availability\": \"Available upon request to the authors.\",\n",
      "        \"matches_dataset/provenance\": \"Data from previous publication and direct experiments. N= 26.\",\n",
      "        \"matches_dataset/splits\": \"training set n = 26, divided in 4 classes. Class 1 = 10 elements, class 2 = 12, class 3 = 3, class 4 = 1.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b81\",\n",
      "        \"publication_pmid\": \"34573923\",\n",
      "        \"publication_updated\": \"02/28/2022 14:25:46\",\n",
      "        \"publication_authors\": \"Rahman T, Al-Ishaq FA, Al-Mohannadi FS, Mubarak RS, Al-Hitmi MH, Islam KR, Khandakar A, Hssain AA, Al-Madeed S, Zughaier SM, Chowdhury MEH\",\n",
      "        \"publication_journal\": \"Diagnostics (Basel)\",\n",
      "        \"publication_title\": \"Mortality Prediction Utilizing Blood Biomarkers to Predict the Severity of COVID-19 Using Machine Learning Technique.\",\n",
      "        \"publication_doi\": \"10.3390/diagnostics11091582\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"10dbaffe-4a11-44af-a1ac-7efd84988759\",\n",
      "        \"shortid\": \"7cpzfr4v7k\",\n",
      "        \"score\": 0.9,\n",
      "        \"matches_publication/updated\": \"02/28/2022 14:25:46\",\n",
      "        \"matches_publication/authors\": \"Rahman T, Al-Ishaq FA, Al-Mohannadi FS, Mubarak RS, Al-Hitmi MH, Islam KR, Khandakar A, Hssain AA, Al-Madeed S, Zughaier SM, Chowdhury MEH\",\n",
      "        \"matches_publication/journal\": \"Diagnostics (Basel)\",\n",
      "        \"matches_publication/title\": \"Mortality Prediction Utilizing Blood Biomarkers to Predict the Severity of COVID-19 Using Machine Learning Technique.\",\n",
      "        \"matches_optimization/algorithm\": \"Multi-view clustering methods (early and late integration, similarity based, dimension reduction and statistical methods)\",\n",
      "        \"matches_optimization/encoding\": \"No, not in detail.\\nClass of feature used are described (gene sequence, expression and methylation) but no detail on encoding (only reference to source of data)\",\n",
      "        \"matches_optimization/features\": \"Yes, indirectly: processed raw data and algorithm for feature selection are given\",\n",
      "        \"matches_optimization/fitting\": \"No exclusion mentioned\",\n",
      "        \"matches_optimization/parameters\": \"Number of clusters: algorithm for selection is presented (elbow method) \\nOther parameters are not directly given but protocol used to select them are given (= if available: adherence to the guidelines given by the packages developers) \",\n",
      "        \"matches_optimization/regularization\": \"Yes, regularization may be used by some methods (but not clear in the publication what was really implemented in the used packages)\\ne.g.\\nLeast Absolute Shrinkage and Selection Operator regularization is used by iCluster\\nNuclear norm regularization is used by LRACluster\\nA regularization term is used by rMKL-LPP\\nSparsity regularization is used by Canonical Correlation Analysis (CCA)\",\n",
      "        \"matches_model/availability\": \"Yes (GitHub)\",\n",
      "        \"matches_model/duration\": \"Yes (runtime in seconds on Windows desktop for eight methods and Linux cluster for one methods)\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"Produces clusters\",\n",
      "        \"matches_evaluation/availability\": \"Yes (supporting information)\",\n",
      "        \"matches_evaluation/comparison\": \"Comparison of logranks\\u2019 test p-values and number of enriched clinical parameters\",\n",
      "        \"matches_evaluation/confidence\": \"No. But no claiming of performance difference\",\n",
      "        \"matches_evaluation/measure\": \"Logrank test (differential survival between clusters)\\n Chi-squared test and Kruskal-Wallis (clinical labels (six) enrichement in clusters)\",\n",
      "        \"matches_evaluation/method\": \"Extrinsic measures (clinical labels)\",\n",
      "        \"matches_dataset/availability\": \"Yes (supporting information and website URL)\",\n",
      "        \"matches_dataset/provenance\": \"Yes (The Cancer Genome Atlas)\",\n",
      "        \"matches_dataset/redundancy\": \"No dataset split  (unsupervised machine learning)\",\n",
      "        \"matches_dataset/splits\": \"No dataset split  (unsupervised machine learning)\\nLabels used to assess performance are given in raw datasets\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b82\",\n",
      "        \"publication_pmid\": \"33465072\",\n",
      "        \"publication_updated\": \"03/23/2022 16:36:18\",\n",
      "        \"publication_authors\": \"Mart\\u00ednez-Garc\\u00eda PM, Garc\\u00eda-Torres M, Divina F, Terr\\u00f3n-Bautista J, Delgado-Sainz I, G\\u00f3mez-Vela F, Cort\\u00e9s-Ledesma F\",\n",
      "        \"publication_journal\": \"PLoS Comput Biol\",\n",
      "        \"publication_title\": \"Genome-wide prediction of topoisomerase II\\u03b2 binding by architectural factors and chromatin accessibility.\",\n",
      "        \"publication_doi\": \"10.1371/journal.pcbi.1007814\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"98d62f4d-4577-4892-9130-684c6464d69c\",\n",
      "        \"shortid\": \"conhqw242m\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches_publication/updated\": \"03/23/2022 16:36:18\",\n",
      "        \"matches_publication/authors\": \"Mart\\u00ednez-Garc\\u00eda PM, Garc\\u00eda-Torres M, Divina F, Terr\\u00f3n-Bautista J, Delgado-Sainz I, G\\u00f3mez-Vela F, Cort\\u00e9s-Ledesma F\",\n",
      "        \"matches_publication/journal\": \"PLoS Comput Biol\",\n",
      "        \"matches_publication/title\": \"Genome-wide prediction of topoisomerase II\\u03b2 binding by architectural factors and chromatin accessibility.\",\n",
      "        \"matches_optimization/algorithm\": \"AIS-ELM is compared with DS-ELM, PSOELM, SaE-ELM, traditional ELM,SVM, and Back Propagation.\",\n",
      "        \"matches_optimization/encoding\": \"All the inputs have been normalized into the range [-1, 1] for fairness.\",\n",
      "        \"matches_optimization/features\": \"1) Ecoli 7, Diabetes 8, Epileptic Seizure 179, Heart Disease 75, Iris 4, Glass 9, Image 19, Satellite 36\\n2)Breast Cancer 32, Parkinson 26,  SinC 1, Servo 4,  Yacht Hydro 13\",\n",
      "        \"matches_optimization/parameters\": \"p=5, the parameters for AIS-ELM are set as follows: \\ud835\\udc4e(antibody population) =10,\\ud835\\udc4f = 50(bit position of the last \\u201con\\u201d bit starting from the most significant bit),\\ud835\\udf00 = 0.1(stimulus region),\\ud835\\udc58 = 5(number of bits that must be flipped to mutate),\\ud835\\udc5f = 0.2(mutation probability)\",\n",
      "        \"matches_model/duration\": \"1) 1-37 seconds\\n 2) 13-33 seconds\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"1) classification\\n 2) regression\",\n",
      "        \"matches_evaluation/confidence\": \"better timing and accuracy\",\n",
      "        \"matches_evaluation/measure\": \"Means and Standard Deviation and training time\",\n",
      "        \"matches_evaluation/method\": \"20-fold cross validation\",\n",
      "        \"matches_dataset/provenance\": \"1) Ecoli, Pima Indians Diabetes\\n(Diabetes), Epileptic Seizure, Iris, Heart Disease, Glass Identification\\n(Glass), Image Segmentation (Image), and Statlog\\n(Satellite)\\n2) Breast Cancer, Parkinson, SinC, Servo, and Yacht Hydro (Yacht)\",\n",
      "        \"matches_dataset/redundancy\": \"all datasets are without overlap, kept coincident for each trial of the algorithms.\",\n",
      "        \"matches_dataset/splits\": \"1) Ecoli train: 180 val:78 test:78, Diabetes train: 384 val:22 test:192, Epileptic Seizure train: 6000 val:2750 test:2750, Heart Disease train: 150 val:76 test:76, Iris train: 70 val:40  test:40, Glass train: 100 val:57 test:57, Image train: 1200 val:555 test:555, Satellite train: 3435 val:1500 test:1500\\n2)Breast Cancer train:98 val:50 test:50, Parkinson train:500 val:270 test:270,  SinC train:5000 val:2500 test:2500, Servo train:384 val:192 test:192,  Yacht Hydro train:150 val:79 test:79\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b83\",\n",
      "        \"publication_pmid\": \"34419924\",\n",
      "        \"publication_updated\": \"03/28/2022 16:40:10\",\n",
      "        \"publication_authors\": \"Hogan CA, Rajpurkar P, Sowrirajan H, Phillips NA, Le AT, Wu M, Garamani N, Sahoo MK, Wood ML, Huang C, Ng AY, Mak J, Cowan TM, Pinsky BA\",\n",
      "        \"publication_journal\": \"EBioMedicine\",\n",
      "        \"publication_title\": \"Nasopharyngeal metabolomics and machine learning approach for the diagnosis of influenza.\",\n",
      "        \"publication_doi\": \"10.1016/j.ebiom.2021.103546\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"b8fe2726-03eb-495c-bdf4-3ad68e43c7a5\",\n",
      "        \"shortid\": \"hilwjyqhpx\",\n",
      "        \"score\": 0.29,\n",
      "        \"matches_publication/updated\": \"03/28/2022 16:40:10\",\n",
      "        \"matches_publication/authors\": \"Hogan CA, Rajpurkar P, Sowrirajan H, Phillips NA, Le AT, Wu M, Garamani N, Sahoo MK, Wood ML, Huang C, Ng AY, Mak J, Cowan TM, Pinsky BA\",\n",
      "        \"matches_publication/title\": \"Nasopharyngeal metabolomics and machine learning approach for the diagnosis of influenza.\",\n",
      "        \"matches_optimization/algorithm\": \"T-distributed stochastic neighbor embedding (t-SNE).\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_dataset/provenance\": \"Data from experiments.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b8e\",\n",
      "        \"publication_pmid\": \"33510068\",\n",
      "        \"publication_updated\": \"02/23/2022 14:26:24\",\n",
      "        \"publication_authors\": \"Skolariki K, Terrera GM, Danso SO\",\n",
      "        \"publication_journal\": \"Neural Regen Res\",\n",
      "        \"publication_title\": \"Predictive models for mild cognitive impairment to Alzheimer's disease conversion.\",\n",
      "        \"publication_doi\": \"10.4103/1673-5374.306071\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"a17d89ff-989f-4293-97a5-94abd04679d9\",\n",
      "        \"shortid\": \"b365zwv48h\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"02/23/2022 14:26:24\",\n",
      "        \"matches_publication/authors\": \"Skolariki K, Terrera GM, Danso SO\",\n",
      "        \"matches_publication/journal\": \"Neural Regen Res\",\n",
      "        \"matches_publication/title\": \"Predictive models for mild cognitive impairment to Alzheimer's disease conversion.\",\n",
      "        \"matches_optimization/algorithm\": \"Deep convolutional neural network trained using gradient descent by standard backpropagation algorithm.\",\n",
      "        \"matches_optimization/encoding\": \"Moving window length across the input sequences by the convolutional kernels and formation of feature maps. One-hot-encoding was used to create vectors for all the types of genotypes available, to ensure that all the categories are equidistant from each other.\",\n",
      "        \"matches_optimization/features\": \"Featured maps formed from filtered exonic variants, one-hot encoded per chromosome.\",\n",
      "        \"matches_optimization/fitting\": \"Application of a batch normalization layer after the max-pooling layer contributes to avoiding overfitting the data. Additionally, balanced training, validation and testing datasets were used.\",\n",
      "        \"matches_optimization/parameters\": \"The deep convolutional network takes in a 23-channel input, with each input being the one-hot encoded variants of a chromosome. Initializing weights to reduce the loss function at each epoch.\",\n",
      "        \"matches_optimization/regularization\": \"Yes. Reduction of feature dimension using L1 regularization with penalty parameter C = 0.85. Less than 1% of the total features remain.\",\n",
      "        \"matches_model/duration\": \"Training the model end-to-end takes close to 6 hours on Nvidia Tesla M40 servers.\",\n",
      "        \"matches_model/interpretability\": \"Black box. Reduced performance due to repeated feature subsampling supports the importance of all features in model performance and the absence of sequencing method artifacts.\",\n",
      "        \"matches_model/output\": \"Classification with binary predictions.\",\n",
      "        \"matches_evaluation/comparison\": \"Decision trees and random forests.\",\n",
      "        \"matches_evaluation/confidence\": \"Higher performance metrics of the convolutional neural network (e.g., accuracy = 0.65) than those of the comparing algorithms (accuracy = 0.55). Confidence intervals were not calculated, and statistical testing was not applied.\",\n",
      "        \"matches_evaluation/measure\": \"Accuracy, Precision, Recall, F1-Score, AUC score, ROC curve.\",\n",
      "        \"matches_dataset/provenance\": \"Exome sequencing data for 1000 samples. Npos = 500 (control group). Nneg = 500 (disease group). Ntrain = 500. Ntest = 500. Data were provided from the Regents of the University of California under the challenge \\u201cBipolar Exomes\\u201d.\",\n",
      "        \"matches_dataset/redundancy\": \"Random sampling from the pool of 1000 samples and balanced datasets between train, validation, and test datasets.\",\n",
      "        \"matches_dataset/splits\": \"Npos,train = 200. Nneg,train = 200. Validation set present. Npos,validation = 50. Nneg,validation = 50. Npos,test = 249. Nneg,test = 251.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b8f\",\n",
      "        \"publication_pmid\": \"33946997\",\n",
      "        \"publication_updated\": \"03/12/2022 20:11:43\",\n",
      "        \"publication_authors\": \"Koureas M, Kalompatsios D, Amoutzias GD, Hadjichristodoulou C, Gourgoulianis K, Tsakalof A\",\n",
      "        \"publication_journal\": \"Molecules\",\n",
      "        \"publication_title\": \"Comparison of Targeted and Untargeted Approaches in Breath Analysis for the Discrimination of Lung Cancer from Benign Pulmonary Diseases and Healthy Persons.\",\n",
      "        \"publication_doi\": \"10.3390/molecules26092609\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"35bd5800-8ba0-4243-bf5c-09f8cfdd9734\",\n",
      "        \"shortid\": \"47cb9iahma\",\n",
      "        \"score\": 0.67,\n",
      "        \"matches_publication/updated\": \"03/12/2022 20:11:43\",\n",
      "        \"matches_publication/authors\": \"Koureas M, Kalompatsios D, Amoutzias GD, Hadjichristodoulou C, Gourgoulianis K, Tsakalof A\",\n",
      "        \"matches_publication/title\": \"Comparison of Targeted and Untargeted Approaches in Breath Analysis for the Discrimination of Lung Cancer from Benign Pulmonary Diseases and Healthy Persons.\",\n",
      "        \"matches_optimization/encoding\": \"Fragments of atoms and bonds (ISIDA Fragmentor software) scaled to the interval [0-1]\",\n",
      "        \"matches_optimization/features\": \"Yes: 5-25 features per model, randomly selected among 250 most informative on training dataset (removal of features returning nearly constant values (about for 99%) and selection of top-250 according to Mutual Information Quotient score (Minimal Redundancy Maximal Relevance mRMR algorithm))\",\n",
      "        \"matches_optimization/meta\": \"Yes: model aggregation (ensemble modeling) and multi-criteria decision making\\nTrained on the same dataset\",\n",
      "        \"matches_optimization/parameters\": \"2 LSSVM parameters (RBF kernel (\\u03c32) and regularization (\\u03b3)) \\nMinimization of the misclassification rate of the 10-fold cross-validated training dataset\",\n",
      "        \"matches_optimization/regularization\": \"Yes: \\u03b3 parameter (LSSVM) \",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"Classification and score based on LSSVM scores\",\n",
      "        \"matches_evaluation/measure\": \"Accuracy (Acc), Sensitivity (Se), Specificity (Sp) and Balanced Classification Rate (BCR)\\n Area Under the Accumulation Curve (AUAC); Area under the Receiver Operating Characteristic Curve (ROC); Enrichment factor (EF) and Boltzmann-enhanced discrimination of ROC (BEDROC)\",\n",
      "        \"matches_evaluation/method\": \"Independent dataset\",\n",
      "        \"matches_dataset/availability\": \"Yes, in supporting information\",\n",
      "        \"matches_dataset/provenance\": \"Yes (ChEMBL-NTD Novartis dataset and dataset from previous publication)\",\n",
      "        \"matches_dataset/redundancy\": \"Yes, independent training, test and external test sets generated using sphere exclusion algorithms\",\n",
      "        \"matches_dataset/splits\": \"Yes: N_pos and N_neg for training, test and external test sets\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b90\",\n",
      "        \"publication_pmid\": \"33953203\",\n",
      "        \"publication_updated\": \"03/16/2022 16:16:20\",\n",
      "        \"publication_authors\": \"Szkalisity A, Piccinini F, Beleon A, Balassa T, Varga IG, Migh E, Molnar C, Paavolainen L, Timonen S, Banerjee I, Ikonen E, Yamauchi Y, Ando I, Peltonen J, Pieti\\u00e4inen V, Honti V, Horvath P\",\n",
      "        \"publication_journal\": \"Nat Commun\",\n",
      "        \"publication_title\": \"Regression plane concept for analysing continuous cellular processes with machine learning.\",\n",
      "        \"publication_doi\": \"10.1038/s41467-021-22866-x\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"92182157-6ae9-46f7-873c-ac1450fee9f5\",\n",
      "        \"shortid\": \"fnmlhciok7\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches_publication/updated\": \"03/16/2022 16:16:20\",\n",
      "        \"matches_publication/authors\": \"Szkalisity A, Piccinini F, Beleon A, Balassa T, Varga IG, Migh E, Molnar C, Paavolainen L, Timonen S, Banerjee I, Ikonen E, Yamauchi Y, Ando I, Peltonen J, Pieti\\u00e4inen V, Honti V, Horvath P\",\n",
      "        \"matches_publication/journal\": \"Nat Commun\",\n",
      "        \"matches_publication/title\": \"Regression plane concept for analysing continuous cellular processes with machine learning.\",\n",
      "        \"matches_optimization/algorithm\": \"Word2Vec + Random Forest\",\n",
      "        \"matches_model/availability\": \"Soft available separately.\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_model/output\": \"Multiclass Multilabel Classification\",\n",
      "        \"matches_evaluation/measure\": \"precision, recall, F1-score\",\n",
      "        \"matches_dataset/provenance\": \"Yes, CheMBL\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305b91\",\n",
      "        \"publication_pmid\": \"33953534\",\n",
      "        \"publication_updated\": \"03/18/2022 15:31:10\",\n",
      "        \"publication_authors\": \"Uthamacumaran A, Suarez NG, Banir\\u00e9 Diallo A, Annabi B\",\n",
      "        \"publication_journal\": \"Cancer Inform\",\n",
      "        \"publication_title\": \"Computational Methods for Structure-to-Function Analysis of Diet-Derived Catechins-Mediated Targeting of In Vitro Vasculogenic Mimicry.\",\n",
      "        \"publication_doi\": \"10.1177/11769351211009229\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.445Z\",\n",
      "        \"uuid\": \"b3a17544-6140-497c-a0d5-c3ee482dce5e\",\n",
      "        \"shortid\": \"mnu68fbrdn\",\n",
      "        \"score\": 0.95,\n",
      "        \"matches_publication/updated\": \"03/18/2022 15:31:10\",\n",
      "        \"matches_publication/authors\": \"Uthamacumaran A, Suarez NG, Banir\\u00e9 Diallo A, Annabi B\",\n",
      "        \"matches_publication/journal\": \"Cancer Inform\",\n",
      "        \"matches_publication/title\": \"Computational Methods for Structure-to-Function Analysis of Diet-Derived Catechins-Mediated Targeting of In Vitro Vasculogenic Mimicry.\",\n",
      "        \"matches_optimization/algorithm\": \"FORCE method using Izhikevich, Theta and LIF neuron models. It does not seem to be a novel approach as they mention building upon others.\",\n",
      "        \"matches_optimization/config\": \"Not sure. MatLab code is available so I guess it is possible to change the hyper-parameter configuration there. See https://senselab.med.yale.edu/ModelDB/ShowModel?model=190565\",\n",
      "        \"matches_optimization/encoding\": \"I did not see it in the text\",\n",
      "        \"matches_optimization/features\": \"I did not see it in the text\",\n",
      "        \"matches_optimization/fitting\": \"I did not see it in the text\",\n",
      "        \"matches_optimization/meta\": \"I did not see it in the text\",\n",
      "        \"matches_optimization/parameters\": \"There is a box listing parameters and their values. They mention previous works for tuning the parameters (not sure if they cover all of the parameters though)\",\n",
      "        \"matches_optimization/regularization\": \"I did not see it in the text\",\n",
      "        \"matches_model/availability\": \"Yes, see https://senselab.med.yale.edu/ModelDB/ShowModel?model=190565 (also in GitHub at https://github.com/ModelDBRepository/190565) I did not see a license\",\n",
      "        \"matches_model/interpretability\": \"It did not look very transparent to me\",\n",
      "        \"matches_model/output\": \"It produces a reproduction, e.g. given a song, the neural network is trained to reproduce it.\",\n",
      "        \"matches_evaluation/availability\": \"I did not see it in the text but it could be part of the available code\",\n",
      "        \"matches_evaluation/comparison\": \"Izhikevich, Theta and LIF models are used\",\n",
      "        \"matches_evaluation/confidence\": \"I did not see it in the text\",\n",
      "        \"matches_evaluation/measure\": \"Accuracy is mentioned in the text.\",\n",
      "        \"matches_evaluation/method\": \"For the songs, it looks like they compared the waves but I did not see a clear mention on how the method was evaluated\",\n",
      "        \"matches_dataset/availability\": \"Availability of data is not reported There is availability of the code (mentioned as data availability). If the data is part of the code repo, I did not see it. Only *.m files for MatLab\",\n",
      "        \"matches_dataset/provenance\": \"Multiple ML pipelines are discussed. Data source is mentioned only for 1 of them (zebra finch singing) via an article reference (so it seems to have been used by a previous paper). I did not find any mention of data points.\",\n",
      "        \"matches_dataset/redundancy\": \"I did not find it in the text\",\n",
      "        \"matches_dataset/splits\": \"I did not find any of this in the text\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305ba6\",\n",
      "        \"publication_pmid\": \"33828982\",\n",
      "        \"publication_updated\": \"03/02/2022 13:51:09\",\n",
      "        \"publication_authors\": \"Cui Y, Li Y, Xing D, Bai T, Dong J, Zhu J\",\n",
      "        \"publication_journal\": \"Front Oncol\",\n",
      "        \"publication_title\": \"Improving the Prediction of Benign or Malignant Breast Masses Using a Combination of Image Biomarkers and Clinical Parameters.\",\n",
      "        \"publication_doi\": \"10.3389/fonc.2021.629321\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"cf9dcd08-f887-4f92-837d-6a795fe980ec\",\n",
      "        \"shortid\": \"wa4n4o4gna\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"03/02/2022 13:51:09\",\n",
      "        \"matches_publication/authors\": \"Cui Y, Li Y, Xing D, Bai T, Dong J, Zhu J\",\n",
      "        \"matches_publication/journal\": \"Front Oncol\",\n",
      "        \"matches_publication/title\": \"Improving the Prediction of Benign or Malignant Breast Masses Using a Combination of Image Biomarkers and Clinical Parameters.\",\n",
      "        \"matches_optimization/algorithm\": \"\\u201cA priori\\u201d algorithm\",\n",
      "        \"matches_optimization/encoding\": \"Yes: Presence/absence of genes\",\n",
      "        \"matches_optimization/features\": \"Yes (13 features)\",\n",
      "        \"matches_optimization/fitting\": \"No exclusion\",\n",
      "        \"matches_optimization/parameters\": \"2 parameters (minimum support threshold and confidence levels)\",\n",
      "        \"matches_model/availability\": \"Yes (URL http://www.cs.waikato.ac.nz/~ml/weka/index.html)\",\n",
      "        \"matches_model/interpretability\": \"Transparent: 24 most frequent rules generated by the apriori algorithm are detailed\",\n",
      "        \"matches_model/output\": \"Binary prediction (statistical classifier)\",\n",
      "        \"matches_evaluation/availability\": \"Yes: confusion matrix in publication\",\n",
      "        \"matches_evaluation/comparison\": \"Univariate statistical analysis (Fishers\\u2019 exact test) and decision tree classifier (J48 ID3)\",\n",
      "        \"matches_evaluation/confidence\": \"Chi-squared test p-value comparison\",\n",
      "        \"matches_evaluation/measure\": \"chi-squared test\",\n",
      "        \"matches_evaluation/method\": \"Evaluation on the training dataset\",\n",
      "        \"matches_dataset/provenance\": \"Yes (Mexican Reference Genomic Dnot reported Collection (MGDC-REF) ). Source of data and number of positives and negatives given, negative dataset was used by a previous paper.\",\n",
      "        \"matches_dataset/redundancy\": \"No, only training set\",\n",
      "        \"matches_dataset/splits\": \"Yes: number of N_pos and N_neg\\nNo data splits. Only training set\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305ba7\",\n",
      "        \"publication_pmid\": \"34112769\",\n",
      "        \"publication_updated\": \"03/29/2022 23:01:05\",\n",
      "        \"publication_authors\": \"Soret P, Le Dantec C, Desvaux E, Foulquier N, Chassagnol B, Hubert S, Jamin C, Barturen G, Desachy G, Devauchelle-Pensec V, Boudjeniba C, Cornec D, Saraux A, Jousse-Joulin S, Barbarroja N, Rodr\\u00edguez-Pint\\u00f3 I, De Langhe E, Beretta L, Chizzolini C, Kov\\u00e1cs L, Witte T, PRECISESADS Clinical Consortium., PRECISESADS Flow Cytometry Consortium., Bettacchioli E, Buttgereit A, Makowska Z, Lesche R, Borghi MO, Martin J, Courtade-Gaiani S, Xuereb L, Guedj M, Moingeon P, Alarc\\u00f3n-Riquelme ME, Laigle L, Pers JO\",\n",
      "        \"publication_journal\": \"Nat Commun\",\n",
      "        \"publication_title\": \"A new molecular classification to drive precision treatment strategies in primary Sj\\u00f6gren's syndrome.\",\n",
      "        \"publication_doi\": \"10.1038/s41467-021-23472-7\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"001278bf-79ae-42c1-b064-88bbc3e18183\",\n",
      "        \"shortid\": \"e1fgv8jwbe\",\n",
      "        \"score\": 0.62,\n",
      "        \"matches_publication/updated\": \"03/29/2022 23:01:05\",\n",
      "        \"matches_publication/authors\": \"Soret P, Le Dantec C, Desvaux E, Foulquier N, Chassagnol B, Hubert S, Jamin C, Barturen G, Desachy G, Devauchelle-Pensec V, Boudjeniba C, Cornec D, Saraux A, Jousse-Joulin S, Barbarroja N, Rodr\\u00edguez-Pint\\u00f3 I, De Langhe E, Beretta L, Chizzolini C, Kov\\u00e1cs L, Witte T, PRECISESADS Clinical Consortium., PRECISESADS Flow Cytometry Consortium., Bettacchioli E, Buttgereit A, Makowska Z, Lesche R, Borghi MO, Martin J, Courtade-Gaiani S, Xuereb L, Guedj M, Moingeon P, Alarc\\u00f3n-Riquelme ME, Laigle L, Pers JO\",\n",
      "        \"matches_publication/journal\": \"Nat Commun\",\n",
      "        \"matches_publication/title\": \"A new molecular classification to drive precision treatment strategies in primary Sj\\u00f6gren's syndrome.\",\n",
      "        \"matches_optimization/algorithm\": \"support vector machine (SVM)\",\n",
      "        \"matches_optimization/encoding\": \"Each 30- to 120-s paired recording was converted into a single bipolar LFP. The multitaper method was used to calculate a spectrogram of the LFP. using a 2-s window with 10% window steps, resulting in a 1-Hz frequency resolution. Time windows containing movement artifacts were visually identified and removed. The spectrogram was averaged over the remaining windows to produce a single power spectral density (PSD) for each paired\\nrecording. An additional feature set was created with phase-amplitude coupling (PAC).\",\n",
      "        \"matches_optimization/features\": \"The entire feature set including both spectral and PAC components contained 206 features.  Feature selection was performed. The lasso regularization technique with 10-fold cross-vali-\\ndation was used to perform feature selection through least-squares regression with a penalty on the size of the estimated coefficients. This procedure finds the combination of features that produces the minimum mean-square error (MSE). Lasso regularization was performed separately for the spectral and PAC feature sets.\",\n",
      "        \"matches_optimization/fitting\": \"Large number of features. Feature selection was performed to reduce the number of features used for the classificationto avoid overfitting.\",\n",
      "        \"matches_optimization/regularization\": \"yes: The lasso regularization technique with 10-fold cross-validation was used to perform feature selection through least-squares regression with a penalty on the size of the estimated coefficients\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/measure\": \"Sensitivity/specificity measures for each subject/class.\",\n",
      "        \"matches_evaluation/method\": \"10-fold cross-validation\",\n",
      "        \"matches_dataset/provenance\": \"669 paired recordings were made across 3 subjects. Data are divided in 4 classes of (276, 149, 157, 87 points each). Data source: experiment.\",\n",
      "        \"matches_dataset/splits\": \"90% of the data was used for training and the remaining 10% was used for testing.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305baf\",\n",
      "        \"publication_pmid\": \"34372798\",\n",
      "        \"publication_updated\": \"02/02/2022 10:53:38\",\n",
      "        \"publication_authors\": \"Li MX, Sun XM, Cheng WG, Ruan HJ, Liu K, Chen P, Xu HJ, Gao SG, Feng XS, Qi YJ\",\n",
      "        \"publication_journal\": \"BMC Cancer\",\n",
      "        \"publication_title\": \"Using a machine learning approach to identify key prognostic molecules for esophageal squamous cell carcinoma.\",\n",
      "        \"publication_doi\": \"10.1186/s12885-021-08647-1\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"7207b60b-e1a1-41bd-bc26-c3720ecbca51\",\n",
      "        \"shortid\": \"fv16isykca\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"02/02/2022 10:53:38\",\n",
      "        \"matches_publication/authors\": \"Li MX, Sun XM, Cheng WG, Ruan HJ, Liu K, Chen P, Xu HJ, Gao SG, Feng XS, Qi YJ\",\n",
      "        \"matches_publication/journal\": \"BMC Cancer\",\n",
      "        \"matches_publication/title\": \"Using a machine learning approach to identify key prognostic molecules for esophageal squamous cell carcinoma.\",\n",
      "        \"matches_optimization/algorithm\": \"Probabilistic machine learning algorithms like Na\\u00efve Bayes and Maximum Entropy.\",\n",
      "        \"matches_optimization/encoding\": \"Strings of text are tokenized and pre-filtered to select candidates.\",\n",
      "        \"matches_optimization/features\": \"4-5 features are indicated.\",\n",
      "        \"matches_optimization/parameters\": \"The parameters are estimated via hill climbing approaches (Improved Iterative Scaling (IIS), Generalized Iterative Scaling (GIS)) and Limited-Memory Variable Metric optimization (L-BFGS). The number of parameters is not reported\",\n",
      "        \"matches_model/availability\": \"The software system implementing NetiNeti can be accessed at http://namefinding.ubio.org.\",\n",
      "        \"matches_model/interpretability\": \"black box\",\n",
      "        \"matches_evaluation/comparison\": \"TaxonFinder and FAT tool.\",\n",
      "        \"matches_evaluation/confidence\": \"The recall for TaxonFinder is significantly lower compared to NetiNeti, while the precisions are comparable. . The FAT approach has lower precision and recall values compared to NetiNeti and TaxonFinder.\",\n",
      "        \"matches_evaluation/measure\": \"Precision and recall values.\",\n",
      "        \"matches_evaluation/method\": \"PubMed Central ids used for evaluation of NetiNeti.\",\n",
      "        \"matches_dataset/availability\": \"The American Seashell book and a list of PubMed Central ids used for evaluation of NetiNeti can be found at http://ubio.org/netinetifiles\",\n",
      "        \"matches_dataset/provenance\": \"Data source are databases.\",\n",
      "        \"matches_dataset/splits\": \"A total of about 40,000 positive examples together with another set of about 43,000\\nnegative examples were used to generate a training set of 83,000 examples for the two class labels.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bb0\",\n",
      "        \"publication_pmid\": \"33995917\",\n",
      "        \"publication_updated\": \"03/16/2022 12:48:49\",\n",
      "        \"publication_authors\": \"Dully V, Wilding TA, M\\u00fchlhaus T, Stoeck T\",\n",
      "        \"publication_journal\": \"Comput Struct Biotechnol J\",\n",
      "        \"publication_title\": \"Identifying the minimum amplicon sequence depth to adequately predict classes in eDNA-based marine biomonitoring using supervised machine learning.\",\n",
      "        \"publication_doi\": \"10.1016/j.csbj.2021.04.005\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"87a282cd-4534-4ee9-a07e-455260a89a6a\",\n",
      "        \"shortid\": \"kottgt7uak\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"03/16/2022 12:48:49\",\n",
      "        \"matches_publication/authors\": \"Dully V, Wilding TA, M\\u00fchlhaus T, Stoeck T\",\n",
      "        \"matches_publication/journal\": \"Comput Struct Biotechnol J\",\n",
      "        \"matches_publication/title\": \"Identifying the minimum amplicon sequence depth to adequately predict classes in eDNA-based marine biomonitoring using supervised machine learning.\",\n",
      "        \"matches_optimization/config\": \"http: //59.73.198.144/AFP_PSSM/\",\n",
      "        \"matches_optimization/encoding\": \"Evolutionary Information, Amino Acid and Dipeptide Composition, Chou\\u2019s Pseudo Amino acid Composition\",\n",
      "        \"matches_optimization/features\": \"400, PSSM-400 (composition of occurrences of each type of amino acid corresponding to each type of amino acids in protein sequence)\",\n",
      "        \"matches_optimization/meta\": \"4 SVM models based on amino acids composition, dipeptides composition,\\nChou\\u2019s PseAAC and PSSM-400\",\n",
      "        \"matches_optimization/parameters\": \"p=2, regularization parameter C and the kernel width parameter \\u03b3.\",\n",
      "        \"matches_model/duration\": \"20 seconds for 500 amino acids sequences\",\n",
      "        \"matches_evaluation/comparison\": \"comparison with work from 10.1016/j.jtbi.2010.10.037. this study obtains accuracy\",\n",
      "        \"matches_evaluation/confidence\": \"Model's accuracy\",\n",
      "        \"matches_evaluation/measure\": \"sensitivity (S_n), specificity (S_p), and accuracy (Acc), ROC\",\n",
      "        \"matches_evaluation/method\": \"Ten-fold cross validation & independent testing dataset\",\n",
      "        \"matches_dataset/provenance\": \"source: 10.1016/j.jtbi.2010.10.037\\n481 antifreeze proteins and 9493 non-antifreeze proteins\",\n",
      "        \"matches_dataset/redundancy\": \"To get rid of redundancy and homology bias,\\nthe sequences with \\u226540% sequence similarity have been removed using program CD-HIT\",\n",
      "        \"matches_dataset/splits\": \"training dataset contains 300 antifreeze proteins randomly selected from the 481 antifreeze proteins and 300 non-antifreeze proteins randomly selected from the 9493 non-antifreeze proteins. The test dataset contains the remaining 181 antifreeze proteins and 9193 non-antifreeze proteins.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bb1\",\n",
      "        \"publication_pmid\": \"34093642\",\n",
      "        \"publication_updated\": \"03/07/2022 11:16:44\",\n",
      "        \"publication_authors\": \"Sardar R, Sharma A, Gupta D\",\n",
      "        \"publication_journal\": \"Front Genet\",\n",
      "        \"publication_title\": \"Machine Learning Assisted Prediction of Prognostic Biomarkers Associated With COVID-19, Using Clinical and Proteomics Data.\",\n",
      "        \"publication_doi\": \"10.3389/fgene.2021.636441\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"dcfa96ac-4881-4efa-baf5-2907ca1a48a8\",\n",
      "        \"shortid\": \"3rafrbsxow\",\n",
      "        \"score\": 0.95,\n",
      "        \"matches_publication/updated\": \"03/07/2022 11:16:44\",\n",
      "        \"matches_publication/authors\": \"Sardar R, Sharma A, Gupta D\",\n",
      "        \"matches_publication/journal\": \"Front Genet\",\n",
      "        \"matches_publication/title\": \"Machine Learning Assisted Prediction of Prognostic Biomarkers Associated With COVID-19, Using Clinical and Proteomics Data.\",\n",
      "        \"matches_optimization/algorithm\": \"Support Vector Machine (SVM) classification with RBF kernel\",\n",
      "        \"matches_optimization/config\": \"Method and data are available to the public upon request.\",\n",
      "        \"matches_optimization/encoding\": \"Calculated amino acid composition in terms of different secondary structures strand (E), helix (H) and coil (C), and solvent accessibility states (buried (B) and exposed (E)), with a method called SSE-ACC. The value of each dimension is calculated by\\n\\nf_i^j=  (N_i^j)/L\\n\\nwhere j = {H, E, C}, N_i^j is the frequency of amino acid i in secondary structure element j, and L is the length of the sequence. The value is calculated similarly for solvent accessibility states.\\n\",\n",
      "        \"matches_optimization/features\": \"100 features. The first 60 features are used to describe the frequency of each amino acid in each of the three possible secondary structure elements. The last 40 dimensions represent the frequency of each amino acid having each of the two possible solvent accessibility states.\",\n",
      "        \"matches_optimization/fitting\": \"Single input for SVM method. Optimization through grid search.\",\n",
      "        \"matches_optimization/parameters\": \"The parameters used for the redundant data set are g = 0.25, C = 4. The parameters used for the non-redundant data set are g =0.5, C = 4. Grid search was used for parameter optimization.\",\n",
      "        \"matches_optimization/regularization\": \"Yes, by setting the regularization parameter C=4. L2 regularization adds an L2 penalty equal to the square of the magnitude of coefficients.\",\n",
      "        \"matches_model/availability\": \"Method and data are available to the public upon request.\",\n",
      "        \"matches_model/duration\": \"The whole computation process took several ten hours. All computation tasks were conducted on a Pentium IV desktop PC with dual CPU (2.8 GHz) and 2 GB RAM.\",\n",
      "        \"matches_model/interpretability\": \"Black box. Not investigating feature importance.\",\n",
      "        \"matches_model/output\": \"Classification, i.e. binary predictions based on the probability of a predicted positive case being p > 0.01.\",\n",
      "        \"matches_evaluation/availability\": \"Method and data are available to the public upon request.\",\n",
      "        \"matches_evaluation/comparison\": \"EffectiveT3, T3SS prediction. Known classifiers for T3SS effector prediction. SVC with cross-validation but with different data encoding.\",\n",
      "        \"matches_evaluation/confidence\": \"Only the non-redundant data were used for the comparisons. Very low precision from EffectiveT3 (recall of 72.2% and precision of 17.9%) and T3SS prediction (recall of 83.3% and precision of 24%) due to being developed in less imbalanced and non-realistic training sets. For different data encoding methods, the recall and precision of effectors were 55.6% and 84.5%, respectively, which were over 5% lower than those of the proposed SSE-ACC method.\",\n",
      "        \"matches_evaluation/measure\": \"Accuracy, Recall, Precision.\",\n",
      "        \"matches_evaluation/method\": \"5-fold cross-validation. Independent dataset. A single predicted positive case of the independent dataset was validated through wet-lab experiments.\",\n",
      "        \"matches_dataset/availability\": \"Method and data are available to the public upon request.\",\n",
      "        \"matches_dataset/provenance\": \"Redundant dataset of type III effectors. Positive cases were identified type III effector (T3SE) proteins from Pseudomonas syringae (P. syringae) pv. tomato strain DC3000, P. syringae pv. syringae strain B728a and P. syringae pv. phaseolicola strain 1448A. Negative cases were all the proteins extracted from the genome of P. syringae pv. tomato strain DC3000, excluding proteins related to type III secretion system (T3SS) and hypothetical proteins. 4,062 proteins total. Npos = 283 protein sequences. Nneg = 3,779 protein sequences. \\nNon-redundant dataset of type III effectors. Removal of all homologous proteins (redundant), with sequence similarity greater than 60% from redundant dataset of type III effectors. 3,532 proteins total. Npos = 108 protein sequences. Nneg = 3,424 protein sequences.\\nOnly the first 100 N-terminal residues were used in both datasets. They were not previously used.\",\n",
      "        \"matches_dataset/redundancy\": \"Homology present within positive cases. Possibility of overestimating negative cases due to the presence of uncharacterized T3SE proteins within them.\",\n",
      "        \"matches_dataset/splits\": \"5-fold cross validation was performed. No information about the sizes of training and testing data sets.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63516fedb9c880af1f305bb8\",\n",
      "        \"publication_pmid\": \"34258160\",\n",
      "        \"publication_updated\": \"03/19/2022 17:28:38\",\n",
      "        \"publication_authors\": \"Liu QX, Zhou D, Han TC, Lu X, Hou B, Li MY, Yang GX, Li QY, Pei ZH, Hong YY, Zhang YX, Chen WZ, Zheng H, He J, Dai JG\",\n",
      "        \"publication_journal\": \"Adv Sci (Weinh)\",\n",
      "        \"publication_title\": \"A Noninvasive Multianalytical Approach for Lung Cancer Diagnosis of Patients with Pulmonary Nodules.\",\n",
      "        \"publication_doi\": \"10.1002/advs.202100104\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"public\": true,\n",
      "        \"created\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"updated\": \"2022-09-01T15:16:05.446Z\",\n",
      "        \"uuid\": \"5ad4302c-53ed-4207-b229-6528206e2f0b\",\n",
      "        \"shortid\": \"4ord5sdl9n\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_publication/updated\": \"03/19/2022 17:28:38\",\n",
      "        \"matches_publication/authors\": \"Liu QX, Zhou D, Han TC, Lu X, Hou B, Li MY, Yang GX, Li QY, Pei ZH, Hong YY, Zhang YX, Chen WZ, Zheng H, He J, Dai JG\",\n",
      "        \"matches_publication/journal\": \"Adv Sci (Weinh)\",\n",
      "        \"matches_publication/title\": \"A Noninvasive Multianalytical Approach for Lung Cancer Diagnosis of Patients with Pulmonary Nodules.\",\n",
      "        \"matches_optimization/algorithm\": \"KStar (K-NN ?), Not novel, Multilayer perceptron, C4.5\",\n",
      "        \"matches_optimization/encoding\": \"Gene expression data\",\n",
      "        \"matches_optimization/features\": \"No feature selection.\",\n",
      "        \"matches_optimization/parameters\": \"Depends on algorithms tested.\",\n",
      "        \"matches_model/interpretability\": \"Black box\",\n",
      "        \"matches_evaluation/comparison\": \"KStar, comparison vs. MLP, C4.5\",\n",
      "        \"matches_evaluation/measure\": \"Rappel/Precision, AUR\",\n",
      "        \"matches_evaluation/method\": \"Cross validation\",\n",
      "        \"matches_dataset/availability\": \"Yes but need to contact the authors apparently\",\n",
      "        \"matches_dataset/provenance\": \"Yes,  Prof. Connie Cepko at Harvard Medical School, claimed publicly available\",\n",
      "        \"matches_dataset/redundancy\": \"Yes, cross-validation\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6634f332ded6e7820f74a19e\",\n",
      "        \"shortid\": \"lf0lzc5ed0\",\n",
      "        \"uuid\": \"68023bc8-b676-4d1f-a508-977183349803\",\n",
      "        \"created\": \"2024-05-03T14:22:42.850Z\",\n",
      "        \"updated\": \"2024-05-03T14:22:42.850Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"34290238\",\n",
      "        \"publication_authors\": \"Gang Hu, Akila Katuwawala, Kui Wang, Zhonghua Wu, Sina Ghadermarzi, Jianzhao Gao & Lukasz Kurgan\",\n",
      "        \"publication_journal\": \"Nature Communications\",\n",
      "        \"publication_title\": \"flDPnn: Accurate intrinsic disorder prediction with putative propensities of disorder functions\",\n",
      "        \"publication_doi\": \"10.1038/s41467-021-24773-7\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"score\": 0.9,\n",
      "        \"matches_evaluation/comparison\": \"The model was compared to other disorder prediction methods, such as IUPred, Espritz, and Spot-Disorder.\",\n",
      "        \"matches_evaluation/confidence\": \"Confidence intervals were not reported. The results indicate superior performance compared to other similar methods and software.\",\n",
      "        \"matches_evaluation/measure\": \"F1-score, MCC, and ROC-AUC are reported as performance metrics.\",\n",
      "        \"matches_evaluation/method\": \"The evaluation is based on the performance of the model on the test dataset.\",\n",
      "        \"matches_optimization/algorithm\": \"Deep feedforward neural network. \\nIt is not a novel algorithm.\",\n",
      "        \"matches_optimization/config\": \"Authors released the code for flDPnn at https://gitlab.com/sina.ghadermarzi/fldpnn.\",\n",
      "        \"matches_optimization/encoding\": \"A protein sequence is analyzed by other previously mentioned algorithms to create sequence profiles, the sequences profiles are encoded and passed to the main ML models created by the authors.\",\n",
      "        \"matches_optimization/features\": \"The profiles are encoded into three feature sets.\",\n",
      "        \"matches_optimization/meta\": \"Multiple predictors are used to generate sequence profiles that are later fed into the ML model.\\nIUPred, PSIPRED, DisoRDPbind, DFLpred, fMoRFpred.\",\n",
      "        \"matches_optimization/parameters\": \"The exact number of parameters not reported.\\nAuthors empirically selected the hyper-parameters including number of layers and the number of nodes in the hidden layer by a grid search.\",\n",
      "        \"matches_optimization/regularization\": \"Authors clustered the data points using CD-HIT (sequence similarity clustering technique) to prevent overfitting.\",\n",
      "        \"matches_model/availability\": \"Authors released the code for flDPnn at https://gitlab.com/sina.ghadermarzi/fldpnn.\",\n",
      "        \"matches_model/duration\": \"5 to 10 s per protein.\",\n",
      "        \"matches_model/interpretability\": \"No mention was made on interpretability. The models seems to be a black box.\",\n",
      "        \"matches_model/output\": \"It is a classifier.\",\n",
      "        \"matches_dataset/availability\": \"Not splits, but the source data was collected by parsing the publicly available DisProt repository (https://www.disprot.org/).\",\n",
      "        \"matches_dataset/provenance\": \"745 experimentally annotated proteins from the DisProt 7.0 database.\\nDisProt has been used frequently by other communities and publications in the field of disorder prediction.\",\n",
      "        \"matches_dataset/redundancy\": \"Data split was done randomly.\\nTest dataset was reduced to 176 proteins that share <25% sequence similarity to the training proteins.\",\n",
      "        \"matches_dataset/splits\": \"Training dataset: 445 proteins\\nValidation dataset: 100 proteins\\nTest dataset: 200 proteins\",\n",
      "        \"matches_publication/authors\": \"Gang Hu, Akila Katuwawala, Kui Wang, Zhonghua Wu, Sina Ghadermarzi, Jianzhao Gao & Lukasz Kurgan\",\n",
      "        \"matches_publication/journal\": \"Nature Communications\",\n",
      "        \"matches_publication/title\": \"flDPnn: Accurate intrinsic disorder prediction with putative propensities of disorder functions\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"664b2a16b30933003cc21843\",\n",
      "        \"shortid\": \"y38upwlhxf\",\n",
      "        \"uuid\": \"9ef704d3-b4f4-461f-aa23-03871338dc04\",\n",
      "        \"created\": \"2024-05-20T10:46:46.631Z\",\n",
      "        \"updated\": \"2024-05-20T10:46:46.631Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"34706730\",\n",
      "        \"publication_authors\": \"Jiao S, Zou Q, Guo H, Shi L. \",\n",
      "        \"publication_journal\": \"Journal of Translational Medicine\",\n",
      "        \"publication_title\": \"iTTCA-RF: a random forest predictor for tumor T cell antigens\",\n",
      "        \"publication_doi\": \"10.1186/s12967-021-03084-x\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"score\": 0.95,\n",
      "        \"matches_evaluation/availability\": \"Not available\",\n",
      "        \"matches_evaluation/comparison\": \"The Authors compared iTTCA-RF with iTTCA-Hybrid (published by Charoenkwan P, et al (2020) Anal Biochem. 599:113747, PMID: 32333902) on the same training andd testing datasets.\\nThe BACC, AUC, Sn, Sp and MCC metrics of the Authors' model on the training set were between 3.6% and 9.0% higher than those of iTTCA-Hybrid, respectively. The same metrics on the independent test were between 0.8% and 4.6% higher.  \",\n",
      "        \"matches_evaluation/confidence\": \"No confidence intervals are reported for any performance measure. Therefore, the statistic significance of the Author's claim can not be calculated.\",\n",
      "        \"matches_evaluation/measure\": \"Balanced Accuracy, AUC, Specifity, Sensitivity, Matthews Correlation Coefficient. \",\n",
      "        \"matches_evaluation/method\": \"Independent dataset (n=197 data points, of which 122 positive, 75 negative). \",\n",
      "        \"matches_optimization/algorithm\": \"The best performing machine learning algorithm was searched among the following 6 standard classifers: random forest (RF), support vector machine (SVM), adaboost (AB), logistic regression (LR), bagging, and gradient boosting machine (GBM), all of them in the implementation of the scikit-learn package.  The best performer turned out to be Random Forest (RF).\",\n",
      "        \"matches_optimization/config\": \"The training and testing datasets are freely accessible at http://lab.malab.cn/~acy/iTTCA.\",\n",
      "        \"matches_optimization/encoding\": \"The protein sequences (T-cell epitopes) were preliminarily encoded using 4 kinds of feature extraction methods: global protein sequence descriptors (GPSD), grouped amino acid and peptide composition (GAAPC), pseudo amino acid composition (PAAC), and adaptive skip dipeptide composition (ASDC).   The iLearn tool package was used to generate the 4 type of sequence features.\",\n",
      "        \"matches_optimization/features\": \"The following two-step feature selection technique to search for the optimal feature subset was applied:  First, the maximum relevance maximum distance (MRMD) algorithm was used to analyze the feature importance of the involved vectors. Then, after application of the incremental feature selection (IFS) strategy, different feature subsets were generated for optimization for each considered classifcation algorithms.      The best performance model was finally constructed using the top 263 selected features.\",\n",
      "        \"matches_optimization/fitting\": \"The number of features was 263, at risk of overfitting. The somewhat lower performance metrics on the test set, relative to the training set, could indicate some overfitting in the model optimization procedure.   The Author's did not claim to have ruled out overfitting, but they have taken some preventive measures, namely the SMOTE-Tomek for balancing the numerosity of the training positive and negative sets and an accurate feature selection strategies.\",\n",
      "        \"matches_optimization/parameters\": \"The number of paramenters was the standard one for each of the 6 classifiers. The hyper-parameters were optimized using grid search, with the search ranges presented in the Supplements. \",\n",
      "        \"matches_optimization/regularization\": \"As mentioned, the Authors have taken some preventive measures: the SMOTE-Tomek for balancing the numerosity of the training positive and negative sets and an accurate feature selection strategies.\",\n",
      "        \"matches_model/availability\": \"The online prediction server was made freely accessible at http://lab.malab.cn/~acy/iTTCA.   All test classifiers were applied as in the Scikit-learn implementation.\",\n",
      "        \"matches_model/duration\": \"Not reported.\",\n",
      "        \"matches_model/interpretability\": \"The MRMD feature selection method selected a subset of features that were strongly correlated with the class label and have low redundancy between features.  However, no analysis of a possible interpretability have been reported in the publication.    \",\n",
      "        \"matches_model/output\": \"Binary classification (TTCA or not TTCA) (TTCA = tumor T cell antigens).  \",\n",
      "        \"matches_dataset/availability\": \"\\\"Availability of data and materials\\nPublicly available datasets were analyzed in this study. This data can be found here: http://lab.malab.cn/~acy/iTTCA.\\\"\",\n",
      "        \"matches_dataset/provenance\": \"A non-redundant dataset of 592 tumor T cell antigens (positive samples, ca 60%) and 393 tumor T cell antigens (negative samples, ca. 40%) was used (n=985).  It was an already existing dataset (generated and used in Charoenkwan P, et al (2020) Anal Biochem. 599:113747, PMID: 32333902).  \\nGiven that 80% of the samples were randomly selected as the training dataset, the latter had 788 data points (470 positive, 318 negative),\",\n",
      "        \"matches_dataset/redundancy\": \"The Authors state that the dataset from (Charoenkwan P, et al (2020) Anal Biochem. 599:113747, PMID: 32333902) was not redundant.  However, the latter Authors, in describing the building of the datatset, only state that \\\"Duplicate peptides were removed\\\", and do not mention any analysis of degree of pairwise identity.\",\n",
      "        \"matches_dataset/splits\": \"80% of the 985 samples were randomly selected as the training dataset and the remaining 20% of samples were taken as the independent test dataset.          Tenfold cross-validation of the training set was used during models optimization.      To balance the positive and negative samples in the training set, the Authors used the integrated resampling technique SMOTE-Tomek, a combination of over- and under-sampling methods: synthetic minority over-sampling technique (SMOTE) (Chawla NV, et al. (2002) J Artif Intell Res.16:321\\u201357) and Tomek\\u2019s links (Tomek) (Tomek I. Two modifcations of CNN. (1976) IEEE Trans Syst Man Cybern.SMC6(11):769\\u201372.). Such hybrid-sampling approach, according to the Authors, can simultaneously avoid the shortcomings of overftting and loss of key information caused by SMOTE and Tomek, respectively.\",\n",
      "        \"matches_publication/authors\": \"Jiao S, Zou Q, Guo H, Shi L. \",\n",
      "        \"matches_publication/journal\": \"Journal of Translational Medicine\",\n",
      "        \"matches_publication/title\": \"iTTCA-RF: a random forest predictor for tumor T cell antigens\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"664b2a4db30933003cc21847\",\n",
      "        \"shortid\": \"t7m3dsf9ni\",\n",
      "        \"uuid\": \"85fd4f8b-595f-4be3-8d57-2d351b44e1ce\",\n",
      "        \"created\": \"2024-05-20T10:47:41.132Z\",\n",
      "        \"updated\": \"2024-05-20T10:47:41.132Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"33584803\",\n",
      "        \"publication_authors\": \"Yu X, Pan X, Zhang S, Zhang YH, Chen L, Wan S, Huang T, Cai YD.\",\n",
      "        \"publication_journal\": \"Frontiers in Genetics\",\n",
      "        \"publication_title\": \"Identification of Gene Signatures and Expression Patterns During Epithelial-to-Mesenchymal Transition From Single-Cell Expression Atlas\",\n",
      "        \"publication_doi\": \"10.3389/fgene.2020.605012\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"score\": 0.95,\n",
      "        \"matches_evaluation/availability\": \"Not available\",\n",
      "        \"matches_evaluation/comparison\": \"No comparisons.\",\n",
      "        \"matches_evaluation/confidence\": \"No confidence intervals for MCC were reported.\",\n",
      "        \"matches_evaluation/measure\": \"MCC (Matthews Correlation Coefficient).\",\n",
      "        \"matches_evaluation/method\": \"Cross-validation.   There were no independent datasets or novel experiments.\",\n",
      "        \"matches_optimization/algorithm\": \"Standard Random Forest (RF) and Support Vector Machine (SVM) algorithms were used.   In addition, repeated incremental pruning to produce error reduction (RIPPER) was applied to produce classification rules for classifying samples from different TCs.  \",\n",
      "        \"matches_optimization/config\": \"Not reported.\",\n",
      "        \"matches_optimization/encoding\": \"Each TC was encoded with the expression levels of 49,585 genes.\",\n",
      "        \"matches_optimization/features\": \"\\nBoruta feature selection (Kursa and Rudnicki (2010) J. Statist. Softw. Artic. 36, 1\\u201313) and minimum redundancy maximum relevance (mRMR) method (Peng et al (2005) IEEE Transact. Patt. Anal. Mach. Intel. 27, 1226\\u20131238) were used, to evaluate the importance of each feature. Key features were then selected, and fed into the incremental feature selection (IFS) with supervised classifiers to identify the optimal gene signatures for screening different TCs.   The IFS was run with SVM, RIPPER, and RF, respectively.   The optimal numbers of features turned out to be 169 (SVM), 159 (RF), 38 (RIPPER).\\n\",\n",
      "        \"matches_optimization/fitting\": \"After SMOTE application, the number of datapoints was 624.    The Authors first used Boruta to select relevant features, resulting in 237 features (genes). After mRMR and IFS, the subsets of features with the optimal classification performance were obtained.  The numbers of features were 169 (SVM), 159 (RF), 38 (RIPPER).     Given the very high Accuracy (>= 0.979) and MCC (>= 0.934) values, obtained with all three classifiers, the methods seem to be at risk of overfitting.   While the high number of features could be a reason for the probable overfitting in SVM and RF, the RIPPER model might eventually have had different sources of overfitting.      \",\n",
      "        \"matches_optimization/parameters\": \"The authors do not mention parameters numbers different from standard.  \",\n",
      "        \"matches_optimization/regularization\": \"Not reported.\",\n",
      "        \"matches_model/availability\": \"The algorithms and software packages used in this publication were all standard or already published.\",\n",
      "        \"matches_model/duration\": \"No reported.\",\n",
      "        \"matches_model/interpretability\": \"According to the Authors, \\\"SVM and RF are \\u201cblackbox\\u201d methods. [...] RIPPER can generate interpretable classification rules.\\\"    Ante-hoc techniques for transparency in SVM and RF were not applied, since feature selection was performed in a completely automatic manner.  Post-hoc analysis was partially interpretable, since several of the selected features were genes already known to be involved in the Epithelial-to-Mesenchymal Transition.  In addition, GO term and KEGG pathway enrichment results were consistent with the known differences between epithelial and mesenchymal cells.\",\n",
      "        \"matches_model/output\": \"Binary classification (the optimal set of genes (features) should be able to clearly separate Epithelial from Mesenchymal cell status).  \",\n",
      "        \"matches_dataset/availability\": \"\\\"Data Availability Statement -- Publicly available datasets were analyzed in this study. This data can be found here: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE110357.\\\"\",\n",
      "        \"matches_dataset/provenance\": \"The datasets were obtained from the study of Pastushenko et al (2018) at https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE110357. The number of data points (mouse Tumor Cells (TCs), each one with single-cell gene expression profiles) was 383.  The datapoints of the 1\\u00b0 dataset were 71 epithelial YFP + Epcam + skin squamous cell carcinoma TCs and the datapoints of the 2\\u00b0 dataset were 312 mesenchymal-like YFP + Epcam \\u2212 skin squamous cell carcinoma TCs.   Epithelial YFP + Epcam + TCs and mesenchymal-like YFP + Epcam \\u2212 TCs represent different EMT (Epithelial-to-Mesenchymal Transition states.   Gene expression differences may reveal the cascade mechanisms of tumor migration and invasion.\",\n",
      "        \"matches_dataset/redundancy\": \"Not applicable.\",\n",
      "        \"matches_dataset/splits\": \"10 fold cross validation.   To balance the two datasets, so that the numbers of epithelial tumor and mesenchymal TCs were equal, the tool \\u201cSMOTE\\u201d (Synthetic Minority Over-samplingTEchnique) in Weka was used, to generate new samples in the class of epithelial TC.   \",\n",
      "        \"matches_publication/authors\": \"Yu X, Pan X, Zhang S, Zhang YH, Chen L, Wan S, Huang T, Cai YD.\",\n",
      "        \"matches_publication/journal\": \"Frontiers in Genetics\",\n",
      "        \"matches_publication/title\": \"Identification of Gene Signatures and Expression Patterns During Epithelial-to-Mesenchymal Transition From Single-Cell Expression Atlas\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6677746e37ea6fa797a6c4a5\",\n",
      "        \"shortid\": \"0kf7cnsa5t\",\n",
      "        \"uuid\": \"341f3bec-3507-4c4b-8d19-c88ba8867202\",\n",
      "        \"created\": \"2024-06-23T01:03:42.235Z\",\n",
      "        \"updated\": \"2024-06-23T01:03:42.235Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"34662334\",\n",
      "        \"publication_authors\": \"Nicolas Arning, Samuel K. Sheppard, Sion Bayliss, David A. Clifton, and Daniel J. Wilson\",\n",
      "        \"publication_journal\": \"PLOS Genetics\",\n",
      "        \"publication_title\": \"Machine learning to predict the source of campylobacteriosis using whole genome data\",\n",
      "        \"publication_doi\": \"10.1371/journal.pgen.1009436\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"score\": 0.95,\n",
      "        \"matches_evaluation/availability\": \"No - not available from the text or from the GitHub.\",\n",
      "        \"matches_evaluation/comparison\": \"The performance of the machine learning models generated in the study for were compared to the most commonly used source attribution method. This method is called 'iSource' and relies on multi-locus sequence typing (MLST) data. \\nThe comparison against this method helps establish a comparison baseline for assessing the improvement offered by the new machine learning models developed.\\n\\nThe study does perform comparisons between the 14x different machine learning models generated using various data types (MLST, cgMLST, WGS). This helps identify which models perform best with different levels of genomic information. Some of these models could be considered as simpler baselines (k-nearest neighbour) to the more complex deep learning models employed (Recurrent Neural Network.).\",\n",
      "        \"matches_evaluation/confidence\": \"Confidence intervals and statistical significance testing - not very prominent or clear in the main text. For the accuracy, the authors does report ' 81.3\\u00b12%/84.6\\u00b10% accuracy' confidence intervals for the cgMLST data used with the XGBoost classifier model. Other model accuracy confidence intervals are noted in Fig 1.\",\n",
      "        \"matches_evaluation/measure\": \"Several performance metrics were used to evaluate the machine learning models in the study:\\n\\n-Precision (positive predictive value) \\n-Recall (sensitivity)\\n-F1\\n-Negative predictive value\\n-Specificity \\n-Speed\\n-Misclassification Matrix\\n\\nHowever some key performance evaluation metrics were not noted such as area under the ROC Curve (AUC). Additionally, while in the text it states these perfomance measures were taken, it appears only a subset of these are actually clearly detailed and not for all models.\\n\\nMost of the performance measure metrics are detailed in Fig 2. and Fig 3.\",\n",
      "        \"matches_evaluation/method\": \"Evaluation methods used include:\\n-Five-fold cross-validation\\n-Comparison to existing methods\\n-Performance of the models evaluated on different data types (core genome data vs whole genome sequence data)\",\n",
      "        \"matches_optimization/algorithm\": \"14x total ML algorithms were used in the study, these are classified as:\\n-Simple learners (6x)\\n-Ensemble learners (3x)\\n-Deep learners (5x)\\n\\nFull breakdown below:\\n\\nSimple learners\\n1. K-nearest neighbour\\n2. Ridge Regression\\n3. SVM (Linear Kernel)\\n4. SVM (RBF Kernel)\\n5. Naive Bayesian\\n6. Decision tree\\n\\nEnsemble learners\\n7. Random forest\\n8. Extra-randomised forest\\n9. XGBoost\\n\\nDeep learners\\n10. 1D-Convolutional NN\\n11. Shallow Dense NN\\n12. Deep Dense NN\\n13. Recurrent NN\\n14. LSTM NN\\n\\nThese are fully detailed in Fig 1. \",\n",
      "        \"matches_optimization/config\": \"Not clear, standard deposition of one of the models (XGboost) in GitHub relating to the paper but not clear if with corresponding hyperparameter configurations, optimization schedule, model files and optimization parameters. These are not well described in the text beyond some hyperparameters.\",\n",
      "        \"matches_optimization/encoding\": \"Several encoding methods were used and varied depending on the data source (MLST vs. WGS). Missing values were handled differently for each data type. Nucleotides of the data were one-hot encoded and k-mers were used to capture sequence information.\",\n",
      "        \"matches_optimization/features\": \"Number of features (f) used as input is 100,000 (ostensibly for all 14x models).\\n\\nFeature selection was perfomed:\\n-Variance Threshold: reduced number of k-mers by discarding those present/absent in over 99% of samples.\\n-Chi-Square Test: evaluated dependence of source labels on individual k-mers using the training data, and from this the top 100,000 k-mers with the highest scores were chosen.\",\n",
      "        \"matches_optimization/fitting\": \"p is unknown in relation to f for fit evaluation. The study used early stopping and 5-fold cross-validation approaches to avoid overfitting.  \",\n",
      "        \"matches_optimization/parameters\": \"Number of parameters not clearly detailed in text for the 14x models generated.\",\n",
      "        \"matches_optimization/regularization\": \"Early stopping: was used during the training. Training was run for 500 generations with early stopping after 50 generations.  No additional validation set clearly noted in text.\",\n",
      "        \"matches_model/availability\": \"Somewhat available - the ML model code repository for the publication is named 'aiSource' and can be found from: https://github.com/narning1992/aiSource. The GitHub contains a downlaodable Python script. No container provided or other run methods clearly noted/linked. Further, it is unclear if all 14x models are available. It seems that only the XGboost model is in the repository.\",\n",
      "        \"matches_model/duration\": \"Unclear for which model, but like the XGboost one, some information provided on execution time:\\n\\n-Possible to run on well provisioned desktop, no GPU explicitly needed. \\n-The prediction detailed in the paper took 892 milliseconds on a Dell OptiPlex 7060 desktop using ten threads on an Intel Core i7-8700 CPU and 16 GB RAM.\\n\\nHowever, all 14x models no clear breakdown of training or standard predicition compute needs.\",\n",
      "        \"matches_model/interpretability\": \"Poor interpretablity of the 14x models - largely black boxes. Exact dataset componenets used are available and clearly described in a machine actionable TSV. Data stored in an open database and accessible. However, for the GitHub linked it is not clear if there are all 14x ML model codes available on GitHub and linked from the paper, no docker containers either for easy redployment. The GitHub seems to only hold the code of the XGboost model generated in the stufy and none of the 13x others, this makes the models black boxes. Paraemeters for the models not described and number of models in the text make the paper very complex to hone in on the specific models or their exact info points. Some machine learning interpretability aspects well covered and considered but the information on model optimisations is poor overall. \",\n",
      "        \"matches_dataset/availability\": \"The data used is detailed in supplementary file 'S1 Table.'. Table contains all samples used in this study and their corresponding PubMLST accession IDs, sequence types, clonal complexes, source labels, predicted labels, generalist index, country of isolation, year of sampling, Campylobacter species and whether they have been used in either training or testing the machine learner.\\nhttps://doi.org/10.1371/journal.pgen.1009436.s001\\n\\nTable is also available on Figshare: https://figshare.com/articles/dataset/Table_containing_all_samples_used_in_this_study_and_their_corresponding_PubMLST_accession_IDs_sequence_types_clonal_complexes_source_labels_predicted_labels_generalist_index_country_of_isolation_year_of_sampling_Campylobacter_species_and_wh/16827740\\n\\nThe data itself is hosted in the publicly available open access database: https://pubmlst.org/.\",\n",
      "        \"matches_dataset/provenance\": \"Data source: database - PubMLST, databases for molecular typing\\nand microbial genome diversity.\\n\\nData type: DNA - genomic data.\\n\\nTotal data points: 5,799 isolate genomes from C. jejuni and C. coli genomes. These were from various source experiments and host species. Genome source species distribution:\\n-Chicken: 4147\\n-Cattle: 716\\n-Sheep: 584\\n-Bird: 212\\n-Environment: 140 \\n\\nNot a community recognised data set, this is a novel dataset composed of publicly available data from an open database for the ML models generation in this study.\",\n",
      "        \"matches_dataset/redundancy\": \"Data sets were split at a ratio of:\\n-Training: 75%\\n-Testing: 25%\\n\\nThe test and training sets were kept independent for the model generation based on text description.\",\n",
      "        \"matches_dataset/splits\": \"Of the total dataset 5,799 data points, these were divided into training (75% = 4,349 approx) and testing (25% = 1,450 approx) sets.\\n\\nThe data corresponded to 3x designated classess:\\n-MLST sequencing type \\n-MLST clonal complex \\n-MLST core genome \\n\\nFor the distributions the authors used phylogeny-aware sorting, wherein all members of one sequencing type were sorted entirely into either training or testing sets. This is detailed in S1 Table.\\n\\nNo separate validation set used as the model is evaluated using five-fold cross-validation with the dataset detailed.  \",\n",
      "        \"matches_publication/authors\": \"Nicolas Arning, Samuel K. Sheppard, Sion Bayliss, David A. Clifton, and Daniel J. Wilson\",\n",
      "        \"matches_publication/journal\": \"PLOS Genetics\",\n",
      "        \"matches_publication/title\": \"Machine learning to predict the source of campylobacteriosis using whole genome data\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"667846cb37ea6fa797a6c4b0\",\n",
      "        \"shortid\": \"3ahkdhcjev\",\n",
      "        \"uuid\": \"725073a0-1dc7-4be3-b693-04fd39944947\",\n",
      "        \"created\": \"2024-06-23T16:01:15.774Z\",\n",
      "        \"updated\": \"2024-06-23T16:01:15.774Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"34104645\",\n",
      "        \"publication_authors\": \"Yan Liu, Hui Geng, Bide Duan, Xiuzhi Yang, Airong Ma, and Xiaoyan Ding\",\n",
      "        \"publication_journal\": \"BioMed Research International\",\n",
      "        \"publication_title\": \"Identification of Diagnostic CpG Signatures in Patients with Gestational Diabetes Mellitus via Epigenome-Wide Association Study Integrated with Machine Learning\",\n",
      "        \"publication_doi\": \"10.1155/2021/1984690\",\n",
      "        \"publication_year\": \"2021\",\n",
      "        \"score\": 0.95,\n",
      "        \"matches_evaluation/availability\": \"No \",\n",
      "        \"matches_evaluation/comparison\": \"No - no clear indication of comparison to other methods using benchmark datasets. Authors did note this was a novel usage of SVM for this classification task meaning there may not have been other methods to compare to.\",\n",
      "        \"matches_evaluation/confidence\": \"No confidence intervals noted in the text related to the SVM model performance.\",\n",
      "        \"matches_evaluation/measure\": \"Limited performance measures reported in the text.\\n\\nArea Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) was used as the primary performance metric for the SVM model in the GDM study.\\n\\nReported Values: AUC values for three datasets:\\n-Training Set (GSE88929): AUC = 0.8138\\n-Testing Set (GSE88929): AUC = 0.7576\\n-Independent Validation Set (GSE102177): AUC = 0.6667\\n\\nAdditional performance measure metrics like accuracy, precision, recall, or F1-score could also be used and are absent from the text/related files.\",\n",
      "        \"matches_evaluation/method\": \"Independent dataset used to validate the model. This was the GSE102177 dataset kept independent for model evaluation and contained 18 samples and 18 controls. \",\n",
      "        \"matches_optimization/algorithm\": \"Support vector machine (SVM) ML algorithm - this is not a new algorithm.\\n\\nWhy chosen: \\n-Previous SVM model usage success for prognosis and diagnosis of disease, such as diabetes mellitus.\\n-Previous successful use and application of SVMs for GDM research.\\n-Novelty of usage for CpG methylation biomarkers.\",\n",
      "        \"matches_optimization/config\": \"No - no configuration available. Little info in text on these model optimisation info points.\",\n",
      "        \"matches_optimization/encoding\": \"No clear information of how the SVM input data was encoded. \\u03b2-values of CpG sites from the data seem to have been used but no further information on how these were encoded.\",\n",
      "        \"matches_optimization/features\": \"Input features, (f) = 6 \\n\\n\\u03b2-values of CpG sites used as features: text notes using the \\u03b2-values of 6 CpG sites for model development. These \\u03b2-values directly represent the features that were used in the model for classification.\\n\\nYes: feature selection was performed to determine these 6x.\",\n",
      "        \"matches_optimization/fitting\": \"Fitting not clearly addressed in the text, very little information on optimising the fit to avoid over-/under- fitting case for the SVM model. Parameter size unkown but most likely somewhat larger than features used. Small number of features used (f=6). Training set size is not very large, only 66. \",\n",
      "        \"matches_optimization/parameters\": \"Parameters used for the SVM ML model are unclear.\\n\\nIn the simplest case there was potentially 6 parameters used based on the 6x CpG sites noted and their \\u03b2-values for the model. However, given the model type there it is very likely there were more than 6x parameters used. e.g. kernel function or tuned hyperparameters.\",\n",
      "        \"matches_optimization/regularization\": \"None clearly mentioned in text if used. Validation data set noted but not in context of use for early stopping.\",\n",
      "        \"matches_model/availability\": \"No source code released or GitHub/ code repository available from the text.\",\n",
      "        \"matches_model/duration\": \"No contextual SVM ML model execution time information in text.\",\n",
      "        \"matches_model/interpretability\": \"Black box - no model source code linked in a repository (No GitHub/Zenodo/other). Dataset info for the training and test set is available in supplementary file. Less clear for separate valdation dataset. Very poor model optimisation information in the text/suppl. files which is also heavily contributing to black box model nature.  \",\n",
      "        \"matches_dataset/availability\": \"Two DNA methylation datasets GSE88929 and GSE102177 with clinical information were downloaded from the GEO database (http://www.ncbi.nlm.nih.gov/geo/). Splits are noted in the text and use of the dataset data points for test, training and validation.\\n\\nTable S3 provided in supplementary data contains the sample information of the training set and testing set in the GSE88929 datasets.\",\n",
      "        \"matches_dataset/provenance\": \"Data source: GEO database\\n\\nDatat type: DNA methylation data\\n\\nAcronym note: Gestational diabetes mellitus (GDM)\\n\\nTwo DNA methylation datasets GSE88929 and GSE102177 with clinical information were downloaded from the GEO database (http://www.ncbi.nlm.nih.gov/geo/). Both datasets were measured by the Illumina HumanMethylation450 BeadChip assays. \\n\\n-GSE88929 dataset: contained 68 umbilical cord blood samples from the newborns of mothers with GDM and 64 controls without GDM [12]. \\n\\n-GSE102177 dataset: consisted of the peripheral blood samples from 18 fullsibling pairs that were exposed to different conditions of intrauterine hyperglycemia (GDM pregnancy or non-GDM pregnancy). Therefore, there were 18 samples with exposure to maternal GDM and 18 controls without exposure to GDM in the GSE102177 dataset [23].\",\n",
      "        \"matches_dataset/redundancy\": \"Little information on redundancy reduction methods for the data splits in the text.\\n\\nLikely based on the text, the test and training were kept separate.\",\n",
      "        \"matches_dataset/splits\": \"Authors randomly separated the samples from GSE88929 into the training set and testing set, containing 66 samples.\\n\\nTable S3 provided in the supplementary data contains the sample information of the training set and testing set in the GSE88929 datasets.\\n\\nData points:\\n-Test: 66 samples.\\n-Training: 66 samples.\\n\\nThe samples from GSE102177 were instead used as an independent validation set. This contained: 18 samples.\",\n",
      "        \"matches_publication/authors\": \"Yan Liu, Hui Geng, Bide Duan, Xiuzhi Yang, Airong Ma, and Xiaoyan Ding\",\n",
      "        \"matches_publication/journal\": \"BioMed Research International\",\n",
      "        \"matches_publication/title\": \"Identification of Diagnostic CpG Signatures in Patients with Gestational Diabetes Mellitus via Epigenome-Wide Association Study Integrated with Machine Learning\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6634f1d6ded6e7820f74a18b\",\n",
      "        \"shortid\": \"fbkgc98sns\",\n",
      "        \"uuid\": \"56d33311-36d5-4be6-9a3f-2b732a2b4c63\",\n",
      "        \"created\": \"2024-05-03T14:16:54.445Z\",\n",
      "        \"updated\": \"2024-05-03T14:16:54.445Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"33532838\",\n",
      "        \"publication_authors\": \"Fergus Imrie, Anthony R Bradley, Charlotte M Deane \",\n",
      "        \"publication_journal\": \"Bioinformatics\",\n",
      "        \"publication_title\": \"Generating property-matched decoy molecules using deep learning\",\n",
      "        \"publication_doi\": \"10.1093/bioinformatics/btab080\",\n",
      "        \"publication_year\": \"2021 \",\n",
      "        \"score\": 0.52,\n",
      "        \"matches_evaluation/confidence\": \"Yes, confidence intervals are reported. The generated decoys by the model improved the Deviation from Optimal Embedding (DOE) score by an average of 81% and 66%, respectively, decreasing from 0.166 to 0.032 for DUD-E and from 0.109 to 0.038 for DEKOIS 2.0.\",\n",
      "        \"matches_evaluation/measure\": \"The reported performance metrics include the DOE (deviation from optimal embedding) score, doppelganger score, and AUC ROC from predictive models and virtual screening performance.\",\n",
      "        \"matches_evaluation/method\": \"The model was evaluated on independent SBVS datasets DUD-E and DEKOIS 2.0.\",\n",
      "        \"matches_optimization/algorithm\": \"It is deep learning method using graph neural networks.\\nIt is not a novel algorithm.\",\n",
      "        \"matches_optimization/encoding\": \"The data were encoded as graphs representing molecules. The model was trained using pairs of molecules, framing decoy generation as a multimodal graph-to-graph translation problem.\",\n",
      "        \"matches_optimization/meta\": \"It is not a meta-predictor.\",\n",
      "        \"matches_model/interpretability\": \"No mention was made on interpretability. The model appears to be a black box.\",\n",
      "        \"matches_model/output\": \"It is a generative model.\",\n",
      "        \"matches_dataset/provenance\": \"The source of the data is 250,000 randomly selected molecules from ZINC\\nThis subset was already used by Go\\u00b4mez-Bombarelli et al. (2018).\\nPairs of molecules were constructed to satisfy the following criteria: \\n(i) identical heavy atom count and counts of specific heavy atoms (C, N, O, S, Cl, F)\\n(ii) high similarity in property-space\\n(iii) low structural similarity\",\n",
      "        \"matches_dataset/redundancy\": \"Test sets are independent from the training data.\",\n",
      "        \"matches_dataset/splits\": \"Authors used two different test sets, DUD-E with 102 targets and DEKOIS 2.0 with 80 targets, and prepared different size training sets accordingly.\\nThis resulted in a training set of 131 199 pairs for DUD-E and 103 170 for DEKOIS 2.0.\\nAuthors selected 1000 pairs for model validation and used the remainder to train the model.\",\n",
      "        \"matches_publication/authors\": \"Fergus Imrie, Anthony R Bradley, Charlotte M Deane \",\n",
      "        \"matches_publication/title\": \"Generating property-matched decoy molecules using deep learning\",\n",
      "        \"matches_publication/year\": \"2021 \"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6634f443ded6e7820f74a1ac\",\n",
      "        \"shortid\": \"l5alam5gs2\",\n",
      "        \"uuid\": \"2a384a79-d63e-4e6d-9930-10b3a40c2718\",\n",
      "        \"created\": \"2024-05-03T14:27:15.320Z\",\n",
      "        \"updated\": \"2024-05-03T14:27:15.320Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"36414666\",\n",
      "        \"publication_authors\": \"Fenglei Li, Qiaoyu Hu, Xianglei Zhang, Renhong Sun, Zhuanghua Liu, Sanan Wu, Siyuan Tian, Xinyue Ma, Zhizhuo Dai, Xiaobao Yang, Shenghua Gao & Fang Bai\",\n",
      "        \"publication_journal\": \"Nature Communications\",\n",
      "        \"publication_title\": \"DeepPROTACs is a deep learning-based targeted degradation predictor for PROTACs\",\n",
      "        \"publication_doi\": \"10.1038/s41467-022-34807-3\",\n",
      "        \"publication_year\": \"2022\",\n",
      "        \"score\": 0.86,\n",
      "        \"matches_evaluation/comparison\": \"Only comparison to SVM and RF models (developed by authors) was done.\",\n",
      "        \"matches_evaluation/measure\": \"Average accuracy and AUROC are the reported performance metrics.\",\n",
      "        \"matches_evaluation/method\": \"The model was eventually evaluated on a test set, after optimization on a validation set in another experiment beforehand.\\nAuthors further validated the model by using a batch recently reported PROTACs.\",\n",
      "        \"matches_optimization/algorithm\": \"The algorithm is a Multi Layer Perceptron (Neural Networks).\\nAuthors compared the algorithm with SVM and RF, and they got better results with Neural Networks.\",\n",
      "        \"matches_optimization/config\": \"They used a validation set to optimize hyperparameters. The source code of DeepPROTACs and associated data preparation scripts are available at github (https://github.com/fenglei104/ DeepPROTACs) 98. The final DeepPROTACs model is also provided.\",\n",
      "        \"matches_optimization/encoding\": \"Authors analyzed each PROTAC molecule from through 5 aspects: POI Pocket, E3 Pocket, Warhead, E3 ligand, and Linker. The first 4 are preprocessed and encoded by Graph Convolution and Max Pooling layers. As mentioned,  to process the data regarding the SMILES format of the \\\"linker\\\" part in PROTAC molecules, they used embeddings followed by bidirectional LSTM and a fully connected layer.\",\n",
      "        \"matches_optimization/features\": \"For each aspect of the PROTAC molecule (5), 64 features were extracted to be fed into the main neural networks at the end.\\nNo mention was made on feature selection\",\n",
      "        \"matches_optimization/fitting\": \"The number of reported parameters is not bigger than training points. Authors used over-sampling method, compared to normal sampling and under-sampling, to address the imbalance in the data.\",\n",
      "        \"matches_optimization/meta\": \"As a part of data encoding, to process the data regarding the SMILES format of the \\\"linker\\\" part in PROTAC molecules, they used embeddings followed by bidirectional LSTM and a fully connected layer.\",\n",
      "        \"matches_optimization/parameters\": \"Overall 17 parameters were reported by Authors.\\nParameters were optimized on validation set.\",\n",
      "        \"matches_optimization/regularization\": \"Authors used over-sampling method, compared to normal sampling and under-sampling, to address the imbalance in the data.\",\n",
      "        \"matches_model/availability\": \"They used a validation set to optimize hyperparameters. The source code of DeepPROTACs and associated data preparation scripts are available at github (https://github.com/fenglei104/ DeepPROTACs) 98. The final DeepPROTACs model is also provided.\",\n",
      "        \"matches_model/interpretability\": \"No mention on interpretability of the model was made. Due to many layers of input encoding and using neural networks, the model appears to be a black box.\",\n",
      "        \"matches_model/output\": \"It is a binary classifier.\",\n",
      "        \"matches_dataset/availability\": \"The PROTACs data used in this study are available in the public database of PROTAC-DB (http://cadd.zju.edu.cn/protacdb/).\",\n",
      "        \"matches_dataset/provenance\": \"The source of the data is PROTAC molecules that are either present on PROTACS-DB, an online database, or gathered from \\\"other public sources\\\".\\nThe size of the whole dataset used is 2832.\\nIt was further labeled as 988 positive and 1844 samples.\",\n",
      "        \"matches_dataset/redundancy\": \"Data was split randomly and no mention on redundancy reduction was made.\\nThe whole dataset is considered to be small in size and, to my knowledge, no previous ML dataset does exist for this purpose.\",\n",
      "        \"matches_dataset/splits\": \"For optimization purpose, they randomly split the data into the training set, validation set, and test set at a ratio of 8:1:1.\\nAfter optimization, they used a 8:2 ratio for training:test.\\nData was split randomly and no mention was made on the distribution of the negatives/positives different divisions.\",\n",
      "        \"matches_publication/authors\": \"Fenglei Li, Qiaoyu Hu, Xianglei Zhang, Renhong Sun, Zhuanghua Liu, Sanan Wu, Siyuan Tian, Xinyue Ma, Zhizhuo Dai, Xiaobao Yang, Shenghua Gao & Fang Bai\",\n",
      "        \"matches_publication/journal\": \"Nature Communications\",\n",
      "        \"matches_publication/title\": \"DeepPROTACs is a deep learning-based targeted degradation predictor for PROTACs\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6634f526ded6e7820f74a1b8\",\n",
      "        \"shortid\": \"skg7vifrfy\",\n",
      "        \"uuid\": \"242800d0-70de-4409-9b2f-bff40afacc32\",\n",
      "        \"created\": \"2024-05-03T14:31:02.390Z\",\n",
      "        \"updated\": \"2024-05-03T14:31:02.390Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"No\",\n",
      "        \"publication_authors\": \"Hannes St\\u00e4rk, Octavian-Eugen Ganea, Lagnajit Pattanaik, Regina Barzilay, Tommi Jaakkola\",\n",
      "        \"publication_journal\": \"arXiv\",\n",
      "        \"publication_title\": \"EQUIBIND: Geometric Deep Learning for Drug Binding Structure Prediction\",\n",
      "        \"publication_doi\": \"https://doi.org/10.48550/arXiv.2202.05146\",\n",
      "        \"publication_year\": \"2022\",\n",
      "        \"score\": 1,\n",
      "        \"matches_evaluation/availability\": \"Code to reproduce results with the provided model weights is available at https://github.com/HannesStark/ EquiBind.\",\n",
      "        \"matches_evaluation/comparison\": \"The model was compared to similar software and methods including QVINA, GNINA, SMINA, and GLIDE.\\nAlso the combinations of the model with SMINA and QVINA was included in the benchmark.\",\n",
      "        \"matches_evaluation/confidence\": \"MEAN, MED, 25TH, 50TH, 75TH, % below 5 and 2 A\\u02da was reported for the mentioned evaluation metrics. While the standard model performs relatively well, in most metrics the best results are obtained when EQUIBIND is combined with SMINA for fine-tuning.\",\n",
      "        \"matches_evaluation/measure\": \"Authos used the ligand root mean square deviation (L-RMSD), the centroid distance, and the KabschRMSD as evaluation metics.\",\n",
      "        \"matches_evaluation/method\": \"The evaluation was carried out on an independent test set in two experiments: 1. Flexible blind self-docking and 2. Blind re-docking\",\n",
      "        \"matches_optimization/algorithm\": \"It is a geometric deep learning model.\",\n",
      "        \"matches_optimization/config\": \"Code to reproduce results or perform fast docking with the provided model weights is available at https://github.com/HannesStark/ EquiBind.\",\n",
      "        \"matches_optimization/encoding\": \"Both input molecules (ligand & receptor) are represented to the model as spatial k-nearest neighbor (k-NN) graphs.\",\n",
      "        \"matches_optimization/features\": \"For the \\u03b1-carbons in the receptor graph, authors used the residue type as a feature. The edges have two attributes.\\n\\nIn the ligand, the edges have features that are encoded in the same fashion as for the receptor. Meanwhile, the atoms have the following features: atomic number; chirality; degree; formal charge; implicit valence; the number of connected hydrogens; the number of radical electrons; hybridization type; whether or not it is in an aromatic ring; in how many rings it is; and finally, 6 features for whether or not it is in a ring of size 3, 4, 5, 6, 7, or 8.\",\n",
      "        \"matches_optimization/fitting\": \"p is not larger than the number of training points. \",\n",
      "        \"matches_optimization/meta\": \"The model combines Graph Matching Networks and E(3)-Equivariant Graph Neural Networks.\",\n",
      "        \"matches_optimization/parameters\": \"Overall 15 parameters were reported.\\nAuthors used search space strategy to obtain a strong performance on the validation set.\",\n",
      "        \"matches_optimization/regularization\": \"Authors optimized the model using \\\"Adam\\\" and did early stopping with patience of 150 epochs based on the percentage of predicted validation set complexes with an RMSD better than 2 A.\",\n",
      "        \"matches_model/availability\": \"The model and its source code is available at https://github.com/HannesStark/ EquiBind.\",\n",
      "        \"matches_model/duration\": \"In \\\"Flexible blind self-docking\\\" experiment, Standard EQUIBIND takes on average 0.16 second on 16 CPU cores and 0.04 second on a 6GB GTX 1060 GPU to process a task.\",\n",
      "        \"matches_model/interpretability\": \"No mention was made on the interoperability of the model. However, due to the complexity of the model, it appears to be a black box.\",\n",
      "        \"matches_model/output\": \"The model is close to a regression model by predicting the coordinates of the ligand-protein binding site alongside the bond angles and lengths of the ligand molecule.\",\n",
      "        \"matches_dataset/availability\": \"The data and associated scripts available at https://github.com/HannesStark/EquiBind.\",\n",
      "        \"matches_dataset/provenance\": \"Authors used protein-ligand complexes from PDBBind in a time split manner.\\nThe newest version, PDBBind v2020, contains 19,443 protein-ligand complexes with 3,890 unique receptors and 15,193 unique ligands.\\n\",\n",
      "        \"matches_dataset/redundancy\": \"A time split strategy was adopted by the authors.\",\n",
      "        \"matches_dataset/splits\": \"Of the 19 119 preprocessed complexes, 1512 were discovered in 2019 or later. From these, they randomly sampled 125 unique proteins and collected all new complexes containing them (363) to create the final test set.\\nFrom the remaining complexes that are older than 2019, we remove those with ligands contained in the test set, giving 17,347 complexes for training and validation. These are divided into 968 validation complexes, which share no ligands with the remaining 16,379 train complexes.\",\n",
      "        \"matches_publication/authors\": \"Hannes St\\u00e4rk, Octavian-Eugen Ganea, Lagnajit Pattanaik, Regina Barzilay, Tommi Jaakkola\",\n",
      "        \"matches_publication/title\": \"EQUIBIND: Geometric Deep Learning for Drug Binding Structure Prediction\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6638a38fb30933003cc215c1\",\n",
      "        \"shortid\": \"63a7xx35gw\",\n",
      "        \"uuid\": \"c4675347-1a80-45e3-b55c-1e43e2e94e91\",\n",
      "        \"created\": \"2024-05-06T09:31:59.998Z\",\n",
      "        \"updated\": \"2024-05-06T09:31:59.998Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"35489069\",\n",
      "        \"publication_authors\": \"Vineet Thumuluri, Jos\\u00e9 Juan Almagro Armenteros, Alexander Rosenberg Johansen, Henrik Nielsen, Ole Winther\",\n",
      "        \"publication_journal\": \"Nucleic Acids Research\",\n",
      "        \"publication_title\": \"DeepLoc 2.0: multi-label subcellular localization prediction using protein language models\",\n",
      "        \"publication_doi\": \"10.1093/nar/gkac278\",\n",
      "        \"publication_year\": \"2022\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_evaluation/comparison\": \"The model was compared to other similar methods including YLoc+, DeepLoc 1.0,  Fuel-mLoc, and LAProtT5\",\n",
      "        \"matches_evaluation/confidence\": \"Standard deviations are reported.\",\n",
      "        \"matches_evaluation/measure\": \"Metrics for quantifying the performance in prediction of subcellular localization:\\nNumber of predicted labels, Accuracy, Jaccard, MicroF1, MacroF1, Matthews Correlation Coefficient\\n\\nFor quantifying the relevance of attention to the sorting signals:\\nImportance in signal: Total attention mass present within the signal.\\nSignal over background: The average attention value within the signal over the average value outside the signal.\\nMetric Entropy: The entropy of the attention normalized by the information length of the protein. \\nKL-Divergence: Distributional dissimilarity between the signal and attention\",\n",
      "        \"matches_evaluation/method\": \"An independent dataset (3) was used for the evaluation purpose.\",\n",
      "        \"matches_optimization/algorithm\": \"The prediction stage consists of two multi-layer perceptron (MLP) classifier heads.\\nThe first head is trained along with the learnable vector from the attention step for the ten-class multi-label subcellular localization task.\\nA second head is trained after freezing the rest of the parameters for the nineclass sorting signal prediction task\",\n",
      "        \"matches_optimization/encoding\": \"Then using an interpretable attention pooling mechanism a sequence representation is produced. The two prediction heads then utilize this representation to predict multiple labels for both the 10-type subcellular localization and 9-type sorting signal prediction tasks.\",\n",
      "        \"matches_optimization/fitting\": \"Discrete-Cosine Transform was used to regularize the attention-pooling layer.\",\n",
      "        \"matches_optimization/meta\": \"DeepLoc 2.0 uses a transformer-based protein language model to encode the input amino acid sequence.\\nFor this purpose, they evaluated three publicly available transformer models:\\nThe 12-layer ESM model with 84M parameters\\nThe 33-layer ESM model with 650M parameters\\nThe 3B parameter ProtT5-XL-UniRef50model\",\n",
      "        \"matches_model/availability\": \"It is available through a webserver: https://services.healthtech.dtu.dk/services/DeepLoc-2.0/\",\n",
      "        \"matches_model/duration\": \"Based on the language model used, webserver estimated time per sequence are as follows:\\n\\nShort sequences (Average length: 104) for ESM1b and ProtT5 respectively:\\nModel load time (s) 11.07 and 26.80 \\nPrediction time (s / seq) 0.83 3.93\\nPlot time (s / seq) 2.38 2.57\\n\\nLong sequences (Average length: 400) for ESM1b and ProtT5 respectively:\\nModel load time (s) 11.09 26.09\\nPrediction time (s / seq) 3.29 7.33\\nPlot time (s / seq) 7.94 7.97\",\n",
      "        \"matches_model/interpretability\": \"After encoding the sequences with protein language models, an interpretable attention pooling mechanism is used to produce sequence representations.\",\n",
      "        \"matches_model/output\": \"The model is a multi-label classification model.\",\n",
      "        \"matches_dataset/availability\": \"The data used for training and testing are available at https://services.healthtech.dtu.dk/service.php?DeepLoc-2.0\",\n",
      "        \"matches_dataset/provenance\": \"The authors used 3 different datasets for different purposes.\\n1. Localization dataset for training purpose, obtained from SwissProt:\\nCytoplasm =  9870 \\nNucleus =  9720\\nExtracellular =  3301 \\nMitochondrion =  2590 \\nCell membrane =  4187 \\nEndoplasmic reticulum (ER) =  2180 \\nPlastid =  1047 \\nGolgi apparatus =  1279 \\nLysosome/Vacuole =  1496 \\nPeroxisome =  304\\n\\n2. Localization dataset for testing purpose, obtained from The Human Protein Atlas:\\nNucleus =  893\\nCytoplasm =  562\\nCell membrane =  287\\nMitochondrion =  196\\nGolgi apparatus =  86\\nEndoplasmic reticulum (ER)  =  77\\n\\n3. Sorting signals dataset, curated from literature:\\nSignal Peptides (SP)  =  1011\\nTransmembrane domains (TM)  =  260 \\nMitochondrial transit peptide (MT)  =  242 \\nChloroplast transit peptide (CH)  =  90 \\nThylakoidal lumen composite transit peptide (TH) 42 \\nNuclear localization signal (NLS) 148 \\nNuclear export signal (NES) 100 \\nPeroxisome targeting signal (PTS) 127\",\n",
      "        \"matches_dataset/redundancy\": \"Authors ensured that each pair of train and test fold does not share sequences that have global sequence identity greater than 30%.\\n\",\n",
      "        \"matches_dataset/splits\": \"1 and 3 datasets are used in a 5-fold cross-validation after homology based partitioning.  \\ndataset 2 is completely used for evaluation purpose.\",\n",
      "        \"matches_publication/authors\": \"Vineet Thumuluri, Jos\\u00e9 Juan Almagro Armenteros, Alexander Rosenberg Johansen, Henrik Nielsen, Ole Winther\",\n",
      "        \"matches_publication/journal\": \"Nucleic Acids Research\",\n",
      "        \"matches_publication/title\": \"DeepLoc 2.0: multi-label subcellular localization prediction using protein language models\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6638a437b30933003cc215cd\",\n",
      "        \"shortid\": \"3a79km88l8\",\n",
      "        \"uuid\": \"fa0099b4-d7bf-44c1-bee9-04ac2176a4d9\",\n",
      "        \"created\": \"2024-05-06T09:34:47.725Z\",\n",
      "        \"updated\": \"2024-05-06T09:34:47.725Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"35896542\",\n",
      "        \"publication_authors\": \"Noelia Ferruz, Steffen Schmidt, Birte H\\u00f6cker\",\n",
      "        \"publication_journal\": \"nature communications\",\n",
      "        \"publication_title\": \"ProtGPT2 is a deep unsupervised language model for protein design\",\n",
      "        \"publication_doi\": \"10.1038/s41467-022-32007-7\",\n",
      "        \"publication_year\": \"2022\",\n",
      "        \"score\": 0.9,\n",
      "        \"matches_evaluation/comparison\": \"The model was not compared to similar methods as it is quite novel.\\nAt one point, the generations by the model were compared to randomly generated sequences as the simplest baseline.\",\n",
      "        \"matches_evaluation/confidence\": \"Only MD calculations for measuring structure stability have confidence intervals.\",\n",
      "        \"matches_evaluation/measure\": \"The generations made by the model were compared to a randomly selected natural dataset of 10,000 data points (sequences) in terms of following measures:\\n1) globular domains % \\n2) Ordered content % \\n3) Alpha-helical content %\\n4) Beta-sheet content and %\\n5) Coil content \\n6) Structure stability using MD calculations\",\n",
      "        \"matches_evaluation/method\": \"The model was evaluated based on the comparison of the model's generations to random naturally occurring samples in terms of sequence and structural properties.\",\n",
      "        \"matches_optimization/algorithm\": \"The model is an autoregressive Transformer.\\nThe model is not novel.\",\n",
      "        \"matches_optimization/config\": \"The model weights are publicly available in the HuggingFace repository: https://huggingface.co/nferruz/ProtGPT2 and Zenodo: https://doi.org/10.5281/zenodo.6796843 [https://zenodo.org/record/ 6796843#.YswB9XbMIVA]\",\n",
      "        \"matches_optimization/encoding\": \"BPE tokenizer was used to train the vocabulary of the dataset. BPE is a sub-word tokenization algorithm.\",\n",
      "        \"matches_optimization/features\": \"The results shown in this work correspond to a model trained with a block size of 512 tokens.\\nNo feature selection step was involved.\",\n",
      "        \"matches_optimization/fitting\": \"p is much larger than f. The model was fit in a way that the generations most resemble the ones that naturally occur. \",\n",
      "        \"matches_optimization/meta\": \"The model is not a meta-predictor.\",\n",
      "        \"matches_optimization/parameters\": \"The final model is a decoder-only architecture of 36 layers and 738 million parameters.\\nThe architecture matches that of the previously released GPT2-large Transformer.\",\n",
      "        \"matches_model/availability\": \"The model is freely available and the code and documentation are available here: https:// huggingface.co/docs/transformers/main_classes/trainer\",\n",
      "        \"matches_model/duration\": \"\\\"ProtGPT2 generates sequences in a matter of seconds\\\".\",\n",
      "        \"matches_model/interpretability\": \"The model is a black box due to sheer number of 738 million parameters.\",\n",
      "        \"matches_model/output\": \"It is a generative model.\",\n",
      "        \"matches_dataset/availability\": \"The used dataset is publicly available through the URL: https://huggingface.co/datasets/nferruz/UR50_2021_04\\nNo information on licence was reported.\",\n",
      "        \"matches_dataset/provenance\": \"The model was trained and evaluated on UniRef50 database (version 2021_04) with 49,874,565 data points.\\nThe dataset has been previously used in many other studies.\",\n",
      "        \"matches_dataset/redundancy\": \"The split has been done randomly.\\nThe evaluation set is a 10% independent exclusion from UniRef50. The rest 90% was used for training.\\nUniRef50 is a 50% identity clustered database of UniProt KB. \",\n",
      "        \"matches_dataset/splits\": \"They have used a 90 - 10 (44.9 million and 4.9 million) split corresponding to training and evaluation set respectively.\\nNo feature has been reported to be taken into account for splitting the data. \",\n",
      "        \"matches_publication/authors\": \"Noelia Ferruz, Steffen Schmidt, Birte H\\u00f6cker\",\n",
      "        \"matches_publication/journal\": \"nature communications\",\n",
      "        \"matches_publication/title\": \"ProtGPT2 is a deep unsupervised language model for protein design\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"667203b937ea6fa797a6c2ef\",\n",
      "        \"shortid\": \"x9vqohdvu0\",\n",
      "        \"uuid\": \"7a30fa4d-704a-4379-b242-310bf0bf9d57\",\n",
      "        \"created\": \"2024-06-18T22:01:29.043Z\",\n",
      "        \"updated\": \"2024-06-18T22:01:29.043Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"36525447\",\n",
      "        \"publication_authors\": \"Xiaohui Zou, Marcus Nguyen, Jamie Overbeek, Bin Cao,  and James J. Davis\",\n",
      "        \"publication_journal\": \"PLOS One\",\n",
      "        \"publication_title\": \"Classification of bacterial plasmid and chromosome derived sequences using machine learning\",\n",
      "        \"publication_doi\": \"10.1371/journal.pone.0279280\",\n",
      "        \"publication_year\": \"2022\",\n",
      "        \"score\": 0.95,\n",
      "        \"matches_evaluation/availability\": \"No - the evaluation is not clearly available based on GitHub repository content or linked from text.\",\n",
      "        \"matches_evaluation/comparison\": \"The different models cross-compared for the classification task could be considered baselines from lower (eg: logistic regression) to higher complexity (eg: neural network) models.\\n\\nFurther, the text does compare the models to existing classification methods described in previous publications:\\n-PlasClass\\n-PlasFlow\\nThese were evaluated on the same datasets used in this study.\",\n",
      "        \"matches_evaluation/confidence\": \"Confidence intervals are reported for the models performances throughout the text. \",\n",
      "        \"matches_evaluation/measure\": \"For classifying plasmid and chromosome sequences using 6-mers as features, the following model metrics were reported in the text:\\n\\n-Accuracy\\n-F1 score\\n-Precision \\n-Recall \",\n",
      "        \"matches_evaluation/method\": \"10-fold cross-validation was employed for model evaluation.\\n\",\n",
      "        \"matches_optimization/algorithm\": \"4x model types were noted to have been used for the model generations based on text:\\n\\n1. Logistic regression \\n2. Random forest   \\n3. eXtreme Gradient Boosting - XGBoost   \\n4. Neural network\\n\\nNone of these models are novel\",\n",
      "        \"matches_optimization/config\": \"Hyperparameters detailed in the text. The model GitHub linked may include more configuration information but unclear.  \",\n",
      "        \"matches_optimization/encoding\": \"The data encoding was through k-merisation which involved creating numerical representations of the categorical data (DNA sequences) for the machine learning models.  Likely one-hot encoding but hard to determine from text as not explictily written..\",\n",
      "        \"matches_optimization/features\": \"Features are somewhat described in the text but exact feature figures not explicitly included in relation the the 4x model types used. However, some of these can be inferred based on the text.\\n\\nSome more information can be extrapolated from the text based on the features below:\\n-K-mer size: the text mentions using k-mers of size 6 (6-mers) for feature extraction.\\n-Subsequence length: the model used two subsequence lengths - 2kb and 5kb.\\n\\n4x nucleotides (A, T, G, C) means a 6-mer can have 4^6 = 4096 possible combinations.\\nThe text notes they only considered the \\\"canonical\\\" k-mer - the lexicographically highest version (e.g., \\\"AAAAAA\\\" instead of \\\"TTTTTT\\\"). This reduces the number of features by half (assuming even distribution of nucleotides).\\n\\nTherefore, the model features for 6-mers could be inferred as (4^6 / 2) = 2048. However, given the exact numbers are not stated for the models in text this may not be true.\",\n",
      "        \"matches_optimization/fitting\": \"Unclear model fittings - there is not a lot of information in the text on the precise number of parameters or features used to generate the 4x models.\",\n",
      "        \"matches_optimization/parameters\": \"Exact parameters for the 4x models are not clearly stated in the text. \\n\\n1. Logistic regression = unkown, but uses a single weight vector with a dimension equal to the number of features.\\n\\n2. Random forest   = 200 (based on 200 decision trees noted in the final model.)\\n\\n3. eXtreme Gradient Boosting - XGBoost  = unkown, little information in text\\n\\n4. Neural network = unkown, not explicitly stated in text\\n-However, information for the neural network parameters can be inferred to be large as it has 7 layers with specific numbers of neurons.\\n-Text notes text number of neurons in each layer (256, 256, 128, 128, 32, 10, and 1).\\n-Hyperparameter tuning & computational Resources seem to have been considered for parameter selection.\\n\",\n",
      "        \"matches_optimization/regularization\": \"10-fold cross-validation was one of the key approaches technique used to prevent overfitting. For the neural network specifically two other approaches were mentioned in the text to avoid overfitting: drop-out layers (these were applied to the first 4x layers to prevent co-adaptation and encourage generalisable features.) and L2 weight regularisation (model used a value of 0.0001 to penalise large weights to prevent overfitting.).\",\n",
      "        \"matches_model/availability\": \"Github containing model source code available: https://github.com/BV-BRC-dependencies/zou-plasmid-prediction. Python code primarily, no interactive notebooks. No docker/container deployment linked or clearly available. Repository license not clear.\",\n",
      "        \"matches_model/duration\": \"Clear equations for helping with the estimation of neural network memory usage are present. However, no exact compute requirements for model training or time to do so. Additionally, no run time info for use on datasets.\\n\\nText notes GPUs plural for model needs - it could be presumed more than one GPU is needed. 2x GPUs are mentioned at another point in the text and improved performance in relation to this.\",\n",
      "        \"matches_model/interpretability\": \"Moderately interpretable - but variable by the 4x model types which makes this harder to discern interpretability. Low information on exact parameters and features in the text and somewhat confusing as there is mutliple models. However, the GitHub with data is available and model source code. Although no containers/environment control tooling/code provided. The simpler model types (e.g. random forest) are more interpretable but the more complex ones (e.g. neural network) are somewhat more complex. The authors did a decent job for describing the various DOME areas.\",\n",
      "        \"matches_dataset/availability\": \"Datasets used for training & test available on the GitHub repository within labelled CSV files. GitHub: https://github.com/BV-BRC-dependencies/zou-plasmid-prediction.\\n\\nThe original data sourced from BV-BRC (https://www.bv-brc.org/) should also still be avaialble provided no changes have occured to the data since the original study publication.\",\n",
      "        \"matches_dataset/provenance\": \"Data source is from the database: PAThosystems Resource Integration Center (PATRIC).\\n-Note: this database is now called the Bacterial and Viral Bioinformatic Resource Center (BV-BRC).\\n\\nThe data type is DNA, plasmids and chromosomes.\\n\\nThe study classed its data as follows:\\n\\u201cplasmid\\u201d as positive class, Npos = 10,654 \\n\\u201cchromosome\\u201d as the negative class, Nneg = 10,584\\n\\nNovel dataset was compiled from publicly available data - this dataset is not community recognised/re-used but the overall database content would be. \",\n",
      "        \"matches_dataset/redundancy\": \"The dataset (exempting the holdout set) was split 7:2:1 ratio for model training, testing, and validation, respectively.\\n\\nYes - independent training and test as noted from use of hold out set.\",\n",
      "        \"matches_dataset/splits\": \"10,654 plasmid genomes with lengths greater than 2kb.\\n-plasmid dataset contained a total of 1,258 species and 485 genera\\n10,584 bacterial chromosomes with lengths greater than 10kb. \\n-chromosomal dataset contained 2,212 species and 906 genera. \\n\\nPrior to building models: 1,000 plasmid and 1,000 chromosomal sequences were separated from the dataset to create a holdout set.\",\n",
      "        \"matches_publication/authors\": \"Xiaohui Zou, Marcus Nguyen, Jamie Overbeek, Bin Cao,  and James J. Davis\",\n",
      "        \"matches_publication/journal\": \"PLOS One\",\n",
      "        \"matches_publication/title\": \"Classification of bacterial plasmid and chromosome derived sequences using machine learning\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"63a25db2e8edf6ce46f6e84b\",\n",
      "        \"uuid\": \"8c0c94cd-3172-4f65-92b0-b997742324e0\",\n",
      "        \"created\": \"2022-12-21T01:13:22.874Z\",\n",
      "        \"updated\": \"2022-12-21T01:38:36.717Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_authors\": \"Ang Guo, Zhiyu Chen, Fang Li, and Qian Luo\",\n",
      "        \"publication_doi\": \"10.1093/gigascience/giad021\",\n",
      "        \"publication_journal\": \"GigaScience\",\n",
      "        \"publication_pmid\": \"37039115\",\n",
      "        \"publication_title\": \"Delineating Regions-of-interest for Mass Spectrometry Imaging by Multimodally Corroborated Spatial Segmentation\",\n",
      "        \"publication_year\": \"2023\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"shortid\": \"ck60ijuxvo\",\n",
      "        \"score\": 0.9,\n",
      "        \"matches_evaluation/comparison\": \"Yes, our method was compared with two internal validation measures: (1) segmentation was evaluated by how closely it resembled the low-dimension overview of the high\\u2010dimensional molecular content of MSI data obtained by nonlinear dimension reduction techniques (here we used UMAP). The resemblance between the UMAP image and the segmentation maps was measured by applying a Canny edge detector to both and computing their edge correlation.  (2) the Davies\\u2013Bouldin index (DBI) was used to find the optimal segmentation for MSI data. DBI measures the ratio of within-cluster distances (the measure of intra-cluster compactness) to between-cluster distances (the measure of inter-cluster separation), so a smaller DBI indicates better-defined clusters and thus supposedly better segmentation. \",\n",
      "        \"matches_evaluation/confidence\": \"not applicable \",\n",
      "        \"matches_evaluation/measure\": \"Cohen's kappa score between MSI- and Histology-segmentation results\",\n",
      "        \"matches_evaluation/method\": \"A multimodal fusion-based method was proposed in our manuscript. Visual evaluation by an expert was also performed.\",\n",
      "        \"matches_optimization/algorithm\": \"Spectral Clustering algorithm with  n_clusters=3 to 8, affinity='cosine' or 'nearest neighbors', n_components=5, assign_labels='kmeans'\",\n",
      "        \"matches_optimization/config\": \"Not applicable \",\n",
      "        \"matches_optimization/encoding\": \"An inner layer (conv5-block32-concat) of DenseNet 201 was used as our extractor of choice to encode the stain color and morphology of a 2D H&E image tile into a set of informative histomorphological features (HF). To stay in keeping with ImageNet, our input tiles had to be resized to [224, 224, 3] through bilinear interpolation and each color channel had to be centered to zero . Eventually, the output arrays after the concatenation operation at the conv5_block32 layer of DenseNet201 were 2-D globally average-pooled, Min-Max scaled, and reshaped as a \\\"histomorphological feature (HF) spectrum\\\" of 1,920 variables.\",\n",
      "        \"matches_optimization/features\": \"HF data cube had 1920 histomorphological features. For the MSI data of whole kidney, the number of m/z variables was 87. For the tumor data, the number of m/z variables was 89. Feature selection was performed to include only the ions that had a stronger signal in the foreground tissue areas than the background glass substrates.\",\n",
      "        \"matches_optimization/parameters\": \"n_clusters were selected objectively by a multimodal fusion method proposed in our manuscript, the affinity and n_components were empirically configured to produce visually less fragmented regions \",\n",
      "        \"matches_optimization/regularization\": \"Not applicable \",\n",
      "        \"matches_model/availability\": \"Yes, available at https://github.com/guoang4github/ROIforMSI/ (Licence: GPL-3)\",\n",
      "        \"matches_model/duration\": \"less than 1 min\",\n",
      "        \"matches_model/interpretability\": \"Not applicable\",\n",
      "        \"matches_model/output\": \"Clustering \",\n",
      "        \"matches_dataset/availability\": \"Yes, The MSI data have been deposited to the ProteomeXchange Consortium (http://proteomecentral.proteomexchange.org) via the iProX partner repository with the dataset identifier PXD038876.\",\n",
      "        \"matches_dataset/provenance\": \"DESI-MSI experiments of whole mouse kidney and renal tumor specimens. Two MSI datasets and their corresponding H&E microscopy images.  The MSI data have been deposited to the ProteomeXchange Consortium (http://proteomecentral.proteomexchange.org) via the iProX partner repository with the dataset identifier PXD038876.\",\n",
      "        \"matches_dataset/redundancy\": \"Not applicable \",\n",
      "        \"matches_dataset/splits\": \"Not applicable \",\n",
      "        \"matches_publication/authors\": \"Ang Guo, Zhiyu Chen, Fang Li, and Qian Luo\",\n",
      "        \"matches_publication/title\": \"Delineating Regions-of-interest for Mass Spectrometry Imaging by Multimodally Corroborated Spatial Segmentation\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"645aa34160bf612a3caabc1b\",\n",
      "        \"uuid\": \"9b42e80b-19bd-49d8-b06e-3b8302ceb152\",\n",
      "        \"created\": \"2023-05-09T19:47:13.177Z\",\n",
      "        \"updated\": \"2023-05-09T19:48:29.691Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_authors\": \"Zhenjiang Fan, Kate F. Kernan, Aditya Sriram, Panayiotis V. Benos, Scott W. Canna, Joseph A. Carcillo, Soyeon Kim, and Hyun Jung Park\",\n",
      "        \"publication_doi\": \"https://doi.org/10.1101/2021.07.17.452800\",\n",
      "        \"publication_journal\": \"GigaScience\",\n",
      "        \"publication_pmid\": \"Not yet assigned\",\n",
      "        \"publication_title\": \"Deep neural networks with knockoff features identify nonlinear causal relations and estimate effect sizes in complex biological systems.\",\n",
      "        \"publication_year\": \"2023\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"shortid\": \"ngjci1cyqx\",\n",
      "        \"score\": 0.86,\n",
      "        \"matches_evaluation/comparison\": \"We compared our method to threeexisting methods, causalMGM, DAG-GNN, and NOTEAR.\",\n",
      "        \"matches_evaluation/confidence\": \"better timing and accuracy\",\n",
      "        \"matches_evaluation/measure\": \"Sensivitity and specificity\",\n",
      "        \"matches_evaluation/method\": \"10-fold cross validation\",\n",
      "        \"matches_optimization/algorithm\": \"The initial weights for the hidden layer are generated using the Glorot normal initializer, which uses \\ud835\\udc3f1\\u2212\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc54\\ud835\\udc62\\ud835\\udc59\\ud835\\udc4e\\ud835\\udc5f\\ud835\\udc56\\ud835\\udc67\\ud835\\udc4e\\ud835\\udc61\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b with the regularization parameter set to O(\\u221a(2logp/n)). To train this model, mean of squares of errors (MSE) is used to calculate the loss in comparison with the response on the output layer. To train the model\\u2019s parameters with respect to the loss function, we used a stochastic gradient descent method called \\u201cAdam optimization\\u201d. \",\n",
      "        \"matches_optimization/encoding\": \"All the inputs have been normalized into the range [-1, 1] for fairness.\",\n",
      "        \"matches_optimization/features\": \"We used a simulation data set, two public data, and one access-controlled data. Our simulation data are downloadable from our project website (https://github.com/ZhenjiangFan/DAG-deepVASE). TCGA breast invasive carcinoma (BRCA) data were downloaded from https://tcga.xenahubs.net, available under BRCA cohort, under gene expression RNAseq section, on IlluminaHiSeq (n=1,218) TCGA Hub. It consists of the gene expression RNAseq dataset (dataset ID: TCGA.BRCA.sampleMap/HiSeqV2) and the clinical phenotype dataset (dataset ID: TCGA.BRCA.sampleMap/BRCA_clinicalMatrix). To investigate the dietary effect of the human gut microbiome, we downloaded a cross-sectional data of 98 healthy volunteers from https://noble.gs.washington.edu/proj/DeepPINK/ that preprocessed the data set.\",\n",
      "        \"matches_optimization/fitting\": \"We used linear fit.\",\n",
      "        \"matches_optimization/parameters\": \"Parameters\\tValue\\nActivation function\\tRectified linear unit (ReLU)\\nInitial weight values\\tGlorot normal intializer\\nRegularization\\t\\ud835\\udc3f1\\u2212\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc54\\ud835\\udc62\\ud835\\udc59\\ud835\\udc4e\\ud835\\udc5f\\ud835\\udc56\\ud835\\udc67\\ud835\\udc4e\\ud835\\udc61\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b\\nOptimization\\tAdam optimization\\nLoss function\\tMean of squares of errors (MSE)\\nFDR control rate\\t0.05\\n\",\n",
      "        \"matches_optimization/regularization\": \"We used \\ud835\\udc3f1\\u2212\\ud835\\udc5f\\ud835\\udc52\\ud835\\udc54\\ud835\\udc62\\ud835\\udc59\\ud835\\udc4e\\ud835\\udc5f\\ud835\\udc56\\ud835\\udc67\\ud835\\udc4e\\ud835\\udc61\\ud835\\udc56\\ud835\\udc5c\\ud835\\udc5b with the regularization parameter set to O(\\u221a(2logp/n)).\",\n",
      "        \"matches_model/duration\": \"Within 6 hours for mid-sized samples.\",\n",
      "        \"matches_model/interpretability\": \"we developed the first computational method that explicitly learns nonlinear causal relations and estimates the effect size using a deep-neural network approach coupled with the knockoff framework.\",\n",
      "        \"matches_model/output\": \"Model classification.\",\n",
      "        \"matches_dataset/provenance\": \"We used a simulation data set, two public data, and one access-controlled data. Our simulation data are downloadable from our project website (https://github.com/ZhenjiangFan/DAG-deepVASE). TCGA breast invasive carcinoma (BRCA) data were downloaded from https://tcga.xenahubs.net, available under BRCA cohort, under gene expression RNAseq section, on IlluminaHiSeq (n=1,218) TCGA Hub. It consists of the gene expression RNAseq dataset (dataset ID: TCGA.BRCA.sampleMap/HiSeqV2) and the clinical phenotype dataset (dataset ID: TCGA.BRCA.sampleMap/BRCA_clinicalMatrix). To investigate the dietary effect of the human gut microbiome, we downloaded a cross-sectional data of 98 healthy volunteers from https://noble.gs.washington.edu/proj/DeepPINK/ that preprocessed the data set.\",\n",
      "        \"matches_dataset/redundancy\": \"all datasets are without overlap, kept coincident for each trial of the algorithms.\",\n",
      "        \"matches_dataset/splits\": \"We used 10 fold cross validation in all the data sets. \",\n",
      "        \"matches_publication/authors\": \"Zhenjiang Fan, Kate F. Kernan, Aditya Sriram, Panayiotis V. Benos, Scott W. Canna, Joseph A. Carcillo, Soyeon Kim, and Hyun Jung Park\",\n",
      "        \"matches_publication/pmid\": \"Not yet assigned\",\n",
      "        \"matches_publication/title\": \"Deep neural networks with knockoff features identify nonlinear causal relations and estimate effect sizes in complex biological systems.\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6634f4c2ded6e7820f74a1b4\",\n",
      "        \"shortid\": \"nsqtgf6bjv\",\n",
      "        \"uuid\": \"a80c9c2f-d151-4ef4-8aaf-28dfedcf8b7c\",\n",
      "        \"created\": \"2024-05-03T14:29:22.628Z\",\n",
      "        \"updated\": \"2024-05-03T14:29:22.628Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"37996753\",\n",
      "        \"publication_authors\": \"Minkyung Baek, Ryan McHugh, Ivan Anishchenko, Hanlun Jiang, David Baker, Frank DiMaio\",\n",
      "        \"publication_journal\": \"nature methods\",\n",
      "        \"publication_title\": \"Accurate prediction of protein-nucleic acid complexes using RoseTTAFoldNA\",\n",
      "        \"publication_doi\": \"10.1038/s41592-023-02086-5\",\n",
      "        \"publication_year\": \"2023\",\n",
      "        \"score\": 0.9,\n",
      "        \"matches_evaluation/comparison\": \"The predictions of the model were compared to AlphaFold (protein structure prediction method), Hdock (protein\\u2013DNA docking method), and methods for RNA prediction such as DeepFoldRNA, FARFAR2, and AIchemy_RNA.\",\n",
      "        \"matches_evaluation/confidence\": \"Confidence metrics were used and reported tailored to different tasks.\",\n",
      "        \"matches_evaluation/measure\": \"Local Distance Difference Test (lDDT),  fraction of native contacts (FNAT), mean interface predicted aligned error (PAE), CAPRI metrics, RMS, and plDDT.\",\n",
      "        \"matches_evaluation/method\": \"The model was evaluated on an independent test set.\",\n",
      "        \"matches_optimization/algorithm\": \"The model is a neural network-based approach adopted from RoseTTAFold.\",\n",
      "        \"matches_optimization/config\": \"Source code and a link to the training weights have been made available at https://github.com/uw-ipd/RoseTTAFold2NA.\",\n",
      "        \"matches_optimization/encoding\": \"The data is encoded as sequence (1D), residue pair (2D) and structural (3D) representations of protein\\u2013nucleic acid complexes. This makes it compatible with the three-track architecture of RoseTTAFoldNA.\",\n",
      "        \"matches_optimization/features\": \"The model simultaneously refines three representations of a biomolecular system: sequence (1D), residue-pair distances (2D) and cartesian coordinates (3D).\",\n",
      "        \"matches_optimization/fitting\": \"p is much larger than the number of training points.\",\n",
      "        \"matches_optimization/meta\": \"It is not a meta-predictor.\",\n",
      "        \"matches_optimization/parameters\": \"The model has \\u223c67\\u2009M parameters and made up of 36 total layers.\",\n",
      "        \"matches_optimization/regularization\": \"To improve generalizability of protein\\u2013DNA interactions, authors added a few ways of \\u2018randomizing\\u2019 inputs during training. They also performed negative training.\",\n",
      "        \"matches_model/availability\": \"Source code and a link to the training weights have been made available at https://github.com/uw-ipd/RoseTTAFold2NA. The model can be used through a conda environment.\",\n",
      "        \"matches_model/interpretability\": \"The model appears to be a black box as a deep neural network with 67M parameteres.\",\n",
      "        \"matches_model/output\": \"It is a structure prediction model that has some resemblance to a regressor in the sense that it predicts the spatial arrangement of atoms.\",\n",
      "        \"matches_dataset/availability\": \"All data used for training and evaluation is publicly available through the PDB (https://www.rcsb.org/). \",\n",
      "        \"matches_dataset/provenance\": \"Protein Data Bank was used as the source data for training, validation, and test.\",\n",
      "        \"matches_dataset/redundancy\": \"Authors adopted a time split strategy to create an independent test set.\\nThe data was clustered using a 1\\u2009\\u00d7\\u200910\\u22123 hhblits E-value for proteins and 80% sequence identity for RNA molecules.\",\n",
      "        \"matches_dataset/splits\": \"For training and validation sets, A dataset was constructed considering all PDB structures published at or before 30 April 2020, consisted of 7,396 RNA chains and 23,583 Protein-NA complexes.\\nFor Test set, all structures published to the PDB from May 2020 or later, consisted of 91 complexes with one protein molecule plus a single RNA chain or DNA duplex, 43 cases with a single RNA chain and 106 cases with more than one protein chain or more than a single RNA chain or DNA duplex.\",\n",
      "        \"matches_publication/authors\": \"Minkyung Baek, Ryan McHugh, Ivan Anishchenko, Hanlun Jiang, David Baker, Frank DiMaio\",\n",
      "        \"matches_publication/journal\": \"nature methods\",\n",
      "        \"matches_publication/title\": \"Accurate prediction of protein-nucleic acid complexes using RoseTTAFoldNA\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6638a35eb30933003cc215bd\",\n",
      "        \"shortid\": \"nfj5rdqggm\",\n",
      "        \"uuid\": \"5231538c-a267-4ece-a6dd-484c57f5f1d8\",\n",
      "        \"created\": \"2024-05-06T09:31:10.078Z\",\n",
      "        \"updated\": \"2024-05-06T09:31:10.078Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"38114456\",\n",
      "        \"publication_authors\": \"Andy M Lau, Shaun M Kandathil, David T Jones\",\n",
      "        \"publication_journal\": \"10.1038/s41467-023-43934-4\",\n",
      "        \"publication_title\": \"Merizo: a rapid and accurate protein domain segmentation method using invariant point attention\",\n",
      "        \"publication_doi\": \"10.1038/s41467-023-43934-4\",\n",
      "        \"publication_year\": \"2023\",\n",
      "        \"score\": 0.9,\n",
      "        \"matches_evaluation/comparison\": \"The benchmark compares the accuracy of domain assignments by Merizo against those produced by four recently published methods including DeepDom, a CNN-based method from Eguchi et al (referred to as Eguchi-CNN), SWORD and UniDoc.\\nThey also included four baseline measures, including scoring ECOD assignments against CATH (where ECOD assignments are treated as a prediction result), and three random assignment methods prefixed with\\u2019Random\\u2019, where the domain count is estimated according to the Domain Guess by Size method.\",\n",
      "        \"matches_evaluation/confidence\": \"Yes, confidence intervals are reported. Merizo is the most performant method on the CATH-663 set when scoring by IoU. It is followed closely by UniDoc, which has a wider distribution.\",\n",
      "        \"matches_evaluation/measure\": \"They scored predictions based on (1) how well the residues in a predicted domain overlap with a true domain, measured via the intersect-over-union (IoU) between residues in the predicted and\\nground-truth domain, and (2) how precise the predicted domain boundaries are, when assessed using the Matthews Correlation Coefficient (MCC).\",\n",
      "        \"matches_evaluation/method\": \"They evaluated the model on a test split which did not overlap at the CATH homologous superfamily (H) level with the training set.\\nNo mention was made of cross-validation.\",\n",
      "        \"matches_optimization/algorithm\": \"The model is a deep neural network.\\nIt is not a novel algorithm.\",\n",
      "        \"matches_optimization/config\": \"The model is accessible through https://github.com/psipred/Merizo\",\n",
      "        \"matches_optimization/encoding\": \"The model takes three inputs: a single representation, pairwise representation and backbone frames. The single representation is produced by one-hot encoding the primary sequence into 20 amino acid classes and then projected into 512 feature dimensions. For the pairwise representation, authors used the pairwise distance map derived from alpha carbons, directly embedded into 32 feature dimensions as continuous values using a linear layer. Finally, the Euclidean backbone frames are calculated from each residue \\u201cframe\\u201d (N-CA-C atoms) via Gram-Schmidt orthogonalization.\",\n",
      "        \"matches_optimization/features\": \"The model takes 3 inputs with varying feature dimensions.\",\n",
      "        \"matches_optimization/fitting\": \"P is much larger than the number of training points. The authors devised a training-test split which did not overlap at the CATH homologous superfamily (H) level  to better gauge performance on folds that the network has not seen before.\",\n",
      "        \"matches_optimization/meta\": \"It is not a meta-predictor.\",\n",
      "        \"matches_optimization/parameters\": \"The model is a small encoder-decoder network with approximately 37 M parameters (20.4 M in the encoder and 16.8 M in the decoder).\",\n",
      "        \"matches_model/availability\": \"It will be incorporated into the PSIPRED workbench at http://bioinf.cs.ucl.ac.uk/psipred/\",\n",
      "        \"matches_model/duration\": \"Average time per target (second) on GPU: 0.112\",\n",
      "        \"matches_model/interpretability\": \"The model is a deep neural network with 37 M parameters, rendering it a black box.\",\n",
      "        \"matches_model/output\": \"The model has elements of both classification and regression tasks.\",\n",
      "        \"matches_dataset/availability\": \"The code and network weights of Merizo are available at https://github.com/psipred/Merizo\",\n",
      "        \"matches_dataset/provenance\": \"The PDB chains and domain annotations used for training were accessed from version 4.3 of the CATH database.\\nThe final training and testing set contained 17,287 and 663 chains respectively.\\nTo fine-tune the model, 7502 and 1195 AFDB-human models were used for the training and testing sets, respectively\",\n",
      "        \"matches_dataset/redundancy\": \"Further redundancy filtering with CD-HIT39 was performed to cluster targets which had a sequence identity of greater than 99%.\",\n",
      "        \"matches_dataset/splits\": \"The authors devised a training-test split which did not overlap at the CATH homologous superfamily (H) level  to better gauge performance on folds that the network has not seen before.\",\n",
      "        \"matches_publication/authors\": \"Andy M Lau, Shaun M Kandathil, David T Jones\",\n",
      "        \"matches_publication/title\": \"Merizo: a rapid and accurate protein domain segmentation method using invariant point attention\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6638a3d4b30933003cc215c5\",\n",
      "        \"shortid\": \"u122uk9z7j\",\n",
      "        \"uuid\": \"2a48fdcb-6313-45be-a84a-d0c8a9843cb5\",\n",
      "        \"created\": \"2024-05-06T09:33:08.069Z\",\n",
      "        \"updated\": \"2024-05-06T09:33:08.069Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"36420989\",\n",
      "        \"publication_authors\": \"Manon R\\u00e9au, Nicolas Renaud, Li C. Xue, Alexandre M. J. J. Bonvin \",\n",
      "        \"publication_journal\": \"Bioinformatics\",\n",
      "        \"publication_title\": \"DeepRank-GNN: a graph neural network framework to learn patterns in protein\\u2013protein interfaces\",\n",
      "        \"publication_doi\": \"10.1093/bioinformatics/btac759\",\n",
      "        \"publication_year\": \"2023\",\n",
      "        \"score\": 0.76,\n",
      "        \"matches_evaluation/comparison\": \"in both applications, the model was compared and benchmarked to other software, including their own previous model.\",\n",
      "        \"matches_evaluation/confidence\": \"Confidence intervals are reported for AUC's.\",\n",
      "        \"matches_evaluation/measure\": \"Area under the ROC Curve (AUC), MSE, R2, Accuracy, TP rate, and TN rate were reported in Application 1.\\nAccuracy, Specificity, Sensitivity, and Precision metrics were reported in Application 2.\",\n",
      "        \"matches_evaluation/method\": \"Application 1: The model was trained with cross-validation on BM5 dataset and tested on CAPRI dataset.\\nApplication 2: The model was trained on MANY dataset without cross-validation, and tested on DC dataset.\",\n",
      "        \"matches_optimization/algorithm\": \"The model is a Graph Neural Network.\\nIt is not a novel model.\",\n",
      "        \"matches_optimization/config\": \"Available on GitHub: https://github.com/DeepRank/Deeprank-GNN\",\n",
      "        \"matches_optimization/encoding\": \"The graph representation of a PPI is split into two sub-graphs, i.e. the internal graph connecting atoms from the same protein and the external graph connecting atoms from distinct proteins. The two sub-graphs are sequentially passed to two consecutive convolution/activation/pooling layers. The two final graph representations are flattened using the mean value of each feature and merged before applying two fully connected layers.\",\n",
      "        \"matches_optimization/features\": \"48 features.\\nNo mention on feature selection.\",\n",
      "        \"matches_model/availability\": \"DeepRank-GNN can be installed using PyPi package manager after installation of dependencies. The source code is available on GitHub: https://github.com/DeepRank/Deeprank-GNN\",\n",
      "        \"matches_model/duration\": \"Average time of graph generation step per model (second) = 0,65\\nAverage scoring time per model (second) = 2,8E-02 \",\n",
      "        \"matches_model/interpretability\": \"Due to the complexity of data pre-processing and the model itself, it appears be a black box or hardly interpretable at least.\",\n",
      "        \"matches_model/output\": \"The model can be used in both classification and regression tasks. \",\n",
      "        \"matches_dataset/availability\": \"All datasets are available from the SBGrid data repository https://data.sbgrid.org/dataset/843/\",\n",
      "        \"matches_dataset/provenance\": \"4 different datasets were used in two different applications of the model, all of them obtained from other publications.\\n\\nApplication 1: scoring of docking models \\nBM5 = 3,592,600 models generated from 142 dimers using HADDOCK\\nCAPRI = 16,666 models generated from 13 protein dimers by over 40 different research teams using a variety of software\\n\\nApplication 2: binary classification of biological and crystal dimers in 50/50 proportions \\nMANY = 5739 dimers\\nDC = 161 dimers\",\n",
      "        \"matches_dataset/redundancy\": \"The splits have been done randomly by sklearn StratifiedKFold tool in an independent way.\\nNo mention on redundancy reduction by pairwise identity.\",\n",
      "        \"matches_dataset/splits\": \"BM5 = 10% test, 90% training and evaluation in a 10-fold cross validation that each fold is splitted 80-20 for training and evaluation, respectively.\\nCAPRI  = completely used to benchmark the trained model on BM5 with other software\\nMANY = 80-20 for training and evaluation respectively\\nDC = completely used for test purpose from the best model trained on MANY\",\n",
      "        \"matches_publication/authors\": \"Manon R\\u00e9au, Nicolas Renaud, Li C. Xue, Alexandre M. J. J. Bonvin \",\n",
      "        \"matches_publication/title\": \"DeepRank-GNN: a graph neural network framework to learn patterns in protein\\u2013protein interfaces\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"664234d0b30933003cc21777\",\n",
      "        \"shortid\": \"nit3xkdwep\",\n",
      "        \"uuid\": \"74d82093-c2cb-4840-8d8a-dc23995f7c82\",\n",
      "        \"created\": \"2024-05-13T15:42:08.260Z\",\n",
      "        \"updated\": \"2024-05-13T15:42:08.260Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"37204193\",\n",
      "        \"publication_authors\": \"Yidong Song, Qianmu Yuan, Sheng Chen, Ken Chen, Yaoqi Zhou and Yuedong Yang\",\n",
      "        \"publication_journal\": \"Briefings in Bioinformatics\",\n",
      "        \"publication_title\": \"Fast and accurate protein intrinsic disorder prediction by using a pretrained language model\",\n",
      "        \"publication_doi\": \"10.1093/bib/bbad173\",\n",
      "        \"publication_year\": \"2023\",\n",
      "        \"score\": 0.9,\n",
      "        \"matches_evaluation/comparison\": \"The model was compared with seven single-sequence-based methods (ESpritz-N, ESpritz-D, ESpritz-X, IUPred2A-short, IUPred2A-long and Spot-Disorder-Single) on DM1229 and SL329. \\nIn addition, it was compared to NetSurfP-3.0, which is based on ESM-1b language model. \",\n",
      "        \"matches_evaluation/measure\": \"Authors employed the area under the receiver operating characteristic curve (AUCROC), precision (Pr), sensitivity (Se), specificity (Sp), the area under the precision-recall curve (AUCPR), Matthews correlation coefficient (MCC), and the weighted score Sw (Sw = sensitivity + specificity \\u2013 1) to evaluate the performance of the model.\",\n",
      "        \"matches_evaluation/method\": \"Authors evaluated the model on a testing set of 1229 proteins (DM1229), in addition to four independent test datasets SL329, DisProt228,\\nMobi9230 and DisProt452.\",\n",
      "        \"matches_optimization/algorithm\": \"The model is comprised of transformer networks and a fully connected layer (ANN).\\nIt is not a novel algorithm.\",\n",
      "        \"matches_optimization/config\": \"The datasets, the source codes and the trained model are available on https://github.com/biomed-AI/LMDisorder.\",\n",
      "        \"matches_optimization/encoding\": \"First, the protein sequence is inputted into the pretrained language model ProtTrans to yield the sequence embedding, which is augmented by Gaussian noise to avoid overfitting.\",\n",
      "        \"matches_optimization/features\": \"Authors extracted the hidden states from the last layer of the ProtTrans encoder as sequence features, which is an n \\u00d7 1024 matrix (n is the sequence length).\",\n",
      "        \"matches_optimization/fitting\": \"The exact number of total parameters not reported. To rule out overfitting, early stopping was used with validation set and additionally, a dropout rate of 0.3 was applied.\",\n",
      "        \"matches_optimization/meta\": \"Yes, the model uses embeddings generated by unsupervised pretrained language models, namely ProtTrans (ProtT5-XL-U50) and ESM-1b.\",\n",
      "        \"matches_optimization/parameters\": \"The number of total parameters is not explicitly stated but authors reported following parameters:\\n2-layer transformer network\\n128 hidden units\\nHyperparameters: h = 4, \\u03b5 = 0.05\\nBatch size: 12\\nDropout rate: 0.3\\nAdam optimizer with learning rate of 3 \\u00d7 10^(-4)\\nBinary cross-entropy loss function\\nImplemented with PyTorch 1.7.1\\n\\np was selected through searching all hyperparameters through a grid search.\",\n",
      "        \"matches_optimization/regularization\": \" Yes, early stopping was used with validation set. Additionally, a dropout rate of 0.3 was applied.\",\n",
      "        \"matches_model/availability\": \"The datasets, the source codes and the trained model are available on https://github.com/biomed-AI/LMDisorder.\",\n",
      "        \"matches_model/duration\": \"For a protein with 500 residues it takes 1 second on an Nvidia GeForce RTX 3090 GPU.\",\n",
      "        \"matches_model/interpretability\": \"No mention was made on interpretability. The model appears to be a black box due to its complexity.\",\n",
      "        \"matches_model/output\": \"It is a binary classifier model.\",\n",
      "        \"matches_dataset/availability\": \"The datasets, the source codes and the trained model are available on https://github.com/biomed-AI/LMDisorder.\",\n",
      "        \"matches_dataset/provenance\": \"The dataset comprises 4229 protein sequences (DM4229), with 72 fully disordered chains from DisProt v5.0 and 4157 high-resolution X-ray crystallography structures from PDB.\\nAdditionally, there are also four independent test datasets: SL329, DisProt228, Mobi9230, and DisProt452,\",\n",
      "        \"matches_dataset/redundancy\": \"The datasets were split into training, validation, and testing sets randomly.\\nTo ensure independence between training and test sets, redundancy reduction was enforced by using a sequence similarity cutoff of <25%, as determined by BLASTClust.\",\n",
      "        \"matches_dataset/splits\": \"The training set consists of 2700 proteins, the validation set 300 proteins, and the testing set 1229 proteins (DM1229).\\nThere are also four independent test datasets: SL329, DisProt228, Mobi9230, and DisProt452.\",\n",
      "        \"matches_publication/authors\": \"Yidong Song, Qianmu Yuan, Sheng Chen, Ken Chen, Yaoqi Zhou and Yuedong Yang\",\n",
      "        \"matches_publication/journal\": \"Briefings in Bioinformatics\",\n",
      "        \"matches_publication/title\": \"Fast and accurate protein intrinsic disorder prediction by using a pretrained language model\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"666ca94f37ea6fa797a6c1f9\",\n",
      "        \"shortid\": \"31tebn1dq4\",\n",
      "        \"uuid\": \"5f5a87ee-e6b1-441d-a425-0abbc75bb322\",\n",
      "        \"created\": \"2024-06-14T20:34:23.344Z\",\n",
      "        \"updated\": \"2024-06-14T20:34:23.344Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"38015968\",\n",
      "        \"publication_authors\": \"Heidi J. Imker, Kenneth E. Schackart III, Ana-Maria Istrate & Charles E. Cook\",\n",
      "        \"publication_journal\": \"PLOS ONE\",\n",
      "        \"publication_title\": \"A machine learning-enabled open biodata resource inventory from the scientific literature\",\n",
      "        \"publication_doi\": \"10.1371/journal.pone.0294812\",\n",
      "        \"publication_year\": \"2023\",\n",
      "        \"score\": 1,\n",
      "        \"matches_evaluation/availability\": \"Yes - several supplmentary files well detail the evaluation. Code: https://zenodo.org/records/10105162 / \",\n",
      "        \"matches_evaluation/comparison\": \"Yes, a camparison to manually curated database regisrties was undertaken as deatailed in section 2.9.2 'Comparison with existing registries.' This utilised data from re3data.org and FAIRsharing regsitries using their APIs. Limitations of the benchmark datasets noted in the text.\\n\\nThis was not a simpler ML model baseline as this work was novel, but instead against manually curated datasets containing the same fields the model was extracting with NER.\\n\\nThe authors initially expected greater overlap with re3data.org and FAIRSharing, but only 536/3112 (17.2%) inventory resources were identified in these two registries; similarly, the majority of life science resources within both re3data (975/1189, 80.5%) and FAIRsharing (1161/1640, 70.8%) are not found in their inventory.\",\n",
      "        \"matches_evaluation/confidence\": \"Confidence scores used but not confidence interval ranges. The use of the models was novel and no comparable  method was deployed in the past to draw direct comparison to these ML methods. However, manual curator validation was used as a baseline as described in text: to determine a threshold probability of < 0.978 as \\u201clow-scoring,\\u201d where 0.978 was the average probability for names determined by a curator to have been correctly predicted in the 10% random sample of the 468 articles that were manually reviewed.\",\n",
      "        \"matches_evaluation/measure\": \"Both the perfomance of the article classification task and that of the NER task were measured to ensure best model performance.\\n\\nPre-trained BERT model selection for article classification: \\n-Performance measured to selected best BERT model for the NLP tasks. \\n-15 total evaluated and noted in table 3 (and cited)\\n-'S(upplementary)5 Table. Article classification' measures BERT model performance and documents this in relation to F1-score, Precision & Recall. \\n\\nPre-trained BERT model selection for NER model performance:\\n-Performance measured to selected best BERT model for the NER tasks.\\n-15 total evaluated and noted in table 3 (and cited)\\n-'S(upplementary)6 Table. NER model performance.' measure BERT model performance and documents this in relation to F1-score, Precision & Recall. \\n\\nMid way evaluation undertaken also to manually assess precision on a 10% random sample (n = 468) of the NER tasks. \",\n",
      "        \"matches_evaluation/method\": \"Independent dataset used for validation. 15% of whole dataset held out to validate the model performance.\",\n",
      "        \"matches_optimization/algorithm\": \"Two machine learning models described in the text were fine-tuned to automate the process of: \\n-1: classifying research articles \\n-2: extracting mentions of biodata resources from those predicted to describe a biodata resource\\n\\nThese were based on pre-trained BERT (Bidirectional Encoder Representations from Transformers) models.\\n\\nPre-trained BERT models leverage deep learning transformer architectures - neural networks utilised for NLP tasks. Not novel algorithm.\",\n",
      "        \"matches_optimization/config\": \"Hyperparameters detailed in 'S4 Table. Hyperparameters used for model fine-tuning for article classification and NER tasks.' - Zenodo PDF: https://doi.org/10.1371/journal.pone.0294812.s008\",\n",
      "        \"matches_optimization/encoding\": \"Data was preprocessed for use by the pre-trained BERT models independently by two curators. Article titles and abstracts were reviewed to classify them as either describing a biodata resource (pos) or not describing a biodata resource(neg). Text strings were tokenized for BERT models using specific BERT tokenizers described in text.\",\n",
      "        \"matches_optimization/features\": \"Not applicable as pre-trained BERT models were used. These do not use a single set of features that you directly extract and feed into the model like traditional machine learning methods. BERT learns features based on the pre-training it was subject to. \\n\\nRelated info on tokenization described above with regards to BERT model input features during the model fine tuning and training for its two tasks NER and classification.\",\n",
      "        \"matches_optimization/fitting\": \"Exact p and f unkown and not detailed in text due to pre-trained BERT models in used. However, the authors used early stopping, a validation set, pre-trained BERT models with cross-comparison across 15 of these, and reported good performance on unseen test data. This in total contributes to a strong likelihood that the authors effectively addressed both overfitting and underfitting concerns. \",\n",
      "        \"matches_optimization/meta\": \"No - data is sourced from direct Europe PMC API query of data as detailed in text, and is not inputting meta-predictions to the models.\",\n",
      "        \"matches_optimization/parameters\": \"Number of parameters (p) are used in the model?: \\n-Not directly mentioned but findable based on the BERT model types being well detailed. \\n-Pre-trained BERT models were used, so model parameters not directly detailed in text as a result but can be found from: Hugging Face Library (https://huggingface.co/docs/transformers/en/index) where you can find the number of parameters for a pre-trained model by using the model.config.num_parameters() function.\\n\\nHyperparameters detailed in 'S4 Table. Hyperparameters used for model fine-tuning for article classification and NER tasks.'\",\n",
      "        \"matches_optimization/regularization\": \"Yes - overfitting prevention techniques were employed.  Early stopping was undertaken using a validation set. Max of 10 epochs but early stopping and use of highest precision.\",\n",
      "        \"matches_model/availability\": \"Source code available: Yes - https://zenodo.org/records/10105162. Algorithms and models can be run using the 2x Snakemake reusable pipelines and also an iPython notebook (ipynb) file is available for use Google Colab/other notebook deployment platforms. \",\n",
      "        \"matches_model/duration\": \"The text directly references computational need for a GPU to re-run the model training. They do not make exact/estimate statements referring to execution times but explictly state a Google Colab instance with a GPU utlising their iPython notebooks (ipynb) provided would be sufficient. This would indicate a desktop equipped with a GPU would suffice rather than there being a requirement for access to HPC resources and several GPUs. To run  \\n\\nPotentially this information is more explicitly noted in the well documented supplementary materials code release: https://zenodo.org/records/10105162.\",\n",
      "        \"matches_model/interpretability\": \"Highly interpretable - the authors made expert efforts to avoid having a black box model publication. For example all code and data & configs, etc are all available on Zenodo repository and expertly documented for ease of interpretability: https://zenodo.org/records/10105162. All test and training data available and clear, linked from text to relevant repositories. Explicit study design noted in text to have been created with open science and reproducibility in mind.\",\n",
      "        \"matches_model/output\": \"Classification model \",\n",
      "        \"matches_dataset/availability\": \"Yes, all the data in the dataset that was used has been documented in the Zenodo repository. The original source literature dataset remains available in the Europe PMC database. Biodata Resource Inventory Code Release: https://zenodo.org/records/10105162\\n\\nEPMC database: https://europepmc.org/\\n\\nEPMC licensing policy: https://plus.europepmc.org/user-guide#Licensing_policies\",\n",
      "        \"matches_dataset/provenance\": \"Data source: Europe PMC - a database for depositing life science literature was the primary data source for the study.  \\n\\nThe life science literature used was: titles and correpsonding abstracts.\\n\\nDataset community recognition: this was not an established dataset but created for the purpose of this study using a subset of literature data available in Europe PMC.\\n\\nNpos/Nneg info: the study kept the entries where two curators agreed on the article classification label \\n-Total positive or negative, n = 1,587\\n-Total positive: 478\\n-Total negative: 1,109\",\n",
      "        \"matches_dataset/redundancy\": \"Test and training sets were independent.\\n\\nDistribution of whole data set: 70% training, 15% validation, 15% test. This aligns to general reccomended redundancy splits for ML model training, fine tuning and evaluation uses.\\n\",\n",
      "        \"matches_dataset/splits\": \"Whole data set:\\n1634 literature records total. This was reduced to 1,587 (data points were kept from origianl 1,634 where 2x curators agreed on classification of pos/neg)\\nThese were dsitributed into: 70% training, 15% validation, 15% test (hold-out).\\n\\nData points - breakdown of the initial 1,587 items of literature data collected:\\n-Training set: 1,110 data points\\n-Test set: 239 data points (+ 238 validation data points)\\n\\nWas a separate validation set used, and if yes, how large was it?: yes, validation set used = 238 data points\\n\\nAre the distributions of data types in both training and test sets plotted?: no - but data cleaning done through curator validation on all npos/nneg idenitfied.\\n\\nThe above information on the data splits can be viewed in an overview table in the paper: Table 1. Training dataset splits for the article classification task - https://doi.org/10.1371/journal.pone.0294812.t001\",\n",
      "        \"matches_publication/authors\": \"Heidi J. Imker, Kenneth E. Schackart III, Ana-Maria Istrate & Charles E. Cook\",\n",
      "        \"matches_publication/journal\": \"PLOS ONE\",\n",
      "        \"matches_publication/title\": \"A machine learning-enabled open biodata resource inventory from the scientific literature\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"666f4a9e37ea6fa797a6c20d\",\n",
      "        \"shortid\": \"hipgaatgji\",\n",
      "        \"uuid\": \"e9d0a4a1-31d9-4782-937b-885197f55f14\",\n",
      "        \"created\": \"2024-06-16T20:27:10.713Z\",\n",
      "        \"updated\": \"2024-06-16T20:27:10.713Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"37126495\",\n",
      "        \"publication_authors\": \"Olga Mineeva, Daniel Danciu, Bernhard Sch\\u00f6lkopf, Ruth E. Ley, Gunnar R\\u00e4tsch, and Nicholas D. Youngblut\",\n",
      "        \"publication_journal\": \"PLOS Computational Biology\",\n",
      "        \"publication_title\": \"ResMiCo: Increasing the quality of metagenome-assembled genomes with deep learning\",\n",
      "        \"publication_doi\": \"https://doi.org/10.1371/journal.pcbi.1011001\",\n",
      "        \"publication_year\": \"2023\",\n",
      "        \"score\": 0.95,\n",
      "        \"matches_evaluation/availability\": \"Large degree of the evaluation is noted throughout the text & figures or in S1 - Supplementary Material ResMiCo: increasing the quality of metagenome-assembled genomes with deep learning (https://journals.plos.org/ploscompbiol/article/file?type=supplementary&id=10.1371/journal.pcbi.1011001.s001). Statistical code for evaluation not clearly avaialble linked from text or within shared GitHub repository.\",\n",
      "        \"matches_evaluation/comparison\": \"The model was compared to other state of the art models for this prediction task:\\n-metaMIC  \\n-DeepMAsED  \\n-ALE \\n\\nThe model was also compared to various benchmark datasets:\\n-CAMI datasets (gut, oral, skin)\\n-Mock communities (BMock12, MBARC-26)\",\n",
      "        \"matches_evaluation/confidence\": \"Confidence intervals are not explictly mentioned in the text. If taking the other models as the baseline for camparison the reported AUPRC & AUROC are noted to outperform these throughout the text. More information for the confidence would be useful beyond comparisons already noted for the datasets and other models.\",\n",
      "        \"matches_evaluation/measure\": \"Various model performances measure metrics were reported in the text eg:\\n-Area Under the Precision-Recall Curve (AUPRC)\\n-Area Under the ROC Curve (AUROC)\\n-Precision and Recall\",\n",
      "        \"matches_evaluation/method\": \"Independent datasets were used to evalaute the model. \\nFor example the text notes that two CAMI datasets that simulate non-human biomes: CAMI-marine and CAMI-plant-associated were used to evaluate the model and corresponding AUPRC & AUROC shared.\",\n",
      "        \"matches_optimization/algorithm\": \"Deep Residual Neural Network (ResNet) \\n-Not a new algorithm \",\n",
      "        \"matches_optimization/config\": \"The list of optimised hyperparameters and the attempted values are provided in Table B in S1 Text. (https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011001#pcbi.1011001.s001). Unclear if further information available and this is unlikely based on the GitHub which is functionally in place to share reuse of the model vs considerations of sharing precise configuration information.  \",\n",
      "        \"matches_optimization/encoding\": \"Data encoding (0-1) detailed in supplemetary data 'Table A. The full list of positional features computed by ResMiCo pipeline'. The fifth column states preprocessing applied to the features of the table as used for the data encoding for the model: standardisation (Std), normalisation (Nrm), and one-hot encoding (Onh).\",\n",
      "        \"matches_optimization/features\": \"14 features as noted in 'Fig 3. Feature ranked by their importance.'.\\n\\nFeature selection was performed and noted in a dedicated paper subsection. \",\n",
      "        \"matches_optimization/fitting\": \"Yes, p much larger than number of training points. Trainable Parameters (559,441) vs. Features (14).\",\n",
      "        \"matches_optimization/parameters\": \"ResMiCo model has 562,573 parameters, of which 559,441 are trainable.\",\n",
      "        \"matches_optimization/regularization\": \"Early stopping likely used based on text information but not explicitly written in the text. Class imbalance handling and data augmentation approaches also noted in the text which can help prevent overfitting a model.\",\n",
      "        \"matches_model/availability\": \"Main ResMiCo GitHub (python package and snakemake pipeline): https://github.com/leylabmpi/ResMiCo - MIT license. Dataset simulation pipeline used available in Snakemake: https://doi.org/10.1093/bioinformatics/bts480 . Dockerfiles noted in the repo but no VMs/web server. Direct pip install possible from a command line and information in GitHub software repo but limitations noted for incompatibility with apple Mac machines due to chipset.  \",\n",
      "        \"matches_model/duration\": \"There is a section dedicated to benchmarking the ResMiCo model resource requirements in the materials and methods.\\n-Using the CAMI gut dataset, ResMiCo ran > 2x faster with a GPU versus a CPU (108 \\u00b1 0.7 versus 38.7 \\u00b1 10.3 contigs per second).\\n-They further note the reccomendation to use multiple GPUs for training the model on larger datasets.\\n-While it is feasible to run the model with a CPU, this is at a much slower rate: 140,000 contigs in 1 hour with a single CPU.\",\n",
      "        \"matches_model/interpretability\": \"Moderately interpretable. GitHub available with model code & datasets hosted online. Important info detailed in paper but not precisely straight forward on all aspects. Tutorials available which are helpful to reuse the model: https://github.com/leylabmpi/ResMiCo/wiki/ResMiCo-SM-tutorial. However, this is a lightweight tutorial page and more information could be provided given the complex nature of the model used. More clarity around the large number of datasets mentioned in the evaluation would be helpful.\",\n",
      "        \"matches_dataset/availability\": \"Yes - data available: http://ftp.tue.mpg.de/ebio/projects/ResMiCo/\\nThis is on the: MPI for Biology FTP server, author noted choice due to size of datasets.\",\n",
      "        \"matches_dataset/provenance\": \"An existing database was the primary source of the data - Release 202 of the Genome Taxonomy Database (GTDB).\\n-18,000 reference genomes from the database were selected for further use.\\n-From this database the authors created a synthetic dataset comprised of bacterial and archaeal genomes with the simulation software 'Metagenome read simulation of multiple synthetic communities' (https://github.com/nick-youngblut/MGSIM).\\n-Illumina ART read simulator was used to generate paired-end Illumina reads of length 100 or 150 using either the default \\u201cIllumina HiSeq 2500\\u201d error profile or the \\u201cHiSeq2500L150R1/2\\u201d error profile used in CAMISIM.\\n-Information detailed with parameters of the simulation in 'Table 1. Parameter values used in the simulation pipeline.'\",\n",
      "        \"matches_dataset/redundancy\": \"The sets were split from the original 18,000 using a family taxonomic level split to divide these into training and test.\\n\\nFor redundancy reduction, max 50 genomes per species were included to avoid overfitting.\\n\\nRandom genome selection was used to divide the test and training in alignment with the 50 genomes max per species. \\n\\n\",\n",
      "        \"matches_dataset/splits\": \"18,000 total reference genomes selected from GTDB. Of these:\\n-Test: 9000 reference genomes used \\n-Training: 9000 reference genomes used\\n\\n10% of the training dataset was used as a validation set for the model selection.\",\n",
      "        \"matches_publication/authors\": \"Olga Mineeva, Daniel Danciu, Bernhard Sch\\u00f6lkopf, Ruth E. Ley, Gunnar R\\u00e4tsch, and Nicholas D. Youngblut\",\n",
      "        \"matches_publication/journal\": \"PLOS Computational Biology\",\n",
      "        \"matches_publication/title\": \"ResMiCo: Increasing the quality of metagenome-assembled genomes with deep learning\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"6670865737ea6fa797a6c28a\",\n",
      "        \"shortid\": \"3cfsqm95ys\",\n",
      "        \"uuid\": \"3badf5a7-cfb0-4138-813b-299c482e3bf4\",\n",
      "        \"created\": \"2024-06-17T18:54:15.621Z\",\n",
      "        \"updated\": \"2024-06-17T18:54:15.621Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"37971967\",\n",
      "        \"publication_authors\": \"Ananthan Nambiar, Veronika Dubinkina, Simon Liu, and Sergei Maslov\",\n",
      "        \"publication_journal\": \"PLOS Computational Biology\",\n",
      "        \"publication_title\": \"FUN-PROSE: A deep learning approach to predict condition-specific gene expression in fungi\",\n",
      "        \"publication_doi\": \"10.1371/journal.pcbi.1011563\",\n",
      "        \"publication_year\": \"2023\",\n",
      "        \"score\": 0.9,\n",
      "        \"matches_evaluation/availability\": \"Not available based on text, evaluation not heavily focused on in text.\",\n",
      "        \"matches_evaluation/comparison\": \"The evaluation of the model performance seems to be against that of the 3x distinct datasets used for the study to create the model.\\n-S. cerevisiae dataset (noted under data section)\\n-N. crassa dataset (noted under data section)\\n-I. orientalis dataset (noted under data section)\\n\\nNo other models cross compared or simpler baseline to evaluate the model. Poorly described evaluation.\",\n",
      "        \"matches_evaluation/measure\": \"Pearson correlation coefficient reported for model use across the 3x datasets used:\\n-0.85 for S. cerevisiae\\n-0.72 for N. crassa\\n-0.81 for I. orientalis\\n\\nNot many other performance measures in the text/supplementary files. \",\n",
      "        \"matches_evaluation/method\": \"Independent data sets used to evaluate FUN-PROSE model.\\n\\nThe authors noted use of several previously published RNA-seq datasets for different fungal species to evaluate the model. Although, this is contradictory as it seems these 3x datasets were used to create the model in the first place. Somewhat unclear the barriers between create the model and datasets used to evaluate the model.\",\n",
      "        \"matches_optimization/algorithm\": \"Convolutional neural network (CNN) - not a new algorithm.\\n-Composed of two convolutional layers\",\n",
      "        \"matches_optimization/config\": \"Hyperparameters described directly in a subsection of the paper: 'Hyperparameter optimization and model training'. This does not have exact hyperparameter configurations, optimization schedule, model files, and optimization parameters reported. However, certain GitHub files in the code repo seem to contain further hyperparameter information such as 'hyperparameter-search.py' (https://github.com/maslov-group/FUN-PROSE/blob/main/hyperparameter-search.py) \",\n",
      "        \"matches_optimization/encoding\": \"Data sources and preprocessing subsection includes info on the utisation of log-transformed RNA-seq expression levels and also the use of one-hot encoded promoter sequences later in other sections.\",\n",
      "        \"matches_optimization/features\": \"Not explicitly noted in the text.\\n\\n256 convolutional filters noted, therefore likely hundreds/thousands of features in the model as there is potential for multiple features to be extracted per filter.\",\n",
      "        \"matches_optimization/fitting\": \"Fitting poorly described. Unknown parameters vs features from text - cannot determine exact figures for these. Fitting not touched on in the text at all. Only comparisons of pearson correlations across use in different datasets.\",\n",
      "        \"matches_optimization/parameters\": \"Specific CNN layer parameters are noted to be described in table 1 - but primarily hyperparameters instead are actually in the table.\\n-Titled 'Table 1.  Configuration search space for hyperparameter optimization and best hyperparameters identified in the space.'\\n-Parameters of the model partially described and it does not seem as if the weights/biases etc are included in one of the many figures/tables clearly. Cannot determine accurate number from text or their selection. \",\n",
      "        \"matches_optimization/regularization\": \"Early stopping was performed: 60 epochs and training was stopped early if the validation correlation coefficient did not improve for 5 epochs in a row.\",\n",
      "        \"matches_model/availability\": \"GitHub repository: https://github.com/maslov-group/FUN-PROSE. Primarily in python and jupyter notebooks. No containers present in the repo or other run method support/variations. \",\n",
      "        \"matches_model/duration\": \"Text notes models were trained on an NVIDIA V100 GPU with 16GB of RAM using automatic mixed-precision training. \\nAlso further notes that there was model training on a NVIDIA GeForce GTX 1080 Ti GPU.\\n\\nExecution time metrics not stated in text.\",\n",
      "        \"matches_model/interpretability\": \"Not very interpretable - comes across as a black box from the text and formatting. The datasets used are confusing and poorly described eg: hosted in Google drive, and from cited publications. Three different fungi species were used for creating the model and not very accessible without combing trhough the text to understand the underlying RNA-seq data within each of these or their splits/data points. No clear tables to detail the splits of test/training/validation although some percents provided. Almost 20 figures in the paper when including supplementary data and very divided information points across the whole paper.  Parameters and features of the model poorly described and very little info on the fitting/evalution of the model.\",\n",
      "        \"matches_dataset/availability\": \"Preprocessed data linked in a Google drive: https://drive.google.com/drive/folders/19K5DxFVpjozpd1rKnBvZZzDmnPp1-Ldw & also off of the main GitHub (https://github.com/maslov-group/FUN-PROSE/blob/main/README.md).\",\n",
      "        \"matches_dataset/provenance\": \"3x RNA-seq datasets used:\\n1. RNA-seq data on N. crassa (wild type and gene-deletion mutants) growing on different carbon sources [44]\\n2. S. cerevisiae RNA-seq data for 28 analog sensitive kinase alleles across 12 different conditions (stresses and different media) [45]\\n3. I. orientalis RNA-seq data for growth in different media conditions (YPD+glucose and lignocellulosic extracts) [45]\\n\\nCorresponding datasets from publications cited in the text:\\n[44.] Wu VW, Thieme N, Huberman LB, Dietschmann A, Kowbel DJ, Lee J, et al. The regulatory and transcriptional landscape associated with carbon utilization in a filamentous fungus. Proceedings of the National Academy of Sciences. 2020;117(11):6003\\u20136013.\\n\\n[45.] Mace K, Krakowiak J, El-Samad H, Pincus D. Multi-kinase control of environmental stress responsive transcription. PloS one. 2020;15(3):e0230246. pmid:32160258\\nView ArticlePubMed/NCBIGoogle Scholar\",\n",
      "        \"matches_dataset/redundancy\": \"Gene condition splits for each of the 3x different data sets corresponding to each of the fungi species are noted as:\\n-70 % training\\n-10% validation \\n-20% test  \\n\\nModel seems to have been trained on each of the 3x corresponding data sets which contains RNA-seq expression data under different conditions. \",\n",
      "        \"matches_dataset/splits\": \"Three different datasets divided into train/test set splits for use in creating the model, each described in supplementary figures 1-3:\\n1. S1 Fig. Vizualizing the Saccharomyces cerevisiae dataset.\\n2. S2 Fig. Vizualizing the Neurospora crassa dataset.\\n3. S3 Fig. Vizualizing the Issatchenkia orientalis dataset.\\n\\nAuthor's first split the gene-condition data into train, validation and test sets by randomly withholding 10% of the elements for the validation set and 20% for the test set.\\n\\nDifficult to discern exact training and test set data points from the text and figures relating to the publication. It appears that relating to each dataset there are:\\nS. cerevisiae = 6645 genes\\nN. crassa = 9725 genes\\nI. orientalis = 4925 genes \\nHowever, it is not very clear.\",\n",
      "        \"matches_publication/authors\": \"Ananthan Nambiar, Veronika Dubinkina, Simon Liu, and Sergei Maslov\",\n",
      "        \"matches_publication/journal\": \"PLOS Computational Biology\",\n",
      "        \"matches_publication/title\": \"FUN-PROSE: A deep learning approach to predict condition-specific gene expression in fungi\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e363261d57eb8bca695a3\",\n",
      "        \"shortid\": \"bgldxl71jp\",\n",
      "        \"uuid\": \"8ac43578-356a-49dc-a0a1-f2bfd3a887e0\",\n",
      "        \"created\": \"2024-10-15T09:30:26.463Z\",\n",
      "        \"updated\": \"2024-10-15T09:30:26.463Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_title\": \"MuLan-Methyl\\u2014multiple transformer-based language models for accurate DNA methylation prediction\",\n",
      "        \"publication_authors\": \"Wenhuan Zeng, Anupam Gautam, Daniel H Huson\",\n",
      "        \"publication_journal\": \"GigaScience\",\n",
      "        \"publication_year\": \"2023\",\n",
      "        \"publication_pmid\": \"37489753\",\n",
      "        \"publication_doi\": \"https://doi.org/10.1093/gigascience/giad054\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 6,\n",
      "        \"score\": 0.78,\n",
      "        \"matches_evaluation/method\": \"We evaluated MuLan-Methyl on the iDNA-MS independent test dataset.\",\n",
      "        \"matches_evaluation/measure\": \"MuLan-Methyl is evaluated by the following evaluation metrics: AUC, Accuracy, F1-score, Recall, and AUPR.\\n\",\n",
      "        \"matches_evaluation/comparison\": \"Yes, MuLan-Methyl is compared with iDNA-ABF and iDNA-ABT on the iDNA-MS independent dataset, MuLan-Methyl outperforms 13 out of 17 sub-dataset.\",\n",
      "        \"matches_evaluation/confidence\": \"Performance metrics of our study doesn't have confidence intervals.\",\n",
      "        \"matches_evaluation/availability\": \"Yes, it's available in the MuLan-Methyl manuscript and its supplementary files.\",\n",
      "        \"matches_optimization/algorithm\": \"MuLan-Methyl is an ensemble framework consists of five transformer-based language models.\\n\",\n",
      "        \"matches_optimization/meta\": \"The model doesn't use data from other ML algorithms as input.\",\n",
      "        \"matches_optimization/config\": \"Yes, all the hyper-parameters are reported in MuLan-Methyl manuscript and its corresponding Github repository(https://github.com/husonlab/mulan-methyl).\",\n",
      "        \"matches_optimization/encoding\": \"The input of MuLan-Methyl is processed by converting each sample' DNA sequences and its taxonomic lineages into a description. Each processed sample is further encoded by tokenizer of each language models.\",\n",
      "        \"matches_optimization/features\": \"Two features of each sample are used as input, one is sample's DNA sequence, another is its taxonomic lineage. No feature selection is performed.\",\n",
      "        \"matches_optimization/fitting\": \"p is much larger than f, Overfitting is ruled out since the loss value of both training process and validation process has similar changing trends.\",\n",
      "        \"matches_optimization/parameters\": \"Here is the models' parameter:\\nModel Number of parameters\\nMuLan-Methyl-BERT 105,242,882\\nMuLan-Methyl-DistilBERT 62,714,114\\nMuLan-Methyl-ALBERT 11,045,122\\nMuLan-Methyl-XLNet 111,934,466\\nMuLan-Methyl-ELECTRA 29,336,578\",\n",
      "        \"matches_optimization/regularization\": \"Yes, early stopping on validation dataset is conducted for preventing overfitting.\",\n",
      "        \"matches_model/interpretability\": \"MuLan-Methyl is interpretable by utilizing the self-attention mechanism of transformer architecture. For example, attention score assigned to each tokens of each sample which predicted positive are used to discover methylation motifs.\",\n",
      "        \"matches_model/output\": \"It's classification model.\",\n",
      "        \"matches_model/duration\": \"In average one second.\",\n",
      "        \"matches_model/availability\": \"The source code is released (https://github.com/husonlab/mulan-methyl). A web server implementing the MuLan-Methyl approach is freely accessible at http://ab.cs.uni-tuebingen.de/software/mulan-methyl/.\",\n",
      "        \"matches_dataset/provenance\": \"Data source: iDNA-MS (Lv, Hao, et al. \\\"iDNA-MS: an integrated computational tool for detecting DNA modification sites in multiple genomes.\\\" Iscience 23.4 (2020): 100991.)\\nData are in classes,the data statistics for positive samples and negative samples in both training dataset and test dataset can be found in supplementary file of published paper.\\n\",\n",
      "        \"matches_dataset/splits\": \"The ratio of training and test set is 1:1.\\nValidation set is generated by sampling 20% training dataset.\\nThe distribution of data types in the training and test sets is same.\",\n",
      "        \"matches_dataset/redundancy\": \"The training and test set are split by iDNA-MS, they are independent.\\n\",\n",
      "        \"matches_dataset/availability\": \"Data are public, can be obtained from iDNA-MS(http://lin-group.cn/server/iDNA-MS/), as well as MuLan-Methyl(https://github.com/husonlab/mulan-methyl).\",\n",
      "        \"matches_publication/title\": \"MuLan-Methyl\\u2014multiple transformer-based language models for accurate DNA methylation prediction\",\n",
      "        \"matches_publication/authors\": \"Wenhuan Zeng, Anupam Gautam, Daniel H Huson\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e389461d57eb8bca695c1\",\n",
      "        \"shortid\": \"zg83kd0vmv\",\n",
      "        \"uuid\": \"3cd05870-401b-496e-9b88-edc18d906026\",\n",
      "        \"created\": \"2024-10-15T09:40:36.120Z\",\n",
      "        \"updated\": \"2024-10-15T09:40:36.120Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_title\": \"KGML-xDTD: a knowledge graph\\u2013based machine learning framework for drug treatment prediction and mechanism description \",\n",
      "        \"publication_authors\": \"Chunyu Ma, Zhihan Zhou, Han Liu, David Koslicki\",\n",
      "        \"publication_journal\": \"GigaScience\",\n",
      "        \"publication_year\": \"2023\",\n",
      "        \"publication_pmid\": \"37602759\",\n",
      "        \"publication_doi\": \"10.1093/gigascience/giad057\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 6,\n",
      "        \"score\": 0.78,\n",
      "        \"matches_evaluation/method\": \"The model is evaluated based on an independent test set.\",\n",
      "        \"matches_evaluation/measure\": \"The accuracy, Macro F1 score, MRR, Hit@K are reported as performance metrics, They are all common evaluation metrics used for the goal of drug repurposing prediction based on the biomedical knowledge graph.\",\n",
      "        \"matches_evaluation/comparison\": \"The KGML-xDTD has been compared with the comprehensive start-of-the-art ML/DL models based on the same dataset we collected from four public datasets mentioned in the Data Chapter.\",\n",
      "        \"matches_evaluation/confidence\": \"For the ranking metrics (e.g., MRR and Hit@K), we generate 10 sets of random drug-disease pairs (each with 1,000 pairs) independently and calculate the mean and standard deviation of the ranking-based metrics outcomes, which are superior to other baselines. \",\n",
      "        \"matches_evaluation/availability\": \"If you follow the evaluation instruction on Github: https://github.com/chunyuma/KGML-xDTD, you can easily reproduce the evaluation results reported in the paper.\",\n",
      "        \"matches_optimization/algorithm\": \"The KGML-xDTD model framework of two modules: a drug repurposing prediction (DRP) module that combines the advantages of GraphSAGE and a Random Forest model, and a Mechanism of Action (MOA) prediction module that utilizes an adversarial actor-critic reinforcement learning (RL) model. \\n\\nThis model framework combines the existing start-of-the-art models with the biologically meaningful \\\"demonstration paths\\\", and achieves better performance than the known alternatives.\",\n",
      "        \"matches_optimization/meta\": \"No, the model uses the training data that are collected by ourselves. The training data is independent of the test data.\",\n",
      "        \"matches_optimization/config\": \"Yes, they are reported in the supplemenatary material in the paper.\",\n",
      "        \"matches_optimization/encoding\": \"Each node in the biomedical knowledge graph is encoded into 512 numeric embedding through the PubMedBERT model and GraphSage. For each drug-disease pair, their embeddings are concatenated and used as input for a Random Forest model to predict drug repurposing.\",\n",
      "        \"matches_optimization/features\": \"The knowledge graph node features are generated via the PubMedBERT model and GraphSage. The dimension of each node feature embedding is 512. There is no manual feature selection needed for this case. The random forest model selects the features by itself. Yes, the model selection via random forest is performed using the training set only.\",\n",
      "        \"matches_optimization/fitting\": \"The training data is larger than p but the underfitting problem was ruled out via the setting of using maximum depth of 35 and the number of tress of 200 in the random forest.\",\n",
      "        \"matches_optimization/parameters\": \"There are 9 hyper-parameters used in unsupervised GraphSAGE embedding training which are selected manually while 2 hyper-parameters are used in the random forest which are selected via grid search algorithm.  The remaining hyper-parameters are set to default values.\",\n",
      "        \"matches_optimization/regularization\": \"There are a few overfitting prevention techniques used in the KGML-xDTD model which includes subsampling and feature selection by the random forest model, early stopping using a validation set in the reinforcement learning model.\",\n",
      "        \"matches_model/interpretability\": \"The model itself is a black box but we utilize a novel knowledge-graph path-based method to explain the drug repurposing prediction result.\",\n",
      "        \"matches_model/output\": \"The model is classification.\",\n",
      "        \"matches_model/duration\": \"A single representative prediction ran on a desktop PC needs only 409 ms.\",\n",
      "        \"matches_model/availability\": \"Yes, the source code released on Github: https://github.com/chunyuma/KGML-xDTD with the MIT license. Please follow the instruction on the GitHub to download and run the executable model.\",\n",
      "        \"matches_dataset/provenance\": \"The data (drug-disease pairs) used for training our KGML-xDTD model were collected from four high-quality and NLP-derived data sources: MyChem Data, SemMedDB Data, NDF-RT Data, and RepoDB Data. All of these are public datasets; please see a more detailed description in our paper \\\"KGML-xDTD: A Knowledge Graph-based Machine Learning Framework for Drug Treatment Prediction and Mechanism Description\\\".\\n\\nThe data are categorized into classes, with 21,437 positive cases and 33,189 negative cases.\\n\\nThe data are in classes\\n  \",\n",
      "        \"matches_dataset/splits\": \"They are 26,552 negative cases and 17,149 positive cases in the training set.\\nThere are 3,318 negative cases and 2,143 positive cases in the validation set.\\nThere are 3,319 negative cases and 2,145 positive cases in the validation set.\\n\\nThe drug class distribution in the training set and test set are similar. We plotted their distribution in Figure 7. in the paper.\",\n",
      "        \"matches_dataset/redundancy\": \"We split the data into training, validation, and test sets where the drug-disease pairs of each unique drug are randomly split according to a ratio of 8:1:1. For example, let\\u2019s say drugA has 10 known diseases that it treats (e.g., drugA-disease1, . . . , drugA-disease10), 8 pairs are randomly split into the training set, 1 pair is to the validation set, 1 pair to the test set. \\n\\nThe drug-disease pairs in the training set and test set are independent, with no overlap. \\n\\nThere is no such drug class distribution analysis reported in the previous dataset that is similar to ours.\\n\\n\\n\",\n",
      "        \"matches_dataset/availability\": \"These data are released in the Zenodo public repository: https://zenodo.org/record/7582233 with a license CC0 1.0.\",\n",
      "        \"matches_publication/title\": \"KGML-xDTD: a knowledge graph\\u2013based machine learning framework for drug treatment prediction and mechanism description \",\n",
      "        \"matches_publication/authors\": \"Chunyu Ma, Zhihan Zhou, Han Liu, David Koslicki\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e39e161d57eb8bca695c5\",\n",
      "        \"shortid\": \"1scfw6g7s4\",\n",
      "        \"uuid\": \"4a182f3e-96e9-4a16-9429-878ae0565956\",\n",
      "        \"created\": \"2024-10-15T09:46:09.031Z\",\n",
      "        \"updated\": \"2024-10-15T09:46:09.031Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_title\": \"Confound-leakage: confound removal in machine learning leads to leakage\",\n",
      "        \"publication_authors\": \"Sami Hamdan, Bradley C Love, Georg G von Polier, Susanne Weis, Holger Schwender, Simon B Eickhoff, Kaustubh R Patil\",\n",
      "        \"publication_journal\": \"GigaScience\",\n",
      "        \"publication_year\": \"2023\",\n",
      "        \"publication_pmid\": \"37776368\",\n",
      "        \"publication_doi\": \"10.1093/gigascience/giad071\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 6,\n",
      "        \"score\": 0.78,\n",
      "        \"matches_evaluation/method\": \"We employed nested cross validation scheme. Train/test split (or simulating new out-of-sample data) was performed only in simulated data or examples and was used to aid understanding of the concepts and results presented in the paper.\",\n",
      "        \"matches_evaluation/measure\": \"We report predictive r\\u00b2 for regression tasks and AUCROC for classification tasks. They are representative of what is common and reommended in the literature.\",\n",
      "        \"matches_evaluation/comparison\": \"We compare the performance of each ML algorithm with and without confound removal. We do not make any claims of performing better on the data than other algorithms. Still, we included a baseline model (dummy classifier/regressor) to evaluate performance not informed by the feature target relationship.\",\n",
      "        \"matches_evaluation/confidence\": \"We report statistically meaningful results using the Bayesian ROPE approach. We also add standard deviations over repeats which could convey similar information as confidence intervals.\",\n",
      "        \"matches_evaluation/availability\": \"The code is available here: https://github.com/juaml/ConfoundLeakage under GNU Affero General Public License v3.0\",\n",
      "        \"matches_optimization/algorithm\": \"We only used the following standard ML algorithms. \\n1) Linear/Logistic Regression \\n2) Support Vector Machine with RBF kernel\\n3) Support Vector Machine with linear kernel\\n4) Decision Tree\\n5) Random Forests\\n6) Multi Layer Perceptron\\n7) Dummy/Baseline Model\\n\",\n",
      "        \"matches_optimization/meta\": \"The input to our models is only the available features and no meta-predictions were used.\",\n",
      "        \"matches_optimization/config\": \"URL: https://github.com/juaml/ConfoundLeakage/blob/main/leakconfound/leakconfound/experiments/helper_func.py. License: GNU Affero General Public License v3.0\",\n",
      "        \"matches_optimization/encoding\": \"Categorical features were one-hot encoded.  All continuous features were z-score standardized. Depending on the experimental condition we performed confound removal using confound regression with or without shuffling the features. All preprocessing steps were cross-validation consistent to avoid any data leakage.\",\n",
      "        \"matches_optimization/features\": \"No feature selection was used. \\nFor the restricted data we followed instructions given by von Polier to follow best practices described in von Polier et al. 2021.\\nList of Feature numbers:\\n1) Income (Adult) f=14\\n2) Bank Marketing f=20\\n3) Heart f=13\\n4) Blood Transfusion f=4\\n5) Breast Cancer f=10\\n6) Student Performance f=30\\n7) Abalone  f=8\\n8) Concrete Compressive Strength f=8\\n9) Residential Building f=107\\n10) Real Estate f=6\\n11) real-world clinical dataset f=616\",\n",
      "        \"matches_optimization/fitting\": \"We observe the same behavior for different datasets with different n/p reatios. Only the real world clinical dataset had p>n. Still we observe the same behaviour over different models as in the other datasets. We explicitly focused in CV for generalization estimates and did not analyse over- or under-fitting.\",\n",
      "        \"matches_optimization/parameters\": \"The parameters of the models were according the corresponding model class as defined in sci-kit learn library.\\nThe hyperparameters were selected using a grid-search within a nested cross-validation scheme. \\nHere is a list of hyperparameters to chose from given the used ML algorithm: \\n1) Logistic Regression : max_iter=100000, c=np.geomspace(1e-2, 1e2, 25)\\n2) RBF Support Vector Machine : c=np.geomspace(1e-2, 1e2, 25)\\n3) Linear Support Vector Machine:c=np.geomspace(1e-2, 1e2, 25), max_iter = 1000\\n4) Decision Tree: None\\n5) Random Forest : n_estimators=500\\n6) Multi Layered Perceptron : hidden_layer_size= [[32], [64], [128], [256]] (max_iter = 100000 for classification)\\n7) Dummy/Baseline Model: strategy='mean' for regression and strategy='prior' for classification\",\n",
      "        \"matches_optimization/regularization\": \"As we used nested cross-validation we can rule out overoptimistic final results with a reasonable confidence. \",\n",
      "        \"matches_model/interpretability\": \"The models used were all standatd models with some degree of interpretability, e.g. we visualized decision trees in Figure 1 and 3. Furthermore, we looked into feature importance of a random forest model in Figure 4.\",\n",
      "        \"matches_model/output\": \"We used both classification and regression given the different datasets.\",\n",
      "        \"matches_model/duration\": \"Prediction on new data takes less than a second on a standard deskop PC.\",\n",
      "        \"matches_model/availability\": \"The code is available under the GNU Affero General Public License v3.0 on GitHub: https://github.com/juaml/ConfoundLeakage\",\n",
      "        \"matches_dataset/provenance\": \"We used two sources of data: I) The widely used and recognized UCI Machine Learning Repository, and II) a real-world clinical dataset. \\nI) UCI data: For classification dataset we subsampled the data to have balanced classes (the corresponding n after subsampling shown in parenthesis) :\\n1) Income (Adult) n=32561 (15682,  equal Npos and Nneg)\\n2) Bank Marketing n=41188 (9280,  equal Npos and Nneg)\\n3) Heart n=297 (274,  equal Npos and Nneg)\\n4) Blood Transfusion n=748 (356,  equal Npos and Nneg)\\n5) Breast Cancer n=569 (424,  equal Npos and Nneg)\\n6) Student Performance n=649 | used for regression\\n7) Abalone n=4177 | used for regression\\n8) Concrete Compressive Strength n=1030 | used for regression\\n9) Residential Building n=372 | used for regression\\n10) Real Estate n=414 | used for regression\\n\\nII) real-world clinical dataset is restricted, but was already used by von Polier at al. 2021\\nn=1045 (126, equal Npos and Nneg)\",\n",
      "        \"matches_dataset/splits\": \"All data splits for the main analyses were performed using repeated k-fold cross-validation (k=5, repeats=10). In case of classification we used a stratified folds to preserve distributions of the data in training and test sets. If hyperparameter tuning was needed, we uses a nested cross-validation with the outer loop used for model assessment as described above and an inner 5-fold CV was used for model selection. We did not plot each of these distributions for our 11 datasets.\",\n",
      "        \"matches_dataset/redundancy\": \"As we used a (nested) cross-validation and thus the training and test sets are independent of each other. To account for the dependence structure across CV repeats when comparing CV outcomes of two ML models, we used the Bayesian ROPE approach which is specifically designed for this purpose.  \",\n",
      "        \"matches_dataset/availability\": \"All UCI datasets are available via https://archive.ics.uci.edu/. \\nWe also provide a clear instruction together with our supporting material such as code on the following GitHub repository: https://github.com/juaml/ConfoundLeakage/tree/main.\\nThe clinical data can be obtained upon request from the original authors as described in the supporting material.\\nOur repo uses the GNU Affero General Public License v3.0. \\n\\nThe sensitive real-world clinical dataset is restricted and can only be requesting it from PeakProfiling GmbH with certain restrictions. See paper for more details.\",\n",
      "        \"matches_publication/title\": \"Confound-leakage: confound removal in machine learning leads to leakage\",\n",
      "        \"matches_publication/authors\": \"Sami Hamdan, Bradley C Love, Georg G von Polier, Susanne Weis, Holger Schwender, Simon B Eickhoff, Kaustubh R Patil\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e3b6e61d57eb8bca695c9\",\n",
      "        \"shortid\": \"d9uiis9a39\",\n",
      "        \"uuid\": \"127575b1-dda0-4c00-9f22-520eb402fc63\",\n",
      "        \"created\": \"2024-10-15T09:52:46.103Z\",\n",
      "        \"updated\": \"2024-10-15T09:52:46.103Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_title\": \"SpheroScan: a user-friendly deep learning tool for spheroid image analysis\",\n",
      "        \"publication_authors\": \"Akshay Akshay, Mitali Katoch, Masoud Abedi, Navid Shekarchizadeh, Mustafa Besic, Fiona C Burkhard, Alex Bigger-Allen, Rosalyn M Adam, Katia Monastyrskaya, Ali Hashemi Gheinani\",\n",
      "        \"publication_journal\": \"GigaScience\",\n",
      "        \"publication_year\": \"2023\",\n",
      "        \"publication_pmid\": \"37889008\",\n",
      "        \"publication_doi\": \"10.1093/gigascience/giad082\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 6,\n",
      "        \"score\": 0.63,\n",
      "        \"matches_evaluation/method\": \"The evaluation method employed for Mask R-CNN involved assessing the model's performance based on object detection accuracy and instance segmentation quality using Intersection over Union (IoU).\",\n",
      "        \"matches_evaluation/measure\": \"To evaluate the performance of the trained models on spheroid segmentation, we used the Average Precision (AP) evaluation metric. \",\n",
      "        \"matches_optimization/algorithm\": \"For spheroid detection and segmentation, we employed a state-of-the-art deep learning model known as Mask Regions with Convolutional Neural Networks (R-CNN).\",\n",
      "        \"matches_optimization/meta\": \"No, our model does not utilize data from other algorithms.\",\n",
      "        \"matches_optimization/config\": \"In this study, we used the Mask R-CNN model for instance segmentation and tuned several of its parameters to fit the specific problem and the dataset we were working with. The backbone of the model was a ResNet-50 feature pyramid network, and we initialised the model with weights from a pre-trained COCO instance segmentation model. The batch size for training was set to 4, and the base learning rate was set to 0.00025. The RoIHead batch size was 256, and we used a single output class (for spheroids). We trained the model for a total of 1000 iterations. In addition to these specified parameters, we used the default values for all other parameters of the Mask R-CNN model.\",\n",
      "        \"matches_optimization/encoding\": \"An experienced researcher in the spheroid assay manually annotated the images from Incucyte and microscopes using the VGG Image Annotator. \",\n",
      "        \"matches_optimization/features\": \"Not applicable.\",\n",
      "        \"matches_optimization/fitting\": \"Not applicable.\",\n",
      "        \"matches_optimization/parameters\": \"In this study, we used the Mask R-CNN model for instance segmentation and tuned several of its parameters to fit the specific problem and the dataset we were working with. The backbone of the model was a ResNet-50 feature pyramid network, and we initialised the model with weights from a pre-trained COCO instance segmentation model. The batch size for training was set to 4, and the base learning rate was set to 0.00025. The RoIHead batch size was 256, and we used a single output class (for spheroids). We trained the model for a total of 1000 iterations. In addition to these specified parameters, we used the default values for all other parameters of the Mask R-CNN model.\",\n",
      "        \"matches_model/interpretability\": \"We utilized the Mask R-CNN model, which is recognized as a black box model itself.\",\n",
      "        \"matches_model/output\": \"No. Mask RCNN is a object detection and semantic segmentation model.\",\n",
      "        \"matches_model/duration\": \"The prediction module exhibits linear runtime complexity, taking approximately 1 second per image to mask the spheroids. The run-time performance evaluation was conducted on a Red Hat server equipped with 16 Central Processing Unit (CPU) cores and 64 GB of Random-Access Memory (RAM).\",\n",
      "        \"matches_model/availability\": \"The source code for SpheroScan is available at https://github.com/FunctionalUrology/SpheroScan with GNU GENERAL PUBLIC LICENSE.\",\n",
      "        \"matches_dataset/provenance\": \"To generate the image datasets required for a DL model, we conducted a spheroid gel contraction assay using 5000 Smooth Muscle Cells (SMCs) and Human Embryonic Kidney (HEK) cells per collagen spheroid. After the collagen droplet had polymerized, we changed the medium and transferred the plates to an Incucyte Live-Cell Analysis System, which captured images of the spheroids every hour for a duration of 24 hours. Additionally, we employed a ZEISS Axio Vert.A1 Inverted Microscope to manually capture images of the spheroids at specific time points. By utilizing both methods, we were able to collect a diverse range of spheroid images, resulting in a robust dataset for our DL model. We obtained a total of 530 images from the Incucyte system and 432 images from the microscope.\",\n",
      "        \"matches_dataset/splits\": \"<!DOCTYPE html>\\n<html>\\n<head>\\n  <title>Dataset Information</title>\\n</head>\\n<body>\\n  \\n  <h4>Incucyte System Dataset:</h4>\\n  <ul>\\n    <li>Training dataset: 336 images</li>\\n    <li>Validation dataset: 144 images</li>\\n    <li>Test dataset: 50 images</li>\\n  </ul>\\n\\n  <h4>Microscope Dataset:</h4>\\n  <ul>\\n    <li>Training dataset: 265 images</li>\\n    <li>Validation dataset: 117 images</li>\\n    <li>Test dataset: 50 images</li>\\n  </ul>\\n</body>\\n</html>\",\n",
      "        \"matches_dataset/redundancy\": \"The training, validation, and test sets are independent of each other. Furthermore, the spheroids in the test dataset underwent different treatment compared to those in the training and validation datasets. For the test dataset, the spheroids were cultured in smooth muscle cell medium and Dulbecco's Modified Eagle Medium (DMEM) with 0.5% and 1% FBS. \",\n",
      "        \"matches_dataset/availability\": \"All the images used for training, validation, and testing are available at Zenodo with the DOI: https://doi.org/10.5281/zenodo.7555467 (Creative Commons \\u2014 CC0 license).\",\n",
      "        \"matches_publication/title\": \"SpheroScan: a user-friendly deep learning tool for spheroid image analysis\",\n",
      "        \"matches_publication/authors\": \"Akshay Akshay, Mitali Katoch, Masoud Abedi, Navid Shekarchizadeh, Mustafa Besic, Fiona C Burkhard, Alex Bigger-Allen, Rosalyn M Adam, Katia Monastyrskaya, Ali Hashemi Gheinani\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e3c5061d57eb8bca695ce\",\n",
      "        \"shortid\": \"16cyggfthl\",\n",
      "        \"uuid\": \"3572dc07-ae4e-497f-b7b7-dc66981fbe02\",\n",
      "        \"created\": \"2024-10-15T09:56:32.676Z\",\n",
      "        \"updated\": \"2024-10-15T09:56:32.676Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_title\": \"Machine learning\\u2013based feature selection to search stable microbial biomarkers: application to inflammatory bowel disease\",\n",
      "        \"publication_authors\": \"Youngro Lee, Marco Cappellato, Barbara Di Camillo\",\n",
      "        \"publication_journal\": \"GigaScience\",\n",
      "        \"publication_year\": \"2023\",\n",
      "        \"publication_pmid\": \"37882604\",\n",
      "        \"publication_doi\": \"10.1093/gigascience/giad083\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 6,\n",
      "        \"score\": 0.78,\n",
      "        \"matches_evaluation/method\": \"As illustrated in Fig.1, we divided the entire dataset into Ensemble Dataset 1 and Ensemble Dataset 2. And each ensemble dataset was divided to training set and test set. With this pipeline, we are able to evaluate the entire pipeline in two independent separate dataset. \",\n",
      "        \"matches_evaluation/measure\": \"To validate the evaluation, we check various performance indexes (MCC, AUC, accuracy, PPV, NPV, sensitivity, specificity) and stability indexes (rank based stability measurement-number of common features, Pearson Correlation, Canberra Distance, Bray-Curtis Dissimilarity). Evaluation is done by test dataset obtained from following process: merging benchmark datasets and splitting into training dataset and test dataset by random sort(bootstrapping). \",\n",
      "        \"matches_evaluation/comparison\": \"To validate the performance improvement/consistence, we compare with public, simple algorithm which is Linear SVM based RFE without any special preprocessing method. \",\n",
      "        \"matches_evaluation/confidence\": \"To prove the low variability of performance, the standard deviation of performance is written together with average in Supplementary Tables. Variability is rounded to two decimal places. \",\n",
      "        \"matches_evaluation/availability\": \"The source code containing evaluation files is open to the public at https://gitlab.com/sysbiobig/mlonmicrobiome with GNU General Public License. \",\n",
      "        \"matches_optimization/algorithm\": \"Eight different types of prediction algorithms, namely logistic regression, linear SVM, random forest, XGBoost, Perceptron, and Multi-Layer Perceptron (MLP) with 1, 2 or 3 hidden layers, were used to classify samples in IBD vs. healthy using the features selected within the RFE phase. There was no new ML algorithm. \",\n",
      "        \"matches_optimization/meta\": \"Before applying the eight different types of prediction algorithms, Recursive Feature Elimination (RFE) by Linear SVM was used. RFE stage was done solely by training dataset, and test dataset was used only for evaluating the performance of eight different prediction algorithms.\",\n",
      "        \"matches_optimization/config\": \"We reported how hyperparameters were tuned in 2.5 Classification Model Algorithms, and reported the code at https://gitlab.com/sysbiobig/mlonmicrobiome with GNU General Public License. \",\n",
      "        \"matches_optimization/encoding\": \"As explained in Section 2.1 Data, we divided the abundance profiles by the geometric mean in each data source and took the log (base 2) of the ratios, and then min-max scaler was applied.\",\n",
      "        \"matches_optimization/features\": \"We selected a core set of features with 283 taxa at the species level and 220 at the genus level. Feature selection was done by RFE, which is a core part of our paper. RFE was done only by training dataset. \",\n",
      "        \"matches_optimization/fitting\": \"In this experiment, f was large so that overfitting should be considered (f>100). In this aspect, we propose stable feature selection method to prevent overfitting. \",\n",
      "        \"matches_optimization/parameters\": \"Grid search is used to tune major parameters (learning rate, regularization parameter). Grid search is done solely on the training dataset in cross validation. As all models are built from scikit-learn library 1.0.2, definitions of parameters are all released in the library page and also summarized in Methods. (This part is described at Section 2.2 and 2.5.1)\",\n",
      "        \"matches_optimization/regularization\": \"We applied RFE with mapping transformation to prevent overfitting. Also, regularization parameter was tuned for applicable machine learning algorithm(logistic regression, linear SVM, XGBoost, MLP regressor).\",\n",
      "        \"matches_model/interpretability\": \"We reported interpretation of model in Figure 5 by SHapley Additive exPlanations (SHAP). \",\n",
      "        \"matches_model/output\": \"We used regressor to predict between healthy and IBD samples. \",\n",
      "        \"matches_model/duration\": \"The major execution time was consumed by RFE stage, and we recorded the execution time in the source code. In each bootstrap, RFE with mapping by Bray-curtis similarity matrix required around 3~4 minutes. \",\n",
      "        \"matches_model/availability\": \"The source code is open to the public at https://gitlab.com/sysbiobig/mlonmicrobiome with GNU General Public License. \",\n",
      "        \"matches_dataset/provenance\": \"Dataset is originated from four different public datasets in Qiita. Each dataset is open to the public from references: 1. Lloyd-Price et al (published 2019, citation#=1233), 2. Flores et al. (published 2014, citation #=377), 3. Halfvarsona et al. (published 2017, citation #=825), 4. McDonald et al. (published 2018, citation #=476). A Total of 2140 samples are used for the experiment. (citation # is referred at 2022/12/22) (This part is described at Section 2.1)\\nAmong 1569 samples which have class state, 702 samples are positive and the rest are negative. Number of positives and negatives is similar, and various performance indexes are calculated to avoid class imbalance problems. (This part is described at Section 2)\",\n",
      "        \"matches_dataset/splits\": \"The ratio between training and test set was 80:20. Separate validation set was not used. To maintain the distribution of data types, bootstrapping was used. \",\n",
      "        \"matches_dataset/redundancy\": \"Partitioning is done by splitting the training and the independent test (never used for preprocessing, feature selection, parameter tuning) and, internally to the training set, by bootstrapping to maintain the class balance and random sorting. (This part is described at Section 2)\",\n",
      "        \"matches_dataset/availability\": \"Raw data and preprocessed data are all accessible at https://gitlab.com/sysbiobig/mlonmicrobiome . You can check raw data in the folder-original_data, and preprocessed data by each step in the folder-Count_Preprocessing and folder-Preprocessing. (This part is described at Section 2 and Code Availability Statement)\",\n",
      "        \"matches_publication/title\": \"Machine learning\\u2013based feature selection to search stable microbial biomarkers: application to inflammatory bowel disease\",\n",
      "        \"matches_publication/authors\": \"Youngro Lee, Marco Cappellato, Barbara Di Camillo\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e3d9261d57eb8bca695d2\",\n",
      "        \"shortid\": \"aqtrrhz75x\",\n",
      "        \"uuid\": \"a404e9b9-96f0-411a-b390-a893a6c59651\",\n",
      "        \"created\": \"2024-10-15T10:01:54.363Z\",\n",
      "        \"updated\": \"2024-10-15T10:01:54.363Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_title\": \"Imputation method for single-cell RNA-seq data using neural topic model\",\n",
      "        \"publication_authors\": \"Yueyang Qi, Shuangkai Han, Lin Tang, Lin Liu\",\n",
      "        \"publication_journal\": \"GigaScience\",\n",
      "        \"publication_year\": \"2023\",\n",
      "        \"publication_pmid\": \"38000911\",\n",
      "        \"publication_doi\": \"10.1093/gigascience/giad098\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 6,\n",
      "        \"score\": 0.7,\n",
      "        \"matches_evaluation/method\": \" Independent dataset\",\n",
      "        \"matches_evaluation/measure\": \"ARI-Adjusted Rand Index, RI-Rand Index, NMI-Normalized Mutual Information, MI-Mutual Information and so on.\",\n",
      "        \"matches_evaluation/comparison\": \"Compare with other algorithms\",\n",
      "        \"matches_evaluation/confidence\": \"Not able to use indicator confidence intervals\",\n",
      "        \"matches_evaluation/availability\": \"Yes.We will publish it on GitHub\",\n",
      "        \"matches_optimization/meta\": \"No other data were used as inputs\",\n",
      "        \"matches_optimization/config\": \"Yes.We will publish it on GitHub\",\n",
      "        \"matches_optimization/encoding\": \"Normalization processing\",\n",
      "        \"matches_optimization/features\": \"The expression of each gene in a single cell\",\n",
      "        \"matches_optimization/parameters\": \"Around 200\",\n",
      "        \"matches_model/interpretability\": \"Transparent.Neural Topic inherit the advantages of the topic model and is highly interpretable\",\n",
      "        \"matches_model/duration\": \"Transfer learning of models is linearly correlated with the number of genes\",\n",
      "        \"matches_model/availability\": \"Links can be provided separately\",\n",
      "        \"matches_dataset/provenance\": \"Human Pancreatic Islet data and Mouse Pancreatic Islet data;Human brain scRNA-seq data.All datasets have been used in other published journals and are available in public dataset repositories\",\n",
      "        \"matches_dataset/splits\": \"No data splitting was done\",\n",
      "        \"matches_dataset/redundancy\": \"Data does not overlap\",\n",
      "        \"matches_dataset/availability\": \"Most of the data are in the NCBI Public Dataset.\",\n",
      "        \"matches_publication/title\": \"Imputation method for single-cell RNA-seq data using neural topic model\",\n",
      "        \"matches_publication/authors\": \"Yueyang Qi, Shuangkai Han, Lin Tang, Lin Liu\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e60fa61d57eb8bca695f6\",\n",
      "        \"shortid\": \"x0nks31fro\",\n",
      "        \"uuid\": \"2f8fe6a8-a0b4-40aa-93a9-3a83e53fde3f\",\n",
      "        \"created\": \"2024-10-15T12:32:58.438Z\",\n",
      "        \"updated\": \"2024-10-15T12:32:58.438Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_title\": \"Euler characteristic curves and profiles: a stable shape invariant for big data problems\",\n",
      "        \"publication_authors\": \"Pawe\\u0142 D\\u0142otko, Davide Gurnari\",\n",
      "        \"publication_journal\": \"GigaScience\",\n",
      "        \"publication_year\": \"2023\",\n",
      "        \"publication_pmid\": \"37966428\",\n",
      "        \"publication_doi\": \"10.1093/gigascience/giad094\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 6,\n",
      "        \"score\": 0.74,\n",
      "        \"matches_evaluation/measure\": \"Average accuracy on the test set.\",\n",
      "        \"matches_evaluation/comparison\": \"we compare our results to the one in the original article by Vipond et al.\",\n",
      "        \"matches_evaluation/confidence\": \"confidence intervals are not present in Vipond et al. , we provide ours in our GitHUb. Our results are statistically significant.\",\n",
      "        \"matches_evaluation/availability\": \"https://github.com/dioscuri-tda/ecp_experiments MIT license\",\n",
      "        \"matches_optimization/algorithm\": \"We repeated the procedure outlined in the original paper, described in section 3D of the supplementary materials.\\nVipond et al. \\\"Multiparameter persistent homology landscapes identify immune cell spatial patterns in tumors\\\" https://doi.org/10.1073/pnas.2102166118 \\n\\nQuoting from the above source:\\n\\nWe test the ability of the MPH-landscape to distinguish the cell types in each tumor. For each pair of cell types we make a randomized 80/20 training/test split, and evaluate the classification accuracy of 3 classifiers (Linear Discriminant Analysis, LDA, Regularised Linear Discriminant Analysis, rLDA, and regularised Quadratic Discriminant Analysis, rQDA) on the test data. Repeating this process 100 times we attain average pairwise classification accuracies.\",\n",
      "        \"matches_optimization/config\": \"https://github.com/dioscuri-tda/ecp_experiments/tree/main/immune_cells MIT license\",\n",
      "        \"matches_optimization/encoding\": \"We used the Vipond et al.'s code to re-generate the same Vietoris-Rips and bifiltered Vietoris-Rips complexes from the provided pointclouds. We then computed ECC (radius only) and ECP (radius and codensity) for each complex and used them as input for the same LDA, rLDA and rQDA classifiers using the same train-test split procedure.\",\n",
      "        \"matches_optimization/features\": \"Both ECCs and ECPs where converted to vectors of lenght 51 by sampling them on a grid.\",\n",
      "        \"matches_optimization/fitting\": \"By comparing train and test accuracies \",\n",
      "        \"matches_optimization/parameters\": \" Default hyperparameters from the scikit-learn implementations, as in the original study.\",\n",
      "        \"matches_model/interpretability\": \"The model is interpretable, but interpretation goes beyond the scope of this work.\",\n",
      "        \"matches_model/duration\": \"Seconds on a consumer-grade laptop.\",\n",
      "        \"matches_model/availability\": \"https://github.com/dioscuri-tda/ecp_experiments MIT license\",\n",
      "        \"matches_dataset/provenance\": \"Anonymized point cloud data from Vipond et al. \\\"Multiparameter persistent homology landscapes identify immune cell spatial patterns in tumors\\\" https://doi.org/10.1073/pnas.2102166118 .\\n\",\n",
      "        \"matches_dataset/splits\": \"We repeated the procedure outlined in the original paper, described in section 3D of the supplementary materials.\\n\\nThere is a total of 1574 data points belonging to 3 different cell types. No separate validation set is provided.\",\n",
      "        \"matches_dataset/redundancy\": \"We repeated the procedure outlined in the original paper, described in sectin 3D of the supplementary materials. \\n\\nFor each pair of cell type we make a randomized 80/20 training/test split with stratification. The process was repeated 100 time\",\n",
      "        \"matches_dataset/availability\": \"Yes. The anonymized point cloud data are available from Vipond et al. \\\"Multiparameter persistent homology landscapes identify immune cell spatial patterns in tumors\\\" https://doi.org/10.1073/pnas.2102166118 \\n\\nhttps://github.com/MultiparameterTDAHistology/SpatialPatterningOfImmuneCells\\n\\nour pipeline is available at\\nhttps://github.com/dioscuri-tda/ecp_experiments/tree/main/immune_cells\\n\\n\",\n",
      "        \"matches_publication/title\": \"Euler characteristic curves and profiles: a stable shape invariant for big data problems\",\n",
      "        \"matches_publication/authors\": \"Pawe\\u0142 D\\u0142otko, Davide Gurnari\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e64f661d57eb8bca695fa\",\n",
      "        \"shortid\": \"vdqf1t5lyj\",\n",
      "        \"uuid\": \"e8f2de3b-25bc-4a43-9af4-fc31a7f05d40\",\n",
      "        \"created\": \"2024-10-15T12:49:58.625Z\",\n",
      "        \"updated\": \"2024-10-15T12:49:58.625Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_title\": \"MLcps: machine learning cumulative performance score for classification problems\",\n",
      "        \"publication_authors\": \"Akshay Akshay, Masoud Abedi, Navid Shekarchizadeh, Fiona C Burkhard, Mitali Katoch, Alex Bigger-Allen,Rosalyn M Adam, Katia Monastyrskaya, Ali Hashemi Gheinani\",\n",
      "        \"publication_journal\": \"GigaScience\",\n",
      "        \"publication_year\": \"2023\",\n",
      "        \"publication_pmid\": \"38091508\",\n",
      "        \"publication_doi\": \"10.1093/gigascience/giad108\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 6,\n",
      "        \"score\": 0.7,\n",
      "        \"matches_evaluation/method\": \"We consistently maintained an independent test set for TCGA dataset to evaluate the model's performance and identify potential issues of overfitting or underfitting. To mitigate the risk of overfitting in the CLL and cervical datasets, we utilized the Repeated Stratified K-fold Cross-Validation method.\",\n",
      "        \"matches_evaluation/measure\": \"We computed 7 evaluation metrics, including precision, recall, F1 score, and area under the curve (AUC), for each trained model across all datasets.This comprehensive approach enabled us to gain a thorough understanding of the model's performance from multiple angles and perspectives. \",\n",
      "        \"matches_evaluation/comparison\": \"We compared the performance of our trained models with a dummy classifier, which is a classifier that makes random predictions. Typically, it is expected that the trained models will outperform the dummy classifier. This serves as a baseline comparison to assess the effectiveness and superiority of our trained models. By comparing the performance metrics of our models against the random predictions of the dummy classifier, we can evaluate the added value and efficacy of our trained models in making accurate predictions.\",\n",
      "        \"matches_evaluation/availability\": \"Not applicable.\",\n",
      "        \"matches_optimization/algorithm\": \"We have utilized 8 classification algorithms for each dataset in order to classify the classes within each dataset.\",\n",
      "        \"matches_optimization/meta\": \"No. \",\n",
      "        \"matches_optimization/config\": \"We did not perform any hyperparameter tuning for the trained models. \",\n",
      "        \"matches_optimization/encoding\": \"For the CLL patients dataset, we specifically utilized the top 5,000 most variable mRNAs, excluding genes from the Y chromosome, as input for the machine learning pipeline. In the case of the BRCA mRNA dataset, our focus was solely on differentially expressed genes identified by edgeR, using a threshold of FDR \\u2264 0.001 and logFC > \\u00b1 2. As for the cervical cancer dataset, we utilized it in its original form without making any modifications.\",\n",
      "        \"matches_optimization/features\": \"No feature selection was performed on any of the datasets.\",\n",
      "        \"matches_optimization/fitting\": \"We consistently maintained an independent test set for TCGA dataset to evaluate the model's performance and identify potential issues of overfitting or underfitting. To mitigate the risk of overfitting in the CLL and cervical datasets, we utilized the Repeated Stratified K-fold Cross-Validation method.\",\n",
      "        \"matches_optimization/parameters\": \"The majority of the trained models were utilized with their default parameters.\",\n",
      "        \"matches_model/interpretability\": \" We have used multiple ML classification algorithms, most of which are black box models. For example, SVM (Support Vector Machine) is considered a black box model, but features like support vectors and feature importance can offer some interpretability.\",\n",
      "        \"matches_model/output\": \" Classification.\",\n",
      "        \"matches_model/duration\": \" It is not applicable to current project.\",\n",
      "        \"matches_model/availability\": \"The source code for MLcps is available at https://github.com/FunctionalUrology/MLcps with GNU GENERAL PUBLIC LICENSE.\",\n",
      "        \"matches_dataset/provenance\": \"\\nIn this project, we utilized four different publicly available datasets that are well recognized in the domain. The first dataset consisted of mRNA data obtained from a study on Chronic Lymphocytic Leukemia (CLL) patients, measuring their transcriptome profiles. The second dataset was collected from a cervical cancer study that analyzed the expression levels of 714 miRNAs in human samples. The third and fourth datasets were obtained from The Cancer Genome Atlas (TCGA) and included mRNA and miRNA sequencing data from patients with Breast Invasive Carcinoma (BRCA). \\n  \\n<!DOCTYPE html>\\n<html>\\n<head>\\n<style>\\ntable {\\n  text-align: center;\\n}\\nth {\\n  text-align: center;\\n}\\n</style>\\n</head>\\n<body>\\n\\n<table>\\n\\n  <tr>\\n    <th>Dataset</th>\\n    <th>Data type</th>\\n    <th>Number of Samples</th>\\n    <th>Number of Features</th>\\n    <th>Target Class ratio</th>\\n  </tr>\\n  <tr>\\n    <td>CLL</td>\\n    <td>mRNA</td>\\n    <td>136</td>\\n    <td>5000</td>\\n    <td>Male (n=82): Female (n=54)</td>\\n  </tr>\\n  <tr>\\n    <td>Cervical cancer</td>\\n    <td>miRNA</td>\\n    <td>58</td>\\n    <td>714</td>\\n    <td>Normal (n=29): Tumor (n=29)</td>\\n  </tr>\\n  <tr>\\n    <td>TCGA-BRCA</td>\\n    <td>miRNA</td>\\n    <td>1207</td>\\n    <td>1404</td>\\n    <td>Normal (n=104): Tumor (n=1104)</td>\\n  </tr>\\n  <tr>\\n    <td>TCGA-BRCA</td>\\n    <td>mRNA</td>\\n    <td>1219</td>\\n    <td>5520</td>\\n    <td>Normal (n=113): Tumor (n=1106)</td>\\n  </tr>\\n\\n</table>\\n\\n</body>\\n</html>\\n\\n\",\n",
      "        \"matches_dataset/splits\": \"We maintained a distinct test/validation dataset to evaluate the model's performance on TCGA datasets. The original datasets were randomly split, ensuring that each class was proportionally represented within the dataset. Approximately 70% of the data was allocated to the training dataset, while the remaining 30% was assigned to the test dataset.\\n\\nTo assess the model's performance on the CLL and cervical cancer datasets, we employed the Repeated (10) Stratified K-fold (3) Cross-Validation method. This approach allowed us to thoroughly evaluate the model by repeatedly dividing the data into folds, ensuring that each fold maintained a balanced distribution of classes.\\n\",\n",
      "        \"matches_dataset/redundancy\": \"We maintained a distinct test/validation dataset to evaluate the model's performance on TCGA datasets. The original datasets were randomly split, ensuring that each class was proportionally represented within the dataset. Approximately 70% of the data was allocated to the training dataset, while the remaining 30% was assigned to the test dataset.\\n\\nTo assess the model's performance on the CLL and cervical cancer datasets, we employed the Repeated (10) Stratified K-fold (3) Cross-Validation method. This approach allowed us to thoroughly evaluate the model by repeatedly dividing the data into folds, ensuring that each fold maintained a balanced distribution of classes.\\n\",\n",
      "        \"matches_dataset/availability\": \"The datasets we have utilized are publicly available datasets. All the relevant details can be found in the manuscript.\",\n",
      "        \"matches_publication/title\": \"MLcps: machine learning cumulative performance score for classification problems\",\n",
      "        \"matches_publication/authors\": \"Akshay Akshay, Masoud Abedi, Navid Shekarchizadeh, Fiona C Burkhard, Mitali Katoch, Alex Bigger-Allen,Rosalyn M Adam, Katia Monastyrskaya, Ali Hashemi Gheinani\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e65ee61d57eb8bca695fe\",\n",
      "        \"shortid\": \"9izph0m2we\",\n",
      "        \"uuid\": \"b2f6bf1e-bccb-4250-98a3-0b71335847dc\",\n",
      "        \"created\": \"2024-10-15T12:54:06.607Z\",\n",
      "        \"updated\": \"2024-10-15T12:54:06.607Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_title\": \"MMV_Im2Im: An Open Source Microscopy Machine Vision Toolbox for Image-to-Image Transformation\",\n",
      "        \"publication_authors\": \"Justin Sonneck, Yu Zhou, Jianxu Chen\",\n",
      "        \"publication_journal\": \"GigaScience\",\n",
      "        \"publication_year\": \"2023\",\n",
      "        \"publication_pmid\": \"38280188\",\n",
      "        \"publication_doi\": \"10.1093/gigascience/giad120\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 6,\n",
      "        \"score\": 0.67,\n",
      "        \"matches_evaluation/method\": \"evaluated on hold-out sets\",\n",
      "        \"matches_evaluation/measure\": \"The objective of this paper is to introduce a geneic machien learning tool, not for a specific scientific study. The evaluation metric varies from application to application. Please refer the \\\"Results\\\" section of the manuscript for details.\",\n",
      "        \"matches_evaluation/availability\": \"All models are released https://zenodo.org/records/10034416, which can be used to reproduce raw outputs\",\n",
      "        \"matches_optimization/algorithm\": \"Neural network. Four types of methods were used, conditional GAN, cycle GAN, FCN, and embedding based instance segmentation network.\",\n",
      "        \"matches_optimization/config\": \"yes, https://github.com/MMV-Lab/mmv_im2im/tree/main/paper_configs\",\n",
      "        \"matches_optimization/encoding\": \"Usually, the images need to go through intensity normalization before feeding into the neural network. Different experiments may use different intensity normalization methods.\",\n",
      "        \"matches_optimization/features\": \"Inputs are images\",\n",
      "        \"matches_optimization/fitting\": \"We demonstration examples of various regularization methods in different experiments, such as weigh decay and early stopping, etc.. The objective of this paper is to introduce a generic machine learning tool, not for a specific scientific question. Users can configure their own way to control overfitting and under fitting, depending on their own data.\",\n",
      "        \"matches_optimization/parameters\": \"We used different neural networks for different applications. Please refer the \\\"Results\\\" section of the manuscript for details. The goal is not to show the best model. Instead, it is to highlight the flexibility of our tool, where users can test differnet models without changing any line of code. The objective of this paper is to introduce a generic machine learning tool, not for a specific scientific question.\",\n",
      "        \"matches_optimization/regularization\": \"yes, we used weight decay in the optimizer and early stopping monitoring the validation loss. (Again, the objective of this paper is to introduce a generic machine learning tool, not for a specific scientific question. One highlight of this tool is that users can easily configure different regularization methods, e.g., different early stopping criteria, different optimizer, adding additional regularization term in the loss, etc.)\",\n",
      "        \"matches_model/interpretability\": \"in general, deep neural networks are not fully interpretable\",\n",
      "        \"matches_model/output\": \"The objective of this paper is to introduce a machine learning tool, not for a specific scientific question. The model can be regression or classification depending on specific image-to-image transformation application. For labelfree, denoising, modality transfer, synthetic image generation, the models are regression; for other segmentation tasks, the models are classification.\",\n",
      "        \"matches_model/duration\": \"Generally about a few seconds, depending on the size of the image and the specific model and application.\",\n",
      "        \"matches_model/availability\": \"yes, open source python package. https://github.com/MMV-Lab/mmv_im2im (MIT license)\",\n",
      "        \"matches_dataset/provenance\": \"The data were all from public repositories released with previous publications. Please refer the \\\"Data Availability\\\" section of the manuscript for details.\",\n",
      "        \"matches_dataset/splits\": \"There are over ten different experiments in this work. In general, K% of the data were held out for testing, while (100-K)% were used during training. Among this (100-K)%, 85%*(100-K)% were used in the training loops, while 15%*(100-K)% were used in the validation loops (e.g., for the purpose of early stoping determination). In most cases, K = 20. But in some cases, due to limited amount of public data, we can only hold out smaller amount of data; otherwise, the training set would be too small to be effective. There are also a few experiments, we just followed the original split from the published dataset. Please refer the \\\"Data Availability\\\" section of the manuscript for details.\",\n",
      "        \"matches_dataset/redundancy\": \"When we do train/test split, all splits are random.\",\n",
      "        \"matches_dataset/availability\": \"The data are all publicly available, as they were all released with previous publications. Please refer the \\\"Data Availability\\\" section of the manuscript for details.\",\n",
      "        \"matches_publication/title\": \"MMV_Im2Im: An Open Source Microscopy Machine Vision Toolbox for Image-to-Image Transformation\",\n",
      "        \"matches_publication/authors\": \"Justin Sonneck, Yu Zhou, Jianxu Chen\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"65d7e78d1502715bfe53c582\",\n",
      "        \"uuid\": \"00e4d4f8-2dd6-452a-b27c-72fe9296b09d\",\n",
      "        \"created\": \"2024-02-23T00:32:13.005Z\",\n",
      "        \"updated\": \"2024-02-23T00:35:32.655Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_title\": \"Discovering genotype-phenotype relationships with machine learning and the Visual Physiology Opsin Database (VPOD)\",\n",
      "        \"publication_authors\": \"Seth A. Frazer, Mahdi Baghbanzadeh, Ali Rahnavard, Keith A. Crandall, Todd H. Oakley\",\n",
      "        \"publication_journal\": \"GigaScience\",\n",
      "        \"publication_year\": \"2024\",\n",
      "        \"publication_pmid\": \"na\",\n",
      "        \"publication_doi\": \"10.1101/2024.02.12.579993\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"shortid\": \"88n4lxv68p\",\n",
      "        \"score\": 0.9,\n",
      "        \"matches_evaluation/method\": \"For model evaluation and comparison, deepBreaks by default uses a 10-fold cross-validation approach and ranks\\nthe models based on their average cross-validation score.\\nAs we described in the methods of the main text \\\"we created eleven data subsets with varying levels of taxonomic and gene family inclusivity (Table 1) to test which factors most impact the reliability/performance of ML methods. We used naming conventions that include versioning to improve reproducibility and reliability of individual datasets and models. For example, one subset combines ultraviolet and SWS opsins, which we named VPOD_uss_het_1.0. Our convention is to name the subset (in this case USS = \\u2018Ultraviolet and Short-wave Sensitive\\u2019 opsins); name the source of phenotype data (heterologous = het), and record the version number of the dataset (1.0). We also created subsets for medium- and long-wave sensitive opsins (VPOD_mls_het_1.0) and all rod (Rh1) and rod-like (Rh2) opsins (VPOD_rod_het_1.0). Other subsets use species taxonomy, one for vertebrates (VPOD_vert_het_1.0) and another for invertebrates (VPOD_inv_het_1.0). For taxonomic subsets, we considered all sequences from phylum Chordata as \\u2018vertebrates\\u2019 and the rest as 'invertebrates\\u2019. Another subset excludes all mutant opsin sequences, called \\u2018wild-types\\u2019 (VPOD_wt_het_1.0). A final named subset is the whole data set (VPOD_wds_het_1.0). \\nUsing various subsets of data, we performed a number of experiments to better understand the performance of ML models in predicting \\u03bbmax. First, to better understand how training data relate to model performance, R2 , and training data size, we gradually increased the size of training datasets, using the WDS, Vertebrate, WT, and Rod subsets separately, by adding between 15-50 randomly selected sequences at a time, repeating the process three times per data split (Table S1). We then analyzed the fit between the size of training data sets (x-axis) and model performance (y-axis), comparing six non-linear models with AIC to find the model that best explains the observed variation (Figure S2). Second, to understand if ML could predict known phenotypic changes due to experimental mutations, we queried the top performing WT model (which lacks data from artificially mutated sequences) using all experimentally mutated opsins to predict their phenotypes. We plotted these results using matplotlib [49] to visualize characteristics of poorly predicted outliers (e.g., taxonomic bias or sensitivity to mutations which caused large shifts in \\u03bbmax from the WT). Third, we examined the ability of our models to predict \\u03bbmax of thirty invertebrate opsins not in VPOD_1.0 because they are only known from physiological studies (Table S3, Figure S4). Here, we collected data both characterized by single-cell microspectrophotometry (MSP) or electroretinogram methods and with expression localized to cell-type by in-situ-hybridization (ISH), to link \\u03bbmax to a specific opsin (the sequences and metadata can be found in \\u2018msp_erg_raw.txt\\u2019 and \\u2018msp_erg_meta.tsv\\u2019, while the resulting predictions can be found under the \\u2018msp_tests\\u2019 folder on our GitHub repository). Finally, we directly compared predictive capabilities of models trained on different data subsets by randomly selecting and removing the same 25 wild-type ultraviolet or short-wave sensitive opsins from the training data of the WDS, Vertebrate, WT, and UVS/SWS models before training and querying the model with those same sequences following training (Table S3, Figure S5). \\\"\\n\",\n",
      "        \"matches_evaluation/measure\": \"The default performance metrics for regression and classification that deepBreaks uses are Mean Absolute Error (MAE) and F-score. The default list of metrics that deepBreaks reports are provided in the documentation provide predefined custom metrics or a set of metrics from the scikit-learn library in python.\",\n",
      "        \"matches_evaluation/comparison\": \"We didn't compare to an existing publicly available ML methods. However, we compared performance of ML models to phylogenetic imputation, which estimates phenotypes using phylogenetic information. Phylogenetic imputation uses maximum likelihood (we will not abbreviate maximum likelihood as ML to avoid confusion with machine learning), assuming Brownian Motion to predict missing phenotypes using a phylogenetic tree, assuming more closely related species or sequences have more similar phenotypes. We randomly removed 50 opsin sequences, and their corresponding \\u03bbmax values from each of the training datasets used to train our ML models (with the exception of the smaller MWS/LWS and invertebrate datasets, in which we only removed 15), then estimated the removed \\u03bbmax values using phylogenetic imputation. We used the phylogenetic imputation sub-module of the phytools R package for performing imputation. We compared imputed and actual \\u03bbmax using regression. \",\n",
      "        \"matches_evaluation/availability\": \"Yes, this all available on our GitHub repository, (10.5281/zenodo.10667840 or https://github.com/VisualPhysiologyDB/visual-physiology-opsin-db/).\",\n",
      "        \"matches_optimization/algorithm\": \"We then trained various ML models employing a custom version of deepBreaks, an ML tool designed for exploring genotype-phenotype associations. For continuous phenotypes, deepBreaks fit models using twelve different existing ML linear regression algorithms including, Ridge Regression, Lasso Regression, Bayesian Regression, Lasso Least Angle Regression, Huber Regressor, Extremely Randomized Trees (Extra Trees), Extreme Gradient Boosting (xgboost), Light Gradient Boosting Machine (lightgbm), Random Forest, Decision Tree, and AdaBoost. deepBreaks takes aligned genotype data (DNA, RNA, Amino Acid) and some measure(s) of corresponding continuous or categorical phenotype data as input to train ML models. \",\n",
      "        \"matches_optimization/config\": \"Yes, they are likely available in the scikit-learn documentation. \",\n",
      "        \"matches_optimization/encoding\": \"The deepBreaks pipeline for preprocessing starts with dropping columns in the dataset that contain missing values over a certain threshold. The default threshold is 80% of the number of samples.  Dropping the zero-entropy (constant) features from the dataset, is the next step.   deepBreaks uses one-hot encoding to convert amino acid sequences into numerical values. One consequence of this encoding is any amino acids at a given position in the alignment, which are not present at that position in any training data, will be treated equivalently as unseen. For example, cases of only A and V at a highly conserved site in the training set that are presented with a sequence with T at that site will be considered as no A and no V. The models cannot distinguish the input whether it's T or other unseen amino acids at that site.  \",\n",
      "        \"matches_optimization/features\": \"The number of input features is variable depending on the length of the sequences following sequences alignment and the many preprocessing and feature selection steps. deepBreaks uses the Kruskal-Wallis tests (for continuous phenotypes)  to reduce the number of positions in the training data set and drop the redundant ones. This statistical test is used to assess the significance of each position by running tests on all the positions against the phenotype one by one. Those features where the p-value of their test against the phenotype is less than a threshold (default p-value = 0.25) will be dropped. A list of all features and their test p-values are provided a report to the user. Then, since deepBreaks considers each position in the sequences as a feature of our training dataset,  it checks for collinearity between our predictive variables, as it can cause issues for parameter estimation. To check for the relationship between\\n\",\n",
      "        \"matches_optimization/fitting\": \"We did not focus on ruling out overfitting or underfitting, however these features may be present in the scikit-learn backend. \",\n",
      "        \"matches_optimization/parameters\": \"For all of the above-mentioned models deepBreaks by default uses the default hyperparameters from the scikit-learn library in python and a grid search (expandable by user preference) parameter set that is provided in the documentation.\",\n",
      "        \"matches_optimization/regularization\": \"We did not directly impliment any regularization measures, however I know certain models like the Light Gradient Boosted Machine and Xtreme Gradient Boosted Machine algorithms have regularization terms/parameters to limit overfitting.  That said, more information on this can be found in the scikit-learn documentation or in the corresponding literature for each machine learning algorithm type. \",\n",
      "        \"matches_model/interpretability\": \"All models used are generally interpretable, primarily due to the nature of the feature selection process, treating each position on an amino acid sequence as a feature. \\nFor interpreting the contribution of sequence positions to the predictive models, we use the feature importance, coefficients, and weights as different algorithms have different kinds of\\noutput. For xgboost and lightgbm the reported feature importance represents the number of times a feature appears in a tree. For AdaBoost, random forest, decision tree, extra tree, and\\ngradient boosting the importance of a feature is its Gini importance which is computed as the\\nnormalized total reduction of the criterion brought by that feature.\",\n",
      "        \"matches_model/output\": \"The models used for our paper were all regression, but deepBreaks provides the option to also train classification models in an identical manner. \",\n",
      "        \"matches_model/duration\": \"A single representative prediction, all the way to several hundred predictions, takes only a matter of seconds to complete on a normal desktop PC.  Additionally, training the models can completed in a matter of minutes on a desktop PC as well.  \",\n",
      "        \"matches_model/availability\": \"As mentioned earlier, all software, code and supporting data are available on our GitHub repository (10.5281/zenodo.10667840 or https://github.com/VisualPhysiologyDB/visual-physiology-opsin-db/). All data and code (software) is covered under a GNU General Public License (Version 3), in accordance with Open Source Initiative (OSI)-policies. \",\n",
      "        \"matches_dataset/provenance\": \"The source of the data is from a database we compiled, the Visual Physiology Opsin Database (VPOD) (10.5281/zenodo.10667840 or https://github.com/VisualPhysiologyDB/visual-physiology-opsin-db/). VPOD_1.0 is a new database, available on GitHub, that currently includes all heterologously expressed animal opsins. We refer to a subset of the database with only heterologous data as VPOD_het_1.0, although for version 1.0, this is synonymous with the entire database. VPOD_het_1.0 relies on 68 publications, mainly primary sources, with dates ranging from the 1980\\u2019s to 2023. The database contains opsin sequences and phenotype data from 166 unique species (counting 35 reconstructed ancestors), including fishes, amphibians, reptiles, mammals, crustaceans, and bivalves. Altogether, VPOD_het_1.0 contains 864 unique opsin sequences and corresponding \\u03bbmax values.\",\n",
      "        \"matches_dataset/splits\": \"For model training, a whole dataset it submitted to the algorithm training pipeline and it is randomly sampled to split the data such  that 80% is used for training, and 20% is used for model validation. The amount of data points in these splits/sets are dependent on the subset of data used to train the models. As mentioned earlier, VPOD_het_1.0 contains 864 unique opsin sequences and corresponding \\u03bbmax values. From this we created eleven data subsets with varying levels of taxonomic and gene family inclusivity to test which factors most impact the reliability/performance of ML methods.\",\n",
      "        \"matches_dataset/redundancy\": \"We used naming conventions that include versioning to improve reproducibility and reliability of individual datasets and models. For example, one subset combines ultraviolet and SWS opsins, which we named VPOD_uss_het_1.0 (n=280). Our convention is to name the subset (in this case USS = \\u2018Ultraviolet and Short-wave Sensitive\\u2019 opsins); name the source of phenotype data (heterologous = het), and record the version number of the dataset (1.0). We also created subsets for medium- and long-wave sensitive opsins (VPOD_mls_het_1.0)(n=91) and all rod (Rh1) and rod-like (Rh2) opsins (VPOD_rod_het_1.0)(n=352). Other subsets use species taxonomy, one for vertebrates (VPOD_vert_het_1.0)(n=721) and another for invertebrates (VPOD_inv_het_1.0)(n=143). For taxonomic subsets, we considered all sequences from phylum Chordata as \\u2018vertebrates\\u2019 and the rest as 'invertebrates\\u2019. Another subset excludes all mutant opsin sequences, called \\u2018wild-types\\u2019 (VPOD_wt_het_1.0)(n=318). A final named subset is the whole data set (VPOD_wds_het_1.0)(n=864). \\nWe used naming conventions that include versioning to improve reproducibility and reliability of individual datasets and models. For example, one subset combines ultraviolet and SWS opsins, which we named VPOD_uss_het_1.0 (n=280). Our convention is to name the subset (in this case USS = \\u2018Ultraviolet and Short-wave Sensitive\\u2019 opsins); name the source of phenotype data (heterologous = het), and record the version number of the dataset (1.0). We also created subsets for medium- and long-wave sensitive opsins (VPOD_mls_het_1.0)(n=91) and all rod (Rh1) and rod-like (Rh2) opsins (VPOD_rod_het_1.0)(n=352). Other subsets use species taxonomy, one for vertebrates (VPOD_vert_het_1.0)(n=721) and another for invertebrates (VPOD_inv_het_1.0)(n=143). For taxonomic subsets, we considered all sequences from phylum Chordata as \\u2018vertebrates\\u2019 and the rest as 'invertebrates\\u2019. Another subset excludes all mutant opsin sequences, called \\u2018wild-types\\u2019 (VPOD_wt_het_1.0)(n=318). A final named subset is the whole data set (VPOD_wds_het_1.0)(n=864). \\n\",\n",
      "        \"matches_dataset/availability\": \"The data set(s) supporting the results and all other code used in this article are available in the \\u2018Visual Physiology Opsin Database\\u2019 GitHub repository, (10.5281/zenodo.10667840 or https://github.com/VisualPhysiologyDB/visual-physiology-opsin-db/). All data and code is covered under a GNU General Public License (Version 3), in accordance with Open Source Initiative (OSI)-policies.  DOME-ML (Data, Optimisation, Model, and Evaluation in Machine Learning) annotation, supporting the current study, is available through DOME Wizard.\\n\",\n",
      "        \"matches_publication/title\": \"Discovering genotype-phenotype relationships with machine learning and the Visual Physiology Opsin Database (VPOD)\",\n",
      "        \"matches_publication/authors\": \"Seth A. Frazer, Mahdi Baghbanzadeh, Ali Rahnavard, Keith A. Crandall, Todd H. Oakley\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"65f598d51502715bfe53d2d8\",\n",
      "        \"uuid\": \"e2ca04b9-38fe-40d6-9fd9-5c8355f4402d\",\n",
      "        \"created\": \"2024-03-16T13:04:21.998Z\",\n",
      "        \"updated\": \"2024-03-16T13:04:21.998Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_pmid\": \"39172545\",\n",
      "        \"publication_authors\": \"Guowei Chen, Jingzhe Jiang, and Yanni Sun\",\n",
      "        \"publication_journal\": \"GigaScience\",\n",
      "        \"publication_title\": \"VirHost: a machine learning-based method for predicting reservoir hosts of RNA viruses through viral genomes\",\n",
      "        \"publication_doi\": \"10.1093/gigascience/giae059\",\n",
      "        \"publication_year\": \"2024\",\n",
      "        \"shortid\": \"ta01kc1au8\",\n",
      "        \"score\": 0.95,\n",
      "        \"matches_evaluation/availability\": \"They are availble in the GigaDB and supplementary information.\",\n",
      "        \"matches_evaluation/comparison\": \"Yes, we set the alignment-based method, BLASTN, as the baseline model. We then further comared VirHost with various available learning-based methods and validated the outperforming accuracy of VirHost.\",\n",
      "        \"matches_evaluation/confidence\": \"We evaluated all the benchmark models across virus orders by their accuracy distribution. VirHost outperformed any other models from the average accuracy. We also tested confidence of the superior accuracy by one-sided Wilcoxon test, which gave p-value smaller then 0.005\",\n",
      "        \"matches_evaluation/measure\": \"We used accuracy, precision, and prediction rate and the performance metrics in this study. These metrics are widely used in previous studies, like DOI:10.1126/science.aap9072 and doi: 10.1093/bioinformatics/btab33 .\",\n",
      "        \"matches_evaluation/method\": \"We extensively assessed the models by stratified 5-fold cross evaluation, leave-one-genus-out experiment, and recently-identified novel RNA viuses.\",\n",
      "        \"matches_optimization/algorithm\": \"We designated XGBoost as the learning architecture out of its superiors accuracy and training efficiency. To validate our choice, we conducted an evaluation of several learning architectures, encompassing XGBoost, Gradient Boosting Decision Tree (GBDT), Random Forest (RF), Support Vector Machine with RBF kernel (SVM), Logistic Regression (LR), K-Nearest Neighbors (KNN), and Gaussian Naive Bayes (GNB). Using the scikit-learn and xgboost package, default parameters were employed to train these models, and their performance was assessed using accuracy as the evaluation metric.\",\n",
      "        \"matches_optimization/config\": \"All of the model configuration can be easily access from the scikit-learn and xgboost documentation. If you wanna check the parameters of our models, you may load the models by pickle package and used the command \\\"model.get_xgb_params()\\\"\",\n",
      "        \"matches_optimization/encoding\": \"We encode the query sequences by their genomic traits and sequence homology. Specifically, we encode the sequences into a (137+m) dimensional vector as the input to models, where m is the number of host labels in the corresponding virus order and model layer. The genomic traits is vectorized as a 137-dimensional vector. To encode the m feature, we first group the reference viruses by their host labels, and then align the query virus against the reference viruses. The highest similarity score against each group is kept to be the corresponding feature value.\",\n",
      "        \"matches_optimization/features\": \"Two groups of feature are used as input, 137 genomic traits and the viral sequence homology. Although we did feature selection, we simply compared the feature contribution and model accuracy between the 137 genomic tratis and the codon pairs groups. This is done in the cross validation experiment. For a fair comparison, we removed all of the codon pair scores without using any relatively important ones, which will not result in the data leakage.\",\n",
      "        \"matches_optimization/fitting\": \"We did not focus on ruling out overfitting or underfitting. However, it is worth noting that the parameter count of XGBoost is typically lower than that of neural networks. Additionally, XGBoost incorporates L2 regularization by default, which helps mitigate the risk of overfitting.\",\n",
      "        \"matches_optimization/parameters\": \"For all of the above-mentioned models, we use the default hyperparameters from scikit-learn and xgboost library to train.\",\n",
      "        \"matches_optimization/regularization\": \"XGBoost incorporates L2 regularization by default, which helps mitigate the risk of overfitting. Besides, we adopted the early stop strategy by evaluating the prediction probability of our models. We set probability cutoff for each model to distinguish predictions with low confidence.\",\n",
      "        \"matches_model/availability\": \"It can be access by https://github.com/GreyGuoweiChen/VirHost\",\n",
      "        \"matches_model/duration\": \"It takes around 5 seconds to run the test cases (3 viruses) on a normal desktop PC.\",\n",
      "        \"matches_model/interpretability\": \"The models are black box models. But we provide the evidence and different confidence level of our predictions to users.\",\n",
      "        \"matches_model/output\": \"We build hierarchical classification models for each virus order.\",\n",
      "        \"matches_dataset/availability\": \"The data supporting the results and software in this article are available in the \\u2018VirHost\\u2019 GitHub repository, (https://github.com/GreyGuoweiChen/VirHost). All data and code is covered under a MIT License. The analytic code is accessible from the GigaDB.\",\n",
      "        \"matches_dataset/provenance\": \"We collected 6,735 RNA viruses from Virus-Host Database and 126,417 records with host annotations from NCBI GenBank, both of which are widely used database. After the careful data preprocessings, including de-replication and removal of ambiguous host annotations, we finally got 14500 RNA viruses, spanning 30 virus orders and 12 host groups, including Invertebrate, Viridiplantae, Fungi, Bacteria, Primates, Rodentia, Artiodactyla, Carnivora, Other mammalia, Aves, Reptilia, and Fish. We also evaluated our method in a set of newly-identified RNA viruses, whose hosts are derived based on experimental evidence. The set includes 126 RNA viruses and were collected from various hosts, including Plant, Invertebrate, Fungi, and Fish. The dataset is complied from 20 publications.\",\n",
      "        \"matches_dataset/redundancy\": \"We evalaute the model by cross-validation, leave-one-genus-out experiment and recently-identified viruses, which are not included in the training data. In all datasets, the training and test sets are independent. Before the evaluation, we remove the data redundancy to be less than 90% coverage and 80% identity. In leave-one-genus-out experiment and recently-identified viruses, the sequence identity between training and test set is even lower. \",\n",
      "        \"matches_dataset/splits\": \"We first evalute the learning architecture by stratified 5-fold cross validation. The viruses in corresponding virus orders are stratified splited into 5 folds by their labels, with 4 folds as training set and 1 as test set. We evaluated the models on each fold and average the results. There is no duplicate samples between the training and test datasets. \\nBesides, we evaluated the models by conducting leave-one-genus-out experiments. Specifically, we used one genus as test set and viruses from other genuses as training set to assess the generalizability of the models. There are 448 virus genera in total. This experiment is a strong demonstration of the generality of the model; no viruses of the same genus are distributed in both the training and test data. \",\n",
      "        \"matches_publication/authors\": \"Guowei Chen, Jingzhe Jiang, and Yanni Sun\",\n",
      "        \"matches_publication/title\": \"VirHost: a machine learning-based method for predicting reservoir hosts of RNA viruses through viral genomes\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e670661d57eb8bca69602\",\n",
      "        \"shortid\": \"bxlfk5g20v\",\n",
      "        \"uuid\": \"bb9e3878-75dc-4120-88f4-0a98f0195ec1\",\n",
      "        \"created\": \"2024-10-15T12:58:46.423Z\",\n",
      "        \"updated\": \"2024-10-15T12:58:46.423Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_title\": \"Machine Learning Made Easy (MLme): a comprehensive toolkit for machine learning\\u2013driven data analysis\",\n",
      "        \"publication_authors\": \"Akshay Akshay, Mitali Katoch, Navid Shekarchizadeh, Masoud Abedi, Ankush Sharma, Fiona C Burkhard, Rosalyn M Adam, Katia Monastyrskaya, Ali Hashemi Gheinani\",\n",
      "        \"publication_journal\": \"GigaScience\",\n",
      "        \"publication_year\": \"2024\",\n",
      "        \"publication_pmid\": \"38206587\",\n",
      "        \"publication_doi\": \"10.1093/gigascience/giad111\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 6,\n",
      "        \"score\": 0.74,\n",
      "        \"matches_evaluation/method\": \"We consistently maintained an independent test set for all datasets to evaluate the model performance accurately. In addition, we employed multiple model evaluation techniques such as repeated stratified k-fold cross-validation, nested cross-validation, and others. These techniques allow for robust and reliable assessment of the models, taking into account the variance and potential bias in the data. By utilizing such methods, we aimed to obtain a comprehensive understanding of the model's performance across different folds and iterations, enhancing the reliability of our results.\",\n",
      "        \"matches_evaluation/measure\": \"We computed more than 10 evaluation metrics, including precision, recall, F1 score, and area under the curve (AUC), for each trained model across all datasets. This comprehensive approach enabled us to gain a thorough understanding of the model's performance from multiple angles and perspectives\",\n",
      "        \"matches_evaluation/comparison\": \"We compared the performance of our trained models with a dummy classifier, which is a classifier that makes random predictions. Typically, it is expected that the trained models will outperform the dummy classifier. This serves as a baseline comparison to assess the effectiveness and superiority of our trained models. By comparing the performance metrics of our models against the random predictions of the dummy classifier, we can evaluate the added value and efficacy of our trained models in making accurate predictions.\",\n",
      "        \"matches_evaluation/availability\": \"All the trained models and corresponding performance results are available on (https://doi.org/10.5281/zenodo.8073635) under the Creative Commons - CC0 license.\",\n",
      "        \"matches_optimization/algorithm\": \"We have utilized over 15 classification algorithms for each dataset in order to classify the classes within each datasets.\",\n",
      "        \"matches_optimization/meta\": \"The ML pipeline employed in this project incorporates several preprocessing steps, including data resampling and feature selection. These steps are followed by model training and evaluation. To prevent any potential data leakage, we perform data preparation within cross validation folds. Additionally, we maintain an independent test dataset to ensure accurate and unbiased evaluation.\",\n",
      "        \"matches_optimization/config\": \"We did not perform any hyperparameter tuning for the trained models. However, all the trained models and corresponding performance results are available on Zenodo (https://doi.org/10.5281/zenodo.8073635) under the Creative Commons - CC0 license.\",\n",
      "        \"matches_optimization/encoding\": \"For the CLL patients dataset, we exclusively utilized the top 5,000 most variable mRNAs, excluding genes from the Y chromosome, as input for ML pipeline. As for the BRCA mRNA dataset, we concentrated solely on differentially expressed genes identified by edgeR, with a threshold of FDR \\u2264 0.001 and logFC > \\u00b1 2.  For the PBMC dataset, we utilized only 500 highly variable genes across the three cell populations. For all other datasets, we employed them as they were originally available without any modifications.\",\n",
      "        \"matches_optimization/features\": \"To evaluate MLme, we utilized datasets ranging from 10 features to 5000 features. Feature selection was performed on all the datasets, but we always maintained an independent dataset solely for evaluating the model's performance. It's important to note that this independent dataset was not used for any kind of preprocessing or model training.\",\n",
      "        \"matches_optimization/fitting\": \"We consistently maintained an independent test set for all datasets in order to evaluate the model's performance and determine if there was any overfitting or underfitting. Additionally, we employed cross-validation methods and feature selection techniques to mitigate the risk of overfitting. These measures helped ensure a more reliable assessment of the model's generalization capabilities and minimize the influence of biased or noisy data.\",\n",
      "        \"matches_optimization/parameters\": \"The majority of the trained models were utilized with their default parameters.\",\n",
      "        \"matches_optimization/regularization\": \"We employed cross-validation methods and feature selection techniques to mitigate the risk of overfitting. These measures helped ensure a more reliable assessment of the model's generalization capabilities and minimize the influence of biased or noisy data.\",\n",
      "        \"matches_model/interpretability\": \"We have used multiple ML classification algorithms, some of which are black box models. For example, SVM (Support Vector Machine) is considered a black box model, but features like support vectors and feature importance can offer some interpretability. In contrast, kNN (K-Nearest Neighbors) is generally interpretable as it relies on nearest neighbors and distance metrics.\",\n",
      "        \"matches_model/duration\": \"It is not applicable to current project.\",\n",
      "        \"matches_model/availability\": \"The source code for MLme is available at https://github.com/FunctionalUrology/MLme with GNU GENERAL PUBLIC LICENSE.\",\n",
      "        \"matches_dataset/provenance\": \"\\nIn this project, we utilized six different publicly available datasets that are well recognized in the domain. The first dataset consisted of mRNA data obtained from a study on Chronic Lymphocytic Leukemia (CLL) patients, measuring their transcriptome profiles. The second dataset was collected from a cervical cancer study that analyzed the expression levels of 714 miRNAs in human samples. The third and fourth datasets were obtained from The Cancer Genome Atlas (TCGA) and included mRNA and miRNA sequencing data from patients with Breast Invasive Carcinoma (BRCA). \\n  <br>\\n  <br>\\n\\n\\nThe fifth dataset consists of scRNA-seq data obtained from peripheral blood mononuclear cells (PBMCs) that were sequenced using 10\\u00d7 chromium technology. Among all the cell populations described in this study, we specifically utilized the scRNA datasets of CD8+ na\\u00efve, CD14+, and CD16+ monocytes (n=1500) with the goal of identifying distinct markers for each of these cell populations. The sixth dataset used in this study was the widely recognized Glass Identification dataset obtained from the University of California Irvine (UCI) ML repository.\\n  \\n<!DOCTYPE html>\\n<html>\\n<head>\\n<style>\\ntable {\\n  text-align: center;\\n}\\nth {\\n  text-align: center;\\n}\\n</style>\\n</head>\\n<body>\\n\\n<table>\\n\\n  <tr>\\n    <th>Dataset</th>\\n    <th>Data type</th>\\n    <th>Number of Samples</th>\\n    <th>Number of Features</th>\\n    <th>Target Class ratio</th>\\n  </tr>\\n  <tr>\\n    <td>CLL</td>\\n    <td>mRNA</td>\\n    <td>136</td>\\n    <td>5000</td>\\n    <td>Male (n=82): Female (n=54)</td>\\n  </tr>\\n  <tr>\\n    <td>Cervical cancer</td>\\n    <td>miRNA</td>\\n    <td>58</td>\\n    <td>714</td>\\n    <td>Normal (n=29): Tumor (n=29)</td>\\n  </tr>\\n  <tr>\\n    <td>TCGA-BRCA</td>\\n    <td>miRNA</td>\\n    <td>1207</td>\\n    <td>1404</td>\\n    <td>Normal (n=104): Tumor (n=1104)</td>\\n  </tr>\\n  <tr>\\n    <td>TCGA-BRCA</td>\\n    <td>mRNA</td>\\n    <td>1219</td>\\n    <td>5520</td>\\n    <td>Normal (n=113): Tumor (n=1106)</td>\\n  </tr>\\n  <tr>\\n    <td> PBMC </td>\\n    <td> scRNA-seq </td>\\n    <td>1500</td>\\n    <td>500</td>\\n    <td> CD8 Naive (n=500 cells) : CD14 Monocytes (n=500 cells) : CD16 Monocytes (n=500 cells) )</td>\\n  </tr>\\n\\n  <tr>\\n    <td>Glass Identification</td>\\n    <td>Oxide content (i.e., Na, Fe, K, etc)</td>\\n    <td>214</td>\\n    <td>10</td>\\n    <td>Glass 1 (70), Glass 2 (76), Glass 3 (17), Glass 5 (12), Glass 6 (10), Glass 7 (29)</td>\\n  </tr>\\n</table>\\n\\n</body>\\n</html>\\n\\n\",\n",
      "        \"matches_dataset/splits\": \"We kept a separate test/validation dataset to assess the model's performance on each dataset. The initial datasets were randomly divided, but in a way that preserved proportional representation of each class in the given dataset, with 70% assigned to the training and 30% assigned to the test dataset.\",\n",
      "        \"matches_dataset/redundancy\": \"We retained an independent dataset to evaluate the performance of the model for each dataset. The original datasets were divided randomly but in a stratified manner, with 70% allocated to the training dataset and 30% allocated to the test dataset.\",\n",
      "        \"matches_dataset/availability\": \"The datasets we have utilized are publicly available datasets. All the relevant details can be found in the manuscript.\",\n",
      "        \"matches_publication/title\": \"Machine Learning Made Easy (MLme): a comprehensive toolkit for machine learning\\u2013driven data analysis\",\n",
      "        \"matches_publication/authors\": \"Akshay Akshay, Mitali Katoch, Navid Shekarchizadeh, Masoud Abedi, Ankush Sharma, Fiona C Burkhard, Rosalyn M Adam, Katia Monastyrskaya, Ali Hashemi Gheinani\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e68a561d57eb8bca69606\",\n",
      "        \"shortid\": \"z5ym87wvmo\",\n",
      "        \"uuid\": \"567d717d-1210-4ce3-92f1-effeabb4d133\",\n",
      "        \"created\": \"2024-10-15T13:05:41.358Z\",\n",
      "        \"updated\": \"2024-10-15T13:05:41.358Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_title\": \"Julearn: an easy-to-use library for leakage-free evaluation and inspection of ML models\",\n",
      "        \"publication_authors\": \"Sami Hamdan, Shammi More, Leonard Sasse, Vera Komeyer, Kaustubh R. Patil, Federico Raimondo\",\n",
      "        \"publication_journal\": \"GigaScience\",\n",
      "        \"publication_year\": \"2024\",\n",
      "        \"publication_pmid\": \"38496213\",\n",
      "        \"publication_doi\": \"10.46471/gigabyte.113\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 6,\n",
      "        \"score\": 0.74,\n",
      "        \"matches_evaluation/method\": \"We used nested cross-validation. Therefore cross-validation.\",\n",
      "        \"matches_evaluation/measure\": \"We used common sets of metrics given the literature. Names of scores refer to the in julearn used names: \\nReplication 1:  [\\n    \\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_squared_error\\\",\\n    \\\"r2\\\",\\n]\\n\\nReplication 2: Performed standard training, scoring with accuracy. Reported mean age of misclassified for corrected and uncorrected models\\n\\nReplication 3:  [\\\"neg_mean_absolute_error\\\",\\n    \\\"neg_mean_squared_error\\\",\\n    \\\"neg_root_mean_squared_error\\\",\\n    \\\"neg_median_absolute_error\\\",\\n    \\\"r2\\\",\\n    \\\"r_corr\\\"]\",\n",
      "        \"matches_evaluation/comparison\": \"We do not claim any improvements over previous methods. Therefore we only performed comparisons also performed in the replicated work. \",\n",
      "        \"matches_evaluation/confidence\": \"The replication examples were able to replicate previous work. Where needed we also show significance and measurements of confidence, i.e. Replication 1 & 2\",\n",
      "        \"matches_evaluation/availability\": \"All code is available here:  https://github.com/juaml/julearn_paper/ (Attribution-NonCommercial-ShareAlike 4.0 International licence). This includes information about what comparisons are made and how we got to the presented results. \",\n",
      "        \"matches_optimization/algorithm\": \"We propose software compatible with scikit-learn standard. It allows users to use any ML algorithm class compatible with that standard. \\nFurthermore, we illustrated or software using multiple examples (including 3 replications).\\nHere we used the following algorithm classes: \\nSVM, RVR, Gaussian Models and unsupervised methods like: PCA & CBPM. \\n\\nThere are no newly proposed ML algorithms.\",\n",
      "        \"matches_optimization/meta\": \"No meta-predictions were used.\",\n",
      "        \"matches_optimization/config\": \"This information ist included in our GitHub repository under: https://github.com/juaml/julearn_paper/ with a Attribution-NonCommercial-ShareAlike 4.0 International licence\",\n",
      "        \"matches_optimization/encoding\": \"PCA, Z-Scoring, Feature Selection, Confound Regression\",\n",
      "        \"matches_optimization/features\": \"All preprocessing steps including feature selection were trained only on the training set in a CV consistent way.\\nVariance thresholding was used in Replication Example 1.\\nCBPM thresholds significantly correlated features with the target and was used in Example 3.\",\n",
      "        \"matches_optimization/fitting\": \"Our analyses are replications of previous research following there setup as we only want to show that our software is able to reproduce previous research. Therefore we know that we at least fitted as well as previous research. Overfitting was ruled out by our regigorous nested cross-validation setupts. As mentioned before we used feature selection or PCA to reduce the number of features if needed to decrease the p. \",\n",
      "        \"matches_optimization/parameters\": \"Using notation of Hyperparameter=ListOfParameters\\nCV -> Cross-Validation\\n\\nReplication Example 1:\\nRVR 1 - using CV: kernel=[\\\"linear\\\", \\\"poly\\\"], degree=[1, 2] and Model 2 using CV: kernel=[\\\"linear\\\", \\\"rbf\\\", \\\"poly\\\"], C=[0.01, 0.1]\\n\\nReplication Example 2: \\nSVM - using CV: C=np.arange(0.1, 4, 0.2)\\n\\nReplication Example 3: \\nCBPM - using manual combinations documented in open source code: \\ncorr_signs = [\\\"pos\\\", \\\"neg\\\", \\\"posneg\\\"]\\nsignificance_threshold = [0.01, 0.05, 0.10 p]\\n\",\n",
      "        \"matches_optimization/regularization\": \"Maninly nested cross-validation.\",\n",
      "        \"matches_model/interpretability\": \"Models used range in their interpretabilty, but all of them are reasonably interpretable using common methods like permutation importance. Some havea direct interpretation of weights such as gaussian models. As we do not aim to gain any new evidence interpretability of the models is not relevant for this work.\",\n",
      "        \"matches_model/output\": \"Replication 1 Models are regression \\nReplication 2 Models are classification\\nReplication 3 Models are regression\",\n",
      "        \"matches_model/availability\": \"Yes our examples are released here: https://github.com/juaml/julearn_paper/ (Attribution-NonCommercial-ShareAlike 4.0 International licence) and the actual software is released here https://github.com/juaml/julearn (GNU Affero General Public License)\",\n",
      "        \"matches_dataset/provenance\": \"All data we use is recognized by the community and was used by it before. As we only do replication examples our analyses and data is by design recognized. \\n\\nReplication 1 Data:   562 data points\\nReplication 2 Data:  498 data points  (291 controls, 207 after balancing)\\nReplication 3 Data: 368 data points \",\n",
      "        \"matches_dataset/splits\": \"Replication 1: Repeated K-Fold Cross-Validation with 5 repeats and 5 equal splits (80% training)\\nReplication 2: Repeated K-Fold Cross-Validation with 60 repeats and 2 splits (50% training) following the work to be replicated\\nReplication 3: Used different cross-validation schemas for different subexperiments out of the following options: \\nLeave-One-Out (1 data point for testing) or Repeated  K-Fold Cross-Validation with 10 repeats and 10 equal splits (90% training)\\n\\nWhen applying hyperparameter tuning training is spitted using another 5 Fold Cross-Validation.\",\n",
      "        \"matches_dataset/redundancy\": \"The splits were created using K-Fold cross-validation. This makes training and test set independent on the level of each iteration. \",\n",
      "        \"matches_dataset/availability\": \"The data splits are created using reproducible code you can find  in our GitHub repository under: https://github.com/juaml/julearn_paper/ with a Attribution-NonCommercial-ShareAlike 4.0 International licence.\",\n",
      "        \"matches_publication/title\": \"Julearn: an easy-to-use library for leakage-free evaluation and inspection of ML models\",\n",
      "        \"matches_publication/authors\": \"Sami Hamdan, Shammi More, Leonard Sasse, Vera Komeyer, Kaustubh R. Patil, Federico Raimondo\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e6a0961d57eb8bca6960a\",\n",
      "        \"shortid\": \"dfyn1yvtz3\",\n",
      "        \"uuid\": \"1261ec25-2b6d-4a8a-aca6-a50c235a4737\",\n",
      "        \"created\": \"2024-10-15T13:11:37.812Z\",\n",
      "        \"updated\": \"2024-10-15T13:11:37.812Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_title\": \"Large-scale Genomic Survey with Deep Learning-based Method Reveals Strain-Level Phage Specificity Determinants\",\n",
      "        \"publication_authors\": \"Yiyan Yang, Keith Dufault-Thompson, Wei Yan, Tian Cai, Lei Xie, Xiaofang Jiang\",\n",
      "        \"publication_journal\": \"GigaScience\",\n",
      "        \"publication_year\": \"2024\",\n",
      "        \"publication_pmid\": \"38649301\",\n",
      "        \"publication_doi\": \"10.1093/gigascience/giae017\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 6,\n",
      "        \"score\": 0.7,\n",
      "        \"matches_evaluation/method\": \"It was evaluated by an independent test dataset.\",\n",
      "        \"matches_evaluation/measure\": \"Evaluation of the model on the testing dataset demonstrated an F1-score of 0.994, precision of 0.991, recall of 0.996, specificity of 1.000, a Mathew\\u2019s correlation coefficient (MCC) of 0.994, and the area under the precision-recall curve of 0.994.\",\n",
      "        \"matches_evaluation/availability\": \"Yes. The data is accessible via GigaDB and the supplemental material.\",\n",
      "        \"matches_optimization/algorithm\": \"This is a deep-learning model that utilizes the pre-trained transformer protein language model ESM-2 (esm2_t33_650M_UR50D) as an embedding layer. This embedding layer is then linked to a neural network comprising three fully connected layers with 1280, 568, and 2 nodes, respectively. The output layer employs a softmax activation function to produce probabilities, indicating whether each sequence corresponds to a tailspike protein or not.\",\n",
      "        \"matches_optimization/meta\": \"This model is not a meta-predictor.\",\n",
      "        \"matches_optimization/config\": \"Yes. The deep-learning model trained in this study is provided at https://figshare.com/articles/online_resource/SpikeHunter_trained_model_pth_file/23577051.\",\n",
      "        \"matches_optimization/encoding\": \"Phage protein sequences were tokenized and transformed into numerical vectors using the batch_converter function in the ESM Python package (https://github.com/facebookresearch/esm).\",\n",
      "        \"matches_optimization/features\": \"Since the sequences are embedded as 1280-length representations using a pre-trained transformer protein language model ESM-2 during training, the number of input features before embedding varies depending on the lengths of protein sequences, while the number of features after the embedding is 1280. No feature selection strategy was performed.\",\n",
      "        \"matches_optimization/fitting\": \"The model's parameter count is approximately eight times the number of training data points. Early stopping was adopted to stop training once the model performance was no longer improved on the validation dataset for three consecutive epochs to avoid overfitting.\",\n",
      "        \"matches_optimization/regularization\": \"Early stopping was adopted to stop training once the model performance was no longer improved on the validation dataset for three consecutive epochs to avoid overfitting.\",\n",
      "        \"matches_model/interpretability\": \"It is a black box.\",\n",
      "        \"matches_model/output\": \"The model is a classification that outputs probabilities to indicate whether each sequence corresponds to a tailspike protein or not.\",\n",
      "        \"matches_model/duration\": \"3 days with two NVIDIA v100x GPUs on a high-performance computing cluster.\",\n",
      "        \"matches_model/availability\": \"Yes, the source code is released at https://github.com/nlm-irp-jianglab/SpikeHunter.\",\n",
      "        \"matches_dataset/provenance\": \"The source of the dataset is INfrastructure for a PHAge REference Database (INPHARED) provided by https://github.com/RyanCook94/inphared on Aug 1st, 2022. There are 3,659 bacteriophage genomes in this dataset. We curated 1912 tailspike protein sequences and 200732 non-tailspike protein sequences from this dataset. This data has not been used in previous papers.\",\n",
      "        \"matches_dataset/splits\": \"The dataset was divided into training, validation, and testing datasets in a ratio of 3:1:1. The training set includes 122,506 proteins (comprising 1,023 positive samples and 121,483 negative samples belonging to 12,170 clusters), a validation set 40,838 proteins (comprising 343 positive samples and 40,495 negative samples belonging to 4,054 clusters), and a test set 39,300 proteins (comprising 546 positive samples and 38,754 negative samples belonging to 4,050 clusters).\",\n",
      "        \"matches_dataset/redundancy\": \"To train and validate the SpikeHunter the manually curated set of tailspike proteins was first clustered into 20,274 clusters at 30% identity using CD-HIT. The dataset was divided into training, validation, and testing datasets in a ratio of 3:1:1 using the StratifiedGroupKFold function in the Scikit-learn python package, with two key objectives in mind: 1) ensuring the absence of overlaps among protein clusters, and 2) maintaining consistent ratios of positive to negative samples across the splits. As a result of this process, the training, validation and test sets are independent.\",\n",
      "        \"matches_dataset/availability\": \"The data is accessible via GigaDB and the supplemental material.\",\n",
      "        \"matches_publication/title\": \"Large-scale Genomic Survey with Deep Learning-based Method Reveals Strain-Level Phage Specificity Determinants\",\n",
      "        \"matches_publication/authors\": \"Yiyan Yang, Keith Dufault-Thompson, Wei Yan, Tian Cai, Lei Xie, Xiaofang Jiang\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e6eef61d57eb8bca6960e\",\n",
      "        \"shortid\": \"345ml05xtn\",\n",
      "        \"uuid\": \"dfddd412-f46b-447b-8ab6-a45bfeaf37c2\",\n",
      "        \"created\": \"2024-10-15T13:32:31.707Z\",\n",
      "        \"updated\": \"2024-10-15T13:32:31.707Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_title\": \"spatiAlign: an unsupervised contrastive learning model for data integration of spatially resolved transcriptomics\",\n",
      "        \"publication_authors\": \"Chao Zhang, Lin Liu, Ying Zhang, Mei Li, Shuangsang Fang, Qiang Kang, Ao Chen, Xun Xu, Yong Zhang, Yuxiang Li\",\n",
      "        \"publication_journal\": \"GigaScience\",\n",
      "        \"publication_year\": \"2024\",\n",
      "        \"publication_pmid\": \"39028588\",\n",
      "        \"publication_doi\": \"10.1093/gigascience/giae042\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 6,\n",
      "        \"score\": 0.59,\n",
      "        \"matches_evaluation/method\": \"We use different dataset to evaluate our method, which include measured by different sequencing platforms, different time-series, different regions, et al.\",\n",
      "        \"matches_evaluation/measure\": \"F1 score of local inverse Simpson's index, adjusted rand index, Moran's I index\\nDownstream bioinformation analysis, differential expression analysis, GO enrichment analysis, trajectory inference analysis, et al.\",\n",
      "        \"matches_evaluation/comparison\": \"benchmarking method: PRECAST, GraphST, SCALEX, Harmony, Combat, BBKNN, Scanorama, MNN\",\n",
      "        \"matches_optimization/algorithm\": \"We first implement a self-supervised contrastive learning architecture (Deep graph infomax framework) for dimensional reduction while simultaneously propagating neighbouring spatil context between spots/cells. And we employ an across-domain adaptation technique to align joint embeddings. \",\n",
      "        \"matches_optimization/config\": \" No\",\n",
      "        \"matches_optimization/encoding\": \"The collected datasets were be saved as '*.h5ad' format, and also includes two-dimensional spatial coordinates for each spot/cell. The dataformat can reference: https://anndata.readthedocs.io/en/latest/  In the preprocessing step, the raw gene expression matrices were first filtered according to criteria 'min_gene' smaller than 20 and 'min_cell' smaller than 20  for each data using SCANPY (version: 1.9.1), and followed by normalization and log transformation of individual spots.  In our algorithm, spatiAlign, we just set the 'is_norm_log' to True.\",\n",
      "        \"matches_optimization/features\": \"base on input data list, we choose common genes as input\",\n",
      "        \"matches_optimization/parameters\": \"There are 17 instantiated model parameters. Details as follows,\\n:param data_path: List of input dataset path.\\n:param min_genes: Minimum number of genes expressed required for a cell to pass filtering, default 20.\\n:param min_cells: Minimum number of cells expressed required for a gene to pass filtering, default 20.\\n:param batch_key: The batch annotation to :attr:`obs` using this key, default, 'batch'.\\n:param is_norm_log: Whether to perform 'sc.pp.normalize_total' and 'sc.pp.log1p' processing, default, True.\\n:param is_scale: Whether to perform 'sc.pp.scale' processing, default, False.\\n:param is_hvg: Whether to perform 'sc.pp.highly_variable_genes' processing, default, False.\\n:param is_reduce: Whether to perform PCA reduce dimensional processing, default, False.\\n:param n_pcs: PCA dimension reduction parameter, valid when 'is_reduce' is True, default, 100.\\n:param n_hvg: 'sc.pp.highly_variable_genes' parameter, valid when 'is_reduce' is True, default, 2000.\\n:param n_neigh: The number of neighbors selected when constructing a spatial neighbor graph. default, 15.\\n:param is_undirected: Whether the constructed spatial neighbor graph is undirected graph, default, True.\\n:param latent_dims: The number of embedding dimensions, default, 100.\\n:param is_verbose: Whether the detail information is print, default, True.\\n:param seed: Random seed.\\n:param gpu: Whether the GPU device is using to train spatialign.\\n:param save_path: The path of alignment dataset and saved spatialign.\\n\\nThere are 7 training model parameters. Details as follows,\\n:param lr: Learning rate, default, 1e-3.\\n:param max_epoch: The number of maximum epochs, default, 500.\\n:param alpha: The momentum parameter, default, 0.5\\n:param patient: Early stop parameter, default, 15.\\n:param tau1: Instance level and pseudo prototypical cluster level contrastive learning parameters, default, 0.2\\nparam tau2: Pseudo prototypical cluster entropy parameter, default, 1.\\n:param tau3: Cross-batch instance self-supervised learning parameter, default, 0.5\\n\",\n",
      "        \"matches_optimization/regularization\": \"early stopping\",\n",
      "        \"matches_model/interpretability\": \"early stopping\",\n",
      "        \"matches_model/output\": \"No, our model output a latent embedding and reconstructed representation, respectively.\",\n",
      "        \"matches_model/duration\": \"base on the input dataset\",\n",
      "        \"matches_model/availability\": \"github1: https://github.com/zhangchao162/Spatialign.git github2: https://github.com/STOmics/Spatialign.git pypi: https://pypi.org/project/spatialign/ tutorial: https://spatialign-tutorials.readthedocs.io/en/latest/index.html\",\n",
      "        \"matches_dataset/splits\": \"We did not split the data and used all datasets for model training and testing.\",\n",
      "        \"matches_dataset/availability\": \"Yes\\n1. Mouse olfactory bulb: \\na. The 10x Geomics Visium dataset can be download from: https://www.10xgenomics.com/resources/datasets/adult-mouse-olfactory-bulb-1-standard-1\\nb. The Stereo-seq datasets can be download from: https://db.cngb.org/stomics/mosta/download/\\n2. Human dorsolateral prefrontal cortex (DLPFC): the 10x Geomics Visium dataset and annotation file can be download from: https://zenodo.org/record/6925603#.YuM5WXZBwuU\\n3. Mouse hippocampal dataset: the Slide-seq datasets can be download from: https://singlecell.broadinstitute.org/single_cell/study/SCP815/highly-sensitive-spatial-transcriptomics-at-near-cellular-resolution-with-slide-seqv2#study-summary, https://singlecell.broadinstitute.org/single_cell/study/SCP354/slide-seq-study#study-summary, and https://singlecell.broadinstitute.org/single_cell/study/SCP948/robust-decomposition-of-cell-type-mixtures-in-spatial-transcriptomics#study-summary, respectively.\\n4. Mouse embryonic brain: the Stereo-seq datasets can be download from: https://db.cngb.org/stomics/mosta/download/\",\n",
      "        \"matches_publication/title\": \"spatiAlign: an unsupervised contrastive learning model for data integration of spatially resolved transcriptomics\",\n",
      "        \"matches_publication/authors\": \"Chao Zhang, Lin Liu, Ying Zhang, Mei Li, Shuangsang Fang, Qiang Kang, Ao Chen, Xun Xu, Yong Zhang, Yuxiang Li\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e70a761d57eb8bca69612\",\n",
      "        \"shortid\": \"iv50u2ycn5\",\n",
      "        \"uuid\": \"49b4a023-592f-4a04-bad2-827e519896e0\",\n",
      "        \"created\": \"2024-10-15T13:39:51.375Z\",\n",
      "        \"updated\": \"2024-10-15T13:39:51.375Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_title\": \"Omada: robust clustering of transcriptomes through multiple testing\",\n",
      "        \"publication_authors\": \"Sokratis Kariotis, Pei Fang Tan, Haiping Lu, Christopher J Rhodes, Martin R Wilkins, Allan Lawrie, Dennis Wang\",\n",
      "        \"publication_journal\": \"GigaScience\",\n",
      "        \"publication_year\": \"2024\",\n",
      "        \"publication_pmid\": \"38991852\",\n",
      "        \"publication_doi\": \"10.1093/gigascience/giae039\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 0,\n",
      "        \"score\": 0.95,\n",
      "        \"matches_evaluation/method\": \"Independent dataset.\",\n",
      "        \"matches_evaluation/measure\": \"As this is unsupervised learning the performance was justified biologically.\",\n",
      "        \"matches_evaluation/comparison\": \"There are no methods that address the same questions. \",\n",
      "        \"matches_evaluation/confidence\": \"The statistical significance was calculated based on biological differences and not ML metrics. \",\n",
      "        \"matches_evaluation/availability\": \"No, but the p-values of the biological validation can be found in https://www.nature.com/articles/s41467-021-27326-0.\",\n",
      "        \"matches_optimization/algorithm\": \"Three (unsupervised) widely-used clustering algorithms were used: spectral, k-means and hierarchical. \",\n",
      "        \"matches_optimization/meta\": \"The input does not consist of other ML algorithm results.\",\n",
      "        \"matches_optimization/encoding\": \"The data were in numeric form representing gene counts (FPKM or TPM depeding on the dataset). The processing consists of arcise transformation.\",\n",
      "        \"matches_optimization/features\": \"Each dataset used a different number of features ranging from 100 to 25,955. Feature selection was performed as a step of Omada using the average cluster stability for different feature subsets after they were ranked by expression variance.\",\n",
      "        \"matches_optimization/fitting\": \"This was unsupervised learning.\",\n",
      "        \"matches_optimization/parameters\": \"In this model, Spectral and k-means clustering allows one parameter (kernel) and hierarchical allows 2 parameters (distance measure and linkage). These parameters were selected to as they provide the most influence towards the clustering results.\",\n",
      "        \"matches_optimization/regularization\": \"This was unsupervised learning.\",\n",
      "        \"matches_model/interpretability\": \"Black box.\",\n",
      "        \"matches_model/output\": \"Unsupervised clustering.\",\n",
      "        \"matches_model/duration\": \"Under a minute for a dataset for few hundred datapoints/features.\",\n",
      "        \"matches_model/availability\": \"The source code can be found: https://github.com/BioSok/omada and is also published as a package in https://www.bioconductor.org/packages/release/bioc/html/omada.html.\",\n",
      "        \"matches_dataset/provenance\": \"Single-class simulated dataset: Simulated by using specific mean and standard deviation. This dataset only contains one class. The dataset hasn't been used before as it was generated from one of Omada's functions.\\n\\nMulti-class simulated dataset: Simulated by using specific means and standard deviations. This dataset contains five classes of almost identical sizes (72,72,72,72,71). The dataset hasn't been used before as it was generated from one of Omada's functions.\\n\\nPan-cancer dataset:  Sourced from https://pubmed.ncbi.nlm.nih.gov/32025007/ and contains 3 classes: Breast cancer found in https://www.cbioportal.org/study/summary?id=brca_tcga_pan_can_atlas_2018, Colorectal cancer found in https://www.cbioportal.org/study/summary?id=coadread_tcga_pan_can_atlas_2018 and Lung cancer found in https://www.cbioportal.org/study/summary?id=luad_tcga_pan_can_atlas_2018. These data have been used in several publications and are widely used for cancer studies.\\n\\nPAH dataset: The transcriptomic data can be found in the EGA (the European Genome-phenome Archive) database under accession code EGAS000010055326562 (https://ega-archive.org/studies/EGAS00001005532) . Restricted access, needs application. This dataset has no defined classes. It has been used by https://www.nature.com/articles/s41467-021-27326-0.\\n\\nGUSTO dataset: This dataset can be found in the GEO database with accession number GSE182409. There are no classes.\",\n",
      "        \"matches_dataset/splits\": \"Single-class simulated dataset: The dataset contains 100 datapoints. No test set as this was used for unsupervised learning methods.\\n\\nMulti-class simulated dataset: The dataset contains 359 datapoints. No test set as this was used for unsupervised learning methods.\\n\\nPan-cancer dataset:  Each of the three classes have the following datapoints: breast (n=1084), lung (n=566) and colorectal (n=594). No test set as this was used for unsupervised learning methods.\\n\\nPAH dataset: The dataset contains 359 datapoints. No test set as this was used for unsupervised learning methods.\\n\\nGUSTO dataset: The dataset contains 238 datapoints. No test set as this was used for unsupervised learning methods.\",\n",
      "        \"matches_dataset/redundancy\": \"No test sets for any dataset.\",\n",
      "        \"matches_dataset/availability\": \"Single-class simulated dataset: Yes, published on https://github.com/BioSok/OmadaSimulatedDatasets. \\n\\nMulti-class simulated dataset: Yes, published on https://github.com/BioSok/OmadaSimulatedDatasets. \\n\\nPan-cancer dataset: These is public data and the Breast cancer found in https://www.cbioportal.org/study/summary?id=brca_tcga_pan_can_atlas_2018, Colorectal cancer found in https://www.cbioportal.org/study/summary?id=coadread_tcga_pan_can_atlas_2018 and Lung cancer found in https://www.cbioportal.org/study/summary?id=luad_tcga_pan_can_atlas_2018.\\n\\nPAH dataset: The data can be found in the EGA (the European Genome-phenome Archive) database under accession code EGAS000010055326562 (https://ega-archive.org/studies/EGAS00001005532) . Restricted access, needs application.\\n\\nGUSTO dataset: The data can be found in the GEO database with accession number GSE182409.\",\n",
      "        \"matches_publication/title\": \"Omada: robust clustering of transcriptomes through multiple testing\",\n",
      "        \"matches_publication/authors\": \"Sokratis Kariotis, Pei Fang Tan, Haiping Lu, Christopher J Rhodes, Martin R Wilkins, Allan Lawrie, Dennis Wang\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e716961d57eb8bca69616\",\n",
      "        \"shortid\": \"4y1myuozde\",\n",
      "        \"uuid\": \"bf403e75-6baf-4278-bf96-1469c78c65e0\",\n",
      "        \"created\": \"2024-10-15T13:43:05.591Z\",\n",
      "        \"updated\": \"2024-10-15T13:43:05.591Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_title\": \"MOBFinder: a tool for MOB typing for plasmid metagenomic fragments based on language model\",\n",
      "        \"publication_authors\": \"Tao Feng, Shufang Wu, Hongwei Zhou, and Zhencheng Fang\",\n",
      "        \"publication_journal\": \"GigaScience\",\n",
      "        \"publication_year\": \"2024\",\n",
      "        \"publication_pmid\": \"39101782\",\n",
      "        \"publication_doi\": \"10.1093/gigascience/giae047\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 6,\n",
      "        \"score\": 0.74,\n",
      "        \"matches_evaluation/method\": \"Independent dataset.\",\n",
      "        \"matches_evaluation/measure\": \"This tool uses F1 score, balanced accuracy, harmonic mean, and AUC to evaluate the model. These metrics are commonly used in other similar algorithms, such as PPR-Meta and PlasTrans.\",\n",
      "        \"matches_evaluation/comparison\": \"As there are currently no benchmark datasets for metagenomic plasmid assembly fragments, this study constructed one from scratch and compared it with existing tools like MOB-suite and MOBscan.\",\n",
      "        \"matches_evaluation/confidence\": \"The evaluation metrics used in this study range from 0 to 1, with 0 indicating the lowest performance and 1 indicating the highest. MOBFinder's performance surpasses existing tools significantly, with an overall accuracy at least 59% higher than MOB-suite and at least 61% higher than MOBscan.\",\n",
      "        \"matches_evaluation/availability\": \" The evaluation script for this tool will be uploaded to the relevant database after the article is published. You can access the MOBFinder tool from Github: https://github.com/FengTaoSMU/MOBFinder.\",\n",
      "        \"matches_optimization/algorithm\": \"The machine learning algorithms used in this study are the Skip-gram language model and Random Forest. Both of these methods are well-known in machine learning. Currently, methods used for MOB typing annotation rely on relaxase-based approaches such as MOB-suite and MOBscan. However, in metagenomic plasmid assembly fragments, relaxase sequences are often missing or incomplete. As a result, most plasmid assembly fragments are annotated as non-transferable plasmids. Due to differences in sequence features and host range among different MOB types, this study utilized the Skip-gram language model to digitally encode the biological patterns and features of metagenomic plasmid assembly fragments, resulting in significant performance improvements for MOBFinder. With a training dataset of up to 990,000 entries, Random Forest was used to prevent overfitting in training the MOB classification models. The combined use of these two algorithms effectively enhanced the performance of predicting MOB types in metagenomic plasmid assembly fragments. In some cases, F1 and AUC scores reached as high as 0.99, almost perfect.\",\n",
      "        \"matches_optimization/config\": \"According to our test results, MOBFinder takes approximately 5 to 18 minutes to predict on the test set, depending on the length and quantity of input data.\",\n",
      "        \"matches_optimization/encoding\": \"1. In word vector training, this study generated overlapping \\\"words\\\" of 4-mers from plasmid genomes and assigned a random numeric vector to each unique \\\"word\\\". These vectors were then inputted into a two-layer neural network for training, learning the probability of occurrence of 10 preceding and succeeding \\\"words\\\". The two-layer neural network consists of a hidden layer with 100 neurons. Finally, 100-dimensional word vectors corresponding to 256 DNA 4-mer \\\"words\\\" were outputted. 2. Training of the MOB classification model: This study utilized known relaxases of MOB types to perform MOB typing on plasmid genomes, selecting plasmid genomes with confirmed MOB types based on their scores to construct benchmark datasets. For each MOB type of plasmid genome, the training and testing sets were divided in a 7:3 ratio. The training set for each MOB type randomly generated 90,000 simulated metagenomic plasmid assembly fragments, while the testing set for each MOB type randomly generated 500 simulated metagenomic plasmid assembly fragments. All fragments were encoded using the generated 4-mer word vectors, with the average 100-dimensional word vector calculated as input for training the Random Forest model.\",\n",
      "        \"matches_optimization/features\": \"This tool did not conduct feature selection; instead, it used 100 word vector features trained by the skip-gram model as input.\",\n",
      "        \"matches_optimization/fitting\": \"The number of each MOB type in the training dataset is the same, and random forest was used to prevent overfitting.\",\n",
      "        \"matches_optimization/parameters\": \"1. The skip-gram model consists of two layers of neural networks: a hidden layer and an output layer, with 100 neurons in the hidden layer. For each input 4-mer \\\"word\\\", it predicts the probability of occurrence of 10 preceding and succeeding words in its context.\\n2. The random forest model uses 500 trees.\",\n",
      "        \"matches_optimization/regularization\": \"Random forest.\",\n",
      "        \"matches_model/interpretability\": \"Black box.\",\n",
      "        \"matches_model/duration\": \"According to our test results, MOBFinder takes approximately 5 to 18 minutes to predict on the test set, depending on the length and quantity of input data.\",\n",
      "        \"matches_model/availability\": \"The source code of this tool will be uploaded to the corresponding database after the article is published. You can access the MOBFinder tool from Github: https://github.com/FengTaoSMU/MOBFinder.\",\n",
      "        \"matches_dataset/provenance\": \"All plasmid genomes were downloaded from NCBI database.\",\n",
      "        \"matches_dataset/splits\": \"When training plasmid DNA word vectors based on the Skip-gram language model, MOBFinder utilized a total of 37,139 plasmid genomes. For training the four MOB classification models, this study obtained the complete plasmid genomes from the NCBI database again and annotated them with MOB typing using the relaxase database. Subsequently, 67,925 plasmid genomes determined by MOB typing were used to simulate plasmid assembly fragments from metagenomic datasets for training the MOB classification models\",\n",
      "        \"matches_dataset/redundancy\": \"When training the four MOB classification models suitable for different length ranges, the training and testing sets were randomly split in a 7:3 ratio. There was no overlap between the training and testing sets; they were independent of each other.\",\n",
      "        \"matches_dataset/availability\": \"The training script and test data for this article will be uploaded to the website's database after publication. Currently, you can use and view the MOBFinder tool on Github: https://github.com/MOBFinder\",\n",
      "        \"matches_publication/title\": \"MOBFinder: a tool for MOB typing for plasmid metagenomic fragments based on language model\",\n",
      "        \"matches_publication/authors\": \"Tao Feng, Shufang Wu, Hongwei Zhou, and Zhencheng Fang\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e76ea61d57eb8bca6961b\",\n",
      "        \"shortid\": \"zn00kk9s7i\",\n",
      "        \"uuid\": \"440c11f3-f064-40d7-9b1d-5d29591896b4\",\n",
      "        \"created\": \"2024-10-15T14:06:34.688Z\",\n",
      "        \"updated\": \"2024-11-14T16:33:58.724Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_title\": \"Deepdefense: annotation of immune systems in prokaryotes using deep learning \",\n",
      "        \"publication_authors\": \"Sven Hauns, Omer S Alkhnbashi, Rolf Backofen\",\n",
      "        \"publication_journal\": \"GigaScience\",\n",
      "        \"publication_year\": \"2024\",\n",
      "        \"publication_pmid\": \"39388605\",\n",
      "        \"publication_doi\": \"10.1093/gigascience/giae062\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 6,\n",
      "        \"publication_created\": \"\",\n",
      "        \"score\": 0.78,\n",
      "        \"matches_evaluation/method\": \"We use cross-validation and ensure the independence of our training/test dataset using BLAST.\",\n",
      "        \"matches_evaluation/measure\": \"We supply representative metrics ROC-AUC and AUPRC togther with BLAST allignment scores, aswell as classification scores for single classes.\",\n",
      "        \"matches_evaluation/comparison\": \"We compare our method to PADLOC on a set of phages, bacteria and archea.\",\n",
      "        \"matches_evaluation/confidence\": \"The confidence of the class assignments is discussed in the publication. Additional wet-lab experiments will be needed to verify the quality.\",\n",
      "        \"matches_evaluation/availability\": \"Additional evaluation files are part of the gigascience database.\",\n",
      "        \"matches_optimization/algorithm\": \"To optimize our algorithm we choose BOHB (bayesian optimization with hyperband)*\\n\\n*Falkner S, Klein A, Hutter F. BOHB: Robust and Efficient Hyperparameter Optimization at Scale. CoRR 2018;abs/1807.01774.http://arxiv.org/abs/1807.01774.\",\n",
      "        \"matches_optimization/meta\": \"does not use a meta-predictor\",\n",
      "        \"matches_optimization/config\": \"Details of the optimization schedule and hyperparameter configurations can be found in the publication.\",\n",
      "        \"matches_optimization/encoding\": \"data was encoded in a one-hot-vector fashion using the aminoacids of the protein\",\n",
      "        \"matches_optimization/features\": \"The input consists primarily of the proteins, ecnoded in a one-hot fashion, additionally we supply information characterizing any proteins as used by a previous publication. No further feature selection was performed.\",\n",
      "        \"matches_optimization/fitting\": \"Overfitting was controlled by using a validation set with an early stopping procedure. \",\n",
      "        \"matches_optimization/parameters\": \"The current deeplearning model has roughly 11700000 learnable parameter. The size of the model was subject of the optimization processed and hence also optimized. \",\n",
      "        \"matches_optimization/regularization\": \"We use early stopping using a validation set to prevent overfitting. Additionally a dropout rate was discovered using the described optimization mechanism. \",\n",
      "        \"matches_model/interpretability\": \"The model is mostly a black box model. The output of the model is more interpretable than it would usually be the case, since we make use of methods to increase the model calibration.\",\n",
      "        \"matches_model/duration\": \"On an older laptop (cpu run only, Intel(R) Core(TM) i5-8350U CPU @ 1.70GHz) after first loading the model a simple prediction can be made in 0.60 seconds.\",\n",
      "        \"matches_model/availability\": \"The source code can be found in our github repro under the free MIT licence: https://github.com/SvenHauns/Deepdefense\",\n",
      "        \"matches_dataset/provenance\": \"Our dataset consists of 21196 unique validated samples available due to a previous publication*. The dataset we used was imbalanced for types, consisting of 1263 Durantia samples, 3723 Gajiba samples,1529 Hachiman samples, 6882 Wadjet samples, 637 Lamassu samples, 2807 Septu samples, 647 Shedu samples, 1097 Thoeris samples, 745 Kiwa samples, 1866 Zorya samples. Hence there were only roughly one-tenth of the samples of Lamassu than for Wadjet.  \\n\\n* Doron S, Melamed S, Ofir G, Leavitt A, Lopatina A,Keren M, et al. Systematic discovery of antiphage defense systems in the microbial pangenome. Science 2018;359(6379):eaar4120. https://www.science.org/doi/abs/10.1126/science.aar4120.\",\n",
      "        \"matches_dataset/splits\": \"We separate our dataset in a stratified training, test, and validation split, using a 10-fold CV split to ensure enough training data samples are available for subclasses with few samples.\",\n",
      "        \"matches_dataset/redundancy\": \"Training and test set were insured to be independent, by controlling for sequence homology using BLAST.\",\n",
      "        \"matches_dataset/availability\": \"The data is available following the original publication*. \\n\\n* Doron S, Melamed S, Ofir G, Leavitt A, Lopatina A,Keren M, et al. Systematic discovery of antiphage defense systems in the microbial pangenome. Science 2018;359(6379):eaar4120. https://www.science.org/doi/abs/10.1126/science.aar4120.\",\n",
      "        \"matches_publication/title\": \"Deepdefense: annotation of immune systems in prokaryotes using deep learning \",\n",
      "        \"matches_publication/authors\": \"Sven Hauns, Omer S Alkhnbashi, Rolf Backofen\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e781961d57eb8bca6961f\",\n",
      "        \"shortid\": \"2bpmmu8yav\",\n",
      "        \"uuid\": \"19954d39-0d13-4f99-9e5d-0624ccd5b638\",\n",
      "        \"created\": \"2024-10-15T14:11:37.681Z\",\n",
      "        \"updated\": \"2024-10-15T14:11:37.681Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_title\": \"Deep learning links localized digital pathology phenotypes with transcriptional subtype and patient outcome in glioblastoma\",\n",
      "        \"publication_authors\": \"Thomas Roetzer-Pejrimovsky, Karl-Heinz Nenning, Barbara Kiesel, Johanna Klughammer, Martin Rajchl, Bernhard Baumann, Georg Langs, Adelheid Woehrer\",\n",
      "        \"publication_journal\": \"GigaScience\",\n",
      "        \"publication_year\": \"2024\",\n",
      "        \"publication_pmid\": \"39185700\",\n",
      "        \"publication_doi\": \"https://doi.org/10.1093/gigascience/giae057\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 6,\n",
      "        \"score\": 0.78,\n",
      "        \"matches_evaluation/method\": \"5-fold CV and independent external test dataset\",\n",
      "        \"matches_evaluation/measure\": \"For prediction of the transcriptional subtype: accuracy, AUC.\\nFor prediction of the survival: median overall survial and logrank test after groupint into high-risk and low-risk groups.\",\n",
      "        \"matches_evaluation/comparison\": \"NA / no benchmark datasets available.\",\n",
      "        \"matches_evaluation/confidence\": \"NA / no other methods for comparison available\",\n",
      "        \"matches_evaluation/availability\": \"Evaluation results are covered in the manuscript. the Model output for the external TCGA validation dataset is available via the github page: https://github.com/tovaroe/GBMatch_CNN (GPL 3.0)\",\n",
      "        \"matches_optimization/algorithm\": \"We used a pre-trained Xception CNN as the backbone with an additional layer for TS/survival prediction and fine-tuning.\",\n",
      "        \"matches_optimization/meta\": \"Not applicable\",\n",
      "        \"matches_optimization/config\": \"Available via the github-page in the config.py (https://github.com/tovaroe/GBMatch_CNN)\",\n",
      "        \"matches_optimization/encoding\": \"Image tiles were used as input for the ML algorithm, the preprocessing was performed according to the keras implementation of the Xception model.\",\n",
      "        \"matches_optimization/features\": \"Image tiles (512x512 px) were used as input, no additional feature selection was performed.\",\n",
      "        \"matches_optimization/fitting\": \"Overfitting/Underfitting was ruled out by keeping track of the validation set error in 5-fold-CV during hyperparameter selection; And by fixing the pre-trained model parameters and only fine-tuning the last few layers.\",\n",
      "        \"matches_optimization/parameters\": \"No additional parameters werde set in the pre-trained Xception model. For prediction of survival, a 1-neuron layer was added as the ultimate layer, and for prediction of the transcriptional subtype, a 3-neuron layer was added.\",\n",
      "        \"matches_optimization/regularization\": \"Dropout (0.25)\",\n",
      "        \"matches_model/interpretability\": \"The model is semi-interpretable. While the prediction of single image tiles is a black box, the mapping of tile prediction onto the whole slide scans allows for interpretability (discussed extensively in the manuscript).\",\n",
      "        \"matches_model/duration\": \"Depending on the slide scan size, a single prediction requires a few minutes on a workstation desktop PC.\",\n",
      "        \"matches_model/availability\": \"The source code is released via github: https://github.com/tovaroe/GBMatch_CNN (GPL 3.0)\",\n",
      "        \"matches_dataset/provenance\": \"The training data is derived from the publication \\\"The DNA methylation landscape of glioblastoma disease progression shows extensive heterogeneity in time and space\\\" (https://doi.org/10.1038/s41591-018-0156-x) and contains a total of 276 cases, 189 of which have information on the transcriptional subtype.\\n\\n\",\n",
      "        \"matches_dataset/splits\": \"For model selection, the above mentioned 276 or 189 cases, respectively, were split into 5 equally sized fold for 5-fold CV, with similar distribution of transcriptional subtypes and survival, respectively.\\n\\nThe external validation data is derived from TCGA, consists of 178 cases and can be accessed via cBioPortal (https://www.cbioportal.org) and/or the GDC Data Portal (https://portal.gdc.cancer.gov). In contrast to the training dataset, the transcriptional subtypes were determined by RNAseq, but the overall distribution is similar, albeit with slightly more classical cases and fewer mesenchymal cases. Due to the strict selection critera for the study underlying the training dataset, the overall survival in the TCGA dataset was slightly lower.\",\n",
      "        \"matches_dataset/redundancy\": \"The external validation set is completely independent, as it is derived from TCGA.\",\n",
      "        \"matches_dataset/availability\": \"The splits for the training data are published in the corresponding github repository (https://github.com/tovaroe/GBMatch_CNN, GPL 3.0).\",\n",
      "        \"matches_publication/title\": \"Deep learning links localized digital pathology phenotypes with transcriptional subtype and patient outcome in glioblastoma\",\n",
      "        \"matches_publication/authors\": \"Thomas Roetzer-Pejrimovsky, Karl-Heinz Nenning, Barbara Kiesel, Johanna Klughammer, Martin Rajchl, Bernhard Baumann, Georg Langs, Adelheid Woehrer\"\n",
      "    },\n",
      "    {\n",
      "        \"_id\": \"670e790061d57eb8bca69627\",\n",
      "        \"shortid\": \"09r03h9clm\",\n",
      "        \"uuid\": \"d77983e0-5279-4379-b608-8032a2990b09\",\n",
      "        \"created\": \"2024-10-15T14:15:28.964Z\",\n",
      "        \"updated\": \"2024-10-15T14:15:28.964Z\",\n",
      "        \"public\": true,\n",
      "        \"publication_title\": \"PhageGE: An interactive web-based R shiny application for exploratory analysis and visualisation of bacteriophage genomes\",\n",
      "        \"publication_authors\": \"Jinxin Zhao1, 2 *, Jiru Han3, Yu-Wei Lin1, Yan Zhu1, 4, Michael Aichem5, Dimitar Garkov5, Phillip J. Bergen1, Sue C. Nang1, Jian-Zhong Ye6, 7, Tie-Li Zhou6, 7, Tony Velkov8, Jiang-Ning Song2, 9, Falk Schreiber5, 10, Jian Li1, 2*\",\n",
      "        \"publication_journal\": \"GigaScience\",\n",
      "        \"publication_year\": \"2024\",\n",
      "        \"publication_pmid\": \"39320317\",\n",
      "        \"publication_doi\": \"10.1093/gigascience/giae074\",\n",
      "        \"publication_done\": 0,\n",
      "        \"publication_skip\": 6,\n",
      "        \"score\": 0.78,\n",
      "        \"matches_evaluation/method\": \"Cross-validation, independent dataset\",\n",
      "        \"matches_evaluation/measure\": \"Our manuscript include the comparison of the performance of PhageGE and other methods.\",\n",
      "        \"matches_evaluation/comparison\": \"Our manuscript include the comparison of the performance of PhageGE and other methods.\",\n",
      "        \"matches_evaluation/confidence\": \"We do provided classification accuracy of each compared method across both the training and test datasets. Based on the comparison, the performance of phageGE is superior to others. \",\n",
      "        \"matches_evaluation/availability\": \"We shared the benchmark dataset in the phageGE github under the example data folder.\",\n",
      "        \"matches_optimization/algorithm\": \"Random forest classifier \",\n",
      "        \"matches_optimization/config\": \"Data and related files for the development of final model have been shared in phageGE github (https://github.com/JinxinMonash/PhageGE/tree/main/Example%20data)\",\n",
      "        \"matches_optimization/encoding\": \"Conserved Domain Database (11/2023) for protein domains that mechanistically involved in lysogeny were collected and manually curated. In the meantime, each genome sequence in the training set, a list of all possible 6-frame translation sequences for all genomes were generated with rhmmer package. \",\n",
      "        \"matches_optimization/features\": \"477 features (protein domains) were collected initially. Testing set was not used for feature selection, pre-processing steps or parameter tuning.\",\n",
      "        \"matches_optimization/fitting\": \"We optimised the initial data collection (from CDD) strategy to limit the possibility of over-fitting. We also performed the comparison of the incorrect predictions of training and testing.\",\n",
      "        \"matches_optimization/parameters\": \"\\u2018bootstrap\\u2019 (True, False), \\u2018class_weight\\u2019 (balanced, balanced_subsample), \\u2018min_samples_leaf\\u2019 , \\u2018n_estimators\\u2019 , and \\u2018max_depth\\u2019. \\nGridSearchCV were used to evaluate all possible parameters or their combinations.\\n\",\n",
      "        \"matches_optimization/regularization\": \"We limited the amount of initial features (protein domains from CDD) from the data collection.\",\n",
      "        \"matches_model/interpretability\": \"Black box \",\n",
      "        \"matches_model/duration\": \"Seconds on HPC cluster\",\n",
      "        \"matches_model/availability\": \"Yes, the source code is released in the PhageGE github page. And it has been incorporated in our phageGE webserver.\",\n",
      "        \"matches_dataset/provenance\": \"The dataset was selected from Mavrich, T., Hatfull, G. Bacteriophage evolution differs by host, lifestyle and genome. Nat Microbiol 2, 17112 (2017). There are 604 positive (temperate) and 453 negative cases (lytic) for the whole dataset. \",\n",
      "        \"matches_dataset/splits\": \"634 genomes were included in the training set while 423 genomes were included in the test set. We applied cross-validation to tune model hyper-parameters, where the training set was randomly split into individual training and validation sets.\",\n",
      "        \"matches_dataset/redundancy\": \"The training and test sets are independent using a 60:40 split.\",\n",
      "        \"matches_dataset/availability\": \"Yes, all the data are released in the PhageGE github example data (https://github.com/JinxinMonash/PhageGE/tree/main/Example%20data).\",\n",
      "        \"matches_publication/title\": \"PhageGE: An interactive web-based R shiny application for exploratory analysis and visualisation of bacteriophage genomes\",\n",
      "        \"matches_publication/authors\": \"Jinxin Zhao1, 2 *, Jiru Han3, Yu-Wei Lin1, Yan Zhu1, 4, Michael Aichem5, Dimitar Garkov5, Phillip J. Bergen1, Sue C. Nang1, Jian-Zhong Ye6, 7, Tie-Li Zhou6, 7, Tony Velkov8, Jiang-Ning Song2, 9, Falk Schreiber5, 10, Jian Li1, 2*\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# 2. Flatten the JSON for easier data processing and write to a new .json file \n",
    "import json\n",
    "\n",
    "# Define the path to the JSON file\n",
    "file_name = 'DOME_Registry_Contents_2024-12-02.json'  # Replace with your actual file name\n",
    "\n",
    "# Function to read JSON data\n",
    "def read_json(file_name):\n",
    "    try:\n",
    "        with open(file_name, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the JSON file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to flatten JSON\n",
    "def flatten_json(y):\n",
    "    out = {}\n",
    "\n",
    "    def flatten(x, name=''):\n",
    "        if type(x) is dict:\n",
    "            for a in x:\n",
    "                flatten(x[a], name + a + '_')\n",
    "        elif type(x) is list:\n",
    "            i = 0\n",
    "            for a in x:\n",
    "                flatten(a, name + str(i) + '_')\n",
    "                i += 1\n",
    "        else:\n",
    "            out[name[:-1]] = x\n",
    "\n",
    "    flatten(y)\n",
    "    return out\n",
    "\n",
    "# Function to save flattened JSON to a file\n",
    "def save_flattened_json(flattened_data, output_file_name):\n",
    "    try:\n",
    "        with open(output_file_name, 'w', encoding='utf-8') as file:\n",
    "            json.dump(flattened_data, file, indent=4)\n",
    "        print(f\"Flattened JSON data saved to '{output_file_name}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving the flattened JSON file: {e}\")\n",
    "\n",
    "# Read JSON data\n",
    "data = read_json(file_name)\n",
    "\n",
    "# Flatten JSON data and save to a new file\n",
    "if data:\n",
    "    flattened_data = [flatten_json(entry) for entry in data]\n",
    "    output_file_name = 'flattened_DOME_Registry_Contents.json'\n",
    "    save_flattened_json(flattened_data, output_file_name)\n",
    "    \n",
    "    # Print the flattened JSON data to view it\n",
    "    print(json.dumps(flattened_data, indent=4))\n",
    "else:\n",
    "    print(\"No data to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data written to 'DOME_Registry_Contents.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# 3. Work with flattened JSON data to produce a .csv file for metadata calculation on entries\n",
    "\n",
    "# Define the path to the flattened JSON file\n",
    "flattened_file_name = 'flattened_DOME_Registry_Contents.json'  # Replace with your actual file name\n",
    "\n",
    "# Function to read flattened JSON data\n",
    "def read_flattened_json(file_name):\n",
    "    try:\n",
    "        with open(file_name, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the flattened JSON file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to write JSON data to a CSV file\n",
    "def write_json_to_csv(json_data, csv_file_name):\n",
    "    try:\n",
    "        # Determine all possible headers from the entire dataset\n",
    "        headers = set()\n",
    "        for entry in json_data:\n",
    "            headers.update(entry.keys())\n",
    "        headers = list(headers)\n",
    "        \n",
    "        # Write data to CSV file\n",
    "        with open(csv_file_name, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=headers)\n",
    "            writer.writeheader()\n",
    "            for entry in json_data:\n",
    "                writer.writerow(entry)\n",
    "        \n",
    "        print(f\"JSON data written to '{csv_file_name}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing to the CSV file: {e}\")\n",
    "\n",
    "# Read flattened JSON data\n",
    "flattened_data = read_flattened_json(flattened_file_name)\n",
    "\n",
    "# Process JSON data into CSV\n",
    "if flattened_data:\n",
    "    csv_file_name = 'DOME_Registry_Contents.csv'\n",
    "    write_json_to_csv(flattened_data, csv_file_name)\n",
    "else:\n",
    "    print(\"No data to process.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211 of 214 PMIDs valid\n",
      "3 of 214 PMIDs invalid\n",
      "208 of 214 DOIs valid\n",
      "6 of 214 DOIs invalid\n",
      "Metadata written to 'Metadata_DOME_Registry_Contents.csv'\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Define the path to the CSV file\n",
    "csv_file_name = 'DOME_Registry_Contents.csv'  # Replace with your actual file name\n",
    "\n",
    "# Define the EPMC regex pattern for PMIDs\n",
    "pmid_pattern = re.compile(r'^\\d{8}$')\n",
    "\n",
    "# Define the regex pattern for DOIs\n",
    "doi_pattern = re.compile(r'^10.\\d{4,9}/[-._;()/:A-Z0-9]+$', re.IGNORECASE)\n",
    "\n",
    "# Function to read CSV data\n",
    "def read_csv(file_name):\n",
    "    try:\n",
    "        with open(file_name, 'r', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            data = [row for row in reader]\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the CSV file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to check PMIDs and DOIs and generate metadata\n",
    "def check_pmids_and_dois_and_generate_metadata(data, csv_file_name):\n",
    "    pmid_valid = 0\n",
    "    pmid_invalid = 0\n",
    "    doi_valid = 0\n",
    "    doi_invalid = 0\n",
    "    total_entries = len(data)\n",
    "    \n",
    "    for row in data:\n",
    "        pmid = row.get('publication_pmid', '')\n",
    "        doi = row.get('publication_doi', '')\n",
    "        \n",
    "        if pmid_pattern.match(pmid):\n",
    "            pmid_valid += 1\n",
    "        else:\n",
    "            pmid_invalid += 1\n",
    "        \n",
    "        if doi_pattern.match(doi):\n",
    "            doi_valid += 1\n",
    "        else:\n",
    "            doi_invalid += 1\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"{pmid_valid} of {total_entries} PMIDs valid\")\n",
    "    print(f\"{pmid_invalid} of {total_entries} PMIDs invalid\")\n",
    "    print(f\"{doi_valid} of {total_entries} DOIs valid\")\n",
    "    print(f\"{doi_invalid} of {total_entries} DOIs invalid\")\n",
    "    \n",
    "    # Create metadata CSV file\n",
    "    metadata_file_name = f\"Metadata_{os.path.basename(csv_file_name)}\"\n",
    "    with open(metadata_file_name, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['Metric', 'Value'])\n",
    "        writer.writerow(['Total Entries', total_entries])\n",
    "        writer.writerow(['Valid PMIDs', pmid_valid])\n",
    "        writer.writerow(['Invalid PMIDs', pmid_invalid])\n",
    "        writer.writerow(['Valid DOIs', doi_valid])\n",
    "        writer.writerow(['Invalid DOIs', doi_invalid])\n",
    "    \n",
    "    print(f\"Metadata written to '{metadata_file_name}'\")\n",
    "\n",
    "# Read CSV data\n",
    "csv_data = read_csv(csv_file_name)\n",
    "\n",
    "# Check PMIDs and DOIs and generate metadata\n",
    "if csv_data:\n",
    "    check_pmids_and_dois_and_generate_metadata(csv_data, csv_file_name)\n",
    "else:\n",
    "    print(\"No data to process.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    631      0 --:--:-- --:--:-- --:--:--   632\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 16524483 saved to 'EPMC_XML_Files/16524483.xml'\n",
      "XML data for PMID 17374164 saved to 'EPMC_XML_Files/17374164.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    588      0 --:--:-- --:--:-- --:--:--   586\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    639      0 --:--:-- --:--:-- --:--:--   642\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 17888165 saved to 'EPMC_XML_Files/17888165.xml'\n",
      "XML data for PMID 17570862 saved to 'EPMC_XML_Files/17570862.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    583      0 --:--:-- --:--:-- --:--:--   586\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    688      0 --:--:-- --:--:-- --:--:--   692\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 19091017 saved to 'EPMC_XML_Files/19091017.xml'\n",
      "XML data for PMID 18586734 saved to 'EPMC_XML_Files/18586734.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    682      0 --:--:-- --:--:-- --:--:--   686\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    682      0 --:--:-- --:--:-- --:--:--   686\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 18221567 saved to 'EPMC_XML_Files/18221567.xml'\n",
      "XML data for PMID 18808707 saved to 'EPMC_XML_Files/18808707.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    668      0 --:--:-- --:--:-- --:--:--   675\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    569      0 --:--:-- --:--:-- --:--:--   570\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 19154573 saved to 'EPMC_XML_Files/19154573.xml'\n",
      "XML data for PMID 19667082 saved to 'EPMC_XML_Files/19667082.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    696      0 --:--:-- --:--:-- --:--:--   692\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    725      0 --:--:-- --:--:-- --:--:--   729\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 19692556 saved to 'EPMC_XML_Files/19692556.xml'\n",
      "XML data for PMID 20122221 saved to 'EPMC_XML_Files/20122221.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    703      0 --:--:-- --:--:-- --:--:--   710\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    595      0 --:--:-- --:--:-- --:--:--   600\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 19994907 saved to 'EPMC_XML_Files/19994907.xml'\n",
      "XML data for PMID 22913485 saved to 'EPMC_XML_Files/22913485.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    528      0 --:--:-- --:--:-- --:--:--   529\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    700      0 --:--:-- --:--:-- --:--:--   704\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 22532634 saved to 'EPMC_XML_Files/22532634.xml'\n",
      "XML data for PMID 22408447 saved to 'EPMC_XML_Files/22408447.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    722      0 --:--:-- --:--:-- --:--:--   723\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    709      0 --:--:-- --:--:-- --:--:--   710\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 22558141 saved to 'EPMC_XML_Files/22558141.xml'\n",
      "XML data for PMID 23102953 saved to 'EPMC_XML_Files/23102953.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    613      0 --:--:-- --:--:-- --:--:--   618\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    722      0 --:--:-- --:--:-- --:--:--   729\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 25404408 saved to 'EPMC_XML_Files/25404408.xml'\n",
      "XML data for PMID 24675637 saved to 'EPMC_XML_Files/24675637.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    500      0 --:--:-- --:--:-- --:--:--   503\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    629      0 --:--:-- --:--:-- --:--:--   632\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 24977146 saved to 'EPMC_XML_Files/24977146.xml'\n",
      "XML data for PMID 24498380 saved to 'EPMC_XML_Files/24498380.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    665      0 --:--:-- --:--:-- --:--:--   669\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    696      0 --:--:-- --:--:-- --:--:--   698\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 26834994 saved to 'EPMC_XML_Files/26834994.xml'\n",
      "XML data for PMID 25878156 saved to 'EPMC_XML_Files/25878156.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    637      0 --:--:-- --:--:-- --:--:--   637\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    560      0 --:--:-- --:--:-- --:--:--   562\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 25849257 saved to 'EPMC_XML_Files/25849257.xml'\n",
      "XML data for PMID 26495028 saved to 'EPMC_XML_Files/26495028.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    522      0 --:--:-- --:--:-- --:--:--   525\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    712      0 --:--:-- --:--:-- --:--:--   716\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 25175491 saved to 'EPMC_XML_Files/25175491.xml'\n",
      "XML data for PMID 26068103 saved to 'EPMC_XML_Files/26068103.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    591      0 --:--:-- --:--:-- --:--:--   595\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    698      0 --:--:-- --:--:-- --:--:--   704\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 26495028 saved to 'EPMC_XML_Files/26495028.xml'\n",
      "XML data for PMID 26422234 saved to 'EPMC_XML_Files/26422234.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    442      0 --:--:-- --:--:-- --:--:--   445\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    714      0 --:--:-- --:--:-- --:--:--   710\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 26495028 saved to 'EPMC_XML_Files/26495028.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    444      0 --:--:-- --:--:-- --:--:--   447\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    594      0 --:--:-- --:--:-- --:--:--   595\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 25783485 saved to 'EPMC_XML_Files/25783485.xml'\n",
      "XML data for PMID 25646976 saved to 'EPMC_XML_Files/25646976.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    693      0 --:--:-- --:--:-- --:--:--   698\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    746      0 --:--:-- --:--:-- --:--:--   750\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 25878156 saved to 'EPMC_XML_Files/25878156.xml'\n",
      "XML data for PMID 27127534 saved to 'EPMC_XML_Files/27127534.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    556      0 --:--:-- --:--:-- --:--:--   558\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    533      0 --:--:-- --:--:-- --:--:--   532\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 26930205 saved to 'EPMC_XML_Files/26930205.xml'\n",
      "XML data for PMID 26205532 saved to 'EPMC_XML_Files/26205532.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    565      0 --:--:-- --:--:-- --:--:--   566\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 27191382 saved to 'EPMC_XML_Files/27191382.xml'\n",
      "XML data for PMID 27592011 saved to 'EPMC_XML_Files/27592011.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    581      0 --:--:-- --:--:-- --:--:--   582\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    591      0 --:--:-- --:--:-- --:--:--   595\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 26746583 saved to 'EPMC_XML_Files/26746583.xml'\n",
      "XML data for PMID 27491922 saved to 'EPMC_XML_Files/27491922.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    642      0 --:--:-- --:--:-- --:--:--   642\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    658      0 --:--:-- --:--:-- --:--:--   663\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 27488918 saved to 'EPMC_XML_Files/27488918.xml'\n",
      "XML data for PMID 27832081 saved to 'EPMC_XML_Files/27832081.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    726      0 --:--:-- --:--:-- --:--:--   729\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    752      0 --:--:-- --:--:-- --:--:--   757\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 27855170 saved to 'EPMC_XML_Files/27855170.xml'\n",
      "XML data for PMID 27222432 saved to 'EPMC_XML_Files/27222432.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    801      0 --:--:-- --:--:-- --:--:--   801\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    742      0 --:--:-- --:--:-- --:--:--   750\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 27875980 saved to 'EPMC_XML_Files/27875980.xml'\n",
      "XML data for PMID 26957000 saved to 'EPMC_XML_Files/26957000.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    701      0 --:--:-- --:--:-- --:--:--   704\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    695      0 --:--:-- --:--:-- --:--:--   698\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 28696170 saved to 'EPMC_XML_Files/28696170.xml'\n",
      "XML data for PMID 27362985 saved to 'EPMC_XML_Files/27362985.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    737      0 --:--:-- --:--:-- --:--:--   743\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    762      0 --:--:-- --:--:-- --:--:--   764\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 29263361 saved to 'EPMC_XML_Files/29263361.xml'\n",
      "XML data for PMID 28678787 saved to 'EPMC_XML_Files/28678787.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    677      0 --:--:-- --:--:-- --:--:--   680\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    646      0 --:--:-- --:--:-- --:--:--   648\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 28624633 saved to 'EPMC_XML_Files/28624633.xml'\n",
      "XML data for PMID 28600868 saved to 'EPMC_XML_Files/28600868.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    651      0 --:--:-- --:--:-- --:--:--   648\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    601      0 --:--:-- --:--:-- --:--:--   604\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    761      0 --:--:-- --:--:-- --:--:--   764\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 28065610 saved to 'EPMC_XML_Files/28065610.xml'\n",
      "XML data for PMID 29219069 saved to 'EPMC_XML_Files/29219069.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    610      0 --:--:-- --:--:-- --:--:--   613\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 28624633 saved to 'EPMC_XML_Files/28624633.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    232      0 --:--:-- --:--:-- --:--:--   232\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    659      0 --:--:-- --:--:-- --:--:--   663\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 28807860 saved to 'EPMC_XML_Files/28807860.xml'\n",
      "XML data for PMID 28747397 saved to 'EPMC_XML_Files/28747397.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    587      0 --:--:-- --:--:-- --:--:--   591\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    721      0 --:--:-- --:--:-- --:--:--   723\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 28881974 saved to 'EPMC_XML_Files/28881974.xml'\n",
      "XML data for PMID 29036374 saved to 'EPMC_XML_Files/29036374.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    613      0 --:--:-- --:--:-- --:--:--   618\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    665      0 --:--:-- --:--:-- --:--:--   669\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 28369334 saved to 'EPMC_XML_Files/28369334.xml'\n",
      "XML data for PMID 29790392 saved to 'EPMC_XML_Files/29790392.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    477      0 --:--:-- --:--:-- --:--:--   479\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 30046299 saved to 'EPMC_XML_Files/30046299.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    312      0 --:--:-- --:--:-- --:--:--   311\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    598      0 --:--:-- --:--:-- --:--:--   600\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 30295871 saved to 'EPMC_XML_Files/30295871.xml'\n",
      "XML data for PMID 29720103 saved to 'EPMC_XML_Files/29720103.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    571      0 --:--:-- --:--:-- --:--:--   574\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    715      0 --:--:-- --:--:-- --:--:--   716\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 29849042 saved to 'EPMC_XML_Files/29849042.xml'\n",
      "XML data for PMID 30388153 saved to 'EPMC_XML_Files/30388153.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    596      0 --:--:-- --:--:-- --:--:--   600\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    687      0 --:--:-- --:--:-- --:--:--   692\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 30388122 saved to 'EPMC_XML_Files/30388122.xml'\n",
      "XML data for PMID 29720103 saved to 'EPMC_XML_Files/29720103.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    626      0 --:--:-- --:--:-- --:--:--   627\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    680      0 --:--:-- --:--:-- --:--:--   686\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 30008861 saved to 'EPMC_XML_Files/30008861.xml'\n",
      "XML data for PMID 30483279 saved to 'EPMC_XML_Files/30483279.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    674      0 --:--:-- --:--:-- --:--:--   675\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    692      0 --:--:-- --:--:-- --:--:--   698\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 29133589 saved to 'EPMC_XML_Files/29133589.xml'\n",
      "XML data for PMID 30109435 saved to 'EPMC_XML_Files/30109435.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    513      0 --:--:-- --:--:-- --:--:--   515\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    643      0 --:--:-- --:--:-- --:--:--   648\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 29679026 saved to 'EPMC_XML_Files/29679026.xml'\n",
      "XML data for PMID 30538725 saved to 'EPMC_XML_Files/30538725.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    574      0 --:--:-- --:--:-- --:--:--   578\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    663      0 --:--:-- --:--:-- --:--:--   669\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 30109435 saved to 'EPMC_XML_Files/30109435.xml'\n",
      "XML data for PMID 28527154 saved to 'EPMC_XML_Files/28527154.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    728      0 --:--:-- --:--:-- --:--:--   729\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    646      0 --:--:-- --:--:-- --:--:--   642\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 31137222 saved to 'EPMC_XML_Files/31137222.xml'\n",
      "XML data for PMID 30615300 saved to 'EPMC_XML_Files/30615300.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    578      0 --:--:-- --:--:-- --:--:--   582\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    601      0 --:--:-- --:--:-- --:--:--   604\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 30819107 saved to 'EPMC_XML_Files/30819107.xml'\n",
      "XML data for PMID 31058230 saved to 'EPMC_XML_Files/31058230.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    551      0 --:--:-- --:--:-- --:--:--   554\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    673      0 --:--:-- --:--:-- --:--:--   675\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 30853547 saved to 'EPMC_XML_Files/30853547.xml'\n",
      "XML data for PMID 31407406 saved to 'EPMC_XML_Files/31407406.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    440      0 --:--:-- --:--:-- --:--:--   442\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    604      0 --:--:-- --:--:-- --:--:--   604\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 31462106 saved to 'EPMC_XML_Files/31462106.xml'\n",
      "XML data for PMID 31176619 saved to 'EPMC_XML_Files/31176619.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    650      0 --:--:-- --:--:-- --:--:--   653\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    683      0 --:--:-- --:--:-- --:--:--   686\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 31132080 saved to 'EPMC_XML_Files/31132080.xml'\n",
      "XML data for PMID 31871774 saved to 'EPMC_XML_Files/31871774.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    632      0 --:--:-- --:--:-- --:--:--   637\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    501      0 --:--:-- --:--:-- --:--:--   503\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 30448611 saved to 'EPMC_XML_Files/30448611.xml'\n",
      "XML data for PMID 30933970 saved to 'EPMC_XML_Files/30933970.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    502      0 --:--:-- --:--:-- --:--:--   503\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 30769139 saved to 'EPMC_XML_Files/30769139.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    373      0 --:--:-- --:--:-- --:--:--   373\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    593      0 --:--:-- --:--:-- --:--:--   595\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 31404081 saved to 'EPMC_XML_Files/31404081.xml'\n",
      "XML data for PMID 31362694 saved to 'EPMC_XML_Files/31362694.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    443      0 --:--:-- --:--:-- --:--:--   445\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    735      0 --:--:-- --:--:-- --:--:--   736\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 31466478 saved to 'EPMC_XML_Files/31466478.xml'\n",
      "XML data for PMID 30970017 saved to 'EPMC_XML_Files/30970017.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    590      0 --:--:-- --:--:-- --:--:--   591\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    697      0 --:--:-- --:--:-- --:--:--   698\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 30857591 saved to 'EPMC_XML_Files/30857591.xml'\n",
      "XML data for PMID 31479437 saved to 'EPMC_XML_Files/31479437.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    610      0 --:--:-- --:--:-- --:--:--   613\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    723      0 --:--:-- --:--:-- --:--:--   723\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 31874628 saved to 'EPMC_XML_Files/31874628.xml'\n",
      "XML data for PMID 31856830 saved to 'EPMC_XML_Files/31856830.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    628      0 --:--:-- --:--:-- --:--:--   632\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    749      0 --:--:-- --:--:-- --:--:--   757\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 31308377 saved to 'EPMC_XML_Files/31308377.xml'\n",
      "XML data for PMID 31148311 saved to 'EPMC_XML_Files/31148311.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    732      0 --:--:-- --:--:-- --:--:--   736\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    677      0 --:--:-- --:--:-- --:--:--   680\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 31534955 saved to 'EPMC_XML_Files/31534955.xml'\n",
      "XML data for PMID 31659164 saved to 'EPMC_XML_Files/31659164.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    604      0 --:--:-- --:--:-- --:--:--   609\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    614      0 --:--:-- --:--:-- --:--:--   618\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 30891794 saved to 'EPMC_XML_Files/30891794.xml'\n",
      "XML data for PMID 30794638 saved to 'EPMC_XML_Files/30794638.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    683      0 --:--:-- --:--:-- --:--:--   686\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    740      0 --:--:-- --:--:-- --:--:--   736\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 30590545 saved to 'EPMC_XML_Files/30590545.xml'\n",
      "XML data for PMID 30950198 saved to 'EPMC_XML_Files/30950198.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    708      0 --:--:-- --:--:-- --:--:--   710\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    753      0 --:--:-- --:--:-- --:--:--   757\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 30877925 saved to 'EPMC_XML_Files/30877925.xml'\n",
      "XML data for PMID 31877719 saved to 'EPMC_XML_Files/31877719.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    770      0 --:--:-- --:--:-- --:--:--   771\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    742      0 --:--:-- --:--:-- --:--:--   750\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 31199787 saved to 'EPMC_XML_Files/31199787.xml'\n",
      "XML data for PMID 32344344 saved to 'EPMC_XML_Files/32344344.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    757      0 --:--:-- --:--:-- --:--:--   764\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    737      0 --:--:-- --:--:-- --:--:--   743\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 32220894 saved to 'EPMC_XML_Files/32220894.xml'\n",
      "XML data for PMID 31161221 saved to 'EPMC_XML_Files/31161221.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    754      0 --:--:-- --:--:-- --:--:--   757\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    745      0 --:--:-- --:--:-- --:--:--   743\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 33039708 saved to 'EPMC_XML_Files/33039708.xml'\n",
      "XML data for PMID 32620137 saved to 'EPMC_XML_Files/32620137.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    730      0 --:--:-- --:--:-- --:--:--   736\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    506      0 --:--:-- --:--:-- --:--:--   509\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 33005419 saved to 'EPMC_XML_Files/33005419.xml'\n",
      "XML data for PMID 31857725 saved to 'EPMC_XML_Files/31857725.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    708      0 --:--:-- --:--:-- --:--:--   710\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    612      0 --:--:-- --:--:-- --:--:--   613\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 32344344 saved to 'EPMC_XML_Files/32344344.xml'\n",
      "XML data for PMID 32826857 saved to 'EPMC_XML_Files/32826857.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    430      0 --:--:-- --:--:-- --:--:--   433\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    449      0 --:--:-- --:--:-- --:--:--   450\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 32300371 saved to 'EPMC_XML_Files/32300371.xml'\n",
      "XML data for PMID 32298292 saved to 'EPMC_XML_Files/32298292.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    657      0 --:--:-- --:--:-- --:--:--   658\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    703      0 --:--:-- --:--:-- --:--:--   704\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 32878308 saved to 'EPMC_XML_Files/32878308.xml'\n",
      "XML data for PMID 32933477 saved to 'EPMC_XML_Files/32933477.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    719      0 --:--:-- --:--:-- --:--:--   723\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    703      0 --:--:-- --:--:-- --:--:--   710\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 33329703 saved to 'EPMC_XML_Files/33329703.xml'\n",
      "XML data for PMID 33324147 saved to 'EPMC_XML_Files/33324147.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    677      0 --:--:-- --:--:-- --:--:--   680\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    612      0 --:--:-- --:--:-- --:--:--   613\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 33133228 saved to 'EPMC_XML_Files/33133228.xml'\n",
      "XML data for PMID 32324731 saved to 'EPMC_XML_Files/32324731.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    581      0 --:--:-- --:--:-- --:--:--   582\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    743      0 --:--:-- --:--:-- --:--:--   743\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 33328863 saved to 'EPMC_XML_Files/33328863.xml'\n",
      "XML data for PMID 32915751 saved to 'EPMC_XML_Files/32915751.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    642      0 --:--:-- --:--:-- --:--:--   648\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    744      0 --:--:-- --:--:-- --:--:--   750\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 33240258 saved to 'EPMC_XML_Files/33240258.xml'\n",
      "XML data for PMID 32218835 saved to 'EPMC_XML_Files/32218835.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    717      0 --:--:-- --:--:-- --:--:--   723\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    540      0 --:--:-- --:--:-- --:--:--   543\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 32753502 saved to 'EPMC_XML_Files/32753502.xml'\n",
      "XML data for PMID 33039708 saved to 'EPMC_XML_Files/33039708.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    667      0 --:--:-- --:--:-- --:--:--   669\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    731      0 --:--:-- --:--:-- --:--:--   736\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 33126877 saved to 'EPMC_XML_Files/33126877.xml'\n",
      "XML data for PMID 32681213 saved to 'EPMC_XML_Files/32681213.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    702      0 --:--:-- --:--:-- --:--:--   704\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    741      0 --:--:-- --:--:-- --:--:--   736\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 33354569 saved to 'EPMC_XML_Files/33354569.xml'\n",
      "XML data for PMID 32545899 saved to 'EPMC_XML_Files/32545899.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    751      0 --:--:-- --:--:-- --:--:--   757\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    723      0 --:--:-- --:--:-- --:--:--   729\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 33679869 saved to 'EPMC_XML_Files/33679869.xml'\n",
      "XML data for PMID 33349236 saved to 'EPMC_XML_Files/33349236.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    689      0 --:--:-- --:--:-- --:--:--   692\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    753      0 --:--:-- --:--:-- --:--:--   757\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 32286325 saved to 'EPMC_XML_Files/32286325.xml'\n",
      "XML data for PMID 33425719 saved to 'EPMC_XML_Files/33425719.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    672      0 --:--:-- --:--:-- --:--:--   675\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    708      0 --:--:-- --:--:-- --:--:--   710\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 32858131 saved to 'EPMC_XML_Files/32858131.xml'\n",
      "XML data for PMID 33126851 saved to 'EPMC_XML_Files/33126851.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    726      0 --:--:-- --:--:-- --:--:--   729\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    482      0 --:--:-- --:--:-- --:--:--   482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 33225896 saved to 'EPMC_XML_Files/33225896.xml'\n",
      "XML data for PMID 33431047 saved to 'EPMC_XML_Files/33431047.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    660      0 --:--:-- --:--:-- --:--:--   663\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 34297718 saved to 'EPMC_XML_Files/34297718.xml'\n",
      "XML data for PMID 34168145 saved to 'EPMC_XML_Files/34168145.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    615      0 --:--:-- --:--:-- --:--:--   618\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    395      0 --:--:-- --:--:-- --:--:--   397\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    498      0 --:--:-- --:--:-- --:--:--   500\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 34388102 saved to 'EPMC_XML_Files/34388102.xml'\n",
      "XML data for PMID 34372798 saved to 'EPMC_XML_Files/34372798.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    723      0 --:--:-- --:--:-- --:--:--   729\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    610      0 --:--:-- --:--:-- --:--:--   609\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 33169030 saved to 'EPMC_XML_Files/33169030.xml'\n",
      "XML data for PMID 33464298 saved to 'EPMC_XML_Files/33464298.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    673      0 --:--:-- --:--:-- --:--:--   675\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    666      0 --:--:-- --:--:-- --:--:--   669\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 33953201 saved to 'EPMC_XML_Files/33953201.xml'\n",
      "XML data for PMID 34099697 saved to 'EPMC_XML_Files/34099697.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    739      0 --:--:-- --:--:-- --:--:--   743\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    675      0 --:--:-- --:--:-- --:--:--   680\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 33810341 saved to 'EPMC_XML_Files/33810341.xml'\n",
      "XML data for PMID 32991297 saved to 'EPMC_XML_Files/32991297.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    756      0 --:--:-- --:--:-- --:--:--   757\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    711      0 --:--:-- --:--:-- --:--:--   716\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 34070374 saved to 'EPMC_XML_Files/34070374.xml'\n",
      "XML data for PMID 34229736 saved to 'EPMC_XML_Files/34229736.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    616      0 --:--:-- --:--:-- --:--:--   618\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    573      0 --:--:-- --:--:-- --:--:--   570\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 34099048 saved to 'EPMC_XML_Files/34099048.xml'\n",
      "XML data for PMID 34603483 saved to 'EPMC_XML_Files/34603483.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    640      0 --:--:-- --:--:-- --:--:--   642\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    692      0 --:--:-- --:--:-- --:--:--   698\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 33535965 saved to 'EPMC_XML_Files/33535965.xml'\n",
      "XML data for PMID 34254032 saved to 'EPMC_XML_Files/34254032.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    504      0 --:--:-- --:--:-- --:--:--   506\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    697      0 --:--:-- --:--:-- --:--:--   698\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 34573923 saved to 'EPMC_XML_Files/34573923.xml'\n",
      "XML data for PMID 33465072 saved to 'EPMC_XML_Files/33465072.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    575      0 --:--:-- --:--:-- --:--:--   578\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    533      0 --:--:-- --:--:-- --:--:--   532\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 34419924 saved to 'EPMC_XML_Files/34419924.xml'\n",
      "XML data for PMID 33510068 saved to 'EPMC_XML_Files/33510068.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    585      0 --:--:-- --:--:-- --:--:--   586\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    722      0 --:--:-- --:--:-- --:--:--   729\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 33946997 saved to 'EPMC_XML_Files/33946997.xml'\n",
      "XML data for PMID 33953203 saved to 'EPMC_XML_Files/33953203.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    629      0 --:--:-- --:--:-- --:--:--   632\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    653      0 --:--:-- --:--:-- --:--:--   658\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 33953534 saved to 'EPMC_XML_Files/33953534.xml'\n",
      "XML data for PMID 33828982 saved to 'EPMC_XML_Files/33828982.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    374      0 --:--:-- --:--:-- --:--:--   376\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 34112769 saved to 'EPMC_XML_Files/34112769.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    176      0 --:--:-- --:--:-- --:--:--   175\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    689      0 --:--:-- --:--:-- --:--:--   692\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 34372798 saved to 'EPMC_XML_Files/34372798.xml'\n",
      "XML data for PMID 33995917 saved to 'EPMC_XML_Files/33995917.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    354      0 --:--:-- --:--:-- --:--:--   355\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 34093642 saved to 'EPMC_XML_Files/34093642.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    149      0 --:--:-- --:--:-- --:--:--   148\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    428      0 --:--:-- --:--:-- --:--:--   428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 34258160 saved to 'EPMC_XML_Files/34258160.xml'\n",
      "XML data for PMID 34290238 saved to 'EPMC_XML_Files/34290238.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    690      0 --:--:-- --:--:-- --:--:--   692\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 34706730 saved to 'EPMC_XML_Files/34706730.xml'\n",
      "XML data for PMID 33584803 saved to 'EPMC_XML_Files/33584803.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    782      0 --:--:-- --:--:-- --:--:--   786\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    711      0 --:--:-- --:--:-- --:--:--   716\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 34662334 saved to 'EPMC_XML_Files/34662334.xml'\n",
      "XML data for PMID 34104645 saved to 'EPMC_XML_Files/34104645.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    435      0 --:--:-- --:--:-- --:--:--   437\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    720      0 --:--:-- --:--:-- --:--:--   716\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 33532838 saved to 'EPMC_XML_Files/33532838.xml'\n",
      "XML data for PMID 36414666 saved to 'EPMC_XML_Files/36414666.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    630      0 --:--:-- --:--:-- --:--:--   632\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    557      0 --:--:-- --:--:-- --:--:--   558\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 35489069 saved to 'EPMC_XML_Files/35489069.xml'\n",
      "XML data for PMID 35896542 saved to 'EPMC_XML_Files/35896542.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    661      0 --:--:-- --:--:-- --:--:--   663\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    719      0 --:--:-- --:--:-- --:--:--   723\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 36525447 saved to 'EPMC_XML_Files/36525447.xml'\n",
      "XML data for PMID 37039115 saved to 'EPMC_XML_Files/37039115.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    726      0 --:--:-- --:--:-- --:--:--   729\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    726      0 --:--:-- --:--:-- --:--:--   729\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 37996753 saved to 'EPMC_XML_Files/37996753.xml'\n",
      "XML data for PMID 38114456 saved to 'EPMC_XML_Files/38114456.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    460      0 --:--:-- --:--:-- --:--:--   460\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    676      0 --:--:-- --:--:-- --:--:--   680\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 36420989 saved to 'EPMC_XML_Files/36420989.xml'\n",
      "XML data for PMID 37204193 saved to 'EPMC_XML_Files/37204193.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    685      0 --:--:-- --:--:-- --:--:--   692\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    400      0 --:--:-- --:--:-- --:--:--   402\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    466      0 --:--:-- --:--:-- --:--:--   468\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 38015968 saved to 'EPMC_XML_Files/38015968.xml'\n",
      "XML data for PMID 37971967 saved to 'EPMC_XML_Files/37971967.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    677      0 --:--:-- --:--:-- --:--:--   680\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 37602759 saved to 'EPMC_XML_Files/37602759.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    402      0 --:--:-- --:--:-- --:--:--   402\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    678      0 --:--:-- --:--:-- --:--:--   680\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 37776368 saved to 'EPMC_XML_Files/37776368.xml'\n",
      "XML data for PMID 37889008 saved to 'EPMC_XML_Files/37889008.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    506      0 --:--:-- --:--:-- --:--:--   509\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    496      0 --:--:-- --:--:-- --:--:--   500\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 37882604 saved to 'EPMC_XML_Files/37882604.xml'\n",
      "XML data for PMID 38000911 saved to 'EPMC_XML_Files/38000911.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    633      0 --:--:-- --:--:-- --:--:--   637\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    551      0 --:--:-- --:--:-- --:--:--   554\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 37966428 saved to 'EPMC_XML_Files/37966428.xml'\n",
      "XML data for PMID 38091508 saved to 'EPMC_XML_Files/38091508.xml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    81    0    81    0     0    710      0 --:--:-- --:--:-- --:--:--   710\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    81    0    81    0     0    696      0 --:--:-- --:--:-- --:--:--   698\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID 38280188 saved to 'EPMC_XML_Files/38280188.xml'\n",
      "XML data for PMID 39172545 saved to 'EPMC_XML_Files/39172545.xml'\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Define the path to the \"Valid DOME Registry\" CSV file\n",
    "valid_csv_file_name = 'valid_DOME_Registry_Contents.csv'  # Replace with your actual file name\n",
    "\n",
    "# Define the output folder for XML files\n",
    "output_folder = 'EPMC_XML_Files'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Function to read CSV data\n",
    "def read_csv(file_name):\n",
    "    try:\n",
    "        with open(file_name, 'r', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            data = [row for row in reader]\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the CSV file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Read CSV data\n",
    "csv_data = read_csv(valid_csv_file_name)\n",
    "\n",
    "# Retrieve and save XML data for each PMID using bash commands\n",
    "if csv_data:\n",
    "    for row in csv_data:\n",
    "        pmid = row.get('publication_pmid', '')\n",
    "        if pmid:\n",
    "            output_file = os.path.join(output_folder, f\"{pmid}.xml\")\n",
    "            command = f\"curl https://europepmc.org/rest/v1/article/{pmid}/full > {output_file}\"\n",
    "            subprocess.run(command, shell=True)\n",
    "            print(f\"XML data for PMID {pmid} saved to '{output_file}'\")\n",
    "else:\n",
    "    print(\"No data to process.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
