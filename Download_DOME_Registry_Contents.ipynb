{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Python script to download latest DOME Registry contents, related full text papers & provide DOME Registry entries metadata read out (20241202)**\n",
    "1. DOME Registry contents will be downloaded by API call proividng the json file of DOME Registry data\n",
    "2. DOME Registry data json will be flattened and converted into CSV for working with entries data (row based data)\n",
    "3. DOME Registry CSV will be checked and used to produce a metadata readout file (+ graphs)\n",
    "4. DOME Registry DOIs of articles will be convrted to PMCIDs for full text retrieval \n",
    "5. DOME Registry entries will be downloaded as full XML files using PMCIDs list and NCBI Entrez service (Replace with EPMC when API works [^1] )\n",
    "\n",
    "[^1]: EPMC full text XL API module issues on 20241204"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DOME Registry contents will be downloaded by API call proividng the json file of DOME Registry data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists for today's date, do you want to overwrite? (y/n)\n",
      "Overwriting file\n",
      "DOME Registry data downloaded and saved to 'DOME_Registry_Contents_2024-12-05.json'\n"
     ]
    }
   ],
   "source": [
    "# 1. Use the DOME API to download all entries of the DOME Registry and store this in a json file \n",
    "import requests\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the URL for the API call: check the API documentation for the correct URL on the DOME Registry website\n",
    "url = \"https://registry.dome-ml.org/api/review?skip=0&limit=250&text=%20&public=true&sort=publication.year&asc=true\"\n",
    "\n",
    "# Make an API request to the URL\n",
    "response = requests.get(url, headers={'accept': '*/*'})\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Get the current date in ISO format for file naming\n",
    "    # Potentially update fiel datetime granularity if needing to run more regularly than daily, DOME Registry contents unlikely to be more regular than this\n",
    "    current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "\n",
    "    # Create the output file name \n",
    "    file_name = f\"DOME_Registry_Contents_{current_date}.json\"\n",
    "\n",
    "    # Check if the file pathway already exists\n",
    "    if os.path.exists(file_name):\n",
    "        print(f\"File already exists for today's date, do you want to overwrite? (y/n)\")\n",
    "        overwrite = input('Do you want to overwrite the file? (y/n): ') \n",
    "        if overwrite == 'n':\n",
    "            print('Exiting without overwriting file')\n",
    "            exit()\n",
    "        elif overwrite == 'y':\n",
    "            print('Overwriting file')\n",
    "        else:\n",
    "            print('Invalid input, exiting')\n",
    "            exit()\n",
    "\n",
    "    \n",
    "    # Save the content to a file\n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        file.write(response.text)\n",
    "    \n",
    "    print(f\"DOME Registry data downloaded and saved to '{file_name}'\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the data. Status code: {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DOME Registry data json will be flattened and converted into CSV for working with entries data (row based data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened JSON data saved to 'flattened_DOME_Registry_Contents_2024-12-05.json'\n",
      "JSON data written to 'flattened_DOME_Registry_Contents_2024-12-05.csv'\n"
     ]
    }
   ],
   "source": [
    "# 2. Produce DOME Registry contents metadata .csv file and data visualisation\n",
    "import json\n",
    "\n",
    "# 2.1 Pretty print DOME Registry contents JSON file for inspection to ensure all looks as expected\n",
    "\n",
    "# Function to read and pretty-print the JSON file sample entry\n",
    "def pretty_print_json(file_name):\n",
    "    try:\n",
    "        # Open and read the JSON file\n",
    "        with open(file_name, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # Pretty-print the JSON data\n",
    "        print(json.dumps(data, indent=4))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the JSON file: {e}\")\n",
    "\n",
    "# Call the function to pretty-print the JSON file\n",
    "# pretty_print_json(file_name)\n",
    "\n",
    "\n",
    "# 2.2 Flatten the JSON for easier data processing and write to a new .json file \n",
    "# Function to read JSON data\n",
    "def read_json(file_name):\n",
    "    try:\n",
    "        with open(file_name, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the JSON file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to flatten JSON\n",
    "def flatten_json(y):\n",
    "    out = {}\n",
    "\n",
    "    def flatten(x, name=''):\n",
    "        if type(x) is dict:\n",
    "            for a in x:\n",
    "                flatten(x[a], name + a + '_')\n",
    "        elif type(x) is list:\n",
    "            i = 0\n",
    "            for a in x:\n",
    "                flatten(a, name + str(i) + '_')\n",
    "                i += 1\n",
    "        else:\n",
    "            out[name[:-1]] = x\n",
    "\n",
    "    flatten(y)\n",
    "    return out\n",
    "\n",
    "# Function to save flattened JSON to a file\n",
    "def save_flattened_json(flattened_data, output_file_name):\n",
    "    try:\n",
    "        with open(output_file_name, 'w', encoding='utf-8') as file:\n",
    "            json.dump(flattened_data, file, indent=4)\n",
    "        print(f\"Flattened JSON data saved to '{output_file_name}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving the flattened JSON file: {e}\")\n",
    "\n",
    "# Read JSON data\n",
    "data = read_json(file_name)\n",
    "\n",
    "# Flatten JSON data and save to a new file\n",
    "if data:\n",
    "    flattened_data = [flatten_json(entry) for entry in data]\n",
    "    flattened_file_name = (\"flattened_\"+file_name)\n",
    "    save_flattened_json(flattened_data, flattened_file_name)\n",
    "    \n",
    "    # Print the flattened JSON data to view it\n",
    "    # to add a print of file output name and sucess ftatement - print(flattened_file_name)\n",
    "    #print(json.dumps(flattened_data, indent=4))\n",
    "else:\n",
    "    print(\"No data to process.\")\n",
    "\n",
    "\n",
    "\n",
    "#2.3 Convert flattened json to csv \n",
    "# Function to read flattened JSON data\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Define the path to the flattened JSON file\n",
    "#flattened_file_name = 'flattened_DOME_Registry_Contents.json'  # Replace with your actual file name\n",
    "\n",
    "# Function to read flattened JSON data\n",
    "def read_flattened_json(file_name):\n",
    "    try:\n",
    "        with open(file_name, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the flattened JSON file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to write JSON data to a CSV file\n",
    "def write_json_to_csv(json_data, csv_file_name):\n",
    "    try:\n",
    "        # Determine all possible headers from the entire dataset\n",
    "        headers = set()\n",
    "        for entry in json_data:\n",
    "            headers.update(entry.keys())\n",
    "        headers = list(headers)\n",
    "        \n",
    "        # Write data to CSV file\n",
    "        with open(csv_file_name, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=headers)\n",
    "            writer.writeheader()\n",
    "            for entry in json_data:\n",
    "                writer.writerow(entry)\n",
    "        \n",
    "        print(f\"JSON data written to '{csv_file_name}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing to the CSV file: {e}\")\n",
    "\n",
    "# Read flattened JSON data\n",
    "flattened_data = read_flattened_json(flattened_file_name)\n",
    "\n",
    "# Process JSON data into CSV\n",
    "if flattened_data:\n",
    "    csv_file_name = flattened_file_name[:-5]+'.csv'\n",
    "    write_json_to_csv(flattened_data, csv_file_name)\n",
    "else:\n",
    "    print(\"No data to process.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DOME Registry CSV will be analysed for entry compliance and used to produce a metadata readout file (+ graphs - TBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f\n",
      "l\n",
      "a\n",
      "t\n",
      "t\n",
      "e\n",
      "n\n",
      "e\n",
      "d\n",
      "_\n",
      "D\n",
      "O\n",
      "M\n",
      "E\n",
      "_\n",
      "R\n",
      "e\n",
      "g\n",
      "i\n",
      "s\n",
      "t\n",
      "r\n",
      "y\n",
      "_\n",
      "C\n",
      "o\n",
      "n\n",
      "t\n",
      "e\n",
      "n\n",
      "t\n",
      "s\n",
      "_\n",
      "2\n",
      "0\n",
      "2\n",
      "4\n",
      "-\n",
      "1\n",
      "2\n",
      "-\n",
      "0\n",
      "4\n",
      ".\n",
      "c\n",
      "s\n",
      "v\n",
      "211 of 214 PMIDs valid\n",
      "3 of 214 PMIDs invalid\n",
      "208 of 214 DOIs valid\n",
      "6 of 214 DOIs invalid\n",
      "Metadata written to 'Metadata_flattened_DOME_Registry_Contents_2024-12-04.csv'\n"
     ]
    }
   ],
   "source": [
    "# Production of the DOME Registry fields validity data & subsequent metadata csv file \n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "\n",
    "# 3.1  Simple print of all DOME fields & simple explainer put into text file \n",
    "# for assisting with use of DOME Regsitry entry data\n",
    "# for header in csv_file_name:\n",
    "#    print(header)\n",
    "\n",
    "# Define regexes to check various CSV header field entries\n",
    "# Define the EPMC regex pattern for PMIDs\n",
    "pmid_pattern = re.compile(r'^\\d{8}$')\n",
    "\n",
    "# Define the regex pattern for DOIs\n",
    "doi_pattern = re.compile(r'^10.\\d{4,9}/[-._;()/:A-Z0-9]+$', re.IGNORECASE)\n",
    "\n",
    "# Function to read CSV data\n",
    "def read_csv(file_name):\n",
    "    try:\n",
    "        with open(file_name, 'r', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            data = [row for row in reader]\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the CSV file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to check PMIDs and DOIs and generate metadata\n",
    "def check_pmids_and_dois_and_generate_metadata(data, csv_file_name):\n",
    "    pmid_valid = 0\n",
    "    pmid_invalid = 0\n",
    "    doi_valid = 0\n",
    "    doi_invalid = 0\n",
    "    total_entries = len(data)\n",
    "    \n",
    "    for row in data:\n",
    "        pmid = row.get('publication_pmid', '')\n",
    "        doi = row.get('publication_doi', '')\n",
    "        \n",
    "        if pmid_pattern.match(pmid):\n",
    "            pmid_valid += 1\n",
    "        else:\n",
    "            pmid_invalid += 1\n",
    "        \n",
    "        if doi_pattern.match(doi):\n",
    "            doi_valid += 1\n",
    "        else:\n",
    "            doi_invalid += 1\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"{pmid_valid} of {total_entries} PMIDs valid\")\n",
    "    print(f\"{pmid_invalid} of {total_entries} PMIDs invalid\")\n",
    "    print(f\"{doi_valid} of {total_entries} DOIs valid\")\n",
    "    print(f\"{doi_invalid} of {total_entries} DOIs invalid\")\n",
    "    \n",
    "    # Create metadata CSV file\n",
    "    metadata_file_name = f\"Metadata_{os.path.basename(csv_file_name)}\"\n",
    "    with open(metadata_file_name, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['Metric', 'Value'])\n",
    "        writer.writerow(['Total Entries', total_entries])\n",
    "        writer.writerow(['Valid PMIDs', pmid_valid])\n",
    "        writer.writerow(['Invalid PMIDs', pmid_invalid])\n",
    "        writer.writerow(['Valid DOIs', doi_valid])\n",
    "        writer.writerow(['Invalid DOIs', doi_invalid])\n",
    "    \n",
    "    print(f\"Metadata written to '{metadata_file_name}'\")\n",
    "\n",
    "# Read CSV data\n",
    "csv_data = read_csv(csv_file_name)\n",
    "\n",
    "# Check PMIDs and DOIs and generate metadata\n",
    "if csv_data:\n",
    "    check_pmids_and_dois_and_generate_metadata(csv_data, csv_file_name)\n",
    "else:\n",
    "    print(\"No data to process.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattened_DOME_Registry_Contents_2024-12-05.csv\n",
      "Number of DOME Registry field entries: 45\n",
      "['matches_evaluation/availability', 'matches_model/duration', 'score', 'matches_publication/authors', 'publication_authors', 'matches_model/availability', 'matches_publication/year', 'matches_optimization/parameters', 'matches_publication/updated', 'matches_publication/doi', 'matches_optimization/fitting', 'publication_skip', 'matches_optimization/config', 'publication_doi', 'matches_optimization/encoding', 'matches_publication/pmid', 'matches_evaluation/method', 'matches_optimization/features', 'matches_optimization/meta', 'updated', 'uuid', 'publication_updated', 'matches_dataset/availability', 'public', 'matches_optimization/algorithm', 'matches_evaluation/measure', 'publication_pmid', 'publication_created', 'matches_evaluation/confidence', 'matches_model/interpretability', 'matches_evaluation/comparison', 'matches_publication/title', 'matches_dataset/provenance', 'publication_year', 'publication_done', 'matches_dataset/splits', 'publication_journal', 'shortid', '_id', 'created', 'matches_publication/journal', 'publication_title', 'matches_model/output', 'matches_dataset/redundancy', 'matches_optimization/regularization']\n",
      "                                 _id                   created  public  \\\n",
      "shortid                                                                  \n",
      "6i0xepuivt  63516fedb9c880af1f305b5c  2022-09-01T15:16:05.444Z    True   \n",
      "nlj5x3dld8  63516fedb9c880af1f305b93  2022-09-01T15:16:05.445Z    True   \n",
      "ysqyy92zyr  66030aaa1502715bfe53d65c  2024-03-26T17:49:30.048Z    True   \n",
      "qx3ex71jye  66041e5d1502715bfe53d70a  2024-03-27T13:25:49.790Z    True   \n",
      "v536tc3b5t  63516fedb9c880af1f305b1c  2022-09-01T15:16:05.443Z    True   \n",
      "\n",
      "                                          publication_authors  \\\n",
      "shortid                                                         \n",
      "6i0xepuivt               Wang H, Zheng H, Simpson D, Azuaje F   \n",
      "nlj5x3dld8               Al-Shahib A, Breitling R, Gilbert DR   \n",
      "ysqyy92zyr  Hui Lan, Rachel Carson , Nicholas J Provart an...   \n",
      "qx3ex71jye  Blaise Gassend, Charles W O'Donnell, William T...   \n",
      "v536tc3b5t                  Tsai RT, Dai HJ, Huang CH, Hsu WL   \n",
      "\n",
      "            publication_created              publication_doi  \\\n",
      "shortid                                                        \n",
      "6i0xepuivt                  NaN      10.1186/1471-2105-7-116   \n",
      "nlj5x3dld8                  NaN       10.1186/1471-2164-8-78   \n",
      "ysqyy92zyr                  NaN      10.1186/1471-2105-8-358   \n",
      "qx3ex71jye                  NaN    10.1186/1471-2105-8-S5-S3   \n",
      "v536tc3b5t                  NaN  10.1186/1471-2105-9-S12-S18   \n",
      "\n",
      "            publication_done publication_journal publication_pmid  \\\n",
      "shortid                                                             \n",
      "6i0xepuivt               0.0  BMC Bioinformatics         16524483   \n",
      "nlj5x3dld8               0.0        BMC Genomics         17374164   \n",
      "ysqyy92zyr               NaN  BMC Bioinformatics         17888165   \n",
      "qx3ex71jye               NaN  BMC Bioinformatics         17570862   \n",
      "v536tc3b5t               0.0  BMC Bioinformatics         19091017   \n",
      "\n",
      "            publication_skip  ...  \\\n",
      "shortid                       ...   \n",
      "6i0xepuivt               0.0  ...   \n",
      "nlj5x3dld8               0.0  ...   \n",
      "ysqyy92zyr               NaN  ...   \n",
      "qx3ex71jye               NaN  ...   \n",
      "v536tc3b5t               0.0  ...   \n",
      "\n",
      "                                    matches_publication/title  \\\n",
      "shortid                                                         \n",
      "6i0xepuivt  Machine learning approaches to supporting the ...   \n",
      "nlj5x3dld8  Predicting protein function by machine learnin...   \n",
      "ysqyy92zyr  Combining classifiers to predict gene function...   \n",
      "qx3ex71jye  Learning biophysically-motivated parameters fo...   \n",
      "v536tc3b5t  Semi-automatic conversion of BioProp semantic ...   \n",
      "\n",
      "           matches_publication/updated matches_publication/year  \\\n",
      "shortid                                                           \n",
      "6i0xepuivt         01/28/2022 00:13:56                      NaN   \n",
      "nlj5x3dld8         03/09/2022 10:14:51                      NaN   \n",
      "ysqyy92zyr                         NaN                      NaN   \n",
      "qx3ex71jye                         NaN                      NaN   \n",
      "v536tc3b5t         03/25/2022 13:35:02                      NaN   \n",
      "\n",
      "                                  matches_publication/authors  \\\n",
      "shortid                                                         \n",
      "6i0xepuivt               Wang H, Zheng H, Simpson D, Azuaje F   \n",
      "nlj5x3dld8               Al-Shahib A, Breitling R, Gilbert DR   \n",
      "ysqyy92zyr  Hui Lan, Rachel Carson , Nicholas J Provart an...   \n",
      "qx3ex71jye  Blaise Gassend, Charles W O'Donnell, William T...   \n",
      "v536tc3b5t                  Tsai RT, Dai HJ, Huang CH, Hsu WL   \n",
      "\n",
      "           matches_publication/doi matches_publication/journal  \\\n",
      "shortid                                                          \n",
      "6i0xepuivt                     NaN          BMC Bioinformatics   \n",
      "nlj5x3dld8                     NaN                BMC Genomics   \n",
      "ysqyy92zyr                     NaN          BMC Bioinformatics   \n",
      "qx3ex71jye                     NaN          BMC Bioinformatics   \n",
      "v536tc3b5t                     NaN          BMC Bioinformatics   \n",
      "\n",
      "           matches_publication/pmid  \\\n",
      "shortid                               \n",
      "6i0xepuivt                      NaN   \n",
      "nlj5x3dld8                      NaN   \n",
      "ysqyy92zyr                      NaN   \n",
      "qx3ex71jye                      NaN   \n",
      "v536tc3b5t                      NaN   \n",
      "\n",
      "                                    matches_publication/title  \\\n",
      "shortid                                                         \n",
      "6i0xepuivt  Machine learning approaches to supporting the ...   \n",
      "nlj5x3dld8  Predicting protein function by machine learnin...   \n",
      "ysqyy92zyr  Combining classifiers to predict gene function...   \n",
      "qx3ex71jye  Learning biophysically-motivated parameters fo...   \n",
      "v536tc3b5t  Semi-automatic conversion of BioProp semantic ...   \n",
      "\n",
      "           matches_publication/updated matches_publication/year  \n",
      "shortid                                                          \n",
      "6i0xepuivt         01/28/2022 00:13:56                      NaN  \n",
      "nlj5x3dld8         03/09/2022 10:14:51                      NaN  \n",
      "ysqyy92zyr                         NaN                      NaN  \n",
      "qx3ex71jye                         NaN                      NaN  \n",
      "v536tc3b5t         03/25/2022 13:35:02                      NaN  \n",
      "\n",
      "[5 rows x 51 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3.1  Simple print of all DOME fields & simple explainer put into text file \n",
    "# for assisting with use of DOME Registry entry data\n",
    "# reformat using dataframe the DOME entries csv columns into more logical format\n",
    "import csv\n",
    "import pandas as pd #because who doesn't love a panda \n",
    "\n",
    "#Read in DOME Entries CSV as dataframe via pandas library functions\n",
    "print(csv_file_name)\n",
    "DOME_Entries_dataframe = pd.read_csv(csv_file_name)\n",
    "\n",
    "# View data frame to inspect all data appears ok\n",
    "DOME_Entries_dataframe.head()\n",
    "DOME_Entries_dataframe.shape\n",
    "\n",
    "#Get number of entries in header row correpsonding to DOME Registry entries fields \n",
    "# from a given entry related to its originating JSON file\n",
    "i=0\n",
    "header_entries_for_text_file = []\n",
    "for header_entry in (DOME_Entries_dataframe.columns):\n",
    "     i = i+1\n",
    "     header_entries_for_text_file.append(header_entry)\n",
    "print('Number of DOME Registry field entries: ' + str(i))\n",
    "print(header_entries_for_text_file)\n",
    "\n",
    "# to remove redundant fields and check over these - TBC\n",
    "df = DOME_Entries_dataframe.reindex(sorted(DOME_Entries_dataframe.columns), axis=1)\n",
    "df.head()\n",
    "# to create more metadata and graph of entries (to work and think on)\n",
    "# to add and choose main ID for rows header\n",
    "# to do DOI checks and regex\n",
    "# to get PMC full text from DOI and store in local folder\n",
    "\n",
    "row_names = df['uuid']\n",
    "#print(row_names)\n",
    "\n",
    "# Set row names as shortid whichh corresponds to DOME Registry unique short id \n",
    "df = pd.DataFrame(df).set_index('shortid')\n",
    "\n",
    "# Reorder metadata to start of columns list\n",
    "# Define the prefixes to match and group csv data\n",
    "prefix_matches_cols = 'matches_'\n",
    "prefix_publications_cols= 'matches_publication'\n",
    "prefix_data_cols= 'matches_data'\n",
    "prefix_optimization_cols= 'matches_optimization'\n",
    "prefix_model_cols= 'matches_model'\n",
    "prefix_evaluation_cols= 'matches_evaluation'\n",
    "\n",
    "# Separate columns based on whether they start with the prefix\n",
    "matches_publication_columns = [col for col in df.columns if col.startswith(prefix_publications_cols)]\n",
    "matches_data_columns = [col for col in df.columns if col.startswith(prefix_publications_cols)]\n",
    "matches_optimization_columns = [col for col in df.columns if col.startswith(prefix_publications_cols)]\n",
    "matches_model_columns = [col for col in df.columns if col.startswith(prefix_publications_cols)]\n",
    "matches_evaluation_columns = [col for col in df.columns if col.startswith(prefix_publications_cols)]\n",
    "other_columns = [col for col in df.columns if not col.startswith(prefix_matches_cols)]\n",
    "\n",
    "# Reorder columns\n",
    "reordered_columns = other_columns + matches_publication_columns + matches_data_columns + matches_optimization_columns + matches_model_columns + matches_evaluation_columns\n",
    "df = df[reordered_columns]\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "df.to_csv(csv_file_name, sep=',', index=True, encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(matches_publication_columns \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col\u001b[38;5;241m.\u001b[39mstartswith(prefix_publications_cols)])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(matches_publication_columns = [col for col in df.columns if col.startswith(prefix_publications_cols)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of DOME Registry field entries: 45\n",
      "['matches_evaluation/availability', 'matches_model/duration', 'score', 'matches_publication/authors', 'publication_authors', 'matches_model/availability', 'matches_publication/year', 'matches_optimization/parameters', 'matches_publication/updated', 'matches_publication/doi', 'matches_optimization/fitting', 'publication_skip', 'matches_optimization/config', 'publication_doi', 'matches_optimization/encoding', 'matches_publication/pmid', 'matches_evaluation/method', 'matches_optimization/features', 'matches_optimization/meta', 'updated', 'uuid', 'publication_updated', 'matches_dataset/availability', 'public', 'matches_optimization/algorithm', 'matches_evaluation/measure', 'publication_pmid', 'publication_created', 'matches_evaluation/confidence', 'matches_model/interpretability', 'matches_evaluation/comparison', 'matches_publication/title', 'matches_dataset/provenance', 'publication_year', 'publication_done', 'matches_dataset/splits', 'publication_journal', 'shortid', '_id', 'created', 'matches_publication/journal', 'publication_title', 'matches_model/output', 'matches_dataset/redundancy', 'matches_optimization/regularization']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>created</th>\n",
       "      <th>matches_dataset/availability</th>\n",
       "      <th>matches_dataset/provenance</th>\n",
       "      <th>matches_dataset/redundancy</th>\n",
       "      <th>matches_dataset/splits</th>\n",
       "      <th>matches_evaluation/availability</th>\n",
       "      <th>matches_evaluation/comparison</th>\n",
       "      <th>matches_evaluation/confidence</th>\n",
       "      <th>matches_evaluation/measure</th>\n",
       "      <th>...</th>\n",
       "      <th>publication_done</th>\n",
       "      <th>publication_journal</th>\n",
       "      <th>publication_pmid</th>\n",
       "      <th>publication_skip</th>\n",
       "      <th>publication_title</th>\n",
       "      <th>publication_updated</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>score</th>\n",
       "      <th>updated</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6i0xepuivt</th>\n",
       "      <td>63516fedb9c880af1f305b5c</td>\n",
       "      <td>2022-09-01T15:16:05.444Z</td>\n",
       "      <td>yes, https://www.nature.com/articles/s41467-01...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BMC Bioinformatics</td>\n",
       "      <td>16524483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Machine learning approaches to supporting the ...</td>\n",
       "      <td>01/28/2022 00:13:56</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.67</td>\n",
       "      <td>2022-09-01T15:16:05.444Z</td>\n",
       "      <td>66a94333-8cd1-499c-86ef-0497a4c4dabc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlj5x3dld8</th>\n",
       "      <td>63516fedb9c880af1f305b93</td>\n",
       "      <td>2022-09-01T15:16:05.445Z</td>\n",
       "      <td>Casp 11 website (https://predictioncenter.org/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not assessed. In principle de novo protein str...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Performance achieved with methods based on aut...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Precision as a function of effective aligned s...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BMC Genomics</td>\n",
       "      <td>17374164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Predicting protein function by machine learnin...</td>\n",
       "      <td>03/09/2022 10:14:51</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.67</td>\n",
       "      <td>2022-09-01T15:16:05.445Z</td>\n",
       "      <td>147ddf2b-6b53-4335-b62f-87994d284310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ysqyy92zyr</th>\n",
       "      <td>66030aaa1502715bfe53d65c</td>\n",
       "      <td>2024-03-26T17:49:30.048Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data are extracted from different databases (T...</td>\n",
       "      <td>Random split has been adopted for cross-valida...</td>\n",
       "      <td>Training set: 11553 data points, No test nor v...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no comparison with other approaches perfomed</td>\n",
       "      <td>no confidence interval reported. No statistica...</td>\n",
       "      <td>ROC curve</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BMC Bioinformatics</td>\n",
       "      <td>17888165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Combining classifiers to predict gene function...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.71</td>\n",
       "      <td>2024-03-26T17:49:30.048Z</td>\n",
       "      <td>600b20de-7c70-41af-ad39-33121af090ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qx3ex71jye</th>\n",
       "      <td>66041e5d1502715bfe53d70a</td>\n",
       "      <td>2024-03-27T13:25:49.790Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data is extracted from the PDB. Data are in cl...</td>\n",
       "      <td>All proteins in the dataset are non-homologous...</td>\n",
       "      <td>Traning set: 150 proteins; Testing set: 150 pr...</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Cmparison with other approaches is missing. No...</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>accuracy and segment-overlap value for alpha h...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BMC Bioinformatics</td>\n",
       "      <td>17570862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Learning biophysically-motivated parameters fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2024-03-27T13:25:49.790Z</td>\n",
       "      <td>b863eb51-d9ae-4fc0-bfd4-006db90d1631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v536tc3b5t</th>\n",
       "      <td>63516fedb9c880af1f305b1c</td>\n",
       "      <td>2022-09-01T15:16:05.443Z</td>\n",
       "      <td>Yes :  data to reproduce the results can be do...</td>\n",
       "      <td>\"Data were extracted from publicly available d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A 5-fold cross-validation was performed to ass...</td>\n",
       "      <td>Yes. (https://github.com/ggonzalezp/hyperfoods)</td>\n",
       "      <td>A baseline input is used, in which all drug ta...</td>\n",
       "      <td>Confidence intervals and statistical significa...</td>\n",
       "      <td>Balanced accuracy, F1 score, AUPR. The last tw...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BMC Bioinformatics</td>\n",
       "      <td>19091017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Semi-automatic conversion of BioProp semantic ...</td>\n",
       "      <td>03/25/2022 13:35:02</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.81</td>\n",
       "      <td>2022-09-01T15:16:05.443Z</td>\n",
       "      <td>28fe7de1-ac05-4cf2-bfa8-d5ddd1ba32b8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 _id                   created  \\\n",
       "shortid                                                          \n",
       "6i0xepuivt  63516fedb9c880af1f305b5c  2022-09-01T15:16:05.444Z   \n",
       "nlj5x3dld8  63516fedb9c880af1f305b93  2022-09-01T15:16:05.445Z   \n",
       "ysqyy92zyr  66030aaa1502715bfe53d65c  2024-03-26T17:49:30.048Z   \n",
       "qx3ex71jye  66041e5d1502715bfe53d70a  2024-03-27T13:25:49.790Z   \n",
       "v536tc3b5t  63516fedb9c880af1f305b1c  2022-09-01T15:16:05.443Z   \n",
       "\n",
       "                                 matches_dataset/availability  \\\n",
       "shortid                                                         \n",
       "6i0xepuivt  yes, https://www.nature.com/articles/s41467-01...   \n",
       "nlj5x3dld8  Casp 11 website (https://predictioncenter.org/...   \n",
       "ysqyy92zyr                                                NaN   \n",
       "qx3ex71jye                                                NaN   \n",
       "v536tc3b5t  Yes :  data to reproduce the results can be do...   \n",
       "\n",
       "                                   matches_dataset/provenance  \\\n",
       "shortid                                                         \n",
       "6i0xepuivt                                                NaN   \n",
       "nlj5x3dld8                                                NaN   \n",
       "ysqyy92zyr  Data are extracted from different databases (T...   \n",
       "qx3ex71jye  Data is extracted from the PDB. Data are in cl...   \n",
       "v536tc3b5t  \"Data were extracted from publicly available d...   \n",
       "\n",
       "                                   matches_dataset/redundancy  \\\n",
       "shortid                                                         \n",
       "6i0xepuivt                                                NaN   \n",
       "nlj5x3dld8  Not assessed. In principle de novo protein str...   \n",
       "ysqyy92zyr  Random split has been adopted for cross-valida...   \n",
       "qx3ex71jye  All proteins in the dataset are non-homologous...   \n",
       "v536tc3b5t                                                NaN   \n",
       "\n",
       "                                       matches_dataset/splits  \\\n",
       "shortid                                                         \n",
       "6i0xepuivt                                                NaN   \n",
       "nlj5x3dld8                                                NaN   \n",
       "ysqyy92zyr  Training set: 11553 data points, No test nor v...   \n",
       "qx3ex71jye  Traning set: 150 proteins; Testing set: 150 pr...   \n",
       "v536tc3b5t  A 5-fold cross-validation was performed to ass...   \n",
       "\n",
       "                            matches_evaluation/availability  \\\n",
       "shortid                                                       \n",
       "6i0xepuivt                                              NaN   \n",
       "nlj5x3dld8                                              NaN   \n",
       "ysqyy92zyr                                              NaN   \n",
       "qx3ex71jye                                    Not available   \n",
       "v536tc3b5t  Yes. (https://github.com/ggonzalezp/hyperfoods)   \n",
       "\n",
       "                                matches_evaluation/comparison  \\\n",
       "shortid                                                         \n",
       "6i0xepuivt                                                NaN   \n",
       "nlj5x3dld8  Performance achieved with methods based on aut...   \n",
       "ysqyy92zyr       no comparison with other approaches perfomed   \n",
       "qx3ex71jye  Cmparison with other approaches is missing. No...   \n",
       "v536tc3b5t  A baseline input is used, in which all drug ta...   \n",
       "\n",
       "                                matches_evaluation/confidence  \\\n",
       "shortid                                                         \n",
       "6i0xepuivt                                                NaN   \n",
       "nlj5x3dld8                                                NaN   \n",
       "ysqyy92zyr  no confidence interval reported. No statistica...   \n",
       "qx3ex71jye                                       Not reported   \n",
       "v536tc3b5t  Confidence intervals and statistical significa...   \n",
       "\n",
       "                                   matches_evaluation/measure  ...  \\\n",
       "shortid                                                        ...   \n",
       "6i0xepuivt                                                NaN  ...   \n",
       "nlj5x3dld8  Precision as a function of effective aligned s...  ...   \n",
       "ysqyy92zyr                                          ROC curve  ...   \n",
       "qx3ex71jye  accuracy and segment-overlap value for alpha h...  ...   \n",
       "v536tc3b5t  Balanced accuracy, F1 score, AUPR. The last tw...  ...   \n",
       "\n",
       "           publication_done publication_journal publication_pmid  \\\n",
       "shortid                                                            \n",
       "6i0xepuivt              0.0  BMC Bioinformatics         16524483   \n",
       "nlj5x3dld8              0.0        BMC Genomics         17374164   \n",
       "ysqyy92zyr              NaN  BMC Bioinformatics         17888165   \n",
       "qx3ex71jye              NaN  BMC Bioinformatics         17570862   \n",
       "v536tc3b5t              0.0  BMC Bioinformatics         19091017   \n",
       "\n",
       "           publication_skip  \\\n",
       "shortid                       \n",
       "6i0xepuivt              0.0   \n",
       "nlj5x3dld8              0.0   \n",
       "ysqyy92zyr              NaN   \n",
       "qx3ex71jye              NaN   \n",
       "v536tc3b5t              0.0   \n",
       "\n",
       "                                            publication_title  \\\n",
       "shortid                                                         \n",
       "6i0xepuivt  Machine learning approaches to supporting the ...   \n",
       "nlj5x3dld8  Predicting protein function by machine learnin...   \n",
       "ysqyy92zyr  Combining classifiers to predict gene function...   \n",
       "qx3ex71jye  Learning biophysically-motivated parameters fo...   \n",
       "v536tc3b5t  Semi-automatic conversion of BioProp semantic ...   \n",
       "\n",
       "            publication_updated publication_year score  \\\n",
       "shortid                                                  \n",
       "6i0xepuivt  01/28/2022 00:13:56             2006  0.67   \n",
       "nlj5x3dld8  03/09/2022 10:14:51             2007  0.67   \n",
       "ysqyy92zyr                  NaN             2007  0.71   \n",
       "qx3ex71jye                  NaN             2007  0.76   \n",
       "v536tc3b5t  03/25/2022 13:35:02             2008  0.81   \n",
       "\n",
       "                             updated                                  uuid  \n",
       "shortid                                                                     \n",
       "6i0xepuivt  2022-09-01T15:16:05.444Z  66a94333-8cd1-499c-86ef-0497a4c4dabc  \n",
       "nlj5x3dld8  2022-09-01T15:16:05.445Z  147ddf2b-6b53-4335-b62f-87994d284310  \n",
       "ysqyy92zyr  2024-03-26T17:49:30.048Z  600b20de-7c70-41af-ad39-33121af090ef  \n",
       "qx3ex71jye  2024-03-27T13:25:49.790Z  b863eb51-d9ae-4fc0-bfd4-006db90d1631  \n",
       "v536tc3b5t  2022-09-01T15:16:05.443Z  28fe7de1-ac05-4cf2-bfa8-d5ddd1ba32b8  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View data frame to inspect all data appears ok\n",
    "DOME_Entries_dataframe.head()\n",
    "DOME_Entries_dataframe.shape\n",
    "\n",
    "#Get number of entries in header row correpsonding to DOME Registry entries fields \n",
    "# from a given entry related to its originating JSON file\n",
    "i=0\n",
    "header_entries_for_text_file = []\n",
    "for header_entry in (DOME_Entries_dataframe.columns):\n",
    "     i = i+1\n",
    "     header_entries_for_text_file.append(header_entry)\n",
    "print('Number of DOME Registry field entries: ' + str(i))\n",
    "print(header_entries_for_text_file)\n",
    "\n",
    "# to remove redundant fields and check over these - TBC\n",
    "df = DOME_Entries_dataframe.reindex(sorted(DOME_Entries_dataframe.columns), axis=1)\n",
    "df.head()\n",
    "# to create more metadata and graph of entries (to work and think on)\n",
    "# to add and choose main ID for rows header\n",
    "# to do DOI checks and regex\n",
    "# to get PMC full text from DOI and store in local folder\n",
    "\n",
    "row_names = df['uuid']\n",
    "#print(row_names)\n",
    "\n",
    "# Set row names as shortid whichh corresponds to DOME Registry unique short id \n",
    "df = pd.DataFrame(df).set_index('shortid')\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['matches_model/availability', 'matches_model/duration', 'matches_model/interpretability', 'matches_model/output']\n",
      "                                 _id                   created  public  \\\n",
      "shortid                                                                  \n",
      "6i0xepuivt  63516fedb9c880af1f305b5c  2022-09-01T15:16:05.444Z    True   \n",
      "nlj5x3dld8  63516fedb9c880af1f305b93  2022-09-01T15:16:05.445Z    True   \n",
      "ysqyy92zyr  66030aaa1502715bfe53d65c  2024-03-26T17:49:30.048Z    True   \n",
      "qx3ex71jye  66041e5d1502715bfe53d70a  2024-03-27T13:25:49.790Z    True   \n",
      "v536tc3b5t  63516fedb9c880af1f305b1c  2022-09-01T15:16:05.443Z    True   \n",
      "\n",
      "                                          publication_authors  \\\n",
      "shortid                                                         \n",
      "6i0xepuivt               Wang H, Zheng H, Simpson D, Azuaje F   \n",
      "nlj5x3dld8               Al-Shahib A, Breitling R, Gilbert DR   \n",
      "ysqyy92zyr  Hui Lan, Rachel Carson , Nicholas J Provart an...   \n",
      "qx3ex71jye  Blaise Gassend, Charles W O'Donnell, William T...   \n",
      "v536tc3b5t                  Tsai RT, Dai HJ, Huang CH, Hsu WL   \n",
      "\n",
      "            publication_created              publication_doi  \\\n",
      "shortid                                                        \n",
      "6i0xepuivt                  NaN      10.1186/1471-2105-7-116   \n",
      "nlj5x3dld8                  NaN       10.1186/1471-2164-8-78   \n",
      "ysqyy92zyr                  NaN      10.1186/1471-2105-8-358   \n",
      "qx3ex71jye                  NaN    10.1186/1471-2105-8-S5-S3   \n",
      "v536tc3b5t                  NaN  10.1186/1471-2105-9-S12-S18   \n",
      "\n",
      "            publication_done publication_journal publication_pmid  \\\n",
      "shortid                                                             \n",
      "6i0xepuivt               0.0  BMC Bioinformatics         16524483   \n",
      "nlj5x3dld8               0.0        BMC Genomics         17374164   \n",
      "ysqyy92zyr               NaN  BMC Bioinformatics         17888165   \n",
      "qx3ex71jye               NaN  BMC Bioinformatics         17570862   \n",
      "v536tc3b5t               0.0  BMC Bioinformatics         19091017   \n",
      "\n",
      "            publication_skip  ...  \\\n",
      "shortid                       ...   \n",
      "6i0xepuivt               0.0  ...   \n",
      "nlj5x3dld8               0.0  ...   \n",
      "ysqyy92zyr               NaN  ...   \n",
      "qx3ex71jye               NaN  ...   \n",
      "v536tc3b5t               0.0  ...   \n",
      "\n",
      "                          matches_optimization/regularization  \\\n",
      "shortid                                                         \n",
      "6i0xepuivt                                                NaN   \n",
      "nlj5x3dld8                                                NaN   \n",
      "ysqyy92zyr                                        Not adopted   \n",
      "qx3ex71jye  No regularization applied. Validation set not ...   \n",
      "v536tc3b5t  Yes.   L2 regularization on weights of the neu...   \n",
      "\n",
      "                                   matches_model/availability  \\\n",
      "shortid                                                         \n",
      "6i0xepuivt                                                NaN   \n",
      "nlj5x3dld8                                                NaN   \n",
      "ysqyy92zyr                                                NaN   \n",
      "qx3ex71jye                                                NaN   \n",
      "v536tc3b5t  The code to reproduce the results can be downl...   \n",
      "\n",
      "                                       matches_model/duration  \\\n",
      "shortid                                                         \n",
      "6i0xepuivt                                                NaN   \n",
      "nlj5x3dld8                                                NaN   \n",
      "ysqyy92zyr                                         not stated   \n",
      "qx3ex71jye                                                NaN   \n",
      "v536tc3b5t  Training time is expressed as milliseconds per...   \n",
      "\n",
      "                               matches_model/interpretability  \\\n",
      "shortid                                                         \n",
      "6i0xepuivt                                          Black box   \n",
      "nlj5x3dld8                                          Black box   \n",
      "ysqyy92zyr  Model is partially interpretable, since classi...   \n",
      "qx3ex71jye  Model is interpreatable, since paramenters lea...   \n",
      "v536tc3b5t  Transparent : The attribution recall score for...   \n",
      "\n",
      "                                         matches_model/output  \\\n",
      "shortid                                                         \n",
      "6i0xepuivt                                                NaN   \n",
      "nlj5x3dld8      Classification prediction of residue contact.   \n",
      "ysqyy92zyr                                                NaN   \n",
      "qx3ex71jye                              binary classification   \n",
      "v536tc3b5t  Regression is the output by neural networks, i...   \n",
      "\n",
      "                            matches_evaluation/availability  \\\n",
      "shortid                                                       \n",
      "6i0xepuivt                                              NaN   \n",
      "nlj5x3dld8                                              NaN   \n",
      "ysqyy92zyr                                              NaN   \n",
      "qx3ex71jye                                    Not available   \n",
      "v536tc3b5t  Yes. (https://github.com/ggonzalezp/hyperfoods)   \n",
      "\n",
      "                                matches_evaluation/comparison  \\\n",
      "shortid                                                         \n",
      "6i0xepuivt                                                NaN   \n",
      "nlj5x3dld8  Performance achieved with methods based on aut...   \n",
      "ysqyy92zyr       no comparison with other approaches perfomed   \n",
      "qx3ex71jye  Cmparison with other approaches is missing. No...   \n",
      "v536tc3b5t  A baseline input is used, in which all drug ta...   \n",
      "\n",
      "                                matches_evaluation/confidence  \\\n",
      "shortid                                                         \n",
      "6i0xepuivt                                                NaN   \n",
      "nlj5x3dld8                                                NaN   \n",
      "ysqyy92zyr  no confidence interval reported. No statistica...   \n",
      "qx3ex71jye                                       Not reported   \n",
      "v536tc3b5t  Confidence intervals and statistical significa...   \n",
      "\n",
      "                                   matches_evaluation/measure  \\\n",
      "shortid                                                         \n",
      "6i0xepuivt                                                NaN   \n",
      "nlj5x3dld8  Precision as a function of effective aligned s...   \n",
      "ysqyy92zyr                                          ROC curve   \n",
      "qx3ex71jye  accuracy and segment-overlap value for alpha h...   \n",
      "v536tc3b5t  Balanced accuracy, F1 score, AUPR. The last tw...   \n",
      "\n",
      "                                    matches_evaluation/method  \n",
      "shortid                                                        \n",
      "6i0xepuivt                         five-fold cross-validation  \n",
      "nlj5x3dld8                    Independent dataset form CASP11  \n",
      "ysqyy92zyr                                   cross validation  \n",
      "qx3ex71jye                  Repeated random traing/test split  \n",
      "v536tc3b5t  Cross-validation. The model was also tested on...  \n",
      "\n",
      "[5 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "#3.2 reorder data frame\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to your CSV file\n",
    "# csv_file_name = 'path_to_your_csv_file.csv'  # Replace with your actual file name\n",
    "\n",
    "# Read in DOME Entries CSV as dataframe via pandas library functions\n",
    "# df = pd.read_csv(csv_file_name)\n",
    "\n",
    "# Define the prefixes to match and group csv data\n",
    "prefix_publications_cols = 'matches_publication'\n",
    "prefix_data_cols = 'matches_data'\n",
    "prefix_optimization_cols = 'matches_optimization'\n",
    "prefix_model_cols = 'matches_model'\n",
    "prefix_evaluation_cols = 'matches_evaluation'\n",
    "\n",
    "# Separate columns based on whether they start with the prefix\n",
    "matches_publication_columns = [col for col in df.columns if col.startswith(prefix_publications_cols)]\n",
    "print(matches_model_columns)\n",
    "matches_data_columns = [col for col in df.columns if col.startswith(prefix_data_cols)]\n",
    "matches_optimization_columns = [col for col in df.columns if col.startswith(prefix_optimization_cols)]\n",
    "matches_model_columns = [col for col in df.columns if col.startswith(prefix_model_cols)]\n",
    "matches_evaluation_columns = [col for col in df.columns if col.startswith(prefix_evaluation_cols)]\n",
    "other_columns = [col for col in df.columns if not col.startswith('matches_')]\n",
    "\n",
    "# Reorder columns\n",
    "reordered_columns = (other_columns + matches_publication_columns + matches_data_columns +\n",
    "                     matches_optimization_columns + matches_model_columns + matches_evaluation_columns)\n",
    "df = df[reordered_columns]\n",
    "\n",
    "# Print the reordered DataFrame\n",
    "print(df.head())\n",
    "\n",
    "df.to_csv(csv_file_name, sep=',', index=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      66a94333-8cd1-499c-86ef-0497a4c4dabc\n",
       "1      147ddf2b-6b53-4335-b62f-87994d284310\n",
       "2      600b20de-7c70-41af-ad39-33121af090ef\n",
       "3      b863eb51-d9ae-4fc0-bfd4-006db90d1631\n",
       "4      28fe7de1-ac05-4cf2-bfa8-d5ddd1ba32b8\n",
       "                       ...                 \n",
       "209    49b4a023-592f-4a04-bad2-827e519896e0\n",
       "210    bf403e75-6baf-4278-bf96-1469c78c65e0\n",
       "211    440c11f3-f064-40d7-9b1d-5d29591896b4\n",
       "212    19954d39-0d13-4f99-9e5d-0624ccd5b638\n",
       "213    d77983e0-5279-4379-b608-8032a2990b09\n",
       "Name: uuid, Length: 214, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['uuid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PMID mapper from NCBI https://pmc.ncbi.nlm.nih.gov/tools/id-converter-api/\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped identifiers saved to 'Mapped_Identifiers/mapped_identifiers.csv'\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Define the path to the \"Valid DOME Registry\" CSV file\n",
    "valid_csv_file_name = 'valid_DOME_Registry_Contents.csv'  # Replace with your actual file name\n",
    "\n",
    "# Define the output folder for the mapped identifiers\n",
    "output_folder = 'Mapped_Identifiers'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Function to read CSV data\n",
    "def read_csv(file_name):\n",
    "    try:\n",
    "        with open(file_name, 'r', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            data = [row for row in reader]\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the CSV file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to map PMIDs to PMCIDs using NCBI E-utilities API\n",
    "def map_pmids_to_pmcids(pmids):\n",
    "    pmid_str = ','.join(pmids)\n",
    "    url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&db=pmc&id={pmid_str}&retmode=json\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Function to save mapped identifiers to a CSV file\n",
    "def save_mapped_identifiers(mapped_data, output_file_name):\n",
    "    with open(output_file_name, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['PMID', 'PMCID'])\n",
    "        for linkset in mapped_data['linksets']:\n",
    "            pmid = linkset['ids'][0]\n",
    "            if 'linksetdbs' in linkset:\n",
    "                for linksetdb in linkset['linksetdbs']:\n",
    "                    if linksetdb['dbto'] == 'pmc':\n",
    "                        for link in linksetdb['links']:\n",
    "                            writer.writerow([pmid, link])\n",
    "            else:\n",
    "                writer.writerow([pmid, ''])\n",
    "\n",
    "# Read CSV data\n",
    "csv_data = read_csv(valid_csv_file_name)\n",
    "\n",
    "# Extract PMIDs from the CSV data\n",
    "pmids = [row.get('publication_pmid', '') for row in csv_data if row.get('publication_pmid', '')]\n",
    "\n",
    "# Map PMIDs to PMCIDs\n",
    "mapped_data = map_pmids_to_pmcids(pmids)\n",
    "\n",
    "# Save the mapped identifiers to a CSV file\n",
    "if mapped_data:\n",
    "    output_file_name = os.path.join(output_folder, 'mapped_identifiers.csv')\n",
    "    save_mapped_identifiers(mapped_data, output_file_name)\n",
    "    print(f\"Mapped identifiers saved to '{output_file_name}'\")\n",
    "else:\n",
    "    print(\"No data to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'PMID': '16524483'}, {'PMID': '17374164'}, {'PMID': '17888165'}, {'PMID': '17570862'}]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#for pmid in pmids:\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#    print(pmid)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mtype\u001b[39m(pmid)\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mprint\u001b[39m(pmid[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m4\u001b[39m]))\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# EPMC get files XML\n",
    "\n",
    "#get list of PMIDs\n",
    "pmid = read_csv('pmids.csv')\n",
    "#for pmid in pmids:\n",
    "#    print(pmid)\n",
    "\n",
    "type(pmid)\n",
    "\n",
    "pmid[0:4]\n",
    "\n",
    "# Define the URL for the EPMC API call\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML data for PMID PMC1421439 saved to 'PMC_XML_Files/PMC1421439.xml'\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "import os\n",
    "\n",
    "# Define your email (required by NCBI)\n",
    "Entrez.email = \"gavinmichael.farrell@studenti.unipd.it\"  # Replace with your actual email\n",
    "\n",
    "# Define the PMID you want to query\n",
    "pmid = 'PMC1421439'  # Replace with your actual PMID\n",
    "\n",
    "# Define the output folder for XML files\n",
    "output_folder = 'PMC_XML_Files'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Fetch the article from PMC\n",
    "handle = Entrez.efetch(db=\"pmc\", id=pmid, rettype=\"full\", retmode=\"xml\")\n",
    "xml_data = handle.read()\n",
    "handle.close()\n",
    "\n",
    "# Save the XML data to a file\n",
    "output_file = os.path.join(output_folder, f\"{pmid}.xml\")\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "    file.write(str(xml_data))\n",
    "\n",
    "print(f\"XML data for PMID {pmid} saved to '{output_file}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
