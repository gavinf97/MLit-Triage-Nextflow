<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd"> 
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-journalpublishing1.dtd?><?SourceDTD.Version 1.2?><?ConverterInfo.XSLTName jats2jats3.xsl?><?ConverterInfo.Version 1?><?subarticle d1e2104?><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">GigaByte</journal-id><journal-id journal-id-type="iso-abbrev">GigaByte</journal-id><journal-id journal-id-type="publisher-id">Gigabyte</journal-id><journal-title-group><journal-title>GigaByte</journal-title></journal-title-group><issn pub-type="epub">2709-4715</issn><publisher><publisher-name>GigaScience Press</publisher-name><publisher-loc>Sha Tin, New Territories, Hong Kong SAR</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmcid">10940896</article-id><article-id pub-id-type="publisher-manuscript">TRR-202311-01</article-id><article-id pub-id-type="publisher-id">113</article-id><article-id pub-id-type="doi">10.46471/gigabyte.113</article-id><article-id pub-id-type="arxiv" specific-use="preprint">https://doi.org/10.48550/arXiv.2310.12568</article-id><article-categories><subj-group subj-group-type="heading"><subject>Technical Release</subject></subj-group><subj-group subj-group-type="classification"><subject>Software and Workflows</subject><subject>Neuroscience</subject><subject>Machine Learning</subject></subj-group></article-categories><title-group><article-title>Julearn: an easy-to-use library for leakage-free evaluation and inspection of ML models</article-title><alt-title alt-title-type="left-running-head">S. Hamdan <italic toggle="yes">et&#x000a0;al.</italic>
</alt-title><alt-title alt-title-type="right-running-head">Julearn: an easy-to-use library for leakage-free evaluation and inspection of ML models</alt-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-5072-542X</contrib-id><name><surname>Hamdan</surname><given-names>Sami</given-names></name><xref rid="aff000a" ref-type="aff">
<sup>1</sup>
</xref><xref rid="aff000b" ref-type="aff">
<sup>2</sup>
</xref><role vocab="Casrai/NISO CRediT" vocab-identifier="http://credit.niso.org/contributor-roles/software/" vocab-term="Software">Software</role><role vocab="Casrai/NISO CRediT" vocab-identifier="http://credit.niso.org/contributor-roles/conceptualization/" vocab-term="Conceptualization">Conceptualization</role><role vocab="Casrai/NISO CRediT" vocab-identifier="http://credit.niso.org/contributor-roles/writing-original-draft/" vocab-term="Writing - original draft">Writing - original draft</role></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-1272-217X</contrib-id><name><surname>More</surname><given-names>Shammi</given-names></name><xref rid="aff000a" ref-type="aff">
<sup>1</sup>
</xref><xref rid="aff000b" ref-type="aff">
<sup>2</sup>
</xref><role vocab="Casrai/NISO CRediT" vocab-identifier="http://credit.niso.org/contributor-roles/software/" vocab-term="Software" degree-contribution="supporting">Software</role><role vocab="Casrai/NISO CRediT" vocab-identifier="http://credit.niso.org/contributor-roles/writing-original-draft/" vocab-term="Writing - original draft">Writing - original draft</role></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-2400-3404</contrib-id><name><surname>Sasse</surname><given-names>Leonard</given-names></name><xref rid="aff000a" ref-type="aff">
<sup>1</sup>
</xref><xref rid="aff000b" ref-type="aff">
<sup>2</sup>
</xref><xref rid="aff000c" ref-type="aff">
<sup>3</sup>
</xref><role vocab="Casrai/NISO CRediT" vocab-identifier="http://credit.niso.org/contributor-roles/software/" vocab-term="Software">Software</role><role vocab="Casrai/NISO CRediT" vocab-identifier="http://credit.niso.org/contributor-roles/writing-original-draft/" vocab-term="Writing - original draft">Writing - original draft</role></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-9486-0922</contrib-id><name><surname>Komeyer</surname><given-names>Vera</given-names></name><xref rid="aff000a" ref-type="aff">
<sup>1</sup>
</xref><xref rid="aff000b" ref-type="aff">
<sup>2</sup>
</xref><role vocab="Casrai/NISO CRediT" vocab-identifier="http://credit.niso.org/contributor-roles/software/" vocab-term="Software">Software</role><role vocab="Casrai/NISO CRediT" vocab-identifier="http://credit.niso.org/contributor-roles/writing-original-draft/" vocab-term="Writing - original draft">Writing - original draft</role></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-0289-5480</contrib-id><name><surname>Patil</surname><given-names>Kaustubh R.</given-names></name><xref rid="aff000a" ref-type="aff">
<sup>1</sup>
</xref><xref rid="aff000b" ref-type="aff">
<sup>2</sup>
</xref><role vocab="Casrai/NISO CRediT" vocab-identifier="http://credit.niso.org/contributor-roles/writing-original-draft/" vocab-term="Writing - original draft">Writing - original draft</role><role vocab="Casrai/NISO CRediT" vocab-identifier="http://credit.niso.org/contributor-roles/supervision/" vocab-term="Supervision" degree-contribution="supporting">Supervision</role></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-4087-8259</contrib-id><name><surname>Raimondo</surname><given-names>Federico</given-names></name><xref rid="aff000a" ref-type="aff">
<sup>1</sup>
</xref><xref rid="aff000b" ref-type="aff">
<sup>2</sup>
</xref><role vocab="Casrai/NISO CRediT" vocab-identifier="http://credit.niso.org/contributor-roles/supervision/" vocab-term="Supervision" degree-contribution="lead">Supervision</role><role vocab="Casrai/NISO CRediT" vocab-identifier="http://credit.niso.org/contributor-roles/software/" vocab-term="Software">Software</role><role vocab="Casrai/NISO CRediT" vocab-identifier="http://credit.niso.org/contributor-roles/writing-original-draft/" vocab-term="Writing - original draft">Writing - original draft</role><xref rid="cor1" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><collab>for the Alzheimer&#x02019;s Disease Neuroimaging Initiative</collab><xref rid="fn0001" ref-type="author-notes">
<sup>&#x02020;</sup>
</xref></contrib><aff id="aff000a">
<label><sup>1</sup></label>
<addr-line content-type="department">Institute of Neuroscience and Medicine (INM-7: Brain and Behaviour)</addr-line>, <institution>Research Centre J&#x000fc;lich</institution>, <country>Germany</country>
</aff><aff id="aff000b">
<label><sup>2</sup></label>
<addr-line content-type="department">Institute of Systems Neuroscience</addr-line>, <institution>Heinrich Heine University D&#x000fc;sseldorf</institution>, <country>Germany</country>
</aff><aff id="aff000c">
<label><sup>3</sup></label>
<institution>Max Planck School of Cognition</institution>, <addr-line>Stephanstrasse 1a</addr-line>, <addr-line content-type="city">Leipzig</addr-line>, <country>Germany</country>
</aff></contrib-group><author-notes><corresp id="cor1">
<label><sup>*</sup></label> Corresponding author. E-mail: <email xlink:href="f.raimondo@fz-juelich.de">f.raimondo@fz-juelich.de</email>
</corresp><fn id="fn0001"><label>
<sup>&#x02020;</sup>
</label><p>Data used in preparation of this article were obtained from the Alzheimer&#x02019;s Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at: <ext-link xlink:href="http://adni.loni.usc.edu/wp-content/uploads/how_to_apply/ADNI_Acknowledgement_List.pdf" ext-link-type="uri" specific-use="url">http://adni.loni.usc.edu/wp-content/uploads/how_to_apply/ADNI_Acknowledgement_List.pdf</ext-link></p></fn></author-notes><pub-date pub-type="epub"><day>07</day><month>3</month><year>2024</year></pub-date><pub-date pub-type="collection"><year>2024</year></pub-date><volume>2024</volume><elocation-id>gigabyte113</elocation-id><history><date date-type="received"><day>13</day><month>11</month><year>2023</year></date><date date-type="accepted"><day>27</day><month>2</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9;&#x000a0;The Author(s) 2024.</copyright-statement><copyright-year>2024</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" specific-use="url" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><abstract><p>The fast-paced development of machine learning (ML) and its increasing adoption in research challenge researchers without extensive training in ML. In neuroscience, ML can help understand brain-behavior relationships, diagnose diseases and develop biomarkers using data from sources like magnetic resonance imaging and electroencephalography. Primarily, ML builds models to make accurate predictions on unseen data. Researchers evaluate models' performance and generalizability using techniques such as cross-validation (CV). However, choosing a CV scheme and evaluating an ML pipeline is challenging and, if done improperly, can lead to overestimated results and incorrect interpretations. Here, we created julearn, an open-source Python library allowing researchers to design and evaluate complex ML pipelines without encountering common pitfalls. We present the rationale behind julearn&#x02019;s design, its core features, and showcase three examples of previously-published research projects. Julearn simplifies the access to ML providing an easy-to-use environment. With its design, unique features, simple interface, and practical documentation, it poses as a useful Python-based library for research projects.</p></abstract><funding-group><award-group><funding-source>
<institution-wrap><institution>Helmholtz-AI project DeGen</institution></institution-wrap>
</funding-source><award-id>ZT-I-PF-5-078</award-id></award-group><award-group><funding-source>
<institution-wrap><institution>Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)</institution></institution-wrap>
</funding-source><award-id>3634/1-1</award-id></award-group><award-group><funding-source>
<institution-wrap><institution>Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)</institution></institution-wrap>
</funding-source><award-id>431549029&#x02013;SFB 1451</award-id></award-group><award-group><funding-source>
<institution-wrap><institution>Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)</institution></institution-wrap>
</funding-source><award-id>B05</award-id></award-group><award-group><funding-source>
<institution-wrap><institution>Helmholtz Imaging Platform and eBRAIN Health</institution></institution-wrap>
</funding-source><award-id>HORIZON-INFRA-2021-TECH-01</award-id></award-group><award-group><funding-source>
<institution-wrap><institution>Alzheimer&#x02019;s Disease Neuroimaging Initiative (ADNI)</institution></institution-wrap>
</funding-source><award-id>U01 AG024904</award-id></award-group><award-group><funding-source>
<institution-wrap><institution>DOD ADNI</institution></institution-wrap>
</funding-source><award-id>W81XWH-12-2-0012</award-id></award-group><award-group><funding-source>
<institution-wrap><institution>National Institute on Aging, the National Institute of Biomedical Imaging and Bioengineering</institution></institution-wrap>
</funding-source></award-group><award-group><funding-source>
<institution-wrap><institution>The Canadian Institutes of Health Research</institution></institution-wrap>
</funding-source></award-group><award-group><funding-source>
<institution-wrap><institution>Foundation for the National Institutes of Health</institution></institution-wrap>
</funding-source></award-group><award-group><funding-source>
<institution-wrap><institution>Northern California Institute for Research and Education</institution></institution-wrap>
</funding-source></award-group><award-group><funding-source>
<institution-wrap><institution>Alzheimers Therapeutic Research Institute at the University of Southern California</institution></institution-wrap>
</funding-source></award-group><award-group><funding-source>
<institution-wrap><institution>Laboratory for Neuro Imaging at the University of Southern California</institution></institution-wrap>
</funding-source></award-group><funding-statement>This work was partly supported by the Helmholtz-AI project DeGen (ZT-I-PF-5-078), the Helmholtz Portfolio Theme &#x0201c;Supercomputing and Modeling for the Human Brain&#x0201d; the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation), project PA 3634/1-1 and project-ID 431549029&#x02013;SFB 1451 project B05, the Helmholtz Imaging Platform and eBRAIN Health (HORIZON-INFRA-2021-TECH-01). Data collection and sharing for this project was funded by the Alzheimer&#x02019;s Disease Neuroimaging Initiative (ADNI) (National Institutes of Health Grant U01 AG024904) and DOD ADNI (Department of Defense award number W81XWH-12-2-0012). ADNI is funded by the National Institute on Aging, the National Institute of Biomedical Imaging and Bioengineering, and through generous contributions from the following: AbbVie, Alzheimer&#x02019;s Association; Alzheimer&#x02019;s Drug Discovery Foundation; Araclon Biotech; BioClinica, Inc.; Biogen; Bristol-Myers Squibb Company; CereSpir, Inc.; Cogstate; Eisai Inc.; Elan Pharmaceuticals, Inc.; Eli Lilly and Company; EuroImmun; F. Hoffmann-La Roche Ltd and its affiliated company Genentech, Inc.; Fujirebio; GE Healthcare; IXICO Ltd; Janssen Alzheimer Immunotherapy Research &#x00026; Development, LLC; Johnson &#x00026; Johnson Pharmaceutical Research &#x00026; Development LLC; Lumosity; Lundbeck; Merck &#x00026; Co., Inc.; Meso Scale Diagnostics, LLC; NeuroRx Research; Neurotrack Technologies; Novartis Pharmaceuticals Corporation; Pfizer Inc.; Piramal Imaging; Servier; Takeda Pharmaceutical Company; and Transition Therapeutics. The Canadian Institutes of Health Research is providing funds to support ADNI clinical sites in Canada. Private sector contributions are facilitated by the Foundation for the National Institutes of Health (www.fnih.org). The grantee organization is the Northern California Institute for Research and Education, and the study is coordinated by the Alzheimer&#x02019;s Therapeutic Research Institute at the University of Southern California. ADNI data are disseminated by the Laboratory for Neuro Imaging at the University of Southern California.</funding-statement></funding-group></article-meta></front><body><sec id="s0001"><title>Introduction</title><p>Machine Learning (ML) is fast becoming an indispensable tool in many research fields. It is rapidly gaining increasing importance within neuroscience, where it is used for understanding brain-behavior relationships&#x000a0;<styled-content style-type="bibr-wrapper">[<xref rid="ref1" ref-type="bibr">1</xref>]</styled-content>, predicting disease status and biomarker development using diverse data modalities such as Magnetic Resonance Imaging (MRI) and electroencephalogram. Such ML applications are driven by the availability of big data and technological advances. However, for domain experts, acquiring relevant ML and programming skills remains a significant challenge. This underscores the need for user-friendly software solutions accessible to domain experts without extensive ML training. Such solutions would enable them to quickly evaluate ML approaches.</p><p>An ML application aims to create a model that provides accurate predictions on new unseen data&#x02014;i.e., a generalizable model. In this context, the goal of a research project is usually to demonstrate that a generalizable model exists for the prediction task at hand. As a single set of samples is usually available, this goal is achieved by assessing the generalization performance by training the model on a subset of the data and testing it on the hold-out test data. If the model performs well on the test data, then the researcher concludes that the prediction task can be solved in a generalizable manner. One of the most prominent approaches to estimating the generalization performance is cross-validation (CV). CV is a systematic subsampling approach, which trains and tests ML pipelines multiple times using independent data splits <styled-content style-type="bibr-wrapper">[<xref rid="ref2" ref-type="bibr">2</xref>]</styled-content>. The average performance over the splits is taken as an estimate of generalization. To achieve good performance or other aims, like data interpretation, it is often necessary to perform additional data processing, for example, feature selection. This results in an ML pipeline that performs all the needed operations from data manipulations, training and evaluation. Choosing a CV scheme and evaluating an ML pipeline can be challenging, and if improperly used, it can lead to incorrect results and misguided insights. This underscores the need for user-friendly software solutions accessible to domain experts without in-depth ML and programming training. Problematically, a common outcome of pitfalls is an overestimation of the generalization performance when using CV, i.e., models are reported as being more accurate than what they actually are. Here, we highlight two common pitfalls: data leakage and overfitting of hyperparameters.</p><p>Data leakage occurs when the separation between the training and test data is not strictly followed. For instance, using all available data in parts of an ML pipeline breaks the required separation between training and test data. Such data leakage invalidates the complete CV procedure, as information on the testing set is available during training. For example, one might apply a preprocessing step, like <italic toggle="yes">z</italic>-standardization or Principal Component Analysis (PCA), on the complete dataset before splitting the data. As the preprocessing step is informed about the test data, the later created and transformed training data will reflect the test data. Therefore, the learning algorithm can leverage this leaked test set information through preprocessing and memorization instead of building a predictive model, thus inflating the generalization estimation of CV. Most problematically, data leakage can happen in many ways through programming errors or lack of awareness of this danger.</p><p>A similar pitfall can occur when tuning hyperparameters by first observing their test set performance. Hyperparameters are parameters not learnable by the algorithms, which greatly impact their prediction performance. To tackle this optimization problem, many practitioners repeat a simple CV to evaluate the test set performance of different hyperparameter combinations. Problematically, both tuning and estimating out-of-sample performance on the same test data breaks the clear distinction between training and testing, as one both optimizes and evaluates the ML pipeline on the same test set. Notably, this can happen very quickly over the natural progression of research projects while iterating through ideas of appropriate hyperparameters. The solution to this pitfall is to select the hyperparameters and evaluate the out-of-sample performance in different data splits, which can be achieved by using a nested CV. In conclusion, both pitfalls can happen easily and without malicious intent through a lack of ML or programming experience. We developed the open-source Python package julearn to allow field experts to circumvent these pitfalls by default while training and evaluating ML pipelines.</p><p>While ML experts can navigate these and other pitfalls using expert software, such as scikit-learn (RRID:<named-content content-type="rrid">SCR_002577</named-content>), domain experts might not always be aware of the pitfalls or how to handle them. This is why we created julearn, to provide an out-of-the-box solution, preventing common mistakes, usable by domain experts. Julearn was created to be easy to use, accessible for researchers with diverse backgrounds, and to create reproducible results. Furthermore, we engineered julearn so it is easy to extend and maintain, in order to keep up with constantly evolving fields such as neuroscience and medicine. The accessibility and usability aspects of julearn were decided to be at the core, as we aimed to help researchers apply ML. We accomplished this through a careful design of the Application Programming Interface (API), comprising only a few simple key functions and classes to create and evaluate complex ML pipelines. Furthermore, we added several utilities that allow investigators to gain a detailed understanding of the resulting pipelines. In order to keep julearn up to date, we built it on top of scikit-learn <styled-content style-type="bibr-wrapper">[<xref rid="ref3" ref-type="bibr">3</xref>, <xref rid="ref4" ref-type="bibr">4</xref>]</styled-content> and followed common best practices of software engineering, like unit testing and continuous integration.</p></sec><sec id="s0002"><title>Methods</title><sec id="s0003"><title>Basic usage</title><p>Julearn is built on top of scikit-learn&#x000a0;<styled-content style-type="bibr-wrapper">[<xref rid="ref3" ref-type="bibr">3</xref>, <xref rid="ref4" ref-type="bibr">4</xref>]</styled-content>, one of the most influential ML libraries in the Python programming language. While scikit-learn provides a powerful interface for programmers to create complex and individualized ML pipelines, julearn mainly adds an abstraction layer, providing a simple interface for novice programmers. That is, a user-friendly and easy-to-program API, tailored for users with basic programming skills or limited knowledge of ML who wish to start with ML or evaluate complex ML pipelines in an error-free way. Note that while scikit-learn is a general ML Library, julearn focuses on so-called supervised ML tasks, which include any prediction task with known labels while training and evaluating pipelines. Therefore, pipelines in the context of julearn always refer to supervised ML pipelines. Importantly, rather than posing itself as a replacement or competitor, julearn aims to enhance scikit-learn&#x02019;s features while providing access to scikit-learn&#x02019;s functionality for supervised ML. Consequently, it is also possible to use a custom scikit-learn compatible model.</p><p>To achieve a simple interface for supervised ML problems, we implemented a core function called <monospace specific-use="monospace">run_cross_validation</monospace> to estimate a model's performance using CV. In this function, the user specifies the data, features, target, preprocessing and model name to evaluate as an ML pipeline in a leakage-free, cross-validated manner. We chose the popular and simple tabular data structure of Pandas&#x02019; <monospace specific-use="monospace">DataFrame</monospace>&#x000a0;<styled-content style-type="bibr-wrapper">[<xref rid="ref5" ref-type="bibr">5</xref>]</styled-content> for both the input data and the output of <monospace specific-use="monospace">run_cross_validation</monospace>. This makes preparing the input, as well as inspecting and analyzing the output of julearn, simple and transparent.</p><p>Furthermore, our API provides arguments for feature and target name(s) referring to the columns of the input data frame. To use any of julearn&#x02019;s ML algorithms, one only needs to provide their name to the <monospace specific-use="monospace">model</monospace> argument of <monospace specific-use="monospace">run_cross_validation</monospace>. Here, julearn will select the model according to the provided <monospace specific-use="monospace">problem_type</monospace> of either classification or regression. Similarly, one can provide any of the supported preprocessing steps to <monospace specific-use="monospace">run_cross_validation</monospace> by name. These steps are executed in a CV-consistent way without the risk of data leakage. Such an interface simplifies the construction and use of ML pipelines, in contrast to scikit-learn, where one must import different ML models depending on the problem type, create a pipeline using both the imported preprocessing steps and the ML model and finally use the <monospace specific-use="monospace">cross_validate</monospace> function (Figure&#x000a0;<xref rid="gigabyte-2024-113-g001" ref-type="fig">1</xref>).</p><fig position="float" id="gigabyte-2024-113-g001"><label>Figure 1.</label><caption><p>Implementation of a simple CV pipeline using julearn (A) in contrast to scikit-learn (B). The julearn pipeline needs only one import, while scikit-learn needs multiple ones. Furthermore, scikit-learn needs to import the Support Vector Machine differently depending on the problem type, while julearn chooses the correct one based on the problem type. The differences between julearn and scikit-learn are most influential for inexperienced programmers who aim to create (complex) supervised ML pipelines. Julearn builds upon scikit-learn by providing a simple interface that does not need any awareness of how to compose and find different classes.</p></caption><graphic xlink:href="gigabyte-2024-113-g001" position="float"/></fig><p>While julearn does not aim to replace scikit-learn, it tries to simplify specific use cases, including the creation of more complex supervised ML pipelines that need hyperparameter tuning or preprocessing a subsample of features. This means that julearn can automatically use nested CV for proper performance assessment in the context of hyperparameter tuning <styled-content style-type="bibr-wrapper">[<xref rid="ref6" ref-type="bibr">6</xref>]</styled-content> and apply preprocessing based on different feature types. These feature types include distinctions like categorical vs continuous features or grouping variables, which can even be used to do confound removal on a subsample of the data.</p></sec><sec id="s0004"><title>Model comparison</title><p>In ML applications, there is no standard or consensus of what a good or acceptable performance is, as this usually depends on the task and domain. Thus, the process of developing predictive models involves comparing models, either to null or dummy models, or to previously published models (i.e., benchmarking). Given that CV produces estimates of the model&#x02019;s performance and that, depending on the CV strategy, these estimates might not be independent from each other, special methods are required to test and conclude if the performance of two models is different or not. For this reason, julearn <monospace specific-use="monospace">run_cross_validation</monospace> output has additional information that can be used to make more accurate model comparisons. Furthermore, it provides a stats module, which implements a student&#x02019;s <italic toggle="yes">t</italic>-test corrected for using the same CV approach to compare multiple ML pipelines&#x000a0;<styled-content style-type="bibr-wrapper">[<xref rid="ref7" ref-type="bibr">7</xref>]</styled-content>. This correction is necessary as CV leads to a dependency between the folds, i.e., each iteration&#x02019;s training set overlaps with the other ones. To gain a detailed view of the models&#x02019; benchmark, one can also use julearn&#x02019;s inbuilt visualization tool (see Figure <xref rid="gigabyte-2024-113-g002" ref-type="fig">2</xref> for example).</p><fig position="float" id="gigabyte-2024-113-g002"><label>Figure 2.</label><caption><p>Screenshot of the julearn scores viewer, depicting the negative mean absolute error in age prediction from gray matter volume. Each dot represents the negative mean absolute error of each CV fold (5 times, 5-folds). Each column represents a different model: Gaussian Process Regression (GPR) (gauss), Relevance Vector Regression (RVR) (rvr) and Support Vector Regression (SVR) (svm). Black lines indicate the mean and 95% confidence intervals. The table at the bottom shows the pairwise statistics using the corrected <italic toggle="yes">t</italic>-test.</p></caption><graphic xlink:href="gigabyte-2024-113-g002" position="float"/></fig></sec><sec id="s0005"><title>Feature types</title><p>One key functionality that julearn provides, which is currently lacking in ML libraries such as scikit-learn, is the ability to define feature types. This allows researchers to define sets of variables and do selective processing, needed when dealing with categorical or confounding variables. For this matter, julearn introduces the <monospace specific-use="monospace">PipelineCreator</monospace> to create complex pipelines in which certain processing steps can be applied to one or more subsets of features. Once the pipeline is defined, users need to provide a dictionary of any user-defined type and the associated column names in their data as the <monospace specific-use="monospace">X_types</monospace> argument. Such functionality allows to implement complex pipelines that transform features based on their <italic toggle="yes">type</italic>, e.g., standardizing only continuous features and then deconfounding both continuous and categorical features.</p></sec><sec id="s0006"><title>Hyperparameter tuning</title><p>As mentioned previously, hyperparameter tuning should be performed in a nested CV to not overfit the predictions of a given pipeline. The <monospace specific-use="monospace">PipelineCreator</monospace> can be used to specify sets of hyperparameters to be tested at each individual step by just using the <monospace specific-use="monospace">add</monospace> method (Figure&#x000a0;<xref rid="gigabyte-2024-113-g003" ref-type="fig">3</xref>). Being able to first define a pipeline and its hyperparameters with the <monospace specific-use="monospace">PipelineCreator</monospace>, and to then train and evaluate this pipeline with <monospace specific-use="monospace">run_cross_validation</monospace>, makes performing leakage-free nested CV easy. In this nested CV, all hyperparameters are optimized in an inner CV using a grid search by default. This default, like most of julearn&#x02019;s defaults, can be easily adjusted by providing any compatible searcher in the <monospace specific-use="monospace">run_cross_validation</monospace>&#x02019;s <monospace specific-use="monospace">model_params</monospace> argument. This is a drastic simplification compared to a typical scikit-learn workflow, where one must create the pipeline manually by combining different objects, wrap it inside a <monospace specific-use="monospace">GridSearchCV</monospace> object, and define the hyperparameter options separately from the pipeline itself, using a complex syntax. Lastly, scikit-learn&#x02019;s <monospace specific-use="monospace">GridSearchCV</monospace> object must be provided to its <monospace specific-use="monospace">cross_validate</monospace> function.</p><fig position="float" id="gigabyte-2024-113-g003"><label>Figure 3.</label><caption><p>Example of julearn (A) and scikit-learn (B) training a typical ML pipeline in a CV consistent way. Both use a grid search to find optimal hyperparameters. Note that julearn is able to specify the hyperparameters at the same time as it defines each step. On the other hand, scikit-learn needs all hyperparameters to be defined separately with a prefix indicating the step they belong to. This can become complex, especially when pipelines are nested and multiple prefixes are needed.</p></caption><graphic xlink:href="gigabyte-2024-113-g003" position="float"/></fig></sec><sec id="s0007"><title>Inspection and analysis</title><p>Inspection of ML pipelines is crucial when working in fields such as neuroscience and medicine, as concepts like trustworthy ML are heavily dependent on the ability to draw insights and conclusions from models. For this purpose, one needs to be able to inspect and verify each pipeline step, check parameters, and evaluate feature importances and further properties of ML pipelines. Julearn includes two functionalities: a <monospace specific-use="monospace">preprocess</monospace> function and an <monospace specific-use="monospace">Inspector</monospace> class. The <monospace specific-use="monospace">preprocess</monospace> function allows users to process the data up to any step of the pipeline, allowing them to check how the different transformations are applied. For example, a user might be interested in examining the PCA components created or the distribution of features after confound removal (see Figure <xref rid="gigabyte-2024-113-g004" ref-type="fig">4</xref> for example). The <monospace specific-use="monospace">Inspector</monospace> object, on the other hand, allows us to inspect the models after estimating their performance using CV. It helps users to check fold-wise predictions and obtain both the hyper- and fitted parameters of the trained models (see Figure <xref rid="gigabyte-2024-113-g005" ref-type="fig">5</xref> for example). This enables users to verify the robustness of the different parameter combinations and evaluate the variability of the performance across folds. Ongoing efforts to increase julearn&#x02019;s inspection tools encompass integrating tools for explainable Artificial Intelligence (AI), such as SHAP&#x000a0;&#x0feff;<styled-content style-type="bibr-wrapper">[<xref rid="ref8" ref-type="bibr">8</xref>]</styled-content>. </p><fig position="float" id="gigabyte-2024-113-g004"><label>Figure 4.</label><caption><p>Example of the utility of the <monospace specific-use="monospace">preprocess</monospace> function. Once the model has been trained and evaluated using <monospace specific-use="monospace">run_cross_validation</monospace>, the user can verify how the data is transformed in the pipeline until a certain step. The whole functioning code as well as plots depicting the data points can be seen in julearn&#x02019;s documentation (Examples &#x02192; Inspection &#x02192; Preprocessing with variance threshold, zscore and PCA).</p></caption><graphic xlink:href="gigabyte-2024-113-g004" position="float"/></fig><fig position="float" id="gigabyte-2024-113-g005"><label>Figure 5.</label><caption><p>Example of the usage of the <monospace specific-use="monospace">inspector</monospace>. The <monospace specific-use="monospace">run_cross_validation</monospace> can return the inspector, allowing the user to check the fold-wise predictions as well as the model parameters from each fold. A working example can be found on julearn&#x02019;s documentation (Examples &#x02192; Inspection &#x02192; Inspecting the fold-wise predictions).</p></caption><graphic xlink:href="gigabyte-2024-113-g005" position="float"/></fig></sec><sec id="s0008"><title>Neuroscience-specific features</title><p>In addition to julearn&#x02019;s field-agnostic features, we also provide neuroscience-specific functionalities. Confound removal in the form of confound regression, which is popularly used in neuroscience, was implemented as the <monospace specific-use="monospace">ConfoundRemover</monospace>. This confound regression can be trained on all features or only on specific subsamples defined by a grouping variable, i.e., allowing neuroscientists to only train it on healthy participants as proposed in Dukart <italic toggle="yes">et&#x000a0;al.</italic>&#x000a0;<styled-content style-type="bibr-wrapper">[<xref rid="ref9" ref-type="bibr">9</xref>]</styled-content>. Additionally, we have included the Connectome Based Predictive Modelling (CBPM) algorithm&#x000a0;<styled-content style-type="bibr-wrapper">[<xref rid="ref10" ref-type="bibr">10</xref>]</styled-content>. This transformer aggregates features significantly correlated with the target into one or two features. This can be done separately for the positively and negatively correlated features. Aggregation can be done using any user-specified aggregation function, such as summation or mean. We plan to add more neuroscience specific features, such as the integration of harmonization techniques, currently developed in a separate project (<italic toggle="yes">juharmonize</italic>).</p></sec><sec id="s0009"><title>Customization and extensibility</title><p>Julearn provides a simple interface to several important ML approaches but is also easily customizable. Each component of julearn is built to be scikit-learn compatible, meaning that any scikit-learn compatible model and transformer can be provided to <monospace specific-use="monospace">run_cross_validation</monospace> and <monospace specific-use="monospace">PipelineCreator</monospace>. Other <monospace specific-use="monospace">run_cross_validation</monospace> arguments, like <monospace specific-use="monospace">cv</monospace> and hyperparameter searchers, were implemented in a way to be extensible by any typical scikit-learn object. This customizability of julearn helps users extend their usage of julearn and prepares them for the case that they want to transition to scikit-learn to build unique expert level ML pipelines.</p></sec></sec><sec id="s0010"><title>Examples</title><p>To illustrate the functionality and quality attributes of julearn, we depict three independent examples, showing how the analysis described in previously-published research projects can be implemented with julearn.</p><sec id="s0011"><title>Example 1: prediction of age using Gray Matter Volume (GMV) derived from T1-weighted MRI images</title><sec id="s0012"><title>Dataset</title><p>We used T1-weighted (T1w) MRI images from the publicly available Information eXtraction from Images (IXI) dataset&#x000a0;<styled-content style-type="bibr-wrapper">[<xref rid="ref11" ref-type="bibr">11</xref>]</styled-content> (IXI, N = 562, age range = 20&#x02013;86 years) for age estimation similar to Franke <italic toggle="yes">et&#x000a0;al.</italic>&#x000a0;<styled-content style-type="bibr-wrapper">[<xref rid="ref12" ref-type="bibr">12</xref>]</styled-content>.</p></sec><sec id="s0013"><title>Image preprocessing</title><p>T1w images were preprocessed using the Computational Anatomy Toolbox (RRID:<named-content content-type="rrid">SCR_019184</named-content>) version 12.8 <styled-content style-type="bibr-wrapper">[<xref rid="ref13" ref-type="bibr">13</xref>]</styled-content>. The initial affine registration of T1w images was done with higher than default accuracy (accstr = 0.8), to ensure accurate normalization and segmentation. After bias field correction and tissue class segmentation, accurate optimized Geodesic shooting <styled-content style-type="bibr-wrapper">[<xref rid="ref14" ref-type="bibr">14</xref>]</styled-content> was used for normalization (regstr = 1). We used 1 mm Geodesic Shooting templates and generated 1 mm isotropic images as output. Next, the normalized Gray Matter (GM) segments were modulated for linear and non-linear transformations.</p></sec><sec id="s0014"><title>Feature spaces and models</title><p>A whole-brain mask was used to select 238,955 GM voxels. Then, smoothing with a 4 mm FWHM Gaussian kernel and resampling using linear interpolation to 8 mm spatial resolution was applied resulting in 3,747 features. We tested three regression models, GPR, RVR and SVR, using this feature space to predict age.</p></sec><sec id="s0015"><title>Prediction analysis</title><p>We used 5 times 5-fold CV to estimate the generalization performance of our pipelines. Hyperparameters were tuned in the inner 5-fold CV. Features with low variance were removed (threshold&#x000a0; &#x0003c; 1 &#x000d7;&#x02009;10<sup>&#x02212;5</sup>). PCA was applied on the features to retain 100% variance. The GPR model gave lowest generalization error (mean Mean Absolute Error (MAE)&#x000a0; = &#x02212;5.30 years), followed by RVR (MAE&#x000a0; = &#x02212;5.56) and SVR (MAE&#x000a0; = &#x02212;6.98). Corrected <italic toggle="yes">t</italic>-test revealed a significant difference between GPR and SVM (<italic toggle="yes">p</italic> =&#x000a0;3.18 &#x000d7;&#x02009;10<sup>&#x02212;9</sup>), and between RVR and SVM (<italic toggle="yes">p</italic> =&#x000a0;8.19 &#x000d7;&#x02009;10<sup>&#x02212;9</sup>). There was no significant difference between RVR and GPR (<italic toggle="yes">p</italic> =&#x000a0;0.075). Results can be visualized with julearn&#x02019;s scores viewer as depicted in Figure&#x000a0;<xref rid="gigabyte-2024-113-g002" ref-type="fig">2</xref>.</p></sec></sec><sec id="s0016"><title>Example 2: confound removal</title><sec id="s0017"><title>Dataset</title><p>For this example, we retrieved data conceptually similar to Dukart <italic toggle="yes">et&#x000a0;al.</italic>&#x000a0;<styled-content style-type="bibr-wrapper">[<xref rid="ref9" ref-type="bibr">9</xref>]</styled-content>. We used the Alzheimer&#x02019;s Disease Neuroimaging Initiative <ext-link xlink:href="https://adni.loni.usc.edu/" ext-link-type="uri">https://adni.loni.usc.edu/</ext-link> database including 498 participants and 68 features. We used age as a confound and the current diagnosis as the target. To simplify the task, we only predicted whether a participant had some form of impairment (mild cognitive impairment or Alzheimer&#x02019;s disease) or not (control).</p></sec><sec id="s0018"><title>Prediction analysis</title><p>We aimed to conceptually replicate Figure 1 from&#x000a0;Dukart <italic toggle="yes">et&#x000a0;al.</italic>
<styled-content style-type="bibr-wrapper">[<xref rid="ref9" ref-type="bibr">9</xref>]</styled-content>. The authors proposed to train confound regression on the healthy participants of a study and then transform all participants using this confound regression. As part of their efforts, they compared two pipelines using the same learning algorithm (i.e., SVM) <styled-content style-type="bibr-wrapper">[<xref rid="ref15" ref-type="bibr">15</xref>]</styled-content>. One pipeline was trained to directly classify healthy vs unhealthy participants without controlling for age, while a second pipeline was configured to first control for age using their proposed method: train the confound regression only on healthy participants. They evaluated the bias of age in the predictions of these models by comparing the age distributions of healthy vs unhealthy participants for each model&#x02019;s misclassifications. This was done by computing, for each pipeline, whether there is a significant age difference between these two groups of participants. They found a significant difference when not controlling for age, but not when controlling for age. With further experiments, they conclude that their method leads to less age-related bias. In this example, we replicated the comparison between the two SVMs. First, we built both pipelines using julearn and then compared their misclassified predictions to find the same differences (Figure <xref rid="gigabyte-2024-113-g006" ref-type="fig">6</xref>).</p><fig position="float" id="gigabyte-2024-113-g006"><label>Figure 6.</label><caption><p>Replication of figure 1 in &#x0201c;Age characteristics of misclassified subjects using SVM&#x0201d; from Dukart <italic toggle="yes">et&#x000a0;al.</italic>&#x000a0;<styled-content style-type="bibr-wrapper">[<xref rid="ref9" ref-type="bibr">9</xref>]</styled-content>. Performing a cross-validated confound removal trained only on the control group using julearn. Julearn greatly simplifies the process of training CV-consistent preprocessing steps based on characteristics like control vs experimental group. **** means a statistical significance at a <italic toggle="yes">p</italic>-value threshold of 0.0001 and ns that there is no statistical difference at that threshold.</p></caption><graphic xlink:href="gigabyte-2024-113-g006" position="float"/></fig><p>While the first pipeline (without confound removal) is straightforward to implement, the second variant requires a complicated preprocessing step in which the confound removal needs to be trained on a subsample of one specific column of the data. Thanks to julearn&#x02019;s support for feature types, the whole procedure can be easily implemented by indicating which feature type are to be considered confounds (e.g., age), which column has the subsampling data (e.g., current diagnosis) and which values should be considered (e.g., healthy). Note that the difference between all subjects in age is significant for our larger, but not their smaller, sample, which can be attributed to the increased power due to the large sample size.</p></sec></sec><sec id="s0019"><title>Example 3: prediction of fluid intelligence using connectome-based predictive modelling</title><sec id="s0020"><title>Dataset</title><p>We used data obtained from two resting-state functional Magnetic Resonance Imaging (rs-fMRI) sessions from the Human Connectome Project Young-Adult (HCP-YA) S1200 release&#x000a0;<styled-content style-type="bibr-wrapper">[<xref rid="ref16" ref-type="bibr">16</xref>]</styled-content>. The details regarding the collection of behavioral data, rs-fMRI acquisition, and image preprocessing have been described elsewhere <styled-content style-type="bibr-wrapper">[<xref rid="ref17" ref-type="bibr">17</xref>, <xref rid="ref18" ref-type="bibr">18</xref>]</styled-content>. Here, we provide an overview. The scanning protocol for HCP-YA was approved by the local Institutional Review Board at Washington University in St. Louis. Retrospective analysis of these datasets was further approved by the local Ethics Committee at the Faculty of Medicine at Heinrich-Heine-University in D&#x000fc;sseldorf. We selected sessions for both phase encoding directions (left-to-right and right-to-left) obtained on the first day of HCP-YA data collection. Due to the HCP-YA&#x02019;s family structure, we selected 399 unrelated subjects (matched for the variable &#x0201c;Gender&#x0201d;), so that we could always maintain independence between folds during cross-validation. In line with Finn <italic toggle="yes">et&#x000a0;al.</italic>&#x000a0;<styled-content style-type="bibr-wrapper">[<xref rid="ref19" ref-type="bibr">19</xref>]</styled-content>, we filtered out subjects with high estimates of overall head motion (frame-to-frame head motion estimate (averaged across both day 1 rest runs; HCP-YA: MOVEMENT_RELATIVERMS_MEAN &#x0003e; 0.14). This resulted in a dataset consisting of 368 subjects (176 female, 192 male). Participants&#x02019; ages ranged from 22 to 37 (mean = 28.7, standard deviation = 3.85). The two sessions of rs-fMRI lasted 15 min each, resulting in 30 min across both sessions. Scans were acquired using a 3T Siemens connectome-Skyra scanner with a gradient-echo EPI sequence (TE = 33.1 ms, TR = 720&#x000a0;ms, flip angle = 52&#x000b0;, 2.0&#x000a0;mm isotropic voxels, 72 slices, multiband factor of 8).</p></sec><sec id="s0021"><title>Image preprocessing</title><p>Data from the rs-fMRI sessions in the HCP-YA had already undergone the HCP&#x02019;s minimal preprocessing pipeline <styled-content style-type="bibr-wrapper">[<xref rid="ref17" ref-type="bibr">17</xref>]</styled-content>, including motion correction and registration to standard space. Additionally, the Independent Component Analysis and FMRIB&#x02019;s ICA-based X-noiseifier (ICA-FIX) procedure&#x000a0;<styled-content style-type="bibr-wrapper">[<xref rid="ref20" ref-type="bibr">20</xref>]</styled-content> were applied to remove structured artefacts. Lastly, the 6 rigid-body parameters, their temporal derivatives and the squares of the 12 previous terms were regressed out, resulting in 24 parameters. In addition, we regressed out mean time courses of white matter, cerebro-spinal fluid and global signal, as well as their squared terms, the temporal derivatives of the mean signals and their squared terms as confounds, resulting in 12 parameters (4 for each noise component). The signal was linearly detrended and bandpass filtered at 0.01&#x02013;0.08 Hz using <monospace specific-use="monospace">nilearn.image.clean_img</monospace>, The resulting voxel-wise time series were then aggregated using the Shen parcellation&#x000a0;<styled-content style-type="bibr-wrapper">[<xref rid="ref19" ref-type="bibr">19</xref>]</styled-content> consisting of 268 parcels. Functional Connectivity (FC) was estimated for each rs-fMRI session as Pearson&#x02019;s correlation between each pair of parcels, resulting in a symmetric 268&#x000a0;&#x000d7;&#x000a0;268 matrix. These two FC matrices were further averaged resulting in one FC matrix per subject. One half of the symmetric matrix as well as the diagonal were discarded so that only unique edges were used as features in the prediction workflow.</p></sec><sec id="s0022"><title>Prediction analysis</title><p>First, we aimed to reproduce Finn <italic toggle="yes">et&#x000a0;al.</italic>&#x000a0;<styled-content style-type="bibr-wrapper">[<xref rid="ref19" ref-type="bibr">19</xref>]</styled-content> prediction pipeline using the CBPM framework and the Leave-One-Out Cross-Validation (LOO-CV) scheme. Specifically, we reconstructed the workflow used to reproduce Figure 5a in Finn <italic toggle="yes">et&#x000a0;al.</italic>&#x000a0;<styled-content style-type="bibr-wrapper">[<xref rid="ref19" ref-type="bibr">19</xref>]</styled-content>. As a prediction target, we used subjects&#x02019; score on the Penn Matrix Test (<sc>PMAT24_A_CR)</sc>. This is a non-verbal reasoning assessment and a measure of fluid intelligence. CBPM first performs correlation-based univariate feature selection based on a pre-specified significance threshold. Selected features are further divided into positively and negatively correlated features and then separately summed up resulting in two features. Subsequently, a linear regression is fitted either on both or one of these features based on user preferences. The results here were obtained using the positive-feature network at a feature selection threshold of <italic toggle="yes">p</italic> &#x0003c;&#x000a0;0.01 in line with Figure&#x000a0;5a from Finn <italic toggle="yes">et&#x000a0;al.</italic>&#x000a0;<styled-content style-type="bibr-wrapper">[<xref rid="ref19" ref-type="bibr">19</xref>]</styled-content>. We observed a similar trend in our results albeit with a lower correlation between observed and predicted values (see Figure <xref rid="gigabyte-2024-113-g007" ref-type="fig">7</xref>). In addition, we also provide results for a 10-Fold cross-validation with 10 repeats. In this analysis, we&#x000a0;also tested CBPM using positive- and negative-feature networks individually as well&#x000a0;&#x0feff;as&#x000a0;both&#x000a0;feature networks combined with varying thresholds for feature selection (0.01, 0.05, 0.1).</p><fig position="float" id="gigabyte-2024-113-g007"><label>Figure 7.</label><caption><p>Results of the prediction of fluid intelligence using CBPM on HCP-YA data as in Finn <italic toggle="yes">et&#x000a0;al.</italic>&#x000a0;<styled-content style-type="bibr-wrapper">[<xref rid="ref19" ref-type="bibr">19</xref>]</styled-content>. Left panel depicts the predicted (<italic toggle="yes">y</italic>-axis) vs the ground truth (<italic toggle="yes">x</italic>-axis) values for each sample in a LOO-CV scheme, following Figure 5a in Finn <italic toggle="yes">et&#x000a0;al.</italic>&#x000a0;<styled-content style-type="bibr-wrapper">[<xref rid="ref19" ref-type="bibr">19</xref>]</styled-content>. Right panel depicts the mean correlation values (<italic toggle="yes">r</italic>) across folds, for a 10-times 10-fold CV scheme, using different thresholds (colors) and considering either negative correlations, positive correlations, or both kinds of correlations (columns).</p></caption><graphic xlink:href="gigabyte-2024-113-g007" position="float"/></fig></sec></sec></sec><sec id="s0023"><title>Discussion</title><p>Julearn aims to bridge the gap between domain expertise in neuroscience and the application of ML pipelines. Toward that goal, julearn provides a simple interface using two key API points only. First, the <monospace specific-use="monospace">run_cross_validation</monospace> function provides functionalites to evaluate common ML pipelines. Second the <monospace specific-use="monospace">PipelineCreator</monospace> provides means to devise complex ML pipelines that can be then evaluated using <monospace specific-use="monospace">run_cross_validation</monospace>. Additional functionalities are also provided to guide and help users to inspect and evaluate the resulting CV scores. In fact, julearn provides a complete workflow for ML that has already been used in several publications&#x000a0;<styled-content style-type="bibr-wrapper">[<xref rid="ref21" ref-type="bibr">21</xref>, <xref rid="ref22" ref-type="bibr">22</xref>]</styled-content>. Furthermore, the customizability and open-source nature of julearn will help it grow and extend its functionality.</p><p>Julearn does not aim to replace core ML libraries such as scikit-learn. Rather, it aims to simplify the entry into the ML world by providing an easy-to-use environment with built-in guards against some of the most common ML pitfalls, such as data leakage that can happen due to not using nested cross-validation and when performing confound removal. Furthermore, julearn is not created to compete with AutoML approaches <styled-content style-type="bibr-wrapper">[<xref rid="ref23" ref-type="bibr">23</xref>&#x02013;<xref rid="ref25" ref-type="bibr">25</xref>],</styled-content> which try to automate the preprocessing and modelling over multiple algorithms and sets of hyperparameters. While these approaches are valid and powerful, they do not offer the full functionalities required in many bio-medical research fields, such as nested cross validation and confound removal. Furthermore, a researcher might require more control over model types, parameters and interpretability, which might not be easily achievable with the current AutoML libraries. Lastly, there are other libraries, such as photon <styled-content style-type="bibr-wrapper">[<xref rid="ref26" ref-type="bibr">26</xref>]</styled-content>, Neurominer&#x000a0;<styled-content style-type="bibr-wrapper">[<xref rid="ref27" ref-type="bibr">27</xref>]</styled-content> or Neuropredict&#x000a0;<styled-content style-type="bibr-wrapper">[<xref rid="ref28" ref-type="bibr">28</xref>],</styled-content> that try to build on top of powerful ML libraires to create different interfaces with unique features for field experts. All these libraries are important for a vibrant open-source community. Hence, julearn&#x02018;s unique features and simple interface will be useful for many research projects.</p></sec><sec id="s0024"><title>Availability of source code</title><p>Julearn&#x02019;s code is available in GitHub&#x000a0;<styled-content style-type="bibr-wrapper">[<xref rid="ref29" ref-type="bibr">29</xref>]</styled-content> with the corresponding documentation in GitHub Pages&#x000a0;<styled-content style-type="bibr-wrapper">[<xref rid="ref30" ref-type="bibr">30</xref>]</styled-content>. The code used for the examples in this manuscript is available at&#x000a0;<styled-content style-type="bibr-wrapper">[<xref rid="ref31" ref-type="bibr">31</xref>]</styled-content>, with instructions on how to get the publicly available data. </p><p>
<list list-type="bullet"><list-item><p>Project name: Julearn</p></list-item><list-item><p>Project home page: <ext-link xlink:href="https://juaml.github.io/julearn/" ext-link-type="uri" specific-use="url">https://juaml.github.io/julearn/</ext-link></p></list-item><list-item><p>Operating system(s): Platform independent</p></list-item><list-item><p>Programming language: Python</p></list-item><list-item><p>License: GNU AGPLv3</p></list-item><list-item><p>RRID: <named-content content-type="rrid">SCR_024881</named-content></p></list-item><list-item><p>biotools: julearn</p></list-item></list>
</p></sec></body><back><ack><title>Acknowledgements</title><p>We want to thank the INM-7 and early adopters of julearn for their valuable contribution at early stages, shaping the direction of our efforts in developing this tool.</p></ack><sec sec-type="data-availability" id="s0025"><title>Data availability</title><p>The data used in this manuscript is publicly available following each dataset requirements. Information on the dataset sources is provided in the description of each example. Snapshots of the underlying code are available in the GigaDB repository <styled-content style-type="bibr-wrapper">[<xref rid="ref32" ref-type="bibr">32</xref>]</styled-content>.</p></sec><sec id="s0026"><title>List of abbreviations</title><p>API, Application Programming Interface; CBPM, Connectome Based Predictive Modelling; CV, cross-validation; FC, Functional Connectivity; GM, Gray Matter; GPR, Gaussian Process Regression; HCP-YA, Human Connectome Project Young-Adult; IXI, Information eXtraction from Images; LOO-CV, Leave-One-Out Cross-Validation; MAE, Mean Absolute Error; ML, machine learning; MRI, Magnetic Resonance Imaging; PCA, Principal Component Analysis; rs-fMRI, resting-state functional Magnetic Resonance Imaging; RVR, Relevance Vector Regression; SVR, Support Vector Regression; T1w, T1-weighted.</p></sec><sec id="s0027"><title>Declarations</title><sec id="s0028"><title>Ethics approval and consent to participate</title><p>The authors declare that ethical approval was not required for this type of research.</p></sec><sec sec-type="COI-statement" id="s0029"><title>Competing interests</title><p>The authors declare that they have no competing interests.</p></sec><sec id="s0030"><title>Consent for publication</title><p>Consent for publication was obtained from the Alzheimer&#x02019;s Disease Neuroimaging Initiative (ADNI; <ext-link xlink:href="https://adni.loni.usc.edu/" ext-link-type="uri" specific-use="url">https://adni.loni.usc.edu/</ext-link>) Data and Publications Committee. Other datasets do not require consent for publication.</p></sec><sec id="s0031"><title>Authors&#x02019; contributions</title><p>SH and FR designed the library. SH, LS, VK, SM, KRP and FR contributed to the development and testing of the library, wrote and reviewed the manuscript. VK contributed to the structural design and writing of julearn&#x02019;s documentation. SM and FR wrote the code for Example 1, SH and FR wrote the code for Example 2 and LS wrote the code for Example 3.</p></sec><sec id="s0032"><title>Funding</title><p>This work was partly supported by the Helmholtz-AI project DeGen (ZT-I-PF-5-078), the Helmholtz Portfolio Theme &#x0201c;Supercomputing and Modeling for the Human Brain&#x0201d; the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation), project PA 3634/1-1 and project-ID 431549029&#x02013;SFB 1451 project B05, the Helmholtz Imaging Platform and eBRAIN Health (HORIZON-INFRA-2021-TECH-01).</p><p>Data collection and sharing for this project was funded by the Alzheimer&#x02019;s Disease Neuroimaging Initiative (ADNI) (National Institutes of Health Grant U01 AG024904) and DOD ADNI (Department of Defense award number W81XWH-12-2-0012). ADNI is funded by the National Institute on Aging, the National Institute of Biomedical Imaging and Bioengineering, and through generous contributions from the following: AbbVie, Alzheimer&#x02019;s Association; Alzheimer&#x02019;s Drug Discovery Foundation; Araclon Biotech; BioClinica, Inc.; Biogen; Bristol-Myers Squibb Company; CereSpir, Inc.; Cogstate; Eisai Inc.; Elan Pharmaceuticals, Inc.; Eli Lilly and Company; EuroImmun; F. Hoffmann-La Roche Ltd and its affiliated company Genentech, Inc.; Fujirebio; GE Healthcare; IXICO Ltd; Janssen Alzheimer Immunotherapy Research &#x00026; Development, LLC; Johnson &#x00026; Johnson Pharmaceutical Research &#x00026; Development LLC; Lumosity; Lundbeck; Merck &#x00026; Co., Inc.; Meso Scale Diagnostics, LLC; NeuroRx Research; Neurotrack Technologies; Novartis Pharmaceuticals Corporation; Pfizer Inc.; Piramal Imaging; Servier; Takeda Pharmaceutical Company; and Transition Therapeutics. The Canadian Institutes of Health Research is providing funds to support ADNI clinical sites in Canada. Private sector contributions are facilitated by the Foundation for the National Institutes of Health (www.fnih.org). The grantee organization is the Northern California Institute for Research and Education, and the study is coordinated by the Alzheimer&#x02019;s Therapeutic Research Institute at the University of Southern California. ADNI data are disseminated by the Laboratory for Neuro Imaging at the University of Southern California.</p></sec></sec><ref-list><title>References</title><ref id="ref1"><label>1</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>J</given-names></name>, <name><surname>Li</surname><given-names>J</given-names></name>, <name><surname>Eickhoff</surname><given-names>SB</given-names></name>
<etal/></person-group>
<article-title>The challenges and prospects of brain-based prediction of behaviour</article-title>. <source>Nat. Hum. Behav.</source>, <year>2023</year>; <volume>7</volume>(<issue>8</issue>): <fpage>1255</fpage>&#x02013;<lpage>1264</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41562-023-01670-1</pub-id>.<pub-id pub-id-type="pmid">37524932</pub-id>
</mixed-citation></ref><ref id="ref2"><label>2</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Varoquaux</surname><given-names>G</given-names></name>, <name><surname>Raamana</surname><given-names>PR</given-names></name>, <name><surname>Engemann</surname><given-names>DA</given-names></name>
<etal/></person-group>
<article-title>Assessing and tuning brain decoders: cross-validation, caveats, and guidelines</article-title>. <source>NeuroImage</source>, <year>2017</year>; <volume>145</volume>: <fpage>166</fpage>&#x02013;<lpage>179</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.10.038</pub-id>.<pub-id pub-id-type="pmid">27989847</pub-id>
</mixed-citation></ref><ref id="ref3"><label>3</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F</given-names></name>, <name><surname>Varoquaux</surname><given-names>G</given-names></name>, <name><surname>Gramfort</surname><given-names>A</given-names></name>
<etal/></person-group>
<article-title>Scikit-learn: Machine Learning in Python</article-title>. <source>J. Mach. Learn. Res.</source>, <year>2012</year>; <volume>12</volume>: <fpage>2825</fpage>&#x02013;<lpage>2830</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s13398-014-0173-7.2</pub-id>.</mixed-citation></ref><ref id="ref4"><label>4</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abraham</surname><given-names>A</given-names></name>, <name><surname>Pedregosa</surname><given-names>F</given-names></name>, <name><surname>Eickenberg</surname><given-names>M</given-names></name>
<etal/></person-group>
<article-title>Machine learning for neuroimaging with scikit-learn</article-title>. <source>Front. Neuroinform.</source>, <year>2014</year>; <volume>8</volume>: <elocation-id content-type="artnum">0000341</elocation-id>. doi:<pub-id pub-id-type="doi">10.3389/fninf.2014.00014</pub-id>.</mixed-citation></ref><ref id="ref5"><label>5</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>McKinney</surname><given-names>W</given-names></name>. </person-group>
<part-title>Data Structures for Statistical Computing in Python</part-title>. In: <source>Proceedings of the 9th Python in Science Conference, Austin, Texas</source>. <year>2010</year>; pp. <fpage>56</fpage>&#x02013;<lpage>61</lpage>, doi:<pub-id pub-id-type="doi">10.25080/Majora-92bf1922-00a</pub-id>.</mixed-citation></ref><ref id="ref6"><label>6</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poldrack</surname><given-names>RA</given-names></name>, <name><surname>Huckins</surname><given-names>G</given-names></name>, <name><surname>Varoquaux</surname><given-names>G</given-names></name>. </person-group>
<article-title>Establishment of best practices for evidence for prediction: a review</article-title>. <source>JAMA Psychiatry</source>, <year>2020</year>; <volume>77</volume>(<issue>5</issue>): <fpage>534</fpage>&#x02013;<lpage>540</lpage>. doi:<pub-id pub-id-type="doi">10.1001/jamapsychiatry.2019.3671</pub-id>.<pub-id pub-id-type="pmid">31774490</pub-id>
</mixed-citation></ref><ref id="ref7"><label>7</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nadeau</surname><given-names>C</given-names></name>, <name><surname>Bengio</surname><given-names>Y</given-names></name>. </person-group>
<article-title>Inference for the Generalization Error</article-title>. <source>Mach. Learn.</source>, <year>2003</year>; <volume>52</volume>(<issue>3</issue>): <fpage>239</fpage>&#x02013;<lpage>281</lpage>. doi:<pub-id pub-id-type="doi">10.1023/A:1024068626366</pub-id>.</mixed-citation></ref><ref id="ref8"><label>8</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lundberg</surname><given-names>SM</given-names></name>, <name><surname>Lee</surname><given-names>SI</given-names></name>. </person-group>
<part-title>A unified approach to interpreting model predictions</part-title>. In: <source>NIPS&#x02019;17: Proceedings of the 31st International Conference on Neural Information Processing Systems</source>. <publisher-loc>Red Hook, NY</publisher-loc>: <publisher-name>Curran Associates Inc.</publisher-name>, <year>2017</year>; pp. <fpage>4768</fpage>&#x02013;<lpage>4777</lpage>.</mixed-citation></ref><ref id="ref9"><label>9</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dukart</surname><given-names>J</given-names></name>, <name><surname>Schroeter</surname><given-names>ML</given-names></name>, <name><surname>Mueller</surname><given-names>K</given-names></name>
<etal/></person-group>
<article-title>Age Correction in Dementia &#x02013; Matching to a Healthy Brain</article-title>. <source>PLoS One</source>, <year>2011</year>; <volume>6</volume>(<issue>7</issue>): <elocation-id content-type="artnum">e22193</elocation-id>. doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0022193</pub-id>.<pub-id pub-id-type="pmid">21829449</pub-id>
</mixed-citation></ref><ref id="ref10"><label>10</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shen</surname><given-names>X</given-names></name>, <name><surname>Finn</surname><given-names>ES</given-names></name>, <name><surname>Scheinost</surname><given-names>D</given-names></name>
<etal/></person-group>
<article-title>Using connectome-based predictive modeling to predict individual behavior from brain connectivity</article-title>. <source>Nat. Protoc.</source>, <year>2017</year>; <volume>12</volume>(<issue>3</issue>): <fpage>506</fpage>&#x02013;<lpage>518</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nprot.2016.178</pub-id>.<pub-id pub-id-type="pmid">28182017</pub-id>
</mixed-citation></ref><ref id="ref11"><label>11</label><mixed-citation publication-type="misc"><person-group person-group-type="author"><collab collab-type="corporate-author">Biomedical Image Analysis Group, Imperial College London</collab></person-group>. IXI Dataset. <ext-link xlink:href="https://brain-development.org/ixi-dataset/" ext-link-type="uri" specific-use="url">https://brain-development.org/ixi-dataset/</ext-link>.</mixed-citation></ref><ref id="ref12"><label>12</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Franke</surname><given-names>K</given-names></name>, <name><surname>Ziegler</surname><given-names>G</given-names></name>, <name><surname>Kl&#x000f6;ppel</surname><given-names>S</given-names></name>
<etal/></person-group>
<article-title>Alzheimer&#x02019;s Disease Neuroimaging Initiative. Estimating the age of healthy subjects from T1-weighted MRI scans using kernel methods: exploring the influence of various parameters</article-title>. <source>NeuroImage</source>, <year>2010</year>; <volume>50</volume>(<issue>3</issue>): <fpage>883</fpage>&#x02013;<lpage>892</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.01.005</pub-id>.<pub-id pub-id-type="pmid">20070949</pub-id>
</mixed-citation></ref><ref id="ref13"><label>13</label><mixed-citation publication-type="misc"><person-group person-group-type="author"><name><surname>Gaser</surname><given-names>C</given-names></name>, <name><surname>Dahnke</surname><given-names>R</given-names></name>, <name><surname>Thompson</surname><given-names>PM</given-names></name>
<etal/></person-group>
<article-title>CAT - A Computational Anatomy Toolbox for the Analysis of Structural MRI Data</article-title>. bioRxiv. <year>2022</year>; <pub-id pub-id-type="doi">10.1101/2022.06.11.495736</pub-id>.</mixed-citation></ref><ref id="ref14"><label>14</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashburner</surname><given-names>J</given-names></name>, <name><surname>Friston</surname><given-names>KJ</given-names></name>. </person-group>
<article-title>Diffeomorphic registration using geodesic shooting and Gauss&#x02013;Newton optimisation</article-title>. <source>NeuroImage</source>, <year>2011</year>; <volume>55</volume>(<issue>3</issue>): <fpage>954</fpage>&#x02013;<lpage>967</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.12.049</pub-id>.<pub-id pub-id-type="pmid">21216294</pub-id>
</mixed-citation></ref><ref id="ref15"><label>15</label><mixed-citation publication-type="misc"><person-group person-group-type="author"><name><surname>Berwick</surname><given-names>R</given-names></name>, <name><surname>Idiot</surname><given-names>V</given-names></name>. </person-group>
<article-title>An Idiot&#x02019;s guide to Support vector machines (SVMs) SVMs: A New Generation of Learning Algorithms Key Ideas</article-title>. <year>1990</year>; p. 1&#x02013;28, <ext-link xlink:href="https://web.mit.edu/6.034/wwwbob/svm.pdf" ext-link-type="uri" specific-use="url">https://web.mit.edu/6.034/wwwbob/svm.pdf</ext-link>.</mixed-citation></ref><ref id="ref16"><label>16</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van&#x000a0;Essen</surname><given-names>DC</given-names></name>, <name><surname>Smith</surname><given-names>SM</given-names></name>, <name><surname>Barch</surname><given-names>DM</given-names></name>
<etal/></person-group>
<article-title>The WU-Minn Human Connectome Project: an overview</article-title>. <source>NeuroImage</source>, <year>2013</year>; <volume>80</volume>: <fpage>62</fpage>&#x02013;<lpage>79</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.041</pub-id>.<pub-id pub-id-type="pmid">23684880</pub-id>
</mixed-citation></ref><ref id="ref17"><label>17</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glasser</surname><given-names>MF</given-names></name>, <name><surname>Sotiropoulos</surname><given-names>SN</given-names></name>, <name><surname>Wilson</surname><given-names>JA</given-names></name>
<etal/></person-group>
<article-title>The minimal preprocessing pipelines for the Human Connectome Project</article-title>. <source>NeuroImage</source>, <year>2013</year>; <volume>80</volume>: <fpage>105</fpage>&#x02013;<lpage>124</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.04.127</pub-id>.<pub-id pub-id-type="pmid">23668970</pub-id>
</mixed-citation></ref><ref id="ref18"><label>18</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barch</surname><given-names>DM</given-names></name>, <name><surname>Burgess</surname><given-names>GC</given-names></name>, <name><surname>Harms</surname><given-names>MP</given-names></name>
<etal/></person-group>
<article-title>Function in the human connectome: task-fMRI and individual differences in behavior</article-title>. <source>NeuroImage</source>, <year>2013</year>; <volume>80</volume>: <fpage>169</fpage>&#x02013;<lpage>189</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.033</pub-id>.<pub-id pub-id-type="pmid">23684877</pub-id>
</mixed-citation></ref><ref id="ref19"><label>19</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Finn</surname><given-names>ES</given-names></name>, <name><surname>Shen</surname><given-names>X</given-names></name>, <name><surname>Scheinost</surname><given-names>D</given-names></name>
<etal/></person-group>
<article-title>Functional connectome fingerprinting: identifying individuals using patterns of brain connectivity</article-title>. <source>Nat. Neurosci.</source>, <year>2015</year>; <volume>18</volume>(<issue>11</issue>): <fpage>1664</fpage>&#x02013;<lpage>1671</lpage>. doi:<ext-link xlink:href="https://1010.1038/nn.4135" ext-link-type="uri" specific-use="url">1010.1038/nn.4135</ext-link>.<pub-id pub-id-type="pmid">26457551</pub-id>
</mixed-citation></ref><ref id="ref20"><label>20</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salimi-Khorshidi</surname><given-names>G</given-names></name>, <name><surname>Douaud</surname><given-names>G</given-names></name>, <name><surname>Beckmann</surname><given-names>CF</given-names></name>
<etal/></person-group>
<article-title>Automatic denoising of functional MRI data: combining independent component analysis and hierarchical fusion of classifiers</article-title>. <source>NeuroImage</source>, <year>2014</year>; <volume>90</volume>: <fpage>449</fpage>&#x02013;<lpage>468</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.11.046</pub-id>.<pub-id pub-id-type="pmid">24389422</pub-id>
</mixed-citation></ref><ref id="ref21"><label>21</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mortaheb</surname><given-names>S</given-names></name>, <name><surname>Van&#x000a0;Calster</surname><given-names>L</given-names></name>, <name><surname>Raimondo</surname><given-names>F</given-names></name>
<etal/></person-group>
<article-title>Mind blanking is a distinct mental state linked to a recurrent brain profile of globally positive connectivity during ongoing mentation</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <year>2022</year>; <volume>119</volume>(<issue>41</issue>): <elocation-id content-type="artnum">e2200511119</elocation-id>. doi:<pub-id pub-id-type="doi">10.1073/pnas.2200511119</pub-id>.<pub-id pub-id-type="pmid">36194631</pub-id>
</mixed-citation></ref><ref id="ref22"><label>22</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>More</surname><given-names>S</given-names></name>, <name><surname>Antonopoulos</surname><given-names>G</given-names></name>, <name><surname>Hoffstaedter</surname><given-names>F</given-names></name>
<etal/></person-group>
<article-title>Brain-age prediction: a systematic comparison of machine learning workflows</article-title>. <source>NeuroImage</source>, <year>2023</year>; <volume>270</volume>: <elocation-id content-type="artnum">119947</elocation-id>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2023.119947</pub-id>.<pub-id pub-id-type="pmid">36801372</pub-id>
</mixed-citation></ref><ref id="ref23"><label>23</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ferreira</surname><given-names>L</given-names></name>, <name><surname>Pilastri</surname><given-names>A</given-names></name>, <name><surname>Martins</surname><given-names>CM</given-names></name>
<etal/></person-group>
<part-title>A Comparison of AutoML Tools for Machine Learning, Deep Learning and XGBoost</part-title>. In: <source>2021 International Joint Conference on Neural Networks (IJCNN)</source>. <publisher-name>IEEE</publisher-name>, <year>2021</year>; pp. <fpage>1</fpage>&#x02013;<lpage>8</lpage>, ISSN: 2161-4407. doi:<pub-id pub-id-type="doi">10.1109/IJCNN52387.2021.9534091</pub-id>.</mixed-citation></ref><ref id="ref24"><label>24</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Z&#x000fc;ller</surname><given-names>MA</given-names></name>, <name><surname>Huber</surname><given-names>MF</given-names></name>. </person-group>
<article-title>Benchmark and Survey of Automated Machine Learning Frameworks</article-title>. <source>J. Artif. Intell. Res.</source>, <year>2021</year>; <volume>70</volume>: <fpage>409</fpage>&#x02013;<lpage>472</lpage>. doi:<ext-link xlink:href="https://1010.1613/jair.1.11854" ext-link-type="uri" specific-use="url">1010.1613/jair.1.11854</ext-link>.</mixed-citation></ref><ref id="ref25"><label>25</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waring</surname><given-names>J</given-names></name>, <name><surname>Lindvall</surname><given-names>C</given-names></name>, <name><surname>Umeton</surname><given-names>R</given-names></name>. </person-group>
<article-title>Automated machine learning: review of the state-of-the-art and opportunities for healthcare</article-title>. <source>Artif. Intell. Med.</source>, <year>2020</year>; <volume>104</volume>: <elocation-id content-type="artnum">101822</elocation-id>. doi:<pub-id pub-id-type="doi">10.1016/j.artmed.2020.101822</pub-id>.<pub-id pub-id-type="pmid">32499001</pub-id>
</mixed-citation></ref><ref id="ref26"><label>26</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leenings</surname><given-names>R</given-names></name>, <name><surname>Winter</surname><given-names>NR</given-names></name>, <name><surname>Plagwitz</surname><given-names>L</given-names></name>
<etal/></person-group>
<article-title>PHOTONAI-A Python API for rapid machine learning model development</article-title>. <source>PLoS One</source>, <year>2021</year>; <volume>16</volume>(<issue>7</issue>): <elocation-id content-type="artnum">e0254062</elocation-id>. doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0254062</pub-id>.<pub-id pub-id-type="pmid">34288935</pub-id>
</mixed-citation></ref><ref id="ref27"><label>27</label><mixed-citation publication-type="misc"><person-group person-group-type="author"><name><surname>Koutsouleris</surname><given-names>N</given-names></name>. </person-group> Neurominer Website. <ext-link xlink:href="http://proniapredictors.eu/neurominer/index.html" ext-link-type="uri" specific-use="url">http://proniapredictors.eu/neurominer/index.html</ext-link>.</mixed-citation></ref><ref id="ref28"><label>28</label><mixed-citation publication-type="misc"><person-group person-group-type="author"><name><surname>Raamana</surname><given-names>PR</given-names></name>. </person-group>
<article-title>neuropredict: easy machine learning and standardized predictive analysis of biomarkers</article-title>. Zenodo, <year>2017</year>; <pub-id pub-id-type="doi">10.5281/zenodo.1058993</pub-id>.</mixed-citation></ref><ref id="ref29"><label>29</label><mixed-citation publication-type="misc"><person-group person-group-type="author"><collab collab-type="corporate-author">Julearn&#x02019;s Github repository</collab>. </person-group>
<ext-link xlink:href="https://github.com/juaml/julearn" ext-link-type="uri" specific-use="url">https://github.com/juaml/julearn</ext-link>.</mixed-citation></ref><ref id="ref30"><label>30</label><mixed-citation publication-type="misc"><person-group person-group-type="author"><collab collab-type="corporate-author">Julearn&#x02019;s Documentation Website</collab>. </person-group>
<ext-link xlink:href="https://juaml.github.io/julearn/" ext-link-type="uri" specific-use="url">https://juaml.github.io/julearn/</ext-link>.</mixed-citation></ref><ref id="ref31"><label>31</label><mixed-citation publication-type="misc"><person-group person-group-type="author"><collab collab-type="corporate-author">Julearn</collab></person-group>. Manuscript&#x02019;s Github repository. <ext-link xlink:href="https://github.com/juaml/julearn_paper" ext-link-type="uri" specific-use="url">https://github.com/juaml/julearn_paper</ext-link>.</mixed-citation></ref><ref id="ref32"><label>32</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hamdan</surname><given-names>S</given-names></name>, <name><surname>More</surname><given-names>S</given-names></name>, <name><surname>Sasse</surname><given-names>L</given-names></name>
<etal/></person-group>
<article-title>Supporting data for &#x0201d;Julearn: an easy-to-use library for leakage-free evaluation and inspection of ML models&#x0201d;</article-title>. <source>GigaScience Database</source>, <year>2024</year>; <pub-id pub-id-type="doi">10.5524/102501</pub-id>.</mixed-citation></ref></ref-list></back><sub-article article-type="author-comment" id="d1e2104"><front><journal-meta><journal-id journal-id-type="nlm-ta">GigaByte</journal-id><journal-id journal-id-type="iso-abbrev">GigaByte</journal-id><journal-id journal-id-type="publisher-id">Gigabyte</journal-id><journal-title-group><journal-title>GigaByte</journal-title></journal-title-group><issn pub-type="epub">2709-4715</issn><publisher><publisher-name>Gigascience Press</publisher-name></publisher></journal-meta>
<article-meta><title-group><article-title>Article Submission</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Raimondo</surname><given-names>Federico</given-names><prefix>Dr</prefix></name><role>Author</role></contrib></contrib-group><history><date date-type="event_start_date"><day>13</day><month>11</month><year>2023</year></date><date date-type="event_complete_date"><day>13</day><month>11</month><year>2023</year></date></history></article-meta></front></sub-article><sub-article article-type="editor-report" id="d1e2110"><front><journal-meta><journal-id journal-id-type="nlm-ta">GigaByte</journal-id><journal-id journal-id-type="iso-abbrev">GigaByte</journal-id><journal-id journal-id-type="publisher-id">Gigabyte</journal-id><journal-title-group><journal-title>GigaByte</journal-title></journal-title-group><issn pub-type="epub">2709-4715</issn><publisher><publisher-name>Gigascience Press</publisher-name></publisher></journal-meta>
<article-meta><title-group><article-title>Assign Handling Editor</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Edmunds</surname><given-names>Scott</given-names><prefix>Dr</prefix></name><role>Editor in Chief</role></contrib></contrib-group><history><date date-type="event_start_date"><day>14</day><month>11</month><year>2023</year></date><date date-type="event_complete_date"><day>14</day><month>11</month><year>2023</year></date></history></article-meta></front></sub-article><sub-article article-type="editor-report" id="d1e2116"><front><journal-meta><journal-id journal-id-type="nlm-ta">GigaByte</journal-id><journal-id journal-id-type="iso-abbrev">GigaByte</journal-id><journal-id journal-id-type="publisher-id">Gigabyte</journal-id><journal-title-group><journal-title>GigaByte</journal-title></journal-title-group><issn pub-type="epub">2709-4715</issn><publisher><publisher-name>Gigascience Press</publisher-name></publisher></journal-meta>
<article-meta><title-group><article-title>Editor Assess MS</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Zhou</surname><given-names>Hongling</given-names><prefix>Ms</prefix></name><role>Handling Editor</role></contrib></contrib-group><history><date date-type="event_start_date"><day>14</day><month>11</month><year>2023</year></date><date date-type="event_complete_date"><day>22</day><month>11</month><year>2023</year></date></history></article-meta></front></sub-article><sub-article article-type="editor-report" id="d1e2122"><front><journal-meta><journal-id journal-id-type="nlm-ta">GigaByte</journal-id><journal-id journal-id-type="iso-abbrev">GigaByte</journal-id><journal-id journal-id-type="publisher-id">Gigabyte</journal-id><journal-title-group><journal-title>GigaByte</journal-title></journal-title-group><issn pub-type="epub">2709-4715</issn><publisher><publisher-name>Gigascience Press</publisher-name></publisher></journal-meta>
<article-meta><title-group><article-title>Curator Assess MS</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Armit</surname><given-names>Chris</given-names><prefix>Dr</prefix></name><role>Curator</role></contrib></contrib-group><history><date date-type="event_start_date"><day>22</day><month>11</month><year>2023</year></date><date date-type="event_complete_date"><day>25</day><month>11</month><year>2023</year></date></history></article-meta></front></sub-article><sub-article article-type="reviewer-report" id="d1e2128"><front><journal-meta><journal-id journal-id-type="nlm-ta">GigaByte</journal-id><journal-id journal-id-type="iso-abbrev">GigaByte</journal-id><journal-id journal-id-type="publisher-id">Gigabyte</journal-id><journal-title-group><journal-title>GigaByte</journal-title></journal-title-group><issn pub-type="epub">2709-4715</issn><publisher><publisher-name>Gigascience Press</publisher-name></publisher></journal-meta>
<article-meta><title-group><article-title>Review MS</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Liu</surname><given-names>Juntao</given-names><prefix>Professor</prefix></name><role>Reviewer 1</role></contrib></contrib-group><history><date date-type="event_start_date"><day>25</day><month>12</month><year>2023</year></date><date date-type="event_complete_date"><day>30</day><month>12</month><year>2023</year></date></history></article-meta></front><body><p>
<array><tbody><tr><td rowspan="1" colspan="1">Reviewer name and names of any other individual's who aided in reviewer</td><td rowspan="1" colspan="1">Juntao Liu</td></tr><tr><td rowspan="1" colspan="1">Do you understand and agree to our policy of having open and named reviews, and having your review included with the published manuscript. (If no, please inform the editor that you cannot review this manuscript.)</td><td rowspan="1" colspan="1">Yes</td></tr><tr><td rowspan="1" colspan="1">Is the language of sufficient quality?</td><td rowspan="1" colspan="1">Yes</td></tr><tr><td rowspan="1" colspan="1">Please add additional comments on language quality to clarify if needed</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Is there a clear statement of need explaining what problems the software is designed to solve and who the target audience is? </td><td rowspan="1" colspan="1">Yes</td></tr><tr><td rowspan="1" colspan="1">Additional Comments</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Is the source code available, and has an appropriate Open Source Initiative license &#x0003c;a href="https://opensource.org/licenses" target="_blank"&#x0003e;(https://opensource.org/licenses)&#x0003c;/a&#x0003e; been assigned to the code?</td><td rowspan="1" colspan="1">Yes</td></tr><tr><td rowspan="1" colspan="1">Additional Comments</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">As Open Source Software are there guidelines on how to contribute, report issues or seek support on the code?</td><td rowspan="1" colspan="1">Yes</td></tr><tr><td rowspan="1" colspan="1">Additional Comments</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Is the code executable?</td><td rowspan="1" colspan="1">Yes</td></tr><tr><td rowspan="1" colspan="1">Additional Comments</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Is installation/deployment sufficiently outlined in the paper and documentation, and does it proceed as outlined?</td><td rowspan="1" colspan="1">Yes</td></tr><tr><td rowspan="1" colspan="1">Additional Comments</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Is the documentation provided clear and user friendly?</td><td rowspan="1" colspan="1">Yes</td></tr><tr><td rowspan="1" colspan="1">Additional Comments</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Is there enough clear information in the documentation to install, run and test this tool, including information on where to seek help if required?</td><td rowspan="1" colspan="1">Yes</td></tr><tr><td rowspan="1" colspan="1">Additional Comments</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Is there a clearly-stated list of dependencies, and is the core functionality of the software documented to a satisfactory level?</td><td rowspan="1" colspan="1">Yes</td></tr><tr><td rowspan="1" colspan="1">Additional Comments</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Have any claims of performance been sufficiently tested and compared to other commonly-used packages? </td><td rowspan="1" colspan="1">Yes</td></tr><tr><td rowspan="1" colspan="1">Additional Comments</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Is test data available, either included with the submission or openly available via cited third party sources (e.g. accession numbers, data DOIs)?</td><td rowspan="1" colspan="1">Yes</td></tr><tr><td rowspan="1" colspan="1">Additional Comments</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Are there (ideally real world) examples demonstrating use of the software? </td><td rowspan="1" colspan="1">Yes</td></tr><tr><td rowspan="1" colspan="1">Additional Comments</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Is automated testing used or are there manual steps described so that the functionality of the software can be verified?</td><td rowspan="1" colspan="1">Yes</td></tr><tr><td rowspan="1" colspan="1">Additional Comments</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Any Additional Overall Comments to the Author</td><td rowspan="1" colspan="1">Julearn is an open-source Python library that allows domain experts without in-depth ML and programming language training to design and evaluate complex ML pipelines without encountering in common pitfalls, such as data leakage and overfitting of hyperparameters. I acknowledged it is a user-friendly software and deserves more attention. Yet, I have some minor concerns.&#x0000d; &#x0000d; 1. It is advisable to include the documentation website of the software in abstract, as comprehensive documentation serves as a crucial resource for users seeking to utilize the software effectively and efficiently.&#x0000d; &#x0000d; 2. When I run the first example mentioned in the manuscript, I got some problems below:&#x0000d; 1) I run the first step, 1_get_data.py to download the data to the path of data/1_brain_age. But when I executed the second step, 2_predict_brain_age.py, I got the error &#x0201c;FileNotFoundError: [Errno 2] No such file or directory: 'data/ixi.S4_R8.csv'&#x0201d;. I changed the code in line 19 of the 2_predict_brain_age.py, data_dir=Path(__file__).parent.parent/"data", to data_dir=Path(__file__).parent.parent/"data"/"1_brain_age". Then it can run successfully.&#x0000d; 2) Before I run the 2_predict_brain_age.py, I got the &#x0201c;ModuleNotFoundError: No module named 'skrvm'&#x0201d; error. I don&#x02019;t know how to install this python library until check in the 2_predict_brain_age.py file. Providing a README file within the directory of each example that details the steps of executing the example code would be useful, as it would allow users to easily download the data required and comprehend the installation process for required libraries and dependencies.&#x0000d; 3) As well as the second example, I need to check the 1_prcess_data.py to known how to download the ADNI data. Still you can write a readme file for each example.&#x0000d; &#x0000d; 3. I found that Figure 3 appears before Figure 2. Maybe you can change the orders of this two Figures.&#x0000d; &#x0000d; 4. The codes in Figure 1 and 2 are intended to show the differences between julearn and sklearn. Instead of the Figures, you can just put the code in an in-line text box, maybe it is clearer. Furthermore, code annotations can be included to provide guidance on potential applications of this code to users.&#x0000d; &#x0000d; 5. In the Inspection and Analysis section, you mentioned that Julearn includes two functionalities: a preprocess_until function and Inspector class. Maybe you can also provide a code in an in-line text box to demonstrate how these two functionalities can be used.</td></tr><tr><td rowspan="1" colspan="1">Recommendation</td><td rowspan="1" colspan="1">Minor Revisions</td></tr></tbody></array>
</p></body></sub-article><sub-article article-type="reviewer-report" id="d1e2134"><front><journal-meta><journal-id journal-id-type="nlm-ta">GigaByte</journal-id><journal-id journal-id-type="iso-abbrev">GigaByte</journal-id><journal-id journal-id-type="publisher-id">Gigabyte</journal-id><journal-title-group><journal-title>GigaByte</journal-title></journal-title-group><issn pub-type="epub">2709-4715</issn><publisher><publisher-name>Gigascience Press</publisher-name></publisher></journal-meta>
<article-meta><title-group><article-title>Review MS</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Fang</surname><given-names>Shuangsang</given-names><prefix>Dr</prefix></name><role>Reviewer 2</role></contrib></contrib-group><history><date date-type="event_start_date"><day>27</day><month>12</month><year>2023</year></date><date date-type="event_complete_date"><day>02</day><month>1</month><year>2024</year></date></history></article-meta></front><body><p>
<array><tbody><tr><td rowspan="1" colspan="1">Reviewer name and names of any other individual's who aided in reviewer</td><td rowspan="1" colspan="1">Shuangsang Fang</td></tr><tr><td rowspan="1" colspan="1">Do you understand and agree to our policy of having open and named reviews, and having your review included with the published manuscript. (If no, please inform the editor that you cannot review this manuscript.)</td><td rowspan="1" colspan="1">Yes</td></tr><tr><td rowspan="1" colspan="1">Is the language of sufficient quality?</td><td rowspan="1" colspan="1">Yes</td></tr><tr><td rowspan="1" colspan="1">Please add additional comments on language quality to clarify if needed</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Is there a clear statement of need explaining what problems the software is designed to solve and who the target audience is? </td><td rowspan="1" colspan="1">Yes</td></tr><tr><td rowspan="1" colspan="1">Additional Comments</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Is the source code available, and has an appropriate Open Source Initiative license &#x0003c;a href="https://opensource.org/licenses" target="_blank"&#x0003e;(https://opensource.org/licenses)&#x0003c;/a&#x0003e; been assigned to the code?</td><td rowspan="1" colspan="1">Yes</td></tr><tr><td rowspan="1" colspan="1">Additional Comments</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">As Open Source Software are there guidelines on how to contribute, report issues or seek support on the code?</td><td rowspan="1" colspan="1">Yes</td></tr><tr><td rowspan="1" colspan="1">Additional Comments</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Is the code executable?</td><td rowspan="1" colspan="1">Unable to test</td></tr><tr><td rowspan="1" colspan="1">Additional Comments</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Is installation/deployment sufficiently outlined in the paper and documentation, and does it proceed as outlined?</td><td rowspan="1" colspan="1">Unable to test</td></tr><tr><td rowspan="1" colspan="1">Additional Comments</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Is the documentation provided clear and user friendly?</td><td rowspan="1" colspan="1">Yes</td></tr><tr><td rowspan="1" colspan="1">Additional Comments</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Additional Comments</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Is there a clearly-stated list of dependencies, and is the core functionality of the software documented to a satisfactory level?</td><td rowspan="1" colspan="1">Yes</td></tr><tr><td rowspan="1" colspan="1">Additional Comments</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Have any claims of performance been sufficiently tested and compared to other commonly-used packages? </td><td rowspan="1" colspan="1">Yes</td></tr><tr><td rowspan="1" colspan="1">Additional Comments</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Is test data available, either included with the submission or openly available via cited third party sources (e.g. accession numbers, data DOIs)?</td><td rowspan="1" colspan="1">Yes</td></tr><tr><td rowspan="1" colspan="1">Additional Comments</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Are there (ideally real world) examples demonstrating use of the software? </td><td rowspan="1" colspan="1">Yes</td></tr><tr><td rowspan="1" colspan="1">Additional Comments</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Additional Comments</td><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">Any Additional Overall Comments to the Author</td><td rowspan="1" colspan="1">The paper titled "Julearn: an easy-to-use library for leakage-free evaluation and inspection of ML models" by Sami Hamdan et al. introduces a library that empowers researchers to design and evaluate complex ML pipelines. This library provides users with a user-friendly environment that incorporates safeguards against common ML pitfalls. Consequently, it offers convenience and usefulness to its users. Nonetheless, there are a few concerns that need to be addressed:&#x0000d; 1.The authors should clearly articulate the relationship between Julearn and Scikit-learn (sklearn) and perform a comparative analysis of their shared and distinctive features.&#x0000d; 2.It would be beneficial to include a table or figure that provides a comprehensive list of functions or ML models available in Julearn, enabling users to quickly familiarize themselves with the library's capabilities.&#x0000d; 3.While the Visualization component of Julearn currently only offers the "plot_scores" function, the inclusion of additional plotting functions would be advantageous in providing users with a more comprehensive visualization toolkit.&#x0000d; &#x0000d; By addressing these concerns, the usability and effectiveness of Julearn can be further enhanced, ensuring a more robust and user-friendly experience for researchers utilizing the library.</td></tr><tr><td rowspan="1" colspan="1">Recommendation</td><td rowspan="1" colspan="1">Minor Revisions</td></tr></tbody></array>
</p></body></sub-article><sub-article article-type="editor-report" id="d1e2141"><front><journal-meta><journal-id journal-id-type="nlm-ta">GigaByte</journal-id><journal-id journal-id-type="iso-abbrev">GigaByte</journal-id><journal-id journal-id-type="publisher-id">Gigabyte</journal-id><journal-title-group><journal-title>GigaByte</journal-title></journal-title-group><issn pub-type="epub">2709-4715</issn><publisher><publisher-name>Gigascience Press</publisher-name></publisher></journal-meta>
<article-meta><title-group><article-title>Editor Decision</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Zhou</surname><given-names>Hongling</given-names><prefix>Ms</prefix></name><role>Handling Editor</role></contrib></contrib-group><history><date date-type="event_start_date"><day>02</day><month>1</month><year>2024</year></date><date date-type="event_complete_date"><day>03</day><month>1</month><year>2024</year></date></history></article-meta></front></sub-article><sub-article article-type="author-comment" id="d1e1845"><front><journal-meta><journal-id journal-id-type="nlm-ta">GigaByte</journal-id><journal-id journal-id-type="iso-abbrev">GigaByte</journal-id><journal-id journal-id-type="publisher-id">Gigabyte</journal-id><journal-title-group><journal-title>GigaByte</journal-title></journal-title-group><issn pub-type="epub">2709-4715</issn><publisher><publisher-name>Gigascience Press</publisher-name></publisher></journal-meta>
<article-meta><title-group><article-title>Minor Revision</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Raimondo</surname><given-names>Federico</given-names><prefix>Dr</prefix></name><role>Author</role></contrib></contrib-group><history><date date-type="event_start_date"><day>15</day><month>1</month><year>2024</year></date><date date-type="event_complete_date"><day>25</day><month>1</month><year>2024</year></date></history></article-meta></front></sub-article><sub-article article-type="editor-report" id="d1e1851"><front><journal-meta><journal-id journal-id-type="nlm-ta">GigaByte</journal-id><journal-id journal-id-type="iso-abbrev">GigaByte</journal-id><journal-id journal-id-type="publisher-id">Gigabyte</journal-id><journal-title-group><journal-title>GigaByte</journal-title></journal-title-group><issn pub-type="epub">2709-4715</issn><publisher><publisher-name>Gigascience Press</publisher-name></publisher></journal-meta>
<article-meta><title-group><article-title>Assess Revision</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Zhou</surname><given-names>Hongling</given-names><prefix>Ms</prefix></name><role>Handling Editor</role></contrib></contrib-group><history><date date-type="event_start_date"><day>25</day><month>1</month><year>2024</year></date><date date-type="event_complete_date"><day>30</day><month>1</month><year>2024</year></date></history></article-meta></front></sub-article><sub-article article-type="editor-report" id="d1e1857"><front><journal-meta><journal-id journal-id-type="nlm-ta">GigaByte</journal-id><journal-id journal-id-type="iso-abbrev">GigaByte</journal-id><journal-id journal-id-type="publisher-id">Gigabyte</journal-id><journal-title-group><journal-title>GigaByte</journal-title></journal-title-group><issn pub-type="epub">2709-4715</issn><publisher><publisher-name>Gigascience Press</publisher-name></publisher></journal-meta>
<article-meta><title-group><article-title>Final Data Preparation</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Tuli</surname><given-names>Mary-Ann</given-names><prefix>Ms</prefix></name><role>Curator</role></contrib></contrib-group><history><date date-type="event_start_date"><day>31</day><month>1</month><year>2024</year></date><date date-type="event_complete_date"><day>08</day><month>2</month><year>2024</year></date></history></article-meta></front></sub-article><sub-article article-type="editor-report" id="d1e1863"><front><journal-meta><journal-id journal-id-type="nlm-ta">GigaByte</journal-id><journal-id journal-id-type="iso-abbrev">GigaByte</journal-id><journal-id journal-id-type="publisher-id">Gigabyte</journal-id><journal-title-group><journal-title>GigaByte</journal-title></journal-title-group><issn pub-type="epub">2709-4715</issn><publisher><publisher-name>Gigascience Press</publisher-name></publisher></journal-meta>
<article-meta><title-group><article-title>Editor Decision</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Zhou</surname><given-names>Hongling</given-names><prefix>Ms</prefix></name><role>Handling Editor</role></contrib></contrib-group><history><date date-type="event_start_date"><day>08</day><month>2</month><year>2024</year></date><date date-type="event_complete_date"><day>27</day><month>2</month><year>2024</year></date></history></article-meta></front></sub-article><sub-article article-type="editor-report" id="d1e1869"><front><journal-meta><journal-id journal-id-type="nlm-ta">GigaByte</journal-id><journal-id journal-id-type="iso-abbrev">GigaByte</journal-id><journal-id journal-id-type="publisher-id">Gigabyte</journal-id><journal-title-group><journal-title>GigaByte</journal-title></journal-title-group><issn pub-type="epub">2709-4715</issn><publisher><publisher-name>Gigascience Press</publisher-name></publisher></journal-meta>
<article-meta><title-group><article-title>Accept</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Edmunds</surname><given-names>Scott</given-names><prefix>Dr</prefix></name><role>Editor in Chief</role></contrib></contrib-group><history><date date-type="event_start_date"><day>27</day><month>2</month><year>2024</year></date><date date-type="event_complete_date"><day>27</day><month>2</month><year>2024</year></date></history></article-meta></front><body><p>
<array><tbody><tr><td rowspan="1" colspan="1">Editor&#x02019;s Assessment</td><td rowspan="1" colspan="1">This Technical Release (Software) paper presents Julearn, an open-source Python library, that allow neuroscience researchers to design and evaluate complex machine learning (ML) pipelines without encountering in common pitfalls such as data leakage and overfitting of hyperparameters. Created to be easy-to-use, accessible for researchers with diverse backgrounds, and to create reproducible results. Bridging the gap between domain expertise in neuroscience and application of ML pipelines. Towards that goal, julearn provides a simple interface only using two key API points. After some debugging and improvements to the documentation testing and review was positive, and a few useful examples are provided in the paper. Additional functionalities are also provided to guide and help users to inspect and evaluate the resulting cross validation scores. </td></tr></tbody></array>
</p></body></sub-article><sub-article article-type="editor-report" id="d1e1875"><front><journal-meta><journal-id journal-id-type="nlm-ta">GigaByte</journal-id><journal-id journal-id-type="iso-abbrev">GigaByte</journal-id><journal-id journal-id-type="publisher-id">Gigabyte</journal-id><journal-title-group><journal-title>GigaByte</journal-title></journal-title-group><issn pub-type="epub">2709-4715</issn><publisher><publisher-name>Gigascience Press</publisher-name></publisher></journal-meta>
<article-meta><title-group><article-title>Export to Production</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Edmunds</surname><given-names>Scott</given-names><prefix>Dr</prefix></name><role>Editor in Chief</role></contrib></contrib-group><history><date date-type="event_start_date"><day>27</day><month>2</month><year>2024</year></date><date date-type="event_complete_date"><day>27</day><month>2</month><year>2024</year></date></history></article-meta></front></sub-article></article>