<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN" "JATS-archivearticle1-mathml3.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-journalpublishing1.dtd?><?SourceDTD.Version 39.96?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="iso-abbrev">PLoS Comput. Biol</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">7237030</article-id><article-id pub-id-type="pmid">32324731</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1007617</article-id><article-id pub-id-type="publisher-id">PCOMPBIOL-D-19-00927</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Information Technology</subject><subj-group><subject>Natural Language Processing</subject><subj-group><subject>Word Embedding</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Biochemistry</subject><subj-group><subject>Proteins</subject><subj-group><subject>Protein Interactions</subject><subj-group><subject>Protein-Protein Interactions</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Pharmacology</subject><subj-group><subject>Drug Interactions</subject><subj-group><subject>Drug-Drug Interactions</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Linguistics</subject><subj-group><subject>Semantics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Artificial Intelligence</subject><subj-group><subject>Machine Learning</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Artificial Intelligence</subject><subj-group><subject>Machine Learning</subject><subj-group><subject>Deep Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Memory</subject><subj-group><subject>Memory Recall</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and Memory</subject><subj-group><subject>Memory</subject><subj-group><subject>Memory Recall</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Artificial Intelligence</subject><subj-group><subject>Artificial Neural Networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Computational Biology</subject><subj-group><subject>Computational Neuroscience</subject><subj-group><subject>Artificial Neural Networks</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Computational Neuroscience</subject><subj-group><subject>Artificial Neural Networks</subject></subj-group></subj-group></subj-group></subj-group></article-categories><title-group><article-title>BioConceptVec: Creating and evaluating literature-based biomedical concept embeddings on a large scale</article-title><alt-title alt-title-type="running-head">Biomedical concept embeddings in bioinformatics and biomedical text mining applications</alt-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-6036-1516</contrib-id><name><surname>Chen</surname><given-names>Qingyu</given-names></name><role content-type="http://credit.casrai.org/">Conceptualization</role><role content-type="http://credit.casrai.org/">Data curation</role><role content-type="http://credit.casrai.org/">Formal analysis</role><role content-type="http://credit.casrai.org/">Investigation</role><role content-type="http://credit.casrai.org/">Methodology</role><role content-type="http://credit.casrai.org/">Software</role><role content-type="http://credit.casrai.org/">Validation</role><role content-type="http://credit.casrai.org/">Writing &#x02013; original draft</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff001"/></contrib><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-2015-3939</contrib-id><name><surname>Lee</surname><given-names>Kyubum</given-names></name><role content-type="http://credit.casrai.org/">Data curation</role><role content-type="http://credit.casrai.org/">Formal analysis</role><role content-type="http://credit.casrai.org/">Validation</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff001"/></contrib><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-0369-4979</contrib-id><name><surname>Yan</surname><given-names>Shankai</given-names></name><role content-type="http://credit.casrai.org/">Data curation</role><role content-type="http://credit.casrai.org/">Formal analysis</role><role content-type="http://credit.casrai.org/">Validation</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff001"/></contrib><contrib contrib-type="author"><name><surname>Kim</surname><given-names>Sun</given-names></name><role content-type="http://credit.casrai.org/">Data curation</role><role content-type="http://credit.casrai.org/">Formal analysis</role><role content-type="http://credit.casrai.org/">Investigation</role><role content-type="http://credit.casrai.org/">Methodology</role><role content-type="http://credit.casrai.org/">Software</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff001"/></contrib><contrib contrib-type="author"><name><surname>Wei</surname><given-names>Chih-Hsuan</given-names></name><role content-type="http://credit.casrai.org/">Formal analysis</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff001"/></contrib><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-9998-916X</contrib-id><name><surname>Lu</surname><given-names>Zhiyong</given-names></name><role content-type="http://credit.casrai.org/">Conceptualization</role><role content-type="http://credit.casrai.org/">Investigation</role><role content-type="http://credit.casrai.org/">Methodology</role><role content-type="http://credit.casrai.org/">Project administration</role><role content-type="http://credit.casrai.org/">Supervision</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="corresp" rid="cor001">*</xref><xref ref-type="aff" rid="aff001"/></contrib></contrib-group><aff id="aff001"><addr-line>National Center for Biotechnology Information (NCBI), National Library of Medicine (NLM), National Institutes of Health (NIH), Bethesda, Maryland, United States of America</addr-line></aff><contrib-group><contrib contrib-type="editor"><name><surname>Kann</surname><given-names>Maricel G.</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1"><addr-line>University of Maryland Baltimore County, UNITED STATES</addr-line></aff><author-notes><fn fn-type="COI-statement" id="coi001"><p>The authors have declared that no competing interests exist.</p></fn><corresp id="cor001">* E-mail: <email>zhiyong.lu@nih.gov</email></corresp></author-notes><pub-date pub-type="epub"><day>23</day><month>4</month><year>2020</year></pub-date><pub-date pub-type="collection"><month>4</month><year>2020</year></pub-date><volume>16</volume><issue>4</issue><elocation-id>e1007617</elocation-id><history><date date-type="received"><day>6</day><month>6</month><year>2019</year></date><date date-type="accepted"><day>19</day><month>12</month><year>2019</year></date></history><permissions><license xlink:href="https://creativecommons.org/publicdomain/zero/1.0/"><license-p>This is an open access article, free of all copyright, and may be freely reproduced, distributed, transmitted, modified, built upon, or otherwise used by anyone for any lawful purpose. The work is made available under the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">Creative Commons CC0</ext-link> public domain dedication.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="pcbi.1007617.pdf"/><abstract><p>A massive number of biological entities, such as genes and mutations, are mentioned in the biomedical literature. The capturing of the semantic relatedness of biological entities is vital to many biological applications, such as protein-protein interaction prediction and literature-based discovery. Concept embeddings&#x02014;which involve the learning of vector representations of concepts using machine learning models&#x02014;have been employed to capture the semantics of concepts. To develop concept embeddings, named-entity recognition (NER) tools are first used to identify and normalize concepts from the literature, and then different machine learning models are used to train the embeddings. Despite multiple attempts, existing biomedical concept embeddings generally suffer from suboptimal NER tools, small-scale evaluation, and limited availability. In response, we employed high-performance machine learning-based NER tools for concept recognition and trained our concept embeddings, BioConceptVec, via four different machine learning models on ~30 million PubMed abstracts. BioConceptVec covers over 400,000 biomedical concepts mentioned in the literature and is of the largest among the publicly available biomedical concept embeddings to date. To evaluate the validity and utility of BioConceptVec, we respectively performed two intrinsic evaluations (identifying related concepts based on drug-gene and gene-gene interactions) and two extrinsic evaluations (protein-protein interaction prediction and drug-drug interaction extraction), collectively using over 25 million instances from nine independent datasets (17 million instances from six intrinsic evaluation tasks and 8 million instances from three extrinsic evaluation tasks), which is, by far, the most comprehensive to our best knowledge. The intrinsic evaluation results demonstrate that BioConceptVec consistently has, by a large margin, better performance than existing concept embeddings in identifying similar and related concepts. More importantly, the extrinsic evaluation results demonstrate that using BioConceptVec with advanced deep learning models can significantly improve performance in downstream bioinformatics studies and biomedical text-mining applications. Our BioConceptVec embeddings and benchmarking datasets are publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/ncbi-nlp/BioConceptVec">https://github.com/ncbi-nlp/BioConceptVec</ext-link>.</p></abstract><abstract abstract-type="summary"><title>Author summary</title><p>Capturing the semantics of related biological concepts, such as genes and mutations, is of significant importance to many research tasks in computational biology such as protein-protein interaction detection, gene-drug association prediction, and biomedical literature-based discovery. Here, we propose to leverage state-of-the-art text mining tools and machine learning models to learn the semantics via vector representations (aka. embeddings) of over 400,000 biological concepts mentioned in the entire PubMed abstracts. Our learned embeddings, namely BioConceptVec, can capture related concepts based on their surrounding contextual information in the literature, which is beyond exact term match or co-occurrence-based methods. BioConceptVec has been thoroughly evaluated in multiple bioinformatics tasks consisting of over 25 million instances from nine different biological datasets. The evaluation results demonstrate that BioConceptVec has better performance than existing methods in all tasks. Finally, BioConceptVec is made freely available to the research community and general public.</p></abstract><funding-group><award-group id="award001"><funding-source><institution>the Intramural Research Program of the NIH, National Library of Medicine</institution></funding-source><principal-award-recipient><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-6036-1516</contrib-id><name><surname>Chen</surname><given-names>Qingyu</given-names></name></principal-award-recipient></award-group><award-group id="award002"><funding-source><institution>the Intramural Research Program of the NIH, National Library of Medicine</institution></funding-source><principal-award-recipient><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-2015-3939</contrib-id><name><surname>Lee</surname><given-names>Kyubum</given-names></name></principal-award-recipient></award-group><award-group id="award003"><funding-source><institution>the Intramural Research Program of the NIH, National Library of Medicine</institution></funding-source><principal-award-recipient><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-0369-4979</contrib-id><name><surname>Yan</surname><given-names>Shankai</given-names></name></principal-award-recipient></award-group><award-group id="award004"><funding-source><institution>the Intramural Research Program of the NIH, National Library of Medicine</institution></funding-source><principal-award-recipient><name><surname>Kim</surname><given-names>Sun</given-names></name></principal-award-recipient></award-group><award-group id="award005"><funding-source><institution>the Intramural Research Program of the NIH, National Library of Medicine</institution></funding-source><principal-award-recipient><name><surname>Wei</surname><given-names>Chih-Hsuan</given-names></name></principal-award-recipient></award-group><award-group id="award006"><funding-source><institution>the Intramural Research Program of the NIH, National Library of Medicine</institution></funding-source><principal-award-recipient><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-9998-916X</contrib-id><name><surname>Lu</surname><given-names>Zhiyong</given-names></name></principal-award-recipient></award-group><funding-statement>This research was supported by the Intramural Research Program of the NIH, National Library of Medicine. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><fig-count count="6"/><table-count count="7"/><page-count count="18"/></counts><custom-meta-group><custom-meta><meta-name>PLOS Publication Stage</meta-name><meta-value>vor-update-to-uncorrected-proof</meta-value></custom-meta><custom-meta><meta-name>Publication Update</meta-name><meta-value>2020-05-19</meta-value></custom-meta><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>All the models and datasets are publicly available via <ext-link ext-link-type="uri" xlink:href="https://github.com/ncbi-nlp/BioConceptVec">https://github.com/ncbi-nlp/BioConceptVec</ext-link>.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>All the models and datasets are publicly available via <ext-link ext-link-type="uri" xlink:href="https://github.com/ncbi-nlp/BioConceptVec">https://github.com/ncbi-nlp/BioConceptVec</ext-link>.</p></notes></front><body><sec sec-type="intro" id="sec001"><title>Introduction</title><p>In the biomedical domain, one primary application of text mining is to extract knowledge within the biomedical literature automatically [<xref rid="pcbi.1007617.ref001" ref-type="bibr">1</xref>]. Specifically, identifying important concepts (mentioned in the literature, such as gene/proteins, diseases, and mutations, is critical to biocuration [<xref rid="pcbi.1007617.ref002" ref-type="bibr">2</xref>], literature-based knowledge discovery [<xref rid="pcbi.1007617.ref003" ref-type="bibr">3</xref>], and many downstream applications [<xref rid="pcbi.1007617.ref004" ref-type="bibr">4</xref>&#x02013;<xref rid="pcbi.1007617.ref006" ref-type="bibr">6</xref>]. Previous studies have used different words such as concepts, entities, names, and mentions to refer to the same topic in the biomedical domain. Here, we use <italic>bio-concepts</italic> for consistency. Similar to the use of word embeddings, capturing the representation of bio-concepts plays a vital role in biomedical applications such as biomedical relation extraction [<xref rid="pcbi.1007617.ref007" ref-type="bibr">7</xref>] and document classification [<xref rid="pcbi.1007617.ref008" ref-type="bibr">8</xref>]. Existing studies use the term <italic>concept embeddings</italic>, which is a special kind of word embedding [<xref rid="pcbi.1007617.ref009" ref-type="bibr">9</xref>&#x02013;<xref rid="pcbi.1007617.ref011" ref-type="bibr">11</xref>]. According to the literature, a concept embedding may contain only the concept vectors [<xref rid="pcbi.1007617.ref010" ref-type="bibr">10</xref>], or it may contain vectors of both concepts and common words [<xref rid="pcbi.1007617.ref011" ref-type="bibr">11</xref>]. Named entity recognition (NER) tools or concept dictionaries are often used to identify and normalize concepts in a consistent format [<xref rid="pcbi.1007617.ref010" ref-type="bibr">10</xref>].</p><p>Since 2014, word embedding models have revolutionized how to represent text. In these models, each word is represented as a high dimensional vector [<xref rid="pcbi.1007617.ref007" ref-type="bibr">7</xref>, <xref rid="pcbi.1007617.ref008" ref-type="bibr">8</xref>, <xref rid="pcbi.1007617.ref012" ref-type="bibr">12</xref>, <xref rid="pcbi.1007617.ref013" ref-type="bibr">13</xref>]. The vector representations are learned on large-scale free text corpora via unsupervised learning. Primary methods include training the embeddings based on (1) averaged surrounding context words, such as the continuous bag-of-words (cbow) model in word2vec [<xref rid="pcbi.1007617.ref014" ref-type="bibr">14</xref>], (2) weighted context words, such as the skip-gram model in word2vec, (3) global co-occurrence statistics, such as GloVe [<xref rid="pcbi.1007617.ref015" ref-type="bibr">15</xref>], and (4) word n-grams, such as fastText [<xref rid="pcbi.1007617.ref016" ref-type="bibr">16</xref>]. The use of vector representations can capture related words from different lexicons, such as cancer and tumor. This overcomes the limitations of traditional bag-of-words approaches that rely on exact term matching [<xref rid="pcbi.1007617.ref017" ref-type="bibr">17</xref>]. To date, text-mining applications have rapidly adopted word embeddings. For instance, the use of embeddings have shown promising performance in biomedical applications such as biomedical document classification [<xref rid="pcbi.1007617.ref018" ref-type="bibr">18</xref>], sentence retrieval [<xref rid="pcbi.1007617.ref019" ref-type="bibr">19</xref>], and question answering [<xref rid="pcbi.1007617.ref020" ref-type="bibr">20</xref>].</p><p>It is known that biomedical concepts have a high degree of ambiguity [<xref rid="pcbi.1007617.ref021" ref-type="bibr">21</xref>]. The same words can be used to describe different types of concepts in free text; for example, AP2 can be the name of a gene (<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/gene/?term=2167">https://www.ncbi.nlm.nih.gov/gene/?term=2167</ext-link>), a chemical (<ext-link ext-link-type="uri" xlink:href="https://meshb.nlm.nih.gov/record/ui?ui=C417523">https://meshb.nlm.nih.gov/record/ui?ui=C417523</ext-link>), or a cell-line (<ext-link ext-link-type="uri" xlink:href="https://web.expasy.org/cellosaurus/CVCL_1147">https://web.expasy.org/cellosaurus/CVCL_1147</ext-link>). Conversely, the same concepts can have different names; for example, the HER2 gene has at least 10 different synonyms mentioned in text (<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/gene/2064">https://www.ncbi.nlm.nih.gov/gene/2064</ext-link>). In addition, a bio-concept can span multiple words; for example, <italic>serum and glucocorticoid-induced protein kinase</italic> is the name of a gene (SGK1, <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/gene/6446">https://www.ncbi.nlm.nih.gov/gene/6446</ext-link>). Therefore, accurate NER is essential prior to training concept embeddings.</p><p>We present a detailed summary of the existing bio-concept embeddings in <xref rid="pcbi.1007617.t001" ref-type="table">Table 1</xref>. These studies have used various corpora (mainly electronic health records (EHR), combined with medical claims, biomedical corpora, or Wikipedia) and several training methods (mainly word2vec, while some used GloVe and fastText) to train concept embeddings. Overall, the primary method paradigm is consistent among these studies and generally involves two steps. In the first step, NER tools are applied to identify and normalize target concepts and to replace the mentions in the text as a preprocessing to the corpora. In the second (embedded training) step, embedding training occurs, whereby standard word embedding training methods, such as word2vec, are employed. Note that we consider concept embeddings trained on knowledge bases, such as gene2vec [<xref rid="pcbi.1007617.ref022" ref-type="bibr">22</xref>], as different work because knowledge bases are distinct from free-text collections. For example, knowledge bases contain concepts already curated either manually or semi-automatically; therefore, training concept embeddings via knowledge bases does not require NER tools. In addition, the relationships between concepts in knowledge bases already have been organized in a structured format, such as ontologies. Free text, however, is unstructured, and training embeddings on free text occurs purely in an unsupervised way. Also note that individual knowledge bases contain only specific types of concepts by design. By contrast, a wide spectrum of concept types are described in the literature.</p><table-wrap id="pcbi.1007617.t001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1007617.t001</object-id><label>Table 1</label><caption><title>An overview of biomedical concept embeddings trained on large-scale free-text corpora.</title><p>Repository: the scope of concepts. Corpora: the training collection. Note that for EHR (electronic health records) and Claims (medical claims), the size is the number of patients, whereas for Wikipedia, PubMed (abstracts), and PMC (full-text articles), the size is the number of documents. #Concepts: the number of distinct concepts in the embedding. Method: the method for training embeddings. PCA: principle component analysis. PMI: pointwise mutual information. Intrinsic evaluation: a focus on applications that directly use the similarity between the vectors produced by word embeddings, such as word-pair similarity and relatedness. Extrinsic evaluation: a focus on downstream applications that use only word embeddings as an intermediate component. For example, the last study evaluated the effectiveness of concept embeddings for heart-failure prediction. Availability: whether the studies made the embeddings publicly available (we accessed on 04/20/2019).</p></caption><alternatives><graphic id="pcbi.1007617.t001g" xlink:href="pcbi.1007617.t001"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" rowspan="2" colspan="1">Study (year)</th><th align="center" rowspan="2" colspan="1">Repository</th><th align="center" rowspan="2" colspan="1">Corpora (size)</th><th align="left" rowspan="2" colspan="1">#Concepts</th><th align="center" rowspan="2" colspan="1">Method</th><th align="center" rowspan="1" colspan="1"/><th align="center" colspan="2" rowspan="1">Evaluation</th><th align="center" rowspan="1" colspan="1"/><th align="center" rowspan="2" colspan="1">Availability</th></tr><tr><th align="center" colspan="2" rowspan="1">Intrinsic</th><th align="center" colspan="2" rowspan="1">Extrinsic</th></tr></thead><tbody><tr><td align="left" rowspan="2" colspan="1">Vine et al. (2014) [<xref rid="pcbi.1007617.ref047" ref-type="bibr">47</xref>]</td><td align="center" rowspan="2" colspan="1">UMLS</td><td align="right" rowspan="2" colspan="1">EHR (&#x0003c;20K)<break/>PubMed (0.35M)</td><td align="right" rowspan="1" colspan="1">52,102</td><td align="center" rowspan="2" colspan="1">skip-gram</td><td align="center" colspan="2" rowspan="2">Concept similarity</td><td align="center" colspan="2" rowspan="2">N</td><td align="center" rowspan="1" colspan="1">N</td></tr><tr><td align="right" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="2" colspan="1">Choi et al. (2016) [<xref rid="pcbi.1007617.ref064" ref-type="bibr">64</xref>]</td><td align="center" rowspan="2" colspan="1">ICD9CM</td><td align="right" rowspan="1" colspan="1">EHR (0.55M)</td><td align="right" rowspan="1" colspan="1">49,873</td><td align="center" rowspan="2" colspan="1">skip-gram</td><td align="center" colspan="2" rowspan="2">Concept clustering</td><td align="center" colspan="2" rowspan="2">N</td><td align="center" rowspan="1" colspan="1">N</td></tr><tr><td align="right" rowspan="1" colspan="1">Claims (0.85M)</td><td align="right" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="2" colspan="1">Choi et al. (2016) [<xref rid="pcbi.1007617.ref010" ref-type="bibr">10</xref>]</td><td align="center" rowspan="2" colspan="1">UMLS</td><td align="right" rowspan="1" colspan="1">EHR (20M)</td><td align="right" rowspan="1" colspan="1">22,705</td><td align="center" rowspan="2" colspan="1">skip-gram</td><td align="center" colspan="2" rowspan="2">Concept clustering</td><td align="center" colspan="2" rowspan="2">N</td><td align="center" rowspan="1" colspan="1">Y</td></tr><tr><td align="right" rowspan="1" colspan="1">Claims (4M)</td><td align="right" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">Yu at al. (2017) [<xref rid="pcbi.1007617.ref043" ref-type="bibr">43</xref>]</td><td align="center" rowspan="1" colspan="1">UMLS</td><td align="right" rowspan="1" colspan="1">PubMed (22M)</td><td align="right" rowspan="1" colspan="1">310,403</td><td align="center" rowspan="1" colspan="1">cbow</td><td align="center" colspan="2" rowspan="1">Concept similarity</td><td align="center" colspan="2" rowspan="1">N</td><td align="center" rowspan="1" colspan="1">Y</td></tr><tr><td align="left" rowspan="3" colspan="1">Beam et al. (2018) [<xref rid="pcbi.1007617.ref009" ref-type="bibr">9</xref>]<break/></td><td align="center" rowspan="3" colspan="1">UMLS</td><td align="right" rowspan="1" colspan="1">EHR (60M)</td><td align="right" rowspan="1" colspan="1">108,477</td><td align="center" rowspan="1" colspan="1">skip-gram</td><td align="center" colspan="2" rowspan="3">Concept similarity</td><td align="center" colspan="2" rowspan="3">N</td><td align="center" rowspan="1" colspan="1">Y</td></tr><tr><td align="right" rowspan="1" colspan="1">Claims (20M)</td><td align="right" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1">GloVe</td><td align="center" rowspan="1" colspan="1"/></tr><tr><td align="right" rowspan="1" colspan="1">PMC (1.7M)</td><td align="right" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1">PCA</td><td align="center" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">Cai at al. (2018) [<xref rid="pcbi.1007617.ref065" ref-type="bibr">65</xref>]</td><td align="center" rowspan="1" colspan="1">UMLS</td><td align="right" rowspan="1" colspan="1">EHR (2M)</td><td align="right" rowspan="1" colspan="1">47,873</td><td align="center" rowspan="1" colspan="1">cbow</td><td align="center" colspan="2" rowspan="1">Concept clustering</td><td align="center" colspan="2" rowspan="1">N</td><td align="center" rowspan="1" colspan="1">N</td></tr><tr><td align="left" rowspan="3" colspan="1">Nguyen at al. (2018) [<xref rid="pcbi.1007617.ref066" ref-type="bibr">66</xref>]</td><td align="center" rowspan="3" colspan="1">UMLS</td><td align="right" rowspan="1" colspan="1">Wikipedia (5M)</td><td align="right" rowspan="1" colspan="1">659,873</td><td align="center" rowspan="3" colspan="1">cbow</td><td align="center" colspan="2" rowspan="3">Concept similarity</td><td align="center" colspan="2" rowspan="3">N</td><td align="center" rowspan="1" colspan="1">N</td></tr><tr><td align="right" rowspan="1" colspan="1">PubMed (24M)</td><td align="right" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/></tr><tr><td align="right" rowspan="1" colspan="1">PMC (3M)</td><td align="right" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="3" colspan="1">Xiang at al. (2019) [<xref rid="pcbi.1007617.ref008" ref-type="bibr">8</xref>]</td><td align="center" rowspan="3" colspan="1">UMLS</td><td align="right" rowspan="3" colspan="1">EHR (50M)</td><td align="right" rowspan="1" colspan="1">30,348</td><td align="center" rowspan="1" colspan="1">skip-gram</td><td align="center" colspan="2" rowspan="3">Concept clustering</td><td align="center" colspan="2" rowspan="3">Y</td><td align="center" rowspan="1" colspan="1">N</td></tr><tr><td align="right" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1">PMI</td><td align="center" rowspan="1" colspan="1"/></tr><tr><td align="right" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1">fastText</td><td align="center" rowspan="1" colspan="1"/></tr></tbody></table></alternatives></table-wrap><p>Despite these recent efforts, past studies share some limitations. As shown in <xref rid="pcbi.1007617.t001" ref-type="table">Table 1</xref>, existing studies used NER tools to recognize and normalize Unified Medical Language System (UMLS) concepts [<xref rid="pcbi.1007617.ref023" ref-type="bibr">23</xref>]. A long series of evaluation studies demonstrate that the effectiveness of these NER tools fluctuates dramatically for different types of UMLS concepts [<xref rid="pcbi.1007617.ref024" ref-type="bibr">24</xref>&#x02013;<xref rid="pcbi.1007617.ref028" ref-type="bibr">28</xref>]. For example, Hassanzadeh et al. evaluated the NER tools used by the studies in <xref rid="pcbi.1007617.t001" ref-type="table">Table 1</xref> and found that the F1-score ranged from 5% to 75% for different types of UMLS concepts [<xref rid="pcbi.1007617.ref024" ref-type="bibr">24</xref>]. Likewise, Re&#x000e1;tegui et al. found that the F1-score of the NER tools varied from 44% to 96% for different types of diseases [<xref rid="pcbi.1007617.ref026" ref-type="bibr">26</xref>]. Importantly, errors produced in the NER step may diminish the effectiveness of bio-concept embeddings. For example, low precision, such as a non-concept word wrongly identified as a bio-concept by NER tools, will bias the context or nearby words of the true bio-concepts when training embeddings. Similarly, low recall, such as true bio-concepts that are not identified by NER tools, will reduce the number of training instances and decrease the concept coverage of bio-concept embeddings.</p><p>Second, almost no studies had evaluated the effectiveness of concept embeddings in extrinsic evaluations. The evaluation of word embeddings can be broadly categorized into two types (i.e., intrinsic and extrinsic) [<xref rid="pcbi.1007617.ref029" ref-type="bibr">29</xref>]. Intrinsic evaluations are commonly accomplished via an unsupervised setting or using weakly supervised labels, whereas extrinsic evaluations are often performed via a supervised setting in downstream applications. As shown in <xref rid="pcbi.1007617.t001" ref-type="table">Table 1</xref>, only one study [<xref rid="pcbi.1007617.ref008" ref-type="bibr">8</xref>] performed extrinsic evaluations for heart failure, predicting whether a patient would be diagnosed as having heart failure based on the associated clinical notes. The study used a basic long short-term memory (LSTM) model with randomly initialized embedding as the baseline and replaced the randomly initialized embedding with the proposed concept embedding to compare the performance. Although the results demonstrated that the proposed concept embedding has better performance, the study (1) did not compare the results with those of other existing concept embeddings and (2) did not compare the results with those of the state-of-the-art model that had achieved the highest performance on that task [<xref rid="pcbi.1007617.ref030" ref-type="bibr">30</xref>].</p><p>Further, importantly, the existing concept embeddings are designed primarily for concepts and applications in the clinical domain, whereas concept embeddings for the biological domain remain to be developed. As shown in <xref rid="pcbi.1007617.t001" ref-type="table">Table 1</xref>, existing studies used UMLS concepts and mainly used EHR data as the training corpora. Correspondingly, the evaluation focuses on clinical applications, i.e., the evaluation datasets are generated from EHR data. For example, most of the studies evaluated the two datasets, UMNSRS (Medical Residents Relatedness Set)-Similarity [<xref rid="pcbi.1007617.ref031" ref-type="bibr">31</xref>] and UMNSRS-Relatedness [<xref rid="pcbi.1007617.ref031" ref-type="bibr">31</xref>], each consisting of ~600 pairs of clinical concepts derived from EHR data and annotated by physicians. Similarly, the above extrinsic evaluation of heart-failure prediction is also based on a patient&#x02019;s clinical notes [<xref rid="pcbi.1007617.ref008" ref-type="bibr">8</xref>]. Developing embeddings for biological concepts and applications is also important.</p><p>In response, we propose BioConceptVec, a collection of concept embeddings on primary biological concepts mentioned in the biomedical literature. <xref ref-type="fig" rid="pcbi.1007617.g001">Fig 1</xref> shows an overview of our study. Specifically, the study has three primary contributions:</p><list list-type="order"><list-item><p>To our knowledge, we are the first study to use machine learning-based NER tools to recognize and normalize biological concepts for training bio-concept embeddings. Specifically, we employed PubTator, a state-of-the-art NER system with concept annotations for the entire PubMed abstracts [<xref rid="pcbi.1007617.ref032" ref-type="bibr">32</xref>]. It contains over 400,000 concepts, which is the largest among the publicly available concept embeddings. For example, our evaluation of the human gene coverage shows that BioConceptVec covers 33% more gene concepts than the existing concept embeddings.</p></list-item><list-item><p>We conducted large-scale intrinsic and extrinsic evaluations to quantify the validity and utility of BioConceptVec. The intrinsic evaluations contain ~18 million instances from six datasets. BioConceptVec has significantly higher performance (up to 10% improvement) than the existing concept embeddings and is consistent across multiple datasets. The extrinsic evaluations cover two downstream applications: protein-protein interaction (PPI) prediction, consisting of ~8 million PPIs from the STRING database [<xref rid="pcbi.1007617.ref033" ref-type="bibr">33</xref>], and drug-drug interaction (DDI) classification, consisting of ~5,000 DDIs from a community-recognized gold standard dataset. The extrinsic evaluation results demonstrate that the deep learning models that use BioConceptVec can significantly improve the state-of-the-art performance, achieving an AUC of 0.95 for predicting PPIs and an F1-score of 0.80 for extracting DDIs.</p></list-item><list-item><p>We make all of the embeddings and evaluation datasets publicly available. The embeddings and datasets can be downloaded via <ext-link ext-link-type="uri" xlink:href="https://github.com/ncbi-nlp/BioConceptVec">https://github.com/ncbi-nlp/BioConceptVec</ext-link>. We also provide a Jupyter notebook that contains code examples for users to get started.</p></list-item></list><fig id="pcbi.1007617.g001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1007617.g001</object-id><label>Fig 1</label><caption><title>An overview of our study.</title><p>BioConceptVec was trained on PubMed abstracts, which consists of ~30 million documents. (1) We employed PubTator, which contains four NER tools, to annotate and normalize the concepts. (2) We trained four concept embeddings on the normalized corpus. (3) We conducted both intrinsic evaluations on drug-gene interactions and gene-gene interactions, and extrinsic evaluations on protein-protein interaction prediction and drug-drug interaction extraction to evaluate the effectiveness of BioConceptVec.</p></caption><graphic xlink:href="pcbi.1007617.g001"/></fig></sec><sec sec-type="materials|methods" id="sec002"><title>Materials and methods</title><sec id="sec003"><title>Training corpus and method</title><sec id="sec004"><title>NER step: Using PubTator to annotate biological concepts</title><p>We trained concept embeddings on the ~30 million abstracts in the entire PubMed. We followed the preprocessing pipeline from [<xref rid="pcbi.1007617.ref034" ref-type="bibr">34</xref>] (the code is publicly available via <ext-link ext-link-type="uri" xlink:href="https://github.com/ncbi-nlp/BioSentVec">https://github.com/ncbi-nlp/BioSentVec</ext-link>). As noted, the first step of bio-concept embedding development is to use NER tools to identify the target concept mentions (e.g., &#x0201c;estrogen receptor&#x0201d;) and to further normalize the mentions to the concept identifiers (e.g., &#x0201c;NCBI Gene: 2099&#x0201d;). As an example, shown in <xref ref-type="fig" rid="pcbi.1007617.g002">Fig 2</xref>, a targeted concept (i.e., MLN4924) is identified and normalized to a chemical concept: MESH:C539933. Due to the requirement of high-quality concept normalization for the concept embeddings, we applied PubTator to annotate the full PubMed abstracts. PubTator [<xref rid="pcbi.1007617.ref032" ref-type="bibr">32</xref>] is a PubMed-scale resource that utilizes four NER tools (i.e., TaggerOne [<xref rid="pcbi.1007617.ref035" ref-type="bibr">35</xref>], GNormPlus [<xref rid="pcbi.1007617.ref036" ref-type="bibr">36</xref>], tmVar [<xref rid="pcbi.1007617.ref037" ref-type="bibr">37</xref>], and SR4GN [<xref rid="pcbi.1007617.ref038" ref-type="bibr">38</xref>]) with a recent deep learning-based module for disambiguating conflict mentions [<xref rid="pcbi.1007617.ref039" ref-type="bibr">39</xref>] (when the mentions are annotated by two or more concept taggers) to recognize six key biological concepts (i.e., genes, mutations, diseases, chemicals, cell lines, and species). <xref ref-type="supplementary-material" rid="pcbi.1007617.s001">S1 Table</xref> provides a summary of the state-of-the-art performance of the NER tools in PubTator on various benchmarking datasets.</p><fig id="pcbi.1007617.g002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1007617.g002</object-id><label>Fig 2</label><caption><title>Identified bio-concept in-text and the normalized versions (one instance per type) in PubTator.</title></caption><graphic xlink:href="pcbi.1007617.g002"/></fig></sec><sec id="sec005"><title>Embedding training step: Using word2vec, GloVe, and fastText to produce BioConceptVec</title><p>We trained concept embeddings on the full collection of PubMed abstracts after concept recognition via PubTator, i.e., identified named entities are replaced with bio-entity types and IDs (e.g., Disease_MESH_D008288) before training. To our knowledge, there is no agreement on which embedding model is the most effective in biomedical domains. For example, Wang et al. [<xref rid="pcbi.1007617.ref040" ref-type="bibr">40</xref>] showed that fastText achieved the highest performance in biomedical event trigger detection versus other word embeddings [<xref rid="pcbi.1007617.ref040" ref-type="bibr">40</xref>], whereas Jin et al. [<xref rid="pcbi.1007617.ref041" ref-type="bibr">41</xref>] found that word2vec has better performance in biomedical sentence classification [<xref rid="pcbi.1007617.ref041" ref-type="bibr">41</xref>]. In this study, we therefore trained four different word embeddings, cbow, skip-gram, GloVe, and fastText such that future studies can choose our concept embeddings according to their specific requirements.</p><p>In general, the methods to train word embeddings can be categorized into two groups: window-based and matrix factorization-based [<xref rid="pcbi.1007617.ref015" ref-type="bibr">15</xref>]. The major distinction between these two categories is that window-based methods aim to learn the semantics of words based on local context, i.e., words within a pre-defined window size, whereas matrix factorization-based methods aim to learn the semantics of words based on global statistics of words in corpora. word2vec and fastText belong to the first category while GloVe belongs to the second category. word2vec has two versions: cbow, training a model using context words as input to predict a target word, and skip-gram: reversely using a target word to predict context words [<xref rid="pcbi.1007617.ref014" ref-type="bibr">14</xref>]. fastText is an extension of word2vec, using character n-grams to represent a word [<xref rid="pcbi.1007617.ref042" ref-type="bibr">42</xref>]. In contrast, GloVe is dramatically different from word2vec and fastText. It builds a matrix based on global co-occurrences between the words and then applies matrix factorization.</p><p>As mentioned, fastText represents each word as a set of character n-grams. In the case of bio-concept embeddings, however, each bio-concept should be considered a unit. Thus, when training with fastText, we disabled the n-grams representation for bio-concepts (in contrast, for the words that are not bio-concepts, we still used the default n-grams representation in fastText).</p><p>The values of hyperparameters for training embeddings are summarized in <xref rid="pcbi.1007617.t002" ref-type="table">Table 2</xref>. Our choice of hyperparameters is based on similar studies in the past and other related work in the general domain.</p><table-wrap id="pcbi.1007617.t002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1007617.t002</object-id><label>Table 2</label><caption><title>The values of hyperparameters used for training BioConceptVec.</title><p><italic>Default values</italic>: the default values are identical to the values selected by baseline embeddings. We used the default values to train BioConceptVec (cbow), BioConceptVec (skip-gram), BioConceptVec (GloVe) and BioConceptVec (fastText). <italic>Other values</italic>: we also adopted other commonly-used hyperparameter values to test the effectiveness of BioConceptVec (cbow) under different parameter settings.</p></caption><alternatives><graphic id="pcbi.1007617.t002g" xlink:href="pcbi.1007617.t002"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" rowspan="1" colspan="1"/><th align="left" rowspan="1" colspan="1">Hyperparameter</th><th align="right" rowspan="1" colspan="1">Default values</th><th align="right" rowspan="1" colspan="1">Other values</th></tr></thead><tbody><tr><td align="left" rowspan="7" colspan="1">Shared hyperparameters</td><td align="left" rowspan="1" colspan="1">Vector dimension</td><td align="right" rowspan="1" colspan="1">200</td><td align="right" rowspan="1" colspan="1">100, 300</td></tr><tr><td align="left" rowspan="1" colspan="1">Window size</td><td align="right" rowspan="1" colspan="1">20</td><td align="right" rowspan="1" colspan="1">5, 10</td></tr><tr><td align="left" rowspan="1" colspan="1">Negative samples</td><td align="right" rowspan="1" colspan="1">5</td><td align="right" rowspan="1" colspan="1">2, 3</td></tr><tr><td align="left" rowspan="1" colspan="1">Down-sampling threshold</td><td align="right" rowspan="1" colspan="1">0.001</td><td align="right" rowspan="1" colspan="1">0.0001, 0.00001</td></tr><tr><td align="left" rowspan="1" colspan="1">Minimal word occurrence</td><td align="right" rowspan="1" colspan="1">5</td><td align="right" rowspan="1" colspan="1">-</td></tr><tr><td align="left" rowspan="1" colspan="1">Learning rate</td><td align="right" rowspan="1" colspan="1">0.025</td><td align="right" rowspan="1" colspan="1">-</td></tr><tr><td align="left" rowspan="1" colspan="1">Training epochs</td><td align="right" rowspan="1" colspan="1">10</td><td align="right" rowspan="1" colspan="1">-</td></tr><tr><td align="left" rowspan="2" colspan="1">fastText-specific hyperparameters</td><td align="left" rowspan="1" colspan="1">Minimal character n-gram length</td><td align="right" rowspan="1" colspan="1">2</td><td align="right" rowspan="1" colspan="1">-</td></tr><tr><td align="left" rowspan="1" colspan="1">Maximum character n-gram length</td><td align="right" rowspan="1" colspan="1">3</td><td align="right" rowspan="1" colspan="1">-</td></tr></tbody></table></alternatives></table-wrap></sec><sec id="sec006"><title>Hyperparameters and other methods for comparison</title><p>To directly compare with the existing concept embeddings, we used the exact hyperparameter values from Yu et al. [<xref rid="pcbi.1007617.ref043" ref-type="bibr">43</xref>] as the default setting. As shown in <xref rid="pcbi.1007617.t001" ref-type="table">Table 1</xref>, of the three publicly available concept embeddings, it is the only concept embedding trained on PubMed. The other two were trained on EHR data. We measured the concept overlap in terms of genes and found that concept embeddings trained on EHR data contain a significantly fewer number of genes than do embeddings trained on PubMed. Thus, we did not compare with those two EHR-driven methods.</p><p>Yu et al. [<xref rid="pcbi.1007617.ref043" ref-type="bibr">43</xref>] used cbow to train the concept embeddings and their hyperparameters are summarized in <xref rid="pcbi.1007617.t002" ref-type="table">Table 2</xref>. Hence, under the same parameter settings, we firstly trained a common cbow word embedding on PubMed abstracts, as a baseline. Common word embeddings do not contain vectors for normalized bio-concepts. The words in a bio-concept name, however, often exist in common word embeddings. For example, the TOR3A gene (<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/gene/64222">https://www.ncbi.nlm.nih.gov/gene/64222</ext-link>) does not exist in a common word embedding, but the words of its name <italic>torsin family 3 member A</italic> all exist. Thus, we averaged the word vectors based on the bio-concept name to represent the concept vector. Averaged vectors are used as a strong baseline for many embedding-related tasks, such as sentence similarity [<xref rid="pcbi.1007617.ref044" ref-type="bibr">44</xref>] and sentiment analysis [<xref rid="pcbi.1007617.ref045" ref-type="bibr">45</xref>]. We refer to the averaged word embedding baseline as BioAvgWord (cbow). As such, we are able to directly compare BioConceptVec (cbow) with the two baselines: BioAvgWord (cbow) and the concept embedding provided by Yu et al.</p><p>In addition, we trained and assessed BioConceptVec (cbow) under different parameters but keeping the same values for minimal word occurrences (so that embeddings share the same vocabulary), learning rate and training epochs (so that embeddings share the same optimization procedure). For each of the other hyperparameters, we selected two representative values that were used in the previous studies on embeddings [<xref rid="pcbi.1007617.ref046" ref-type="bibr">46</xref>, <xref rid="pcbi.1007617.ref047" ref-type="bibr">47</xref>], as shown in <xref rid="pcbi.1007617.t002" ref-type="table">Table 2</xref> (other values). Note that we do not select larger values for the negative samples and down-sampling threshold because the training epoch is set to be 10 &#x02013;it would require more epochs to stabilize the loss when there are more samples.</p><p>Furthermore, different studies show that performance can vary by different embedding methods [<xref rid="pcbi.1007617.ref046" ref-type="bibr">46</xref>, <xref rid="pcbi.1007617.ref048" ref-type="bibr">48</xref>]. Thus, we also train BioConceptVec using skip-gram, GloVe and fastText, using the same default setups. We make all of the four versions of BioConceptVec (cbow, skip-gram, GloVe and fastText) publicly available so that users can experiment and choose between the models for their tasks.</p><p>To ensure a fair comparison, the evaluation datasets described below contain only concepts shared among these baseline methods and BioConceptVec. We also measured the coverage of concepts using human genes as an example.</p></sec></sec><sec id="sec007"><title>Intrinsic evaluations</title><sec id="sec008"><title>Identifying related genes based on drug-gene and gene-gene interactions</title><p>We posit that concept embeddings should give higher similarity to related concepts than to unrelated concepts. The intrinsic evaluations in our study quantify the effectiveness of concept embeddings in terms of identifying related genes. We concentrate on genes because genes are a central focus of biological studies; the interactions between genes (or genes and other biological concepts) are essential for understanding the structures and functions of a cell [<xref rid="pcbi.1007617.ref049" ref-type="bibr">49</xref>, <xref rid="pcbi.1007617.ref050" ref-type="bibr">50</xref>]. In addition, biological studies over the decades have collected related genes from different perspectives, such as those based on expression signatures, pathways, and gene ontologies (GO). These collected related genes can be used as a gold standard for our intrinsic evaluations. In contrast, other biological concepts, such as diseases and mutations, are somewhat difficult to define in regard to the notion of relatedness systematically. We considered related gene pairs based on drug-gene interactions and gene-gene interactions, as explained below.</p></sec><sec id="sec009"><title>Evaluation dataset construction and evaluation metrics</title><p>We adopted six datasets for creating evaluation datasets. The detailed statistics of these datasets are summarized in <xref rid="pcbi.1007617.t003" ref-type="table">Table 3</xref>. The relatedness of genes was modeled from two broad categories. The first was based on the relationships between genes and other bio-concepts, and the second was based on the relationships among genes.</p><table-wrap id="pcbi.1007617.t003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1007617.t003</object-id><label>Table 3</label><caption><title>The statistics of datasets in intrinsic evaluation tasks.</title><p>There are six datasets in total. #groups: the number of groups in a dataset. Each group has a related set and an unrelated set of genes based on drug-gene interactions provided by CTD or gene sets provided by MSIGDB. #distinct concepts: the total number of distinct genes in a dataset. Avg #concepts per group: the average of number of genes in a group; note that one gene may be in multiple groups. #pairs: the total number of pairs in a dataset. Avg #pairs per group: the average of the number of pairs per group.</p></caption><alternatives><graphic id="pcbi.1007617.t003g" xlink:href="pcbi.1007617.t003"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" rowspan="1" colspan="1">Dataset</th><th align="center" rowspan="1" colspan="1">#groups</th><th align="center" rowspan="1" colspan="1">#distinct concepts</th><th align="center" rowspan="1" colspan="1">Avg #concepts<break/>per group</th><th align="center" rowspan="1" colspan="1">#pairs</th><th align="center" rowspan="1" colspan="1">Avg #pairs<break/>per group</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">CTD</td><td align="right" rowspan="1" colspan="1">6383</td><td align="right" rowspan="1" colspan="1">14,654</td><td align="right" rowspan="1" colspan="1">22.39</td><td align="right" rowspan="1" colspan="1">2,146,482</td><td align="right" rowspan="1" colspan="1">358.88</td></tr><tr><td align="left" rowspan="1" colspan="1">MSigDB datasets</td><td align="right" rowspan="1" colspan="1"/><td align="right" rowspan="1" colspan="1"/><td align="right" rowspan="1" colspan="1"/><td align="right" rowspan="1" colspan="1"/><td align="right" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">&#x000a0;&#x000a0;&#x000a0;&#x000a0;C1 positional gene sets</td><td align="right" rowspan="1" colspan="1">326</td><td align="right" rowspan="1" colspan="1">11,709</td><td align="right" rowspan="1" colspan="1">63.30</td><td align="right" rowspan="1" colspan="1">431,254</td><td align="right" rowspan="1" colspan="1">1447.16</td></tr><tr><td align="left" rowspan="1" colspan="1">&#x000a0;&#x000a0;&#x000a0;&#x000a0;C2 curated gene sets</td><td align="right" rowspan="1" colspan="1">4,762</td><td align="right" rowspan="1" colspan="1">13,783</td><td align="right" rowspan="1" colspan="1">66.21</td><td align="right" rowspan="1" colspan="1">6,171,976</td><td align="right" rowspan="1" colspan="1">1621.21</td></tr><tr><td align="left" rowspan="1" colspan="1">&#x000a0;&#x000a0;&#x000a0;&#x000a0;C3 motif gene sets</td><td align="right" rowspan="1" colspan="1">836</td><td align="right" rowspan="1" colspan="1">9,553</td><td align="right" rowspan="1" colspan="1">115.63</td><td align="right" rowspan="1" colspan="1">910,722</td><td align="right" rowspan="1" colspan="1">3976.95</td></tr><tr><td align="left" rowspan="1" colspan="1">&#x000a0;&#x000a0;&#x000a0;&#x000a0;C4 computational gene sets</td><td align="right" rowspan="1" colspan="1">858</td><td align="right" rowspan="1" colspan="1">8,637</td><td align="right" rowspan="1" colspan="1">85.84</td><td align="right" rowspan="1" colspan="1">1,452,542</td><td align="right" rowspan="1" colspan="1">2392.99</td></tr><tr><td align="left" rowspan="1" colspan="1">&#x000a0;&#x000a0;&#x000a0;&#x000a0;C5 GO gene sets</td><td align="right" rowspan="1" colspan="1">5,917</td><td align="right" rowspan="1" colspan="1">13,627</td><td align="right" rowspan="1" colspan="1">62.71</td><td align="right" rowspan="1" colspan="1">6,697,736</td><td align="right" rowspan="1" colspan="1">1455.08</td></tr><tr><td align="left" rowspan="1" colspan="1">Total</td><td align="right" rowspan="1" colspan="1">19,082</td><td align="right" rowspan="1" colspan="1">14,998</td><td align="right" rowspan="1" colspan="1">-</td><td align="right" rowspan="1" colspan="1">17,810,712</td><td align="right" rowspan="1" colspan="1">-</td></tr></tbody></table></alternatives></table-wrap><p>For the first category, we used the Comparative Toxicogenomics Database (CTD) [<xref rid="pcbi.1007617.ref051" ref-type="bibr">51</xref>], which captures drug-gene interactions. For each drug, we consider the genes that interact with the same drug as a related set and randomly select the same number of genes that do not interact with the drug as an unrelated set. A related and unrelated set together form a group. Ideally, concept embeddings should have significantly higher similarity for the related sets than the unrelated sets for each group.</p><p>For the second category, we used five gene sets (C1&#x02013;C5) of MSigDB [<xref rid="pcbi.1007617.ref052" ref-type="bibr">52</xref>]. MSigDB captures related genes using different perspectives, and each gene set is generated from a distinct perspective. For example, MSigDB C1 is generated based on human chromosomes, and MSigDB C5 is generated based on GO. The strategy of creating related and unrelated sets is the same as above. For example, in terms of MSigDB C5, the genes that share the same GO term are considered a related set, and the same number of genes that do not share that GO term are randomly generated as an unrelated set.</p><p>We computed the similarity of a set by averaging the cosine similarity of all of the pairs in the set, using concept embeddings. Cosine similarity is the most popular similarity measure used by embeddings [<xref rid="pcbi.1007617.ref029" ref-type="bibr">29</xref>]. Importantly, different embeddings may report different cosine similarities for same pairs, and the range of cosine similarities also may be different, which is strictly inevitable [<xref rid="pcbi.1007617.ref053" ref-type="bibr">53</xref>]. To reduce the biases, for each embedding, we first applied <italic>Z</italic>-score standardization to the cosine similarities of all of the pairs and then used Min-Max normalization to transform the range to [0, 1].</p><p>We used the similarity score difference between related sets and unrelated sets at group level as the final evaluation metric. As noted, a more effective concept embedding should have a greater similarity score difference between the related set and the unrelated set for a group. For computational efficiency, we restricted the maximum number of genes in a set to be 100, i.e., a group has, at most, 200 genes in total. Note that MSigDB has other gene sets, such as C6 and C7. We did not use them because the number is fewer than 100 in shared genes. Collectively, our intrinsic evaluation datasets contain over 13,000 genes and over 17 million instances across six datasets.</p></sec></sec><sec id="sec010"><title>Extrinsic evaluations</title><p>We further evaluated the utility of BioConceptVec in two downstream applications: protein-protein interaction (PPI) prediction on the STRING database [<xref rid="pcbi.1007617.ref033" ref-type="bibr">33</xref>] and drug-drug interaction (DDI) classification on biomedical literature [<xref rid="pcbi.1007617.ref054" ref-type="bibr">54</xref>].</p><sec id="sec011"><title>Protein-protein interaction prediction on the STRING database</title><p>Analyzing functional interactions between proteins, which facilitates the understanding of the cellular processing and characterization, is a routine task in molecular systems biology [<xref rid="pcbi.1007617.ref055" ref-type="bibr">55</xref>]. The STRING database is one of the most comprehensive data resources that integrate, score, and analyze publicly available PPIs [<xref rid="pcbi.1007617.ref033" ref-type="bibr">33</xref>]. To date, it consists of over 3 billion PPIs from ~25 million proteins (<ext-link ext-link-type="uri" xlink:href="https://string-db.org/">https://string-db.org/</ext-link>). The PPIs in the STRING database are scored by accumulating a wide range of evidence, such as measurements from biological experiments, co-expressions, and gene co-occurrences.</p><p>Existing studies have used STRING for training and testing machine learning models for PPI prediction [<xref rid="pcbi.1007617.ref056" ref-type="bibr">56</xref>, <xref rid="pcbi.1007617.ref057" ref-type="bibr">57</xref>]. In a recent study, for example, Smaili et al. constructed two PPI datasets for human proteins: (1) PPIs based on combined scores, i.e., the score calculated from multiple sources (including results from the biomedical literature and many others, such as gene co-expressions, biological experiments and pathways), which we refer to as the <italic>combined-score</italic>, and (2) PPIs that have the experimental score over 700, i.e., the score is based only on biological experiments and is greater than 700, which we refer to as the <italic>experimental-700</italic>. The study considered these PPIs as positive instances and randomly generated the same number of negative instances. Smaili et al. split the datasets into the training and testing datasets, accounting for 70% and 30% of the total number of PPIs, respectively. They further developed a deep learning model by taking the vector representations of the two proteins as inputs and predicting whether the proteins have interactions. The deep learning model was an artificial neural network (ANN) that had two hidden layers [<xref rid="pcbi.1007617.ref057" ref-type="bibr">57</xref>]. Using the same model, the study tested different vector representations and reported Area Under the Curve (AUC) accordingly.</p><p>We followed this study [<xref rid="pcbi.1007617.ref057" ref-type="bibr">57</xref>] for creating the datasets and implementing the reported ANN model. <xref rid="pcbi.1007617.t004" ref-type="table">Table 4</xref> provides a summary of the statistics of the datasets. The combined-score dataset covers all of the 13,802 proteins that are shared by concept embeddings and STRING databases. In comparison, the previous study sampled only 1,800 proteins. We also implemented a 2-layer ANN. The details of the hyperparameters are summarized in <xref ref-type="supplementary-material" rid="pcbi.1007617.s002">S2 Table</xref>. In keeping with the previous study, the model and hyperparameters are identical when testing different concept embeddings. The Precision, Recall, F1-score, and AUC are reported.</p><table-wrap id="pcbi.1007617.t004" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1007617.t004</object-id><label>Table 4</label><caption><title>Statistics of the datasets for PPI prediction.</title><p>#Concepts: the number of concepts in the dataset. #Training: the number of training instances; same applies to #Validation and #Testing.</p></caption><alternatives><graphic id="pcbi.1007617.t004g" xlink:href="pcbi.1007617.t004"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Dataset</th><th align="right" rowspan="1" colspan="1">#Concepts</th><th align="right" rowspan="1" colspan="1">#Training</th><th align="right" rowspan="1" colspan="1">#Validation</th><th align="right" rowspan="1" colspan="1">#Testing</th><th align="right" rowspan="1" colspan="1">Total</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">combined-score</td><td align="right" rowspan="1" colspan="1">13,802</td><td align="right" rowspan="1" colspan="1">5,245,358</td><td align="right" rowspan="1" colspan="1">582,818</td><td align="right" rowspan="1" colspan="1">2,497,790</td><td align="right" rowspan="1" colspan="1">8,325,966</td></tr><tr><td align="left" rowspan="1" colspan="1">experimental-700</td><td align="right" rowspan="1" colspan="1">13,290</td><td align="right" rowspan="1" colspan="1">24,684</td><td align="right" rowspan="1" colspan="1">2,743</td><td align="right" rowspan="1" colspan="1">11,755</td><td align="right" rowspan="1" colspan="1">39,182</td></tr></tbody></table></alternatives></table-wrap></sec><sec id="sec012"><title>Drug-drug interaction extraction on biomedical literature</title><p>We also examined the usefulness of concept embeddings in a text-mining task. Specifically we evaluated the performance of concept embeddings on the SemEval 2013: Task 9 DDI extraction corpus [<xref rid="pcbi.1007617.ref054" ref-type="bibr">54</xref>] for DDI classification. This dataset consists of over 1,000 documents from the DrugBank database [<xref rid="pcbi.1007617.ref058" ref-type="bibr">58</xref>] and PubMed abstracts and ~5,000 DDIs manually annotated by two senior pharmacists, serving as a gold standard dataset for relation extraction by the community [<xref rid="pcbi.1007617.ref059" ref-type="bibr">59</xref>].</p><p>In this task, the input is a sentence that contains a pair of drugs. If the pair of drugs represents a true DDI, the model needs to output the DDI type; otherwise, the model needs to indicate the pair is not a true DDI [<xref rid="pcbi.1007617.ref054" ref-type="bibr">54</xref>]. The annotators classified a DDI into one of four types: advice, effect, mechanism, and int (the interaction occurs, but its type cannot be classified) [<xref rid="pcbi.1007617.ref059" ref-type="bibr">59</xref>]. We used the official training and testing datasets. The statistics of the datasets are summarized in <xref rid="pcbi.1007617.t005" ref-type="table">Table 5</xref>. This is a multi-class classification problem (i.e., 5 classes: 4 DDI types and a negative class indicating a pair is not a DDI), and the organizers used the F1-score to measure the multi-class performance of true DDIs (i.e., without considering the negative cases). We followed the same evaluation procedure.</p><table-wrap id="pcbi.1007617.t005" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1007617.t005</object-id><label>Table 5</label><caption><title>Statistics of the DDI extraction datasets.</title><p>Mechanism, Effect, Advice, Int are four types of DDIs. Negative means that the instance does not contain a DDI.</p></caption><alternatives><graphic id="pcbi.1007617.t005g" xlink:href="pcbi.1007617.t005"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Class</th><th align="right" rowspan="1" colspan="1">#Training</th><th align="right" rowspan="1" colspan="1">#Testing</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Mechanism</td><td align="right" rowspan="1" colspan="1">1,319</td><td align="right" rowspan="1" colspan="1">302</td></tr><tr><td align="left" rowspan="1" colspan="1">Effect</td><td align="right" rowspan="1" colspan="1">1,621</td><td align="right" rowspan="1" colspan="1">360</td></tr><tr><td align="left" rowspan="1" colspan="1">Advice</td><td align="right" rowspan="1" colspan="1">826</td><td align="right" rowspan="1" colspan="1">221</td></tr><tr><td align="left" rowspan="1" colspan="1">Int</td><td align="right" rowspan="1" colspan="1">188</td><td align="right" rowspan="1" colspan="1">96</td></tr><tr><td align="left" rowspan="1" colspan="1">Negative</td><td align="right" rowspan="1" colspan="1">23,772</td><td align="right" rowspan="1" colspan="1">4,737</td></tr></tbody></table></alternatives></table-wrap><p>We implemented a simple averaged sentence embedding neural network model (SEN) for DDI classification. <xref ref-type="fig" rid="pcbi.1007617.g003">Fig 3</xref> illustrates the architecture of SEN. For an input sentence, it first uses word embedding to map the vectors of each word in the sentence (Embedding Layer in <xref ref-type="fig" rid="pcbi.1007617.g003">Fig 3</xref>). We used the recent context-based word embedding ELMo in the Embedding Layer [<xref rid="pcbi.1007617.ref060" ref-type="bibr">60</xref>], which was shown to be superior to common word embeddings in relation extraction tasks [<xref rid="pcbi.1007617.ref061" ref-type="bibr">61</xref>]. Then it averages all of the word vectors to obtain the sentence vectors (Averaged Layer), followed by dense layers (the hidden layers used in the ANN above). Finally, it outputs class probabilities. The details of the hyperparameters of SEN are summarized in <xref ref-type="supplementary-material" rid="pcbi.1007617.s003">S3 Table</xref>. SEN has been used widely as a baseline model in sentence-related applications [<xref rid="pcbi.1007617.ref034" ref-type="bibr">34</xref>]. We hypothesized that adding the vector representations of the drugs mentioned in the sentences will increase the classification performance. We used PubTator to map the drug mentions into concept identifiers. Thus, similar to PPI prediction, we used the same model and tested different concept embeddings. The Precision, Recall, and F-1 score are reported.</p><fig id="pcbi.1007617.g003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1007617.g003</object-id><label>Fig 3</label><caption><title>The architecture of the model used for DDI extraction.</title></caption><graphic xlink:href="pcbi.1007617.g003"/></fig></sec></sec></sec><sec sec-type="conclusions" id="sec013"><title>Results and discussions</title><sec id="sec014"><title>Number of shared human genes in BioConceptVec and other public embeddings</title><p><xref ref-type="fig" rid="pcbi.1007617.g004">Fig 4</xref> shows the number of human genes with computed embeddings in each method. We compared all of the publicly available concept embeddings shown in <xref rid="pcbi.1007617.t001" ref-type="table">Table 1</xref>. There are two embeddings provided by Choi et al. (<ext-link ext-link-type="uri" xlink:href="https://github.com/clinicalml/embeddings">https://github.com/clinicalml/embeddings</ext-link>). We used the version from <italic>stanford_cuis_svd_300</italic>.<italic>txt</italic>.<italic>gz</italic> because it contains more concepts and also more human genes than the other one. <xref ref-type="fig" rid="pcbi.1007617.g004">Fig 4</xref> illustrates that BioConceptVec contains more human genes than other publicly available concept embeddings. Specifically, it covers about 3,000 more human genes than does the second highest embedding method (Yu et al). In total, these four embeddings cover 18,881 human genes, ~98% of which can be found in BioConceptVec. We manually examined the genes that were missing in BioConceptVec and found that most of them only occurred once. We also found that these genes occur more frequently in PMC full-text articles; we plan to integrate both PubMed abstracts and PMC full-text articles for training concept embeddings in the future.</p><fig id="pcbi.1007617.g004" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1007617.g004</object-id><label>Fig 4</label><caption><title>Gene coverage results in terms of human genes.</title><p>The number of human genes in different embeddings is shown individually. In total, these four embeddings consist of 18,881 human genes. Note that the embeddings from Beam et al. and Choi et al. were mainly trained on EHR. The results mainly aim to demonstrate that biomedical literature and EHR contain significantly different concepts.</p></caption><graphic xlink:href="pcbi.1007617.g004"/></fig><p>Notably, the embeddings from Beam et al. and Choi et al, were primarily trained on EHR, and these embeddings are designed mainly for clinical applications. Hence, they only cover a small number of gene and protein concepts. This comparison thus further illustrates that the biomedical literature contains significantly different bio-concepts from clinical notes.</p></sec><sec id="sec015"><title>Intrinsic evaluation results</title><p><xref ref-type="fig" rid="pcbi.1007617.g005">Fig 5</xref> and <xref ref-type="fig" rid="pcbi.1007617.g006">Fig 6</xref> show the intrinsic evaluation results on the six evaluation datasets. As noted, the average group similarity difference (%) is used as the evaluation metric. A more effective concept embedding should have higher similarity difference between the positive set and the negative set of a group. Using the same embedding training method and the same hyperparameters, the results in <xref ref-type="fig" rid="pcbi.1007617.g005">Fig 5</xref> show that the performance of BioConceptVec (cbow) is consistently higher (an average of 4 percentage points) than that of Yu et al. on the six datasets. The differences are even more remarked when compared to the average word embedding (an average of 7 percentage points). In addition, the results also show that BioConceptVec (cbow) achieves consistently better performance than that of baseline approaches with different hyperparameters. Collectively, these results suggest the positive impact of our selected NER methods.</p><fig id="pcbi.1007617.g005" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1007617.g005</object-id><label>Fig 5</label><caption><title>The intrinsic evaluation results in terms of average group similarity difference (%) for the six evaluation datasets.</title><p><italic>Direct comparison</italic> shows the results of BioConceptVec (cbow) using identical hyperparameters as the baselines. The baselines were also trained using cbow. <italic>Different hyperparameters</italic> shows the results of BioConceptVec (cbow) using different hyperparameters (provided in <xref rid="pcbi.1007617.t002" ref-type="table">Table 2</xref>): w, v, s, and n stand for window size, vector dimension, sampling threshold, and negative samples, respectively.</p></caption><graphic xlink:href="pcbi.1007617.g005"/></fig><fig id="pcbi.1007617.g006" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1007617.g006</object-id><label>Fig 6</label><caption><title>The intrinsic evaluation results for BioConceptVec from different embedding methods (cbow, skip-gram, Glove, and fastText).</title><p>The embeddings were trained using the same default parameters. Direct comparison: the results of baseline embeddings and BioConceptVec trained using cbow.</p></caption><graphic xlink:href="pcbi.1007617.g006"/></fig><p>In <xref ref-type="fig" rid="pcbi.1007617.g006">Fig 6</xref>, we report the effect of different embedding methods. As shown, there is no one-size-fits-all method that always achieves the best performance across all of the datasets. For instance, BioConceptVec (cbow) had the best performance on the CTD dataset, whereas BioConceptVec (GloVe) had the highest score on the MSigDB C1 dataset. This is consistent with the findings in the previous literature on embedding comparison [<xref rid="pcbi.1007617.ref046" ref-type="bibr">46</xref>, <xref rid="pcbi.1007617.ref048" ref-type="bibr">48</xref>]. Hence, it is necessary to make embeddings trained with different methods publicly available.</p></sec><sec id="sec016"><title>Extrinsic evaluation results</title><sec id="sec017"><title>Protein-protein interaction predictions on STRING database</title><p><xref rid="pcbi.1007617.t006" ref-type="table">Table 6</xref> illustrates the classification results of PPI predictions on the STRING database. The direct comparison results show that BioConceptVec (cbow) has better performance than the baseline approaches&#x02013;achieving the highest F1 score and AUC on both datasets. The results of BioConceptVec (cbow) with different hyperparameters is summarized in <xref ref-type="supplementary-material" rid="pcbi.1007617.s004">S4 Table</xref>, which further demonstrate that its performance was consistent overall. When comparing BioConceptVec trained using different methods, BioConceptVec (fastText) had the best overall performance for this task, although the performance of BioConceptVec (cbow) and BioConceptVec (skip) are very close. Note that we were unable to directly compare with the previous study [<xref rid="pcbi.1007617.ref057" ref-type="bibr">57</xref>] because the proposed embedding is not publicly available. Also as noted, the performance of the study was measured on ~1,800 proteins, whereas our datasets contain ~13,000 proteins.</p><table-wrap id="pcbi.1007617.t006" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1007617.t006</object-id><label>Table 6</label><caption><title>Classification results of PPI predictions on the STRING database.</title><p>Combined-scores: PPIs that have combined scores are considered positive cases. Experimental-700: PPIs that have experimental scores over 700 are considered positive cases. Direct comparison: the results of embeddings using the same method (cbow) and same hyperparameters. Different embedding methods: the results of BioConceptVec (skip-gram), BioConceptVec (GloVe) and BioConceptVec (fastText). The highest results of each section are marked as bold.</p></caption><alternatives><graphic id="pcbi.1007617.t006g" xlink:href="pcbi.1007617.t006"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="2" colspan="1"/><th align="center" colspan="4" rowspan="1">Combined-score dataset</th><th align="center" colspan="4" rowspan="1">Experimental-700 dataset</th></tr><tr><th align="center" rowspan="1" colspan="1">Precision</th><th align="center" rowspan="1" colspan="1">Recall</th><th align="center" rowspan="1" colspan="1">F1</th><th align="center" rowspan="1" colspan="1">AUC</th><th align="center" rowspan="1" colspan="1">Precision</th><th align="center" rowspan="1" colspan="1">Recall</th><th align="center" rowspan="1" colspan="1">F1</th><th align="center" rowspan="1" colspan="1">AUC</th></tr></thead><tbody><tr><td align="left" colspan="9" rowspan="1"><bold>Direct comparison</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">BioAvgWord (cbow)</td><td align="right" rowspan="1" colspan="1">0.8195</td><td align="right" rowspan="1" colspan="1">0.7935</td><td align="right" rowspan="1" colspan="1">0.8063</td><td align="right" rowspan="1" colspan="1">0.8941</td><td align="right" rowspan="1" colspan="1">0.8851</td><td align="right" rowspan="1" colspan="1">0.7422</td><td align="right" rowspan="1" colspan="1">0.8074</td><td align="right" rowspan="1" colspan="1">0.9123</td></tr><tr><td align="left" rowspan="1" colspan="1">Yu et al. (cbow)</td><td align="right" rowspan="1" colspan="1">0.8236</td><td align="right" rowspan="1" colspan="1">0.8017</td><td align="right" rowspan="1" colspan="1">0.8125</td><td align="right" rowspan="1" colspan="1">0.9029</td><td align="right" rowspan="1" colspan="1">0.9130</td><td align="right" rowspan="1" colspan="1">0.7686</td><td align="right" rowspan="1" colspan="1">0.8346</td><td align="right" rowspan="1" colspan="1">0.9283</td></tr><tr><td align="left" rowspan="1" colspan="1">BioConceptVec (cbow)</td><td align="right" rowspan="1" colspan="1"><bold>0.8304</bold></td><td align="right" rowspan="1" colspan="1"><bold>0.8025</bold></td><td align="right" rowspan="1" colspan="1"><bold>0.8162</bold></td><td align="right" rowspan="1" colspan="1"><bold>0.9064</bold></td><td align="right" rowspan="1" colspan="1"><bold>0.9476</bold></td><td align="right" rowspan="1" colspan="1"><bold>0.7981</bold></td><td align="right" rowspan="1" colspan="1"><bold>0.8664</bold></td><td align="right" rowspan="1" colspan="1"><bold>0.9525</bold></td></tr><tr><td align="left" colspan="9" rowspan="1"><bold>Different embedding methods</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">BioConcept (skip-gram)</td><td align="right" rowspan="1" colspan="1">0.8279</td><td align="right" rowspan="1" colspan="1">0.8097</td><td align="right" rowspan="1" colspan="1">0.8187</td><td align="right" rowspan="1" colspan="1">0.9074</td><td align="right" rowspan="1" colspan="1"><bold>0.9201</bold></td><td align="right" rowspan="1" colspan="1">0.8525</td><td align="right" rowspan="1" colspan="1">0.8850</td><td align="right" rowspan="1" colspan="1">0.9522</td></tr><tr><td align="left" rowspan="1" colspan="1">BioConcept (GloVe)</td><td align="right" rowspan="1" colspan="1">0.8116</td><td align="right" rowspan="1" colspan="1"><bold>0.8102</bold></td><td align="right" rowspan="1" colspan="1">0.8109</td><td align="right" rowspan="1" colspan="1">0.9004</td><td align="right" rowspan="1" colspan="1">0.8656</td><td align="right" rowspan="1" colspan="1">0.8289</td><td align="right" rowspan="1" colspan="1">0.8468</td><td align="right" rowspan="1" colspan="1">0.9218</td></tr><tr><td align="left" rowspan="1" colspan="1">BioConcept (fastText)</td><td align="right" rowspan="1" colspan="1"><bold>0.8324</bold></td><td align="right" rowspan="1" colspan="1">0.8100</td><td align="right" rowspan="1" colspan="1"><bold>0.8210</bold></td><td align="right" rowspan="1" colspan="1"><bold>0.9099</bold></td><td align="right" rowspan="1" colspan="1">0.9076</td><td align="right" rowspan="1" colspan="1"><bold>0.8677</bold></td><td align="right" rowspan="1" colspan="1"><bold>0.8872</bold></td><td align="right" rowspan="1" colspan="1"><bold>0.9556</bold></td></tr></tbody></table></alternatives></table-wrap></sec><sec id="sec018"><title>Drug-drug interaction extraction results</title><p><xref rid="pcbi.1007617.t007" ref-type="table">Table 7</xref> demonstrates the evaluation results on DDI extraction. We ran the model 5 times with different random seeds and then calculated the average performance [<xref rid="pcbi.1007617.ref062" ref-type="bibr">62</xref>]. The state-of-the-art (SOTA) model by Zhang and colleagues achieved an F1-score of 0.73 on this dataset [<xref rid="pcbi.1007617.ref063" ref-type="bibr">63</xref>]. Their model uses an LSTM as an encoder with an attention mechanism and outperforms other feature-based, kernel-based, and neural networks-based methods. We found that, compared with the SOTA model, the SEN model had a slightly better classification performance on advice, effect, and mechanism relation types but had a dramatically lower performance on int relation where a DDI cannot be classified into a specific type.</p><table-wrap id="pcbi.1007617.t007" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1007617.t007</object-id><label>Table 7</label><caption><title>Classification results of DDI classification.</title><p>SOTA: state-of-the-art. P: Precision. R: Recall. The SOTA results are extracted from [<xref rid="pcbi.1007617.ref063" ref-type="bibr">63</xref>]. Direct comparison: the results of embeddings using the same method (cbow) and same hyperparameters. Different embedding methods: the results of BioConceptVec (skip-gram), BioConceptVec (GloVe) and BioConceptVec (fastText). The highest results of each section are marked as bold.</p></caption><alternatives><graphic id="pcbi.1007617.t007g" xlink:href="pcbi.1007617.t007"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" rowspan="2" colspan="1">Model</th><th align="center" colspan="4" rowspan="1">F1-score on each relation type</th><th align="center" colspan="3" rowspan="1">Overall performance</th></tr><tr><th align="center" rowspan="1" colspan="1">Int</th><th align="center" rowspan="1" colspan="1">Advice</th><th align="center" rowspan="1" colspan="1">Effect</th><th align="center" rowspan="1" colspan="1">Mechanism</th><th align="center" rowspan="1" colspan="1">P</th><th align="center" rowspan="1" colspan="1">R</th><th align="center" rowspan="1" colspan="1">F</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Zhang et al. (SOTA)</td><td align="right" rowspan="1" colspan="1"><bold>0.5400</bold></td><td align="right" rowspan="1" colspan="1">0.8000</td><td align="right" rowspan="1" colspan="1">0.7200</td><td align="center" rowspan="1" colspan="1">0.7400</td><td align="right" rowspan="1" colspan="1">0.7400</td><td align="right" rowspan="1" colspan="1">0.7200</td><td align="right" rowspan="1" colspan="1">0.7300</td></tr><tr><td align="left" rowspan="1" colspan="1">SEN</td><td align="right" rowspan="1" colspan="1">0.3569</td><td align="right" rowspan="1" colspan="1"><bold>0.8336</bold></td><td align="right" rowspan="1" colspan="1"><bold>0.7978</bold></td><td align="center" rowspan="1" colspan="1"><bold>0.8463</bold></td><td align="right" rowspan="1" colspan="1"><bold>0.7940</bold></td><td align="right" rowspan="1" colspan="1"><bold>0.7832</bold></td><td align="right" rowspan="1" colspan="1"><bold>0.7776</bold></td></tr><tr><td align="left" colspan="8" rowspan="1"><bold>Direct comparison</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">SEN + BioAvgWord (cbow)</td><td align="right" rowspan="1" colspan="1">0.3150</td><td align="right" rowspan="1" colspan="1">0.7787</td><td align="right" rowspan="1" colspan="1">0.8000</td><td align="center" rowspan="1" colspan="1">0.8824</td><td align="right" rowspan="1" colspan="1">0.7883</td><td align="right" rowspan="1" colspan="1">0.7814</td><td align="right" rowspan="1" colspan="1">0.7731</td></tr><tr><td align="left" rowspan="1" colspan="1">SEN &#x000a0;&#x000a0;&#x000a0;&#x000a0;+ Yu et al. (cbow)</td><td align="right" rowspan="1" colspan="1">0.4285</td><td align="right" rowspan="1" colspan="1">0.8263</td><td align="right" rowspan="1" colspan="1">0.8133</td><td align="center" rowspan="1" colspan="1">0.8559</td><td align="right" rowspan="1" colspan="1">0.7948</td><td align="right" rowspan="1" colspan="1">0.7961</td><td align="right" rowspan="1" colspan="1">0.7916</td></tr><tr><td align="left" rowspan="1" colspan="1">SEN &#x000a0;&#x000a0;&#x000a0;&#x000a0;+ BioConceptVec (cbow)</td><td align="right" rowspan="1" colspan="1"><bold>0.5206</bold></td><td align="right" rowspan="1" colspan="1"><bold>0.8423</bold></td><td align="right" rowspan="1" colspan="1"><bold>0.8191</bold></td><td align="center" rowspan="1" colspan="1"><bold>0.8692</bold></td><td align="right" rowspan="1" colspan="1"><bold>0.8167</bold></td><td align="right" rowspan="1" colspan="1"><bold>0.8161</bold></td><td align="right" rowspan="1" colspan="1"><bold>0.8105</bold></td></tr><tr><td align="left" colspan="8" rowspan="1"><bold>Different embedding methods</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">SEN&#x000a0;&#x000a0;&#x000a0;&#x000a0;+ BioConcept (skip-gram)</td><td align="right" rowspan="1" colspan="1">0.4090</td><td align="right" rowspan="1" colspan="1"><bold>0.8164</bold></td><td align="right" rowspan="1" colspan="1"><bold>0.8255</bold></td><td align="center" rowspan="1" colspan="1">0.8626</td><td align="right" rowspan="1" colspan="1"><bold>0.8088</bold></td><td align="right" rowspan="1" colspan="1">0.8025</td><td align="right" rowspan="1" colspan="1">0.7941</td></tr><tr><td align="left" rowspan="1" colspan="1">SEN&#x000a0;&#x000a0;&#x000a0;&#x000a0;+ BioConcept (GloVe)</td><td align="right" rowspan="1" colspan="1"><bold>0.4587</bold></td><td align="right" rowspan="1" colspan="1">0.8100</td><td align="right" rowspan="1" colspan="1">0.8160</td><td align="center" rowspan="1" colspan="1"><bold>0.8702</bold></td><td align="right" rowspan="1" colspan="1">0.8046</td><td align="right" rowspan="1" colspan="1"><bold>0.8029</bold></td><td align="right" rowspan="1" colspan="1"><bold>0.7963</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">SEN&#x000a0;&#x000a0;&#x000a0;&#x000a0;+ BioConcept (fastText)</td><td align="right" rowspan="1" colspan="1">0.4382</td><td align="right" rowspan="1" colspan="1">0.8153</td><td align="right" rowspan="1" colspan="1">0.8200</td><td align="center" rowspan="1" colspan="1">0.8571</td><td align="right" rowspan="1" colspan="1">0.7999</td><td align="right" rowspan="1" colspan="1">0.7998</td><td align="right" rowspan="1" colspan="1">0.7930</td></tr></tbody></table></alternatives></table-wrap><p>We also measured the performance of SEN by adding concept vectors. The direct comparison results show that BioConceptVec has better performance than the baseline approaches. Adding BioConceptVec improves the F1-score significantly and BioConceptVec (cbow) appears to be the most effective in this task. The results of BioConceptVec (cbow) using different hyperparameters are summarized in <xref ref-type="supplementary-material" rid="pcbi.1007617.s005">S5 Table</xref>. It also shows that the performance is consistent.</p><p>We further qualitatively analyzed the errors by comparing the results of the SEN model with and without BioConceptVec. We found that the SEN model failed to classify challenging cases in which the definitions of relation types are somewhat similar. For example, the sentence, &#x0201c;Zidovudine competitively inhibits the intracellular phosphorylation of stavudine,&#x0201d; contains the relation &#x0201c;zidovudine-stavudine.&#x0201d; The annotator classified it as the effect type, but the SEN model wrongly classified it as the mechanism type. According to the annotation guidelines, both effect and mechanism types can describe pharmacological effects. The effect type, however, focuses on the change of the effect, whereas the mechanism type focuses on the underlying reason for the change. For this case, inhibiting the intracellular phosphorylation describes the change rather than the mechanism. There are ~20 similar erroneous cases for which the SEN model only mixed the effect type with the mechanism type. Adding BioConceptVec (cbow) to the SEN model correctly classified all of them. This is likely due to the fact that BioConceptVec provides additional information learnt from the entire PubMed abstracts, making the classification of the two related types easier as a result. Collectively, the results confirm the hypothesis that adding concept representatives improves the performance of downstream deep learning models and suggests that BioConceptVec has the potential to facilitate the development of deep learning models in the biomedical domain.</p><p>In this work, we propose BioConceptVec, concept embeddings that focus on primary biological concepts mentioned in the biomedical literature. We employed SOTA biological NER tools and trained four concept embeddings on the full collection of ~30 million PubMed abstracts. We evaluated the effectiveness of BioConceptVec in intrinsic and extrinsic settings, consisting of ~25 million instances in total. The results demonstrate that BioConceptVec consistently achieves the best performance in multiple datasets and in a range of applications. We hope that it can facilitate the development of deep learning models in biomedical research. In the future, we plan to leverage both PubMed abstracts and PMC full-text articles for training BioConceptVec.</p><p>This study focused on the evaluation on human genes because there are rich resources readily available for serving as a gold standard. We plan to evaluate BioConceptVec embeddings on different concept types in the future. Also, the quality of our concept embeddings is dependent on the accuracy of the NER tools. Improving NER tools such as PubTator would help enhance the quality of BioConceptVec. Finally, in this work, we did not apply retro-fitting, which is a fine-tuning step to further optimize the embeddings based on specific tasks with gold standard labels. For example, one of the most common retro-fitting procedures is to optimize the performance of the generated embeddings on identifying synonyms and acronyms. We did not employ it because such datasets are very limited for biomedical concepts. We plan to develop related datasets and apply the approach to further enhance BioConceptVec.</p></sec></sec></sec><sec sec-type="supplementary-material" id="sec019"><title>Supporting information</title><supplementary-material content-type="local-data" id="pcbi.1007617.s001"><label>S1 Table</label><caption><title>Evaluation results of the performance of the NER tools in PubTator on the concept types targeted in our study.</title><p>(DOCX)</p></caption><media xlink:href="pcbi.1007617.s001.docx"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pcbi.1007617.s002"><label>S2 Table</label><caption><title>Hyperparameters of the ANN model for the protein-protein interaction prediction.</title><p>(DOCX)</p></caption><media xlink:href="pcbi.1007617.s002.docx"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pcbi.1007617.s003"><label>S3 Table</label><caption><title>Hyperparameters of the SEN model for the drug-drug interaction prediction.</title><p>(DOCX)</p></caption><media xlink:href="pcbi.1007617.s003.docx"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pcbi.1007617.s004"><label>S4 Table</label><caption><title>Classification results of BioConceptVec (cbow) trained using different hyperparameters for the protein-protein interaction prediction.</title><p>(DOCX)</p></caption><media xlink:href="pcbi.1007617.s004.docx"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pcbi.1007617.s005"><label>S5 Table</label><caption><title>Classification results of BioConceptVec (cbow) trained using different hyperparameters for the drug-drug interaction prediction.</title><p>(DOCX)</p></caption><media xlink:href="pcbi.1007617.s005.docx"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><ack><p>The authors thank Dr. Alexis Allot and Dr. Robert Leaman for helpful discussions. We also thank Dr W. John Wilbur for proofreading the manuscript.</p></ack><ref-list><title>References</title><ref id="pcbi.1007617.ref001"><label>1</label><mixed-citation publication-type="journal"><name><surname>Singhal</surname><given-names>A</given-names></name>, <name><surname>Leaman</surname><given-names>R</given-names></name>, <name><surname>Catlett</surname><given-names>N</given-names></name>, <name><surname>Lemberger</surname><given-names>T</given-names></name>, <name><surname>McEntyre</surname><given-names>J</given-names></name>, <name><surname>Polson</surname><given-names>S</given-names></name>, <etal>et al</etal>
<article-title>Pressing needs of biomedical text mining in biocuration and beyond: opportunities and challenges</article-title>. <source>Database</source>. <year>2016</year>.</mixed-citation></ref><ref id="pcbi.1007617.ref002"><label>2</label><mixed-citation publication-type="journal"><name><surname>Lu</surname><given-names>Z</given-names></name>, <name><surname>Hirschman</surname><given-names>L</given-names></name>. <article-title>Biocuration workflows and text mining: overview of the BioCreative 2012 Workshop Track II</article-title>. <source>Database</source>. <year>2012</year>.</mixed-citation></ref><ref id="pcbi.1007617.ref003"><label>3</label><mixed-citation publication-type="journal"><name><surname>Henry</surname><given-names>S</given-names></name>, <name><surname>McInnes</surname><given-names>BT</given-names></name>. <article-title>Literature based discovery: models, methods, and trends</article-title>. <source>Journal of biomedical informatics</source>. <year>2017</year>;<volume>74</volume>:<fpage>20</fpage>&#x02013;<lpage>32</lpage>. <pub-id pub-id-type="doi">10.1016/j.jbi.2017.08.011</pub-id>
<?supplied-pmid 28838802?><pub-id pub-id-type="pmid">28838802</pub-id></mixed-citation></ref><ref id="pcbi.1007617.ref004"><label>4</label><mixed-citation publication-type="other">Ningthoujam D, Yadav S, Bhattacharyya P, Ekbal A. Relation extraction between the clinical entities based on the shortest dependency path based LSTM. arXiv preprint arXiv:190309941. 2019.</mixed-citation></ref><ref id="pcbi.1007617.ref005"><label>5</label><mixed-citation publication-type="journal"><name><surname>Zheng</surname><given-names>JG</given-names></name>, <name><surname>Howsmon</surname><given-names>D</given-names></name>, <name><surname>Zhang</surname><given-names>B</given-names></name>, <name><surname>Hahn</surname><given-names>J</given-names></name>, <name><surname>McGuinness</surname><given-names>D</given-names></name>, <name><surname>Hendler</surname><given-names>J</given-names></name>, <etal>et al</etal>
<article-title>Entity linking for biomedical literature</article-title>. <source>BMC medical informatics and decision making</source>. <year>2015</year>;<volume>15</volume>(<issue>1</issue>):<fpage>S4</fpage>.</mixed-citation></ref><ref id="pcbi.1007617.ref006"><label>6</label><mixed-citation publication-type="journal"><name><surname>Do&#x0011f;an</surname><given-names>RI</given-names></name>, <name><surname>Kim</surname><given-names>S</given-names></name>, <name><surname>Chatr-aryamontri</surname><given-names>A</given-names></name>, <name><surname>Wei</surname><given-names>C-H</given-names></name>, <name><surname>Comeau</surname><given-names>DC</given-names></name>, <name><surname>Antunes</surname><given-names>R</given-names></name>, <etal>et al</etal>
<article-title>Overview of the BioCreative VI Precision Medicine Track: mining protein interactions and mutations for precision medicine</article-title>. <source>Database: the journal of biological databases and curation</source>. <year>2019</year>.</mixed-citation></ref><ref id="pcbi.1007617.ref007"><label>7</label><mixed-citation publication-type="journal"><name><surname>Erk</surname><given-names>K</given-names></name>. <article-title>Vector space models of word meaning and phrase meaning: A survey</article-title>. <source>Language and Linguistics Compass</source>. <year>2012</year>;<volume>6</volume>(<issue>10</issue>):<fpage>635</fpage>&#x02013;<lpage>53</lpage>.</mixed-citation></ref><ref id="pcbi.1007617.ref008"><label>8</label><mixed-citation publication-type="book"><name><surname>Li</surname><given-names>Y</given-names></name>, <name><surname>Yang</surname><given-names>T</given-names></name>. <chapter-title>Word embedding for understanding natural language: a survey</chapter-title>
<source>Guide to Big Data Applications</source>: <publisher-name>Springer</publisher-name>; <year>2018</year> p. <fpage>83</fpage>&#x02013;<lpage>104</lpage>.</mixed-citation></ref><ref id="pcbi.1007617.ref009"><label>9</label><mixed-citation publication-type="journal"><name><surname>Park</surname><given-names>J</given-names></name>, <name><surname>Kim</surname><given-names>K</given-names></name>, <name><surname>Hwang</surname><given-names>W</given-names></name>, <name><surname>Lee</surname><given-names>D</given-names></name>. <article-title>Concept Embedding to Measure Semantic Relatedness for Biomedical Information Ontologies</article-title>. <source>Journal of Biomedical Informatics</source>. <year>2019</year>:<fpage>103182</fpage>
<pub-id pub-id-type="doi">10.1016/j.jbi.2019.103182</pub-id>
<?supplied-pmid 31009761?><pub-id pub-id-type="pmid">31009761</pub-id></mixed-citation></ref><ref id="pcbi.1007617.ref010"><label>10</label><mixed-citation publication-type="journal"><name><surname>Xiang</surname><given-names>Y</given-names></name>, <name><surname>Xu</surname><given-names>J</given-names></name>, <name><surname>Si</surname><given-names>Y</given-names></name>, <name><surname>Li</surname><given-names>Z</given-names></name>, <name><surname>Rasmy</surname><given-names>L</given-names></name>, <name><surname>Zhou</surname><given-names>Y</given-names></name>, <etal>et al</etal>
<article-title>Time-sensitive clinical concept embeddings learned from large electronic health records</article-title>. <source>BMC medical informatics and decision making</source>. <year>2019</year>;<volume>19</volume>(<issue>2</issue>):<fpage>58</fpage>.<pub-id pub-id-type="pmid">30961579</pub-id></mixed-citation></ref><ref id="pcbi.1007617.ref011"><label>11</label><mixed-citation publication-type="other">Beam AL, Kompa B, Fried I, Palmer NP, Shi X, Cai T, et al. Clinical Concept Embeddings Learned from Massive Sources of Multimodal Medical Data. arXiv preprint arXiv:180401486. 2018.</mixed-citation></ref><ref id="pcbi.1007617.ref012"><label>12</label><mixed-citation publication-type="journal"><name><surname>Choi</surname><given-names>Y</given-names></name>, <name><surname>Chiu</surname><given-names>CY-I</given-names></name>, <name><surname>Sontag</surname><given-names>D</given-names></name>. <article-title>Learning low-dimensional representations of medical concepts</article-title>. <source>AMIA Summits on Translational Science Proceedings</source>. <year>2016</year>;<volume>2016</volume>:<fpage>41</fpage>.</mixed-citation></ref><ref id="pcbi.1007617.ref013"><label>13</label><mixed-citation publication-type="other">Ma Y, Cambria E. Concept-Based Embeddings for Natural Language Processing. arXiv preprint arXiv:180705519. 2018.</mixed-citation></ref><ref id="pcbi.1007617.ref014"><label>14</label><mixed-citation publication-type="other">Mikolov T, Sutskever I, Chen K, Corrado GS, Dean J, editors. Distributed representations of words and phrases and their compositionality. Advances in neural information processing systems; 2013.</mixed-citation></ref><ref id="pcbi.1007617.ref015"><label>15</label><mixed-citation publication-type="other">Pennington J, Socher R, Manning C, editors. Glove: Global vectors for word representation. Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP); 2014.</mixed-citation></ref><ref id="pcbi.1007617.ref016"><label>16</label><mixed-citation publication-type="other">Mikolov T, Grave E, Bojanowski P, Puhrsch C, Joulin A. Advances in pre-training distributed word representations. arXiv preprint arXiv:171209405. 2017.</mixed-citation></ref><ref id="pcbi.1007617.ref017"><label>17</label><mixed-citation publication-type="book"><name><surname>Aggarwal</surname><given-names>CC</given-names></name>, <name><surname>Zhai</surname><given-names>C</given-names></name>. <source>Mining text data</source>: <publisher-name>Springer Science &#x00026; Business Media</publisher-name>; <year>2012</year>.</mixed-citation></ref><ref id="pcbi.1007617.ref018"><label>18</label><mixed-citation publication-type="journal"><name><surname>Lee</surname><given-names>K</given-names></name>, <name><surname>Famiglietti</surname><given-names>ML</given-names></name>, <name><surname>McMahon</surname><given-names>A</given-names></name>, <name><surname>Wei</surname><given-names>C-H</given-names></name>, <name><surname>MacArthur</surname><given-names>JAL</given-names></name>, <name><surname>Poux</surname><given-names>S</given-names></name>, <etal>et al</etal>
<article-title>Scaling up data curation using deep learning: An application to literature triage in genomic variation resources</article-title>. <source>PLoS computational biology</source>. <year>2018</year>;<volume>14</volume>(<issue>8</issue>):<fpage>e1006390</fpage>
<pub-id pub-id-type="doi">10.1371/journal.pcbi.1006390</pub-id>
<?supplied-pmid 30102703?><pub-id pub-id-type="pmid">30102703</pub-id></mixed-citation></ref><ref id="pcbi.1007617.ref019"><label>19</label><mixed-citation publication-type="journal"><name><surname>Allot</surname><given-names>A</given-names></name>, <name><surname>Chen</surname><given-names>Q</given-names></name>, <name><surname>Kim</surname><given-names>S</given-names></name>, <name><surname>Vera Alvarez</surname><given-names>R</given-names></name>, <name><surname>Comeau</surname><given-names>DC</given-names></name>, <name><surname>Wilbur</surname><given-names>WJ</given-names></name>, <etal>et al</etal>
<article-title>LitSense: making sense of biomedical literature at sentence level</article-title>. <source>Nucleic acids research</source>. <year>2019</year>.</mixed-citation></ref><ref id="pcbi.1007617.ref020"><label>20</label><mixed-citation publication-type="journal"><name><surname>Dimitriadis</surname><given-names>D</given-names></name>, <name><surname>Tsoumakas</surname><given-names>G</given-names></name>. <article-title>Word embeddings and external resources for answer processing in biomedical factoid question answering</article-title>. <source>Journal of biomedical informatics</source>. <year>2019</year>;<volume>92</volume>:<fpage>103118</fpage>
<pub-id pub-id-type="doi">10.1016/j.jbi.2019.103118</pub-id>
<?supplied-pmid 30753948?><pub-id pub-id-type="pmid">30753948</pub-id></mixed-citation></ref><ref id="pcbi.1007617.ref021"><label>21</label><mixed-citation publication-type="other">Wei C-H, Lee K, Leaman R, Lu Z, editors. Biomedical Mention Disambiguation using a Deep Learning Approach. Proceedings of the 10th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics; 2019: ACM.</mixed-citation></ref><ref id="pcbi.1007617.ref022"><label>22</label><mixed-citation publication-type="journal"><name><surname>Du</surname><given-names>J</given-names></name>, <name><surname>Jia</surname><given-names>P</given-names></name>, <name><surname>Dai</surname><given-names>Y</given-names></name>, <name><surname>Tao</surname><given-names>C</given-names></name>, <name><surname>Zhao</surname><given-names>Z</given-names></name>, <name><surname>Zhi</surname><given-names>D</given-names></name>. <article-title>Gene2vec: distributed representation of genes based on co-expression</article-title>. <source>BMC genomics</source>. <year>2019</year>;<volume>20</volume>(<issue>1</issue>):<fpage>82</fpage>.<pub-id pub-id-type="pmid">30712510</pub-id></mixed-citation></ref><ref id="pcbi.1007617.ref023"><label>23</label><mixed-citation publication-type="journal"><name><surname>Bodenreider</surname><given-names>O</given-names></name>. <article-title>The unified medical language system (UMLS): integrating biomedical terminology</article-title>. <source>Nucleic acids research</source>. <year>2004</year>;<volume>32</volume>(<issue>suppl_1</issue>):<fpage>D267</fpage>&#x02013;<lpage>D70</lpage>.<pub-id pub-id-type="pmid">14681409</pub-id></mixed-citation></ref><ref id="pcbi.1007617.ref024"><label>24</label><mixed-citation publication-type="other">Hassanzadeh H, Nguyen A, Koopman B, editors. Evaluation of medical concept annotation systems on clinical records. Proceedings of the Australasian Language Technology Association Workshop 2016; 2016.</mixed-citation></ref><ref id="pcbi.1007617.ref025"><label>25</label><mixed-citation publication-type="other">Lin Y-C, Christen V, Gro&#x000df; A, Cardoso SD, Pruski C, Da Silveira M, et al., editors. Evaluating and improving annotation tools for medical forms. International Conference on Data Integration in the Life Sciences; 2017: Springer.</mixed-citation></ref><ref id="pcbi.1007617.ref026"><label>26</label><mixed-citation publication-type="journal"><name><surname>Re&#x000e1;tegui</surname><given-names>R</given-names></name>, <name><surname>Ratt&#x000e9;</surname><given-names>S</given-names></name>. <article-title>Comparison of MetaMap and cTAKES for entity extraction in clinical notes</article-title>. <source>BMC medical informatics and decision making</source>. <year>2018</year>;<volume>18</volume>(<issue>3</issue>):<fpage>74</fpage>.<pub-id pub-id-type="pmid">30255810</pub-id></mixed-citation></ref><ref id="pcbi.1007617.ref027"><label>27</label><mixed-citation publication-type="journal"><name><surname>Suominen</surname><given-names>H</given-names></name>, <name><surname>Zhou</surname><given-names>L</given-names></name>, <name><surname>Hanlen</surname><given-names>L</given-names></name>, <name><surname>Ferraro</surname><given-names>G</given-names></name>. <article-title>Benchmarking clinical speech recognition and information extraction: new data, methods, and evaluations</article-title>. <source>JMIR medical informatics</source>. <year>2015</year>;<volume>3</volume>(<issue>2</issue>):<fpage>e19</fpage>
<pub-id pub-id-type="doi">10.2196/medinform.4321</pub-id>
<?supplied-pmid 25917752?><pub-id pub-id-type="pmid">25917752</pub-id></mixed-citation></ref><ref id="pcbi.1007617.ref028"><label>28</label><mixed-citation publication-type="journal"><name><surname>Pradhan</surname><given-names>S</given-names></name>, <name><surname>Elhadad</surname><given-names>N</given-names></name>, <name><surname>South</surname><given-names>BR</given-names></name>, <name><surname>Martinez</surname><given-names>D</given-names></name>, <name><surname>Christensen</surname><given-names>L</given-names></name>, <name><surname>Vogel</surname><given-names>A</given-names></name>, <etal>et al</etal>
<article-title>Evaluating the state of the art in disorder recognition and normalization of the clinical narrative</article-title>. <source>Journal of the American Medical Informatics Association</source>. <year>2014</year>;<volume>22</volume>(<issue>1</issue>):<fpage>143</fpage>&#x02013;<lpage>54</lpage>. <pub-id pub-id-type="doi">10.1136/amiajnl-2013-002544</pub-id>
<?supplied-pmid 25147248?><pub-id pub-id-type="pmid">25147248</pub-id></mixed-citation></ref><ref id="pcbi.1007617.ref029"><label>29</label><mixed-citation publication-type="other">Schnabel T, Labutov I, Mimno D, Joachims T, editors. Evaluation methods for unsupervised word embeddings. Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing; 2015.</mixed-citation></ref><ref id="pcbi.1007617.ref030"><label>30</label><mixed-citation publication-type="other">Choi E, Bahadori MT, Sun J, Kulas J, Schuetz A, Stewart W, editors. Retain: An interpretable predictive model for healthcare using reverse time attention mechanism. Advances in Neural Information Processing Systems; 2016.</mixed-citation></ref><ref id="pcbi.1007617.ref031"><label>31</label><mixed-citation publication-type="other">Pakhomov S, McInnes B, Adam T, Liu Y, Pedersen T, Melton GB, editors. Semantic similarity and relatedness between clinical terms: an experimental study. AMIA annual symposium proceedings; 2010: American Medical Informatics Association.</mixed-citation></ref><ref id="pcbi.1007617.ref032"><label>32</label><mixed-citation publication-type="journal"><name><surname>Wei</surname><given-names>C-H</given-names></name>, <name><surname>Kao</surname><given-names>H-Y</given-names></name>, <name><surname>Lu</surname><given-names>Z</given-names></name>. <article-title>PubTator: a web-based text mining tool for assisting biocuration</article-title>. <source>Nucleic acids research</source>. <year>2013</year>;<volume>41</volume>(<issue>W1</issue>):<fpage>W518</fpage>&#x02013;<lpage>W22</lpage>.<pub-id pub-id-type="pmid">23703206</pub-id></mixed-citation></ref><ref id="pcbi.1007617.ref033"><label>33</label><mixed-citation publication-type="journal"><name><surname>Szklarczyk</surname><given-names>D</given-names></name>, <name><surname>Gable</surname><given-names>AL</given-names></name>, <name><surname>Lyon</surname><given-names>D</given-names></name>, <name><surname>Junge</surname><given-names>A</given-names></name>, <name><surname>Wyder</surname><given-names>S</given-names></name>, <name><surname>Huerta-Cepas</surname><given-names>J</given-names></name>, <etal>et al</etal>
<article-title>STRING v11: protein&#x02013;protein association networks with increased coverage, supporting functional discovery in genome-wide experimental datasets</article-title>. <source>Nucleic acids research</source>. <year>2018</year>;<volume>47</volume>(<issue>D1</issue>):<fpage>D607</fpage>&#x02013;<lpage>D13</lpage>.</mixed-citation></ref><ref id="pcbi.1007617.ref034"><label>34</label><mixed-citation publication-type="other">Chen Q, Peng Y, Lu Z, editors. BioSentVec: creating sentence embeddings for biomedical texts. 2019 IEEE International Conference on Healthcare Informatics (ICHI); 2019: IEEE.</mixed-citation></ref><ref id="pcbi.1007617.ref035"><label>35</label><mixed-citation publication-type="journal"><name><surname>Leaman</surname><given-names>R</given-names></name>, <name><surname>Lu</surname><given-names>Z</given-names></name>. <article-title>TaggerOne: joint named entity recognition and normalization with semi-Markov Models</article-title>. <source>Bioinformatics</source>. <year>2016</year>;<volume>32</volume>(<issue>18</issue>):<fpage>2839</fpage>&#x02013;<lpage>46</lpage>. Epub 2016/06/11. <pub-id pub-id-type="doi">10.1093/bioinformatics/btw343</pub-id>
<?supplied-pmid 27283952?><pub-id pub-id-type="pmid">27283952</pub-id></mixed-citation></ref><ref id="pcbi.1007617.ref036"><label>36</label><mixed-citation publication-type="journal"><name><surname>Wei</surname><given-names>C-H</given-names></name>, <name><surname>Kao</surname><given-names>H-Y</given-names></name>, <name><surname>Lu</surname><given-names>Z</given-names></name>. <article-title>GNormPlus: an integrative approach for tagging genes, gene families, and protein domains</article-title>. <source>BioMed research international</source>. <year>2015</year>;<volume>2015</volume>.</mixed-citation></ref><ref id="pcbi.1007617.ref037"><label>37</label><mixed-citation publication-type="journal"><name><surname>Wei</surname><given-names>C-H</given-names></name>, <name><surname>Phan</surname><given-names>L</given-names></name>, <name><surname>Feltz</surname><given-names>J</given-names></name>, <name><surname>Maiti</surname><given-names>R</given-names></name>, <name><surname>Hefferon</surname><given-names>T</given-names></name>, <name><surname>Lu</surname><given-names>Z</given-names></name>. <article-title>tmVar 2.0: integrating genomic variant information from literature with dbSNP and ClinVar for precision medicine</article-title>. <source>Bioinformatics</source>. <year>2017</year>;<volume>34</volume>(<issue>1</issue>):<fpage>80</fpage>&#x02013;<lpage>7</lpage>.</mixed-citation></ref><ref id="pcbi.1007617.ref038"><label>38</label><mixed-citation publication-type="journal"><name><surname>Wei</surname><given-names>CH</given-names></name>, <name><surname>Kao</surname><given-names>HY</given-names></name>, <name><surname>Lu</surname><given-names>Z</given-names></name>. <article-title>SR4GN: a species recognition software tool for gene normalization</article-title>. <source>PLoS One</source>. <year>2012</year>;<volume>7</volume>(<issue>6</issue>):<fpage>e38460</fpage> Epub 2012/06/09. <pub-id pub-id-type="doi">10.1371/journal.pone.0038460</pub-id>
<?supplied-pmid 22679507?><pub-id pub-id-type="pmid">22679507</pub-id></mixed-citation></ref><ref id="pcbi.1007617.ref039"><label>39</label><mixed-citation publication-type="book"><name><surname>Wei</surname><given-names>C-H</given-names></name>, <name><surname>Allot</surname><given-names>A</given-names></name>, <name><surname>Leaman</surname><given-names>R</given-names></name>, <name><surname>Lu</surname><given-names>Z</given-names></name>. <source>PubTator central: automated concept annotation for biomedical full text articles</source>. <publisher-name>Nucleic acids research</publisher-name>
<year>2019</year>.</mixed-citation></ref><ref id="pcbi.1007617.ref040"><label>40</label><mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>Y</given-names></name>, <name><surname>Wang</surname><given-names>J</given-names></name>, <name><surname>Lin</surname><given-names>H</given-names></name>, <name><surname>Tang</surname><given-names>X</given-names></name>, <name><surname>Zhang</surname><given-names>S</given-names></name>, <name><surname>Li</surname><given-names>L</given-names></name>. <article-title>Bidirectional long short-term memory with CRF for detecting biomedical event trigger in FastText semantic space</article-title>. <source>BMC bioinformatics</source>. <year>2018</year>;<volume>19</volume>(<issue>20</issue>):<fpage>507</fpage>.<pub-id pub-id-type="pmid">30577839</pub-id></mixed-citation></ref><ref id="pcbi.1007617.ref041"><label>41</label><mixed-citation publication-type="other">Jin D, Szolovits P. Hierarchical Neural Networks for Sequential Sentence Classification in Medical Scientific Abstracts. arXiv preprint arXiv:180806161. 2018.</mixed-citation></ref><ref id="pcbi.1007617.ref042"><label>42</label><mixed-citation publication-type="other">Bojanowski P, Grave E, Joulin A, Mikolov T. Enriching word vectors with subword information. arXiv preprint arXiv:160704606. 2016.</mixed-citation></ref><ref id="pcbi.1007617.ref043"><label>43</label><mixed-citation publication-type="other">Yu Z, Wallace BC, Johnson T, Cohen T. Retrofitting concept vector representations of medical concepts to improve estimates of semantic similarity and relatedness. arXiv preprint arXiv:170907357. 2017.</mixed-citation></ref><ref id="pcbi.1007617.ref044"><label>44</label><mixed-citation publication-type="other">Chen Q, Du J, Kim S, Wilbur WJ, Lu Z. Deep learning with sentence embeddings pre-trained on biomedical corpora improves the performance of finding similar sentences in electronic medical records. arXiv preprint arXiv:190903044. 2019.</mixed-citation></ref><ref id="pcbi.1007617.ref045"><label>45</label><mixed-citation publication-type="other">Jang M, Kang P. Paraphrase Thought: Sentence Embedding Module Imitating Human Language Recognition. arXiv preprint arXiv:180805505. 2018.</mixed-citation></ref><ref id="pcbi.1007617.ref046"><label>46</label><mixed-citation publication-type="other">Chiu B, Crichton G, Korhonen A, Pyysalo S, editors. How to train good word embeddings for biomedical NLP. Proceedings of the 15th Workshop on Biomedical Natural Language Processing; 2016.</mixed-citation></ref><ref id="pcbi.1007617.ref047"><label>47</label><mixed-citation publication-type="other">De Vine L, Zuccon G, Koopman B, Sitbon L, Bruza P, editors. Medical semantic similarity with a neural language model. Proceedings of the 23rd ACM international conference on conference on information and knowledge management; 2014: ACM.</mixed-citation></ref><ref id="pcbi.1007617.ref048"><label>48</label><mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>Y</given-names></name>, <name><surname>Liu</surname><given-names>S</given-names></name>, <name><surname>Afzal</surname><given-names>N</given-names></name>, <name><surname>Rastegar-Mojarad</surname><given-names>M</given-names></name>, <name><surname>Wang</surname><given-names>L</given-names></name>, <name><surname>Shen</surname><given-names>F</given-names></name>, <etal>et al</etal>
<article-title>A comparison of word embeddings for the biomedical natural language processing</article-title>. <source>Journal of biomedical informatics</source>. <year>2018</year>.</mixed-citation></ref><ref id="pcbi.1007617.ref049"><label>49</label><mixed-citation publication-type="journal"><name><surname>Barabasi</surname><given-names>A-L</given-names></name>, <name><surname>Oltvai</surname><given-names>ZN</given-names></name>. <article-title>Network biology: understanding the cell's functional organization</article-title>. <source>Nature reviews genetics</source>. <year>2004</year>;<volume>5</volume>(<issue>2</issue>):<fpage>101</fpage>
<pub-id pub-id-type="doi">10.1038/nrg1272</pub-id>
<?supplied-pmid 14735121?><pub-id pub-id-type="pmid">14735121</pub-id></mixed-citation></ref><ref id="pcbi.1007617.ref050"><label>50</label><mixed-citation publication-type="journal"><name><surname>Hartwell</surname><given-names>LH</given-names></name>, <name><surname>Hopfield</surname><given-names>JJ</given-names></name>, <name><surname>Leibler</surname><given-names>S</given-names></name>, <name><surname>Murray</surname><given-names>AW</given-names></name>. <article-title>From molecular to modular cell biology</article-title>. <source>Nature</source>. <year>1999</year>;<volume>402</volume>(<issue>6761supp</issue>):<fpage>C47</fpage>.<pub-id pub-id-type="pmid">10591225</pub-id></mixed-citation></ref><ref id="pcbi.1007617.ref051"><label>51</label><mixed-citation publication-type="journal"><name><surname>Davis</surname><given-names>AP</given-names></name>, <name><surname>Grondin</surname><given-names>CJ</given-names></name>, <name><surname>Johnson</surname><given-names>RJ</given-names></name>, <name><surname>Sciaky</surname><given-names>D</given-names></name>, <name><surname>McMorran</surname><given-names>R</given-names></name>, <name><surname>Wiegers</surname><given-names>J</given-names></name>, <etal>et al</etal>
<article-title>The comparative toxicogenomics database: Update 2019</article-title>. <source>Nucleic acids research</source>. <year>2018</year>;<volume>47</volume>(<issue>D1</issue>):<fpage>D948</fpage>&#x02013;<lpage>D54</lpage>.</mixed-citation></ref><ref id="pcbi.1007617.ref052"><label>52</label><mixed-citation publication-type="journal"><name><surname>Liberzon</surname><given-names>A</given-names></name>, <name><surname>Subramanian</surname><given-names>A</given-names></name>, <name><surname>Pinchback</surname><given-names>R</given-names></name>, <name><surname>Thorvaldsd&#x000f3;ttir</surname><given-names>H</given-names></name>, <name><surname>Tamayo</surname><given-names>P</given-names></name>, <name><surname>Mesirov</surname><given-names>JP</given-names></name>. <article-title>Molecular signatures database (MSigDB) 3.0</article-title>. <source>Bioinformatics</source>. <year>2011</year>;<volume>27</volume>(<issue>12</issue>):<fpage>1739</fpage>&#x02013;<lpage>40</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btr260</pub-id>
<?supplied-pmid 21546393?><pub-id pub-id-type="pmid">21546393</pub-id></mixed-citation></ref><ref id="pcbi.1007617.ref053"><label>53</label><mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>Y</given-names></name>, <name><surname>Chen</surname><given-names>Q</given-names></name>, <name><surname>Yang</surname><given-names>Z</given-names></name>, <name><surname>Lin</surname><given-names>H</given-names></name>, <name><surname>Lu</surname><given-names>Z</given-names></name>. <article-title>BioWordVec, improving biomedical word embeddings with subword information and MeSH</article-title>. <source>Scientific data</source>. <year>2019</year>;<volume>6</volume>(<issue>1</issue>):<fpage>52</fpage>
<pub-id pub-id-type="doi">10.1038/s41597-019-0055-0</pub-id>
<?supplied-pmid 31076572?><pub-id pub-id-type="pmid">31076572</pub-id></mixed-citation></ref><ref id="pcbi.1007617.ref054"><label>54</label><mixed-citation publication-type="other">Segura Bedmar I, Mart&#x000ed;nez P, Herrero Zazo M, editors. Semeval-2013 task 9: Extraction of drug-drug interactions from biomedical texts (ddiextraction 2013)2013: Association for Computational Linguistics.</mixed-citation></ref><ref id="pcbi.1007617.ref055"><label>55</label><mixed-citation publication-type="journal"><name><surname>Huttlin</surname><given-names>EL</given-names></name>, <name><surname>Ting</surname><given-names>L</given-names></name>, <name><surname>Bruckner</surname><given-names>RJ</given-names></name>, <name><surname>Gebreab</surname><given-names>F</given-names></name>, <name><surname>Gygi</surname><given-names>MP</given-names></name>, <name><surname>Szpyt</surname><given-names>J</given-names></name>, <etal>et al</etal>
<article-title>The BioPlex network: a systematic exploration of the human interactome</article-title>. <source>Cell</source>. <year>2015</year>;<volume>162</volume>(<issue>2</issue>):<fpage>425</fpage>&#x02013;<lpage>40</lpage>. <pub-id pub-id-type="doi">10.1016/j.cell.2015.06.043</pub-id>
<?supplied-pmid 26186194?><pub-id pub-id-type="pmid">26186194</pub-id></mixed-citation></ref><ref id="pcbi.1007617.ref056"><label>56</label><mixed-citation publication-type="journal"><name><surname>Smaili</surname><given-names>FZ</given-names></name>, <name><surname>Gao</surname><given-names>X</given-names></name>, <name><surname>Hoehndorf</surname><given-names>R</given-names></name>. <article-title>Onto2vec: joint vector-based representation of biological entities and their ontology-based annotations</article-title>. <source>Bioinformatics</source>. <year>2018</year>;<volume>34</volume>(<issue>13</issue>):<fpage>i52</fpage>&#x02013;<lpage>i60</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/bty259</pub-id>
<?supplied-pmid 29949999?><pub-id pub-id-type="pmid">29949999</pub-id></mixed-citation></ref><ref id="pcbi.1007617.ref057"><label>57</label><mixed-citation publication-type="other">Smaili FZ, Gao X, Hoehndorf R. Opa2vec: combining formal and informal content of biomedical ontologies to improve similarity-based prediction. arXiv preprint arXiv:180410922. 2018.</mixed-citation></ref><ref id="pcbi.1007617.ref058"><label>58</label><mixed-citation publication-type="journal"><name><surname>Wishart</surname><given-names>DS</given-names></name>, <name><surname>Feunang</surname><given-names>YD</given-names></name>, <name><surname>Guo</surname><given-names>AC</given-names></name>, <name><surname>Lo</surname><given-names>EJ</given-names></name>, <name><surname>Marcu</surname><given-names>A</given-names></name>, <name><surname>Grant</surname><given-names>JR</given-names></name>, <etal>et al</etal>
<article-title>DrugBank 5.0: a major update to the DrugBank database for 2018</article-title>. <source>Nucleic acids research</source>. <year>2017</year>;<volume>46</volume>(<issue>D1</issue>):<fpage>D1074</fpage>&#x02013;<lpage>D82</lpage>.</mixed-citation></ref><ref id="pcbi.1007617.ref059"><label>59</label><mixed-citation publication-type="journal"><name><surname>Herrero-Zazo</surname><given-names>M</given-names></name>, <name><surname>Segura-Bedmar</surname><given-names>I</given-names></name>, <name><surname>Mart&#x000ed;nez</surname><given-names>P</given-names></name>, <name><surname>Declerck</surname><given-names>T</given-names></name>. <article-title>The DDI corpus: An annotated corpus with pharmacological substances and drug&#x02013;drug interactions</article-title>. <source>Journal of biomedical informatics</source>. <year>2013</year>;<volume>46</volume>(<issue>5</issue>):<fpage>914</fpage>&#x02013;<lpage>20</lpage>. <pub-id pub-id-type="doi">10.1016/j.jbi.2013.07.011</pub-id>
<?supplied-pmid 23906817?><pub-id pub-id-type="pmid">23906817</pub-id></mixed-citation></ref><ref id="pcbi.1007617.ref060"><label>60</label><mixed-citation publication-type="other">Peters ME, Neumann M, Iyyer M, Gardner M, Clark C, Lee K, et al. Deep contextualized word representations. arXiv preprint arXiv:180205365. 2018.</mixed-citation></ref><ref id="pcbi.1007617.ref061"><label>61</label><mixed-citation publication-type="other">Chauhan G, McDermott M, Szolovits P. Reflex: Flexible Framework for Relation Extraction in Multiple Domains. arXiv preprint arXiv:190608318. 2019.</mixed-citation></ref><ref id="pcbi.1007617.ref062"><label>62</label><mixed-citation publication-type="other">Peters ME, Ammar W, Bhagavatula C, Power R. Semi-supervised sequence tagging with bidirectional language models. arXiv preprint arXiv:170500108. 2017.</mixed-citation></ref><ref id="pcbi.1007617.ref063"><label>63</label><mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>Y</given-names></name>, <name><surname>Zheng</surname><given-names>W</given-names></name>, <name><surname>Lin</surname><given-names>H</given-names></name>, <name><surname>Wang</surname><given-names>J</given-names></name>, <name><surname>Yang</surname><given-names>Z</given-names></name>, <name><surname>Dumontier</surname><given-names>M</given-names></name>. <article-title>Drug&#x02013;drug interaction extraction via hierarchical RNNs on sequence and shortest dependency paths</article-title>. <source>Bioinformatics</source>. <year>2017</year>;<volume>34</volume>(<issue>5</issue>):<fpage>828</fpage>&#x02013;<lpage>35</lpage>.</mixed-citation></ref><ref id="pcbi.1007617.ref064"><label>64</label><mixed-citation publication-type="other">Choi E, Bahadori MT, Searles E, Coffey C, Thompson M, Bost J, et al., editors. Multi-layer representation learning for medical concepts. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; 2016: ACM.</mixed-citation></ref><ref id="pcbi.1007617.ref065"><label>65</label><mixed-citation publication-type="other">Cai X, Gao J, Ngiam KY, Ooi BC, Zhang Y, Yuan X. Medical concept embedding with time-aware attention. arXiv preprint arXiv:180602873. 2018.</mixed-citation></ref><ref id="pcbi.1007617.ref066"><label>66</label><mixed-citation publication-type="other">Nguyen K, Ichise R, editors. Learning Effective Distributed Representation of Complex Biomedical Concepts. 2018 IEEE 18th International Conference on Bioinformatics and Bioengineering (BIBE); 2018: IEEE.</mixed-citation></ref></ref-list></back></article>