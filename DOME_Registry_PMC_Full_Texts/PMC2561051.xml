<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id><journal-title>BMC Bioinformatics</journal-title><issn pub-type="epub">1471-2105</issn><publisher><publisher-name>BioMed Central</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">2561051</article-id><article-id pub-id-type="publisher-id">1471-2105-9-389</article-id><article-id pub-id-type="pmid">18808707</article-id><article-id pub-id-type="doi">10.1186/1471-2105-9-389</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>Combining classifiers for improved classification of proteins from sequence or structure</article-title></title-group><contrib-group><contrib id="A1" contrib-type="author"><name><surname>Melvin</surname><given-names>Iain</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>iainmelvin@gmail.com</email></contrib><contrib id="A2" contrib-type="author"><name><surname>Weston</surname><given-names>Jason</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>jasonw@nec-labs.com</email></contrib><contrib id="A3" contrib-type="author"><name><surname>Leslie</surname><given-names>Christina S</given-names></name><xref ref-type="aff" rid="I2">2</xref><email>cleslie@cbio.mskcc.org</email></contrib><contrib id="A4" corresp="yes" contrib-type="author"><name><surname>Noble</surname><given-names>William S</given-names></name><xref ref-type="aff" rid="I3">3</xref><email>noble@gs.washington.edu</email></contrib></contrib-group><aff id="I1"><label>1</label>NEC Laboratories of America, Princeton, NJ, USA</aff><aff id="I2"><label>2</label>Computational Biology Program, Sloan-Kettering Institute, Memorial Sloan-Kettering Cancer Center, New York, NY, USA</aff><aff id="I3"><label>3</label>Department of Genome Sciences, Department of Computer Science and Engineering, University of Washington, Seattle, WA, USA</aff><pub-date pub-type="collection"><year>2008</year></pub-date><pub-date pub-type="epub"><day>22</day><month>9</month><year>2008</year></pub-date><volume>9</volume><fpage>389</fpage><lpage>389</lpage><ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/1471-2105/9/389"/><history><date date-type="received"><day>1</day><month>2</month><year>2008</year></date><date date-type="accepted"><day>22</day><month>9</month><year>2008</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2008 Melvin et al; licensee BioMed Central Ltd.</copyright-statement><copyright-year>2008</copyright-year><copyright-holder>Melvin et al; licensee BioMed Central Ltd.</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0"><p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0"/>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</p><!--<rdf xmlns="http://web.resource.org/cc/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1" xmlns:dcterms="http://purl.org/dc/terms"><Work xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:dcterms="http://purl.org/dc/terms/" rdf:about=""><license rdf:resource="http://creativecommons.org/licenses/by/2.0"/><dc:type rdf:resource="http://purl.org/dc/dcmitype/Text"/><dc:author>
               Melvin
               Iain
               
               iainmelvin@gmail.com
            </dc:author><dc:title>
            Combining classifiers for improved classification of proteins from sequence or structure
         </dc:title><dc:date>2008</dc:date><dcterms:bibliographicCitation>BMC Bioinformatics 9(1): 389-. (2008)</dcterms:bibliographicCitation><dc:identifier type="sici">1471-2105(2008)9:1&#x0003c;389&#x0003e;</dc:identifier><dcterms:isPartOf>urn:ISSN:1471-2105</dcterms:isPartOf><License rdf:about="http://creativecommons.org/licenses/by/2.0"><permits rdf:resource="http://web.resource.org/cc/Reproduction" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/Distribution" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Notice" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Attribution" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/DerivativeWorks" xmlns=""/></License></Work></rdf>--></license></permissions><abstract><sec><title>Background</title><p>Predicting a protein's structural or functional class from its amino acid sequence or structure is a fundamental problem in computational biology. Recently, there has been considerable interest in using discriminative learning algorithms, in particular support vector machines (SVMs), for classification of proteins. However, because sufficiently many positive examples are required to train such classifiers, all SVM-based methods are hampered by limited coverage.</p></sec><sec><title>Results</title><p>In this study, we develop a hybrid machine learning approach for classifying proteins, and we apply the method to the problem of assigning proteins to structural categories based on their sequences or their 3D structures. The method combines a full-coverage but lower accuracy nearest neighbor method with higher accuracy but reduced coverage multiclass SVMs to produce a full coverage classifier with overall improved accuracy. The hybrid approach is based on the simple idea of "punting" from one method to another using a learned threshold.</p></sec><sec><title>Conclusion</title><p>In cross-validated experiments on the SCOP hierarchy, the hybrid methods consistently outperform the individual component methods at all levels of coverage.</p><p>Code and data sets are available at <ext-link ext-link-type="uri" xlink:href="http://noble.gs.washington.edu/proj/sabretooth"/></p></sec></abstract></article-meta></front><body><sec><title>Background</title><p>To facilitate the automatic annotation of newly sequenced proteins or newly resolved protein structures, we are interested in developing computational methods to automatically assign proteins to structural and functional categories. Traditional computational methods for comparing protein structures depend on pairwise structural alignment programs such as CE [<xref ref-type="bibr" rid="B1">1</xref>], DALI [<xref ref-type="bibr" rid="B2">2</xref>] or MAMMOTH [<xref ref-type="bibr" rid="B3">3</xref>]. Similarly, sequence-based algorithms such as Smith-Waterman [<xref ref-type="bibr" rid="B4">4</xref>], BLAST [<xref ref-type="bibr" rid="B5">5</xref>], SAM-T98 [<xref ref-type="bibr" rid="B6">6</xref>] and PSI-BLAST [<xref ref-type="bibr" rid="B7">7</xref>] assign similarity scores to pairs of protein sequences. Using pairwise structural comparisons of a query sequence or structure against a curated database, one can use any of these tools to implement a nearest neighbor (NN) strategy to classify the query.</p><p>In 1999, Jaakkola <italic>et al. </italic>[<xref ref-type="bibr" rid="B8">8</xref>] first applied the support vector machine (SVM) classifier [<xref ref-type="bibr" rid="B9">9</xref>] to the problem of predicting a protein's structural class from its amino acid sequence. They focused on a particular protein structural hierarchy called the Structural Classification of Proteins (SCOP) [<xref ref-type="bibr" rid="B10">10</xref>], and they trained SVMs to recognize novel families within a given superfamily. This seminal work led to the development of many SVM-based protein classifiers (reviewed in [<xref ref-type="bibr" rid="B11">11</xref>]), and this work continues up to the present [<xref ref-type="bibr" rid="B12">12</xref>-<xref ref-type="bibr" rid="B15">15</xref>].</p><p>Primarily, these classifiers differ in their <italic>kernel functions</italic>. In this context, a kernel is a function that defines similarities between pairs of proteins. For this task, a good kernel function is one that allows the SVM to separate proteins easily according to their SCOP categories. In the experiments reported here, we train SVMs to classify amino acid sequences into SCOP superfamilies using the profile kernel [<xref ref-type="bibr" rid="B16">16</xref>], which is among the best-performing SVM-based methods.</p><p>More recently, several groups have extended SVM-based methods to the classification of protein structures, rather than protein sequences [<xref ref-type="bibr" rid="B17">17</xref>-<xref ref-type="bibr" rid="B19">19</xref>]. In the current work, for prediction of SCOP superfamilies from structures, we train SVMs using a kernel function based on MAMMOTH [<xref ref-type="bibr" rid="B3">3</xref>]. Benchmark experiments have shown that SVM-based discrimination with a MAMMOTH kernel outperforms several other SVM-based methods and also outperforms using MAMMOTH in a nearest neighbor fashion [<xref ref-type="bibr" rid="B19">19</xref>].</p><p>In this work, we aim to address a fundamental limitation of any SVM-based method, namely, that an SVM can only be trained when a sufficient number of training examples are available. In particular, to train an SVM to recognize a given SCOP category, we must be able to present to the SVM at least a handful of representative proteins. For under-represented SCOP categories, the SVM cannot be trained, and as a result, the classifier has limited coverage. For example, in SCOP version 1.69, 60.2% of the superfamilies contain three or fewer proteins. Failing to make predictions for these small superfamilies significantly decreases the effective accuracy of the SVM-based method, making it impractical for automated classification of the entire SCOP hierarchy.</p><p>In this study, we develop a hybrid machine learning approach that we apply to the problems of classifying proteins from sequence or from structure. Our goal is to combine nearest neighbor methods, which in principle have complete coverage over any given data set, with higher accuracy but reduced coverage multiclass SVM approaches to produce a full coverage method with overall improved accuracy. The hybrid approach is based on the simple idea of "punting" from one method to another. We use held-out data to learn a set of score thresholds. At test time, predictions from the primary method that receive scores below the threshold are "punted" to the secondary method. In addition, we consider different coverage thresholds at which to punt out of the secondary method (i.e., abstain from making a prediction altogether), and we compute error rates of the hybrid method at these different coverage levels.</p><p>We use this punting method to build hybrid predictors of SCOP superfamilies, taking as input either protein sequences or structures. Using punting, we find that the hybrid methods consistently outperform the individual component methods at all levels of coverage.</p></sec><sec><title>Results</title><sec><title>Approach</title><p>The punting strategy is depicted in Figure <xref ref-type="fig" rid="F1">1</xref>. In its simplest form (Figure <xref ref-type="fig" rid="F1">1A</xref>), the strategy relies upon a vector <bold>T </bold>of class-specific parameters. These parameters are learned by the algorithm, given a <italic>single </italic>hyperparameter supplied by the user. A query protein representation is first given to the primary classification method. The classifier produces a predicted classification <italic>i </italic>along with a score <italic>s</italic>, the magnitude of which indicates the confidence in the prediction. If this score exceeds <italic>T</italic><sub><italic>i</italic></sub>, then the current class is predicted. Otherwise, the query is punted to the secondary classifier, which makes its own prediction. Typically, the primary classifier is the one with higher accuracy and lower coverage, although we also experiment with punting in the other direction. It is sometimes preferable to make no prediction at all, rather than make a prediction that is very likely incorrect. In this case, a second set of class-specific thresholds allows the second classifier to punt as well, as shown in Figure <xref ref-type="fig" rid="F1">1B</xref>.</p><fig position="float" id="F1"><label>Figure 1</label><caption><p><bold>Two punting strategies</bold>. (A) Two classifiers are combined to produce a hybrid classifier with improved accuracy and coverage. The punting thresholds (<bold>T </bold>= [<italic>T</italic><sub>1</sub>, ..., <italic>T</italic><sub><italic>n</italic></sub>]) are class-dependent and are set using held-out data. (B) This approach is similar to (A), except that using two vectors of punting thresholds &#x02013; <bold>T</bold><sup>1 </sup>for the primary classifier and <bold>T</bold><sup>2 </sup>for the secondary classifier &#x02013; allows the method sometimes to make no prediction at all.</p></caption><graphic xlink:href="1471-2105-9-389-1"/></fig><p>To learn punting thresholds, we divide our training set into two portions, a <italic>classifier training set </italic>and a <italic>threshold training set</italic>, which are used, respectively, to train the classifier and to learn class-specific score thresholds. The user must set a <italic>single </italic>hyperparameter <italic>&#x003c1; </italic>between 0 and 1, which controls the fraction of examples that one wishes to cover, as illustrated in Figure <xref ref-type="fig" rid="F2">2</xref>. The algorithm then sets, for each class, the score threshold such that a fraction <italic>&#x003c1; </italic>of the negative examples from the threshold training set are false positives, given the predictions of that classifier. Hence, when we set <italic>&#x003c1; </italic>= 1 the method will never punt. When we set <italic>&#x003c1; </italic>= 0, on the other hand, the algorithm is rather unlikely to produce a false positive. Values of <italic>&#x003c1; </italic>between 0 and 1 yield behavior between these two extremes.</p><fig position="float" id="F2"><label>Figure 2</label><caption><p><bold>Learning punting thresholds</bold>. The punting threshold is learnt according to the percentage of false positives in a validation set. The figure illustrates, for a simulated data set of 20 positive and 20 negative examples, three choices of threshold: 0%, 5% or 20% false positives.</p></caption><graphic xlink:href="1471-2105-9-389-2"/></fig><p>We compare this method to a few simple variants. First, we can apply punting to a <italic>single </italic>method, rather than a hybrid method. In this setting, when the punting algorithm decides to punt, there is simply no prediction made at all. Second, for a given method, rather than having a vector of class-specific score thresholds <bold>T</bold>, we can use a single threshold that applies to all of the classes predicted. This threshold is selected so that the class-specific SVMs collectively achieve the user-specified coverage on the threshold training set. The motivation for this simpler thresholding strategy is to reduce the risk of overfitting on the threshold training set. If the confidence scores are well calibrated, then this single threshold approach should also perform well; conversely, if the scores are not well calibrated then the multi-threshold method should perform better.</p></sec><sec><title>Experimental design</title><p>We tested two methods for predicting SCOP superfamilies. In the first, we made predictions from amino acid sequences, and in the second we made predictions from protein structures. For prediction from amino acid sequence, we used pairwise alignments based on PSI-BLAST for the nearest neighbor method, and we used the profile kernel [<xref ref-type="bibr" rid="B16">16</xref>] to define a kernel representation. For prediction from protein structure, we used structural alignments based on MAMMOTH, both for the nearest neighbor method and to define a kernel representation for training SVMs to recognize SCOP superfamilies [<xref ref-type="bibr" rid="B19">19</xref>]. For simplicity, in both cases we used a standard one-vs-all approach for making multiclass predictions from binary SVM classifiers.</p><p>We divided the data set (all of SCOP version 1.69) into four parts: <italic>A</italic><sub><italic>trn</italic></sub>, <italic>A</italic><sub><italic>tst</italic></sub>, <italic>B</italic><sub><italic>trn</italic></sub>, <italic>B</italic><sub><italic>tst</italic></sub>. We determined <italic>A</italic><sub><italic>trn </italic></sub>and <italic>A</italic><sub><italic>tst </italic></sub>to suit the requirement of training and testing binary SVM superfamily classifiers: <italic>A</italic><sub><italic>tst </italic></sub>consists of totally held-out families from superfamilies that have 2 or more member families of at least 3 proteins each; <italic>A</italic><sub><italic>trn </italic></sub>consists of all other families belonging to these superfamilies. Data set <italic>B </italic>consists of all superfamilies in SCOP that are not covered by data set <italic>A</italic>. <italic>B </italic>is then split into train and test by families at random such that the ratio of families for <italic>B</italic><sub><italic>tst</italic></sub>/<italic>B</italic><sub><italic>train </italic></sub>is equal to the ratio <italic>A</italic><sub><italic>tst</italic></sub>/<italic>A</italic><sub><italic>train</italic></sub>. The data set for superfamily detection has 74 superfamilies in <italic>A </italic>and 1458 superfamilies in <italic>B </italic>(total 1532).</p><p>We considered punting both from SVMs to the nearest neighbor method and vice versa. When using SVMs as the primary method, we used <italic>B</italic><sub><italic>trn </italic></sub>as additional negative examples on which to calculate punting thresholds. In the reverse case, because the nearest-neighbor method had accrued no bias in "training," we used all of the negative superfamilies in <italic>A</italic><sub><italic>trn </italic></sub>and <italic>B</italic><sub><italic>trn </italic></sub>to determine thresholds.</p></sec><sec><title>Punting once</title><p>Initially, we evaluated superfamily detection performance at full coverage, that is, when we make a prediction for every test example (as in Figure <xref ref-type="fig" rid="F1">1A</xref>). Results for classification from sequence are shown in the left half of Table <xref ref-type="table" rid="T1">1</xref>. Here <italic>A</italic><sub><italic>tst </italic></sub>consists of held-out families from superfamilies within the coverage of the SVM classifiers; <italic>B</italic><sub><italic>tst </italic></sub>consists of familes outside of SVM coverage. Consequently, the SVM yields a 100% error rate on <italic>B</italic><sub><italic>tst</italic></sub>, whereas PSI-BLAST incorrectly classifies 55.7% of these sequences. Conversely, for the sequences within classes covered by the SVM, PSI-BLAST's error rate (49.1%) is significantly higher than the SVM's error rate (24.0%). When we combine the two methods, the overall error rate drops by 10.8% from 51.8% for PSI-BLAST to 40.8% for PSI-BLAST &#x02192; SVM. To evaluate the statistical significance of the observed differences in performance, we use McNemar's test to compute a <italic>p </italic>value for the null hypothesis that the same proportion of proteins are correctly classified by both methods. These tests, applied to the entire test set, show that each of the hybrid classifiers performs significantly better than each of the single classifiers; i.e., all four relevant <italic>p </italic>values are less than 0.01.</p><table-wrap position="float" id="T1"><label>Table 1</label><caption><p>Superfamily detection error rates at full coverage.</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="center" colspan="5">Classifying sequences</td><td align="center" colspan="5">Classifying structures</td></tr><tr><td align="center">Primary</td><td align="center">Secondary</td><td align="center"><italic>A</italic><sub><italic>tst</italic></sub></td><td align="center"><italic>B</italic><sub><italic>tst</italic></sub></td><td align="center"><italic>A</italic><sub><italic>tst </italic></sub>+ <italic>B</italic><sub><italic>tst</italic></sub></td><td align="center">Primary</td><td align="center">Secondary</td><td align="center"><italic>A</italic><sub><italic>tst</italic></sub></td><td align="center"><italic>B</italic><sub><italic>tst</italic></sub></td><td align="center"><italic>A</italic><sub><italic>tst </italic></sub>+ <italic>B</italic><sub><italic>tst</italic></sub></td></tr></thead><tbody><tr><td align="center">SVM</td><td align="center">-</td><td align="center">0.2396</td><td align="center">1.0000</td><td align="center">0.5510</td><td align="center">SVM</td><td align="center">-</td><td align="center">0.2194</td><td align="center">1.0000</td><td align="center">0.5391</td></tr><tr><td align="center">PSI-BLAST</td><td align="center">-</td><td align="center">0.4914</td><td align="center">0.5569</td><td align="center">0.5182</td><td align="center">MAMMOTH</td><td align="center">-</td><td align="center">0.2922</td><td align="center">0.3309</td><td align="center">0.3081</td></tr><tr><td align="center">SVM</td><td align="center">PSI-BLAST</td><td align="center">0.2376</td><td align="center">0.5598</td><td align="center">0.4322</td><td align="center">SVM</td><td align="center">MAMMOTH</td><td align="center">0.1790</td><td align="center">0.3367</td><td align="center">0.2794</td></tr><tr><td align="center">PSI-BLAST</td><td align="center">SVM</td><td align="center">0.2730</td><td align="center">0.5569</td><td align="center">0.4078</td><td align="center">MAMMOTH</td><td align="center">SVM</td><td align="center">0.2053</td><td align="center">0.3309</td><td align="center">0.2633</td></tr></tbody></table><table-wrap-foot><p>Each entry in the table is the fraction of proteins in the test set that are assigned to the incorrect superfamily by the given method.</p></table-wrap-foot></table-wrap><p>Results from the classification of protein structures are shown in the right half of Table <xref ref-type="table" rid="T1">1</xref>. For this task, a drop in error rate of 4.5% (30.8% to 26.3%) is achieved from MAMMOTH to MAMMOTH &#x02192; SVM. Again, McNemar's test shows that both hybrid methods outperform both of the single classifiers at <italic>p &#x0003c;</italic>0.01.</p></sec><sec><title>Punting once versus punting twice</title><p>In practical applications, it may be preferable for the classifier to say "I don't know" rather than return an incorrect classification. To achieve this behavior, we included a second level of punting, based on a second set of thresholds (Figure <xref ref-type="fig" rid="F1">1B</xref>). This strategy allows the classifier to punt completely and not give a prediction for an example. The target percentage for both the primary and final punting thresholds were varied for both hybrid methods, yielding a range of coverage and error rates.</p><p>Results for classification over a range of coverages can be seen in Figure <xref ref-type="fig" rid="F3">3A</xref> for protein sequences and Figure <xref ref-type="fig" rid="F3">3B</xref> for protein structures. For both tasks, punting in either direction &#x02013; from the SVM to the nearest neighbor classifier or vice versa &#x02013; yields higher accuracy than either single method at all coverage rates. The unbalanced error rate used in Figure <xref ref-type="fig" rid="F3">3A&#x02013;B</xref> counts the number of proteins in the test set whose SCOP superfamily is incorrectly predicted; hence, this metric implicitly assigns more weight to larger classes. To evaluate the improvement over small classes, we also measured the balanced error rate, in which we compute the error rate separately for each class and then average the resulting values (Figure <xref ref-type="fig" rid="F3">3B&#x02013;C</xref>). Again, punting in either direction, we generally achieve higher balanced accuracy with the hybrid method for both classification tasks.</p><fig position="float" id="F3"><label>Figure 3</label><caption><p><bold>Hybrid methods for protein classification yield lower error for all coverage values</bold>. The figures plot (A, B) unbalanced error rates and (C, D) balanced error rates as a function of unbalanced coverage. In panels (A) and (C), we are classifying protein sequences; in panels (B) and (D), we are classifying protein structures.</p></caption><graphic xlink:href="1471-2105-9-389-3"/></fig><p>To understand better why the punting procedure produces better overall accuracy, we plot in Figure <xref ref-type="fig" rid="F4">4</xref> the percentage of predictions made by the SVM as a function of the total number of predictions. The oscillatory behavior of all four series is a result of the grid search over two independent punting thresholds. The hybrid classifier can either (1) assign a low threshold to punt from method A to method B and a high threshold to make no prediction or (2) assign a high threshold to punt from A to B and a low threshold to make no prediction. These two strategies achieve a similar level of coverage and a similar errror rate but, as shown in Figure <xref ref-type="fig" rid="F4">4</xref>, the resulting set of predictions may contain quite different percentages of predictions from each of the individual classifiers.</p><fig position="float" id="F4"><label>Figure 4</label><caption><p><bold>Percentage of predictions made by the SVM</bold>. Each panel plots, for one of the two classification tasks, the percentage of predictions made by the SVM as a function of the total number of predictions made.</p></caption><graphic xlink:href="1471-2105-9-389-4"/></fig><p>Comparing Figure <xref ref-type="fig" rid="F4">4A</xref> and <xref ref-type="fig" rid="F4">4B</xref>, we see a different overall trend for the two classification tasks. For the sequence classification problem, as coverage approaches 100%, the two methods end up sharing predictions almost 50/50. In contrast, for the structure classification problem, the SVM method converges to fewer predictions &#x02013; MAMMOTH makes approximately twice as many predictions as the SVM at full coverage. This observation may explain why the improvement provided by the hybrid classifier is smaller in the structure classification problem (4.5% decrease in error) compared with the sequence classification problem (10.8% decrease). For the structure classification task, the high coverage classifier (MAMMOTH) is already very good, so adding a second, supervised classifier does not yield a large improvement.</p></sec><sec><title>Single versus multiple thresholds</title><p>Thus far, we have reported results using class-specific thresholds. A simpler approach would be to learn a single, class-independent threshold for a given classifier. Figure <xref ref-type="fig" rid="F5">5</xref> compares the results of these two approaches for the hybrid methods on both classification tasks. For classification of protein structures, using class-specific thresholds consistently improves the overall performance. In contrast, when we apply the same analysis to classification by sequence, we find there is no benefit from using multiple thresholds. Using multiple thresholds should help when the class-specific classifiers are not well calibrated; i.e., when an observed score of <italic>X </italic>always corresponds to the same class-conditional posterior probability. Thus, these results suggest that the E-values returned by MAMMOTH are not as well calibrated as those computed by PSI-BLAST.</p><fig position="float" id="F5"><label>Figure 5</label><caption><p><bold>The value of using class-specific thresholds</bold>. The figure compares, for both hybrid methods on both classification tasks, the performance when using a single threshold for all classes versus using class-specific <italic>learnt </italic>thresholds.</p></caption><graphic xlink:href="1471-2105-9-389-5"/></fig></sec><sec><title>Combining low and high coverage methods</title><p>As mentioned above, approximately 60% of the SCOP superfamilies in our data set contain fewer than three members. The punting methodology allows us to predict members of these superfamilies, even though an SVM is not trained for small superfamilies. Moreover, if the high coverage (NN) classifier incorrectly places a member of a large superfamily into a small superfamily, then the low coverage classifier (SVM) can correct this error, because it has high accuracy for large superfamilies.</p><p>An alternative to the approach described here would be to attempt to train an SVM even for superfamilies with one or two members. In this case, we could still punt from the SVM to NN or vice versa. We do not expect, however, this approach to yield a significant improvement, because SVMs are not designed to work well from so few examples. Figure <xref ref-type="fig" rid="F6">6</xref> provides evidence to support this claim. For both sequence and structure based prediction experiments, we plot the accuracy for SVMs over NNs averaged over all superfamilies less than or equal to a given size. One can see that as the superfamily size increases, the accuracy gain of SVM over NN increases. For the sequence-based prediction problem, for small superfamily sizes, SVM is on average outperformed by NN. For example, the average accuracy of SVM and NN for all superfamilies less than size 30 is 0.3956 and 0.4762 respectively. In contrast, for all superfamilies <italic>larger than </italic>size 30 the averages are 0.6578 and 0.4714 respectively.</p><fig position="float" id="F6"><label>Figure 6</label><caption><p><bold>SVM performs better than NN for larger superfamily sizes</bold>. The figure plots the accuracy of NN and SVM classifiers (y-axis), averaged over all superfamilies less than or equal to a given size (x-axis) for classification from (A) sequence and (B) structure.</p></caption><graphic xlink:href="1471-2105-9-389-6"/></fig><p>If the effect shown in Figure <xref ref-type="fig" rid="F6">6</xref> were not a problem &#x02013; i.e., if both classifiers worked well enough across all superfamily sizes &#x02013; then one could use standard methods for combining classifiers, such as a voting scheme. However, even in such a case, one would still not be able to control the accuracy versus coverage of predictions. This flexibility, which is provided by the punting strategy, is one of the main contributions of our work.</p></sec><sec><title>Punting as stacked generalization</title><p>Stacked generalization [<xref ref-type="bibr" rid="B20">20</xref>] is a general scheme for optimizing the generalization error of several classifiers by learning how to combine them accurately. The basic idea is to (i) train each classifier on the same problem and then (ii) use a second set of data to learn a combining scheme when using these classifiers. One example of this approach is that in stage (ii) one could construct a feature space whose inputs are the guesses of the classifiers trained in stage (i), so training a linear classifier in stage (ii) would mean learning a weighted majority vote over the classifiers. However, the stacked generalization approach, as Wolpert describes it, can include any two-stage method of combination. In that sense, our punting method is an instance of stacked generalization where the second stage learns a function that chooses which classifier to apply, depending on the magnitude of the real-valued outputs (i.e., the classifier decides when to punt). Just as in stacked generalization, we divide our data set into two portions: one for training stage (i), the classifiers, and one for training stage (ii), the punting thresholds. However, Wolpert neither describes the use of punting for choosing classifiers, nor for finding a trade-off between coverage and accuracy of the resulting combined classifier, making our approach a novel instance of his general scheme.</p></sec><sec><title>AutoSCOP comparison</title><p>We compared the performance of our hybrid classifiers with that of the webserver AutoSCOP [<xref ref-type="bibr" rid="B21">21</xref>].</p><p>AutoSCOP uses a database built from SCOP 1.69, as does our method. To test both methods, we therefore created a dataset of 100 new protein domains from SCOP version 1.73. We combined the dataset used in this study, consisting of 11,944 sequences from Astral version 1.69, with 9,536 sequences from Astral version 1.73, and we clustered the combined set using a 40% sequence identity threshold. We then identified clusters that contained only sequences from version 1.73, and we extracted the longest sequence from each of these clusters. This procedure yielded a total of 2285 novel domain sequences, which are members of 698 distinct SCOP superfamilies. Finally, we randomly selected 100 of these sequences for use in our test. Results for superfamily detection can be found in Table <xref ref-type="table" rid="T2">2</xref>. Our simple hybrid classifier achieves a 27% error rate, which is nearly as good as the 25% error rate achieved by AutoSCOP. Most of the difference between the methods arises for small superfamilies, where the SVM is not applicable. For superfamilies that are covered by an SVM, the SVM error rate (3/38 = 7.9%) is less than half AutoSCOP's error rate (7/38 = 18.4%).</p><table-wrap position="float" id="T2"><label>Table 2</label><caption><p>AutoSCOP comparison.</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="right">Method</td><td align="center">Covered</td><td align="center">Uncovered</td><td align="center">Total</td></tr></thead><tbody><tr><td align="right">AutoSCOP</td><td align="center">7</td><td align="center">18</td><td align="center">25</td></tr><tr><td align="right">SVM</td><td align="center">3</td><td align="center">62</td><td align="center">65</td></tr><tr><td align="right">PSI-BLAST</td><td align="center">6</td><td align="center">24</td><td align="center">30</td></tr><tr><td align="right">SVM &#x02192; PSI-BLAST</td><td align="center">4</td><td align="center">40</td><td align="center">44</td></tr><tr><td align="right">PSI-BLAST &#x02192; SVM</td><td align="center">3</td><td align="center">24</td><td align="center">27</td></tr><tr><td align="right">Total</td><td align="center">38</td><td align="center">62</td><td align="center">100</td></tr></tbody></table><table-wrap-foot><p>Each entry in the table is the number of proteins from a test set of 100 proteins taken from SCOP.1.73 that are assigned to the incorrect superfamily by the given method. Each superfamily is "covered" or "uncovered," depending on whether an SVM has been trained to recognize it.</p></table-wrap-foot></table-wrap></sec></sec><sec><title>Discussion</title><p>We have described a simple method of combining a high coverage, low accuracy classifier with a low coverage, high accuracy classifier, based on learning a collection of class-specific thresholds from held-out data. For SCOP superfamily recognition from structure and sequence, the resulting hybrid classifiers yield consistently lower error rates across a wide range of coverage.</p><p><italic>A priori</italic>, punting seems most intuitive when the low-coverage/high-accuracy classifier punts to the high-coverage/low-accuracy classifier. However, the results in Figure <xref ref-type="fig" rid="F3">3</xref> suggest that, for the combination of SVM and NN classifiers applied to SCOP classification, punting in the opposite direction is slightly more effective. We speculate that the best performance will be obtained when the primary classifier is the one that returns the most accurate <italic>confidence measure </italic>in its predictions, rather than the most accurate generalization performance. In this way, if the primary classifier always punts accurately when it is incorrect, then the combined generalization performance can be optimized. Hence, the NN &#x02192; SVM hybrid may be slightly better than the SVM &#x02192; NN hybrid because the NN method punts more accurately.</p><p>One of the primary contributions of this work is to make SVM-based classifiers practically applicable. Although they have been shown to provide superior performance for protein classification problems in which the number of examples is large enough, SVMs have not been used in practice because of their limited coverage. On the other hand, the goal of this paper is not to argue that SVMs are better than other methods, but to show how to make an SVM classifier practical, by giving it complete coverage. Our results presumably generalize to other supervised classification algorithms, though we have not tested this hypothesis directly.</p><p>For simplicity of exposition, we have used a simple one-vs-all approach to multiclass SVM classification. In practice, it is generally preferable to use a more complex multiclass approach such as code learning [<xref ref-type="bibr" rid="B13">13</xref>]. Combining code-learning with the punting approach described here yields even lower error rates than are shown in Figure <xref ref-type="fig" rid="F3">3</xref> (data not shown). In general it is straightforward to combine any pair of (low and high coverage) classifiers using our approach. The only prerequisite is that they provide a real-valued output for each class, and that these values are correlated with the confidence in their predictions. From these outputs we can learn punting thresholds.</p><p>In this work, we use a relatively simple strategy to define the data for learning punting thresholds given the user-specified hyperparameter <italic>&#x003c1;</italic>. More complex internal cross-validation schemes would likely yield slightly better performance and increased running time.</p><p>Eventually, rather than combining two existing classifiers, we would like to train a single classifier that has the advantages of both systems in one. This approach would obviate the need for the punting strategy described here. We are currently investigating approaches to this problem by training a ranking based algorithm, rather than a class predictor.</p></sec><sec><title>Authors' contributions</title><p>The authors jointly conceived and designed the experiments and wrote the manuscript. Iain Melvin carried out the experiments.</p></sec></body><back><ack><sec><title>Acknowledgements</title><p>This work was supported by National Institutes of Health award R01 GM74257.</p></sec></ack><ref-list><ref id="B1"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Shindyalov</surname><given-names>IN</given-names></name><name><surname>Bourne</surname><given-names>PE</given-names></name></person-group><article-title>Protein structure alignment by incremental combinatorial extension (CE) of the optimal path</article-title><source>Protein Engineering</source><year>1998</year><volume>11</volume><fpage>739</fpage><lpage>747</lpage><pub-id pub-id-type="pmid">9796821</pub-id><pub-id pub-id-type="doi">10.1093/protein/11.9.739</pub-id></citation></ref><ref id="B2"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Holm</surname><given-names>L</given-names></name><name><surname>Sander</surname><given-names>C</given-names></name></person-group><article-title>Protein Structure Comparison by Alignment of Distance Matrices</article-title><source>Journal of Molecular Biology</source><year>1993</year><volume>233</volume><fpage>123</fpage><lpage>138</lpage><pub-id pub-id-type="pmid">8377180</pub-id><pub-id pub-id-type="doi">10.1006/jmbi.1993.1489</pub-id></citation></ref><ref id="B3"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ortiz</surname><given-names>AR</given-names></name><name><surname>Strauss</surname><given-names>CEM</given-names></name><name><surname>Olmea</surname><given-names>O</given-names></name></person-group><article-title>MAMMOTH (Matching molecular models obtained from theory): An automated method for model comparison</article-title><source>Protein Science</source><year>2002</year><volume>11</volume><fpage>2606</fpage><lpage>2621</lpage><pub-id pub-id-type="pmid">12381844</pub-id><pub-id pub-id-type="doi">10.1110/ps.0215902</pub-id></citation></ref><ref id="B4"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>T</given-names></name><name><surname>Waterman</surname><given-names>M</given-names></name></person-group><article-title>Identification of common molecular subsequences</article-title><source>Journal of Molecular Biology</source><year>1981</year><volume>147</volume><fpage>195</fpage><lpage>197</lpage><pub-id pub-id-type="pmid">7265238</pub-id><pub-id pub-id-type="doi">10.1016/0022-2836(81)90087-5</pub-id></citation></ref><ref id="B5"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Altschul</surname><given-names>SF</given-names></name><name><surname>Gish</surname><given-names>W</given-names></name><name><surname>Miller</surname><given-names>W</given-names></name><name><surname>Myers</surname><given-names>EW</given-names></name><name><surname>Lipman</surname><given-names>DJ</given-names></name></person-group><article-title>A basic local alignment search tool</article-title><source>Journal of Molecular Biology</source><year>1990</year><volume>215</volume><fpage>403</fpage><lpage>410</lpage><pub-id pub-id-type="pmid">2231712</pub-id></citation></ref><ref id="B6"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Karplus</surname><given-names>K</given-names></name><name><surname>Barrett</surname><given-names>C</given-names></name><name><surname>Hughey</surname><given-names>R</given-names></name></person-group><article-title>Hidden Markov models for detecting remote protein homologies</article-title><source>Bioinformatics</source><year>1998</year><volume>14</volume><fpage>846</fpage><lpage>56</lpage><pub-id pub-id-type="pmid">9927713</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/14.10.846</pub-id></citation></ref><ref id="B7"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Altschul</surname><given-names>SF</given-names></name><name><surname>Madden</surname><given-names>TL</given-names></name><name><surname>Schaffer</surname><given-names>AA</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>Z</given-names></name><name><surname>Miller</surname><given-names>W</given-names></name><name><surname>Lipman</surname><given-names>DJ</given-names></name></person-group><article-title>Gapped BLAST and PSI-BLAST: A new generation of protein database search programs</article-title><source>Nucleic Acids Research</source><year>1997</year><volume>25</volume><fpage>3389</fpage><lpage>3402</lpage><pub-id pub-id-type="pmid">9254694</pub-id><pub-id pub-id-type="doi">10.1093/nar/25.17.3389</pub-id></citation></ref><ref id="B8"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Jaakkola</surname><given-names>T</given-names></name><name><surname>Diekhans</surname><given-names>M</given-names></name><name><surname>Haussler</surname><given-names>D</given-names></name></person-group><article-title>Using the Fisher kernel method to detect remote protein homologies</article-title><source>Proceedings of the Seventh International Conference on Intelligent Systems for Molecular Biology</source><year>1999</year><publisher-name>Menlo Park, CA: AAAI Press</publisher-name><fpage>149</fpage><lpage>158</lpage></citation></ref><ref id="B9"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Boser</surname><given-names>BE</given-names></name><name><surname>Guyon</surname><given-names>IM</given-names></name><name><surname>Vapnik</surname><given-names>VN</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Haussler D</surname></name></person-group><article-title>A Training Algorithm for Optimal Margin Classifiers</article-title><source>5th Annual ACM Workshop on COLT</source><year>1992</year><publisher-name>Pittsburgh, PA: ACM Press</publisher-name><fpage>144</fpage><lpage>152</lpage></citation></ref><ref id="B10"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Murzin</surname><given-names>AG</given-names></name><name><surname>Brenner</surname><given-names>SE</given-names></name><name><surname>Hubbard</surname><given-names>T</given-names></name><name><surname>Chothia</surname><given-names>C</given-names></name></person-group><article-title>SCOP: A structural classification of proteins database for the investigation of sequences and structures</article-title><source>Journal of Molecular Biology</source><year>1995</year><volume>247</volume><fpage>536</fpage><lpage>540</lpage><pub-id pub-id-type="pmid">7723011</pub-id></citation></ref><ref id="B11"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Noble</surname><given-names>WS</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Schoelkopf B, Tsuda K, Vert JP</surname></name></person-group><article-title>Support vector machine applications in computational biology</article-title><source>Kernel methods in computational biology</source><year>2004</year><publisher-name>Cambridge, MA: MIT Press</publisher-name><fpage>71</fpage><lpage>92</lpage></citation></ref><ref id="B12"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Melvin</surname><given-names>I</given-names></name><name><surname>Ie</surname><given-names>E</given-names></name><name><surname>Kuang</surname><given-names>R</given-names></name><name><surname>Weston</surname><given-names>J</given-names></name><name><surname>Noble</surname><given-names>WS</given-names></name><name><surname>Leslie</surname><given-names>C</given-names></name></person-group><article-title>SVM-fold: a tool for discriminative multi-class protein fold and superfamily recognition</article-title><source>BMC Bioinformatics</source><year>2007</year><volume>8</volume><fpage>S2</fpage><pub-id pub-id-type="pmid">17570145</pub-id><pub-id pub-id-type="doi">10.1186/1471-2105-8-S4-S2</pub-id></citation></ref><ref id="B13"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Melvin</surname><given-names>I</given-names></name><name><surname>Ie</surname><given-names>E</given-names></name><name><surname>Weston</surname><given-names>J</given-names></name><name><surname>Noble</surname><given-names>WS</given-names></name><name><surname>Leslie</surname><given-names>C</given-names></name></person-group><article-title>Multi-class protein classification using adaptive codes</article-title><source>Journal of Machine Learning Research</source><year>2007</year><volume>8</volume><fpage>1557</fpage><lpage>1581</lpage></citation></ref><ref id="B14"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Rangwala</surname><given-names>H</given-names></name><name><surname>Karypis</surname><given-names>G</given-names></name></person-group><article-title>Building multiclass classifiers for remote homology detection and fold recognition</article-title><source>BMC Bioinformatics</source><year>2006</year><volume>16</volume><fpage>455</fpage><pub-id pub-id-type="pmid">17042943</pub-id><pub-id pub-id-type="doi">10.1186/1471-2105-7-455</pub-id></citation></ref><ref id="B15"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Shamim</surname><given-names>MT</given-names></name><name><surname>Anwaruddin</surname><given-names>M</given-names></name><name><surname>Nagarajaram</surname><given-names>HA</given-names></name></person-group><article-title>Support vector machine-based classification of protein folds using the structural properties of amino acid residues and amino acid residue pairs</article-title><source>Bioinformatics</source><year>2007</year><volume>23</volume><fpage>3320</fpage><lpage>3327</lpage><pub-id pub-id-type="pmid">17989092</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/btm527</pub-id></citation></ref><ref id="B16"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kuang</surname><given-names>R</given-names></name><name><surname>Ie</surname><given-names>E</given-names></name><name><surname>Wang</surname><given-names>K</given-names></name><name><surname>Wang</surname><given-names>K</given-names></name><name><surname>Siddiqi</surname><given-names>M</given-names></name><name><surname>Freund</surname><given-names>Y</given-names></name><name><surname>Leslie</surname><given-names>C</given-names></name></person-group><article-title>Profile-based string kernels for remote homology detection and motif extraction</article-title><source>Journal of Bioinformatics and Computational Biology</source><year>2005</year><volume>3</volume><fpage>527</fpage><lpage>550</lpage><pub-id pub-id-type="pmid">16108083</pub-id><pub-id pub-id-type="doi">10.1142/S021972000500120X</pub-id></citation></ref><ref id="B17"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Dobson</surname><given-names>PD</given-names></name><name><surname>Doig</surname><given-names>AJ</given-names></name></person-group><article-title>Predicting Enzyme Class From Protein Structure Without Alignments</article-title><source>Journal of Molecular Biology</source><year>2005</year><volume>345</volume><fpage>187</fpage><lpage>199</lpage><pub-id pub-id-type="pmid">15567421</pub-id><pub-id pub-id-type="doi">10.1016/j.jmb.2004.10.024</pub-id></citation></ref><ref id="B18"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Borgwardt</surname><given-names>K</given-names></name><name><surname>Ong</surname><given-names>CS</given-names></name><name><surname>Schoenauer</surname><given-names>S</given-names></name><name><surname>Vishwanathan</surname><given-names>S</given-names></name><name><surname>Smola</surname><given-names>A</given-names></name><name><surname>Kriegel</surname><given-names>HP</given-names></name></person-group><article-title>Protein Function Prediction via Graph Kernels</article-title><source>Bioinformatics</source><year>2005</year><volume>21</volume><fpage>i47</fpage><lpage>i56</lpage><pub-id pub-id-type="pmid">15961493</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/bti1007</pub-id></citation></ref><ref id="B19"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Qiu</surname><given-names>J</given-names></name><name><surname>Hue</surname><given-names>M</given-names></name><name><surname>Ben-Hur</surname><given-names>A</given-names></name><name><surname>Vert</surname><given-names>JP</given-names></name><name><surname>Noble</surname><given-names>WS</given-names></name></person-group><article-title>A structural alignment kernel for protein structures</article-title><source>Bioinformatics</source><year>2007</year><volume>23</volume><fpage>1090</fpage><lpage>1098</lpage><pub-id pub-id-type="pmid">17234638</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/btl642</pub-id></citation></ref><ref id="B20"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Wolpert</surname><given-names>D</given-names></name></person-group><article-title>Stacked generalization</article-title><source>Neural Networks</source><year>1992</year><volume>5</volume><fpage>241</fpage><lpage>259</lpage><pub-id pub-id-type="doi">10.1016/S0893-6080(05)80023-1</pub-id></citation></ref><ref id="B21"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Jan</surname><given-names>E</given-names></name><name><surname>Gewehr</surname><given-names>VH</given-names></name><name><surname>Zimmer</surname><given-names>R</given-names></name></person-group><article-title>AutoSCOP: Automated Prediction of SCOP Classifications using Unique Pattern-Class Mappings</article-title><source>Bioinformatics</source><year>2007</year><volume>23</volume><fpage>1203</fpage><lpage>1210</lpage><pub-id pub-id-type="pmid">17379694</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/btm089</pub-id></citation></ref></ref-list></back></article>