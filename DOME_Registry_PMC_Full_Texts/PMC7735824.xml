<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN" "JATS-archivearticle1-mathml3.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.0 20120330//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-journalpublishing1.dtd?><?SourceDTD.Version 1.0?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">Biomed Res Int</journal-id><journal-id journal-id-type="iso-abbrev">Biomed Res Int</journal-id><journal-id journal-id-type="publisher-id">BMRI</journal-id><journal-title-group><journal-title>BioMed Research International</journal-title></journal-title-group><issn pub-type="ppub">2314-6133</issn><issn pub-type="epub">2314-6141</issn><publisher><publisher-name>Hindawi</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">7735824</article-id><article-id pub-id-type="doi">10.1155/2020/6248686</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>PmDNE: Prediction of miRNA-Disease Association Based on Network Embedding and Network Similarity Analysis</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-8045-5264</contrib-id><name><surname>Li</surname><given-names>Junyi</given-names></name><email>lijunyi@hit.edu.cn</email><xref ref-type="aff" rid="I1">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-6397-6313</contrib-id><name><surname>Liu</surname><given-names>Ying</given-names></name><xref ref-type="aff" rid="I1">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Zhang</surname><given-names>Zhongqing</given-names></name><xref ref-type="aff" rid="I1">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Liu</surname><given-names>Bo</given-names></name><xref ref-type="aff" rid="I2">
<sup>2</sup>
</xref></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-6500-6217</contrib-id><name><surname>Wang</surname><given-names>Yadong</given-names></name><email>ydwang@hit.edu.cn</email><xref ref-type="aff" rid="I1">
<sup>1</sup>
</xref><xref ref-type="aff" rid="I2">
<sup>2</sup>
</xref></contrib></contrib-group><aff id="I1">
<sup>1</sup>School of Computer Science and Technology, Harbin Institute of Technology (Shenzhen), Shenzhen, Guangdong 518055, China</aff><aff id="I2">
<sup>2</sup>School of Computer Science and Technology, Harbin Institute of Technology, Harbin, Heilongjiang 150001, China</aff><author-notes><fn fn-type="other"><p>Academic Editor: Zhenguo Zhang</p></fn></author-notes><pub-date pub-type="collection"><year>2020</year></pub-date><pub-date pub-type="epub"><day>7</day><month>12</month><year>2020</year></pub-date><volume>2020</volume><elocation-id>6248686</elocation-id><history><date date-type="received"><day>24</day><month>7</month><year>2020</year></date><date date-type="rev-recd"><day>20</day><month>10</month><year>2020</year></date><date date-type="accepted"><day>21</day><month>10</month><year>2020</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2020 Junyi Li et al.</copyright-statement><copyright-year>2020</copyright-year><license xlink:href="https://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><abstract><p>Successful prediction of miRNA-disease association is nontrivial for the diagnosis and prognosis of genetic diseases. There are many methods to predict miRNA and disease, but biological data are numerous and complex, and they often exist in the form of network. How to accurately use the features of miRNA and disease-related biological networks to predict unknown association has always been a challenge. Here, we propose PmDNE, a method based on network embedding and network similarity analysis, to predict the miRNA-disease association. In PmDNE, the structure of network bipartite graph is improved, and a random walk generator is designed. For embedded vectors, 128 dimensions are used, and the accuracy of prediction is significantly improved. Compared with other network embedding methods, PmDNE is comparable and competitive with the state of art methods. Our method can solve the problem of feature extraction, reduce the dimension of features, and improve the efficiency of miRNA-disease association prediction. This method can also be extended to other area for biomedical network prediction.</p></abstract><funding-group><award-group><funding-source>Harbin Institute of Technology</funding-source></award-group><award-group><funding-source>Shenzhen stable support program</funding-source></award-group><award-group><funding-source>National Key Research Program</funding-source><award-id>2017YFC1201201</award-id></award-group><award-group><funding-source>National &#x0201c;863&#x0201d; Key Basic Research Development Program</funding-source><award-id>2014AA021505</award-id></award-group></funding-group></article-meta></front><body><sec id="sec1"><title>1. Introduction</title><p>microRNA (miRNA) is a kind of noncoding RNA with length of around 22 nucleotides. It has been found in plants, animals, and viruses. Recent studies have shown that microRNAs play an important role in different biological processes [<xref rid="B1" ref-type="bibr">1</xref>]. It is able to prevent tumor invasion, control cell growth, regulate cell cycle regulation, and so on. Studies have also shown that many miRNAs are involved in human diseases [<xref rid="B2" ref-type="bibr">2</xref>], such as cancer, viral diseases, and immune-related diseases [<xref rid="B3" ref-type="bibr">3</xref>&#x02013;<xref rid="B5" ref-type="bibr">5</xref>]. Therefore, successful prediction of disease-related miRNAs is nontrivial for the diagnosis and prognosis of genetic diseases and drug development.</p><p>How to predict human miRNA in the relationship and make good use of the existing miRNA disease association data is an important topic in the study of human diseases. For biomedicine, the accuracy of data is very important. There are many public databases related to miRNAs such as mir2disease [<xref rid="B6" ref-type="bibr">6</xref>], miRBase [<xref rid="B7" ref-type="bibr">7</xref>], and TarBase [<xref rid="B8" ref-type="bibr">8</xref>]. With the increasing concern of the scientific community on the relationship between diseases and miRNAs, their data are also included. For instance, HMDD [<xref rid="B9" ref-type="bibr">9</xref>] is the miRNA human disease association database established in 2007.</p><p>There are two kinds of major methods to predict disease-miRNA association. The first method is based on traditional network iteration, and the second one is based on machine learning.</p><p>In the traditional iterative method, the miRNAs and the nodes in the disease network are iterated, and the possible relationship is found from high to low through the final convergence result ranking. In 2016, Chen et al. suggested that global network similarity can capture the association between disease and miRNA more effectively than traditional local network similarity. Therefore, RWRMDA [<xref rid="B10" ref-type="bibr">10</xref>] method was developed to predict potential miRNA-disease associations. Chen et al. also proposed a computational model of HGIMDA [<xref rid="B11" ref-type="bibr">11</xref>], which integrates the known miRNA disease association, different types of disease similarity, and miRNA similarity into the heterograph to predict new disease-related miRNAs. However, the method of using network has its own disadvantages. It may be biased towards the well-known miRNAs and diseases. In the network method, restarting random walk is very time-consuming and parameters with transition probability; different selection of parameters also affects the final results. The experimental results of this kind of method highly depend on the reliable biological network model and cannot be applied to new miRNAs or new diseases.</p><p>The second kind of method is based on machine learning. This kind of method is able to solve the problem of new miRNAs and disease relation prediction. In 2011, Xu introduced a method [<xref rid="B12" ref-type="bibr">12</xref>] based on miRNA target imbalance network (MTDN) to give priority to new disease-related miRNAs. A weighted KNN-based HDMP [<xref rid="B13" ref-type="bibr">13</xref>] method is proposed by Xuan et al. In addition, the semantic similarity and phenotypic similarity of diseases are used to calculate the functional similarity matrix of miRNA. Chen proposed a semisupervised learning RLSMDA [<xref rid="B14" ref-type="bibr">14</xref>] model to predict potential disease-related miRNAs in 2014. RLSMDA [<xref rid="B14" ref-type="bibr">14</xref>] can calculate miRNA disease association prediction score of new diseases. This kind of method needs to solve two major problems: feature extraction and negative case missing.</p><p>Recently, people pay more and more attention to the network embedding method [<xref rid="B15" ref-type="bibr">15</xref>, <xref rid="B16" ref-type="bibr">16</xref>]. It extracts features by extracting some relations of complex data and embeds the high latitude features of complex data into low dimensional space. In order to better predict the relationship between disease and miRNA, the network embedding method can be used to solve the problem of feature extraction. Therefore, we propose a method based on network embedding and network similarity analysis called PmDNE to predict the miRNA-disease association. In PmDNE, the structure of network bipartite graph is improved, and a random walk generator is designed. The accuracy of prediction has improved. Compared with other network embedding methods, PmDNE is comparable and competitive with the state of art methods. Our method can solve the problem of feature extraction, reduce the dimension of features, and improve the efficiency of miRNA-disease association prediction. This method can also be extended to other area for biomedical network prediction.</p></sec><sec id="sec2"><title>2. Materials and Methods</title><sec id="sec2.1"><title>2.1. miRNA Disease Association Data</title><p>miRNA disease association data is obtained from the database HMDD3.0 (<ext-link ext-link-type="uri" xlink:href="http://www.cuilab.cn/hmdde">http://www.cuilab.cn/hmdde</ext-link>). In order to predict the effect effectively, we use the latest version of HMDD3.0. Some other databases, such as mri2disease, are not up to date. Some databases do not focus on the relationship between miRNA and disease, so we chose HMDD. A total of 894 disease nodes and 1208 miRNA nodes are obtained from the HMDD database, and 18733 diseases and miRNA association relationships are obtained as shown in Tables <xref rid="tab1" ref-type="table">1</xref> and <xref rid="tab2" ref-type="table">2</xref>.</p></sec><sec id="sec2.2"><title>2.2. Disease Similarity Data about the Disease Similarity Network</title><p>We construct a directed acyclic graph (DAG) to describe the disease according to the literature [<xref rid="B17" ref-type="bibr">17</xref>] of Wang et al. Based on the medical subject title descriptor, it can be downloaded from the national medical library (<ext-link ext-link-type="uri" xlink:href="http://www.nlm.nih.gov/">http://www.nlm.nih.gov/</ext-link>). A total of 414003 related disease similarity relationships were obtained as shown in <xref rid="tab2" ref-type="table">Table 2</xref>.</p></sec><sec id="sec2.3"><title>2.3. miRNA Similarity Data</title><p>miRNA similarity network is based on the method of calculating miRNA functional similarity proposed by Wang et al. [<xref rid="B17" ref-type="bibr">17</xref>]. The functional similarity of 495 miRNA nodes was obtained by downloading miRNA function similarity data conveniently.</p></sec><sec id="sec2.4"><title>2.4. Isomorphic Network Construction and Binetwork Construction</title><p>When constructing miRNA-disease binetwork, if there is correlation, the weight of their edges is 1, and the weight of nonexistent edges is 0. In this way, we can transform the prediction method into a binary classification problem. For isomorphic network, the weight of similarity data is set as the weight of isomorphic network.</p></sec><sec id="sec2.5"><title>2.5. The First Similarity Obtains the Node Embedding Vector of Graph Representation Learning</title><p>In order to better reconstruct the original network in the low dimensional space after embedding, the first similarity relation is represented by the existing edge learning, and the second similarity relationship is represented by the edge learning with transitive relationship. The final node representation is learned by combining the two methods. The modelling of explicit relationship is the same as the first similarity of Line [<xref rid="B18" ref-type="bibr">18</xref>]. By considering local similarity, the compactness of two connected nodes is defined as Equation (<xref ref-type="disp-formula" rid="EEq1">1</xref>). <disp-formula id="EEq1"><label>(1)</label><mml:math id="M1"><mml:mtable><mml:mtr><mml:mtd><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>&#x02208;</mml:mo><mml:mi>E</mml:mi><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <italic>w</italic><sub><italic>ij</italic></sub> is the edge <italic>e</italic><sub><italic>ij</italic></sub>'s weight. The denominator is the sum of the weights of all edges. If two nodes are linked together, the probability of two nodes appearing together after embedding is very high.</p><p>Many research works [<xref rid="B19" ref-type="bibr">19</xref>, <xref rid="B20" ref-type="bibr">20</xref>] have achieved good results on measuring the similarity of two nodes embedded in the space. Most of them refer to the idea of taking vector inner product of word2vec [<xref rid="B21" ref-type="bibr">21</xref>]. Herein, we also use this method to define the possibility of two nodes adjacent to each other in the embedded space as Equation (<xref ref-type="disp-formula" rid="EEq2">2</xref>). <disp-formula id="EEq2"><label>(2)</label><mml:math id="M2"><mml:mtable><mml:mtr><mml:mtd><mml:mover accent="true"><mml:mrow><mml:mtext>&#x02009;</mml:mtext><mml:mi>P</mml:mi></mml:mrow><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi mathvariant="normal">exp</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>U</mml:mi><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <italic>u</italic><sub><italic>i</italic></sub><italic>v</italic><sub><italic>j</italic></sub>&#x02009;is the embedded node vector. Embedding vector means minimizing the difference between two nodes. That is, the closer the original node is, the closer the embedded node is still the closest relationship. To minimize the difference of the possibility of appearing together before and after embedding, KL divergence is used. <disp-formula id="eq1"><label>(3)</label><mml:math id="M3"><mml:mtable><mml:mtr><mml:mtd><mml:mi mathvariant="normal">Minimize</mml:mi><mml:mtext>&#x02009;</mml:mtext><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext>KL</mml:mtext><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>P</mml:mi><mml:mo>&#x02009;</mml:mo><mml:mo>&#x02223;</mml:mo><mml:mo>&#x02009;</mml:mo><mml:mfenced open="|" close=""><mml:mrow><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mfenced><mml:mi mathvariant="normal">log</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>I</mml:mi><mml:mo>,</mml:mo><mml:mi>J</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mo>&#x0221d;</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo></mml:mrow><mml:munder><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mi mathvariant="normal">log</mml:mi><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>The equation above represents that the closer the distance between the two nodes before and after embedding, the smaller the KL divergence is, the more similar the two distributions are. The local information of the original network is retained through the first similarity relationship. In other words, for two closely connected nodes, the representation of the two nodes learned in this way is also close to each other in the low dimensional vector space.</p></sec><sec id="sec2.6"><title>2.6. The Second Similarity Obtains the Node Embedding Vector of Graph Representation Learning</title><p>We model the second similarity relationship and extract the feature vector by DeepWalk [<xref rid="B20" ref-type="bibr">20</xref>]. But the feature vectors embedded by the random walk of DeepWalk are all based on the same type of nodes. Therefore, we embed the nodes based on such a theory. Although there are no directly connected edges between two nodes of the same type, if there is a path from <italic>u</italic><sub><italic>i</italic></sub> to <italic>u</italic><sub><italic>j</italic></sub>, it can be considered that there is a relationship between the two nodes. If two nodes of the same type are connected to the same node, they can be considered as having links. In PmDNE, we need to split a bipartite graph into two homogeneous networks, and combine it with miRNA network similarity and disease semantic similarity network. Through Equations (<xref ref-type="disp-formula" rid="EEq3">4</xref>) and (<xref ref-type="disp-formula" rid="EEq3">5</xref>), we generate two corpora containing different types of nodes. Then the random walk model is used to determine the node sequence library, and skipgram is used to obtain the similarity feature vector. <disp-formula id="EEq3"><label>(4)</label><mml:math id="M4"><mml:mtable><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>c</mml:mi><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="EEq4"><label>(5)</label><mml:math id="EEq4EAAA0AB0ECCCA"><mml:mtable><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>e</mml:mi><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <italic>w</italic><sub><italic>ik</italic></sub><italic>w</italic><sub><italic>jk</italic></sub> is the weight from <italic>i</italic> to <italic>j</italic> and <italic>j</italic> to <italic>k</italic> and <italic>d</italic><sub><italic>ij</italic></sub> is the weight of nodes <italic>i</italic> to <italic>j</italic> in the disease similarity network. <italic>m</italic><sub><italic>ij</italic></sub> is the weight of nodes <italic>i</italic> to <italic>j</italic> in miRNA network. <italic>c</italic> and <italic>e</italic> are the weights of similarity networks.</p><p>However, the random walk strategy of DeepWalk is not optimal, so we redesign a random walk method. The specific way is as follows:
<list list-type="order"><list-item><p>Obtain two networks with the same type of nodes by Equations (<xref ref-type="disp-formula" rid="EEq3">4</xref>) and (<xref ref-type="disp-formula" rid="EEq4">5</xref>) and construct two homogeneous networks by combining disease semantic similarity and miRNA functional similarity</p></list-item><list-item><p>The more links for one node, the more important the proof is, and the more random walk sequences start from it</p></list-item><list-item><p>Many random walk strategies [<xref rid="B22" ref-type="bibr">22</xref>] are to produce fixed length sequences, which does not conform to the actual rule of node embedding. The number of words in each sentence is uncertain. Therefore, we obtain node sequences of different lengths by making random walk stop or return to the original initial node at a certain step. The algorithm of measuring node importance we can chooses centrality algorithm or hits [<xref rid="B23" ref-type="bibr">23</xref>]. <xref ref-type="fig" rid="pseudo1"> Pseudocode 1</xref> shows the pseudocode of node sequence obtained by random walk.</p></list-item></list></p><p>Then, skipgram [<xref rid="B24" ref-type="bibr">24</xref>] algorithm is used to learn the embedded vector. <disp-formula id="eq2"><label>(6)</label><mml:math id="M5"><mml:mtable><mml:mtr><mml:mtd><mml:mi mathvariant="normal">Maximize</mml:mi><mml:mtext>&#x02009;</mml:mtext><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo>&#x0220f;</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mi>S</mml:mi><mml:mo>&#x02227;</mml:mo><mml:mi>S</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>U</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mo>&#x0220f;</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02009;</mml:mo><mml:mo>&#x02223;</mml:mo><mml:mo>&#x02009;</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="eq3"><label>(7)</label><mml:math id="eq3EAAAACCCCA"><mml:mtable><mml:mtr><mml:mtd><mml:mi mathvariant="normal">Maximize</mml:mi><mml:mtext>&#x02009;</mml:mtext><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo>&#x0220f;</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mi>S</mml:mi><mml:mo>&#x02227;</mml:mo><mml:mi>S</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mo>&#x0220f;</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02009;</mml:mo><mml:mo>&#x02223;</mml:mo><mml:mo>&#x02009;</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>where <italic>p</italic>(<italic>u</italic><sub><italic>c</italic></sub> | <italic>u</italic><sub><italic>i</italic></sub>) softmax is used for output. <disp-formula id="eq4"><label>(8)</label><mml:math id="M6"><mml:mtable><mml:mtr><mml:mtd><mml:mi>p</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02009;</mml:mo><mml:mo>&#x02223;</mml:mo><mml:mo>&#x02009;</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">exp</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>&#x02009;</mml:mo><mml:mo>&#x02223;</mml:mo><mml:mo>&#x02009;</mml:mo><mml:mi>U</mml:mi><mml:mo>&#x02009;</mml:mo><mml:mo>&#x02223;</mml:mo><mml:mo>&#x02009;</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mi mathvariant="normal">exp</mml:mi></mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="eq5"><label>(9)</label><mml:math id="eq5EAAAABCCCA"><mml:mtable><mml:mtr><mml:mtd><mml:mi>p</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02009;</mml:mo><mml:mo>&#x02223;</mml:mo><mml:mo>&#x02009;</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">exp</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>&#x02009;</mml:mo><mml:mo>&#x02223;</mml:mo><mml:mo>&#x02009;</mml:mo><mml:mi>V</mml:mi><mml:mo>&#x02009;</mml:mo><mml:mo>&#x02223;</mml:mo><mml:mo>&#x02009;</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mi mathvariant="normal">exp</mml:mi></mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>However, due to the large amount of denominator calculation of softmax, we adopt the method of negative sampling [<xref rid="B24" ref-type="bibr">24</xref>&#x02013;<xref rid="B26" ref-type="bibr">26</xref>], which transforms the calculation of each context vector into a binary classification problem of noncontext vector and context vector. <disp-formula id="eq6"><label>(10)</label><mml:math id="M7"><mml:mtable><mml:mtr><mml:mtd><mml:mi>p</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msubsup><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>&#x02009;</mml:mo><mml:mo>&#x02223;</mml:mo><mml:mo>&#x02009;</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo>&#x0220f;</mml:mo></mml:mrow><mml:mrow><mml:mi>z</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02227;</mml:mo><mml:msubsup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msubsup><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:munder><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>z</mml:mi><mml:mo>&#x02009;</mml:mo><mml:mo>&#x02223;</mml:mo><mml:mo>&#x02009;</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="eq7"><label>(11)</label><mml:math id="eq7EAAAAACCCA"><mml:mtable><mml:mtr><mml:mtd><mml:mi>p</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>z</mml:mi><mml:mo>&#x02009;</mml:mo><mml:mo>&#x02223;</mml:mo><mml:mo>&#x02009;</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced open="{" close=""><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mi>&#x003c3;</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mtd><mml:mtd columnalign="left"><mml:mtext>if&#x02009;</mml:mtext><mml:mi>z</mml:mi><mml:mtext>&#x02009;is&#x02009;</mml:mtext><mml:msubsup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02032;</mml:mo></mml:mrow></mml:msubsup><mml:mi>s</mml:mi><mml:mtext>&#x02009;context</mml:mtext></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mtd><mml:mtd columnalign="left"><mml:mi>z</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msubsup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msubsup><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p></sec><sec id="sec2.7"><title>2.7. Obtain the Node Embedding Vector of the Final Graph Representation Learning</title><p>The function formula of the final optimization is Equation (<xref ref-type="disp-formula" rid="EEq5">12</xref>). <disp-formula id="EEq5"><label>(12)</label><mml:math id="M8"><mml:mtable><mml:mtr><mml:mtd><mml:mi mathvariant="normal">Maximize</mml:mi><mml:mtext>&#x02009;</mml:mtext><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mi mathvariant="normal">log</mml:mi><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>&#x003b2;</mml:mi><mml:mi mathvariant="normal">log</mml:mi><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b3;</mml:mi><mml:msub><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>In the end, the embedding vector is obtained by iterating the embedding vector with random gradient descent [<xref rid="B27" ref-type="bibr">27</xref>]. For example, we use random gradient descent to update <inline-formula><mml:math id="M9"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M10"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> for <italic>O</italic><sub>1</sub>:<disp-formula id="eq8"><label>(13)</label><mml:math id="M11"><mml:mtable><mml:mtr><mml:mtd><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mfenced open="{" close="}"><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b3;</mml:mi><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mfenced open="[" close="]"><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>&#x02217;</mml:mo><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="eq9"><label>(14)</label><mml:math id="eq9EAAAAEBCCA"><mml:mtable><mml:mtr><mml:mtd><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mfenced open="{" close="}"><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003b3;</mml:mi><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mfenced open="[" close="]"><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>&#x02217;</mml:mo><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>where <italic>&#x003c3;</italic> is the sigmoid function and <italic>&#x003bb;</italic> is the learning rate.</p><p>For <italic>O</italic><sub>2</sub> and <italic>O</italic><sub>3</sub>, gradient descent is also used to update <inline-formula><mml:math id="M12"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M13"><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover><mml:mo>:</mml:mo></mml:math></inline-formula><disp-formula id="eq10"><label>(15)</label><mml:math id="M14"><mml:mtable><mml:mtr><mml:mtd><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mfenced open="{" close="}"><mml:mrow><mml:munder><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>z</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mfenced open="{" close="}"><mml:mrow><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>&#x0222a;</mml:mo><mml:msubsup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msubsup><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:munder><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow><mml:mfenced open="[" close="]"><mml:mrow><mml:mi>I</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>&#x02217;</mml:mo><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="eq11"><label>(16)</label><mml:math id="eq11EAAAACBCCA"><mml:mtable><mml:mtr><mml:mtd><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mfenced open="{" close="}"><mml:mrow><mml:munder><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>z</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mfenced open="{" close="}"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>&#x0222a;</mml:mo><mml:msubsup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msubsup><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:munder><mml:mrow><mml:mi>&#x003b2;</mml:mi></mml:mrow><mml:mfenced open="[" close="]"><mml:mrow><mml:mi>I</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>&#x003d1;</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>&#x02217;</mml:mo><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>&#x003d1;</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>where <italic>I</italic>(<italic>z</italic>, <italic>u</italic><sub><italic>i</italic></sub>) is <italic>i</italic> in <italic>u</italic><sub><italic>i</italic></sub>'s context, if exist <italic>I</italic>(<italic>z</italic>, <italic>u</italic><sub><italic>i</italic></sub>) is 1 and 0 if not. <italic>I</italic>(<italic>z</italic>, <italic>v</italic><sub><italic>j</italic></sub>) is similarity. For the centre word's contextual and noncontext word vectors <inline-formula><mml:math id="M15"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M16"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>&#x003d1;</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, they are defined as (<xref ref-type="disp-formula" rid="EEq6">17</xref>) and (<xref ref-type="disp-formula" rid="EEq7">18</xref>). <disp-formula id="EEq6"><label>(17)</label><mml:math id="M17"><mml:mtable><mml:mtr><mml:mtd><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mfenced open="{" close="}"><mml:mrow><mml:mi>&#x003b1;</mml:mi><mml:mfenced open="[" close="]"><mml:mrow><mml:mi>I</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>&#x02217;</mml:mo><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula><disp-formula id="EEq7"><label>(18)</label><mml:math id="EEq7EAAAABBCCA"><mml:mtable><mml:mtr><mml:mtd><mml:mtext>&#x02009;</mml:mtext><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>&#x003d1;</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>&#x003d1;</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mfenced open="{" close="}"><mml:mrow><mml:mi>&#x003b2;</mml:mi><mml:mfenced open="[" close="]"><mml:mrow><mml:mi>I</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>&#x003d1;</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>&#x02217;</mml:mo><mml:mover accent="true"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x020d1;</mml:mo></mml:mover></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>By considering both the first similarity relation and the second similarity relation, the node representation is learned. Then, we can use random forests to make predictions.</p></sec><sec id="sec2.8"><title>2.8. Criteria for Validation of Prediction</title><p>For the binary classification problem, according to the combination of real class and learner prediction category, the examples can be divided into true positive example (TP), false negative example (FN), false positive example (FP), and true negative example (TN) as shown in <xref rid="tab3" ref-type="table">Table 3</xref>.</p><p>AUC is the area under the curve, and its calculation method takes into account the classification ability of the classifier for positive and negative cases. In the case of unbalanced samples, the classifier can still make a reasonable evaluation. The larger the AUC, the more advanced the prediction results of the samples and the better the prediction effect. In addition to the above two important indicators, we also select precision and accuracy; F1 scores and recall were used as the evaluation criteria.</p></sec></sec><sec id="sec3"><title>3. Results and Discussion</title><sec id="sec3.1"><title>3.1. Results</title><p>The 4&#x02009;:&#x02009;1 data set is divided into training set and test set, and the final features are obtained by five cross validation. The feature dimension is 128 dimensions, and 2102 node vectors are obtained. Because this is an unbalanced classification task, we solve this problem by randomly selecting the same number of unconnected edges as negative examples. The random forest [<xref rid="B28" ref-type="bibr">28</xref>] is used to predict the parameters. For the weight of the similarity between the two networks, we choose 0.5 that is half. The maximum number of steps max_t of random walk is 32, and the minimum number of steps is 1, 0.15 for the probability of stopping immediately. 0.0001, 0.01, and 0.1 are for the three optimization objective functions, respectively. The AUC values of ROC and PR are 0.8954 &#x000b1; 0.001 and 0.9002 &#x000b1; 0.0015.</p><p>We also measure the results of adding network similarity and not adding network similarity. The results shown in <xref rid="tab4" ref-type="table">Table 4</xref> are as follows: 1 is the embedding method with two similar networks added, 2 is the embedding method without adding network, 3 is the embedding method with adding disease network, and 4 is the result of adding miRNA similarity network. From the results, we can see the result of adding similar network. It is the best. This shows that we have greatly improved the prediction effect by adding network similarity.</p></sec><sec id="sec3.2"><title>3.2. Computational Efficiency</title><p>Because this paper uses Python implementation, so the time efficiency will be lower than other embedding methods completed by C++. C++ is closer to the bottom, so the efficiency will be improved. However, Python has many data processing-related libraries, which will make the code writing more convenient. In this paper, the running time efficiency is minute level, and other methods are seconds' level.</p></sec><sec id="sec3.3"><title>3.3. Parameter Analysis</title><p>Important parameters are analyzed as shown in <xref ref-type="fig" rid="fig1">Figure 1</xref>. The parameter scores mean the value obtained by ROC or PR, and <italic>w</italic><sub><italic>s</italic></sub> is the size of the context window after selecting a central word in the random walk corpus. As the window becomes larger, the AUC of ROC and AUC of PR increase, which is in line with the actual law. The more context is, the more accurate the prediction will be. However, when the window reaches a certain value, AUC of ROC and AUC of PR tend to be stable, because the context information is enough to produce prediction results.&#x02009;<italic>n</italic><sub><italic>s</italic></sub> is the number of negative samples selected. With the increase of the number of negative samples, the prediction will be more accurate. <italic>d</italic> is the dimension of the embedded vector. It can be concluded that the higher the dimension is, the more original information it retains, and the more accurate the prediction is. But when it reaches a certain value, it also tends to be stable. <italic>&#x003b1;</italic>, <italic>&#x003b2;</italic>, and <italic>&#x003b3;</italic> are the coefficients of the optimization function, respectively. It can be seen that the fluctuation is very obvious, which indicates that they are important parameters to balance the first similarity and the second similarity for the embedded vector. Single increase of explicit or implicit relationship will lead to the uneven proportion of the first similarity and the second similarity, which will lead to the fluctuation of the prediction results.</p></sec><sec id="sec3.4"><title>3.4. Comparison of Network Embedding Methods</title><p>In order to compare the characteristics of this paper, we select six methods, such as DeepWalk, line, node2vec, grarep [<xref rid="B29" ref-type="bibr">29</xref>], GF, lap [<xref rid="B30" ref-type="bibr">30</xref>], and LLE [<xref rid="B31" ref-type="bibr">31</xref>], and we compare the results. The same data and prediction methods are used to measure the performance of this method. The following are the introduction of some of these methods and the results of comparative experiments.</p><p>DeepWalk: a node embedding method for heterogeneous networks, which obtains node sequences through unbalanced random walks, and then uses word2vec to obtain embedding vectors</p><p>Line: by optimizing the first and second similarity in a heterogeneous network, the final node vector is obtained</p><p>Node2vec: inherits DeepWalk and generates node sequence through organized random walk</p><p>Grarep: using matrix decomposition to solve network embedding problem. It can deal with weighted networks and integrate the global structure information in the process of learning network representation. However, due to the large amount of computation, this method will be particularly time-consuming, so it cannot be used in large-scale networks</p><p>GF: higher order nearest neighbor keeps embedding. By introducing higher order similarity matrix, higher-order similarity is preserved by generalized singular value decomposition to obtain embedding vector</p><p>From <xref rid="tab5" ref-type="table">Table 5</xref> to <xref ref-type="fig" rid="fig2">Figure 2</xref>, we can see that the ROC and AUC of PR method in this paper are better than other network embedding methods.</p></sec><sec id="sec3.5"><title>3.5. Comparison of Different Classifiers</title><p>
<xref rid="tab6" ref-type="table">Table 6</xref> shows the comparison of the prediction results of different classifiers on the embedded vector. We compared six classifiers. The RF is the Random Forest Classifier; KNN is the K Neighbors Classifier; ADBC is the AdaBoost Classifier; LR is the Logistic Regression Classifier; GBC is the Gradient Boosting Classifier; SVM is the support vector machines.</p></sec></sec><sec id="sec4"><title>4. Conclusion</title><p>We propose PmDNE, a method based on network embedding and network similarity analysis, to predict the miRNA-disease association. For embedded vectors, 128 dimensions are used, and the accuracy of prediction is significantly improved. The values of PR and AUC of PmDNE are 0.9002 and 0.8954, respectively. Compared with other network embedding methods, PmDNE has better ability on extract the features of disease and miRNA networks. Our method improves the efficiency of miRNA-disease association prediction. This method can also be extended to other area for biomedical network prediction.</p></sec></body><back><ack><title>Acknowledgments</title><p>This work was supported by the grants from the National &#x0201c;863&#x0201d; Key Basic Research Development Program (2014AA021505), the National Key Research Program (2017YFC1201201), the Shenzhen stable support program, and the startup grant of Harbin Institute of Technology (Shenzhen).</p></ack><sec sec-type="data-availability"><title>Data Availability</title><p>miRNA disease association data is obtained from the database website: HMDD3.0, link: <ext-link ext-link-type="uri" xlink:href="http://www.cuilab.cn/hmdde">http://www.cuilab.cn/hmdde</ext-link>. Disease theme data is downloaded from the national medical library, link: <ext-link ext-link-type="uri" xlink:href="http://www.nlm.nih.gov">http://www.nlm.nih.gov</ext-link>. The functional similarity of 495 miRNA nodes was obtained by downloading miRNA function similarity data [<xref rid="B17" ref-type="bibr">17</xref>].</p></sec><sec sec-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare that there is no conflict of interest regarding the publication of this paper.</p></sec><sec><title>Authors' Contributions</title><p>JL and YL designed the study, performed bioinformatics analysis, and drafted the manuscript. All of the authors performed the analysis and participated in the revision of the manuscript. JL and YW conceived the study, participated in its design and coordination, and drafted the manuscript. All authors read and approved the final manuscript.</p></sec><sec sec-type="supplementary-material" id="supplementary-material-1"><title>Supplementary Materials</title><supplementary-material content-type="local-data" id="supp-1"><label>Supplementary Materials</label><caption><p>Supplementary file 1: main code for PmDNA.</p></caption><media xlink:href="6248686.f1.py"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec><ref-list><ref id="B1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bartel</surname><given-names>D. P.</given-names></name></person-group><article-title>microRNAs: target recognition and regulatory functions</article-title><source><italic toggle="yes">Cell</italic></source><year>2009</year><volume>136</volume><issue>2</issue><fpage>215</fpage><lpage>233</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2009.01.002</pub-id><pub-id pub-id-type="other">2-s2.0-58249088751</pub-id><pub-id pub-id-type="pmid">19167326</pub-id></element-citation></ref><ref id="B2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meola</surname><given-names>N.</given-names></name><name><surname>Gennarino</surname><given-names>V. A.</given-names></name><name><surname>Banfi</surname><given-names>S.</given-names></name></person-group><article-title>microRNAs and genetic diseases</article-title><source><italic toggle="yes">Pathogenetics</italic></source><year>2009</year><volume>2</volume><issue>1</issue><fpage>p. 7</fpage><pub-id pub-id-type="doi">10.1186/1755-8417-2-7</pub-id></element-citation></ref><ref id="B3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reinhart</surname><given-names>B. J.</given-names></name><name><surname>Slack</surname><given-names>F. J.</given-names></name><name><surname>Basson</surname><given-names>M.</given-names></name><etal/></person-group><article-title>The 21-nucleotide let-7 RNA regulates developmental timing in Caenorhabditis elegans</article-title><source><italic toggle="yes">Nature</italic></source><year>2000</year><volume>403</volume><issue>6772</issue><fpage>901</fpage><lpage>906</lpage><pub-id pub-id-type="doi">10.1038/35002607</pub-id><pub-id pub-id-type="other">2-s2.0-0034708122</pub-id><?supplied-pmid 10706289?><pub-id pub-id-type="pmid">10706289</pub-id></element-citation></ref><ref id="B4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brennecke</surname><given-names>J.</given-names></name><name><surname>Hipfner</surname><given-names>D. R.</given-names></name><name><surname>Stark</surname><given-names>A.</given-names></name><name><surname>Russell</surname><given-names>R. B.</given-names></name><name><surname>Cohen</surname><given-names>S. M.</given-names></name></person-group><article-title>bantam encodes a developmentally regulated microRNA that controls cell proliferation and regulates the proapoptotic gene hid in Drosophila</article-title><source><italic toggle="yes">Cell</italic></source><year>2003</year><volume>113</volume><issue>1</issue><fpage>25</fpage><lpage>36</lpage><pub-id pub-id-type="doi">10.1016/S0092-8674(03)00231-9</pub-id><pub-id pub-id-type="other">2-s2.0-0037418839</pub-id><?supplied-pmid 12679032?><pub-id pub-id-type="pmid">12679032</pub-id></element-citation></ref><ref id="B5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miska</surname><given-names>E. A.</given-names></name></person-group><article-title>How microRNAs control cell division, differentiation and death</article-title><source><italic toggle="yes">Current Opinion in Genetics &#x00026; Development</italic></source><year>2005</year><volume>15</volume><issue>5</issue><fpage>563</fpage><lpage>568</lpage><pub-id pub-id-type="doi">10.1016/j.gde.2005.08.005</pub-id><pub-id pub-id-type="other">2-s2.0-24344494340</pub-id><?supplied-pmid 16099643?><pub-id pub-id-type="pmid">16099643</pub-id></element-citation></ref><ref id="B6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>Q.</given-names></name><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Hao</surname><given-names>Y.</given-names></name><etal/></person-group><article-title>miR2Disease: a manually curated database for microRNA deregulation in human disease</article-title><source><italic toggle="yes">Nucleic Acids Research</italic></source><year>2008</year><volume>37</volume><issue>suppl_1</issue><fpage>D98</fpage><lpage>D104</lpage><pub-id pub-id-type="pmid">18927107</pub-id></element-citation></ref><ref id="B7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Griffiths-Jones</surname><given-names>S.</given-names></name><name><surname>Saini</surname><given-names>H. K.</given-names></name><name><surname>van Dongen</surname><given-names>S.</given-names></name><name><surname>Enright</surname><given-names>A. J.</given-names></name></person-group><article-title>miRBase: tools for microRNA genomics</article-title><source><italic toggle="yes">Nucleic Acids Research</italic></source><year>2007</year><volume>36</volume><issue>Database</issue><fpage>D154</fpage><lpage>D158</lpage><pub-id pub-id-type="doi">10.1093/nar/gkm952</pub-id><pub-id pub-id-type="other">2-s2.0-38549150275</pub-id><?supplied-pmid 17991681?><pub-id pub-id-type="pmid">17991681</pub-id></element-citation></ref><ref id="B8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sethupathy</surname><given-names>P.</given-names></name><name><surname>Corda</surname><given-names>B.</given-names></name><name><surname>Hatzigeorgiou</surname><given-names>A. G.</given-names></name></person-group><article-title>TarBase: a comprehensive database of experimentally supported animal microRNA targets</article-title><source><italic toggle="yes">RNA</italic></source><year>2006</year><volume>12</volume><issue>2</issue><fpage>192</fpage><lpage>197</lpage><pub-id pub-id-type="doi">10.1261/rna.2239606</pub-id><pub-id pub-id-type="other">2-s2.0-31044444975</pub-id><?supplied-pmid 16373484?><pub-id pub-id-type="pmid">16373484</pub-id></element-citation></ref><ref id="B9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y.</given-names></name><name><surname>Qiu</surname><given-names>C.</given-names></name><name><surname>Tu</surname><given-names>J.</given-names></name><etal/></person-group><article-title>HMDD v2. 0: a database for experimentally supported human microRNA and disease associations</article-title><source><italic toggle="yes">Nucleic Acids Research</italic></source><year>2013</year><volume>42</volume><issue>D1</issue><fpage>D1070</fpage><lpage>D1074</lpage><pub-id pub-id-type="pmid">24194601</pub-id></element-citation></ref><ref id="B10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>X.</given-names></name><name><surname>Liu</surname><given-names>M.-X.</given-names></name><name><surname>Yan</surname><given-names>G.-Y.</given-names></name></person-group><article-title>RWRMDA: predicting novel human microRNA-disease associations</article-title><source><italic toggle="yes">Molecular BioSystems</italic></source><year>2012</year><volume>8</volume><issue>10</issue><fpage>2792</fpage><lpage>2798</lpage><pub-id pub-id-type="doi">10.1039/c2mb25180a</pub-id><pub-id pub-id-type="other">2-s2.0-84865786695</pub-id><?supplied-pmid 22875290?><pub-id pub-id-type="pmid">22875290</pub-id></element-citation></ref><ref id="B11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>X.</given-names></name><name><surname>Yan</surname><given-names>C. C.</given-names></name><name><surname>Zhang</surname><given-names>X.</given-names></name><name><surname>You</surname><given-names>Z. H.</given-names></name><name><surname>Huang</surname><given-names>Y. A.</given-names></name><name><surname>Yan</surname><given-names>G. Y.</given-names></name></person-group><article-title>HGIMDA: heterogeneous graph inference for miRNA-disease association prediction</article-title><source><italic toggle="yes">Oncotarget</italic></source><year>2016</year><volume>7</volume><issue>40</issue><fpage>65257</fpage><lpage>65269</lpage><pub-id pub-id-type="doi">10.18632/oncotarget.11251</pub-id><pub-id pub-id-type="other">2-s2.0-84994092024</pub-id><?supplied-pmid 27533456?><pub-id pub-id-type="pmid">27533456</pub-id></element-citation></ref><ref id="B12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>J.</given-names></name><name><surname>Li</surname><given-names>C.-X.</given-names></name><name><surname>Lv</surname><given-names>J.-Y.</given-names></name><etal/></person-group><article-title>Prioritizing candidate disease miRNAs by topological features in the miRNA target&#x02013;dysregulated network: case study of prostate cancer</article-title><source><italic toggle="yes">Molecular Cancer Therapeutics</italic></source><year>2011</year><volume>10</volume><issue>10</issue><fpage>1857</fpage><lpage>1866</lpage><pub-id pub-id-type="doi">10.1158/1535-7163.MCT-11-0055</pub-id><pub-id pub-id-type="other">2-s2.0-80053955783</pub-id><?supplied-pmid 21768329?><pub-id pub-id-type="pmid">21768329</pub-id></element-citation></ref><ref id="B13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xuan</surname><given-names>P.</given-names></name><name><surname>Han</surname><given-names>K.</given-names></name><name><surname>Guo</surname><given-names>M.</given-names></name><etal/></person-group><article-title>Prediction of microRNAs associated with human diseases based on weighted k most similar neighbors</article-title><source><italic toggle="yes">PLoS One</italic></source><year>2013</year><volume>8</volume><issue>8, article e70204</issue><pub-id pub-id-type="doi">10.1371/journal.pone.0070204</pub-id><pub-id pub-id-type="other">2-s2.0-84881349217</pub-id><?supplied-pmid 23950912?><pub-id pub-id-type="pmid">23950912</pub-id></element-citation></ref><ref id="B14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>X.</given-names></name><name><surname>Yan</surname><given-names>G.-Y.</given-names></name></person-group><article-title>Semi-supervised learning for potential human microRNA-disease associations inference</article-title><source><italic toggle="yes">Scientific Reports</italic></source><year>2014</year><volume>4</volume><fpage>p. 5501</fpage></element-citation></ref><ref id="B15"><label>15</label><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Ribeiro</surname><given-names>L. F.</given-names></name><name><surname>Saverese</surname><given-names>P. H.</given-names></name><name><surname>Figueiredo</surname><given-names>D. R.</given-names></name></person-group><source><italic toggle="yes">struc2vec: learning node representations from structural identity</italic></source><year>2017</year></element-citation></ref><ref id="B16"><label>16</label><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>H.</given-names></name><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Wang</surname><given-names>J.</given-names></name><etal/></person-group><article-title>GraphGAN: graph representation learning with generative adversarial nets</article-title><source><italic toggle="yes">IEEE Transactions on Knowledge and Data Engineering</italic></source><year>2017</year></element-citation></ref><ref id="B17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>D.</given-names></name><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Lu</surname><given-names>M.</given-names></name><name><surname>Song</surname><given-names>F.</given-names></name><name><surname>Cui</surname><given-names>Q.</given-names></name></person-group><article-title>Inferring the human microRNA functional similarity and functional network based on microRNA-associated diseases</article-title><source><italic toggle="yes">Bioinformatics</italic></source><year>2010</year><volume>26</volume><issue>13</issue><fpage>1644</fpage><lpage>1650</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btq241</pub-id><pub-id pub-id-type="other">2-s2.0-77954193356</pub-id><?supplied-pmid 20439255?><pub-id pub-id-type="pmid">20439255</pub-id></element-citation></ref><ref id="B18"><label>18</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Tang</surname><given-names>J.</given-names></name><name><surname>Qu</surname><given-names>M.</given-names></name><name><surname>Wang</surname><given-names>M.</given-names></name><name><surname>Zhang</surname><given-names>M.</given-names></name><name><surname>Yan</surname><given-names>J.</given-names></name><name><surname>Mei</surname><given-names>Q.</given-names></name></person-group><article-title>LINE: large-scale information network embedding</article-title><conf-name>WWW '15: Proceedings of the 24th International Conference on World Wide Web</conf-name><conf-date>2015</conf-date><conf-loc>Florence Italy</conf-loc><pub-id pub-id-type="doi">10.1145/2736277.2741093</pub-id><pub-id pub-id-type="other">2-s2.0-84968754224</pub-id></element-citation></ref><ref id="B19"><label>19</label><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Grover</surname><given-names>A.</given-names></name><name><surname>Leskovec</surname><given-names>J.</given-names></name></person-group><source><italic toggle="yes">node2vec: scalable feature learning for networks</italic></source><year>2016</year></element-citation></ref><ref id="B20"><label>20</label><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Perozzi</surname><given-names>B.</given-names></name><name><surname>Al-Rfou</surname><given-names>R.</given-names></name><name><surname>Skiena</surname><given-names>S.</given-names></name></person-group><source><italic toggle="yes">DeepWalk: online learning of social representations</italic></source><year>2014</year></element-citation></ref><ref id="B21"><label>21</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Mikolov</surname><given-names>T.</given-names></name><name><surname>Chen</surname><given-names>K.</given-names></name><name><surname>Corrado</surname><given-names>G.</given-names></name><name><surname>Dean</surname><given-names>J.</given-names></name></person-group><article-title>Efficient estimation of word representations in vector space</article-title><conf-name>ICLR 2013, International Conference on Learning Representations</conf-name><conf-date>2013</conf-date><conf-loc>Scottsdale, AZ, USA</conf-loc></element-citation></ref><ref id="B22"><label>22</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Swami</surname><given-names>Ananthram</given-names></name><name><surname>Chawla</surname><given-names>Nitesh V.</given-names></name><name><surname>Dong</surname><given-names>Yuxiao</given-names></name></person-group><article-title>metapath2vec: scalable representation learning for heterogeneous networks</article-title><conf-name>KDD '17: Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</conf-name><conf-date>2017</conf-date><conf-loc>Halifax NS Canada</conf-loc><pub-id pub-id-type="doi">10.1145/3097983.3098036</pub-id><pub-id pub-id-type="other">2-s2.0-85029022395</pub-id></element-citation></ref><ref id="B23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kleinberg</surname><given-names>J. M.</given-names></name></person-group><article-title>Authoritative sources in a hyperlinked environment</article-title><source><italic toggle="yes">Journal of the ACM (JACM)</italic></source><year>1999</year><volume>46</volume><issue>5</issue><fpage>604</fpage><lpage>632</lpage><pub-id pub-id-type="doi">10.1145/324133.324140</pub-id><pub-id pub-id-type="other">2-s2.0-4243148480</pub-id></element-citation></ref><ref id="B24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mikolov</surname><given-names>T.</given-names></name></person-group><article-title>Distributed representations of words and phrases and their\n compositionality</article-title><source><italic toggle="yes">Advances in Neural Information Processing Systems</italic></source><year>2013</year><volume>26</volume><fpage>3111</fpage><lpage>3119</lpage></element-citation></ref><ref id="B25"><label>25</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Yin</surname><given-names>H.</given-names></name><name><surname>Zou</surname><given-names>L.</given-names></name><name><surname>Nguyen</surname><given-names>Q. V.</given-names></name><name><surname>Huang</surname><given-names>Z.</given-names></name><name><surname>Zhou</surname><given-names>X.</given-names></name></person-group><article-title>Joint event-partner recommendation in event-based social networks</article-title><conf-name>2018 IEEE 34th International Conference on Data Engineering (ICDE)</conf-name><conf-date>2018</conf-date><conf-loc>Paris, France</conf-loc></element-citation></ref><ref id="B26"><label>26</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>H.</given-names></name><name><surname>Cao</surname><given-names>J.</given-names></name><name><surname>Shu</surname><given-names>L.</given-names></name><name><surname>Rafiei</surname><given-names>D.</given-names></name></person-group><article-title>Locality sensitive hashing revisited: filling the gap between theory and algorithm analysis</article-title><conf-name>CIKM'13: 22nd ACM International Conference on Information and Knowledge Management</conf-name><conf-date>2013</conf-date><conf-loc>San Francisco CA USA</conf-loc></element-citation></ref><ref id="B27"><label>27</label><element-citation publication-type="other"><person-group person-group-type="author"><name><surname>Bottou</surname><given-names>L.</given-names></name></person-group><source><italic toggle="yes">Stochastic gradient tricks</italic></source><year>2012</year></element-citation></ref><ref id="B28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liaw</surname><given-names>A.</given-names></name><name><surname>Wiener</surname><given-names>M.</given-names></name></person-group><article-title>Classification and regression by randomForest</article-title><source><italic toggle="yes">R News</italic></source><year>2002</year><volume>23</volume><issue>23</issue><pub-id pub-id-type="doi">10.1057/9780230509993</pub-id></element-citation></ref><ref id="B29"><label>29</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Cao</surname><given-names>Shaosheng</given-names></name><name><surname>Lu</surname><given-names>Wei</given-names></name><name><surname>Xu</surname><given-names>Qiongkai</given-names></name></person-group><article-title>GraRep: learning graph representations with global structural information</article-title><conf-name>CIKM'15: 24th ACM International Conference on Information and Knowledge Management</conf-name><conf-date>2015</conf-date><conf-loc>Melbourne Australia</conf-loc><pub-id pub-id-type="doi">10.1145/2806416.2806512</pub-id><pub-id pub-id-type="other">2-s2.0-84958239002</pub-id></element-citation></ref><ref id="B30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Belkin</surname><given-names>M.</given-names></name><name><surname>Niyogi</surname><given-names>P.</given-names></name></person-group><article-title>Laplacian eigenmaps for dimensionality reduction and data representation</article-title><source><italic toggle="yes">Neural computation</italic></source><year>2003</year><volume>15</volume><issue>6</issue><fpage>1373</fpage><lpage>1396</lpage><pub-id pub-id-type="doi">10.1162/089976603321780317</pub-id><pub-id pub-id-type="other">2-s2.0-0042378381</pub-id></element-citation></ref><ref id="B31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roweis</surname><given-names>S.</given-names></name><name><surname>Saul</surname><given-names>L.</given-names></name></person-group><article-title>Nonlinear dimensionality reduction by locally linear embedding</article-title><source><italic toggle="yes">Science</italic></source><year>2000</year><volume>290</volume><issue>5500</issue><fpage>2323</fpage><lpage>2326</lpage><pub-id pub-id-type="doi">10.1126/science.290.5500.2323</pub-id><pub-id pub-id-type="other">2-s2.0-0034704222</pub-id><?supplied-pmid 11125150?><pub-id pub-id-type="pmid">11125150</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="fig1" orientation="portrait" position="float"><label>Figure 1</label><caption><p>Influence of parameters on prediction effect. The parameter scores mean the value obtained by ROC or PR. The scores of alpha, beta, and gamma fluctuate greatly. These three parameters play an important role in regulating the size of the first similarity and the second similarity.</p></caption><graphic xlink:href="BMRI2020-6248686.001"/></fig><fig id="fig2" orientation="portrait" position="float"><label>Figure 2</label><caption><p>Experimental results for PR and ROC curves of each models: (a) ROC curves for all models; (b) PR curves for all models.</p></caption><graphic xlink:href="BMRI2020-6248686.002"/></fig><fig id="pseudo1" orientation="portrait" position="float"><label>Pseudocode 1</label><caption><p> Pseudocode of node sequence.</p></caption><graphic xlink:href="BMRI2020-6248686.pseudo.001"/></fig><table-wrap id="tab1" orientation="portrait" position="float"><label>Table 1</label><caption><p>Number of edges about miRNA and disease, miRNA and miRNA, and disease and disease.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1">miRNA</th><th align="center" rowspan="1" colspan="1">Disease</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">miRNA</td><td align="center" rowspan="1" colspan="1">644918</td><td align="center" rowspan="1" colspan="1">18733</td></tr><tr><td align="left" rowspan="1" colspan="1">Disease</td><td align="center" rowspan="1" colspan="1">18733</td><td align="center" rowspan="1" colspan="1">414003</td></tr></tbody></table></table-wrap><table-wrap id="tab2" orientation="portrait" position="float"><label>Table 2</label><caption><p>The number of miRNA nodes and disease node.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1">Nodes number</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">miRNA</td><td align="center" rowspan="1" colspan="1">1208</td></tr><tr><td align="left" rowspan="1" colspan="1">Disease</td><td align="center" rowspan="1" colspan="1">894</td></tr></tbody></table></table-wrap><table-wrap id="tab3" orientation="portrait" position="float"><label>Table 3</label><caption><p>Concept of TF, FN, FP, and TN.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2" colspan="1">Prediction values</th><th align="center" colspan="2" rowspan="1">Actual values</th></tr><tr><th align="center" rowspan="1" colspan="1">Positive</th><th align="center" rowspan="1" colspan="1">Negative</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Positive</td><td align="center" rowspan="1" colspan="1">TP</td><td align="center" rowspan="1" colspan="1">FN</td></tr><tr><td align="left" rowspan="1" colspan="1">Negative</td><td align="center" rowspan="1" colspan="1">FP</td><td align="center" rowspan="1" colspan="1">TN</td></tr></tbody></table><table-wrap-foot><fn><p>PR curve: abscissa is recall rate and ordinate is precision; precision = TP/(TP + FP); recall = TP/(total&#x02009;positive&#x02009;samples) = TP/(TP + FN); ROC curve: the abscissa is FPR and the ordinate is TPR; TPR = TP/(TP + FN); FPR = FP/(TN + FP).</p></fn></table-wrap-foot></table-wrap><table-wrap id="tab4" orientation="portrait" position="float"><label>Table 4</label><caption><p>Influence of different networks on results.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1">ROC_AUC</th><th align="center" rowspan="1" colspan="1">PR_AUC</th><th align="center" rowspan="1" colspan="1">PREC</th><th align="center" rowspan="1" colspan="1">ACC</th><th align="center" rowspan="1" colspan="1">F1</th><th align="center" rowspan="1" colspan="1">Recall</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">0.8952 &#x000b1; 0.003</td><td align="center" rowspan="1" colspan="1">0.9002 &#x000b1; 0.002</td><td align="center" rowspan="1" colspan="1">0.6744 &#x000b1; 0.01</td><td align="center" rowspan="1" colspan="1">0.8153 &#x000b1; 0.02</td><td align="center" rowspan="1" colspan="1">0.8104 &#x000b1; 0.004</td><td align="center" rowspan="1" colspan="1">0.7863 &#x000b1; 0.004</td></tr><tr><td align="left" rowspan="1" colspan="1">2</td><td align="center" rowspan="1" colspan="1">0.8833 &#x000b1; 0.002</td><td align="center" rowspan="1" colspan="1">0.8916 &#x000b1; 0.0015</td><td align="center" rowspan="1" colspan="1">0.6480 &#x000b1; 0.015</td><td align="center" rowspan="1" colspan="1">0.8034 &#x000b1; 0.02</td><td align="center" rowspan="1" colspan="1">0.7986 &#x000b1; 0.004</td><td align="center" rowspan="1" colspan="1">0.7861 &#x000b1; 0.005</td></tr><tr><td align="left" rowspan="1" colspan="1">3</td><td align="center" rowspan="1" colspan="1">0.8906 &#x000b1; 0.0015</td><td align="center" rowspan="1" colspan="1">0.8966 &#x000b1; 0.002</td><td align="center" rowspan="1" colspan="1">0.663 &#x000b1; 0.001</td><td align="center" rowspan="1" colspan="1">0.8103 &#x000b1; 0.015</td><td align="center" rowspan="1" colspan="1">0.8054 &#x000b1; 0.003</td><td align="center" rowspan="1" colspan="1">0.7857 &#x000b1; 0.004</td></tr><tr><td align="left" rowspan="1" colspan="1">4</td><td align="center" rowspan="1" colspan="1">0.8914 &#x000b1; 0.001</td><td align="center" rowspan="1" colspan="1">0.8968 &#x000b1; 0.0015</td><td align="center" rowspan="1" colspan="1">0.6634 &#x000b1; 0.003</td><td align="center" rowspan="1" colspan="1">0.8115 &#x000b1; 0.02</td><td align="center" rowspan="1" colspan="1">0.8056 &#x000b1; 0.002</td><td align="center" rowspan="1" colspan="1">0.7813 &#x000b1; 0.004</td></tr></tbody></table></table-wrap><table-wrap id="tab5" orientation="portrait" position="float"><label>Table 5</label><caption><p>Comparison of network embedding methods.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1">Auc_roc</th><th align="center" rowspan="1" colspan="1">Auc_pr</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">PmDNE</td><td align="center" rowspan="1" colspan="1">0.8954 &#x000b1; 0.003</td><td align="center" rowspan="1" colspan="1">0.9002 &#x000b1; 0.002</td></tr><tr><td align="left" rowspan="1" colspan="1">DeepWalk</td><td align="center" rowspan="1" colspan="1">0.8689 &#x000b1; 0.002</td><td align="center" rowspan="1" colspan="1">0.8780 &#x000b1; 0.002</td></tr><tr><td align="left" rowspan="1" colspan="1">Line</td><td align="center" rowspan="1" colspan="1">0.8302 &#x000b1; 0.003</td><td align="center" rowspan="1" colspan="1">0.8305 &#x000b1; 0.002</td></tr><tr><td align="left" rowspan="1" colspan="1">Node2Vec</td><td align="center" rowspan="1" colspan="1">0.8807 &#x000b1; 0.004</td><td align="center" rowspan="1" colspan="1">0.8782 &#x000b1; 0.004</td></tr><tr><td align="left" rowspan="1" colspan="1">GraRep</td><td align="center" rowspan="1" colspan="1">0.8766 &#x000b1; 0.002</td><td align="center" rowspan="1" colspan="1">0.8760 &#x000b1; 0.003</td></tr><tr><td align="left" rowspan="1" colspan="1">GF</td><td align="center" rowspan="1" colspan="1">0.8881 &#x000b1; 0.004</td><td align="center" rowspan="1" colspan="1">0.8856 &#x000b1; 0.003</td></tr><tr><td align="left" rowspan="1" colspan="1">Lap</td><td align="center" rowspan="1" colspan="1">0.7706 &#x000b1; 0.004</td><td align="center" rowspan="1" colspan="1">0.7062 &#x000b1; 0.002</td></tr><tr><td align="left" rowspan="1" colspan="1">lle</td><td align="center" rowspan="1" colspan="1">0.8670 &#x000b1; 0.004</td><td align="center" rowspan="1" colspan="1">0.8673 &#x000b1; 0.004</td></tr></tbody></table></table-wrap><table-wrap id="tab6" orientation="portrait" position="float"><label>Table 6</label><caption><p>Comparison of the effect of different classifiers.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1">ROC_AUC</th><th align="center" rowspan="1" colspan="1">PR_AUC</th><th align="center" rowspan="1" colspan="1">PREC</th><th align="center" rowspan="1" colspan="1">ACC</th><th align="center" rowspan="1" colspan="1">F1</th><th align="center" rowspan="1" colspan="1">Recall</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">RF</td><td align="center" rowspan="1" colspan="1">0.8954 &#x000b1; 0.003</td><td align="center" rowspan="1" colspan="1">0.9002 &#x000b1; 0.002</td><td align="center" rowspan="1" colspan="1">0.6744 &#x000b1; 0.01</td><td align="center" rowspan="1" colspan="1">0.8153 &#x000b1; 0.02</td><td align="center" rowspan="1" colspan="1">0.8104 &#x000b1; 0.004</td><td align="center" rowspan="1" colspan="1">0.7863 &#x000b1; 0.004</td></tr><tr><td align="left" rowspan="1" colspan="1">KNN</td><td align="center" rowspan="1" colspan="1">0.8746 &#x000b1; 0.002</td><td align="center" rowspan="1" colspan="1">0.8560 &#x000b1; 0.0015</td><td align="center" rowspan="1" colspan="1">0.7933 &#x000b1; 0.015</td><td align="center" rowspan="1" colspan="1">0.8075 &#x000b1; 0.02</td><td align="center" rowspan="1" colspan="1">0.8014 &#x000b1; 0.004</td><td align="center" rowspan="1" colspan="1">0.7758 &#x000b1; 0.005</td></tr><tr><td align="left" rowspan="1" colspan="1">GBC</td><td align="center" rowspan="1" colspan="1">0.8827 &#x000b1; 0.0015</td><td align="center" rowspan="1" colspan="1">0.8955 &#x000b1; 0.002</td><td align="center" rowspan="1" colspan="1">0.7747 &#x000b1; 0.001</td><td align="center" rowspan="1" colspan="1">0.8045 &#x000b1; 0.015</td><td align="center" rowspan="1" colspan="1">0.7937 &#x000b1; 0.003</td><td align="center" rowspan="1" colspan="1">0.7532 &#x000b1; 0.004</td></tr><tr><td align="left" rowspan="1" colspan="1">SVM</td><td align="center" rowspan="1" colspan="1">0.7693 &#x000b1; 0.001</td><td align="center" rowspan="1" colspan="1">0.8194 &#x000b1; 0.0015</td><td align="center" rowspan="1" colspan="1">0.7367 &#x000b1; 0.003</td><td align="center" rowspan="1" colspan="1">0.7042 &#x000b1; 0.02</td><td align="center" rowspan="1" colspan="1">0.5989 &#x000b1; 0.002</td><td align="center" rowspan="1" colspan="1">0.4495 &#x000b1; 0.004</td></tr><tr><td align="left" rowspan="1" colspan="1">LR</td><td align="center" rowspan="1" colspan="1">0.8070 &#x000b1; 0.02</td><td align="center" rowspan="1" colspan="1">0.8412 &#x000b1; 0.005</td><td align="center" rowspan="1" colspan="1">0.7541 &#x000b1; 0.004</td><td align="center" rowspan="1" colspan="1">0.7390 &#x000b1; 0.015</td><td align="center" rowspan="1" colspan="1">0.7153 &#x000b1; 0.004</td><td align="center" rowspan="1" colspan="1">0.65618 &#x000b1; 0.005</td></tr><tr><td align="left" rowspan="1" colspan="1">ADBC</td><td align="center" rowspan="1" colspan="1">0.8330 &#x000b1; 0.002</td><td align="center" rowspan="1" colspan="1">0.8579 &#x000b1; 0.002</td><td align="center" rowspan="1" colspan="1">0.71370.0015</td><td align="center" rowspan="1" colspan="1">0.7570 &#x000b1; 0.002</td><td align="center" rowspan="1" colspan="1">0.7348 &#x000b1; 0.004</td><td align="center" rowspan="1" colspan="1">0.6757 &#x000b1; 0.005</td></tr></tbody></table></table-wrap></floats-group></article>