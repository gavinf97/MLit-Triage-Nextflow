<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd"> 
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 1?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Nat Commun</journal-id><journal-id journal-id-type="iso-abbrev">Nat Commun</journal-id><journal-title-group><journal-title>Nature Communications</journal-title></journal-title-group><issn pub-type="epub">2041-1723</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmcid">10730818</article-id><article-id pub-id-type="publisher-id">43934</article-id><article-id pub-id-type="doi">10.1038/s41467-023-43934-4</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Merizo: a rapid and accurate protein domain segmentation method using invariant point attention</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Lau</surname><given-names>Andy M.</given-names></name><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2671-2140</contrib-id><name><surname>Kandathil</surname><given-names>Shaun M.</given-names></name><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8626-3765</contrib-id><name><surname>Jones</surname><given-names>David T.</given-names></name><address><email>d.t.jones@ucl.ac.uk</email></address><xref ref-type="aff" rid="Aff1"/></contrib><aff id="Aff1"><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02jx3x895</institution-id><institution-id institution-id-type="GRID">grid.83440.3b</institution-id><institution-id institution-id-type="ISNI">0000 0001 2190 1201</institution-id><institution>Department of Computer Science, </institution><institution>University College London, </institution></institution-wrap>London, WC1E 6BT UK </aff></contrib-group><pub-date pub-type="epub"><day>19</day><month>12</month><year>2023</year></pub-date><pub-date pub-type="pmc-release"><day>19</day><month>12</month><year>2023</year></pub-date><pub-date pub-type="collection"><year>2023</year></pub-date><volume>14</volume><elocation-id>8445</elocation-id><history><date date-type="received"><day>9</day><month>6</month><year>2023</year></date><date date-type="accepted"><day>24</day><month>11</month><year>2023</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2023</copyright-statement><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article&#x02019;s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article&#x02019;s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">The AlphaFold Protein Structure Database, containing predictions for over 200 million proteins, has been met with enthusiasm over its potential in enriching structural biological research and beyond. Currently, access to the database is precluded by an urgent need for tools that allow the efficient traversal, discovery, and documentation of its contents. Identifying domain regions in the database is a non-trivial endeavour and doing so will aid our understanding of protein structure and function, while facilitating drug discovery and comparative genomics. Here, we describe a deep learning method for domain segmentation called Merizo, which learns to cluster residues into domains in a bottom-up manner. Merizo is trained on CATH domains and fine-tuned on AlphaFold2 models via self-distillation, enabling it to be applied to both experimental and AlphaFold2 models. As proof of concept, we apply Merizo to the human proteome, identifying 40,818 putative domains that can be matched to CATH representative domains.</p></abstract><abstract id="Abs2" abstract-type="web-summary"><p id="Par2">Proteins contain modular structural and functional units called domains. Here, the authors have developed Merizo, a deep learning method for domain segmentation applicable to experimental structures as well as those generated by AlphaFold2.</p></abstract><kwd-group kwd-group-type="npg-subject"><title>Subject terms</title><kwd>Molecular modelling</kwd><kwd>Machine learning</kwd><kwd>Protein structure predictions</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">https://doi.org/10.13039/501100000268</institution-id><institution>RCUK | Biotechnology and Biological Sciences Research Council (BBSRC)</institution></institution-wrap></funding-source><award-id>BB/T019409/1</award-id><principal-award-recipient><name><surname>Jones</surname><given-names>David T.</given-names></name></principal-award-recipient></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Springer Nature Limited 2023</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1" sec-type="introduction"><title>Introduction</title><p id="Par3">Domains are locally compact regions within proteins that can fold independently of the rest of the protein and can sometimes support a biological function on their own. The fold of a domain is not unique to individual proteins but can be found and adopted by a variety of different sequences. Structural domains are well-annotated in databases such as CATH<sup><xref ref-type="bibr" rid="CR1">1</xref>,<xref ref-type="bibr" rid="CR2">2</xref></sup>, ECOD<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>, Pfam<sup><xref ref-type="bibr" rid="CR4">4</xref></sup> and SCOP<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>, which leverage sequence, structure, function and their evolutionary relationships to provide a comprehensive hierarchical classification of fold space, each with different levels of granularity.</p><p id="Par4">A long-standing challenge in structural biology is the problem of domain segmentation, or more precisely, how to divide protein structures into their constituent domains. Wetlaufer envisioned splitting proteins into domains as early as 1973, but even the denominations of what constitutes a domain are contested by different classification databases<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>. The structure of protein kinase CK2 (PDB 3BQC [10.2210/pdb3BQC/pdb] chain A) for example, is classified in CATH as a two-domain protein (superfamilies 3.30.200.20 and 1.10.510.10), but in ECOD as a single domain (ECOD 206.1.1.24)<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>. The difference in the assignment is due to ECOD preserving an active site formed between the N- and C-terminal lobes, while CATH bases its assignment on the internal structures of the two (sub)domains.</p><p id="Par5">Early segmentation methods such as PUU<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>, DOMAK<sup><xref ref-type="bibr" rid="CR9">9</xref></sup> and DETECTIVE<sup><xref ref-type="bibr" rid="CR10">10</xref></sup> published in the 1990s relied on the proposition that domains have a high intra-to-inter-domain contact ratio, and directly applied this principle to each protein structure to identify its domains. Newer methods, such as those used in automatic domain classification by CATH, ECOD and SCOP, instead capitalise on the extensive annotations already conducted and use existing classifications to seed and find similar domains in query structures based on various criteria<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>. CATH, for example, uses CATHEDRAL which clusters new structures to already assigned domains by detecting similarities between the secondary structure components in the protein core, using a graph theory-based algorithm<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>.</p><p id="Par6">Broadly, methods that identify domains can be divided into two groups based on how segmentation is conducted. PUU, DOMAK and DETECTIVE, as well as the more recent DeepDom<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>, DistDom<sup><xref ref-type="bibr" rid="CR13">13</xref></sup> and FUPred<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>, all conduct segmentation in a top-down fashion, in which the most likely &#x0201c;cut points&#x0201d; along the protein sequence are determined and used to partition it into domains. A key disadvantage of this regime is that discontinuous domains - those that fold in 3D space via two or more disjoint stretches of residues are typically left over-segmented as separate domains. The dual of the task, and a more challenging one, is to instead predict the domain membership of each residue individually. The second category of domain detection methods is therefore composed of bottom-up methods such as UniDoc<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>, SWORD<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> and DomBPred<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>, which decompose the input protein into fragments that are then progressively aggregated into domains. SWORD, in particular, proposes several alternative configurations as well as an optimal one, which can be reviewed by users to identify a suitable partitioning.</p><p id="Par7">The AlphaFold Protein Structure Database (AFDB) contains predicted models for over 200 million protein sequences and constitutes a valuable expansion of protein space<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>. An obvious use case for domain segmentation is in the high-throughput identification of domains from the AFDB, facilitating their sorting into structure databases such as CATH. Compared to experimentallyderived PDB structures, AFDB models may exhibit less optimal packing or folding, particularly for rare folds with limited known sequence homology. Furthermore, unlike experimental structures, the generation of in silico models is not constrained by the same factors (such as crystallisation success, quality, etc.), enabling the modelling of the entire sequences, including previously difficult-to-resolve regions. As such, many AFDB models also feature long stretches of unstructured regions that may hinder the performance of methods that are not prepared to operate on such models. More recently, methods such as DPAM have been developed to specifically operate on AFDB models, leveraging a combination of inter-residue distances, structural similarity to ECOD domains and the predicted aligned error (PAE) map produced by AlphaFold2 to inform domain assignment<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>.</p><p id="Par8">Our approach to the domain segmentation problem, called Merizo, is based on a deep neural network which conducts bottom-up domain assignment by learning to directly cluster residues into domains, based on a combination of its sequence and structure. Notably, our method makes use of the Invariant Point Attention (IPA) module introduced in AlphaFold2<sup><xref ref-type="bibr" rid="CR20">20</xref></sup>, leveraging its ability to mix together sequence and coordinate information to directly encode a protein structure into a latent representation (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>). Residue embeddings are clustered together by using an affinity learning<sup><xref ref-type="bibr" rid="CR21">21</xref>&#x02013;<xref ref-type="bibr" rid="CR23">23</xref></sup> approach whereby the ground-truth domain map is used directly as an objective, thereby allowing class index-invariant predictions. Residues that are part of the same domain are encouraged towards the same embedding, while those that are not are encouraged to have different embeddings. Merizo is trained on CATH domain annotations and fine-tuned on a subset of AFDB models using a self-knowledge distillation approach, allowing the network to be equally applied to experimental structures as well as those generated by AlphaFold2. Furthermore, we show how fast and accurate methods such as Merizo can be applied to the human genome, identifying 40,818 putative domains that can be matched to existing structures in CATH at various levels of similarity.<fig id="Fig1"><label>Fig. 1</label><caption><title>Overview of the Merizo network.</title><p><bold>a</bold> Summary of the network architecture. Network inputs to the IPA encoder are the single and pairwise representations and backbone frames in the style of AlphaFold2. The IPA encoder comprises six weight-shared blocks, each containing a single IPA block with RoPE positional encoding, and a bi-GRU transition block. <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$N$$\end{document}</tex-math><mml:math id="M2"><mml:mi>N</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_43934_Article_IEq1.gif"/></alternatives></inline-formula> denotes the residue count in a given target, and <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M4"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_43934_Article_IEq2.gif"/></alternatives></inline-formula> denotes the maximum number of assignable classes, set to 20. The encoder returns an updated single representation which is decoded by a masked transformer decoder. <bold>b</bold> Summary of the masked transformer decoder. In the decoder, learnable domain mask embeddings <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d$$\end{document}</tex-math><mml:math id="M6"><mml:mi>d</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_43934_Article_IEq3.gif"/></alternatives></inline-formula> are concatenated to the single representation and passed through a 10-layer MHA stack with ALiBi positional encoding. The attention-treated output is split to recover updated single and domain mask embeddings, and each are passed through a linear layer followed by normalisation. Domain mask predictions are made via calculating the inner product between the updated single representation <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${s{{\hbox{'}}}{{\hbox{'}}}}$$\end{document}</tex-math><mml:math id="M8"><mml:mi>s</mml:mi><mml:mi>&#x02019;</mml:mi><mml:mi>&#x02019;</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_43934_Article_IEq4.gif"/></alternatives></inline-formula> and the conditioned domain embeddings <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${d{{\hbox{'}}}}$$\end{document}</tex-math><mml:math id="M10"><mml:mi>d</mml:mi><mml:mi>&#x02019;</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_43934_Article_IEq5.gif"/></alternatives></inline-formula>. The positions of NDRs are predicted by passing <inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${s{{\hbox{'}}}{{\hbox{'}}}}$$\end{document}</tex-math><mml:math id="M12"><mml:mi>s</mml:mi><mml:mi>&#x02019;</mml:mi><mml:mi>&#x02019;</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_43934_Article_IEq6.gif"/></alternatives></inline-formula> through a two-layer bi-GRU followed by projection into two dimensions. To make per-domain pIoU predictions, the predicted domain mask tensor is split according to the predicted domain and is passed through a two-layer bi-GRU, followed by projection into one dimension to produce a single pIoU value for each domain. <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${ndom}$$\end{document}</tex-math><mml:math id="M14"><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_43934_Article_IEq7.gif"/></alternatives></inline-formula> represents the number of predicted domains.</p></caption><graphic xlink:href="41467_2023_43934_Fig1_HTML" id="d32e354"/></fig></p></sec><sec id="Sec2" sec-type="results"><title>Results</title><sec id="Sec3"><title>Benchmark against existing state-of-the-art methods</title><p id="Par9">Merizo was trained on 17,287 multi-domain proteins with annotations sourced from CATH 4.3, and another 663 chains were held out to be used as a testing set (referred to as CATH-663). Targets in CATH-663 do not share any domains from the same homologous superfamily as the training set in order to better gauge performance on folds that the network has not seen before. How well a predicted assignment agrees with the ground truth can be quantified via a number of different measures. Here, we score predictions based on (1) how well the residues in a predicted domain overlap with a true domain, measured via the intersect-over-union (IoU) between residues in the predicted and ground-truth domain, and (2) how precise the predicted domain boundaries are, when assessed using the Matthews Correlation Coefficient (MCC; <xref rid="MOESM1" ref-type="media">Supplementary Methods</xref>). The MCC describes the correlation between the predicted and ground-truth boundary positions, and a boundary is deemed correct if it is predicted within <inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\pm m$$\end{document}</tex-math><mml:math id="M16"><mml:mo>&#x000b1;</mml:mo><mml:mi>m</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_43934_Article_IEq8.gif"/></alternatives></inline-formula> residues of a ground-truth domain boundary (where <inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$m$$\end{document}</tex-math><mml:math id="M18"><mml:mi>m</mml:mi></mml:math><inline-graphic xlink:href="41467_2023_43934_Article_IEq9.gif"/></alternatives></inline-formula> is evaluated at 20 residues). Both scores are calculated at the domain level, and we report the domain length-weighted average for each target.</p><p id="Par10">Our benchmark compares the accuracy of domain assignments by Merizo against those produced by four recently published methods including DeepDom<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>, a CNN-based method from Eguchi et al<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>. (referred to as Eguchi-CNN), SWORD<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> and UniDoc<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>. Both DeepDom and Eguchi-CNN are machine learning (ML)-based methods and operate on primary sequence and distance map inputs respectively. In contrast, SWORD and UniDoc are non-ML-based and conduct segmentation on coordinates in a bottom-up fashion by clustering low-level structural elements into domains, in a manner similar to Merizo. In addition to the four published methods, we include four baseline measures, including scoring ECOD assignments against CATH (where ECOD assignments are treated as a prediction result), and three random assignment methods prefixed with&#x02019;Random&#x02019;, where the domain count is estimated according to the Domain Guess by Size method<sup><xref ref-type="bibr" rid="CR25">25</xref></sup>. Targets are then divided into either equally or unequally sized segments (&#x02019;Random equal/unequal&#x02019;) or each residue is assigned into a domain at random (&#x02019;Random assigned&#x02019;).</p><p id="Par11">A summary of the benchmark is shown in Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>. Overall, it can be seen that Merizo is the most performant method on the CATH-663 set when scoring by IoU, achieving a similar median IoU to the ECOD baseline. Merizo is followed closely by UniDoc which exhibits a similar median IoU, albeit with a wider distribution. As domain assignments can change drastically depending on the classification scheme used, we further divided CATH-663 into two sets, depending on whether there is consensus between the definitions from CATH and ECOD (a consensus set with 313 targets and a dissensus set with 350 targets) (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2a</xref>). Based on this split, most methods perform more strongly on the consensus set, where targets may be more obvious in their domain arrangement and are easier to both classify (for CATH and ECOD) as well as predict. The opposite is true for the dissensus set, where the gap between Merizo and UniDoc widens, indicating that where CATH and ECOD disagree on an assignment, Merizo is more likely than other methods to produce a CATH-like result.<fig id="Fig2"><label>Fig. 2</label><caption><title>Benchmark against existing methods on the CATH-663 set.</title><p><bold>a</bold> IoU distributions for each method for all CATH-663 targets, and targets where there is consensus or no consensus between CATH and ECOD assignments. <bold>b</bold> Comparison of IoU achieved when scoring Merizo against CATH or ECOD domain assignments. The colour gradient indicates the density of data points, where yellow and dark blue are high and low respectively. <bold>c</bold> Box plots showing IoU and MCC (<inline-formula id="IEq10"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\pm 20$$\end{document}</tex-math><mml:math id="M20"><mml:mo>&#x000b1;</mml:mo><mml:mn>20</mml:mn></mml:math><inline-graphic xlink:href="41467_2023_43934_Article_IEq10.gif"/></alternatives></inline-formula>) distributions an<bold>d d</bold> the percentage of domains that agree between Merizo and either CATH (dark blue), ECOD (light blue) or the maximum of either (red). Correct domains are defined as those with an IoU of at least 0.8 to the ground-truth domain. Performance of each method on <bold>e</bold> domain count prediction, and <bold>f</bold> the number of under (blue) and over-predicted (red) domains across all targets. All data shown in this figure represent the fine-tuned version of Merizo. <italic>n</italic>&#x02009;=&#x02009;663 for all panels unless specified otherwise. For all box plots shown, minima and maxima are shown by the whiskers, the box limits represent the lower and upper quartiles, and solid lines inside each box represent the distribution median. Outliers are defined as data points exceeding 1.5x the interquartile range.</p></caption><graphic xlink:href="41467_2023_43934_Fig2_HTML" id="d32e452"/></fig></p><p id="Par12">Where Merizo does not produce a well-scoring result based on CATH, the assignment may not be wrong per se, but may represent an alternative assignment that the network has negotiated given its internal knowledge of domain packing. When the possibility of an alternative ground truth is considered (such as scoring Merizo against ECOD), it can be seen that Merizo does produce ECOD-like assignments for a subset of targets despite not being trained to do so (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2b</xref>). Points on the scatterplot where a data point falls in the upper triangle indicate targets where Merizo&#x02019;s domain assignment matches that of ECOD over CATH, while the lower triangle represents the opposite. For some targets, the domain annotation of CATH may contain errors, or where the assignment was made from the culmination of other priors that our method does not have access to. Indeed, several cases were identified in the CATH-663 set where pairs of chains shared similar structures but were inconsistently parsed by CATH, leading to Merizo underperforming against the conflicting ground-truth labels (Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">3</xref>).</p><p id="Par13">When CATH or ECOD are individually used as the ground truth for scoring Merizo, it is both expected and observed that Merizo is attuned to producing CATH-like assignments (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2c</xref>). However, scoring Merizo dynamically to either CATH or ECOD (whichever ground truth scores highest), yields a much stronger performance in terms of both IoU and MCC scores, as well as the number of correctly predicted domains which increases to nearly 75%, from 65% when scoring against CATH only (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2d</xref>).</p><p id="Par14">Another important facet of domain segmentation is correctly predicting the number of domains within a given target. On this task, domain count predictions by Merizo were the most accurate, scoring a mean absolute error (MAE) of 0.332 (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2e</xref>). All ML-based methods including Merizo, Eguchi-CNN and DeepDom also have a tendency to underestimate rather than overestimate the number of domains, whereas the opposite is true for all other methods (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2f</xref>).</p></sec><sec id="Sec4"><title>Fine-tuning Merizo on AlphaFold2 models</title><p id="Par15">As some AFDB models may contain large stretches of unstructured regions (which we refer to as non-domain residues or NDRs), we fine-tuned Merizo on a subset of the AFDB human proteome (AFDB-human) to encourage the network to become performant on these models. Domains from AFDB-human have been classified in ECOD, describing 47,577 domains across 18,038 proteins<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>. Since Merizo is a CATH-specific domain segmentation method, we opted not to train on the ECOD classifications, but to instead utilise a self-knowledge distillation approach which was conducted in two stages (see Methods sections &#x02018;Fine-tuning on AFDB models&#x02019;).</p><p id="Par16">A comparison of before and after fine-tuning Merizo is shown in Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>. On the task of NDR detection, we compared the number of NDRs predicted by Merizo before and after fine-tuning, as well as to three baselines: (1) predictions by UniDoc, (2) inferring from PAE/plDDT and (3) predictions by DPAM. Results show that after fine-tuning, the ability of Merizo to detect NDRs drastically increases, and is highly correlated with NDR counts inferred from PAE/plDDT and those reported by DPAM (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3a</xref>). Examples of domain assignments by Merizo before and after fine-tuning are shown in Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">4</xref>. Performance on domain prediction on the CATH-663 set changes little after fine-tuning but noticeably results in a small drop in median IoU and MCC scores, but with narrower overall distributions, suggesting that self-distillation leads to more consistent assignments (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3b</xref>).<fig id="Fig3"><label>Fig. 3</label><caption><title>Performance of Merizo on the AFDB-1195 set.</title><p><bold>a</bold> Agreement between the number of NDRs identified by Merizo after fine-tuning, compared to before fine-tuning (blue), UniDoc (purple), inferring from PAE and plDDT data (red) and as classified by DPAM (teal) (n&#x02009;=&#x02009;1195). The inset shows the coefficient of determination (R2) for each correlation. <bold>b</bold> IoU and MCC (&#x02009;&#x000b1;&#x02009;20) distributions on the CATH-663 set before (light blue) and after (dark blue) fine-tuning (n&#x02009;=&#x02009;663). For all box plots shown, minima and maxima are shown by the whiskers, the box limits represent the lower and upper quartiles, and solid lines inside each box represent the distribution median. Outliers are defined as data points exceeding 1.5x the interquartile range. <bold>c</bold> The number of domains identified by Merizo and DPAM (dark blue), as well as the number of identified domains matched to ECOD domains (light blue) is shown for each method. Merizo domains were assigned to ECOD representative domains via TM-align, using a threshold of 0.5 (TM-align score normalised by the length of the Merizo domain). <bold>d-e</bold> Examples of domain assignments by UniDoc, UniDoc (following removal of residues with plDDT less than 60), SWORD, DPAM and Merizo. Each identified domain has been shown in a different colour as well as by the text labels from A to O. NDRs are shown in white. In both examples, NDR detection is the most robust in Merizo, while UniDoc and SWORD do not classify these regions entirely, and DPAM over-segments NDRs into additional domains.</p></caption><graphic xlink:href="41467_2023_43934_Fig3_HTML" id="d32e518"/></fig></p><p id="Par17">On the set of AFDB-1195, where ground-truth domain assignments are unavailable, Merizo identifies a total of 3752 domains (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3c</xref>). Despite DPAM identifying many more domains (5119) than Merizo, only 3749 (73%) were later classified into ECOD domains. One possible explanation for this discrepancy is that DPAM has detected domains that are novel to ECOD and cannot be easily assigned to an ECOD class. However, a closer examination of targets where DPAM has predicted a large number of domains revealed that DPAM had the tendency to find domains within the unstructured regions of AFDB models (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3d-e</xref>). The examples depicted in Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3d, e</xref> illustrate cases where DPAM has over-segmented NDRs, leading to inflated estimates of domain counts. Furthermore, nearly all domains (3605 domains; 96%) identified by Merizo can be aligned to the ECOD F40 representative set<sup><xref ref-type="bibr" rid="CR3">3</xref></sup> with a TM-align score of 0.5 or greater<sup><xref ref-type="bibr" rid="CR27">27</xref></sup> (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3c</xref>). Even at a higher threshold of 0.6, 3242 domains (86%) can be matched, suggesting that Merizo-identified domains are reasonably recognisable by ECOD (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3c</xref>).</p><p id="Par18">Both SWORD and UniDoc are incapable of differentiating domains from NDRs, resulting in the inclusion of the latter in domain predictions. In models with a significant proportion of NDRs, this limitation reduces the effectiveness of both methods when applied to AFDB models, as NDRs must be addressed separately in order to accurately segment domains. We briefly explored the possibility of using a plDDT filter to remove low-quality residues, however, this commonly resulted in over-fragmented structures, unsatisfactory clean-up, or removal of residues from folded domains at higher plDDT thresholds (Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">5</xref>). Assigning domains on these models using UniDoc, highlighted cases where UniDoc was unable to partition folded domains from leftover NDR fragments (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3d</xref> and Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">5</xref>). In many cases, removing low plDDT residues altered the assignment by UniDoc (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3d</xref> and Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">5</xref>). Taken together, the above observations illustrate that the presence of NDRs in AFDB models can obfuscate the performance of methods that are unable to handle such regions, leading to unsatisfactory segmentation. By employing a targeted approach whereby Merizo is fine-tuned to recognise NDRs, domain segmentation on AFDB models can be made more robust.</p></sec><sec id="Sec5"><title>Application of Merizo to the human proteome</title><p id="Par19">As a demonstration of our method, we applied Merizo to the entire AFDB-human set containing 23,391 models generated by AlphaFold2<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>. The first observation is that approximately 37% of analysed residues were classified by Merizo as NDRs (Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4a</xref>). This value is supported by observations from Schaeffer et al<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>. which found that globular domains comprised 62% of residues in the AFDB-human set. Overall, across 23,391 AFDB-human models, 74,250 candidate domains were identified, with most of these having high domain-level plDDT scores (residue plDDT averaged across the domain). 96.4% of these domains fall within the&#x02019;confident&#x02019; to&#x02019;very high&#x02019; plDDT bins demarcated by AlphaFold2<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>, indicating that most domains identified by Merizo are segmented from well-folded regions where AlphaFold2 is confident (Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4b</xref>).<fig id="Fig4"><label>Fig. 4</label><caption><title>Putative domains identified in the entire human proteome.</title><p><bold>a</bold> The number of residues identified as domain residues (DR) and NDR in the AFDB-human set. Distributions showing the <bold>b</bold> average domain plDDT and <bold>c</bold> domain pIoU for 74,250 domains identified by Merizo in 23,391 models of the AFDB-human set. The red lines indicate thresholds applied to the plDDT and pIoU scores which were used to dichotomise a subset for further analysis. The colour bar indicates the plDDT confidence bin as per AlphaFold2, with very low (red), low (yellow), confident (light blue) and very high (dark blue) bins. <bold>d</bold> Distribution of SSAP scores for 50,175 confident domains, aligned to the CATH S40 non-redundant set. SSAP score bins demarcated above the histogram represent similarity at the CATH architecture (A; 70&#x02009;&#x0003e;&#x02009;SSAP&#x02009;&#x02265;&#x02009;60; yellow), topology (T; 80&#x02009;&#x0003e;&#x02009;SSAP&#x02009;&#x02265;&#x02009;70; light blue) and homologous superfamily (H; SSAP&#x02009;&#x02265;&#x02009;80; dark blue) levels. SSAP scores below 60 indicate weak similarity (red). 40,818 identified domains align to CATH domains with a SSAP score of at least 60. <bold>e</bold> The most abundant superfamilies identified in AFDB-human by Merizo. The inset shows the distribution of domains assigned to each CATH class. <bold>f-i</bold> Examples of AFDB-human models segmented by Merizo, where each colour represents a different predicted domain. NDRs are shown in white.</p></caption><graphic xlink:href="41467_2023_43934_Fig4_HTML" id="d32e610"/></fig></p><p id="Par20">In addition to predictions of domains, Merizo also outputs estimates of confidence in the predictions, expressed as predicted IoU (pIoU). The pIoU distribution produced by Merizo also illustrates that the network is confident in most of its predictions, as most fall into the 0.95&#x02013;1.00 pIoU bin (Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4c</xref>). From our analysis of the CATH-663 set, we determined that a pIoU cut-off of 0.75 can be used to group domain predictions into high (pIoU &#x02265; 0.75) and low-quality (pIoU &#x0003c;0.75) predictions (Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">6</xref>).</p><p id="Par21">Next, to verify the validity of the identified domains, we extracted a subset of high-confidence domains by applying cut-offs to the domain-level plDDT (plDDT &#x02265; 70) and pIoU scores (pIoU &#x02265; 0.75). This process yielded 50,175 high-confidence domains, which were then putatively assigned to CATH superfamilies using the sequential structure alignment program (SSAP) score<sup><xref ref-type="bibr" rid="CR29">29</xref></sup> against the CATH S40 nonredundant set<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>. The SSAP score quantifies the similarity between two structures, taking into account the order of residues as well as secondary structure elements and motifs. SSAP scores in the ranges of 60&#x02013;70, 70&#x02013;80, and 80&#x02013;100 correspond to similarity at roughly the architecture, topology, and homologous superfamily levels, respectively. The distribution of SSAP scores, depicted in Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4d</xref>, illustrates the similarity between each high-confidence domain and the best-matching representative CATH domain. Overall, 40,818 domains (81.3%) were successfully aligned to an existing CATH class, with 49.7%, 19.2%, and 12.5% matching at the superfamily, topology, and architecture levels, respectively.</p><p id="Par22">To analyse the subset of models that did not align straightforwardly to a CATH representative domain, we employed Foldseek&#x02019;s easy-cluster algorithm<sup><xref ref-type="bibr" rid="CR30">30</xref></sup> for clustering these structures. Applying a criterion of 50% coverage and a TM-score threshold of 0.5, we identified 5281 distinct clusters. On closer examination, a significant number of clusters corresponded to domain fragments, including segmented blades from propeller folds and variable-sized fragments from repetitive domains like HEAT repeats. However, several clusters corresponded to structures exhibiting high domain plDDT (average residue plDDT greater than 70), which did not find a match among CATH representatives. We provide examples of these identified folds in Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">7</xref>.</p><p id="Par23">The superfamily distribution of the putatively assigned domains is shown in Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4e</xref>. CATH classes 1 to 3 (1: mainly alpha, 2: mainly beta, and 3: alpha beta domains) comprised most of the assignments, with only roughly 1% finding matches to classes 4 and 6 (4: few secondary structures and 6: special). Like the ECOD classification of the AFDB-human set<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>, the most abundant domain families included immunoglobulin-like folds such as canonical immunoglobulins (2.60.40.10) and cadherins (2.60.40.60). Domains in this topology are found in a range of proteins related to cell adhesion and immune response and are formed as long tandem repeats, including titin (Q8WZ42), sialoadhesin (Q9BZZ2), hemicentin-1 (Q96RW7), and FRAS1 (Q86XX4; Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4f&#x02013;i</xref>). The most abundant superfolds identified included Rossmann folds (3.40.50), jelly rolls (2.60.120), alpha/beta plaits (3.30.70), transferases (1.10.510) and helix-hairpins (1.10.287) (Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">8</xref>).</p></sec><sec id="Sec6"><title>Benchmarking runtime against other segmentation methods</title><p id="Par24">Besides accuracy, another important consideration of a method is its speed. Although accuracy should be the primary concern, the enormous number of models that have been made available in different databases including the AFDB, means that the speed and efficiency of methods are increasingly important factors that should not be overlooked. As such, we conducted a benchmark study of runtimes, comparing Merizo against other methods on two sets of proteins. The first is the CATH-663 benchmark set which contains proteins from 90 to 739 residues long, while the second is a small set of 27 proteins (referred to as AFDB-27) selected from the AFDB-human set, chosen to encompass the full range of lengths (up to a maximum of 2700 residues) and to test runtimes on longer models.</p><p id="Par25">Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref> shows the measured runtimes for Merizo against UniDoc, SWORD, DeepDom and Eguchi-CNN and on different hardware. For several methods including Merizo, the average runtime per target on the most optimal hardware type (CPU or GPU) is less than a fifth of a second, with the fastest method being DeepDom, which can process inputs in batches to allow them to be segmented concurrently. The slowest method in our benchmark was SWORD, which required 6366&#x02009;sec (1.7&#x02009;h) to process the CATH-663 set. As expected, runtimes on CPU are in general slower than on GPU hardware, however an exception to this is the UniDoc method which was 30% faster than Merizo (GPU). While UniDoc boasts faster runtime than Merizo, it is constrained by a rule whereby residues that are part of secondary structure elements are never considered as potential domain boundaries. Although this, in theory, reduces the computational cost of the method greatly, it comes at the cost of not being able to split domains on residues which fall onto secondary structure elements. Examples of such cases can be seen in CATH, ECOD as well as in SCOPe (Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">9</xref> and Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">10</xref>).<table-wrap id="Tab1"><label>Table 1</label><caption><p>Comparison of runtimes on CATH-663 targets</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Method</th><th>Hardware</th><th>Average time per target (s)</th><th>Total runtime (s)</th><th>Relative</th></tr></thead><tbody><tr><td>Merizo</td><td>GPU</td><td>0.112</td><td>74.32</td><td>1.00</td></tr><tr><td/><td>CPU</td><td>1.095</td><td>725.77</td><td>9.77</td></tr><tr><td>UniDoc</td><td>CPU</td><td>0.078</td><td>51.75</td><td>0.70</td></tr><tr><td>SWORD</td><td>CPU</td><td>9.602</td><td>6366.00</td><td>85.65</td></tr><tr><td>DeepDom</td><td>GPU</td><td>0.020</td><td>13.29</td><td>0.18</td></tr><tr><td/><td>CPU</td><td>0.055</td><td>36.69</td><td>0.49</td></tr><tr><td>Eguchi-CNN</td><td>CPU</td><td>4.475</td><td>2966.77</td><td>39.92</td></tr></tbody></table></table-wrap></p><p id="Par26">Similar results were obtained from the AFDB-27 set which compared Merizo against other high-accuracy methods (including UniDoc, SWORD and DPAM) on AFDB models. Results are shown in Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">11</xref>, where it can be seen that Merizo (GPU) and UniDoc are overall the fastest methods. On targets with fewer than 1500 residues, UniDoc achieves lower runtimes than Merizo, however, the difference becomes smaller as models approach 2000 residues in length. The maximum model size that Merizo can process is limited by GPU memory; on an NVIDIA 1080Ti with 11GB of memory, this maximum is roughly 2100 residues. Models longer than this cut-off can instead be processed either on a GPU with larger memory capacity, or by CPU, albeit at an 8&#x02013;10x increase in runtime. Even on a CPU, however, Merizo compares very favourably to SWORD and DPAM, which on the longer models can be up to three orders of magnitude slower than Merizo. This difference is especially prominent when comparing the total runtime of each method, as SWORD and DPAM require approximately 40&#x02009;h to process the set of 27 models on a single CPU core while Merizo requires only 14&#x02009;min on the same hardware. When the accuracy of each method is also taken into consideration, as well as applicability to AFDB models, the performance of Merizo compares favourably, being able to produce accurate domain assignments even on AFDB models with reasonable runtimes.</p></sec></sec><sec id="Sec7" sec-type="discussion"><title>Discussion</title><p id="Par27">In this study, we have developed a fast and accurate domain segmentation method which can be applied to both experimentally-derived PDBs as well as in silico models such as those generated by AlphaFold2. AlphaFold2 models differ considerably from the former, particularly in the abundance of NDRs seen in some models (which we estimate to be around 40% of residues in the AFDB-human set). The presence of these residues can preclude some methods (including UniDoc and SWORD) from operating successfully. Despite the apparent correlation between NDRs and residues with low plDDT, it is important to note that applying a simple plDDT filter does not guarantee the successful removal of NDRs, as shown in Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3d</xref> and Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">5</xref>. It is conceivable that there could exist less common domains that are adequately modelled by AlphaFold2, but may be scored with lower confidence owing to their limited representation in the training data. Applying a poorly characterised plDDT filter could inadvertently lead to the exclusion of the most interesting aspects of the AFDB. The process of NDR detection is an intricate process and is addressed in Merizo by explicitly predicting their locations through a fine-tuning regime that familiarises the network with these types of residues.</p><p id="Par28">Besides its speed, the major advantage of Merizo over other AFDB-centric methods such as DPAM is that Merizo requires only a PDB structure to operate, while DPAM makes use of several tools and databases (including HH-suite<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>, DALI<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>, Foldseek<sup><xref ref-type="bibr" rid="CR30">30</xref></sup> and databases UniRef<sup><xref ref-type="bibr" rid="CR30">30</xref>,<xref ref-type="bibr" rid="CR33">33</xref></sup> PDB70<sup><xref ref-type="bibr" rid="CR34">34</xref></sup> and ECOD<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>) as well as the PAE map from AlphaFold2. In a high-throughput setting, the minimal dependencies of Merizo make it particularly well-suited to operate on a large number of models, reducing both the amount of time spent on computation as well as on file management.</p><p id="Par29">On an individual basis, one may surmise that identifying the boundaries of a domain within a single structure may not be difficult even by eye, however, the segmentation problem rapidly becomes intractable when a large number of structures are concerned. As the basic structural and functional units of protein structures, expanding our coverage of domain annotations across protein space can improve our understanding of their functions and how they interact with one another. In drug discovery, an expanded description of domains may facilitate the identification of potential targets as well as aid in repurposing existing drugs to new targets. A combination of Merizo together with structure searching or comparison tools such as Foldseek<sup><xref ref-type="bibr" rid="CR30">30</xref></sup> or Progres<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> would be well suited for identifying the structural homologs of a protein of interest by limiting the search space to the domains that matter most.</p><p id="Par30">More recently, developments in single-sequence and language model-based prediction methods<sup><xref ref-type="bibr" rid="CR36">36</xref>&#x02013;<xref ref-type="bibr" rid="CR38">38</xref></sup> have also been accompanied by faster runtimes over traditional sequence alignment-based methods (including AlphaFold2), which will undoubtedly boost the rate at which models will be made available to the scientific community. As these methods continue to improve in predictive accuracy, it may become commonplace for predictions to be made at genome scale or above, necessitating that any downstream analysis such as domain segmentation or function prediction be prepared to process or even re-process large amounts of data on a regular basis.</p><p id="Par31">Furthermore, classification schemes such as CATH, which we used for our ground-truth labels, would benefit from having domains pre-parsed from these large model databases in order to facilitate their sorting into families. Although we have based our segmentation predictions on CATH, we recognise that other databases such as ECOD or SCOP could have been used. However, as other studies have pointed out, domain assignments for the same protein are not necessarily agreed upon between different schemes, and classification by function, secondary structure or spatial separation may give different, but equally valid assignments<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>. In the context of ML, it may be advantageous to confine the labels used for training on a single classification scheme (at least in cases where assignments by different databases are at odds with one another) in order to avoid inadvertently introducing conflicting ground truths. That being said, as shown in Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">3</xref>, there are cases where Merizo has produced an assignment that matches that of ECOD but not CATH, and these cases illustrate that the network&#x02019;s definition of domain packing was confident enough to challenge the ground-truth CATH assignment.</p><p id="Par32">Fast and accurate segmentation methods could also play a role in determining the domain arrangement of newly discovered folds and structures, which is especially applicable to exercises such as the Critical Assessment of Structure Prediction (CASP). In CASP, tools such as Merizo could be used by the organisers to determine the domain boundaries of prediction targets, particularly in the free-modelling category, in which targets have no known homologs in the Protein Data Bank. Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">12</xref> shows three multi-domain targets from the CASP15 exercise which we predicted the domain boundaries for. Two of these targets, T1170 and T1121, are annotated by the CASP organisers as two-domain proteins, however, are segmented into three plausible domains by Merizo. It is interesting to speculate how the prediction performance of some participating groups may have changed depending on the domain definitions used for assessment.</p></sec><sec id="Sec8"><title>Methods</title><sec id="Sec9"><title>CATH training dataset</title><p id="Par33">The PDB chains and domain annotations used for training were accessed from version 4.3 of the CATH database<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>. To later assess our method&#x02019;s ability to generalise to folds not seen during training, we devised a training-test split which did not overlap at the CATH homologous superfamily (H) level. Splitting the dataset at the superfamily level is imperative, as homology can occur even at low sequence identities. To generate non-overlapping training and testing datasets, we constructed an adjacency matrix containing all CATH superfamilies across classes 1 to 6. Edges were added between superfamilies if a PDB chain can be found that contains domains from two superfamilies (Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">1</xref>). The resulting graph contains 655 components and is highly disproportionate, with the first and largest component containing roughly 60% of all superfamilies (2295), while the rest are spread across the other 654 components (1585 superfamilies). Additional statistics are summarised in Supplementary Table&#x000a0;<xref rid="MOESM1" ref-type="media">1</xref>.</p><p id="Par34">Each graph component represents a subset of PDB chains which only contain domains from an isolated set of superfamilies. Thus, by iterating over the list of components, each can be assigned to either the training or the test set without PDB chains overlapping at the H-level. As the largest component contains the majority of superfamilies and domains, it is naturally assigned to the training set. Of the remaining components, roughly 1 in 20 were held out to comprise the test set. Further redundancy filtering with CD-HIT<sup><xref ref-type="bibr" rid="CR39">39</xref></sup> was performed to cluster targets which had a sequence identity of greater than 99%. The final training and testing set contained 17,287 and 663 chains respectively.</p><p id="Par35">CATH maintains a list of ambiguous domains which have not yet been assigned to any superfamily referred to as being in the &#x0201c;holding pen&#x0201d;. Such domains are unfinalized in their classification and boundary annotations. As such, they are masked out during training to avoid polluting the network by learning these regions as either single domains or NDRs.</p></sec><sec id="Sec10"><title>AFDB models used for fine-tuning</title><p id="Par36">After training our network initially on the CATH dataset, Merizo was fine-tuned on models from the AFDB-human set, in order to improve predictive performance on these types of models. The AFDB-human set contains 23,391 models, however, not all models could be used for fine-tuning for several reasons. First, some AFDB-human models may contain domains that are homologous to those in the CATH-663 set and such models should be avoided. To determine a subset of AFDB-human models which did not share homologous domains with those in the CATH-663 set, we made use of ECOD domain annotations available for both datasets (standard ECOD database for CATH-663, and Schaeffer et al<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>. for AFDB-human models). Any AFDB-human model which contained an ECOD domain in the same H-group as those in the CATH-663 set were considered overlapping and thus were not suitable for training during fine-tuning. Conversely, such overlapping models were suitable for testing purposes following fine-tuning. Applying this methodology to the 18,038 AFDB-human models which had ECOD domain annotations, followed by the removal of single-domain targets and those with fewer than 200 residues (to expose the network to longer models with more varied NDRs), we were able to identify 7502 and 1195 AFDB-human models for the training and testing sets, respectively.</p><p id="Par37">To determine ground-truth NDR labels for each model, we developed a proxy measure which incorporated both residue plDDT and PAE maps for each target. Residues were dichotomised into either NDR (class 0) or non-NDR (class 1) categories based on two criteria: (1) the residue plDDT is less than 60, and (2) the standard deviation of PAE values for the residue is less than 0.4. All residues meeting both criteria are assigned as NDR, and all other residues are non-NDR.</p></sec><sec id="Sec11"><title>Network architecture</title><p id="Par38">Merizo is a small encoder-decoder network with approximately 37&#x02009;M parameters (20.4&#x02009;M in the encoder and 16.8&#x02009;M in the decoder; Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>). At the core of our network is the Invariant Point Attention (IPA) encoder, which makes use of the IPA module found within the structure module of AlphaFold2<sup><xref ref-type="bibr" rid="CR20">20</xref>,<xref ref-type="bibr" rid="CR40">40</xref></sup>. The role of the IPA module is to facilitate information mixing between the single and pairwise channels, while iteratively organising the backbone frames towards the ground-truth structure. In our usage, we repurpose the IPA module in an input-reversed fashion to instead read a folded structure into a latent representation which can then be decoded to provide the segmentation map. The IPA module takes three inputs: a single representation, pairwise representation and backbone frames. The single representation is produced by one-hot encoding the primary sequence into 20 amino acid classes and then projected into 512 feature dimensions. The dimensionality of the single representation is maintained throughout the network. For the pairwise representation, we use the pairwise distance map derived from alpha carbons, directly embedded into 32 feature dimensions as continuous values using a linear layer. Finally, the Euclidean backbone frames are calculated from each residue &#x0201c;frame&#x0201d; (N-CA-C atoms) via Gram-Schmidt orthogonalization as per AlphaFold2. Each frame consists of a rotation matrix of shape [3, 3] and translation vector of length 3.</p><p id="Par39">The IPA encoder is composed of six weight-shared blocks, each with 16 attention heads and employs rotary positional encoding (RoPE<sup><xref ref-type="bibr" rid="CR41">41</xref></sup>). In place of the typical feed-forward network that processes the attention outputs in the original Transformer model (and in AlphaFold2), we instead utilise a two-layer bi-directional gated recurrent unit (bi-GRU) which processes the post-attention single representation and introduces sequential dependency to the residue embeddings. The output of the IPA encoder is an updated single representation which is conditioned on structural information present in the pairwise and frame channels.</p><p id="Par40">To make predictions from the single representation, the masked transformer decoder adapted from the Segmenter model<sup><xref ref-type="bibr" rid="CR42">42</xref></sup> is used to predict domain masks (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1b</xref>). Learnable embeddings corresponding to <italic>k</italic> domain masks, where <italic>k</italic> is an arbitrary value which controls the maximum number of domains that can be assigned by the network (set to 20 in our implementation), are concatenated with the single representation (as if they were extra residues). Setting <italic>k</italic> to 20 is an architectural decision and a value greater than the largest number of domains concurrently seen by the network during training is typically selected. The largest target in our training set consists of 18 domains (Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">2</xref>), however with input cropping (see &#x0201c;Methods&#x0201d; section &#x02018;Training procedures&#x02019;), this value will drop to approximately 2&#x02013;4 domains.</p><p id="Par41">The new single representation and learnable domain mask embeddings are passed through a stack of 10 multi-head attention (MHA) blocks. Each MHA block employs Attention with Linear Biases (ALiBi) style positional encoding<sup><xref ref-type="bibr" rid="CR43">43</xref></sup> which applies a penalty to the attention score between pairs of residues, according to the separation between their residue indices. The output of the MHA stack is divided to recover the original dimensions of the single representation and learned domain mask embeddings. Per-residue domain probability distributions of shape [<italic>N</italic>, <italic>k</italic>] are derived by calculating the inner product between the [<italic>N</italic>, 512] single representation and [<italic>k</italic>, 512] domain mask embeddings. The per-residue domain probability distributions can be converted into predicted domain masks (per-residue domain indices) via the <italic>argmax</italic> function.</p><p id="Par42">In addition to domain masks, our network predicts two additional outputs: the positions of NDRs and per-domain pIoU predictions. NDR positions are predicted by passing the decoder-updated single representation through a two-layer bi-GRU with 256 hidden dimensions and projecting the output features of the final layer into two dimensions (with indices 0 and 1 signifying whether a residue is an NDR or not, respectively). The argmax of the output generates a binary array of length <italic>N</italic> (where <italic>N</italic> is the number of residues in the input) which can be multiplied with the domain ID assignments to mask out the positions of predicted NDRs. To make pIoU predictions, the domain ID probability distributions are divided according to the predicted domain masks, and the set of residue probability distributions corresponding to each domain are passed through a two-layer bi-GRU with 512 hidden dimensions. In each case, the final timestep of the bi-GRU is projected into one dimension to predict a pIoU value between 0&#x02013;1 which is trained to match the calculated IoU of the assigned domain against the ground-truth assignment.</p><p id="Par43">In a final stage, the predicted domain assignments are postprocessed in a cleaning step which coalesces any domain with fewer than 30 residues or any segment fewer than 10 residues, with the domain preceding it. This step is also performed on the output of the network prior to pIoU prediction by the final bi-GRU to ensure that domain pIoU is predicted on the same assignments produced by the network. During inference, an additional post-processing step is performed on the full chain input whereby if multiple domains are assigned to the same domain index by the network (which for example, can occur when a target contains a large number of domains), these domains are separated into different domains if the minimum distance between them is greater than 10 &#x000c5;. This can be done by calculating the intersection between the predicted domain map and the thresholded distance map (a.k.a. contact map), as an adjacency matrix, and assigning each graph component to a new unique domain index.</p></sec><sec id="Sec12"><title>Training procedures</title><p id="Par44">Our method is trained fully end-to-end in PyTorch, with all input features calculated directly from PDB files. Training was conducted in two phases: initial and fine-tuning (not to be confused with fine-tuning on AFDB models, described in Methods section &#x02018;Fine-tuning on AFDB models&#x02019;). Initial training was carried out for approximately 30 epochs using the Rectified Adam (RAdam) optimiser with a learning rate of 1e-4. During training, each target chain was randomly cropped to a window of 512 residues. Fine-tuning was carried out for approximately 10 epochs in which the contribution of both the IPA and decoder loss terms were multiplied by a factor of 2. A minibatch of size 1 was used throughout, and gradients were accumulated and back-propagated every 32 mini-batches. All training was conducted using up to 6 NVIDIA GTX 1080Ti GPUs with 11GB of memory. Additional details such as the affinity learning procedure as well as loss functions are described in the&#x000a0;<xref rid="MOESM1" ref-type="media">Supplementary Methods section</xref>.</p></sec><sec id="Sec13"><title>Fine-tuning on AFDB models</title><p id="Par45">The fine-tuning of Merizo on AFDB models was performed in two stages. First, Merizo was fine-tuned to detect NDRs in the AFDB models. NDR tuning needs to occur first before self-distillation since the predicted NDR mask overrides the domain mask. Poor performance in predicting NDRs would naturally lead to poor domain boundary prediction. As ground-truth labels for NDRs are not available, we inferred these positions via an empirically determined proxy based on residue-level PAE and plDDT scores (see Methods section &#x02018;AFDB models used for fine-tuning&#x02019;). All network parameters are frozen with the exception of the bi-GRU that predicts the NDR masks. The dataset used for this exercise consists of the set of 7052 AFDB models (see Methods section &#x02018;AFDB models used for fine-tuning&#x02019;). The <italic>L</italic><sub>bg,CE</sub> loss component (<xref rid="MOESM1" ref-type="media">Supplementary Methods</xref>) on the AFDB-1195 set is monitored throughout to measure network performance on the NDR task.</p><p id="Par46">The second stage is conducted when the loss on the NDR task converges. All network weights are unfrozen, and training is conducted as described in Methods section &#x02018;Training procedures&#x02019;. As ground-truth labels for the AFDB-human models are not available, we adopted a self-distillation approach whereby the predicted domain assignment is taken as the ground truth, following a cleaning function that removes any domains smaller than 30 residues as well as coalesces any segments that are fewer than 10 residues with the domain preceding it. During fine-tuning, the network is trained on the 17,287 chains with CATH annotations and 7052 AFDB-human models. Network performance on the CATH-663 set is monitored to ensure that performance on this set does not degrade. Losses on AFDB models were also scaled by a factor of 0.2. Hyperparameters were the same as those described in Methods section &#x02018;Training procedures&#x02019;.</p></sec><sec id="Sec14"><title>Statistics &#x00026; Reproducibility</title><p id="Par47">Sample sizes reported throughout the study were determined based on the availability of training and testing data available. The procedures taken to generate the training and testing split for developing our deep learning method are described clearly in the Methods section &#x0201c;CATH training dataset&#x0201d; and &#x0201c;AFDB models used for fine-tuning&#x0201d;. No data were excluded from the analyses. The experiments were not randomised. The Investigators were not blinded to allocation during experiments and outcome assessment.</p></sec><sec id="Sec15"><title>Reporting summary</title><p id="Par48">Further information on research design is available in the&#x000a0;<xref rid="MOESM3" ref-type="media">Nature Portfolio Reporting Summary</xref> linked to this article.</p></sec></sec><sec sec-type="supplementary-material"><sec id="Sec16"><title>Supplementary information</title><p>
<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="41467_2023_43934_MOESM1_ESM.pdf"><caption><p>Supplementary Information</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM2"><media xlink:href="41467_2023_43934_MOESM2_ESM.pdf"><caption><p>Peer Review File</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM3"><media xlink:href="41467_2023_43934_MOESM3_ESM.pdf"><caption><p>Reporting Summary</p></caption></media></supplementary-material>
</p></sec><sec id="Sec17"><title>Source data</title><p>
<supplementary-material content-type="local-data" id="MOESM4"><media xlink:href="41467_2023_43934_MOESM4_ESM.xls"><caption><p>Source Data</p></caption></media></supplementary-material>
</p></sec></sec></body><back><fn-group><fn><p><bold>Publisher&#x02019;s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><sec><title>Supplementary information</title><p>The online version contains supplementary material available at 10.1038/s41467-023-43934-4.</p></sec><ack><title>Acknowledgements</title><p>We would like to thank Ian Sillitoe for helpful discussions on CATH domain annotations and Daniel Buchan for helpful feedback. This research was funded in whole, or in part, by the UKRI [Grant number BB/T019409/1] to D. T. J.</p></ack><notes notes-type="author-contribution"><title>Author contributions</title><p>A. M. L., S. M. K. and D. T. J. conceptualised the study. A. M. L. prepared the datasets, performed network training, and conducted data analysis and visualisation. A. M. L. and S. M. K. wrote the manuscript. All authors read and approved the final version of the manuscript.</p></notes><notes notes-type="peer-review"><title>Peer review</title><sec id="FPar1"><title>Peer review information</title><p id="Par49"><italic>Nature Communications</italic> thanks the anonymous reviewer(s) for their contribution to the peer review of this work. A peer review file is available.</p></sec></notes><notes notes-type="data-availability"><title>Data availability</title><p>Datasets used as part of this study have been deposited to <ext-link ext-link-type="uri" xlink:href="https://github.com/psipred/Merizo">https://github.com/psipred/Merizo</ext-link>. Domain assignments for PDB and AFDB structures from CATH, ECOD, SCOPe and DPAM have been deposited at <ext-link ext-link-type="uri" xlink:href="https://github.com/psipred/Merizo/tree/main/datasets">https://github.com/psipred/Merizo/tree/main/datasets</ext-link>. AlphaFold2 human proteome models used in this study can be downloaded from <ext-link ext-link-type="uri" xlink:href="https://ftp.ebi.ac.uk/pub/databases/alphafold/latest/UP000005640_9606_HUMAN_v4.tar">https://ftp.ebi.ac.uk/pub/databases/alphafold/latest/UP000005640_9606_HUMAN_v4.tar</ext-link>. Protein Data Bank structure files were accessed from <ext-link ext-link-type="uri" xlink:href="https://www.rcsb.org">https://www.rcsb.org</ext-link> including PDB 3BQC [10.2210/pdb3BQC/pdb] (protein kinase CK2).&#x000a0;<xref ref-type="sec" rid="Sec17">Source data</xref> are provided with this paper.</p></notes><notes notes-type="data-availability"><title>Code availability</title><p>The code and network weights of Merizo are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/psipred/Merizo">https://github.com/psipred/Merizo</ext-link> and will be incorporated into the PSIPRED workbench at <ext-link ext-link-type="uri" xlink:href="http://bioinf.cs.ucl.ac.uk/psipred/">http://bioinf.cs.ucl.ac.uk/psipred/</ext-link>.</p></notes><notes id="FPar2" notes-type="COI-statement"><title>Competing interests</title><p id="Par50">The authors declare no competing interests.</p></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Orengo</surname><given-names>CA</given-names></name><etal/></person-group><article-title>CATH&#x02013;a hierarchic classification of protein domain structures</article-title><source>Structure</source><year>1997</year><volume>5</volume><fpage>1093</fpage><lpage>1109</lpage><pub-id pub-id-type="doi">10.1016/S0969-2126(97)00260-8</pub-id><?supplied-pmid 9309224?><pub-id pub-id-type="pmid">9309224</pub-id>
</element-citation></ref><ref id="CR2"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sillitoe</surname><given-names>I</given-names></name><etal/></person-group><article-title>CATH: increased structural coverage of functional space</article-title><source>Nucleic Acids Res.</source><year>2021</year><volume>49</volume><fpage>D266</fpage><lpage>D273</lpage><pub-id pub-id-type="doi">10.1093/nar/gkaa1079</pub-id><?supplied-pmid 33237325?><pub-id pub-id-type="pmid">33237325</pub-id>
</element-citation></ref><ref id="CR3"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheng</surname><given-names>H</given-names></name><etal/></person-group><article-title>ECOD: an evolutionary classification of protein domains</article-title><source>PLoS Comput. Biol</source><year>2014</year><volume>10</volume><fpage>e1003926</fpage><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003926</pub-id><?supplied-pmid 25474468?><pub-id pub-id-type="pmid">25474468</pub-id>
</element-citation></ref><ref id="CR4"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mistry</surname><given-names>J</given-names></name><etal/></person-group><article-title>Pfam: The protein families database in 2021</article-title><source>Nucleic Acids Res.</source><year>2021</year><volume>49</volume><fpage>D412</fpage><lpage>D419</lpage><pub-id pub-id-type="doi">10.1093/nar/gkaa913</pub-id><?supplied-pmid 33125078?><pub-id pub-id-type="pmid">33125078</pub-id>
</element-citation></ref><ref id="CR5"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andreeva</surname><given-names>A</given-names></name><name><surname>Kulesha</surname><given-names>E</given-names></name><name><surname>Gough</surname><given-names>J</given-names></name><name><surname>Murzin</surname><given-names>AG</given-names></name></person-group><article-title>The SCOP database in 2020: expanded classification of representative family and superfamily domains of known protein structures</article-title><source>Nucleic Acids Res.</source><year>2020</year><volume>48</volume><fpage>D376</fpage><lpage>D382</lpage><pub-id pub-id-type="doi">10.1093/nar/gkz1064</pub-id><?supplied-pmid 31724711?><pub-id pub-id-type="pmid">31724711</pub-id>
</element-citation></ref><ref id="CR6"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wetlaufer</surname><given-names>DB</given-names></name></person-group><article-title>Nucleation, rapid folding, and globular intrachain regions in proteins</article-title><source>Proc. Natl Acad. Sci.</source><year>1973</year><volume>70</volume><fpage>697</fpage><lpage>701</lpage><pub-id pub-id-type="doi">10.1073/pnas.70.3.697</pub-id><?supplied-pmid 4351801?><pub-id pub-id-type="pmid">4351801</pub-id>
</element-citation></ref><ref id="CR7"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schaeffer</surname><given-names>RD</given-names></name><name><surname>Kinch</surname><given-names>LN</given-names></name><name><surname>Pei</surname><given-names>J</given-names></name><name><surname>Medvedev</surname><given-names>KE</given-names></name><name><surname>Grishin</surname><given-names>NV</given-names></name></person-group><article-title>Completeness and consistency in structural domain classifications</article-title><source>ACS Omega</source><year>2021</year><volume>6</volume><fpage>15698</fpage><lpage>15707</lpage><pub-id pub-id-type="doi">10.1021/acsomega.1c00950</pub-id><?supplied-pmid 34179613?><pub-id pub-id-type="pmid">34179613</pub-id>
</element-citation></ref><ref id="CR8"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holm</surname><given-names>L</given-names></name><name><surname>Sander</surname><given-names>C</given-names></name></person-group><article-title>Parser for protein folding units</article-title><source>Proteins: Struct. Funct. Bioinforma.</source><year>1994</year><volume>19</volume><fpage>256</fpage><lpage>268</lpage><pub-id pub-id-type="doi">10.1002/prot.340190309</pub-id></element-citation></ref><ref id="CR9"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Siddiqui</surname><given-names>AS</given-names></name><name><surname>Barton</surname><given-names>GJ</given-names></name></person-group><article-title>Continuous and discontinuous domains: an algorithm for the automatic generation of reliable protein domain definitions</article-title><source>Protein Sci.</source><year>1995</year><volume>4</volume><fpage>872</fpage><lpage>884</lpage><pub-id pub-id-type="doi">10.1002/pro.5560040507</pub-id><?supplied-pmid 7663343?><pub-id pub-id-type="pmid">7663343</pub-id>
</element-citation></ref><ref id="CR10"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Swindells</surname><given-names>MB</given-names></name></person-group><article-title>A procedure for detecting structural domains in proteins</article-title><source>Protein Sci.</source><year>1995</year><volume>4</volume><fpage>103</fpage><lpage>112</lpage><pub-id pub-id-type="doi">10.1002/pro.5560040113</pub-id><?supplied-pmid 7773168?><pub-id pub-id-type="pmid">7773168</pub-id>
</element-citation></ref><ref id="CR11"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Redfern</surname><given-names>OC</given-names></name><name><surname>Harrison</surname><given-names>A</given-names></name><name><surname>Dallman</surname><given-names>T</given-names></name><name><surname>Pearl</surname><given-names>FM</given-names></name><name><surname>Orengo</surname><given-names>CA</given-names></name></person-group><article-title>CATHEDRAL: a fast and effective algorithm to predict folds and domain boundaries from multidomain protein structures</article-title><source>PLoS Comput. Biol.</source><year>2007</year><volume>3</volume><fpage>e232</fpage><pub-id pub-id-type="doi">10.1371/journal.pcbi.0030232</pub-id><?supplied-pmid 18052539?><pub-id pub-id-type="pmid">18052539</pub-id>
</element-citation></ref><ref id="CR12"><label>12.</label><mixed-citation publication-type="other">Jiang Y., Wang D. &#x00026; Xu D. DeepDom: Predicting protein domain boundary from sequence alone using stacked bidirectional LSTM. In BIOCOMPUTING 2019: Proceedings of the Pacific Symposium, pages 66&#x02013;75. World Scientific, 2018.</mixed-citation></ref><ref id="CR13"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mahmud</surname><given-names>S</given-names></name><name><surname>Guo</surname><given-names>Z</given-names></name><name><surname>Quadir</surname><given-names>F</given-names></name><name><surname>Liu</surname><given-names>J</given-names></name><name><surname>Cheng</surname><given-names>J</given-names></name></person-group><article-title>Multi-head attention-based U-nets for predicting protein domain boundaries using 1d sequence features and 2d distance maps</article-title><source>bioRxiv</source><year>2022</year><volume>23</volume><fpage>283</fpage></element-citation></ref><ref id="CR14"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>W</given-names></name><etal/></person-group><article-title>FUpred: detecting protein domains through deep-learning-based contact map prediction</article-title><source>Bioinformatics</source><year>2020</year><volume>36</volume><fpage>3749</fpage><lpage>3757</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btaa217</pub-id><?supplied-pmid 32227201?><pub-id pub-id-type="pmid">32227201</pub-id>
</element-citation></ref><ref id="CR15"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>K</given-names></name><name><surname>Su</surname><given-names>H</given-names></name><name><surname>Peng</surname><given-names>Z</given-names></name><name><surname>Yang</surname><given-names>J</given-names></name></person-group><article-title>A unified approach to protein domain parsing with interresidue distance matrix</article-title><source>Bioinformatics</source><year>2023</year><volume>39</volume><fpage>btad070</fpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btad070</pub-id><?supplied-pmid 36734597?><pub-id pub-id-type="pmid">36734597</pub-id>
</element-citation></ref><ref id="CR16"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Postic</surname><given-names>G</given-names></name><name><surname>Ghouzam</surname><given-names>Y</given-names></name><name><surname>Chebrek</surname><given-names>R</given-names></name><name><surname>Gelly</surname><given-names>J-C</given-names></name></person-group><article-title>An ambiguity principle for assigning protein structural domains</article-title><source>Sci. Adv.</source><year>2017</year><volume>3</volume><fpage>e1600552</fpage><pub-id pub-id-type="doi">10.1126/sciadv.1600552</pub-id><?supplied-pmid 28097215?><pub-id pub-id-type="pmid">28097215</pub-id>
</element-citation></ref><ref id="CR17"><label>17.</label><mixed-citation publication-type="other">Yu Z.-Z. et al. DomBpred: protein domain boundary prediction based on domain-residue clustering using inter-residue distance. IEEE/ACM Transactions on Computational Biology and Bioinformatics, pages 1&#x02013;1, 2022.</mixed-citation></ref><ref id="CR18"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Varadi</surname><given-names>M</given-names></name><etal/></person-group><article-title>AlphaFold protein structure database: massively expanding the structural coverage of protein-sequence space with high-accuracy models</article-title><source>Nucleic Acids Res.</source><year>2022</year><volume>50</volume><fpage>D439</fpage><lpage>D444</lpage><pub-id pub-id-type="doi">10.1093/nar/gkab1061</pub-id><?supplied-pmid 34791371?><pub-id pub-id-type="pmid">34791371</pub-id>
</element-citation></ref><ref id="CR19"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Schaeffer</surname><given-names>RD</given-names></name><name><surname>Durham</surname><given-names>J</given-names></name><name><surname>Cong</surname><given-names>Q</given-names></name><name><surname>Grishin</surname><given-names>NV</given-names></name></person-group><article-title>DPAM: A domain parser for alphafold models</article-title><source>Protein Sci.</source><year>2023</year><volume>32</volume><fpage>e4548</fpage><pub-id pub-id-type="doi">10.1002/pro.4548</pub-id><?supplied-pmid 36539305?><pub-id pub-id-type="pmid">36539305</pub-id>
</element-citation></ref><ref id="CR20"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jumper</surname><given-names>J</given-names></name><etal/></person-group><article-title>Highly accurate protein structure prediction with AlphaFold</article-title><source>Nature</source><year>2021</year><volume>596</volume><fpage>583</fpage><lpage>589</lpage><pub-id pub-id-type="doi">10.1038/s41586-021-03819-2</pub-id><?supplied-pmid 34265844?><pub-id pub-id-type="pmid">34265844</pub-id>
</element-citation></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="other">Hsu Y.-C., Xu Z., Kira Z. &#x00026; Huang J. Learning to cluster for proposal-free instance segmentation. arXiv preprint, arXiv:1803.06459, 2018.</mixed-citation></ref><ref id="CR22"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>W</given-names></name><name><surname>Deng</surname><given-names>S</given-names></name><name><surname>Chen</surname><given-names>C</given-names></name><name><surname>Fu</surname><given-names>X</given-names></name><name><surname>Xiong</surname><given-names>Z</given-names></name></person-group><article-title>Learning to model pixel-embedded affinity for homogeneous instance segmentation</article-title><source>Proc. AAAI Conf. Artif. Intell.</source><year>2022</year><volume>36</volume><fpage>1007</fpage><lpage>1015</lpage></element-citation></ref><ref id="CR23"><label>23.</label><mixed-citation publication-type="other">Jin L., Chen Z. &#x00026; Tu Z. Object detection free instance segmentation with labeling transformations. arXiv preprint, arXiv:1611.08991, (2016).</mixed-citation></ref><ref id="CR24"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eguchi</surname><given-names>RR</given-names></name><name><surname>Huang</surname><given-names>P-S</given-names></name></person-group><article-title>Multi-scale structural analysis of proteins by deep semantic segmentation</article-title><source>Bioinformatics</source><year>2020</year><volume>36</volume><fpage>1740</fpage><lpage>1749</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btz650</pub-id><?supplied-pmid 31424530?><pub-id pub-id-type="pmid">31424530</pub-id>
</element-citation></ref><ref id="CR25"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wheelan</surname><given-names>SJ</given-names></name><name><surname>Marchler-Bauer</surname><given-names>A</given-names></name><name><surname>Bryant</surname><given-names>SH</given-names></name></person-group><article-title>Domain size distributions can predict domain boundaries</article-title><source>Bioinformatics</source><year>2000</year><volume>16</volume><fpage>613</fpage><lpage>618</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/16.7.613</pub-id><?supplied-pmid 11038331?><pub-id pub-id-type="pmid">11038331</pub-id>
</element-citation></ref><ref id="CR26"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schaeffer</surname><given-names>RD</given-names></name><etal/></person-group><article-title>Classification of domains in predicted structures of the human proteome</article-title><source>Proc. Natl. Acad. Sci.</source><year>2023</year><volume>120</volume><fpage>e2214069120</fpage><pub-id pub-id-type="doi">10.1073/pnas.2214069120</pub-id><?supplied-pmid 36917664?><pub-id pub-id-type="pmid">36917664</pub-id>
</element-citation></ref><ref id="CR27"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name></person-group><article-title>How significant is a protein structure similarity with TM-score = 0.5?</article-title><source>Bioinformatics</source><year>2010</year><volume>26</volume><fpage>889</fpage><lpage>895</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btq066</pub-id><?supplied-pmid 20164152?><pub-id pub-id-type="pmid">20164152</pub-id>
</element-citation></ref><ref id="CR28"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tunyasuvunakool</surname><given-names>K</given-names></name><etal/></person-group><article-title>Highly accurate protein structure prediction for the human proteome</article-title><source>Nature</source><year>2021</year><volume>596</volume><fpage>590</fpage><lpage>596</lpage><pub-id pub-id-type="doi">10.1038/s41586-021-03828-1</pub-id><?supplied-pmid 34293799?><pub-id pub-id-type="pmid">34293799</pub-id>
</element-citation></ref><ref id="CR29"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taylor</surname><given-names>WR</given-names></name><name><surname>Orengo</surname><given-names>CA</given-names></name></person-group><article-title>Protein structure alignment</article-title><source>J. Mol. Biol.</source><year>1989</year><volume>208</volume><fpage>1</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.1016/0022-2836(89)90084-3</pub-id><?supplied-pmid 2769748?><pub-id pub-id-type="pmid">2769748</pub-id>
</element-citation></ref><ref id="CR30"><label>30.</label><mixed-citation publication-type="other">van Kempen M. et al. Fast and accurate protein structure search with Foldseek. Nature Biotechnology. 10.1038/s41587-023-01773-0 (2023).</mixed-citation></ref><ref id="CR31"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steinegger</surname><given-names>M</given-names></name><etal/></person-group><article-title>HH-suite3 for fast remote homology detection and deep protein annotation</article-title><source>BMC Bioinforma.</source><year>2019</year><volume>20</volume><fpage>1</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1186/s12859-019-3019-7</pub-id></element-citation></ref><ref id="CR32"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holm</surname><given-names>L</given-names></name></person-group><article-title>DALI and the persistence of protein shape.</article-title><source>Protein Sci.</source><year>2020</year><volume>29</volume><fpage>128</fpage><lpage>140</lpage><pub-id pub-id-type="doi">10.1002/pro.3749</pub-id><?supplied-pmid 31606894?><pub-id pub-id-type="pmid">31606894</pub-id>
</element-citation></ref><ref id="CR33"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mirdita</surname><given-names>M</given-names></name><etal/></person-group><article-title>UniClust databases of clustered and deeply annotated protein sequences and alignments.</article-title><source>Nucleic Acids Res.</source><year>2017</year><volume>45</volume><fpage>D170</fpage><lpage>D176</lpage><pub-id pub-id-type="doi">10.1093/nar/gkw1081</pub-id><?supplied-pmid 27899574?><pub-id pub-id-type="pmid">27899574</pub-id>
</element-citation></ref><ref id="CR34"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berman</surname><given-names>HM</given-names></name><etal/></person-group><article-title>The protein data bank</article-title><source>Nucleic Acids Res.</source><year>2000</year><volume>28</volume><fpage>235</fpage><lpage>242</lpage><pub-id pub-id-type="doi">10.1093/nar/28.1.235</pub-id><?supplied-pmid 10592235?><pub-id pub-id-type="pmid">10592235</pub-id>
</element-citation></ref><ref id="CR35"><label>35.</label><mixed-citation publication-type="other">Greener, J. G. &#x00026; Jamali, K. Fast protein structure searching using structure graph embeddings. bioRxiv, 2022.</mixed-citation></ref><ref id="CR36"><label>36.</label><mixed-citation publication-type="other">Lin, Z. et al. Evolutionary scale prediction of atomic level protein structure with a language model. <italic>Science</italic><bold>79</bold>, 1123&#x02013;1130 (2023).</mixed-citation></ref><ref id="CR37"><label>37.</label><mixed-citation publication-type="other">Wu, R. et al. High-resolution de novo structure prediction from primary sequence. bioRxiv (2022).</mixed-citation></ref><ref id="CR38"><label>38.</label><mixed-citation publication-type="other">Weissenow, K., Heinzinger M., Steinegger, M., &#x00026; Rost, B. Ultra-fast protein structure prediction to capture effects of sequence variation in mutation movies. bioRxiv, pages 2022&#x02013;11, 2022.</mixed-citation></ref><ref id="CR39"><label>39.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>W</given-names></name><name><surname>Jaroszewski</surname><given-names>L</given-names></name><name><surname>Godzik</surname><given-names>A</given-names></name></person-group><article-title>Clustering of highly homologous sequences to reduce the size of large protein databases</article-title><source>Bioinformatics</source><year>2001</year><volume>17</volume><fpage>282</fpage><lpage>283</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/17.3.282</pub-id><?supplied-pmid 11294794?><pub-id pub-id-type="pmid">11294794</pub-id>
</element-citation></ref><ref id="CR40"><label>40.</label><mixed-citation publication-type="other">Ahdritz, G. et al. OpenFold: Retraining AlphaFold2 yields new insights into its learning mechanisms and capacity for generalization. bioRxiv, pages 2022&#x02013;11, (2022).</mixed-citation></ref><ref id="CR41"><label>41.</label><mixed-citation publication-type="other">Su, J., et al. RoFormer: Enhanced transformer with rotary position embedding. arXiv preprint arXiv:2104.09864, (2021).</mixed-citation></ref><ref id="CR42"><label>42.</label><mixed-citation publication-type="other">Strudel, R., Garcia, R., Laptev, I., &#x00026; Schmid, C. Segmenter: Transformer for semantic segmentation. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 7262&#x02013; 7272, 2021.</mixed-citation></ref><ref id="CR43"><label>43.</label><mixed-citation publication-type="other">Press, O., Smith, N. A., &#x00026; Lewis, M. Train short, test long: Attention with linear biases enables input length extrapolation. arXiv preprint arXiv:2108.12409, 2021.</mixed-citation></ref></ref-list></back></article>