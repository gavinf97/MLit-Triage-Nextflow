<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Genomics</journal-id><journal-id journal-id-type="iso-abbrev">BMC Genomics</journal-id><journal-title-group><journal-title>BMC Genomics</journal-title></journal-title-group><issn pub-type="epub">1471-2164</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">5930664</article-id><article-id pub-id-type="pmid">29720103</article-id><article-id pub-id-type="publisher-id">4665</article-id><article-id pub-id-type="doi">10.1186/s12864-018-4665-2</article-id><article-categories><subj-group subj-group-type="heading"><subject>Methodology Article</subject></subj-group></article-categories><title-group><article-title>Prediction of plant lncRNA by ensemble machine learning classifiers</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Simopoulos</surname><given-names>Caitlin M. A.</given-names></name><address><email>simopocm@mcmaster.ca</email></address><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author"><name><surname>Weretilnyk</surname><given-names>Elizabeth A.</given-names></name><address><email>weretil@mcmaster.ca</email></address><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Golding</surname><given-names>G. Brian</given-names></name><address><email>golding@mcmaster.ca</email></address><xref ref-type="aff" rid="Aff1"/></contrib><aff id="Aff1"><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1936 8227</institution-id><institution-id institution-id-type="GRID">grid.25073.33</institution-id><institution>Department of Biology, </institution><institution>McMaster University, </institution></institution-wrap>1280 Main Street West, Hamilton, Canada </aff></contrib-group><pub-date pub-type="epub"><day>2</day><month>5</month><year>2018</year></pub-date><pub-date pub-type="pmc-release"><day>2</day><month>5</month><year>2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>19</volume><elocation-id>316</elocation-id><history><date date-type="received"><day>23</day><month>11</month><year>2017</year></date><date date-type="accepted"><day>12</day><month>4</month><year>2018</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2018</copyright-statement><license license-type="OpenAccess"><license-p><bold>Open Access</bold> This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p></license></permissions><abstract id="Abs1"><sec><title>Background</title><p>In plants, long non-protein coding RNAs are believed to have essential roles in development and stress responses. However, relative to advances on discerning biological roles for long non-protein coding RNAs in animal systems, this RNA class in plants is largely understudied. With comparatively few validated plant long non-coding RNAs, research on this potentially critical class of RNA is hindered by a lack of appropriate prediction tools and databases. Supervised learning models trained on data sets of mostly non-validated, non-coding transcripts have been previously used to identify this enigmatic RNA class with applications largely focused on animal systems. Our approach uses a training set comprised only of empirically validated long non-protein coding RNAs from plant, animal, and viral sources to predict and rank candidate long non-protein coding gene products for future functional validation.</p></sec><sec><title>Results</title><p>Individual stochastic gradient boosting and random forest classifiers trained on only empirically validated long non-protein coding RNAs were constructed. In order to use the strengths of multiple classifiers, we combined multiple models into a single stacking meta-learner. This ensemble approach benefits from the diversity of several learners to effectively identify putative plant long non-coding RNAs from transcript sequence features. When the predicted genes identified by the ensemble classifier were compared to those listed in GreeNC, an established plant long non-coding RNA database, overlap for predicted genes from <italic>Arabidopsis thaliana</italic>, <italic>Oryza sativa</italic> and <italic>Eutrema salsugineum</italic> ranged from 51 to 83% with the highest agreement in <italic>Eutrema salsugineum</italic>. Most of the highest ranking predictions from <italic>Arabidopsis thaliana</italic> were annotated as potential natural antisense genes, pseudogenes, transposable elements, or simply computationally predicted hypothetical protein. Due to the nature of this tool, the model can be updated as new long non-protein coding transcripts are identified and functionally verified.</p></sec><sec><title>Conclusions</title><p>This ensemble classifier is an accurate tool that can be used to rank long non-protein coding RNA predictions for use in conjunction with gene expression studies. Selection of plant transcripts with a high potential for regulatory roles as long non-protein coding RNAs will advance research in the elucidation of long non-protein coding RNA function.</p></sec><sec><title>Electronic supplementary material</title><p>The online version of this article (10.1186/s12864-018-4665-2) contains supplementary material, which is available to authorized users.</p></sec></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>lncRNA</kwd><kwd>Classifier</kwd><kwd>Machine learning</kwd><kwd>Ensemble</kwd><kwd>Transcript</kwd></kwd-group><funding-group><award-group><funding-source><institution>Natural Sciences and Engineering Research Council of Canada</institution></funding-source><award-id>RGPIN-2015-04477</award-id></award-group></funding-group><funding-group><award-group><funding-source><institution>Ontario Research Fund-Research Excellence</institution></funding-source><award-id>RGPIN-2015-06530</award-id></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; The Author(s) 2018</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Background</title><p>Long non-protein coding RNAs (lncRNAs) represent a diverse and functionally important class of RNAs [<xref ref-type="bibr" rid="CR1">1</xref>], and have been classically defined as transcripts longer than 200 nucleotides with little protein-coding potential [<xref ref-type="bibr" rid="CR2">2</xref>]. Previously thought to be transcriptional noise, there is now evidence of their involvement in the development, disease, and stress responses of plants [<xref ref-type="bibr" rid="CR3">3</xref>, <xref ref-type="bibr" rid="CR4">4</xref>]; however, these transcripts are also found throughout all kingdoms of life. LncRNA transcripts often lack sequence conservation within close relatives, and the evolution of these transcripts remains poorly understood, but there exists growing evidence of positional and structural conservation that may indicate selection on transcript function [<xref ref-type="bibr" rid="CR5">5</xref>].</p><p>Unlike other non-coding RNAs, the mechanisms and functions of lncRNAs can range wildly &#x02013; from epigenetic regulation, as exemplified by mouse <italic>Xist</italic> and human <italic>XIST</italic> [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR7">7</xref>], to small RNA target mimics, as seen with <italic>IPS1</italic> and <italic>ath-miR399</italic> in <italic>Arabidopsis thaliana</italic> [<xref ref-type="bibr" rid="CR8">8</xref>]. <italic>COLDAIR</italic>, a lncRNA associated with flowering, functions by remodeling chromatin and alters expression of the <italic>FLC</italic> locus [<xref ref-type="bibr" rid="CR9">9</xref>]. A recent review by Ma et al. [<xref ref-type="bibr" rid="CR10">10</xref>] suggests that most known lncRNAs regulate transcription, both in <italic>cis</italic> and <italic>trans</italic>, while others can affect translation, splicing, post-translational regulation or are classified as &#x0201c;other functional mechanisms.&#x0201d; Due to such a wide range of functionality, lncRNAs are typically classified by their position to protein coding genes as intergenic (also referred to as lincRNAs), natural antisense, or intronic [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR10">10</xref>].</p><p>Notably, lncRNAs can not only be functional in their long RNA form, but also act as small RNA precursors and sources of small regulatory peptides [<xref ref-type="bibr" rid="CR11">11</xref>&#x02013;<xref ref-type="bibr" rid="CR13">13</xref>] although extensive translation of lncRNAs has been disputed [<xref ref-type="bibr" rid="CR14">14</xref>]. Adding to the complexity of these RNAs, some transcripts do not meet the arbitrary length cutoffs set by the classical definition for lncRNAs, such as <italic>BC1</italic> in mice (152nt) [<xref ref-type="bibr" rid="CR15">15</xref>]. Even with recent developments in sequencing technologies, lncRNAs remain difficult to identify due to low, and condition-dependent and tissue-dependent expression levels [<xref ref-type="bibr" rid="CR16">16</xref>]. Demonstrating minimal homology with close relatives [<xref ref-type="bibr" rid="CR5">5</xref>], current research suggests these transcripts undergo fast and unclear evolution making functional predictions challenging. This lack of distinct rules for predicting and identifying lncRNAs is a likely contributor to the lack of validated plant lncRNAs.</p><p>Currently, many lncRNA prediction softwares that are available to researchers, such as PLEK [<xref ref-type="bibr" rid="CR17">17</xref>], lncRScan-SVM [<xref ref-type="bibr" rid="CR18">18</xref>], and COME [<xref ref-type="bibr" rid="CR19">19</xref>], use machine learning methods trained on data consisting of lncRNA transcripts yet to be empirically validated. Without empirical validation, many of these predicted lncRNA transcripts could have no regulatory function and could be produced due to spurious transcription because of the low fidelity of RNApolII [<xref ref-type="bibr" rid="CR20">20</xref>]. In addition, CPAT [<xref ref-type="bibr" rid="CR21">21</xref>] and CPC2 [<xref ref-type="bibr" rid="CR22">22</xref>] are popular softwares used to identify non-coding transcripts. These softwares are successful at quickly predicting the protein-coding potential of mRNA sequences, but are not specific to lncRNAs and are unsuitable for identifying those lncRNAs that may code for small peptides. Additionally, since the majority of lncRNA research is on animals, software packages for lncRNAs prediction often use only animal training datasets. While the exact functions of most plant and animal lncRNAs remain poorly understood, there are known differences in biogenesis and mechanisms of other non-coding RNAs, such as miRNAs [<xref ref-type="bibr" rid="CR23">23</xref>]. As such, ignoring the few plant lncRNA transcripts with known function could hinder the potential of future plant lncRNA predictors.</p><p>Depending on the source, lncRNA databases can also fall victim to biases toward animal systems and non-validated transcripts as they are often model organism specific with a preference for humans, and rarely differentiate between validated and predicted lncRNA transcripts. These biases can be seen in the popular lncRNA databases, LNCipedia and NONCODE [<xref ref-type="bibr" rid="CR24">24</xref>, <xref ref-type="bibr" rid="CR25">25</xref>].</p><p>Outputs from lncRNA software often result in thousands of unranked predictions leaving the researcher to choose the most likely candidates for empirical validation. In combination with an RNASeq experiment that can result in tens of thousands of transcripts, filtering through thousands of lncRNA predictions can be difficult and time consuming for a researcher. Objectively ranking predictions in combination with gene expression estimates can help researchers complete functional validation of lncRNAs more efficiently.</p><p>Recently, ensemble methods have become popular for approaching difficult biological problems typically solved by machine learning [<xref ref-type="bibr" rid="CR26">26</xref>, <xref ref-type="bibr" rid="CR27">27</xref>]. Ensemble models work by combining multiple learners into a single model which helps to avoid over fitting and encourages generalization of the classifier. In addition to improved classification, ensemble methods also remove the difficulty in choosing the &#x0201c;best&#x0201d; model as all models can be used in a single classifier. Each individual classifier used in the construction of the overall ensemble model will have its own classification strengths, resulting in stronger and more accurate predictions when these classifiers are used in combination.</p><p>Here we describe a lncRNA predictor constructed using an ensemble of machine learning models developed for and tested on plant transcript sequences. We compared accuracy of this meta-learner trained on multiple machine learning models to the prediction ability of individual random forest and gradient boosting models making up the meta-learner. All models were trained on empirically validated lncRNAs to ensure only true lncRNA transcripts were used in each model&#x02019;s training sets. We found the most successful method to be a stacking meta-learner constructed from eight stochastic gradient boosting models. This approach offers multiple advantages over those currently available as this machine learning approach prevents predictions from being constrained to the arbitrary classic definitions of lncRNAs, such as ignoring transcripts with high coding potential of small open reading frames (ORFs). In addition, our method numerically scores each prediction to help researchers focus their validation efforts on highly ranked lncRNA predictions. Finally, this approach uses the Diamond algorithm [<xref ref-type="bibr" rid="CR28">28</xref>] that allows for efficient and fast sequence alignment in protein databases, an essential feature for lncRNA prediction.</p></sec><sec id="Sec2"><title>Methods</title><sec id="Sec3"><title>Overview of classifiers</title><p>Multiple machine learning approaches to lncRNA prediction were compared to find the most accurate plant transcript classifier. Ensemble approaches were chosen due to the diversity of RNAs in the lncRNA category as these approaches are ideal for heterogeneous data. Ensemble models typically follow three main approaches: bagging, boosting, and stacking. Bagging (<bold>b</bold>ootstrap <bold>agg</bold>regat<bold>ing</bold>) relies on creating <italic>n</italic> models on bootstrapped training data, and averages predictions of all models for a final group prediction. This protocol is used in the random forest method. With boosting, such as in gradient boosting, one iteratively trains <italic>n</italic> learners, with each iteration attempting to reduce prediction error. The predictions are summed for a final classification. Finally, a stacking generalizer refers to training a new learner, for example by logistic regression, on the output of multiple learners. This is commonly referred to as meta-learner.</p><p>This study used all three approaches to ensemble methods, firstly by evaluating the lncRNA prediction accuracy of individual stochastic gradient boosting and random forest models. These individual models were then also combined into four ensemble classifiers explained further in the proceeding sections: 1. Arithmetic mean of scores, 2. Geometric mean of scores, 3. Majority vote, 4. Logistic regression meta-learner, and were evaluated similarly.</p></sec><sec id="Sec4"><title>Individual stochastic gradient boosting and random forest models</title><sec id="Sec5"><title>Data</title><p>Positive data remained constant in each training set and consisted of a total of 436 unique, validated lncRNA sequences downloaded from two separate lncRNA databases: 1. lncRNAdb v2.0 (<ext-link ext-link-type="uri" xlink:href="http://lncrnadb.org">http://lncrnadb.org</ext-link>) on November 25, 2016 and 2. lncRNAdisease (<ext-link ext-link-type="uri" xlink:href="http://www.cuilab.cn/lncrnadisease">http://www.cuilab.cn/lncrnadisease</ext-link>) on February 15, 2017. These sources for lncRNA sequences include all available validated lncRNAs, but are heavily populated by animal systems and include only six plant lncRNA sequences.</p><p>Negative data for each training set consisted of sequences from four different species: <italic>Homo sapiens</italic>, <italic>A. thaliana</italic>, <italic>Mus musculus</italic>, and <italic>Oryza sativa</italic>. <italic>H. sapiens</italic> and <italic>M. musculus</italic> sequences were included in the negative data of the training set as these species are the source for the majority of validated lncRNAs. <italic>H. sapiens</italic> sequences were downloaded from Ensembl (<ext-link ext-link-type="uri" xlink:href="http://www.ensembl.org">http://www.ensembl.org</ext-link>) on December 19, 2016, <italic>A. thaliana</italic> from Araport v11 (<ext-link ext-link-type="uri" xlink:href="https://araport-dev.tacc.utexas.edu">https://araport-dev.tacc.utexas.edu</ext-link>) on December 16, 2016, <italic>M. musculus</italic> from Ensembl on March 28, 2017 and <italic>O. sativa</italic> from Ensembl on March 28, 2017. These data are made available in Additional file&#x000a0;<xref rid="MOESM2" ref-type="media">2</xref>. To ensure that lncRNA, tRNAs, and rRNAs were removed from the negative training data, these types of sequences were downloaded from RNAcentral v6 (<ext-link ext-link-type="uri" xlink:href="http://rnacentral.org">http://rnacentral.org</ext-link>) on March 28, 2017, using search terms available in Additional file&#x000a0;<xref rid="MOESM1" ref-type="media">1</xref> and were then removed from the dataset. Eight different training sets with different combinations of negative data from multiple species were used to construct eight different models and are described in Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>. Sets denoted &#x0201c;A&#x0201d; and &#x0201c;B&#x0201d; remained constant throughout the training sets and were randomly chosen from the transcript sequences of each species. These training datasets were used in both random forest and gradient boosting methods, for a total of 16 preliminary models. The variety of training datasets was used to maximize model diversity, a requirement for the proceeding ensemble models.
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Negative training data sets in individual models, and corresponding accuracy, sensitivity, specificity and AUC values</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Training dataset</th><th align="left">Negative data</th><th align="left" colspan="2">AUC</th><th align="left" colspan="2">Accuracy</th><th align="left" colspan="2">Specificity</th><th align="left" colspan="2">Sensitivity</th></tr></thead><tbody><tr><td align="left"/><td align="left"/><td align="left">GB</td><td align="left">RF</td><td align="left">GB</td><td align="left">RF</td><td align="left">GB</td><td align="left">RF</td><td align="left">GB</td><td align="left">RF</td></tr><tr><td align="left">1</td><td align="left">3000 <italic>H. sapiens</italic> (set A)</td><td align="left">0.940</td><td align="left">0.943</td><td align="left">0.962</td><td align="left">0.956</td><td align="left">0.988</td><td align="left">0.990</td><td align="left">0.548</td><td align="left">0.404</td></tr><tr><td align="left"/><td align="left">1000 <italic>M. musculus</italic> (set A)</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left"/><td align="left">3000 <italic>O. sativa</italic> (set A)</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">2</td><td align="left">3000 <italic>H. sapiens</italic> (set A)</td><td align="left">0.943</td><td align="left">0.944</td><td align="left">0.960</td><td align="left">0.953</td><td align="left">0.988</td><td align="left">0.989</td><td align="left">0.576</td><td align="left">0.461</td></tr><tr><td align="left"/><td align="left">3000 <italic>O. sativa</italic> (set A)</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">3</td><td align="left">3000 <italic>H. sapiens</italic> (set A)</td><td align="left">0.961</td><td align="left">0.962</td><td align="left">0.973</td><td align="left">0.970</td><td align="left">0.990</td><td align="left">0.992</td><td align="left">0.693</td><td align="left">0.592</td></tr><tr><td align="left"/><td align="left">1000 <italic>M. musculus</italic> (set A)</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left"/><td align="left">3000 <italic>A. thaliana</italic> (set A)</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">4</td><td align="left">3000 <italic>H. sapiens</italic> (set A)</td><td align="left">0.962</td><td align="left">0.966</td><td align="left">0.972</td><td align="left">0.967</td><td align="left">0.990</td><td align="left">0.990</td><td align="left">0.725</td><td align="left">0.640</td></tr><tr><td align="left"/><td align="left">3000 <italic>A. thaliana</italic> (set A)</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">5</td><td align="left">3000 <italic>H. sapiens</italic> (set B)</td><td align="left">0.955</td><td align="left">0.959</td><td align="left">0.965</td><td align="left">0.958</td><td align="left">0.991</td><td align="left">0.980</td><td align="left">0.608</td><td align="left">0.530</td></tr><tr><td align="left"/><td align="left">3000 <italic>A. thaliana</italic> (set B)</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">6</td><td align="left">4500 <italic>H. sapiens</italic> (set A + 1500 seq)</td><td align="left">0.961</td><td align="left">0.967</td><td align="left">0.979</td><td align="left">0.979</td><td align="left">0.995</td><td align="left">0.995</td><td align="left">0.633</td><td align="left">0.571</td></tr><tr><td align="left"/><td align="left">4500 <italic>A. thaliana</italic> (set A + 1500 seq)</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">7</td><td align="left">3000 <italic>H. sapiens</italic> (set A)</td><td align="left">0.963</td><td align="left">0.967</td><td align="left">0.976</td><td align="left">0.971</td><td align="left">0.993</td><td align="left">0.992</td><td align="left">0.700</td><td align="left">0.603</td></tr><tr><td align="left"/><td align="left">4500 <italic>A. thaliana</italic> (set A + 1500 seq)</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">8</td><td align="left">2000 <italic>H. sapiens</italic> (2000 from set A)</td><td align="left">0.964</td><td align="left">0.965</td><td align="left">0.968</td><td align="left">0.965</td><td align="left">0.988</td><td align="left">0.990</td><td align="left">0.695</td><td align="left">0.619</td></tr><tr><td align="left"/><td align="left">1000 <italic>M. musculus</italic> (set A)</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left"/><td align="left">3000 <italic>A. thaliana</italic> (set A)</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr></tbody></table><table-wrap-foot><p>Training datasets of random forest (RF) and gradient boosting (GB) individual models are described. The positive training dataset, 436 validated lncRNAs, remained constant throughout all training datasets. Specificity, sensitivity, accuracy and AUC values were found using 10-fold cross validation of all training data</p></table-wrap-foot></table-wrap></p></sec><sec id="Sec6"><title>Feature extraction and selection</title><p>Eleven features were chosen for use in model construction: 
<list list-type="order"><list-item><p>mRNA length</p></list-item><list-item><p>ORF length</p></list-item><list-item><p>GC%</p></list-item><list-item><p>Fickett score</p></list-item><list-item><p>hexamer score</p></list-item><list-item><p>alignment identity in SwissProt database</p></list-item><list-item><p>length of alignment in SwissProt database</p></list-item><list-item><p>proportion of alignment length and mRNA length (alignment length:mRNA length)</p></list-item><list-item><p>proportion of alignment length and ORF length (alignment length:ORF)</p></list-item><list-item><p>presence of transposable element</p></list-item><list-item><p>sequence percent divergence from transposable element</p></list-item></list></p><p>Features were extracted using a combination of custom Python scripts and known software (CPAT [<xref ref-type="bibr" rid="CR21">21</xref>] used for features 4 and 5, Diamond [<xref ref-type="bibr" rid="CR28">28</xref>] used for features 6, 7, 8, 9, RepeatMasker [<xref ref-type="bibr" rid="CR29">29</xref>] used for features 10 and 11).</p><sec id="Sec7"><title>CPAT model creation and application</title><p>As no publicly available plant CPAT model exists, two logit models were built using coding and non-protein coding RNA sequences from <italic>A. thaliana</italic> and <italic>O. sativa</italic>. Non-coding lncRNA, miRNA, snRNA, and snoRNA sequences from each species were downloaded from the Plant Non-coding RNA Database on September 26, 2016 (<italic>A. thaliana</italic>, 5062 sequences total) and July 14, 2017 (<italic>O. sativa</italic>, 4718 sequences total) [<xref ref-type="bibr" rid="CR30">30</xref>]. Protein coding transcript sequences from each species were downloaded from Phytozome v11 [<xref ref-type="bibr" rid="CR31">31</xref>] on August 3, 2016. In order to supply a balanced training set, 5938 <italic>A. thaliana</italic> and 5283 <italic>O. sativa</italic> protein coding sequences were randomly selected for a total of 11,000 <italic>A. thaliana</italic> transcripts and 10,000 <italic>O. sativa</italic> transcripts for CPAT model construction.</p><p><italic>A. thaliana</italic> CPAT models were used for predictions in all species but <italic>A. thaliana</italic> itself, which used <italic>O. sativa</italic> CPAT models. Fickett and hexamer values from CPAT results were used as features in machine learning model construction.</p></sec><sec id="Sec8"><title>Diamond alignment in SwissProt database</title><p>Diamond v0.8.34 [<xref ref-type="bibr" rid="CR28">28</xref>] was used to quantify transcript sequence alignments to curated protein sequences in the SwissProt database [<xref ref-type="bibr" rid="CR32">32</xref>] downloaded February 1, 2017 from <ext-link ext-link-type="uri" xlink:href="http://www.uniprot.org/downloads">http://www.uniprot.org/downloads</ext-link>. We ran Diamond in &#x0201c;more-sensitive&#x0201d; mode as we aligned full transcript sequences to the SwissProt database rather than RNASeq reads. Options for each Diamond run were as follows: -e 0.001, -k 5, &#x02013;matrix BLOSUM62, &#x02013;gapopen 11, &#x02013;gapextend: 1, -f 6 qseqid pident length qframe qstart qend sstart send evalue bitscore.</p></sec><sec id="Sec9"><title>RepeatMasker</title><p>RepeatMasker [<xref ref-type="bibr" rid="CR29">29</xref>] was used to extract information on transcription element related features. The software was run on transcript sequences using default settings, and with -species set to Eukaryota.</p></sec></sec><sec id="Sec10"><title>Stochastic gradient boosting and random forest model construction and hyper-parameter selection</title><p>Once features were extracted, models were constructed using Python&#x02019;s scikit-learn package [<xref ref-type="bibr" rid="CR33">33</xref>]. Eight separate models were constructed using both gradient boosting and random forest approaches, for a total of 16 models differing in negative training data or machine learning algorithm (Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>). All transposable element related features were removed after performing recursive feature elimination as they were found to be uninformative and reduced the accuracy of models. With the 9 remaining features, a nested 4-fold cross-validation grid search was performed for 30 trials in gradient boosting hyper-parameter selection with possible hyper-parameters: 
<list list-type="bullet"><list-item><p>learning_rate: 0.02, 0.04, 0.06, 0.08, 0.1</p></list-item><list-item><p>max_depth: 4, 6, 8, 10</p></list-item><list-item><p>subsample: 0.2, 0.4, 0.6, 0.8, 1</p></list-item><list-item><p>n_estimators: 100, 500, 1000</p></list-item></list></p><p>Random forest hyper-parameters remained constant through all models with the only change from default parameters being n_estimators = 5000 and min_samples_leaf = 20.</p><p>Models were evaluated by sensitivity, specificity, accuracy area under the curve (AUC) values using 10-fold cross validation and the caret R package [<xref ref-type="bibr" rid="CR34">34</xref>].</p></sec></sec><sec id="Sec11"><title>Ensemble learner construction</title><p>As gradient boosting and random forest models 1-8 were trained using eight different negative training sets, 3000 randomly selected <italic>Zea mays</italic> protein coding sequences were used as negative data in the construction and/or testing of each ensemble model for consistency through models. <italic>Z. mays</italic> was chosen as no training set contained sequences from this species and the genome is well annotated. <italic>Z. mays</italic> transcripts were downloaded from EnsemblPlants on April 27, 2017. Two separate values were used for the creation of each ensemble model &#x02013; scores <italic>s</italic><sub><italic>ij</italic></sub> and predictions <italic>p</italic><sub><italic>ij</italic></sub> where <italic>i</italic> represents model number and <italic>j</italic> transcript. Scores can take any number between 0 and 1, while predictions are binary and indicate if the transcript was or was not predicted as a lncRNA. A score greater than or equal to 0.5 would indicate the transcript is predicted as a lncRNA and would have a prediction value of 1. Ensemble models were constructed for random forest and gradient boosting models separately in order to avoid potential correlation of predictions. The four ensemble approaches included both algebraic combiners and voting methods as non-trainable methods, and a stacking generalizer as a meta-learner.</p><p>The four ensemble methods are described as follows and are illustrated in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>:
<fig id="Fig1"><label>Fig. 1</label><caption><p>Illustration of ensemble methods. An illustrative example of all four ensemble methods: arithmetic mean, geometric mean, majority vote and the stacking generalizer. Real examples from three different genes are given: gene A represents AT5G44470 a predicted protein, gene B represents At43G09922.1 <italic>IPS1</italic> a known lncRNA, and gene C represents At2G18130.1 a known protein coding gene, <italic>AtPAP11</italic>. Note the final stacking generalizer score of gene B compared to the individual model scores for the gene</p></caption><graphic xlink:href="12864_2018_4665_Fig1_HTML" id="MO1"/></fig>
<list list-type="order"><list-item><p>
<bold>Arithmetic Mean</bold>
<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ \frac{1}{n}\sum\limits_{i=1}^{n}s_{ij}  $$ \end{document}</tex-math><mml:math id="M2"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ij</mml:mtext></mml:mrow></mml:msub></mml:math><graphic xlink:href="12864_2018_4665_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>
</p><p>Where <italic>n</italic>=8, the number of individual models combined into the ensemble approach. The ensemble decision is made from taking the arithmetic mean of each score <italic>s</italic><sub><italic>ij</italic></sub> from models 1-8 for each gene <italic>j</italic>. The arithmetic mean of scores will act as a new ensemble score, and prediction will be made as described previously.</p></list-item><list-item><p>
<bold>Geometric mean</bold>
<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ \left(\prod\limits_{i=1}^{n}s_{ij}\right)^{\frac{1}{n}}  $$ \end{document}</tex-math><mml:math id="M4"><mml:msup><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>&#x0220f;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ij</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:math><graphic xlink:href="12864_2018_4665_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>
</p><p>Where <italic>n</italic>=8, the number of individual models combined into the ensemble approach. The ensemble decision is made from taking the geometric mean for each score <italic>s</italic><sub><italic>ij</italic></sub> from models 1-8 for each gene <italic>j</italic>. The geometric mean of scores will act as a new ensemble score, and prediction will be made as described previously.</p></list-item><list-item><p>
<bold>Majority vote</bold>
<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ \frac{1}{n}\sum\limits_{i=1}^{n}p_{ij}  $$ \end{document}</tex-math><mml:math id="M6"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ij</mml:mtext></mml:mrow></mml:msub></mml:math><graphic xlink:href="12864_2018_4665_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>
</p><p>Where <italic>n</italic>=8, the number of individual models combined into the ensemble approach. The ensemble decision depends only on final predictions and is decided on which label (0 or 1) receives the largest vote. The final prediction is made depending on the value of the majority vote score.</p></list-item><list-item><p>
<bold>Logistic regression</bold>
</p><p>This meta learner is trained on a training dataset of 3000 known <italic>Z. mays</italic> protein coding sequences as negative data and the 10-fold cross validation prediction outputs of known lncRNAs as positive data.</p></list-item></list></p><p>Voting, arithmetic mean, and geometric mean ensemble models were evaluated by directly comparing scores of predictions to the known outcomes of validated lncRNAs and 3000 <italic>Z. mays</italic> protein coding sequences. The logistic regression stacking generalizer was evaluated by 10-fold cross validation. Accuracy, sensitivity, specificity, Matthews correlation coefficient (MCC), and AUC values were calculated using a custom R script and the R package caret [<xref ref-type="bibr" rid="CR34">34</xref>].</p></sec><sec id="Sec12"><title>Comparison of predicted lncRNAs to GreeNC and annotation exploration</title><p>Transcript sequences of <italic>O. sativa</italic> and <italic>Eutrema salsugineum</italic> were downloaded from Phytozome v10.3 and <italic>A. thaliana</italic> from TAIR10 for direct comparison to GreeNC. LncRNAs predictions by GreeNC of <italic>A. thaliana</italic>, <italic>O. sativa</italic> and <italic>E. salsugineum</italic> were downloaded on June 19, 2017. Annotations from each species were downloaded from Phytozome v12, with extra <italic>A. thaliana</italic> annotation downloaded from Araport v11.</p></sec></sec><sec id="Sec13" sec-type="results"><title>Results</title><sec id="Sec14"><title>Individual random forest and stochastic gradient boosting model construction</title><sec id="Sec15"><title>Feature selection</title><p>Researchers have proposed that specific characters in transcript sequences can be useful in lncRNA classification. For example, lncRNAs can be translated into short peptides [<xref ref-type="bibr" rid="CR11">11</xref>&#x02013;<xref ref-type="bibr" rid="CR13">13</xref>], however most validated lncRNAs remain functional in their RNA form with little protein coding potential. The potential for a transcript to be translated into a protein can be predicted by codon bias, often measured by Fickett score, and hexamer usage bias [<xref ref-type="bibr" rid="CR21">21</xref>]. Mammalian lncRNAs are known to have a lower GC content than protein-coding RNAs [<xref ref-type="bibr" rid="CR35">35</xref>], and this feature has been used as a defining feature for <italic>A. thaliana</italic> lncRNA prediction in the past [<xref ref-type="bibr" rid="CR36">36</xref>]. Transposable elements (TEs) are also known to be sources for plant lncRNAs [<xref ref-type="bibr" rid="CR3">3</xref>]. Based on these studies, 11 features were originally chosen for use in lncRNA classification: mRNA length, ORF length, GC%, Fickett score, hexamer score, alignment identity in SwissProt database, length of alignment in SwissProt database, proportion of alignment length and mRNA length (alignment length:mRNA length), proportion of alignment length and ORF length (alignment length:ORF), presence of transposable element, and sequence percent divergence from transposable element. Using recursive feature elimination as described in the &#x0201c;<xref rid="Sec2" ref-type="sec">Methods</xref>&#x0201d; section, features that related to transposable elements were removed since inclusion of these features in classifiers decreased prediction accuracy and thus were deemed uninformative for this training data. After feature elimination, nine features were chosen for implementation in individual random forest and gradient boosting models: mRNA length, ORF length, GC%, Fickett score, hexamer score, alignment identity, length of alignment, alignment length:mRNA length, and alignment length:ORF.</p></sec><sec id="Sec16"><title>Individual model configuration and model evaluation</title><p>Gradient boosting and random forest models were constructed using eight different negative training datasets for a total of sixteen models (Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>). Empirically validated lncRNA transcripts were downloaded from databases as described in &#x0201c;<xref rid="Sec2" ref-type="sec">Methods</xref>&#x0201d; section. To ensure optimal performance of each gradient boosting classifier, proper calibration of multiple hyper-parameters is required. As such, hyper-parameter tuning (learning_rate, max_depth, subsample, and n_estimators) for each gradient boosting model was completed by grid search and 30 iterations of 4-fold nested cross validation with results summarized in Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>. All random forest models were constructed with the same hyper-parameters; all options were left as default other than n_estimators=5000 and min_samples_leaf = 20.
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Gradient boosting hyper-parameters chosen by grid search for each model</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">GB Model #</th><th align="left">Learning rate</th><th align="left">Maxdepth</th><th align="left">Subsample</th><th align="left">n estimators</th></tr></thead><tbody><tr><td align="left">1</td><td align="left">0.04</td><td align="left">10</td><td align="left">0.6</td><td align="left">100</td></tr><tr><td align="left">2</td><td align="left">0.04</td><td align="left">10</td><td align="left">0.6</td><td align="left">100</td></tr><tr><td align="left">3</td><td align="left">0.04</td><td align="left">10</td><td align="left">0.6</td><td align="left">100</td></tr><tr><td align="left">4</td><td align="left">0.02</td><td align="left">8</td><td align="left">0.6</td><td align="left">100</td></tr><tr><td align="left">5</td><td align="left">0.02</td><td align="left">10</td><td align="left">0.6</td><td align="left">100</td></tr><tr><td align="left">6</td><td align="left">0.02</td><td align="left">10</td><td align="left">0.6</td><td align="left">100</td></tr><tr><td align="left">7</td><td align="left">0.04</td><td align="left">10</td><td align="left">0.6</td><td align="left">100</td></tr><tr><td align="left">8</td><td align="left">0.04</td><td align="left">10</td><td align="left">0.6</td><td align="left">100</td></tr></tbody></table><table-wrap-foot><p>Hyper-parameters were chosen by grid search using 30 iterations of 4-fold nested cross validation. The given hyper-parameters corresponded to models with the highest accuracy values of all given hyper-parameter combinations</p></table-wrap-foot></table-wrap></p><p>After training calibrated models, gradient boosting and random forest models were evaluated individually by 10-fold cross validation by accuracy, specificity, sensitivity and AUC measures for model validation (Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>). All models performed at or above accuracy, specificity and AUC measures of 0.94, however, sensitivity values ranged from 0.40 to 0.725 (Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>). Because of this wide range of sensitivity values, four alternative ensemble approaches using combined random forest and gradient boosting models were explored.</p></sec></sec><sec id="Sec17"><title>Ensemble classifier construction</title><p>To take advantage of the predictive strengths of each random forest and gradient boosting model, ensemble learners for all random forest and all gradient boosting models were constructed. As ensemble classifiers function by combining &#x0201c;diverse&#x0201d; learners [<xref ref-type="bibr" rid="CR37">37</xref>], only models constructed from different training sets were used in each ensemble classifier to maintain diversity in predictors. In other words, ensemble classifiers were constructed from all eight random forest models and a separate set of ensemble classifiers were constructed from all eight gradient boosting models.</p><p>Four types of ensemble classifiers were constructed: a majority vote model, arithmetic means of scores model, geometric means of scores model, and a stacking ensemble model constructed from a logistic regression of model outputs (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref> and &#x0201c;<xref rid="Sec2" ref-type="sec">Methods</xref>&#x0201d; section for details).</p><p>A final training set comprised of 3000 known <italic>Z. mays</italic> protein coding genes and validated lncRNAs was created. This <italic>Z. mays</italic> training data set was used for training the logistic regression classifier because random forest and gradient boosting models were trained on different data sets (see &#x0201c;<xref rid="Sec2" ref-type="sec">Methods</xref>&#x0201d; section). For consistency, all four ensemble methods were also evaluated using these data. The arithmetic mean, geometric mean, and majority vote methods were evaluated by comparing ensemble method outputs to true labels, and 10-fold cross validation scores were used to evaluate the logistic regression stacking model. Accuracy, specificity, and AUC values were similar for all ensemble approaches; therefore, the best performing ensemble method was largely determined by both sensitivity and MCC measures (Table&#x000a0;<xref rid="Tab3" ref-type="table">3</xref>). Using these values as methods of evaluation, the stacking model constructed from gradient boosting model outputs was found to be the best performing model and was used for the remainder of the study.
<table-wrap id="Tab3"><label>Table 3</label><caption><p>Evaluation measures of random forest (RF) and gradient boosting (GB) ensemble models</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">ML model type</th><th align="left">Ensemble type</th><th align="left">AUC</th><th align="left">MCC</th><th align="left">Accuracy</th><th align="left">Sensitivity</th><th align="left">Specificity</th></tr></thead><tbody><tr><td align="left">RF</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left"/><td align="left">Vote</td><td align="left">0.834</td><td align="left">0.725</td><td align="left">0.944</td><td align="left">0.594</td><td align="left">0.995</td></tr><tr><td align="left"/><td align="left">Arithmetic mean</td><td align="left">0.963</td><td align="left">0.661</td><td align="left">0.941</td><td align="left">0.562</td><td align="left">0.996</td></tr><tr><td align="left"/><td align="left">Geometric mean</td><td align="left">0.963</td><td align="left">0.706</td><td align="left">0.941</td><td align="left">0.555</td><td align="left">0.997</td></tr><tr><td align="left"/><td align="left">Logistic regression</td><td align="left">0.835</td><td align="left">0.765</td><td align="left">0.952</td><td align="left">0.665</td><td align="left">0.994</td></tr><tr><td align="left">GB</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left"/><td align="left">Vote</td><td align="left">0.887</td><td align="left">0.797</td><td align="left">0.958</td><td align="left">0.702</td><td align="left">0.995</td></tr><tr><td align="left"/><td align="left">Arithmetic mean</td><td align="left">0.945</td><td align="left">0.786</td><td align="left">0.956</td><td align="left">0.681</td><td align="left">0.996</td></tr><tr><td align="left"/><td align="left">Geometric mean</td><td align="left">0.940</td><td align="left">0.750</td><td align="left">0.949</td><td align="left">0.601</td><td align="left">0.999</td></tr><tr><td align="left"/><td align="left">Logistic regression</td><td align="left">0.883</td><td align="left">0.822</td><td align="left">0.963</td><td align="left">0.745</td><td align="left">0.994</td></tr></tbody></table><table-wrap-foot><p>Statistics for vote, arithmetic mean, and geometric mean models were calculated using outputs of models compared to true labels. Logistic regression evaluation statistics were calculated using the scores found by 10-fold cross validation of <italic>O. sativa</italic> training data and validated lncRNA sequences</p></table-wrap-foot></table-wrap></p></sec><sec id="Sec18"><title>Comparison of meta-learner to GreeNC predictions</title><p>To assess the overlap of predictions to another plant lncRNA resource, the lncRNAs predicted by the stacking generalizer were compared to an established lncRNA database, GreeNC [<xref ref-type="bibr" rid="CR38">38</xref>]. This database uses a transcript filtering method, rather than a machine learning approach, where transcripts must meet the criteria of a classic lncRNA in order to be identified as putative lncRNAs. To be considered a lncRNA in the GreeNC database, the transcript must: be larger than 200nt, have an ORF smaller than 120aa, not have a hit in the SwissProt database or be considered non-coding by the Coding Potential Calculator [<xref ref-type="bibr" rid="CR39">39</xref>], and not be already classified as another class of functional RNA as identified by Rfam.</p><p>Transcript sequences of <italic>O. sativa</italic>, and <italic>E. salsugineum</italic> were downloaded from Phytozome v10.3 and <italic>A. thaliana</italic> sequences from TAIR10 to enable direct comparison to the GreeNC protocol. In total, 1310, 856 and 198 lncRNAs were predicted from <italic>A. thaliana</italic>, <italic>O. sativa</italic>, and <italic>E. salsugineum</italic> respectively, of which 872 (66.6%), 444 (51.9%), and 164 (82.8%) have been previously predicted by GreeNC (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>). Comparing number of predicted lncRNAs using this method to GreeNC, 1700, 4381, and 1471 fewer lncRNAs are identified in <italic>A. thaliana</italic>, <italic>O. sativa</italic> and <italic>E. salsugineum</italic> using the stacking method. Another 438, 412 and 34 putative lncRNAs were identified using the stacking learner that have not been predicted by GreeNC in <italic>A. thaliana</italic>, <italic>O. sativa</italic>, and <italic>E. salsugineum</italic>.
<fig id="Fig2"><label>Fig. 2</label><caption><p>Counts of predicted lncRNAs in <italic>A. thaliana</italic>, <italic>E. salsugineum</italic> and <italic>O. sativa</italic> from the gradient boosting stacking generalizer method and GreeNC database. Counts of predicted lncRNAs in this work from all three species were also compared to predictions recorded in GreeNC. Overlapping predictions of the two methods are represented as shaded bars. The percentages above each bar represent the percent of the total predictions by each method that are shared</p></caption><graphic xlink:href="12864_2018_4665_Fig2_HTML" id="MO2"/></fig></p><sec id="Sec19"><title>Current annotation of top ranking lncRNAs in <italic>A. thaliana</italic>, <italic>E. salsugineum</italic>, and <italic>O. sativa</italic></title><p>Using the prediction scoring system of this stacking method, the current annotation of the highest ranking lncRNAs from each species was explored. Due to the nature of a logistic regression-type ensemble method, transcripts with similar features will have identical prediction scores. As such, multiple prediction score ties exist in the top ranking transcripts of each species (See Additional file&#x000a0;<xref rid="MOESM3" ref-type="media">3</xref> for distribution of lncRNA scores). Using a cutoff of the top three unique prediction scores, annotations of 256, 17 and 94 transcripts in <italic>A. thaliana</italic>, <italic>E. salsugineum</italic>, and <italic>O. sativa</italic> were identified as &#x0201c;top scoring&#x0201d; due to these multiple ties. The majority of predicted lncRNAs in <italic>A. thaliana</italic> were annotated by TAIR as potential natural antisense lncRNAs, pseudogenes, and transposable element related genes (Table&#x000a0;<xref rid="Tab4" ref-type="table">4</xref>). Only one transcript from <italic>E. salsugineum</italic>&#x02019;s top predictions, and two transcripts from <italic>O. sativa</italic>&#x02019;s top predictions have annotation in Phytozome v12.
<table-wrap id="Tab4"><label>Table 4</label><caption><p>Number of transcripts in annotation categories of top ranking lncRNAs in the <italic>A. thaliana</italic> transcriptome</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Annotation category</th><th align="left">Number of annotations</th></tr></thead><tbody><tr><td align="left">Natural antisense lncRNA</td><td align="left">64</td></tr><tr><td align="left">Pseudogene</td><td align="left">75</td></tr><tr><td align="left">Transposable element gene</td><td align="left">10</td></tr><tr><td align="left">Transposase</td><td align="left">46</td></tr><tr><td align="left">miRNA primary transcript</td><td align="left">4</td></tr><tr><td align="left">Hypothetical protein</td><td align="left">5</td></tr><tr><td align="left">Protein</td><td align="left">8</td></tr><tr><td align="left">Other</td><td align="left">8</td></tr></tbody></table></table-wrap></p></sec><sec id="Sec20"><title>Novel lncRNAs identified by the stacking generalizer</title><p>Annotation of the predicted lncRNAs not previously identified by GreeNC from all three species were explored. While all of the newly predicted lncRNAs from <italic>E. salsugineum</italic> and <italic>O. sativa</italic> were annotated as homologs of <italic>A. thaliana</italic> genes, 10 of 34 novel lncRNAs from <italic>E. salsugineum</italic> and 11 of 412 novel lncRNAs from <italic>O. sativa</italic> were annotated specifically as proteins. Of the newly predicted lncRNAs from <italic>A. thaliana</italic>, 417 remain unannotated, with only seven predicted as potential proteins.</p></sec></sec></sec><sec id="Sec21" sec-type="discussion"><title>Discussion</title><p>Our approach to lncRNA prediction by stacking with logistic regression allows researchers to combine the strengths of various machine learning models without restricting predictions to arbitrary feature cutoffs of a classic lncRNA definition. The flexible nature of this lncRNA prediction tool allows the model to be updated when additional lncRNAs are validated, helping researchers focus on empirical validation of plant lncRNA transcripts. As lncRNA research has previously primarily focused on animal systems with a large emphasis on humans and mice, this tools&#x02019; training sets may have a human and mouse bias that is present out of necessity. When more plant lncRNAs are added to the tool&#x02019;s training set, the human and mouse lncRNA bias that may be found in the model will be reduced. Acting as positive feedback, as more plant lncRNAs are added to the model, the predictions themselves will improve.</p><p>To help researchers choose the best lncRNAs for validation, the predictions are ranked. While softwares that rank lncRNA predictions, such as COME [<xref ref-type="bibr" rid="CR19">19</xref>], do exist, they are trained on a majority of non-empirically validated transcripts adding a potential bias towards non functional transcripts. A combination of ranked predictions and models trained only on true lncRNAs will help ensure researchers focus on the most likely functional lncRNAs</p><p>A lower number of identified lncRNAs in comparison to other prediction methods, such as GreeNC, was expected. Using a machine learning classification method, lncRNA predictions were not constrained to arbitrary criteria for this RNA classification. Instead, the classifiers were trained on validated lncRNAs and are expected to identify only true functional lncRNA transcripts. In other words, although transcripts were subjected to less rules for lncRNA identification, the stacking method is expected to have higher accuracy. Further, this work was tested only on sequence information available from Phytozome v10.3 in order to compare predictions directly to GreeNC. Additional transcript sequences available in public repositories, or from researchers&#x02019; own sequencing libraries, would add to the number of putative lncRNAs and could be used to improve accuracy. Moreover, COOLAIR and COLDAIR, known <italic>A. thaliana</italic> lncRNAs, are not predicted by GreeNC because the database relies on transcript sequences provided by Phytozome and these transcript sequences were not available in the database at the time of prediction. Our stacking generalizer method for lncRNA prediction is not restricted to a single data source, and allows researchers to calculate a lncRNA score from any transcript sequence, not solely those available from an online repository.</p><p>While we expect a lower number of putative lncRNAs than other protocols, of interest is the lower proportion of predicted lncRNAs <italic>E. salsugineum</italic> genome compared to <italic>O. sativa</italic> or <italic>A. thaliana</italic>. A reason for the low lncRNA discovery rate in <italic>E. salsugineum</italic>, could potentially be that plants were not subjected to conditions sufficient for observable lncRNA expression. For example, <italic>IPS1</italic> [<xref ref-type="bibr" rid="CR8">8</xref>] and <italic>COLDAIR</italic> [<xref ref-type="bibr" rid="CR9">9</xref>], two well studied <italic>A. thaliana</italic> lncRNAs, are induced by phosphate or cold-related stresses respectively. This hypothesis is supported by Derrien et al. [<xref ref-type="bibr" rid="CR16">16</xref>] who found human lncRNA expression to be at low levels in a condition, tissue and developmental state specific manner. It is also possible that there exists natural variation in the numbers of putative lncRNAs in different species. Further investigation on the number of putative lncRNA and their relationships to plant growth conditions for transcriptome sequencing of multiple plant species is currently underway.</p><p>Although the quantity of detected lncRNAs was low in <italic>E. salsugineum</italic>, the quality of putative lncRNAs in all three species is high, demonstrating that this tool can accurately classify transcripts no matter size or quality of input transcript sequence data. When exploring the annotations of the top scoring predictions in <italic>A. thaliana</italic>, the majority of transcripts were annotated as potential natural antisense lncRNA, pseudogenes, transposable elements, small RNA primary transcripts, or remain computationally predicted as hypothetical proteins (Table&#x000a0;<xref rid="Tab4" ref-type="table">4</xref>). Pseudogenes remain poorly understood, however there is evidence of pseudogene derived lncRNAs regulating their parental genes [<xref ref-type="bibr" rid="CR40">40</xref>], making pseudogene derived lncRNAs targets of potential regulatory interest. Transposable elements are another known source of lncRNAs, particularly in vertebrates [<xref ref-type="bibr" rid="CR41">41</xref>] and long intergenic non-protein coding RNAs in plants [<xref ref-type="bibr" rid="CR3">3</xref>]. This study did not find evidence that features related to transposable elements were helpful at predicting plant lncRNAs as the addition of transposable related features decreased the quality of lncRNA predictions. However, exploration of the training data used for model creation indicates that only 19 of the 436 (4.4%) validated lncRNAs show evidence of transposable element association. Of this minor group of transposable element associated lncRNAs, none were from plant species. Nonetheless, the tool did not favour lncRNAs that are not associated with transposable elements, as the tool remained successful at identifying these types of transcripts. Additionally, as novel lncRNAs are validated and added to this tool, an update to the models&#x02019; feature selection step may be required, and may lead to future inclusion of transposable element associated characters. However, by not including transposable element information, the computational time for data preprocessing before transcript classification is significantly reduced to minutes from days as RepeatMasker is no longer needed.</p><p>Features of secondary RNA structure have previously been used in other RNA classifiers, such as nRC [<xref ref-type="bibr" rid="CR42">42</xref>] and GraPPLE [<xref ref-type="bibr" rid="CR43">43</xref>], that are used to classify RNAs into functional categories. These classifications include RNAs such as miRNAs, tRNAs, rRNA, ribozymes, and riboswitch domains, all of which have conserved secondary structures. Rather than using sequence homology, commonly used with protein coding genes, structural homology has previously been used in lncRNA functional prediction, and identification [<xref ref-type="bibr" rid="CR5">5</xref>]. However, a lack of secondary structure conservation in animal lncRNAs with conserved sequences (<italic>e. g. HOTAIR, ncSRA and Xist</italic>) was recently observed [<xref ref-type="bibr" rid="CR44">44</xref>]. As structural conservation may not be as pervasive in lncRNA classification as previously thought, we did not include structural features in our ensemble learner. A lack of structural features allows the predictor to identify a wide variety of lncRNAs and does not limit the predictor to the structures of the small number of validated plant lncRNAs available. An additional test was completed to ensure our predictor, lacking structural features, did not merely distinguish non-coding transcripts from protein coding genes. By comparing the results of the ensemble learner to predicted CPAT protein coding probabilities [<xref ref-type="bibr" rid="CR21">21</xref>], our ensemble method was able distinguish between other CPAT-predicted non-coding transcripts and likely lncRNAs (Additional file&#x000a0;<xref rid="MOESM4" ref-type="media">4</xref>: Table S2). A portion of putative lncRNAs in all three plant species are also predicted to be protein coding and may encode small regulatory peptides.</p><p>High quality lncRNA predictions from this method require sequences from fully processed transcripts and cannot be predicted directly from genomic sequences. Nevertheless, potential lncRNA sequences of interest are typically more accessible by transcriptome sequencing rather than complete genome sequencing, which remains technically challenging for crop plants with large and/or polyploid genomes. This tool is flexible and can be used to identify lncRNAs from all transcriptional units of an organism, or to check the lncRNA score of a single transcript. Furthermore, as mentioned in their summary, Kang et al. [<xref ref-type="bibr" rid="CR22">22</xref>] suggest that researchers should now consider working on uncovering the biological implications of lncRNAs rather than solely using computational tools for transcript classification. We agree that future work should centre around using software to also further knowledge on these types of transcripts. Due to the diversity of these transcripts, there is increasing need for classification of lncRNAs into categories based on mechanism and function, as well as continuation of empirical validation, particularly for plants. Once validated, not only can novel lncRNAs mechanisms be explored, but their features can be added to this tool for further improvement in lncRNA prediction.</p></sec><sec id="Sec22" sec-type="conclusion"><title>Conclusion</title><p>For this machine learning based tool for lncRNA prediction, we have used only empirically validated lncRNAs for training. Although lncRNAs from multiple species were used, our tool identified putative plant lncRNAs with high scores. Ranking of lncRNA predictions should improve the confidence by which gene products meriting validation are selected for empirical testing. The machine learning structure and its open source availability allows for the flexible inclusion of validated lncRNAs as our knowledge of this class of RNA improves. An important consideration of this tool is that it is not constrained by preconceived rules that may or may not appropriately classify lncRNA properties. As Kung et al. [<xref ref-type="bibr" rid="CR1">1</xref>] suggest, setting rules for the detection of these non-conforming transcripts could be detrimental due to the diversity in functionality, structure, expression and mechanism of these transcripts. Accordingly, our stacking generalizer model based on gradient boosting models will facilitate lncRNA identification without imposing arbitrary rules for lncRNA detection.</p></sec><sec sec-type="supplementary-material"><title>Additional files</title><sec id="Sec23"><p>
<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="12864_2018_4665_MOESM1_ESM.zip"><label>Additional file 1</label><caption><p>Non-coding RNA search terms. Terms used to search for organism specific non-coding sequences on RNA central. (ZIP 16500 kb)</p></caption></media></supplementary-material>
</p><p>
<supplementary-material content-type="local-data" id="MOESM2"><media xlink:href="12864_2018_4665_MOESM2_ESM.txt"><label>Additional file 2</label><caption><p>Random protein training data sets, lncRNA data sets. Fasta files of protein coding and lncRNA sequences in data sets used for training machine learning classifiers. (TXT 0.07725 kb)</p></caption></media></supplementary-material>
</p><p>
<supplementary-material content-type="local-data" id="MOESM3"><media xlink:href="12864_2018_4665_MOESM3_ESM.pdf"><label>Additional file 3</label><caption><p>Distribution of predicted lncRNA scores. Figure and table of distribution of scores. (PDF 58 kb)</p></caption></media></supplementary-material>
</p><p>
<supplementary-material content-type="local-data" id="MOESM4"><media xlink:href="12864_2018_4665_MOESM4_ESM.pdf"><label>Additional file 4</label><caption><p>Comparison of predicted lncRNAs to CPAT results. Table of results and explanation of additional test. (PDF 31 kb)</p></caption></media></supplementary-material>
</p></sec></sec></body><back><glossary><title>Abbreviations</title><def-list><def-item><term>AUC</term><def><p>Area under the curve</p></def></def-item><def-item><term>lncRNA</term><def><p>Long non-protein coding RNA</p></def></def-item><def-item><term>MCC</term><def><p>Matthews correlation coefficient</p></def></def-item><def-item><term>ORF</term><def><p>Open reading frame</p></def></def-item><def-item><term>TE</term><def><p>Transposable element</p></def></def-item></def-list></glossary><fn-group><fn><p><bold>Electronic supplementary material</bold></p><p>The online version of this article (10.1186/s12864-018-4665-2) contains supplementary material, which is available to authorized users.</p></fn></fn-group><ack><title>Acknowledgements</title><p>We thank two anonymous reviewers for their helpful questions and comments.</p><sec id="d29e2389"><title>Funding</title><p>This work was supported by grants from the Ontario Research Fund-Research Excellence and Natural Science and Engineering Research Council of Canada to EAW (RGPIN-2015-06530) and to GBG (RGPIN-2015-04477). The funding bodies supported the publication costs of this manuscript.</p></sec><sec id="d29e2394"><title>Availability of data and materials</title><p>The first version of code used in this work is available at <ext-link ext-link-type="uri" xlink:href="http://www.github.com/gbgolding/crema">www.github.com/gbgolding/crema</ext-link>. Random protein and lncRNA datasets used for machine learning model training are attached as supplementary material.</p></sec></ack><notes notes-type="author-contribution"><title>Authors&#x02019; contributions</title><p>The idea of this article was conceived by all authors. CMAS developed the tool, acquired the datasets, obtained and analyzed the results, and prepared the manuscript. GBG and EAW supervised the analysis, and edited the manuscript. All authors have read and approved the manuscript.</p></notes><notes notes-type="COI-statement"><sec id="d29e2410"><title>Ethics approval and consent to participate</title><p>Not applicable as this study did not use plant or animal material, and instead genomic and transcriptomic data available from various databases.</p></sec><sec id="d29e2415"><title>Competing interests</title><p>The authors declare that they have no competing interests.</p></sec><sec id="d29e2420"><title>Publisher&#x02019;s Note</title><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></sec></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1</label><mixed-citation publication-type="other">Kung JT, Colognori D, Lee JT. Long noncoding RNAs: past, present, and future. Genetics. 2013; 193:651&#x02013;9. 10.1534/genetics.112.146704.</mixed-citation></ref><ref id="CR2"><label>2</label><mixed-citation publication-type="other">Kapranov P, Cheng J, Dike S, Nix DA, Duttagupta R, Willingham AT, Stadler PF, Hertel J, Hackerm&#x000fc;ller J, Hofacker IL, Bell I, Cheung E, Drenkow J, Dumais E, Patel S, Helt G, Ganesh M, Ghosh S, Piccolboni A, Sementchenko V, Tammana H, Gingeras TR. RNA maps reveal new RNA classes and a possible function for pervasive transcription. Science. 2007; 316:1484&#x02013;8. 10.1126/science.1138341.</mixed-citation></ref><ref id="CR3"><label>3</label><mixed-citation publication-type="other">Wang D, Qu Z, Yang L, Zhang Q, Liu ZH, Do T, Adelson DL, Wang ZY, Searle I, Zhu JK. Transposable elements (TEs) contribute to stress-related long intergenic noncoding RNAs in plants. Plant J. 2017; 90:133&#x02013;46. 10.1111/tpj.13481.</mixed-citation></ref><ref id="CR4"><label>4</label><mixed-citation publication-type="other">Xu Q, Song Z, Zhu C, Tao C, Kang L, Liu W, He F, Yan J, Sang T. Systematic comparison of lncRNAs with protein coding mRNAs in population expression and their response to environmental change. BMC Plant Biol. 2017; 17:42. 10.1186/s12870-017-0984-8.</mixed-citation></ref><ref id="CR5"><label>5</label><mixed-citation publication-type="other">Hezroni H, Koppstein D, Schwartz MG, Avrutin A, Bartel DP, Ulitsky I. Principles of long noncoding RNA evolution derived from direct comparison of transcriptomes in 17 species. Cell Rep. 2015; 11:1110&#x02013;22. 10.1016/j.celrep.2015.04.023.</mixed-citation></ref><ref id="CR6"><label>6</label><mixed-citation publication-type="other">Jeon Y, Lee JT. YY1 tethers Xist RNA to the inactive X nucleation center. Cell. 2011; 146:119&#x02013;33. 10.1016/j.cell.2011.06.026.</mixed-citation></ref><ref id="CR7"><label>7</label><mixed-citation publication-type="other">Zhao J, Sun BK, Erwin JA, Song JJ, Lee JT. Polycomb proteins targeted by a short repeat RNA to the mouse X chromosome. Science. 2008; 322:750&#x02013;6. 10.1126/science.1163045.</mixed-citation></ref><ref id="CR8"><label>8</label><mixed-citation publication-type="other">Franco-Zorrilla JM, Valli A, Todesco M, Mateos I, Puga MI, Rubio-Somoza I, Leyva A, Weigel D, Garcia JA, Paz-Ares J. Target mimicry provides a new mechanism for regulation of microRNA activity. Nat Genet. 2007; 39:1033&#x02013;7. 10.1038/ng2079.</mixed-citation></ref><ref id="CR9"><label>9</label><mixed-citation publication-type="other">He C, Huang H, Xu L. Mechanisms guiding Polycomb activities during gene silencing in Arabidopsis thaliana. Front Plant Sci. 2013; 4:454. 10.3389/fpls.2013.00454.</mixed-citation></ref><ref id="CR10"><label>10</label><mixed-citation publication-type="other">Ma L, Bajic VB, Zhang Z. On the classification of long non-coding RNAs. RNA Biol. 2013; 10:925&#x02013;33. 10.4161/rna.24604.</mixed-citation></ref><ref id="CR11"><label>11</label><mixed-citation publication-type="other">Anderson DM, Anderson KM, Chang CL, Makarewich CA, Nelson BR, McAnally JR, Kasaragod P, Shelton JM, Liou J, Bassel-Duby R, Olson EN. A micropeptide encoded by a putative long noncoding RNA regulates muscle performance. Cell. 2015; 160:595&#x02013;606. 10.1016/j.cell.2015.01.009.</mixed-citation></ref><ref id="CR12"><label>12</label><mixed-citation publication-type="other">Ji Z, Song R, Regev A, Struhl K. Many lncRNAs, 5&#x02019;UTRs, and pseudogenes are translated and some are likely to express functional proteins. Elife. 2015; 4:08890. 10.7554/eLife.08890.</mixed-citation></ref><ref id="CR13"><label>13</label><mixed-citation publication-type="other">Juntawong P, Girke T, Bazin J, Bailey-Serres J. Translational dynamics revealed by genome-wide profiling of ribosome footprints in Arabidopsis. Proc Natl Acad Sci U S A. 2014; 111:203&#x02013;12. 10.1073/pnas.1317811111.</mixed-citation></ref><ref id="CR14"><label>14</label><mixed-citation publication-type="other">Guttman M, Russell P, Ingolia NT, Weissman JS, Lander ES. Ribosome profiling provides evidence that large noncoding RNAs do not encode proteins. Cell. 2013; 154:240&#x02013;51. 10.1016/j.cell.2013.06.009.</mixed-citation></ref><ref id="CR15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeChiara</surname><given-names>TM</given-names></name><name><surname>Brosius</surname><given-names>J</given-names></name></person-group><article-title>Neural BC1 RNA: cDNA clones reveal nonrepetitive sequence content</article-title><source>Proc Natl Acad Sci U S A</source><year>1987</year><volume>84</volume><fpage>2624</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1073/pnas.84.9.2624</pub-id><?supplied-pmid 2437583?><pub-id pub-id-type="pmid">2437583</pub-id></element-citation></ref><ref id="CR16"><label>16</label><mixed-citation publication-type="other">Derrien T, Johnson R, Bussotti G, Tanzer A, Djebali S, Tilgner H, Guernec G, Martin D, Merkel A, Knowles DG, Lagarde J, Veeravalli L, Ruan X, Ruan Y, Lassmann T, Carninci P, Brown JB, Lipovich L, Gonzalez JM, Thomas M, Davis CA, Shiekhattar R, Gingeras TR, Hubbard TJ, Notredame C, Harrow J, Guigo R. The GENCODE v7 catalog of human long noncoding RNAs: analysis of their gene structure, evolution, and expression. Genome Res. 2012; 22:1775&#x02013;89. 10.1101/gr.132159.111.</mixed-citation></ref><ref id="CR17"><label>17</label><mixed-citation publication-type="other">Li A, Zhang J, Zhou Z. PLEK: a tool for predicting long non-coding RNAs and messenger RNAs based on an improved k-mer scheme. BMC Bioinformatics. 2014; 15:311. 10.1186/1471-2105-15-311.</mixed-citation></ref><ref id="CR18"><label>18</label><mixed-citation publication-type="other">Sun L, Liu H, Zhang L, Meng J. lncRScan-SVM: A Tool for Predicting Long Non-Coding RNAs Using Support Vector Machine. PLoS ONE. 2015; 10:0139654. 10.1371/journal.pone.0139654.</mixed-citation></ref><ref id="CR19"><label>19</label><mixed-citation publication-type="other">Hu L, Xu Z, Hu B, Lu ZJ. COME: a robust coding potential calculation tool for lncRNA identification and characterization based on multiple features. Nucleic Acids Res. 2017; 45:2. 10.1093/nar/gkw798.</mixed-citation></ref><ref id="CR20"><label>20</label><mixed-citation publication-type="other">Struhl K. Transcriptional noise and the fidelity of initiation by RNA polymerase II. Nat Struct Mol Biol. 2007; 14:103&#x02013;5. 10.1038/nsmb0207-103.</mixed-citation></ref><ref id="CR21"><label>21</label><mixed-citation publication-type="other">Wang L, Park HJ, Dasari S, Wang S, Kocher JP, Li W. CPAT: Coding-Potential Assessment Tool using an alignment-free logistic regression model. Nucleic Acids Res. 2013; 41:74. 10.1093/nar/gkt006.</mixed-citation></ref><ref id="CR22"><label>22</label><mixed-citation publication-type="other">Kang YJ, Yang DC, Kong L, Hou M, Meng YQ, Wei L, Gao G. CPC2: a fast and accurate coding potential calculator based on sequence intrinsic features. Nucleic Acids Res. 2017. 10.1093/nar/gkx428.</mixed-citation></ref><ref id="CR23"><label>23</label><mixed-citation publication-type="other">Axtell MJ, Westholm JO, Lai EC. Vive la difference: biogenesis and evolution of microRNAs in plants and animals. Genome Biol. 2011; 12:221. 10.1186/gb-2011-12-4-221.</mixed-citation></ref><ref id="CR24"><label>24</label><mixed-citation publication-type="other">Volders PJ, Helsens K, Wang X, Menten B, Martens L, Gevaert K, Vandesompele J, Mestdagh P. LNCipedia: a database for annotated human lncRNA transcript sequences and structures. Nucleic Acids Res. 2013; 41:246&#x02013;51. 10.1093/nar/gks915.</mixed-citation></ref><ref id="CR25"><label>25</label><mixed-citation publication-type="other">Zhao Y, Li H, Fang S, Kang Y, Wu W, Hao Y, Li Z, Bu D, Sun N, Zhang MQ, Chen R. NONCODE 2016: an informative and valuable data source of long non-coding RNAs. Nucleic Acids Res. 2016; 44:203&#x02013;8. 10.1093/nar/gkv1252.</mixed-citation></ref><ref id="CR26"><label>26</label><mixed-citation publication-type="other">Liu B, Wang S, Long R, Chou KC. iRSpot-EL: identify recombination spots with an ensemble learning approach. Bioinformatics. 2017; 33:35&#x02013;41. 10.1093/bioinformatics/btw539.</mixed-citation></ref><ref id="CR27"><label>27</label><mixed-citation publication-type="other">You ZH, Lei YK, Zhu L, Xia J, Wang B. Prediction of protein-protein interactions from amino acid sequences with ensemble extreme learning machines and principal component analysis. BMC Bioinformatics. 2013; 14 Suppl 8:10. 10.1186/1471-2105-14-S8-S10.</mixed-citation></ref><ref id="CR28"><label>28</label><mixed-citation publication-type="other">Buchfink B, Xie C, Huson DH. Fast and sensitive protein alignment using DIAMOND. Nat Methods. 2015; 12:59&#x02013;60. 10.1038/nmeth.3176.</mixed-citation></ref><ref id="CR29"><label>29</label><mixed-citation publication-type="other">Smit AFA, Hubley R, Green P. Repeatmasker open-4.0. 2015. <ext-link ext-link-type="uri" xlink:href="http://www.repeatmasker.org">http://www.repeatmasker.org</ext-link>.</mixed-citation></ref><ref id="CR30"><label>30</label><mixed-citation publication-type="other">Yi X, Zhang Z, Ling Y, Xu W, Su Z. PNRD: a plant non-coding RNA database. Nucleic Acids Res. 2015; 43:982&#x02013;9. 10.1093/nar/gku1162.</mixed-citation></ref><ref id="CR31"><label>31</label><mixed-citation publication-type="other">Goodstein DM, Shu S, Howson R, Neupane R, Hayes RD, Fazo J, Mitros T, Dirks W, Hellsten U, Putnam N, Rokhsar DS. Phytozome: a comparative platform for green plant genomics. Nucleic Acids Res. 2012; 40:1178&#x02013;86. 10.1093/nar/gkr944.</mixed-citation></ref><ref id="CR32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bairoch</surname><given-names>A</given-names></name><name><surname>Apweiler</surname><given-names>R</given-names></name></person-group><article-title>The SWISS-PROT protein sequence database and its supplement TrEMBL in 2000</article-title><source>Nucleic Acids Res</source><year>2000</year><volume>28</volume><fpage>45</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1093/nar/28.1.45</pub-id><?supplied-pmid 10592178?><pub-id pub-id-type="pmid">10592178</pub-id></element-citation></ref><ref id="CR33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F</given-names></name><name><surname>Varoquaux</surname><given-names>G</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Michel</surname><given-names>V</given-names></name><name><surname>Thirion</surname><given-names>B</given-names></name><name><surname>Grisel</surname><given-names>O</given-names></name><name><surname>Blondel</surname><given-names>M</given-names></name><name><surname>Prettenhofer</surname><given-names>P</given-names></name><name><surname>Weiss</surname><given-names>R</given-names></name><name><surname>Dubourg</surname><given-names>V</given-names></name><name><surname>Vanderplas</surname><given-names>J</given-names></name><name><surname>Passos</surname><given-names>A</given-names></name><name><surname>Cournapeau</surname><given-names>D</given-names></name><name><surname>Brucher</surname><given-names>M</given-names></name><name><surname>Perrot</surname><given-names>M</given-names></name><name><surname>Duchesnay</surname><given-names>E</given-names></name></person-group><article-title>Scikit-learn: machine learning in Python</article-title><source>J Mach Learn Res</source><year>2011</year><volume>12</volume><fpage>2825</fpage><lpage>30</lpage></element-citation></ref><ref id="CR34"><label>34</label><mixed-citation publication-type="other">Jed Wing MKC, Weston S, Williams A, Keefer C, Engelhardt A, Cooper T, Mayer Z, Kenkel B, The R Core Team, Benesty M, Lescarbeau R, Ziem A, Scrucca L, Tang Y, Candan C, Hunt T. Caret: Classification and Regression Training. 2017. R package version 6.0-76. <ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=caret">https://CRAN.R-project.org/package=caret</ext-link>. Accessed 1 Feb 2018.</mixed-citation></ref><ref id="CR35"><label>35</label><mixed-citation publication-type="other">Niazi F, Valadkhan S. Computational analysis of functional long noncoding RNAs reveals lack of peptide-coding capacity and parallels with 3&#x02019; UTRs. RNA. 2012; 18:825&#x02013;43. 10.1261/rna.029520.111.</mixed-citation></ref><ref id="CR36"><label>36</label><mixed-citation publication-type="other">Di C, Yuan J, Wu Y, Li J, Lin H, Hu L, Zhang T, Qi Y, Gerstein MB, Guo Y, Lu ZJ. Characterization of stress-responsive lncRNAs in Arabidopsis thaliana by integrating expression, epigenetic and structural features. Plant J. 2014; 80:848&#x02013;61. 10.1111/tpj.12679.</mixed-citation></ref><ref id="CR37"><label>37</label><mixed-citation publication-type="other">Brown G, Wyatt J, Harris R, Yao X. Diversity creation methods: a survey and categorisation. Inf Fusion. 2005. 10.1016/j.inffus.2004.04.004.</mixed-citation></ref><ref id="CR38"><label>38</label><mixed-citation publication-type="other">PaytuviGallart A, HermosoPulido A, AnzarMartinezdeLagran I, Sanseverino W, AieseCigliano R. GREENC: a Wiki-based database of plant lncRNAs. Nucleic Acids Res. 2016; 44:1161&#x02013;6. 10.1093/nar/gkv1215.</mixed-citation></ref><ref id="CR39"><label>39</label><mixed-citation publication-type="other">Kong L, Zhang Y, Ye ZQ, Liu XQ, Zhao SQ, Wei L, Gao G. CPC: assess the protein-coding potential of transcripts using sequence features and support vector machine. Nucleic Acids Res. 2007; 35:345&#x02013;9. 10.1093/nar/gkm391.</mixed-citation></ref><ref id="CR40"><label>40</label><mixed-citation publication-type="other">Milligan MJ, Lipovich L. Pseudogene-derived lncRNAs: emerging regulators of gene expression. Front Genet. 2014; 5:476. 10.3389/fgene.2014.00476.</mixed-citation></ref><ref id="CR41"><label>41</label><mixed-citation publication-type="other">Kapusta A, Kronenberg Z, Lynch VJ, Zhuo X, Ramsay L, Bourque G, Yandell M, Feschotte C. Transposable elements are major contributors to the origin, diversification, and regulation of vertebrate long noncoding RNAs. PLoS Genet. 2013; 9:1003470. 10.1371/journal.pgen.1003470.</mixed-citation></ref><ref id="CR42"><label>42</label><mixed-citation publication-type="other">Fiannaca A, LaRosa M, LaPaglia L, Rizzo R, Urso A. nRC: non-coding RNA Classifier based on structural features. BioData Min. 2017; 10:27. 10.1186/s13040-017-0148-2.</mixed-citation></ref><ref id="CR43"><label>43</label><mixed-citation publication-type="other">Childs L, Nikoloski Z, May P, Walther D. Identification and classification of ncRNA molecules using graph properties. Nucleic Acids Res. 2009; 37:66. 10.1093/nar/gkp206.</mixed-citation></ref><ref id="CR44"><label>44</label><mixed-citation publication-type="other">Rivas E, Clements J, Eddy SR. A statistical test for conserved RNA structure shows lack of evidence for structure in lncRNAs. Nat Methods. 2017; 14:45&#x02013;8. 10.1038/nmeth.4066.</mixed-citation></ref></ref-list></back></article>